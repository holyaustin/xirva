[{"id": "2011.00041", "submitter": "Mouloud Belbahri", "authors": "Belbahri Mouloud, Gandouet Olivier, Kazma Ghaith", "title": "Adapting Neural Networks for Uplift Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift is a particular case of individual treatment effect modeling. Such\nmodels deal with cause-and-effect inference for a specific factor, such as a\nmarketing intervention. In practice, these models are built on customer data\nwho purchased products or services to improve product marketing. Uplift is\nestimated using either i) conditional mean regression or ii) transformed\noutcome regression. Most existing approaches are adaptations of classification\nand regression trees for the uplift case. However, in practice, these\nconventional approaches are prone to overfitting. Here we propose a new method\nusing neural networks. This representation allows to jointly optimize the\ndifference in conditional means and the transformed outcome losses. As a\nconsequence, the model not only estimates the uplift, but also ensures\nconsistency in predicting the outcome. We focus on fully randomized\nexperiments, which is the case of our data. We show our proposed method\nimproves the state-of-the-art on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:42:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mouloud", "Belbahri", ""], ["Olivier", "Gandouet", ""], ["Ghaith", "Kazma", ""]]}, {"id": "2011.00046", "submitter": "Edoardo Belli", "authors": "Edoardo Belli, Simone Vantini", "title": "Measure Inducing Classification and Regression Trees for Functional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a tree-based algorithm for classification and regression problems\nin the context of functional data analysis, which allows to leverage\nrepresentation learning and multiple splitting rules at the node level,\nreducing generalization error while retaining the interpretability of a tree.\nThis is achieved by learning a weighted functional $L^{2}$ space by means of\nconstrained convex optimization, which is then used to extract multiple\nweighted integral features from the input functions, in order to determine the\nbinary split for each internal node of the tree. The approach is designed to\nmanage multiple functional inputs and/or outputs, by defining suitable\nsplitting rules and loss functions that can depend on the specific problem and\ncan also be combined with scalar and categorical data, as the tree is grown\nwith the original greedy CART algorithm. We focus on the case of scalar-valued\nfunctional inputs defined on unidimensional domains and illustrate the\neffectiveness of our method in both classification and regression tasks,\nthrough a simulation study and four real world applications.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:49:53 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Belli", "Edoardo", ""], ["Vantini", "Simone", ""]]}, {"id": "2011.00050", "submitter": "Timothy Nguyen", "authors": "Timothy Nguyen, Zhourong Chen, Jaehoon Lee", "title": "Dataset Meta-Learning from Kernel Ridge-Regression", "comments": "Accepted to ICLR 2021. Open source implementation:\n  https://colab.sandbox.google.com/github/google-research/google-research/blob/master/kip/KIP.ipynb", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most fundamental aspects of any machine learning algorithm is the\ntraining data used by the algorithm. We introduce the novel concept of\n$\\epsilon$-approximation of datasets, obtaining datasets which are much smaller\nthan or are significant corruptions of the original training data while\nmaintaining similar model performance. We introduce a meta-learning algorithm\ncalled Kernel Inducing Points (KIP) for obtaining such remarkable datasets,\ninspired by the recent developments in the correspondence between\ninfinitely-wide neural networks and kernel ridge-regression (KRR). For KRR\ntasks, we demonstrate that KIP can compress datasets by one or two orders of\nmagnitude, significantly improving previous dataset distillation and subset\nselection methods while obtaining state of the art results for MNIST and\nCIFAR-10 classification. Furthermore, our KIP-learned datasets are transferable\nto the training of finite-width neural networks even beyond the lazy-training\nregime, which leads to state of the art results for neural network dataset\ndistillation with potential applications to privacy-preservation.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:54:04 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 16:52:32 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 19:15:46 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Nguyen", "Timothy", ""], ["Chen", "Zhourong", ""], ["Lee", "Jaehoon", ""]]}, {"id": "2011.00094", "submitter": "Yuan Chen", "authors": "Yuan Chen, Donglin Zeng, Tianchen Xu, Yuanjia Wang", "title": "Representation Learning for Integrating Multi-domain Outcomes to\n  Optimize Individualized Treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For mental disorders, patients' underlying mental states are non-observed\nlatent constructs which have to be inferred from observed multi-domain\nmeasurements such as diagnostic symptoms and patient functioning scores.\nAdditionally, substantial heterogeneity in the disease diagnosis between\npatients needs to be addressed for optimizing individualized treatment policy\nin order to achieve precision medicine. To address these challenges, we propose\nan integrated learning framework that can simultaneously learn patients'\nunderlying mental states and recommend optimal treatments for each individual.\nThis learning framework is based on the measurement theory in psychiatry for\nmodeling multiple disease diagnostic measures as arising from the underlying\ncauses (true mental states). It allows incorporation of the multivariate pre-\nand post-treatment outcomes as well as biological measures while preserving the\ninvariant structure for representing patients' latent mental states. A\nmulti-layer neural network is used to allow complex treatment effect\nheterogeneity. Optimal treatment policy can be inferred for future patients by\ncomparing their potential mental states under different treatments given the\nobserved multi-domain pre-treatment measurements. Experiments on simulated data\nand a real-world clinical trial data show that the learned treatment polices\ncompare favorably to alternative methods on heterogeneous treatment effects,\nand have broad utilities which lead to better patient outcomes on multiple\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:30:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Chen", "Yuan", ""], ["Zeng", "Donglin", ""], ["Xu", "Tianchen", ""], ["Wang", "Yuanjia", ""]]}, {"id": "2011.00144", "submitter": "Samarth Gupta", "authors": "Samarth Gupta, Saurabh Amin", "title": "Integer Programming-based Error-Correcting Output Code Design for Robust\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error-Correcting Output Codes (ECOCs) offer a principled approach for\ncombining simple binary classifiers into multiclass classifiers. In this paper,\nwe investigate the problem of designing optimal ECOCs to achieve both nominal\nand adversarial accuracy using Support Vector Machines (SVMs) and binary deep\nlearning models. In contrast to previous literature, we present an Integer\nProgramming (IP) formulation to design minimal codebooks with desirable error\ncorrecting properties. Our work leverages the advances in IP solvers to\ngenerate codebooks with optimality guarantees. To achieve tractability, we\nexploit the underlying graph-theoretic structure of the constraint set in our\nIP formulation. This enables us to use edge clique covers to substantially\nreduce the constraint set. Our codebooks achieve a high nominal accuracy\nrelative to standard codebooks (e.g., one-vs-all, one-vs-one, and dense/sparse\ncodes). We also estimate the adversarial accuracy of our ECOC-based classifiers\nin a white-box setting. Our IP-generated codebooks provide non-trivial\nrobustness to adversarial perturbations even without any adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 23:35:18 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Gupta", "Samarth", ""], ["Amin", "Saurabh", ""]]}, {"id": "2011.00159", "submitter": "Xiaowu Dai", "authors": "Xiaowu Dai and Michael I. Jordan", "title": "Learning Strategies in Decentralized Matching Markets under Uncertain\n  Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two-sided decentralized matching markets in which participants have\nuncertain preferences. We present a statistical model to learn the preferences.\nThe model incorporates uncertain state and the participants' competition on one\nside of the market. We derive an optimal strategy that maximizes the agent's\nexpected payoff and calibrate the uncertain state by taking the opportunity\ncosts into account. We discuss the sense in which the matching derived from the\nproposed strategy has a stability property. We also prove a fairness property\nthat asserts that there exists no justified envy according to the proposed\nstrategy. We provide numerical results to demonstrate the improved payoff,\nstability and fairness, compared to alternative methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 03:08:22 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Dai", "Xiaowu", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.00179", "submitter": "Shuman Peng", "authors": "Shuman Peng, Weilian Song, Martin Ester", "title": "Combining Domain-Specific Meta-Learners in the Parameter Space for\n  Cross-Domain Few-Shot Classification", "comments": "Code coming soon at https://github.com/shumanpng/CosML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of few-shot classification is to learn a model that can classify\nnovel classes using only a few training examples. Despite the promising results\nshown by existing meta-learning algorithms in solving the few-shot\nclassification problem, there still remains an important challenge: how to\ngeneralize to unseen domains while meta-learning on multiple seen domains? In\nthis paper, we propose an optimization-based meta-learning method, called\nCombining Domain-Specific Meta-Learners (CosML), that addresses the\ncross-domain few-shot classification problem. CosML first trains a set of\nmeta-learners, one for each training domain, to learn prior knowledge (i.e.,\nmeta-parameters) specific to each domain. The domain-specific meta-learners are\nthen combined in the \\emph{parameter space}, by taking a weighted average of\ntheir meta-parameters, which is used as the initialization parameters of a task\nnetwork that is quickly adapted to novel few-shot classification tasks in an\nunseen domain. Our experiments show that CosML outperforms a range of\nstate-of-the-art methods and achieves strong cross-domain generalization\nability.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 03:33:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Peng", "Shuman", ""], ["Song", "Weilian", ""], ["Ester", "Martin", ""]]}, {"id": "2011.00194", "submitter": "Ali Lotfi Rezaabad", "authors": "Ali Lotfi Rezaabad, Rahi Kalantari, Sriram Vishwanath, Mingyuan Zhou,\n  Jonathan Tamir", "title": "Hyperbolic Graph Embedding with Enhanced Semi-Implicit Variational\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Efficient modeling of relational data arising in physical, social, and\ninformation sciences is challenging due to complicated dependencies within the\ndata. In this work, we build off of semi-implicit graph variational\nauto-encoders to capture higher-order statistics in a low-dimensional graph\nlatent representation. We incorporate hyperbolic geometry in the latent space\nthrough a Poincare embedding to efficiently represent graphs exhibiting\nhierarchical structure. To address the naive posterior latent distribution\nassumptions in classical variational inference, we use semi-implicit\nhierarchical variational Bayes to implicitly capture posteriors of given graph\ndata, which may exhibit heavy tails, multiple modes, skewness, and highly\ncorrelated latent structures. We show that the existing semi-implicit\nvariational inference objective provably reduces information in the observed\ngraph. Based on this observation, we estimate and add an additional mutual\ninformation term to the semi-implicit variational inference learning objective\nto capture rich correlations arising between the input and latent spaces. We\nshow that the inclusion of this regularization term in conjunction with the\nPoincare embedding boosts the quality of learned high-level representations and\nenables more flexible and faithful graphical modeling. We experimentally\ndemonstrate that our approach outperforms existing graph variational\nauto-encoders both in Euclidean and in hyperbolic spaces for edge link\nprediction and node classification.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 05:48:34 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 21:48:07 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Rezaabad", "Ali Lotfi", ""], ["Kalantari", "Rahi", ""], ["Vishwanath", "Sriram", ""], ["Zhou", "Mingyuan", ""], ["Tamir", "Jonathan", ""]]}, {"id": "2011.00213", "submitter": "Wenhao Yang", "authors": "Wenhao Yang, Xiang Li, Guangzeng Xie, Zhihua Zhang", "title": "Finding the Near Optimal Policy via Adaptive Reduced Regularization in\n  MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized MDPs serve as a smooth version of original MDPs. However, biased\noptimal policy always exists for regularized MDPs. Instead of making the\ncoefficient{\\lambda}of regularized term sufficiently small, we propose an\nadaptive reduction scheme for {\\lambda} to approximate optimal policy of the\noriginal MDP. It is shown that the iteration complexity for obtaining\nan{\\epsilon}-optimal policy could be reduced in comparison with setting\nsufficiently small{\\lambda}. In addition, there exists strong duality\nconnection between the reduction method and solving the original MDP directly,\nfrom which we can derive more adaptive reduction method for certain algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 08:31:34 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yang", "Wenhao", ""], ["Li", "Xiang", ""], ["Xie", "Guangzeng", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2011.00216", "submitter": "Thomas Berrett", "authors": "Thomas Berrett, L\\'aszl\\'o Gy\\\"orfi, Harro Walk", "title": "Strongly universally consistent nonparametric regression and\n  classification with privatised data", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we revisit the classical problem of nonparametric regression,\nbut impose local differential privacy constraints. Under such constraints, the\nraw data $(X_1,Y_1),\\ldots,(X_n,Y_n)$, taking values in $\\mathbb{R}^d \\times\n\\mathbb{R}$, cannot be directly observed, and all estimators are functions of\nthe randomised output from a suitable privacy mechanism. The statistician is\nfree to choose the form of the privacy mechanism, and here we add Laplace\ndistributed noise to a discretisation of the location of a feature vector $X_i$\nand to the value of its response variable $Y_i$. Based on this randomised data,\nwe design a novel estimator of the regression function, which can be viewed as\na privatised version of the well-studied partitioning regression estimator. The\nmain result is that the estimator is strongly universally consistent. Our\nmethods and analysis also give rise to a strongly universally consistent binary\nclassification rule for locally differentially private data.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 09:00:43 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Berrett", "Thomas", ""], ["Gy\u00f6rfi", "L\u00e1szl\u00f3", ""], ["Walk", "Harro", ""]]}, {"id": "2011.00228", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Matthias Schonlau", "title": "Optimal 1-NN Prototypes for Pathological Geometries", "comments": "8 pages", "journal-ref": null, "doi": "10.7717/peerj-cs.464", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using prototype methods to reduce the size of training datasets can\ndrastically reduce the computational cost of classification with instance-based\nlearning algorithms like the k-Nearest Neighbour classifier. The number and\ndistribution of prototypes required for the classifier to match its original\nperformance is intimately related to the geometry of the training data. As a\nresult, it is often difficult to find the optimal prototypes for a given\ndataset, and heuristic algorithms are used instead. However, we consider a\nparticularly challenging setting where commonly used heuristic algorithms fail\nto find suitable prototypes and show that the optimal prototypes can instead be\nfound analytically. We also propose an algorithm for finding nearly-optimal\nprototypes in this setting, and use it to empirically validate the theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 10:15:08 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Schonlau", "Matthias", ""]]}, {"id": "2011.00261", "submitter": "Cheng Fu Dr.", "authors": "Cheng Fu and Robert Weibel", "title": "Towards Measuring Place Function Similarity at Fine Spatial Granularity\n  with Trajectory Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling place functions from a computational perspective is a prevalent\nresearch topic. Trajectory embedding, as a neural-network-backed dimension\nreduction technology, allows the possibility to put places with similar social\nfunctions at close locations in the embedding space if the places share similar\nchronological context as part of a trajectory. The embedding similarity was\npreviously proposed as a new metric for measuring the similarity of place\nfunctions. This study explores if this approach is meaningful for geographical\nunits at a much smaller geographical granularity compared to previous studies.\nIn addition, this study investigates if the geographical distance can influence\nthe embedding similarity. The empirical evaluations based on a big vehicle\ntrajectory data set confirm that the embedding similarity can be a metric proxy\nfor place functions. However, the results also show that the embedding\nsimilarity is still bounded by the distance at the local scale.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 12:59:46 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 16:13:29 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fu", "Cheng", ""], ["Weibel", "Robert", ""]]}, {"id": "2011.00289", "submitter": "Edoardo Belli", "authors": "Edoardo Belli", "title": "Smoothly Adaptively Centered Ridge Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a focus on linear models with smooth functional covariates, we propose a\npenalization framework (SACR) based on the nonzero centered ridge, where the\ncenter of the penalty is optimally reweighted in a supervised way, starting\nfrom the ordinary ridge solution as the initial centerfunction. In particular,\nwe introduce a convex formulation that jointly estimates the model's\ncoefficients and the weight function, with a roughness penalty on the\ncenterfunction and constraints on the weights in order to recover a possibly\nsmooth and/or sparse solution. This allows for a non-iterative and continuous\nvariable selection mechanism, as the weight function can either inflate or\ndeflate the initial center, in order to target the penalty towards a suitable\ncenter, with the objective to reduce the unwanted shrinkage on the nonzero\ncoefficients, instead of uniformly shrinking the whole coefficient function. As\nempirical evidence of the interpretability and predictive power of our method,\nwe provide a simulation study and two real world spectroscopy applications with\nboth classification and regression.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 15:04:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Belli", "Edoardo", ""]]}, {"id": "2011.00328", "submitter": "Adam Krzyzak", "authors": "Michael Kohler and Adam Krzyzak", "title": "On the rate of convergence of a deep recurrent neural network estimate\n  in a regression problem with dependent data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regression problem with dependent data is considered. Regularity\nassumptions on the dependency of the data are introduced, and it is shown that\nunder suitable structural assumptions on the regression function a deep\nrecurrent neural network estimate is able to circumvent the curse of\ndimensionality.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:07:06 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kohler", "Michael", ""], ["Krzyzak", "Adam", ""]]}, {"id": "2011.00330", "submitter": "Brijen Thananjeyan", "authors": "Brijen Thananjeyan, Kirthevasan Kandasamy, Ion Stoica, Michael I.\n  Jordan, Ken Goldberg, Joseph E. Gonzalez", "title": "Resource Allocation in Multi-armed Bandit Exploration: Overcoming\n  Sublinear Scaling with Adaptive Parallelism", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study exploration in stochastic multi-armed bandits when we have access to\na divisible resource that can be allocated in varying amounts to arm pulls. We\nfocus in particular on the allocation of distributed computing resources, where\nwe may obtain results faster by allocating more resources per pull, but might\nhave reduced throughput due to nonlinear scaling. For example, in\nsimulation-based scientific studies, an expensive simulation can be sped up by\nrunning it on multiple cores. This speed-up however, is partly offset by the\ncommunication among cores, which results in lower throughput than if fewer\ncores were allocated per trial to run more trials in parallel. In this paper,\nwe explore these trade-offs in two settings. First, in a fixed confidence\nsetting, we need to find the best arm with a given target success probability\nas quickly as possible. We propose an algorithm which trades off between\ninformation accumulation and throughput and show that the time taken can be\nupper bounded by the solution of a dynamic program whose inputs are the gaps\nbetween the sub-optimal and optimal arms. We also prove a matching hardness\nresult. Second, we present an algorithm for a fixed deadline setting, where we\nare given a time deadline and need to maximize the probability of finding the\nbest arm. We corroborate our theoretical insights with simulation experiments\nthat show that the algorithms consistently match or outperform baseline\nalgorithms on a variety of problem instances.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:19:29 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 19:25:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Thananjeyan", "Brijen", ""], ["Kandasamy", "Kirthevasan", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""], ["Goldberg", "Ken", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2011.00344", "submitter": "Mikhail Konobeev", "authors": "Mikhail Konobeev, Ilja Kuzborskij, Csaba Szepesv\\'ari", "title": "A Distribution-Dependent Analysis of Meta-Learning", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in the theory of meta-learning is to understand how the task\ndistributions influence transfer risk, the expected error of a meta-learner on\na new task drawn from the unknown task distribution. In this paper, focusing on\nfixed design linear regression with Gaussian noise and a Gaussian task (or\nparameter) distribution, we give distribution-dependent lower bounds on the\ntransfer risk of any algorithm, while we also show that a novel, weighted\nversion of the so-called biased regularized regression method is able to match\nthese lower bounds up to a fixed constant factor. Notably, the weighting is\nderived from the covariance of the Gaussian task distribution. Altogether, our\nresults provide a precise characterization of the difficulty of meta-learning\nin this Gaussian setting. While this problem setting may appear simple, we show\nthat it is rich enough to unify the \"parameter sharing\" and \"representation\nlearning\" streams of meta-learning; in particular, representation learning is\nobtained as the special case when the covariance matrix of the task\ndistribution is unknown. For this case we propose to adopt the EM method, which\nis shown to enjoy efficient updates in our case. The paper is completed by an\nempirical study of EM. In particular, our experimental results show that the EM\nalgorithm can attain the lower bound as the number of tasks grows, while the\nalgorithm is also successful in competing with its alternatives when used in a\nrepresentation learning context.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 19:36:15 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 15:47:47 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 03:38:06 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Konobeev", "Mikhail", ""], ["Kuzborskij", "Ilja", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2011.00355", "submitter": "Yatong Chen", "authors": "Yatong Chen, Jialu Wang, Yang Liu", "title": "Linear Classifiers that Encourage Constructive Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems are often used in settings where individuals adapt\ntheir features to obtain a desired outcome. In such settings, strategic\nbehavior leads to a sharp loss in model performance in deployment. In this\nwork, we aim to address this problem by learning classifiers that encourage\ndecision subjects to change their features in a way that leads to improvement\nin both predicted \\emph{and} true outcome. We frame the dynamics of prediction\nand adaptation as a two-stage game, and characterize optimal strategies for the\nmodel designer and its decision subjects. In benchmarks on simulated and\nreal-world datasets, we find that classifiers trained using our method maintain\nthe accuracy of existing approaches while inducing higher levels of improvement\nand less manipulation.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 20:35:32 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 08:17:18 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 04:13:23 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chen", "Yatong", ""], ["Wang", "Jialu", ""], ["Liu", "Yang", ""]]}, {"id": "2011.00364", "submitter": "Jelena Diakonikolas", "authors": "Jelena Diakonikolas, Constantinos Daskalakis, and Michael I. Jordan", "title": "Efficient Methods for Structured Nonconvex-Nonconcave Min-Max\n  Optimization", "comments": "in Proc. AISTATS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of min-max optimization in adversarial training of deep neural\nnetwork classifiers and training of generative adversarial networks has\nmotivated the study of nonconvex-nonconcave optimization objectives, which\nfrequently arise in these applications. Unfortunately, recent results have\nestablished that even approximate first-order stationary points of such\nobjectives are intractable, even under smoothness conditions, motivating the\nstudy of min-max objectives with additional structure. We introduce a new class\nof structured nonconvex-nonconcave min-max optimization problems, proposing a\ngeneralization of the extragradient algorithm which provably converges to a\nstationary point. The algorithm applies not only to Euclidean spaces, but also\nto general $\\ell_p$-normed finite-dimensional real vector spaces. We also\ndiscuss its stability under stochastic oracles and provide bounds on its sample\ncomplexity. Our iteration complexity and sample complexity bounds either match\nor improve the best known bounds for the same or less general\nnonconvex-nonconcave settings, such as those that satisfy variational coherence\nor in which a weak solution to the associated variational inequality problem is\nassumed to exist.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 21:35:42 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 22:09:24 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Diakonikolas", "Jelena", ""], ["Daskalakis", "Constantinos", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.00392", "submitter": "Ankit Bandyopadhyay", "authors": "Ankit Bandyopadhyay", "title": "Measure Theoretic Approach to Nonuniform Learnability", "comments": "Submitting to STOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An earlier introduced characterization of nonuniform learnability that allows\nthe sample size to depend on the hypothesis to which the learner is compared\nhas been redefined using the measure theoretic approach. Where nonuniform\nlearnability is a strict relaxation of the Probably Approximately Correct\nframework. Introduction of a new algorithm, Generalize Measure Learnability\nframework, to implement this approach with the study of its sample and\ncomputational complexity bounds. Like the Minimum Description Length principle,\nthis approach can be regarded as an explication of Occam razor. Furthermore,\nmany situations were presented, Hypothesis Classes that are countable where we\ncan apply the GML framework, which we can learn to use the GML scheme and can\nachieve statistical consistency.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 01:03:26 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bandyopadhyay", "Ankit", ""]]}, {"id": "2011.00415", "submitter": "Tim G. J. Rudner", "authors": "Tim G. J. Rudner, Dino Sejdinovic, Yarin Gal", "title": "Inter-domain Deep Gaussian Processes", "comments": "Published in Proceedings of the 37th International Conference on\n  Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-domain Gaussian processes (GPs) allow for high flexibility and low\ncomputational cost when performing approximate inference in GP models. They are\nparticularly suitable for modeling data exhibiting global structure but are\nlimited to stationary covariance functions and thus fail to model\nnon-stationary data effectively. We propose Inter-domain Deep Gaussian\nProcesses, an extension of inter-domain shallow GPs that combines the\nadvantages of inter-domain and deep Gaussian processes (DGPs), and demonstrate\nhow to leverage existing approximate inference methods to perform simple and\nscalable approximate inference using inter-domain features in DGPs. We assess\nthe performance of our method on a range of regression tasks and demonstrate\nthat it outperforms inter-domain shallow GPs and conventional DGPs on\nchallenging large-scale real-world datasets exhibiting both global structure as\nwell as a high-degree of non-stationarity.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:03:35 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Rudner", "Tim G. J.", ""], ["Sejdinovic", "Dino", ""], ["Gal", "Yarin", ""]]}, {"id": "2011.00417", "submitter": "Shiyun Xu", "authors": "Shiyun Xu, Zhiqi Bu", "title": "DebiNet: Debiasing Linear Models with Nonlinear Overparameterized Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed strong empirical performance of\nover-parameterized neural networks on various tasks and many advances in the\ntheory, e.g. the universal approximation and provable convergence to global\nminimum. In this paper, we incorporate over-parameterized neural networks into\nsemi-parametric models to bridge the gap between inference and prediction,\nespecially in the high dimensional linear problem. By doing so, we can exploit\na wide class of networks to approximate the nuisance functions and to estimate\nthe parameters of interest consistently. Therefore, we may offer the best of\ntwo worlds: the universal approximation ability from neural networks and the\ninterpretability from classic ordinary linear model, leading to both valid\ninference and accurate prediction. We show the theoretical foundations that\nmake this possible and demonstrate with numerical experiments. Furthermore, we\npropose a framework, DebiNet, in which we plug-in arbitrary feature selection\nmethods to our semi-parametric neural network. DebiNet can debias the\nregularized estimators (e.g. Lasso) and perform well, in terms of the\npost-selection inference and the generalization error.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:12:53 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 00:50:23 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Xu", "Shiyun", ""], ["Bu", "Zhiqi", ""]]}, {"id": "2011.00467", "submitter": "Tejas Kulkarni", "authors": "Tejas Kulkarni, Joonas J\\\"alk\\\"o, Antti Koskela, Samuel Kaski and\n  Antti Honkela", "title": "Differentially Private Bayesian Inference for Generalized Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generalized linear models (GLMs) such as logistic regression are among the\nmost widely used arms in data analyst's repertoire and often used on sensitive\ndatasets. A large body of prior works that investigate GLMs under differential\nprivacy (DP) constraints provide only private point estimates of the regression\ncoefficients, and are not able to quantify parameter uncertainty. In this work,\nwith logistic and Poisson regression as running examples, we introduce a\ngeneric noise-aware DP Bayesian inference method for a GLM at hand, given a\nnoisy sum of summary statistics. Quantifying uncertainty allows us to determine\nwhich of the regression coefficients are statistically significantly different\nfrom zero. We provide a previously unknown tight privacy analysis and\nexperimentally demonstrate that the posteriors obtained from our model, while\nadhering to strong privacy guarantees, are close to the non-private posteriors.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 10:38:22 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 15:05:08 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 08:57:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Kulkarni", "Tejas", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Koskela", "Antti", ""], ["Kaski", "Samuel", ""], ["Honkela", "Antti", ""]]}, {"id": "2011.00515", "submitter": "Tim G. J. Rudner", "authors": "Tim G. J. Rudner, Oscar Key, Yarin Gal, Tom Rainforth", "title": "On Signal-to-Noise Ratio Issues in Variational Inference for Deep\n  Gaussian Processes", "comments": "Published in Proceedings of the 38th International Conference on\n  Machine Learning (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the gradient estimates used in training Deep Gaussian Processes\n(DGPs) with importance-weighted variational inference are susceptible to\nsignal-to-noise ratio (SNR) issues. Specifically, we show both theoretically\nand via an extensive empirical evaluation that the SNR of the gradient\nestimates for the latent variable's variational parameters decreases as the\nnumber of importance samples increases. As a result, these gradient estimates\ndegrade to pure noise if the number of importance samples is too large. To\naddress this pathology, we show how doubly reparameterized gradient estimators,\noriginally proposed for training variational autoencoders, can be adapted to\nthe DGP setting and that the resultant estimators completely remedy the SNR\nissue, thereby providing more reliable training. Finally, we demonstrate that\nour fix can lead to consistent improvements in the predictive performance of\nDGP models.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 14:38:02 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 12:14:08 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Rudner", "Tim G. J.", ""], ["Key", "Oscar", ""], ["Gal", "Yarin", ""], ["Rainforth", "Tom", ""]]}, {"id": "2011.00576", "submitter": "Andrew Wagenmaker", "authors": "Andrew Wagenmaker, Julian Katz-Samuels, Kevin Jamieson", "title": "Experimental Design for Regret Minimization in Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel experimental design-based algorithm to\nminimize regret in online stochastic linear and combinatorial bandits. While\nexisting literature tends to focus on optimism-based algorithms--which have\nbeen shown to be suboptimal in many cases--our approach carefully plans which\naction to take by balancing the tradeoff between information gain and reward,\novercoming the failures of optimism. In addition, we leverage tools from the\ntheory of suprema of empirical processes to obtain regret guarantees that scale\nwith the Gaussian width of the action set, avoiding wasteful union bounds. We\nprovide state-of-the-art finite time regret guarantees and show that our\nalgorithm can be applied in both the bandit and semi-bandit feedback regime. In\nthe combinatorial semi-bandit setting, we show that our algorithm is\ncomputationally efficient and relies only on calls to a linear maximization\noracle. In addition, we show that with slight modification our algorithm can be\nused for pure exploration, obtaining state-of-the-art pure exploration\nguarantees in the semi-bandit setting. Finally, we provide, to the best of our\nknowledge, the first example where optimism fails in the semi-bandit regime,\nand show that in this setting our algorithm succeeds.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:59:19 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 01:07:39 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wagenmaker", "Andrew", ""], ["Katz-Samuels", "Julian", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2011.00593", "submitter": "Kevin Liang", "authors": "Kevin J Liang, Weituo Hao, Dinghan Shen, Yufan Zhou, Weizhu Chen,\n  Changyou Chen, Lawrence Carin", "title": "MixKD: Towards Efficient Distillation of Large-scale Language Models", "comments": "ICLR 2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale language models have recently demonstrated impressive empirical\nperformance. Nevertheless, the improved results are attained at the price of\nbigger models, more power consumption, and slower inference, which hinder their\napplicability to low-resource (both memory and computation) platforms.\nKnowledge distillation (KD) has been demonstrated as an effective framework for\ncompressing such big models. However, large-scale neural network systems are\nprone to memorize training instances, and thus tend to make inconsistent\npredictions when the data distribution is altered slightly. Moreover, the\nstudent model has few opportunities to request useful information from the\nteacher model when there is limited task-specific data available. To address\nthese issues, we propose MixKD, a data-agnostic distillation framework that\nleverages mixup, a simple yet efficient data augmentation approach, to endow\nthe resulting model with stronger generalization ability. Concretely, in\naddition to the original training examples, the student model is encouraged to\nmimic the teacher's behavior on the linear interpolation of example pairs as\nwell. We prove from a theoretical perspective that under reasonable conditions\nMixKD gives rise to a smaller gap between the generalization error and the\nempirical error. To verify its effectiveness, we conduct experiments on the\nGLUE benchmark, where MixKD consistently leads to significant gains over the\nstandard KD training, and outperforms several competitive baselines.\nExperiments under a limited-data setting and ablation studies further\ndemonstrate the advantages of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:47:51 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 06:38:05 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Liang", "Kevin J", ""], ["Hao", "Weituo", ""], ["Shen", "Dinghan", ""], ["Zhou", "Yufan", ""], ["Chen", "Weizhu", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "2011.00613", "submitter": "Yansong Gao Mr.", "authors": "Yansong Gao and Pratik Chaudhari", "title": "An Information-Geometric Distance on the Space of Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper prescribes a distance between learning tasks modeled as joint\ndistributions on data and labels. Using tools in information geometry, the\ndistance is defined to be the length of the shortest weight trajectory on a\nRiemannian manifold as a classifier is fitted on an interpolated task. The\ninterpolated task evolves from the source to the target task using an optimal\ntransport formulation. This distance, which we call the \"coupled transfer\ndistance\" can be compared across different classifier architectures. We develop\nan algorithm to compute the distance which iteratively transports the marginal\non the data of the source task to that of the target task while updating the\nweights of the classifier to track this evolving data distribution. We develop\ntheory to show that our distance captures the intuitive idea that a good\ntransfer trajectory is the one that keeps the generalization gap small during\ntransfer, in particular at the end on the target task. We perform thorough\nempirical validation and analysis across diverse image classification datasets\nto show that the coupled transfer distance correlates strongly with the\ndifficulty of fine-tuning.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 19:48:39 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 03:33:30 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gao", "Yansong", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2011.00635", "submitter": "Jakub Marecek", "authors": "Jakub Marecek", "title": "Screening for an Infectious Disease as a Problem in Stochastic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent interest in screening populations for an\ninfectious disease. Here, we present a stochastic-control model, wherein the\noptimum screening policy is provably difficult to find, but wherein Thompson\nsampling has provably optimal performance guarantees in the form of Bayesian\nregret. Thompson sampling seems applicable especially to diseases, for which we\ndo not understand the dynamics well, such as to the super-spreading COVID-19.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 22:03:26 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Marecek", "Jakub", ""]]}, {"id": "2011.00641", "submitter": "Chandler Squires", "authors": "Chandler Squires, Sara Magliacane, Kristjan Greenewald, Dmitriy Katz,\n  Murat Kocaoglu, Karthikeyan Shanmugam", "title": "Active Structure Learning of Causal DAGs via Directed Clique Tree", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of work has begun to study intervention design for efficient\nstructure learning of causal directed acyclic graphs (DAGs). A typical setting\nis a causally sufficient setting, i.e. a system with no latent confounders,\nselection bias, or feedback, when the essential graph of the observational\nequivalence class (EC) is given as an input and interventions are assumed to be\nnoiseless. Most existing works focus on worst-case or average-case lower bounds\nfor the number of interventions required to orient a DAG. These worst-case\nlower bounds only establish that the largest clique in the essential graph\ncould make it difficult to learn the true DAG. In this work, we develop a\nuniversal lower bound for single-node interventions that establishes that the\nlargest clique is always a fundamental impediment to structure learning.\nSpecifically, we present a decomposition of a DAG into independently orientable\ncomponents through directed clique trees and use it to prove that the number of\nsingle-node interventions necessary to orient any DAG in an EC is at least the\nsum of half the size of the largest cliques in each chain component of the\nessential graph. Moreover, we present a two-phase intervention design algorithm\nthat, under certain conditions on the chordal skeleton, matches the optimal\nnumber of interventions up to a multiplicative logarithmic factor in the number\nof maximal cliques. We show via synthetic experiments that our algorithm can\nscale to much larger graphs than most of the related work and achieves better\nworst-case performance than other scalable approaches. A code base to recreate\nthese results can be found at https://github.com/csquires/dct-policy\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 23:11:17 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Squires", "Chandler", ""], ["Magliacane", "Sara", ""], ["Greenewald", "Kristjan", ""], ["Katz", "Dmitriy", ""], ["Kocaoglu", "Murat", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "2011.00647", "submitter": "Jiangzhou Wang", "authors": "Jiangzhou Wang, Jingfei Zhang, Binghui Liu, Ji Zhu, and Jianhua Guo", "title": "Fast Network Community Detection with Profile-Pseudo Likelihood Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic block model is one of the most studied network models for\ncommunity detection. It is well-known that most algorithms proposed for fitting\nthe stochastic block model likelihood function cannot scale to large-scale\nnetworks. One prominent work that overcomes this computational challenge is\nAmini et al.(2013), which proposed a fast pseudo-likelihood approach for\nfitting stochastic block models to large sparse networks. However, this\napproach does not have convergence guarantee, and is not well suited for small-\nor medium- scale networks. In this article, we propose a novel likelihood based\napproach that decouples row and column labels in the likelihood function, which\nenables a fast alternating maximization; the new method is computationally\nefficient, performs well for both small and large scale networks, and has\nprovable convergence guarantee. We show that our method provides strongly\nconsistent estimates of the communities in a stochastic block model. As\ndemonstrated in simulation studies, the proposed method outperforms the\npseudo-likelihood approach in terms of both estimation accuracy and computation\nefficiency, especially for large sparse networks. We further consider\nextensions of our proposed method to handle networks with degree heterogeneity\nand bipartite properties.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 23:40:26 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 10:46:50 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Jiangzhou", ""], ["Zhang", "Jingfei", ""], ["Liu", "Binghui", ""], ["Zhu", "Ji", ""], ["Guo", "Jianhua", ""]]}, {"id": "2011.00697", "submitter": "Frank Xiao", "authors": "Frank Xiao", "title": "Time Series Forecasting with Stacked Long Short-Term Memory Networks", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) networks are often used to capture temporal\ndependency patterns. By stacking multi-layer LSTM networks, it can capture even\nmore complex patterns. This paper explores the effectiveness of applying\nstacked LSTM networks in the time series prediction domain, specifically, the\ntraffic volume forecasting. Being able to predict traffic volume more\naccurately can result in better planning, thus greatly reduce the operation\ncost and improve overall efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 03:09:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xiao", "Frank", ""]]}, {"id": "2011.00716", "submitter": "Sangdon Park", "authors": "Sangdon Park, Shuo Li, Insup Lee, Osbert Bastani", "title": "PAC Confidence Predictions for Deep Neural Network Classifiers", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for deploying deep neural networks (DNNs) in safety critical\nsettings is the need to provide rigorous ways to quantify their uncertainty. In\nthis paper, we propose a novel algorithm for constructing predicted\nclassification confidences for DNNs that comes with provable correctness\nguarantees. Our approach uses Clopper-Pearson confidence intervals for the\nBinomial distribution in conjunction with the histogram binning approach to\ncalibrated prediction. In addition, we demonstrate how our predicted\nconfidences can be used to enable downstream guarantees in two settings: (i)\nfast DNN inference, where we demonstrate how to compose a fast but inaccurate\nDNN with an accurate but slow DNN in a rigorous way to improve performance\nwithout sacrificing accuracy, and (ii) safe planning, where we guarantee safety\nwhen using a DNN to predict whether a given action is safe based on visual\nobservations. In our experiments, we demonstrate that our approach can be used\nto provide guarantees for state-of-the-art DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 04:09:17 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 19:20:42 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 02:57:49 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 20:57:35 GMT"}, {"version": "v5", "created": "Wed, 17 Mar 2021 19:51:37 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Park", "Sangdon", ""], ["Li", "Shuo", ""], ["Lee", "Insup", ""], ["Bastani", "Osbert", ""]]}, {"id": "2011.00717", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei, Tom Wan, Jason Eisner", "title": "Noise-Contrastive Estimation for Multivariate Point Processes", "comments": "NeurIPS 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The log-likelihood of a generative model often involves both positive and\nnegative terms. For a temporal multivariate point process, the negative term\nsums over all the possible event types at each time and also integrates over\nall the possible times. As a result, maximum likelihood estimation is\nexpensive. We show how to instead apply a version of noise-contrastive\nestimation---a general parameter estimation method with a less expensive\nstochastic objective. Our specific instantiation of this general idea works out\nin an interestingly non-trivial way and has provable guarantees for its\noptimality, consistency and efficiency. On several synthetic and real-world\ndatasets, our method shows benefits: for the model to achieve the same level of\nlog-likelihood on held-out data, our method needs considerably fewer function\nevaluations and less wall-clock time.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 04:09:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mei", "Hongyuan", ""], ["Wan", "Tom", ""], ["Eisner", "Jason", ""]]}, {"id": "2011.00810", "submitter": "Konstantinos Stavropoulos", "authors": "Dimitris Fotakis, Alkis Kalavasis, Konstantinos Stavropoulos", "title": "Aggregating Incomplete and Noisy Rankings", "comments": "21 pages, 3 figures. Minor changes and experimental results added in\n  this version. Corresponding to the camera-ready version that appeared in the\n  24th International Conference on Artificial Intelligence and Statistics\n  (AISTATS 2021)", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics, PMLR 130:2278-2286, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the true ordering of a set of\nalternatives from largely incomplete and noisy rankings. We introduce a natural\ngeneralization of both the classical Mallows model of ranking distributions and\nthe extensively studied model of noisy pairwise comparisons. Our selective\nMallows model outputs a noisy ranking on any given subset of alternatives,\nbased on an underlying Mallows distribution. Assuming a sequence of subsets\nwhere each pair of alternatives appears frequently enough, we obtain strong\nasymptotically tight upper and lower bounds on the sample complexity of\nlearning the underlying complete ranking and the (identities and the) ranking\nof the top-k alternatives from selective Mallows rankings. Moreover, building\non the work of (Braverman and Mossel, 2009), we show how to efficiently compute\nthe maximum likelihood complete ranking from selective Mallows rankings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:18:33 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 13:01:15 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Fotakis", "Dimitris", ""], ["Kalavasis", "Alkis", ""], ["Stavropoulos", "Konstantinos", ""]]}, {"id": "2011.00813", "submitter": "Viktor Bengs", "authors": "Viktor Bengs and Eyke H\\\"ullermeier", "title": "Multi-Armed Bandits with Censored Consumption of Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a resource-aware variant of the classical multi-armed bandit\nproblem: In each round, the learner selects an arm and determines a resource\nlimit. It then observes a corresponding (random) reward, provided the (random)\namount of consumed resources remains below the limit. Otherwise, the\nobservation is censored, i.e., no reward is obtained. For this problem setting,\nwe introduce a measure of regret, which incorporates the actual amount of\nallocated resources of each learning round as well as the optimality of\nrealizable rewards. Thus, to minimize regret, the learner needs to set a\nresource limit and choose an arm in such a way that the chance to realize a\nhigh reward within the predefined resource limit is high, while the resource\nlimit itself should be kept as low as possible. We derive the theoretical lower\nbound on the cumulative regret and propose a learning algorithm having a regret\nupper bound that matches the lower bound. In a simulation study, we show that\nour learning algorithm outperforms straightforward extensions of standard\nmulti-armed bandit algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:27:38 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bengs", "Viktor", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2011.00819", "submitter": "Yoan Russac", "authors": "Yoan Russac (DI-ENS, CNRS, PSL, VALDA), Louis Faury, Olivier Capp\\'e\n  (DI-ENS, VALDA), Aur\\'elien Garivier (UMPA-ENSL)", "title": "Self-Concordant Analysis of Generalized Linear Bandits with Forgetting", "comments": null, "journal-ref": "AISTATS 2021 - International Conference on Artificial Intelligence\n  and Statistics, Apr 2021, San Diego / Virtual, United States", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual sequential decision problems with categorical or numerical\nobservations are ubiquitous and Generalized Linear Bandits (GLB) offer a solid\ntheoretical framework to address them. In contrast to the case of linear\nbandits, existing algorithms for GLB have two drawbacks undermining their\napplicability. First, they rely on excessively pessimistic concentration bounds\ndue to the non-linear nature of the model. Second, they require either\nnon-convex projection steps or burn-in phases to enforce boundedness of the\nestimators. Both of these issues are worsened when considering non-stationary\nmodels, in which the GLB parameter may vary with time. In this work, we focus\non self-concordant GLB (which include logistic and Poisson regression) with\nforgetting achieved either by the use of a sliding window or exponential\nweights. We propose a novel confidence-based algorithm for the maximum-likehood\nestimator with forgetting and analyze its perfomance in abruptly changing\nenvironments. These results as well as the accompanying numerical simulations\nhighlight the potential of the proposed approach to address non-stationarity in\nGLB.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:36:39 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 09:37:14 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Russac", "Yoan", "", "DI-ENS, CNRS, PSL, VALDA"], ["Faury", "Louis", "", "DI-ENS, VALDA"], ["Capp\u00e9", "Olivier", "", "DI-ENS, VALDA"], ["Garivier", "Aur\u00e9lien", "", "UMPA-ENSL"]]}, {"id": "2011.00835", "submitter": "Jeremie Messud Dr", "authors": "Thibault Lesieur, J\\'er\\'emie Messud, Issa Hammoud, Hanyuan Peng,\n  C\\'eline Lacombe, Paulien Jeunesse", "title": "Adversarial training for predictive tasks: theoretical analysis and\n  limitations in the deterministic case", "comments": "NeurIPS 2020, ICBINB Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To train a deep neural network to mimic the outcomes of processing sequences,\na version of Conditional Generalized Adversarial Network (CGAN) can be used. It\nhas been observed by others that CGAN can help to improve the results even for\ndeterministic sequences, where only one output is associated with the\nprocessing of a given input. Surprisingly, our CGAN-based tests on\ndeterministic geophysical processing sequences did not produce a real\nimprovement compared to the use of an $L_p$ loss; we here propose a first\ntheoretical explanation why. Our analysis goes from the non-deterministic case\nto the deterministic one. It led us to develop an adversarial way to train a\ncontent loss that gave better results on our data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:05:38 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 07:11:19 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 07:41:52 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lesieur", "Thibault", ""], ["Messud", "J\u00e9r\u00e9mie", ""], ["Hammoud", "Issa", ""], ["Peng", "Hanyuan", ""], ["Lacombe", "C\u00e9line", ""], ["Jeunesse", "Paulien", ""]]}, {"id": "2011.00865", "submitter": "Matthias H\\\"user", "authors": "Jonathan Heitz, Joanna Ficek, Martin Faltys, Tobias M. Merz, Gunnar\n  R\\\"atsch, Matthias H\\\"user", "title": "WRSE -- a non-parametric weighted-resolution ensemble for predicting\n  individual survival distributions in the ICU", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic assessment of mortality risk in the intensive care unit (ICU) can be\nused to stratify patients, inform about treatment effectiveness or serve as\npart of an early-warning system. Static risk scoring systems, such as APACHE or\nSAPS, have recently been supplemented with data-driven approaches that track\nthe dynamic mortality risk over time. Recent works have focused on enhancing\nthe information delivered to clinicians even further by producing full survival\ndistributions instead of point predictions or fixed horizon risks. In this\nwork, we propose a non-parametric ensemble model, Weighted Resolution Survival\nEnsemble (WRSE), tailored to estimate such dynamic individual survival\ndistributions. Inspired by the simplicity and robustness of ensemble methods,\nthe proposed approach combines a set of binary classifiers spaced according to\na decay function reflecting the relevance of short-term mortality predictions.\nModels and baselines are evaluated under weighted calibration and\ndiscrimination metrics for individual survival distributions which closely\nreflect the utility of a model in ICU practice. We show competitive results\nwith state-of-the-art probabilistic models, while greatly reducing training\ntime by factors of 2-9x.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:13:59 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Heitz", "Jonathan", ""], ["Ficek", "Joanna", ""], ["Faltys", "Martin", ""], ["Merz", "Tobias M.", ""], ["R\u00e4tsch", "Gunnar", ""], ["H\u00fcser", "Matthias", ""]]}, {"id": "2011.00871", "submitter": "Suvajit Majumder", "authors": "Heng-Yu Chen, Yang-Hui He, Shailesh Lal, Suvajit Majumder", "title": "Machine Learning Lie Structures & Applications to Physics", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.physletb.2021.136297", "report-no": null, "categories": "hep-th cs.LG hep-ph math.RT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical and exceptional Lie algebras and their representations are among\nthe most important tools in the analysis of symmetry in physical systems. In\nthis letter we show how the computation of tensor products and branching rules\nof irreducible representations are machine-learnable, and can achieve relative\nspeed-ups of orders of magnitude in comparison to the non-ML algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:27:29 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 18:47:26 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Chen", "Heng-Yu", ""], ["He", "Yang-Hui", ""], ["Lal", "Shailesh", ""], ["Majumder", "Suvajit", ""]]}, {"id": "2011.00898", "submitter": "Christian M\\\"uller", "authors": "L\\'eo Simpson, Patrick L. Combettes, Christian L. M\\\"uller", "title": "c-lasso -- a Python package for constrained sparse and robust regression\n  and classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce c-lasso, a Python package that enables sparse and robust linear\nregression and classification with linear equality constraints. The underlying\nstatistical forward model is assumed to be of the following form: \\[ y = X\n\\beta + \\sigma \\epsilon \\qquad \\textrm{subject to} \\qquad C\\beta=0 \\] Here, $X\n\\in \\mathbb{R}^{n\\times d}$is a given design matrix and the vector $y \\in\n\\mathbb{R}^{n}$ is a continuous or binary response vector. The matrix $C$ is a\ngeneral constraint matrix. The vector $\\beta \\in \\mathbb{R}^{d}$ contains the\nunknown coefficients and $\\sigma$ an unknown scale. Prominent use cases are\n(sparse) log-contrast regression with compositional data $X$, requiring the\nconstraint $1_d^T \\beta = 0$ (Aitchion and Bacon-Shone 1984) and the\nGeneralized Lasso which is a special case of the described problem (see, e.g,\n(James, Paulson, and Rusmevichientong 2020), Example 3). The c-lasso package\nprovides estimators for inferring unknown coefficients and scale (i.e.,\nperspective M-estimators (Combettes and M\\\"uller 2020a)) of the form \\[\n\\min_{\\beta \\in \\mathbb{R}^d, \\sigma \\in \\mathbb{R}_{0}} f\\left(X\\beta -\ny,{\\sigma} \\right) + \\lambda \\left\\lVert \\beta\\right\\rVert_1 \\qquad\n\\textrm{subject to} \\qquad C\\beta = 0 \\] for several convex loss functions\n$f(\\cdot,\\cdot)$. This includes the constrained Lasso, the constrained scaled\nLasso, and sparse Huber M-estimators with linear equality constraints.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 11:16:27 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Simpson", "L\u00e9o", ""], ["Combettes", "Patrick L.", ""], ["M\u00fcller", "Christian L.", ""]]}, {"id": "2011.00901", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Hadi Nekoei, Aydin Ghojogh, Fakhri Karray, Mark\n  Crowley", "title": "Sampling Algorithms, from Survey Sampling to Monte Carlo Methods:\n  Tutorial and Literature Review", "comments": "The first three authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a tutorial and literature review on sampling algorithms. We\nhave two main types of sampling in statistics. The first type is survey\nsampling which draws samples from a set or population. The second type is\nsampling from probability distribution where we have a probability density or\nmass function. In this paper, we cover both types of sampling. First, we review\nsome required background on mean squared error, variance, bias, maximum\nlikelihood estimation, Bernoulli, Binomial, and Hypergeometric distributions,\nthe Horvitz-Thompson estimator, and the Markov property. Then, we explain the\ntheory of simple random sampling, bootstrapping, stratified sampling, and\ncluster sampling. We also briefly introduce multistage sampling, network\nsampling, and snowball sampling. Afterwards, we switch to sampling from\ndistribution. We explain sampling from cumulative distribution function, Monte\nCarlo approximation, simple Monte Carlo methods, and Markov Chain Monte Carlo\n(MCMC) methods. For simple Monte Carlo methods, whose iterations are\nindependent, we cover importance sampling and rejection sampling. For MCMC\nmethods, we cover Metropolis algorithm, Metropolis-Hastings algorithm, Gibbs\nsampling, and slice sampling. Then, we explain the random walk behaviour of\nMonte Carlo methods and more efficient Monte Carlo methods, including\nHamiltonian (or hybrid) Monte Carlo, Adler's overrelaxation, and ordered\noverrelaxation. Finally, we summarize the characteristics, pros, and cons of\nsampling methods compared to each other. This paper can be useful for different\nfields of statistics, machine learning, reinforcement learning, and\ncomputational physics.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 11:27:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Nekoei", "Hadi", ""], ["Ghojogh", "Aydin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2011.00981", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang, K. Sudhir, Nisheeth K. Vishnoi", "title": "Coresets for Regressions with Panel Data", "comments": "This is a Full version of a paper to appear in NeurIPS 2020. The code\n  can be found in\n  https://github.com/huanglx12/Coresets-for-regressions-with-panel-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the problem of coresets for regression problems to\npanel data settings. We first define coresets for several variants of\nregression problems with panel data and then present efficient algorithms to\nconstruct coresets of size that depend polynomially on 1/$\\varepsilon$ (where\n$\\varepsilon$ is the error parameter) and the number of regression parameters -\nindependent of the number of individuals in the panel data or the time units\neach individual is observed for. Our approach is based on the Feldman-Langberg\nframework in which a key step is to upper bound the \"total sensitivity\" that is\nroughly the sum of maximum influences of all individual-time pairs taken over\nall possible choices of regression parameters. Empirically, we assess our\napproach with synthetic and real-world datasets; the coreset sizes constructed\nusing our approach are much smaller than the full dataset and coresets indeed\naccelerate the running time of computing the regression objective.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:58:31 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 02:52:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Huang", "Lingxiao", ""], ["Sudhir", "K.", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2011.00986", "submitter": "Auguste Charles", "authors": "Charles Auguste (IMI), Sean Malory, Ivan Smirnov", "title": "A better method to enforce monotonic constraints in regression and\n  classification trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we present two new ways of enforcing monotone constraints in\nregression and classification trees. One yields better results than the current\nLightGBM, and has a similar computation time. The other one yields even better\nresults, but is much slower than the current LightGBM. We also propose a\nheuristic that takes into account that greedily splitting a tree by choosing a\nmonotone split with respect to its immediate gain is far from optimal. Then, we\ncompare the results with the current implementation of the constraints in the\nLightGBM library, using the well known Adult public dataset. Throughout the\nreport, we mostly focus on the implementation of our methods that we made for\nthe LightGBM library, even though they are general and could be implemented in\nany regression or classification tree. The best method we propose (a smarter\nway to split the tree coupled to a penalization of monotone splits)\nconsistently beats the current implementation of LightGBM. With small or\naverage trees, the loss reduction can be as high as 1% in the early stages of\ntraining and decreases to around 0.1% at the loss peak for the Adult dataset.\nThe results would be even better with larger trees. In our experiments, we\ndidn't do a lot of tuning of the regularization parameters, and we wouldn't be\nsurprised to see that increasing the performance of our methods on test sets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:04:21 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Auguste", "Charles", "", "IMI"], ["Malory", "Sean", ""], ["Smirnov", "Ivan", ""]]}, {"id": "2011.01035", "submitter": "Akshar Nair", "authors": "Nikhil Fernandes, Alexandra Gkolia, Nicolas Pizzo, James Davenport,\n  Akshar Nair", "title": "Unification of HDP and LDA Models for Optimal Topic Clustering of\n  Subject Specific Question Banks", "comments": "8 pages, 5 figures, Submitted to EAAI21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasingly popular trend in Universities for curriculum\ntransformation to make teaching more interactive and suitable for online\ncourses. An increase in the popularity of online courses would result in an\nincrease in the number of course-related queries for academics. This, coupled\nwith the fact that if lectures were delivered in a video on demand format,\nthere would be no fixed time where the majority of students could ask\nquestions. When questions are asked in a lecture there is a negligible chance\nof having similar questions repeatedly, but asynchronously this is more likely.\nIn order to reduce the time spent on answering each individual question,\nclustering them is an ideal choice. There are different unsupervised models fit\nfor text clustering, of which the Latent Dirichlet Allocation model is the most\ncommonly used. We use the Hierarchical Dirichlet Process to determine an\noptimal topic number input for our LDA model runs. Due to the probabilistic\nnature of these topic models, the outputs of them vary for different runs. The\ngeneral trend we found is that not all the topics were being used for\nclustering on the first run of the LDA model, which results in a less effective\nclustering. To tackle probabilistic output, we recursively use the LDA model on\nthe effective topics being used until we obtain an efficiency ratio of 1.\nThrough our experimental results we also establish a reasoning on how Zeno's\nparadox is avoided.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 18:21:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Fernandes", "Nikhil", ""], ["Gkolia", "Alexandra", ""], ["Pizzo", "Nicolas", ""], ["Davenport", "James", ""], ["Nair", "Akshar", ""]]}, {"id": "2011.01048", "submitter": "Edoardo Belli", "authors": "Edoardo Belli, Simone Vantini", "title": "Ridge regression with adaptive additive rectangles and other piecewise\n  functional templates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an $L_{2}$-based penalization algorithm for functional linear\nregression models, where the coefficient function is shrunk towards a\ndata-driven shape template $\\gamma$, which is constrained to belong to a class\nof piecewise functions by restricting its basis expansion. In particular, we\nfocus on the case where $\\gamma$ can be expressed as a sum of $q$ rectangles\nthat are adaptively positioned with respect to the regression error. As the\nproblem of finding the optimal knot placement of a piecewise function is\nnonconvex, the proposed parametrization allows to reduce the number of\nvariables in the global optimization scheme, resulting in a fitting algorithm\nthat alternates between approximating a suitable template and solving a convex\nridge-like problem. The predictive power and interpretability of our method is\nshown on multiple simulations and two real world case studies.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:28:54 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Belli", "Edoardo", ""], ["Vantini", "Simone", ""]]}, {"id": "2011.01075", "submitter": "Nan Jiang", "authors": "Philip Amortila, Nan Jiang, Tengyang Xie", "title": "A Variant of the Wang-Foster-Kakade Lower Bound for the Discounted\n  Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Wang et al. (2020) showed a highly intriguing hardness result for\nbatch reinforcement learning (RL) with linearly realizable value function and\ngood feature coverage in the finite-horizon case. In this note we show that\nonce adapted to the discounted setting, the construction can be simplified to a\n2-state MDP with 1-dimensional features, such that learning is impossible even\nwith an infinite amount of data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:04:42 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 03:53:02 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Amortila", "Philip", ""], ["Jiang", "Nan", ""], ["Xie", "Tengyang", ""]]}, {"id": "2011.01089", "submitter": "Martin Bertran", "authors": "Martin Bertran, Natalia Martinez, Mariano Phielipp, Guillermo Sapiro", "title": "Instance based Generalization in Reinforcement Learning", "comments": "Accepted on NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents trained via deep reinforcement learning (RL) routinely fail to\ngeneralize to unseen environments, even when these share the same underlying\ndynamics as the training levels. Understanding the generalization properties of\nRL is one of the challenges of modern machine learning. Towards this goal, we\nanalyze policy learning in the context of Partially Observable Markov Decision\nProcesses (POMDPs) and formalize the dynamics of training levels as instances.\nWe prove that, independently of the exploration strategy, reusing instances\nintroduces significant changes on the effective Markov dynamics the agent\nobserves during training. Maximizing expected rewards impacts the learned\nbelief state of the agent by inducing undesired instance specific speedrunning\npolicies instead of generalizeable ones, which are suboptimal on the training\nset. We provide generalization bounds to the value gap in train and test\nenvironments based on the number of training instances, and use insights based\non these to improve performance on unseen levels. We propose training a shared\nbelief representation over an ensemble of specialized policies, from which we\ncompute a consensus policy that is used for data collection, disallowing\ninstance specific exploitation. We experimentally validate our theory,\nobservations, and the proposed computational solution over the CoinRun\nbenchmark.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:19:44 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bertran", "Martin", ""], ["Martinez", "Natalia", ""], ["Phielipp", "Mariano", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "2011.01090", "submitter": "Cong Shen", "authors": "Chengshuai Shi, Cong Shen", "title": "On No-Sensing Adversarial Multi-player Multi-armed Bandits with\n  Collision Communications", "comments": "19 pages, 8 figures. Accepted to IEEE Journal on Selected Areas in\n  Information Theory, Special Issue on Sequential, Active, and Reinforcement\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the notoriously difficult no-sensing adversarial multi-player\nmulti-armed bandits (MP-MAB) problem from a new perspective. Instead of\nfocusing on the hardness of multiple players, we introduce a new dimension of\nhardness, called attackability. All adversaries can be categorized based on the\nattackability and we introduce Adversary-Adaptive Collision-Communication\n(A2C2), a family of algorithms with forced-collision communication among\nplayers. Both attackability-aware and unaware settings are studied, and\ninformation-theoretic tools of the Z-channel model and error-correction coding\nare utilized to address the challenge of implicit communication without\ncollision information in an adversarial environment. For the more challenging\nattackability-unaware problem, we propose a simple method to estimate the\nattackability enabled by a novel error-detection repetition code and randomized\ncommunication for synchronization. Theoretical analysis proves that asymptotic\nattackability-dependent sublinear regret can be achieved, with or without\nknowing the attackability. In particular, the asymptotic regret does not have\nan exponential dependence on the number of players, revealing a fundamental\ntradeoff between the two dimensions of hardness in this problem.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:21:18 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 18:36:25 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Shi", "Chengshuai", ""], ["Shen", "Cong", ""]]}, {"id": "2011.01111", "submitter": "Ping Li", "authors": "Yunfeng Cai and Ping Li", "title": "Identification of Matrix Joint Block Diagonalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $\\mathcal{C}=\\{C_i\\}_{i=1}^m$ of square matrices, the matrix\nblind joint block diagonalization problem (BJBDP) is to find a full column rank\nmatrix $A$ such that $C_i=A\\Sigma_iA^\\text{T}$ for all $i$, where $\\Sigma_i$'s\nare all block diagonal matrices with as many diagonal blocks as possible. The\nBJBDP plays an important role in independent subspace analysis (ISA). This\npaper considers the identification problem for BJBDP, that is, under what\nconditions and by what means, we can identify the diagonalizer $A$ and the\nblock diagonal structure of $\\Sigma_i$, especially when there is noise in\n$C_i$'s. In this paper, we propose a ``bi-block diagonalization'' method to\nsolve BJBDP, and establish sufficient conditions under which the method is able\nto accomplish the task. Numerical simulations validate our theoretical results.\nTo the best of the authors' knowledge, existing numerical methods for BJBDP\nhave no theoretical guarantees for the identification of the exact solution,\nwhereas our method does.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:42:32 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cai", "Yunfeng", ""], ["Li", "Ping", ""]]}, {"id": "2011.01150", "submitter": "Daniel Fern\\'andez-S\\'anchez", "authors": "Daniel Fern\\'andez-S\\'anchez, Eduardo C. Garrido-Merch\\'an and Daniel\n  Hern\\'andez-Lobato", "title": "Improved Max-value Entropy Search for Multi-objective Bayesian\n  Optimization with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MESMOC+, an improved version of Max-value Entropy search for\nMulti-Objective Bayesian optimization with Constraints (MESMOC). MESMOC+ can be\nused to solve constrained multi-objective problems when the objectives and the\nconstraints are expensive to evaluate. MESMOC+ works by minimizing the entropy\nof the solution of the optimization problem in function space, i.e., the Pareto\nfrontier, to guide the search for the optimum. The cost of MESMOC+ is linear in\nthe number of objectives and constraints. Furthermore, it is often\nsignificantly smaller than the cost of alternative methods based on minimizing\nthe entropy of the Pareto set. The reason for this is that it is easier to\napproximate the required computations in MESMOC+. Moreover, MESMOC+'s\nacquisition function is expressed as the sum of one acquisition per each\nblack-box (objective or constraint). Thus, it can be used in a decoupled\nevaluation setting in which one chooses not only the next input location to\nevaluate, but also which black-box to evaluate there. We compare MESMOC+ with\nrelated methods in synthetic and real optimization problems. These experiments\nshow that the entropy estimation provided by MESMOC+ is more accurate than that\nof previous methods. This leads to better optimization results. MESMOC+ is also\ncompetitive with other information-based methods for constrained\nmulti-objective Bayesian optimization, but it is significantly faster.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:45:25 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 15:37:38 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Fern\u00e1ndez-S\u00e1nchez", "Daniel", ""], ["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "2011.01156", "submitter": "Ashish Shrivastava", "authors": "Ting-Yao Hu, Ashish Shrivastava, Jen-Hao Rick Chang, Hema Koppula,\n  Stefan Braun, Kyuyeon Hwang, Ozlem Kalinli, Oncel Tuzel", "title": "SapAugment: Learning A Sample Adaptive Policy for Data Augmentation", "comments": "Accepted at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation methods usually apply the same augmentation (or a mix of\nthem) to all the training samples. For example, to perturb data with noise, the\nnoise is sampled from a Normal distribution with a fixed standard deviation,\nfor all samples. We hypothesize that a hard sample with high training loss\nalready provides strong training signal to update the model parameters and\nshould be perturbed with mild or no augmentation. Perturbing a hard sample with\na strong augmentation may also make it too hard to learn from. Furthermore, a\nsample with low training loss should be perturbed by a stronger augmentation to\nprovide more robustness to a variety of conditions. To formalize these\nintuitions, we propose a novel method to learn a Sample-Adaptive Policy for\nAugmentation -- SapAugment. Our policy adapts the augmentation parameters based\non the training loss of the data samples. In the example of Gaussian noise, a\nhard sample will be perturbed with a low variance noise and an easy sample with\na high variance noise. Furthermore, the proposed method combines multiple\naugmentation methods into a methodical policy learning framework and obviates\nhand-crafting augmentation parameters by trial-and-error. We apply our method\non an automatic speech recognition (ASR) task, and combine existing and novel\naugmentations using the proposed framework. We show substantial improvement, up\nto 21% relative reduction in word error rate on LibriSpeech dataset, over the\nstate-of-the-art speech augmentation method.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:52:26 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 18:02:59 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hu", "Ting-Yao", ""], ["Shrivastava", "Ashish", ""], ["Chang", "Jen-Hao Rick", ""], ["Koppula", "Hema", ""], ["Braun", "Stefan", ""], ["Hwang", "Kyuyeon", ""], ["Kalinli", "Ozlem", ""], ["Tuzel", "Oncel", ""]]}, {"id": "2011.01170", "submitter": "Frederik Kunstner", "authors": "Frederik Kunstner, Raunak Kumar, Mark Schmidt", "title": "Homeomorphic-Invariance of EM: Non-Asymptotic Convergence in KL\n  Divergence for Exponential Families via Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation maximization (EM) is the default algorithm for fitting\nprobabilistic models with missing or latent variables, yet we lack a full\nunderstanding of its non-asymptotic convergence properties. Previous works show\nresults along the lines of \"EM converges at least as fast as gradient descent\"\nby assuming the conditions for the convergence of gradient descent apply to EM.\nThis approach is not only loose, in that it does not capture that EM can make\nmore progress than a gradient step, but the assumptions fail to hold for\ntextbook examples of EM like Gaussian mixtures. In this work we first show that\nfor the common setting of exponential family distributions, viewing EM as a\nmirror descent algorithm leads to convergence rates in Kullback-Leibler (KL)\ndivergence. Then, we show how the KL divergence is related to first-order\nstationarity via Bregman divergences. In contrast to previous works, the\nanalysis is invariant to the choice of parametrization and holds with minimal\nassumptions. We also show applications of these ideas to local linear (and\nsuperlinear) convergence rates, generalized EM, and non-exponential family\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:09:05 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 03:42:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Kunstner", "Frederik", ""], ["Kumar", "Raunak", ""], ["Schmidt", "Mark", ""]]}, {"id": "2011.01191", "submitter": "Mohamad H Danesh", "authors": "Mohamad H. Danesh", "title": "Reducing Neural Network Parameter Initialization Into an SMT Problem", "comments": "AAAI-21 SA Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network (NN) depends on multiple factors, including but not\nlimited to the initial weights. In this paper, we focus on initializing deep NN\nparameters such that it performs better, comparing to random or zero\ninitialization. We do this by reducing the process of initialization into an\nSMT solver. Previous works consider certain activation functions on small NNs,\nhowever the studied NN is a deep network with different activation functions.\nOur experiments show that the proposed approach for parameter initialization\nachieves better performance comparing to randomly initialized networks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:31:29 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 17:15:58 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 06:28:16 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Danesh", "Mohamad H.", ""]]}, {"id": "2011.01205", "submitter": "Jeffrey Li", "authors": "Jeffrey Li, Vaishnavh Nagarajan, Gregory Plumb, Ameet Talwalkar", "title": "A Learning Theoretic Perspective on Local Explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore connections between interpretable machine learning\nand learning theory through the lens of local approximation explanations.\nFirst, we tackle the traditional problem of performance generalization and\nbound the test-time accuracy of a model using a notion of how locally\nexplainable it is. Second, we explore the novel problem of explanation\ngeneralization which is an important concern for a growing class of finite\nsample-based local approximation explanations. Finally, we validate our\ntheoretical results empirically and show that they reflect what can be seen in\npractice.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:48:46 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Li", "Jeffrey", ""], ["Nagarajan", "Vaishnavh", ""], ["Plumb", "Gregory", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2011.01226", "submitter": "Charles Gadd", "authors": "Charles Gadd, Markus Heinonen, Harri L\\\"ahdesm\\\"aki and Samuel Kaski", "title": "Sample-efficient reinforcement learning using deep Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning provides a framework for learning to control which\nactions to take towards completing a task through trial-and-error. In many\napplications observing interactions is costly, necessitating sample-efficient\nlearning. In model-based reinforcement learning efficiency is improved by\nlearning to simulate the world dynamics. The challenge is that model\ninaccuracies rapidly accumulate over planned trajectories. We introduce deep\nGaussian processes where the depth of the compositions introduces model\ncomplexity while incorporating prior knowledge on the dynamics brings\nsmoothness and structure. Our approach is able to sample a Bayesian posterior\nover trajectories. We demonstrate highly improved early sample-efficiency over\ncompeting methods. This is shown across a number of continuous control tasks,\nincluding the half-cheetah whose contact dynamics have previously posed an\ninsurmountable problem for earlier sample-efficient Gaussian process based\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:37:57 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Gadd", "Charles", ""], ["Heinonen", "Markus", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""], ["Kaski", "Samuel", ""]]}, {"id": "2011.01272", "submitter": "Ammar Shaker", "authors": "Ammar Shaker, Shujian Yu, Francesco Alesiani", "title": "Modular-Relatedness for Continual Learning", "comments": "We realized one conclusion in the submission is erroneous and\n  disconnected from the results shown in one theorem is. We decide to withdraw\n  the current version to avoid misleading conclusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a continual learning (CL) technique that is\nbeneficial to sequential task learners by improving their retained accuracy and\nreducing catastrophic forgetting. The principal target of our approach is the\nautomatic extraction of modular parts of the neural network and then estimating\nthe relatedness between the tasks given these modular components. This\ntechnique is applicable to different families of CL methods such as\nregularization-based (e.g., the Elastic Weight Consolidation) or the\nrehearsal-based (e.g., the Gradient Episodic Memory) approaches where episodic\nmemory is needed. Empirical results demonstrate remarkable performance gain (in\nterms of robustness to forgetting) for methods such as EWC and GEM based on our\ntechnique, especially when the memory budget is very limited.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 19:30:15 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 02:47:19 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Shaker", "Ammar", ""], ["Yu", "Shujian", ""], ["Alesiani", "Francesco", ""]]}, {"id": "2011.01324", "submitter": "Peter Xenopoulos", "authors": "Peter Xenopoulos, Harish Doraiswamy, Claudio Silva", "title": "Valuing Player Actions in Counter-Strike: Global Offensive", "comments": "to be published in 2020 IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Esports, despite its expanding interest, lacks fundamental sports analytics\nresources such as accessible data or proven and reproducible analytical\nframeworks. Even Counter-Strike: Global Offensive (CSGO), the second most\npopular esport, suffers from these problems. Thus, quantitative evaluation of\nCSGO players, a task important to teams, media, bettors and fans, is difficult.\nTo address this, we introduce (1) a data model for CSGO with an open-source\nimplementation; (2) a graph distance measure for defining distances in CSGO;\nand (3) a context-aware framework to value players' actions based on changes in\ntheir team's chances of winning. Using over 70 million in-game CSGO events, we\ndemonstrate our framework's consistency and independence compared to existing\nvaluation frameworks. We also provide use cases demonstrating high-impact play\nidentification and uncertainty estimation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 21:11:14 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:35:51 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Xenopoulos", "Peter", ""], ["Doraiswamy", "Harish", ""], ["Silva", "Claudio", ""]]}, {"id": "2011.01343", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani", "title": "p-value peeking and estimating extrema", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pervasive issue in statistical hypothesis testing is that the reported\n$p$-values are biased downward by data \"peeking\" -- the practice of reporting\nonly progressively extreme values of the test statistic as more data samples\nare collected. We develop principled mechanisms to estimate such running\nextrema of test statistics, which directly address the effect of peeking in\nsome general scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 22:00:57 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Balsubramani", "Akshay", ""]]}, {"id": "2011.01464", "submitter": "Liya Wang", "authors": "Liya Wang, Panta Lucic, Keith Campbell, Craig Wanke", "title": "Autoencoding Features for Aviation Machine Learning Problems", "comments": "Paper has been submitted to AIAA conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current practice of manually processing features for high-dimensional and\nheterogeneous aviation data is labor-intensive, does not scale well to new\nproblems, and is prone to information loss, affecting the effectiveness and\nmaintainability of machine learning (ML) procedures. This research explored an\nunsupervised learning method, autoencoder, to extract effective features for\naviation machine learning problems. The study explored variants of autoencoders\nwith the aim of forcing the learned representations of the input to assume\nuseful properties. A flight track anomaly detection autoencoder was developed\nto demonstrate the versatility of the technique. The research results show that\nthe autoencoder can not only automatically extract effective features for the\nflight track data, but also efficiently deep clean data, thereby reducing the\nworkload of data scientists. Moreover, the research leveraged transfer learning\nto efficiently train models for multiple airports. Transfer learning can reduce\nmodel training times from days to hours, as well as improving model\nperformance. The developed applications and techniques are shared with the\nwhole aviation community to improve effectiveness of ongoing and future machine\nlearning studies.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:09:34 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 17:15:17 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wang", "Liya", ""], ["Lucic", "Panta", ""], ["Campbell", "Keith", ""], ["Wanke", "Craig", ""]]}, {"id": "2011.01474", "submitter": "Jing Wang", "authors": "Jing Wang, Anna Choromanska", "title": "SGB: Stochastic Gradient Bound Method for Optimizing Partition Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of optimizing partition functions in a\nstochastic learning setting. We propose a stochastic variant of the bound\nmajorization algorithm that relies on upper-bounding the partition function\nwith a quadratic surrogate. The update of the proposed method, that we refer to\nas Stochastic Partition Function Bound (SPFB), resembles scaled stochastic\ngradient descent where the scaling factor relies on a second order term that is\nhowever different from the Hessian. Similarly to quasi-Newton schemes, this\nterm is constructed using the stochastic approximation of the value of the\nfunction and its gradient. We prove sub-linear convergence rate of the proposed\nmethod and show the construction of its low-rank variant (LSPFB). Experiments\non logistic regression demonstrate that the proposed schemes significantly\noutperform SGD. We also discuss how to use quadratic partition function bound\nfor efficient training of deep learning models and in non-convex optimization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:42:51 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Jing", ""], ["Choromanska", "Anna", ""]]}, {"id": "2011.01479", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Hau-Tieng Wu", "title": "Convergence of Graph Laplacian with kNN Self-tuned Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernelized Gram matrix $W$ constructed from data points $\\{x_i\\}_{i=1}^N$ as\n$W_{ij}= k_0( \\frac{ \\| x_i - x_j \\|^2} {\\sigma^2} )$ is widely used in\ngraph-based geometric data analysis and unsupervised learning. An important\nquestion is how to choose the kernel bandwidth $\\sigma$, and a common practice\ncalled self-tuned kernel adaptively sets a $\\sigma_i$ at each point $x_i$ by\nthe $k$-nearest neighbor (kNN) distance. When $x_i$'s are sampled from a\n$d$-dimensional manifold embedded in a possibly high-dimensional space, unlike\nwith fixed-bandwidth kernels, theoretical results of graph Laplacian\nconvergence with self-tuned kernels have been incomplete. This paper proves the\nconvergence of graph Laplacian operator $L_N$ to manifold (weighted-)Laplacian\nfor a new family of kNN self-tuned kernels $W^{(\\alpha)}_{ij} = k_0( \\frac{ \\|\nx_i - x_j \\|^2}{ \\epsilon \\hat{\\rho}(x_i)\n\\hat{\\rho}(x_j)})/\\hat{\\rho}(x_i)^\\alpha \\hat{\\rho}(x_j)^\\alpha$, where\n$\\hat{\\rho}$ is the estimated bandwidth function {by kNN}, and the limiting\noperator is also parametrized by $\\alpha$. When $\\alpha = 1$, the limiting\noperator is the weighted manifold Laplacian $\\Delta_p$. Specifically, we prove\nthe point-wise convergence of $L_N f $ and convergence of the graph Dirichlet\nform with rates. Our analysis is based on first establishing a $C^0$\nconsistency for $\\hat{\\rho}$ which bounds the relative estimation error\n$|\\hat{\\rho} - \\bar{\\rho}|/\\bar{\\rho}$ uniformly with high probability, where\n$\\bar{\\rho} = p^{-1/d}$, and $p$ is the data density function. Our theoretical\nresults reveal the advantage of self-tuned kernel over fixed-bandwidth kernel\nvia smaller variance error in low-density regions. In the algorithm, no prior\nknowledge of $d$ or data density is needed. The theoretical results are\nsupported by numerical experiments on simulated data and hand-written digit\nimage data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:55:33 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 02:17:46 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "2011.01516", "submitter": "Gaurush Hiranandani", "authors": "Gaurush Hiranandani, Jatin Mathur, Harikrishna Narasimhan, Oluwasanmi\n  Koyejo", "title": "Quadratic Metric Elicitation with Application to Fairness", "comments": "32 pages, 9 figures, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric elicitation is a recent framework for eliciting performance metrics\nthat best reflect implicit user preferences. This framework enables a\npractitioner to adjust the performance metrics based on the application,\ncontext, and population at hand. However, available elicitation strategies have\nbeen limited to linear (or fractional-linear) functions of predictive rates. In\nthis paper, we develop an approach to elicit from a wider range of complex\nmulticlass metrics defined by quadratic functions of rates by exploiting their\nlocal linear structure. We apply this strategy to elicit quadratic metrics for\ngroup-based fairness, and also discuss how it can be generalized to\nhigher-order polynomials. Our elicitation strategies require only relative\npreference feedback and are robust to both feedback and finite sample noise.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:22:15 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hiranandani", "Gaurush", ""], ["Mathur", "Jatin", ""], ["Narasimhan", "Harikrishna", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "2011.01591", "submitter": "Hajo Holzmann", "authors": "Philipp Hermann and Hajo Holzmann", "title": "Support estimation in high-dimensional heteroscedastic mean regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A current strand of research in high-dimensional statistics deals with\nrobustifying the available methodology with respect to deviations from the\npervasive light-tail assumptions. In this paper we consider a linear mean\nregression model with random design and potentially heteroscedastic,\nheavy-tailed errors, and investigate support estimation in this framework. We\nuse a strictly convex, smooth variant of the Huber loss function with tuning\nparameter depending on the parameters of the problem, as well as the adaptive\nLASSO penalty for computational efficiency. For the resulting estimator we show\nsign-consistency and optimal rates of convergence in the $\\ell_\\infty$ norm as\nin the homoscedastic, light-tailed setting. In our analysis, we have to deal\nwith the issue that the support of the target parameter in the linear mean\nregression model and its robustified version may differ substantially even for\nsmall values of the tuning parameter of the Huber loss function. Simulations\nillustrate the favorable numerical performance of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 09:46:31 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hermann", "Philipp", ""], ["Holzmann", "Hajo", ""]]}, {"id": "2011.01647", "submitter": "Alireza Daneshkhah", "authors": "A. Daneshkhah, O. Chatrabgoun, M. Esmaeilbeigi, T. Sedighi, S.\n  Abolfathi", "title": "Uncertainty Quantification of Darcy Flow through Porous Media using Deep\n  Gaussian Process", "comments": "27 pages, 11 figures, presented in SIAM Conference on Uncertainty\n  Quantification (UQ16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational method based on the non-linear Gaussian process (GP), known\nas deep Gaussian processes (deep GPs) for uncertainty quantification &\npropagation in modelling of flow through heterogeneous porous media is\npresented. The method is also used for reducing dimensionality of model output\nand consequently emulating highly complex relationship between hydrogeological\nproperties and reduced order fluid velocity field in a tractable manner. Deep\nGPs are multi-layer hierarchical generalisations of GPs with multiple,\ninfinitely wide hidden layers that are very efficient models for deep learning\nand modelling of high-dimensional complex systems by tackling the complexity\nthrough several hidden layers connected with non-linear mappings. According to\nthis approach, the hydrogeological data is modelled as the output of a\nmultivariate GP whose inputs are governed by another GP such that each single\nlayer is either a standard GP or the Gaussian process latent variable model. A\nvariational approximation framework is used so that the posterior distribution\nof the model outputs associated to given inputs can be analytically\napproximated. In contrast to the other dimensionality reduction, methods that\ndo not provide any information about the dimensionality of each hidden layer,\nthe proposed method automatically selects the dimensionality of each hidden\nlayer and it can be used to propagate uncertainty obtained in each layer across\nthe hierarchy. Using this, dimensionality of the full input space consists of\nboth geometrical parameters of modelling domain and stochastic hydrogeological\nparameters can be simultaneously reduced without the need for any\nsimplifications generally being assumed for stochastic modelling of subsurface\nflow problems. It allows estimation of the flow statistics with greatly reduced\ncomputational efforts compared to other stochastic approaches such as Monte\nCarlo method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 11:57:38 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 11:31:03 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Daneshkhah", "A.", ""], ["Chatrabgoun", "O.", ""], ["Esmaeilbeigi", "M.", ""], ["Sedighi", "T.", ""], ["Abolfathi", "S.", ""]]}, {"id": "2011.01661", "submitter": "Subhadip Maji", "authors": "Indranil Basu and Subhadip Maji", "title": "Multicollinearity Correction and Combined Feature Effect in Shapley\n  Values", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretability is one of the most intriguing problems in most of the\nMachine Learning models, particularly for those that are mathematically\nsophisticated. Computing Shapley Values are arguably the best approach so far\nto find the importance of each feature in a model, at the row level. In other\nwords, Shapley values represent the importance of a feature for a particular\nrow, especially for Classification or Regression problems. One of the biggest\nlimitations of Shapley vales is that, Shapley value calculations assume all the\nfeatures are uncorrelated (independent of each other), this assumption is often\nincorrect. To address this problem, we present a unified framework to calculate\nShapley values with correlated features. To be more specific, we do an\nadjustment (Matrix formulation) of the features while calculating Independent\nShapley values for the rows. Moreover, we have given a Mathematical proof\nagainst the said adjustments. With these adjustments, Shapley values\n(Importance) for the features become independent of the correlations existing\nbetween them. We have also enhanced this adjustment concept for more than\nfeatures. As the Shapley values are additive, to calculate combined effect of\ntwo features, we just have to add their individual Shapley values. This is\nagain not right if one or more of the features (used in the combination) are\ncorrelated with the other features (not in the combination). We have addressed\nthis problem also by extending the correlation adjustment for one feature to\nmultiple features in the said combination for which Shapley values are\ndetermined. Our implementation of this method proves that our method is\ncomputationally efficient also, compared to original Shapley method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 12:28:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Basu", "Indranil", ""], ["Maji", "Subhadip", ""]]}, {"id": "2011.01668", "submitter": "Fanghui Liu", "authors": "Fanghui Liu, Xiaolin Huang, Yudong Chen, and Johan A.K. Suykens", "title": "Towards a Unified Quadrature Framework for Large-Scale Kernel Machines", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a quadrature framework for large-scale kernel\nmachines via a numerical integration representation. Considering that the\nintegration domain and measure of typical kernels, e.g., Gaussian kernels,\narc-cosine kernels, are fully symmetric, we leverage deterministic fully\nsymmetric interpolatory rules to efficiently compute quadrature nodes and\nassociated weights for kernel approximation. The developed interpolatory rules\nare able to reduce the number of needed nodes while retaining a high\napproximation accuracy. Further, we randomize the above deterministic rules by\nthe classical Monte-Carlo sampling and control variates techniques with two\nmerits: 1) The proposed stochastic rules make the dimension of the feature\nmapping flexibly varying, such that we can control the discrepancy between the\noriginal and approximate kernels by tuning the dimnension. 2) Our stochastic\nrules have nice statistical properties of unbiasedness and variance reduction\nwith fast convergence rate. In addition, we elucidate the relationship between\nour deterministic/stochastic interpolatory rules and current quadrature rules\nfor kernel approximation, including the sparse grids quadrature and stochastic\nspherical-radial rules, thereby unifying these methods under our framework.\nExperimental results on several benchmark datasets show that our methods\ncompare favorably with other representative kernel approximation based methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 12:48:07 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 19:29:22 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Liu", "Fanghui", ""], ["Huang", "Xiaolin", ""], ["Chen", "Yudong", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2011.01681", "submitter": "Chang Liu", "authors": "Chang Liu, Xinwei Sun, Jindong Wang, Haoyue Tang, Tao Li, Tao Qin, Wei\n  Chen, Tie-Yan Liu", "title": "Learning Causal Semantic Representation for Out-of-Distribution\n  Prediction", "comments": "Figures for CSG-ind/DA; model selection highlighted; condition and\n  intuition of identifiability; new version of OOD error bound supporting\n  CSG-ind; improved experiment implementation, with shifted-MNIST and\n  ImageCLEF-DA results updated; MDD and BNM baselines added; results on PACS\n  and VLCS datasets added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional supervised learning methods, especially deep ones, are found to\nbe sensitive to out-of-distribution (OOD) examples, largely because the learned\nrepresentation mixes the semantic factor with the variation factor due to their\ndomain-specific correlation, while only the semantic factor causes the output.\nTo address the problem, we propose a Causal Semantic Generative model (CSG)\nbased on a causal reasoning so that the two factors are modeled separately, and\ndevelop methods for OOD prediction from a single training domain, which is\ncommon and challenging. The methods are based on the causal invariance\nprinciple, with a novel design for both efficient learning and easy prediction.\nTheoretically, we prove that under certain conditions, CSG can identify the\nsemantic factor by fitting training data, and this semantic-identification\nguarantees the boundedness of OOD generalization error and the success of\nadaptation. Empirical study shows improved OOD performance over prevailing\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:16:05 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 12:18:28 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 12:30:03 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 16:17:09 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Liu", "Chang", ""], ["Sun", "Xinwei", ""], ["Wang", "Jindong", ""], ["Tang", "Haoyue", ""], ["Li", "Tao", ""], ["Qin", "Tao", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2011.01695", "submitter": "Ana-Maria Bucur", "authors": "Ana-Maria Bucur and Liviu P. Dinu", "title": "Detecting Early Onset of Depression from Social Media Text using Learned\n  Confidence Scores", "comments": "Accepted at Seventh Italian Conference on Computational Linguistics\n  CLiC-it 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational research on mental health disorders from written texts covers\nan interdisciplinary area between natural language processing and psychology. A\ncrucial aspect of this problem is prevention and early diagnosis, as suicide\nresulted from depression being the second leading cause of death for young\nadults. In this work, we focus on methods for detecting the early onset of\ndepression from social media texts, in particular from Reddit. To that end, we\nexplore the eRisk 2018 dataset and achieve good results with regard to the\nstate of the art by leveraging topic analysis and learned confidence scores to\nguide the decision process.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:34:04 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Bucur", "Ana-Maria", ""], ["Dinu", "Liviu P.", ""]]}, {"id": "2011.01704", "submitter": "Fabian Guignard", "authors": "Fabian Guignard, Federico Amato and Mikhail Kanevski", "title": "Uncertainty Quantification in Extreme Learning Machine: Analytical\n  Developments, Variance Estimates and Confidence Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification is crucial to assess prediction quality of a\nmachine learning model. In the case of Extreme Learning Machines (ELM), most\nmethods proposed in the literature make strong assumptions on the data, ignore\nthe randomness of input weights or neglect the bias contribution in confidence\ninterval estimations. This paper presents novel estimations that overcome these\nconstraints and improve the understanding of ELM variability. Analytical\nderivations are provided under general assumptions, supporting the\nidentification and the interpretation of the contribution of different\nvariability sources. Under both homoskedasticity and heteroskedasticity,\nseveral variance estimates are proposed, investigated, and numerically tested,\nshowing their effectiveness in replicating the expected variance behaviours.\nFinally, the feasibility of confidence intervals estimation is discussed by\nadopting a critical approach, hence raising the awareness of ELM users\nconcerning some of their pitfalls. The paper is accompanied with a scikit-learn\ncompatible Python library enabling efficient computation of all estimates\ndiscussed herein.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:45:59 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Guignard", "Fabian", ""], ["Amato", "Federico", ""], ["Kanevski", "Mikhail", ""]]}, {"id": "2011.01706", "submitter": "Yuhao Wang", "authors": "Haotian Zhang, Yuhao Wang, Jianyong Sun, Zongben Xu", "title": "Amortized Variational Deep Q Network", "comments": "Accepted to appear in the Deep Reinforcement Learning Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is one of the most important issues in deep\nreinforcement learning. To address this issue, recent methods consider the\nvalue function parameters as random variables, and resort variational inference\nto approximate the posterior of the parameters. In this paper, we propose an\namortized variational inference framework to approximate the posterior\ndistribution of the action value function in Deep Q Network. We establish the\nequivalence between the loss of the new model and the amortized variational\ninference loss. We realize the balance of exploration and exploitation by\nassuming the posterior as Cauchy and Gaussian, respectively in a two-stage\ntraining process. We show that the amortized framework can results in\nsignificant less learning parameters than existing state-of-the-art method.\nExperimental results on classical control tasks in OpenAI Gym and chain Markov\nDecision Process tasks show that the proposed method performs significantly\nbetter than state-of-art methods and requires much less training time.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:48:18 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Zhang", "Haotian", ""], ["Wang", "Yuhao", ""], ["Sun", "Jianyong", ""], ["Xu", "Zongben", ""]]}, {"id": "2011.01715", "submitter": "Sage Hahn", "authors": "Sage Hahn, Dekang Yuan, Wesley Thompson, Max M Owens, Nicholas\n  Allgaier and Hugh Garavan", "title": "Brain Predictability toolbox: a Python library for neuroimaging based\n  machine learning", "comments": "3 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summary Brain Predictability toolbox (BPt) represents a unified framework of\nmachine learning (ML) tools designed to work with both tabulated data (in\nparticular brain, psychiatric, behavioral, and physiological variables) and\nneuroimaging specific derived data (e.g., brain volumes and surfaces). This\npackage is suitable for investigating a wide range of different neuroimaging\nbased ML questions, in particular, those queried from large human datasets.\n  Availability and Implementation BPt has been developed as an open-source\nPython 3.6+ package hosted at https://github.com/sahahn/BPt under MIT License,\nwith documentation provided at https://bpt.readthedocs.io/en/latest/, and\ncontinues to be actively developed. The project can be downloaded through the\ngithub link provided. A web GUI interface based on the same code is currently\nunder development and can be set up through docker with instructions at\nhttps://github.com/sahahn/BPt_app.\n  Contact Please contact Sage Hahn at sahahn@uvm.edu\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:06:43 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hahn", "Sage", ""], ["Yuan", "Dekang", ""], ["Thompson", "Wesley", ""], ["Owens", "Max M", ""], ["Allgaier", "Nicholas", ""], ["Garavan", "Hugh", ""]]}, {"id": "2011.01737", "submitter": "Deborah Sulem", "authors": "Mihai Cucuringu, Apoorv Vikram Singh, D\\'eborah Sulem, Hemant Tyagi", "title": "Regularized spectral methods for clustering signed networks", "comments": "55 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of $k$-way clustering in signed graphs. Considerable\nattention in recent years has been devoted to analyzing and modeling signed\ngraphs, where the affinity measure between nodes takes either positive or\nnegative values. Recently, Cucuringu et al. [CDGT 2019] proposed a spectral\nmethod, namely SPONGE (Signed Positive over Negative Generalized Eigenproblem),\nwhich casts the clustering task as a generalized eigenvalue problem optimizing\na suitably defined objective function. This approach is motivated by social\nbalance theory, where the clustering task aims to decompose a given network\ninto disjoint groups, such that individuals within the same group are connected\nby as many positive edges as possible, while individuals from different groups\nare mainly connected by negative edges. Through extensive numerical\nsimulations, SPONGE was shown to achieve state-of-the-art empirical\nperformance. On the theoretical front, [CDGT 2019] analyzed SPONGE and the\npopular Signed Laplacian method under the setting of a Signed Stochastic Block\nModel (SSBM), for $k=2$ equal-sized clusters, in the regime where the graph is\nmoderately dense.\n  In this work, we build on the results in [CDGT 2019] on two fronts for the\nnormalized versions of SPONGE and the Signed Laplacian. Firstly, for both\nalgorithms, we extend the theoretical analysis in [CDGT 2019] to the general\nsetting of $k \\geq 2$ unequal-sized clusters in the moderately dense regime.\nSecondly, we introduce regularized versions of both methods to handle sparse\ngraphs -- a regime where standard spectral methods underperform -- and provide\ntheoretical guarantees under the same SSBM model. To the best of our knowledge,\nregularized spectral methods have so far not been considered in the setting of\nclustering signed graphs. We complement our theoretical results with an\nextensive set of numerical experiments on synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:40:34 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Singh", "Apoorv Vikram", ""], ["Sulem", "D\u00e9borah", ""], ["Tyagi", "Hemant", ""]]}, {"id": "2011.01758", "submitter": "Markus Wulfmeier", "authors": "Markus Wulfmeier, Arunkumar Byravan, Tim Hertweck, Irina Higgins,\n  Ankush Gupta, Tejas Kulkarni, Malcolm Reynolds, Denis Teplyashin, Roland\n  Hafner, Thomas Lampe, Martin Riedmiller", "title": "Representation Matters: Improving Perception and Exploration for\n  Robotics", "comments": "Published at ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projecting high-dimensional environment observations into lower-dimensional\nstructured representations can considerably improve data-efficiency for\nreinforcement learning in domains with limited data such as robotics. Can a\nsingle generally useful representation be found? In order to answer this\nquestion, it is important to understand how the representation will be used by\nthe agent and what properties such a 'good' representation should have. In this\npaper we systematically evaluate a number of common learnt and hand-engineered\nrepresentations in the context of three robotics tasks: lifting, stacking and\npushing of 3D blocks. The representations are evaluated in two use-cases: as\ninput to the agent, or as a source of auxiliary tasks. Furthermore, the value\nof each representation is evaluated in terms of three properties:\ndimensionality, observability and disentanglement. We can significantly improve\nperformance in both use-cases and demonstrate that some representations can\nperform commensurate to simulator states as agent inputs. Finally, our results\nchallenge common intuitions by demonstrating that: 1) dimensionality strongly\nmatters for task generation, but is negligible for inputs, 2) observability of\ntask-relevant aspects mostly affects the input representation use-case, and 3)\ndisentanglement leads to better auxiliary tasks, but has only limited benefits\nfor input representations. This work serves as a step towards a more systematic\nunderstanding of what makes a 'good' representation for control in robotics,\nenabling practitioners to make more informed choices for developing new learned\nor hand-engineered representations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:00:36 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 18:31:54 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wulfmeier", "Markus", ""], ["Byravan", "Arunkumar", ""], ["Hertweck", "Tim", ""], ["Higgins", "Irina", ""], ["Gupta", "Ankush", ""], ["Kulkarni", "Tejas", ""], ["Reynolds", "Malcolm", ""], ["Teplyashin", "Denis", ""], ["Hafner", "Roland", ""], ["Lampe", "Thomas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2011.01797", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Hao Liu, Wenjing Liao, Tuo Zhao", "title": "Doubly Robust Off-Policy Learning on Low-Dimensional Manifolds by Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference explores the causation between actions and the consequent\nrewards on a covariate set. Recently deep learning has achieved a remarkable\nperformance in causal inference, but existing statistical theories cannot well\nexplain such an empirical success, especially when the covariates are\nhigh-dimensional. Most theoretical results in causal inference are asymptotic,\nsuffer from the curse of dimensionality, and only work for the finite-action\nscenario. To bridge such a gap between theory and practice, this paper studies\ndoubly robust off-policy learning by deep neural networks. When the covariates\nlie on a low-dimensional manifold, we prove nonasymptotic regret bounds, which\nconverge at a fast rate depending on the intrinsic dimension of the manifold.\nOur results cover both the finite- and continuous-action scenarios. Our theory\nshows that deep neural networks are adaptive to the low-dimensional geometric\nstructures of the covariates, and partially explains the success of deep\nlearning for causal inference.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:44:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chen", "Minshuo", ""], ["Liu", "Hao", ""], ["Liao", "Wenjing", ""], ["Zhao", "Tuo", ""]]}, {"id": "2011.01799", "submitter": "Camille Chapdelaine", "authors": "Sylvaine Picard, Camille Chapdelaine, Cyril Cappi, Laurent Gardes,\n  Eric Jenn, Baptiste Lef\\`evre, Thomas Soumarmon", "title": "Ensuring Dataset Quality for Machine Learning Certification", "comments": null, "journal-ref": "The 10th IEEE International Workshop on Software Certification\n  (WoSoCer 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of dataset quality in the context of\nMachine Learning (ML)-based critical systems. We briefly analyse the\napplicability of some existing standards dealing with data and show that the\nspecificities of the ML context are neither properly captured nor taken into\nac-count. As a first answer to this concerning situation, we propose a dataset\nspecification and verification process, and apply it on a signal recognition\nsystem from the railway domain. In addi-tion, we also give a list of\nrecommendations for the collection and management of datasets. This work is one\nstep towards the dataset engineering process that will be required for ML to be\nused on safety critical systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:45:43 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Picard", "Sylvaine", ""], ["Chapdelaine", "Camille", ""], ["Cappi", "Cyril", ""], ["Gardes", "Laurent", ""], ["Jenn", "Eric", ""], ["Lef\u00e8vre", "Baptiste", ""], ["Soumarmon", "Thomas", ""]]}, {"id": "2011.01821", "submitter": "Martin Bertran", "authors": "Natalia Martinez, Martin Bertran, Guillermo Sapiro", "title": "Minimax Pareto Fairness: A Multi Objective Perspective", "comments": null, "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we formulate and formally characterize group fairness as a\nmulti-objective optimization problem, where each sensitive group risk is a\nseparate objective. We propose a fairness criterion where a classifier achieves\nminimax risk and is Pareto-efficient w.r.t. all groups, avoiding unnecessary\nharm, and can lead to the best zero-gap model if policy dictates so. We provide\na simple optimization algorithm compatible with deep neural networks to satisfy\nthese constraints. Since our method does not require test-time access to\nsensitive attributes, it can be applied to reduce worst-case classification\nerrors between outcomes in unbalanced classification problems. We test the\nproposed methodology on real case-studies of predicting income, ICU patient\nmortality, skin lesions classification, and assessing credit risk,\ndemonstrating how our framework compares favorably to other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 16:21:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Martinez", "Natalia", ""], ["Bertran", "Martin", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "2011.01845", "submitter": "Heinke Hihn", "authors": "Heinke Hihn and Daniel A. Braun", "title": "Specialization in Hierarchical Learning Systems", "comments": null, "journal-ref": "Neural Processing Letters, 1-34, 2020", "doi": "10.1007/s11063-020-10351-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Joining multiple decision-makers together is a powerful way to obtain more\nsophisticated decision-making systems, but requires to address the questions of\ndivision of labor and specialization. We investigate in how far information\nconstraints in hierarchies of experts not only provide a principled method for\nregularization but also to enforce specialization. In particular, we devise an\ninformation-theoretically motivated on-line learning rule that allows\npartitioning of the problem space into multiple sub-problems that can be solved\nby the individual experts. We demonstrate two different ways to apply our\nmethod: (i) partitioning problems based on individual data samples and (ii)\nbased on sets of data samples representing tasks. Approach (i) equips the\nsystem with the ability to solve complex decision-making problems by finding an\noptimal combination of local expert decision-makers. Approach (ii) leads to\ndecision-makers specialized in solving families of tasks, which equips the\nsystem with the ability to solve meta-learning problems. We show the broad\napplicability of our approach on a range of problems including classification,\nregression, density estimation, and reinforcement learning problems, both in\nthe standard machine learning setup and in a meta-learning setting.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:00:31 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hihn", "Heinke", ""], ["Braun", "Daniel A.", ""]]}, {"id": "2011.01848", "submitter": "Ananda Theertha Suresh", "authors": "Ananda Theertha Suresh", "title": "Robust hypothesis testing and distribution estimation in Hellinger\n  distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple robust hypothesis test that has the same sample\ncomplexity as that of the optimal Neyman-Pearson test up to constants, but\nrobust to distribution perturbations under Hellinger distance. We discuss the\napplicability of such a robust test for estimating distributions in Hellinger\ndistance. We empirically demonstrate the power of the test on canonical\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:09:32 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Suresh", "Ananda Theertha", ""]]}, {"id": "2011.01889", "submitter": "Eric Strobl", "authors": "Eric V. Strobl", "title": "Automated Hyperparameter Selection for the PC Algorithm", "comments": "Under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PC algorithm infers causal relations using conditional independence tests\nthat require a pre-specified Type I $\\alpha$ level. PC is however unsupervised,\nso we cannot tune $\\alpha$ using traditional cross-validation. We therefore\npropose AutoPC, a fast procedure that optimizes $\\alpha$ directly for a user\nchosen metric. We in particular force PC to double check its output by\nexecuting a second run on the recovered graph. We choose the final output as\nthe one which maximizes stability between the two runs. AutoPC consistently\noutperforms the state of the art across multiple metrics.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:08:55 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 16:01:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Strobl", "Eric V.", ""]]}, {"id": "2011.01926", "submitter": "Ke Li", "authors": "Shichong Peng and Ke Li", "title": "Generating Unobserved Alternatives", "comments": "Videos in the article are also available as ancillary files in the\n  previous version (arXiv:2011.01926v3). Website:\n  https://niopeng.github.io/HyperRIM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider problems where multiple predictions can be considered correct,\nbut only one of them is given as supervision. This setting differs from both\nthe regression and class-conditional generative modelling settings: in the\nformer, there is a unique observed output for each input, which is provided as\nsupervision; in the latter, there are many observed outputs for each input, and\nmany are provided as supervision. Applying either regression methods and\nconditional generative models to the present setting often results in a model\nthat can only make a single prediction for each input. We explore several\nproblems that have this property and develop an approach that can generate\nmultiple high-quality predictions given the same input. As a result, it can be\nused to generate high-quality outputs that are different from the observed\noutput.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:57:57 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 18:03:05 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 08:20:49 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 10:05:52 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Peng", "Shichong", ""], ["Li", "Ke", ""]]}, {"id": "2011.01928", "submitter": "Ayush Jain", "authors": "Ayush Jain, Andrew Szot, Joseph J. Lim", "title": "Generalization to New Actions in Reinforcement Learning", "comments": "ICML 2020. Videos and code:\n  https://sites.google.com/view/action-generalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental trait of intelligence is the ability to achieve goals in the\nface of novel circumstances, such as making decisions from new action choices.\nHowever, standard reinforcement learning assumes a fixed set of actions and\nrequires expensive retraining when given a new action set. To make learning\nagents more adaptable, we introduce the problem of zero-shot generalization to\nnew actions. We propose a two-stage framework where the agent first infers\naction representations from action information acquired separately from the\ntask. A policy flexible to varying action sets is then trained with\ngeneralization objectives. We benchmark generalization on sequential tasks,\nsuch as selecting from an unseen tool-set to solve physical reasoning puzzles\nand stacking towers with novel 3D shapes. Videos and code are available at\nhttps://sites.google.com/view/action-generalization\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:58:39 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Jain", "Ayush", ""], ["Szot", "Andrew", ""], ["Lim", "Joseph J.", ""]]}, {"id": "2011.01963", "submitter": "Jinhyun So", "authors": "Jinhyun So, Basak Guler, A. Salman Avestimehr", "title": "A Scalable Approach for Privacy-Preserving Collaborative Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a collaborative learning scenario in which multiple data-owners\nwish to jointly train a logistic regression model, while keeping their\nindividual datasets private from the other parties. We propose COPML, a\nfully-decentralized training framework that achieves scalability and\nprivacy-protection simultaneously. The key idea of COPML is to securely encode\nthe individual datasets to distribute the computation load effectively across\nmany parties and to perform the training computations as well as the model\nupdates in a distributed manner on the securely encoded data. We provide the\nprivacy analysis of COPML and prove its convergence. Furthermore, we\nexperimentally demonstrate that COPML can achieve significant speedup in\ntraining over the benchmark protocols. Our protocol provides strong statistical\nprivacy guarantees against colluding parties (adversaries) with unbounded\ncomputational power, while achieving up to $16\\times$ speedup in the training\ntime against the benchmark protocols.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:09:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["So", "Jinhyun", ""], ["Guler", "Basak", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2011.01973", "submitter": "Neharika Jali", "authors": "Neharika Jali, Nikhil Karamchandani, and Sharayu Moharir", "title": "Greedy $k$-Center from Noisy Distance Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the canonical $k$-center problem over a set of vertices\nin a metric space, where the underlying distances are apriori unknown. Instead,\nwe can query an oracle which provides noisy/incomplete estimates of the\ndistance between any pair of vertices. We consider two oracle models: Dimension\nSampling where each query to the oracle returns the distance between a pair of\npoints in one dimension; and Noisy Distance Sampling where the oracle returns\nthe true distance corrupted by noise. We propose active algorithms, based on\nideas such as UCB and Thompson sampling developed in the closely related\nMulti-Armed Bandit problem, which adaptively decide which queries to send to\nthe oracle and are able to solve the $k$-center problem within an approximation\nratio of two with high probability. We analytically characterize\ninstance-dependent query complexity of our algorithms and also demonstrate\nsignificant improvements over naive implementations via numerical evaluations\non two real-world datasets (Tiny ImageNet and UT Zappos50K).\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:37:02 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:19:50 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Jali", "Neharika", ""], ["Karamchandani", "Nikhil", ""], ["Moharir", "Sharayu", ""]]}, {"id": "2011.01977", "submitter": "Ali el Hassouni", "authors": "Daniel Lutscher, Ali el Hassouni, Maarten Stol, Mark Hoogendoorn", "title": "Mixing Consistent Deep Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding well-defined clusters in data represents a fundamental challenge for\nmany data-driven applications, and largely depends on good data representation.\nDrawing on literature regarding representation learning, studies suggest that\none key characteristic of good latent representations is the ability to produce\nsemantically mixed outputs when decoding linear interpolations of two latent\nrepresentations. We propose the Mixing Consistent Deep Clustering method which\nencourages interpolations to appear realistic while adding the constraint that\ninterpolations of two data points must look like one of the two inputs. By\napplying this training method to various clustering (non-)specific autoencoder\nmodels we found that using the proposed training method systematically changed\nthe structure of learned representations of a model and it improved clustering\nperformance for the tested ACAI, IDEC, and VAE models on the MNIST, SVHN, and\nCIFAR-10 datasets. These outcomes have practical implications for numerous\nreal-world clustering tasks, as it shows that the proposed method can be added\nto existing autoencoders to further improve clustering performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:47:06 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Lutscher", "Daniel", ""], ["Hassouni", "Ali el", ""], ["Stol", "Maarten", ""], ["Hoogendoorn", "Mark", ""]]}, {"id": "2011.01979", "submitter": "Kristjan Greenewald", "authors": "Kristjan Greenewald, Dmitriy Katz-Rogozhnikov, Karthik Shanmugam", "title": "High-Dimensional Feature Selection for Sample Efficient Treatment Effect\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of causal treatment effects from observational data is a\nfundamental problem in causal inference. To avoid bias, the effect estimator\nmust control for all confounders. Hence practitioners often collect data for as\nmany covariates as possible to raise the chances of including the relevant\nconfounders. While this addresses the bias, this has the side effect of\nsignificantly increasing the number of data samples required to accurately\nestimate the effect due to the increased dimensionality. In this work, we\nconsider the setting where out of a large number of covariates $X$ that satisfy\nstrong ignorability, an unknown sparse subset $S$ is sufficient to include to\nachieve zero bias, i.e. $c$-equivalent to $X$. We propose a common objective\nfunction involving outcomes across treatment cohorts with nonconvex joint\nsparsity regularization that is guaranteed to recover $S$ with high probability\nunder a linear outcome model for $Y$ and subgaussian covariates for each of the\ntreatment cohort. This improves the effect estimation sample complexity so that\nit scales with the cardinality of the sparse subset $S$ and $\\log |X|$, as\nopposed to the cardinality of the full set $X$. We validate our approach with\nexperiments on treatment effect estimation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:54:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Greenewald", "Kristjan", ""], ["Katz-Rogozhnikov", "Dmitriy", ""], ["Shanmugam", "Karthik", ""]]}, {"id": "2011.01990", "submitter": "Eddie Pei", "authors": "E. Pei, E. Fokou\\'e", "title": "Graph Enhanced High Dimensional Kernel Regression", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the flexibility, versatility and predictive power of kernel\nregression are combined with now lavishly available network data to create\nregression models with even greater predictive performances. Building from\nprevious work featuring generalized linear models built in the presence of\nnetwork cohesion data, we construct a kernelized extension that captures\nsubtler nonlinearities in extremely high dimensional spaces and also produces\nfar better predictive performances. Applications of seamless yet substantial\nadaptation to simulated and real-life data demonstrate the appeal and strength\nof our work.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:09:36 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Pei", "E.", ""], ["Fokou\u00e9", "E.", ""]]}, {"id": "2011.02004", "submitter": "Tony Wu", "authors": "Tony C. Wu, Daniel Flam-Shepherd, Al\\'an Aspuru-Guzik", "title": "Bayesian Variational Optimization for Combinatorial Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on Bayesian Optimization in combinatorial spaces. In many\napplications in the natural science. Broad applications include the study of\nmolecules, proteins, DNA, device structures and quantum circuit designs, a on\noptimization over combinatorial categorical spaces is needed to find optimal or\npareto-optimal solutions. However, only a limited amount of methods have been\nproposed to tackle this problem. Many of them depend on employing Gaussian\nProcess for combinatorial Bayesian Optimizations. Gaussian Processes suffer\nfrom scalability issues for large data sizes as their scaling is cubic with\nrespect to the number of data points. This is often impractical for optimizing\nlarge search spaces. Here, we introduce a variational Bayesian optimization\nmethod that combines variational optimization and continuous relaxations to the\noptimization of the acquisition function for Bayesian optimization. Critically,\nthis method allows for gradient-based optimization and has the capability of\noptimizing problems with large data size and data dimensions. We have shown the\nperformance of our method is comparable to state-of-the-art methods while\nmaintaining its scalability advantages. We also applied our method in molecular\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:56:13 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wu", "Tony C.", ""], ["Flam-Shepherd", "Daniel", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "2011.02086", "submitter": "Yan Zuo", "authors": "Yan Zuo, Tom Drummond", "title": "Residual Likelihood Forests", "comments": "Accepted at BMVC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel ensemble learning approach called Residual\nLikelihood Forests (RLF). Our weak learners produce conditional likelihoods\nthat are sequentially optimized using global loss in the context of previous\nlearners within a boosting-like framework (rather than probability\ndistributions that are measured from observed data) and are combined\nmultiplicatively (rather than additively). This increases the efficiency of our\nstrong classifier, allowing for the design of classifiers which are more\ncompact in terms of model capacity. We apply our method to several machine\nlearning classification tasks, showing significant improvements in performance.\nWhen compared against several ensemble approaches including Random Forests and\nGradient Boosted Trees, RLFs offer a significant improvement in performance\nwhilst concurrently reducing the required model size.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:59:41 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zuo", "Yan", ""], ["Drummond", "Tom", ""]]}, {"id": "2011.02089", "submitter": "Grace Deng", "authors": "Grace Deng, Cuize Han, David S. Matteson", "title": "Learning to Rank with Missing Data via Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the role of Conditional Generative Adversarial Networks (GAN) in\nimputing missing data and apply GAN imputation on a novel use case in\ne-commerce: a learning-to-rank problem with incomplete training data.\nConventional imputation methods often make assumptions regarding the underlying\ndistribution of the missing data, while GANs offer an alternative framework to\nsidestep approximating intractable distributions. First, we prove that GAN\nimputation offers theoretical guarantees beyond the naive Missing Completely At\nRandom (MCAR) scenario. Next, we show that empirically, the Conditional GAN\nstructure is well suited for data with heterogeneous distributions and across\nunbalanced classes, improving performance metrics such as RMSE. Using an Amazon\nSearch ranking dataset, we produce standard ranking models trained on\nGAN-imputed data that are comparable to training on ground-truth data based on\nstandard ranking quality metrics NDCG and MRR. We also highlight how different\nneural net features such as convolution and dropout layers can improve\nperformance given different missing value settings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 01:15:41 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 20:42:19 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Deng", "Grace", ""], ["Han", "Cuize", ""], ["Matteson", "David S.", ""]]}, {"id": "2011.02147", "submitter": "Chun-Na Li", "authors": "Jiakou Liu, Xiong Xiong, Pei-Wei Ren, Da Zhao, Chun-Na Li, Yuan-Hai\n  Shao", "title": "Capped norm linear discriminant analysis and its applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical linear discriminant analysis (LDA) is based on squared Frobenious\nnorm and hence is sensitive to outliers and noise. To improve the robustness of\nLDA, in this paper, we introduce capped l_{2,1}-norm of a matrix, which employs\nnon-squared l_2-norm and \"capped\" operation, and further propose a novel capped\nl_{2,1}-norm linear discriminant analysis, called CLDA. Due to the use of\ncapped l_{2,1}-norm, CLDA can effectively remove extreme outliers and suppress\nthe effect of noise data. In fact, CLDA can be also viewed as a weighted LDA.\nCLDA is solved through a series of generalized eigenvalue problems with\ntheoretical convergency. The experimental results on an artificial data set,\nsome UCI data sets and two image data sets demonstrate the effectiveness of\nCLDA.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:15:10 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Liu", "Jiakou", ""], ["Xiong", "Xiong", ""], ["Ren", "Pei-Wei", ""], ["Zhao", "Da", ""], ["Li", "Chun-Na", ""], ["Shao", "Yuan-Hai", ""]]}, {"id": "2011.02150", "submitter": "Wei Yuan", "authors": "Wei Yuan and Kai-Xin Gao", "title": "EAdam Optimizer: How $\\epsilon$ Impact Adam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many adaptive optimization methods have been proposed and used in deep\nlearning, in which Adam is regarded as the default algorithm and widely used in\nmany deep learning frameworks. Recently, many variants of Adam, such as\nAdabound, RAdam and Adabelief, have been proposed and show better performance\nthan Adam. However, these variants mainly focus on changing the stepsize by\nmaking differences on the gradient or the square of it. Motivated by the fact\nthat suitable damping is important for the success of powerful second-order\noptimizers, we discuss the impact of the constant $\\epsilon$ for Adam in this\npaper. Surprisingly, we can obtain better performance than Adam simply changing\nthe position of $\\epsilon$. Based on this finding, we propose a new variant of\nAdam called EAdam, which doesn't need extra hyper-parameters or computational\ncosts. We also discuss the relationships and differences between our method and\nAdam. Finally, we conduct extensive experiments on various popular tasks and\nmodels. Experimental results show that our method can bring significant\nimprovement compared with Adam. Our code is available at\nhttps://github.com/yuanwei2019/EAdam-optimizer.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:39:44 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Yuan", "Wei", ""], ["Gao", "Kai-Xin", ""]]}, {"id": "2011.02159", "submitter": "Niru Maheswaranathan", "authors": "Niru Maheswaranathan, David Sussillo, Luke Metz, Ruoxi Sun, Jascha\n  Sohl-Dickstein", "title": "Reverse engineering learned optimizers reveals known and novel\n  mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned optimizers are algorithms that can themselves be trained to solve\noptimization problems. In contrast to baseline optimizers (such as momentum or\nAdam) that use simple update rules derived from theoretical principles, learned\noptimizers use flexible, high-dimensional, nonlinear parameterizations.\nAlthough this can lead to better performance in certain settings, their inner\nworkings remain a mystery. How is a learned optimizer able to outperform a well\ntuned baseline? Has it learned a sophisticated combination of existing\noptimization techniques, or is it implementing completely new behavior? In this\nwork, we address these questions by careful analysis and visualization of\nlearned optimizers. We study learned optimizers trained from scratch on three\ndisparate tasks, and discover that they have learned interpretable mechanisms,\nincluding: momentum, gradient clipping, learning rate schedules, and a new form\nof learning rate adaptation. Moreover, we show how the dynamics of learned\noptimizers enables these behaviors. Our results help elucidate the previously\nmurky understanding of how learned optimizers work, and establish tools for\ninterpreting future learned optimizers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 07:12:43 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Maheswaranathan", "Niru", ""], ["Sussillo", "David", ""], ["Metz", "Luke", ""], ["Sun", "Ruoxi", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2011.02179", "submitter": "Nafiseh Ghoroghchian Ms.", "authors": "Nafiseh Ghoroghchian, David M. Groppe, Roman Genov, Taufik A.\n  Valiante, and Stark C. Draper", "title": "Node-Centric Graph Learning from Data for Brain State Identification", "comments": null, "journal-ref": "IEEE Transactions on Signal and Information Processing over\n  Networks, 6, 120-132 (2020)", "doi": "10.1109/TSIPN.2020.2964230", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven graph learning models a network by determining the strength of\nconnections between its nodes. The data refers to a graph signal which\nassociates a value with each graph node. Existing graph learning methods either\nuse simplified models for the graph signal, or they are prohibitively expensive\nin terms of computational and memory requirements. This is particularly true\nwhen the number of nodes is high or there are temporal changes in the network.\nIn order to consider richer models with a reasonable computational\ntractability, we introduce a graph learning method based on representation\nlearning on graphs. Representation learning generates an embedding for each\ngraph node, taking the information from neighbouring nodes into account. Our\ngraph learning method further modifies the embeddings to compute the graph\nsimilarity matrix. In this work, graph learning is used to examine brain\nnetworks for brain state identification. We infer time-varying brain graphs\nfrom an extensive dataset of intracranial electroencephalographic (iEEG)\nsignals from ten patients. We then apply the graphs as input to a classifier to\ndistinguish seizure vs. non-seizure brain states. Using the binary\nclassification metric of area under the receiver operating characteristic curve\n(AUC), this approach yields an average of 9.13 percent improvement when\ncompared to two widely used brain network modeling methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 08:44:44 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ghoroghchian", "Nafiseh", ""], ["Groppe", "David M.", ""], ["Genov", "Roman", ""], ["Valiante", "Taufik A.", ""], ["Draper", "Stark C.", ""]]}, {"id": "2011.02203", "submitter": "Xinwei Sun", "authors": "Xinwei Sun, Botong Wu, Xiangyu Zheng, Chang Liu, Wei Chen, Tao Qin,\n  Tie-yan Liu", "title": "Latent Causal Invariant Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current supervised learning can learn spurious correlation during the\ndata-fitting process, imposing issues regarding interpretability,\nout-of-distribution (OOD) generalization, and robustness. To avoid spurious\ncorrelation, we propose a Latent Causal Invariance Model (LaCIM) which pursues\ncausal prediction. Specifically, we introduce latent variables that are\nseparated into (a) output-causative factors and (b) others that are spuriously\ncorrelated to the output via confounders, to model the underlying causal\nfactors. We further assume the generating mechanisms from latent space to\nobserved data to be causally invariant. We give the identifiable claim of such\ninvariance, particularly the disentanglement of output-causative factors from\nothers, as a theoretical guarantee for precise inference and avoiding spurious\ncorrelation. We propose a Variational-Bayesian-based method for estimation and\nto optimize over the latent space for prediction. The utility of our approach\nis verified by improved interpretability, prediction power on various OOD\nscenarios (including healthcare) and robustness on security.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 10:00:27 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 17:04:41 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 09:54:44 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 23:28:44 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Sun", "Xinwei", ""], ["Wu", "Botong", ""], ["Zheng", "Xiangyu", ""], ["Liu", "Chang", ""], ["Chen", "Wei", ""], ["Qin", "Tao", ""], ["Liu", "Tie-yan", ""]]}, {"id": "2011.02255", "submitter": "Yuzhao Chen", "authors": "Yuzhao Chen, Yatao Bian, Xi Xiao, Yu Rong, Tingyang Xu, Junzhou Huang", "title": "On Self-Distilling Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the teacher-student knowledge distillation framework has\ndemonstrated its potential in training Graph Neural Networks (GNNs). However,\ndue to the difficulty of training over-parameterized GNN models, one may not\neasily obtain a satisfactory teacher model for distillation. Furthermore, the\ninefficient training process of teacher-student knowledge distillation also\nimpedes its applications in GNN models. In this paper, we propose the first\nteacher-free knowledge distillation method for GNNs, termed GNN\nSelf-Distillation (GNN-SD), that serves as a drop-in replacement of the\nstandard training process. The method is built upon the proposed neighborhood\ndiscrepancy rate (NDR), which quantifies the non-smoothness of the embedded\ngraph in an efficient way. Based on this metric, we propose the adaptive\ndiscrepancy retaining (ADR) regularizer to empower the transferability of\nknowledge that maintains high neighborhood discrepancy across GNN layers. We\nalso summarize a generic GNN-SD framework that could be exploited to induce\nother distillation strategies. Experiments further prove the effectiveness and\ngeneralization of our approach, as it brings: 1) state-of-the-art GNN\ndistillation performance with less training cost, 2) consistent and\nconsiderable performance enhancement for various popular backbones.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:29:33 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 04:31:53 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Chen", "Yuzhao", ""], ["Bian", "Yatao", ""], ["Xiao", "Xi", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Junzhou", ""]]}, {"id": "2011.02256", "submitter": "Masaaki Imaizumi", "authors": "Masaaki Imaizumi, Kenji Fukumizu", "title": "Advantage of Deep Neural Networks for Estimating Functions with\n  Singularity on Curves", "comments": "Complete version of arXiv:1802.04474", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theory to elucidate the reason that deep neural networks (DNNs)\nperform better than other methods. In terms of the nonparametric regression\nproblem, it is well known that many standard methods attain the minimax optimal\nrate of estimation errors for smooth functions, and thus, it is not\nstraightforward to identify the theoretical advantages of DNNs. This study\nfills this gap by considering the estimation for a class of non-smooth\nfunctions with singularities on smooth curves. Our findings are as follows: (i)\nWe derive the generalization error of a DNN estimator and prove that its\nconvergence rate is almost optimal. (ii) We reveal that a certain class of\ncommon models are sub-optimal, including linear estimators and other harmonic\nanalysis methods such as wavelets and curvelets. This advantage of DNNs comes\nfrom a fact that a shape of singularity can be successfully handled by their\nmulti-layered structure.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:51:14 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Imaizumi", "Masaaki", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "2011.02258", "submitter": "Huiming Zhang", "authors": "Huiming Zhang, Song Xi Chen", "title": "Concentration Inequalities for Statistical Inference", "comments": "Invited review article on constants-specified concentration\n  inequalities published in Communications in Mathematical Research", "journal-ref": "Communications in Mathematical Research. 37(1), 1-85 (2021)", "doi": "10.4208/cmr.2020-0041", "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a review of concentration inequalities which are widely\nemployed in non-asymptotical analyses of mathematical statistics in a wide\nrange of settings, from distribution-free to distribution-dependent, from\nsub-Gaussian to sub-exponential, sub-Gamma, and sub-Weibull random variables,\nand from the mean to the maximum concentration. This review provides results in\nthese settings with some fresh new results. Given the increasing popularity of\nhigh-dimensional data and inference, results in the context of high-dimensional\nlinear and Poisson regressions are also provided. We aim to illustrate the\nconcentration inequalities with known constants and to improve existing bounds\nwith sharper constants.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:54:06 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 04:09:05 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 05:30:11 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zhang", "Huiming", ""], ["Chen", "Song Xi", ""]]}, {"id": "2011.02268", "submitter": "Ilyes Khemakhem", "authors": "Ilyes Khemakhem, Ricardo Pio Monti, Robert Leech, Aapo Hyv\\\"arinen", "title": "Causal Autoregressive Flows", "comments": "Published at AISTATS2021. Code available at\n  https://github.com/piomonti/carefl", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two apparently unrelated fields -- normalizing flows and causality -- have\nrecently received considerable attention in the machine learning community. In\nthis work, we highlight an intrinsic correspondence between a simple family of\nautoregressive normalizing flows and identifiable causal models. We exploit the\nfact that autoregressive flow architectures define an ordering over variables,\nanalogous to a causal ordering, to show that they are well-suited to performing\na range of causal inference tasks, ranging from causal discovery to making\ninterventional and counterfactual predictions. First, we show that causal\nmodels derived from both affine and additive autoregressive flows with fixed\norderings over variables are identifiable, i.e. the true direction of causal\ninfluence can be recovered. This provides a generalization of the additive\nnoise model well-known in causal discovery. Second, we derive a bivariate\nmeasure of causal direction based on likelihood ratios, leveraging the fact\nthat flow models can estimate normalized log-densities of data. Third, we\ndemonstrate that flows naturally allow for direct evaluation of both\ninterventional and counterfactual queries, the latter case being possible due\nto the invertible nature of flows. Finally, throughout a series of experiments\non synthetic and real data, the proposed method is shown to outperform current\napproaches for causal discovery as well as making accurate interventional and\ncounterfactual predictions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:17:35 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 16:35:26 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Khemakhem", "Ilyes", ""], ["Monti", "Ricardo Pio", ""], ["Leech", "Robert", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "2011.02271", "submitter": "Amir Dib", "authors": "Amir Dib", "title": "Quantized Variational Inference", "comments": null, "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Quantized Variational Inference, a new algorithm for Evidence\nLower Bound maximization. We show how Optimal Voronoi Tesselation produces\nvariance free gradients for ELBO optimization at the cost of introducing\nasymptotically decaying bias. Subsequently, we propose a Richardson\nextrapolation type method to improve the asymptotic bound. We show that using\nthe Quantized Variational Inference framework leads to fast convergence for\nboth score function and the reparametrized gradient estimator at a comparable\ncomputational cost. Finally, we propose several experiments to assess the\nperformance of our method and its limitations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:22:50 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Dib", "Amir", ""]]}, {"id": "2011.02273", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela and Maria Perez-Ortiz and Emine Yilmaz and John\n  Shawe-Taylor", "title": "VLEngagement: A Dataset of Scientific Video Lectures for Evaluating\n  Population-based Engagement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the emergence of e-learning and personalised education, the production\nand distribution of digital educational resources have boomed. Video lectures\nhave now become one of the primary modalities to impart knowledge to masses in\nthe current digital age. The rapid creation of video lecture content challenges\nthe currently established human-centred moderation and quality assurance\npipeline, demanding for more efficient, scalable and automatic solutions for\nmanaging learning resources. Although a few datasets related to engagement with\neducational videos exist, there is still an important need for data and\nresearch aimed at understanding learner engagement with scientific video\nlectures. This paper introduces VLEngagement, a novel dataset that consists of\ncontent-based and video-specific features extracted from publicly available\nscientific video lectures and several metrics related to user engagement. We\nintroduce several novel tasks related to predicting and understanding\ncontext-agnostic engagement in video lectures, providing preliminary baselines.\nThis is the largest and most diverse publicly available dataset to our\nknowledge that deals with such tasks. The extraction of Wikipedia topic-based\nfeatures also allows associating more sophisticated Wikipedia based features to\nthe dataset to improve the performance in these tasks. The dataset, helper\ntools and example code snippets are available publicly at\nhttps://github.com/sahanbull/context-agnostic-engagement\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:20:19 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Bulathwela", "Sahan", ""], ["Perez-Ortiz", "Maria", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "2011.02330", "submitter": "Maximilian Kasy", "authors": "Maximilian Kasy and Alexander Teytelboym", "title": "Adaptive Combinatorial Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider settings where an allocation has to be chosen repeatedly, returns\nare unknown but can be learned, and decisions are subject to constraints. Our\nmodel covers two-sided and one-sided matching, even with complex constraints.\nWe propose an approach based on Thompson sampling. Our main result is a\nprior-independent finite-sample bound on the expected regret for this\nalgorithm. Although the number of allocations grows exponentially in the number\nof participants, the bound does not depend on this number. We illustrate the\nperformance of our algorithm using data on refugee resettlement in the United\nStates.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 15:02:59 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Kasy", "Maximilian", ""], ["Teytelboym", "Alexander", ""]]}, {"id": "2011.02396", "submitter": "Zhenhuan(Neyo) Yang", "authors": "Zhenhuan Yang, Baojian Zhou, Yunwen Lei, Yiming Ying", "title": "Stochastic Hard Thresholding Algorithms for AUC Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to develop stochastic hard thresholding algorithms for\nthe important problem of AUC maximization in imbalanced classification. The\nmain challenge is the pairwise loss involved in AUC maximization. We overcome\nthis obstacle by reformulating the U-statistics objective function as an\nempirical risk minimization (ERM), from which a stochastic hard thresholding\nalgorithm (\\texttt{SHT-AUC}) is developed. To our best knowledge, this is the\nfirst attempt to provide stochastic hard thresholding algorithms for AUC\nmaximization with a per-iteration cost $\\O(b d)$ where $d$ and $b$ are the\ndimension of the data and the minibatch size, respectively. We show that the\nproposed algorithm enjoys the linear convergence rate up to a tolerance error.\nIn particular, we show, if the data is generated from the Gaussian\ndistribution, then its convergence becomes slower as the data gets more\nimbalanced. We conduct extensive experiments to show the efficiency and\neffectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:49:29 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Yang", "Zhenhuan", ""], ["Zhou", "Baojian", ""], ["Lei", "Yunwen", ""], ["Ying", "Yiming", ""]]}, {"id": "2011.02402", "submitter": "Youssef Mroueh", "authors": "Youssef Mroueh, Truyen Nguyen", "title": "On the Convergence of Gradient Descent in GANs: MMD GAN As a Gradient\n  Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the maximum mean discrepancy ($\\mathrm{MMD}$) GAN problem and\npropose a parametric kernelized gradient flow that mimics the min-max game in\ngradient regularized $\\mathrm{MMD}$ GAN. We show that this flow provides a\ndescent direction minimizing the $\\mathrm{MMD}$ on a statistical manifold of\nprobability distributions. We then derive an explicit condition which ensures\nthat gradient descent on the parameter space of the generator in gradient\nregularized $\\mathrm{MMD}$ GAN is globally convergent to the target\ndistribution. Under this condition, we give non asymptotic convergence results\nof gradient descent in MMD GAN. Another contribution of this paper is the\nintroduction of a dynamic formulation of a regularization of $\\mathrm{MMD}$ and\ndemonstrating that the parametric kernelized descent for $\\mathrm{MMD}$ is the\ngradient flow of this functional with respect to the new Riemannian structure.\nOur obtained theoretical result allows ones to treat gradient flows for quite\ngeneral functionals and thus has potential applications to other types of\nvariational inferences on a statistical manifold beyond GANs. Finally,\nnumerical experiments suggest that our parametric kernelized gradient flow\nstabilizes GAN training and guarantees convergence.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:55:00 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Mroueh", "Youssef", ""], ["Nguyen", "Truyen", ""]]}, {"id": "2011.02408", "submitter": "Manuel Nonnenmacher", "authors": "Manuel Nonnenmacher, David Reeb, Ingo Steinwart", "title": "Which Minimizer Does My Neural Network Converge To?", "comments": "27 pages incl. appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss surface of an overparameterized neural network (NN) possesses many\nglobal minima of zero training error. We explain how common variants of the\nstandard NN training procedure change the minimizer obtained. First, we make\nexplicit how the size of the initialization of a strongly overparameterized NN\naffects the minimizer and can deteriorate its final test performance. We\npropose a strategy to limit this effect. Then, we demonstrate that for adaptive\noptimization such as AdaGrad, the obtained minimizer generally differs from the\ngradient descent (GD) minimizer. This adaptive minimizer is changed further by\nstochastic mini-batch training, even though in the non-adaptive case GD and\nstochastic GD result in essentially the same minimizer. Lastly, we explain that\nthese effects remain relevant for less overparameterized NNs. While\noverparameterization has its benefits, our work highlights that it induces\nsources of error absent from underparameterized models, some of which can be\nchallenging to control.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:04:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Nonnenmacher", "Manuel", ""], ["Reeb", "David", ""], ["Steinwart", "Ingo", ""]]}, {"id": "2011.02436", "submitter": "Ramesh Ragala", "authors": "Ramesh Ragala and Bharadwaja kumar", "title": "Rank Based Pseudoinverse Computation in Extreme Learning Machine for\n  Large Datasets", "comments": null, "journal-ref": "International Journal of Innovative Technology and Exploring\n  Engineering 10(2019) 1341-1346", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme Learning Machine (ELM) is an efficient and effective\nleast-square-based learning algorithm for classification, regression problems\nbased on single hidden layer feed-forward neural network (SLFN). It has been\nshown in the literature that it has faster convergence and good generalization\nability for moderate datasets. But, there is great deal of challenge involved\nin computing the pseudoinverse when there are large numbers of hidden nodes or\nfor large number of instances to train complex pattern recognition problems. To\naddress this problem, a few approaches such as EM-ELM, DF-ELM have been\nproposed in the literature. In this paper, a new rank-based matrix\ndecomposition of the hidden layer matrix is introduced to have the optimal\ntraining time and reduce the computational complexity for a large number of\nhidden nodes in the hidden layer. The results show that it has constant\ntraining time which is closer towards the minimal training time and very far\nfrom worst-case training time of the DF-ELM algorithm that has been shown\nefficient in the recent literature.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:34:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ragala", "Ramesh", ""], ["kumar", "Bharadwaja", ""]]}, {"id": "2011.02466", "submitter": "Zhao Song", "authors": "Josh Alman, Timothy Chu, Aaron Schild, Zhao Song", "title": "Algorithms and Hardness for Linear Algebra on Geometric Graphs", "comments": "FOCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  For a function $\\mathsf{K} : \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\to\n\\mathbb{R}_{\\geq 0}$, and a set $P = \\{ x_1, \\ldots, x_n\\} \\subset\n\\mathbb{R}^d$ of $n$ points, the $\\mathsf{K}$ graph $G_P$ of $P$ is the\ncomplete graph on $n$ nodes where the weight between nodes $i$ and $j$ is given\nby $\\mathsf{K}(x_i, x_j)$. In this paper, we initiate the study of when\nefficient spectral graph theory is possible on these graphs. We investigate\nwhether or not it is possible to solve the following problems in $n^{1+o(1)}$\ntime for a $\\mathsf{K}$-graph $G_P$ when $d < n^{o(1)}$:\n  $\\bullet$ Multiply a given vector by the adjacency matrix or Laplacian matrix\nof $G_P$\n  $\\bullet$ Find a spectral sparsifier of $G_P$\n  $\\bullet$ Solve a Laplacian system in $G_P$'s Laplacian matrix\n  For each of these problems, we consider all functions of the form\n$\\mathsf{K}(u,v) = f(\\|u-v\\|_2^2)$ for a function $f:\\mathbb{R} \\rightarrow\n\\mathbb{R}$. We provide algorithms and comparable hardness results for many\nsuch $\\mathsf{K}$, including the Gaussian kernel, Neural tangent kernels, and\nmore. For example, in dimension $d = \\Omega(\\log n)$, we show that there is a\nparameter associated with the function $f$ for which low parameter values imply\n$n^{1+o(1)}$ time algorithms for all three of these problems and high parameter\nvalues imply the nonexistence of subquadratic time algorithms assuming Strong\nExponential Time Hypothesis ($\\mathsf{SETH}$), given natural assumptions on\n$f$.\n  As part of our results, we also show that the exponential dependence on the\ndimension $d$ in the celebrated fast multipole method of Greengard and Rokhlin\ncannot be improved, assuming $\\mathsf{SETH}$, for a broad class of functions\n$f$. To the best of our knowledge, this is the first formal limitation proven\nabout fast multipole methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 18:35:02 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Alman", "Josh", ""], ["Chu", "Timothy", ""], ["Schild", "Aaron", ""], ["Song", "Zhao", ""]]}, {"id": "2011.02521", "submitter": "Yongxin Chen", "authors": "Qinsheng Zhang, Rahul Singh, Yongxin Chen", "title": "Filtering for Aggregate Hidden Markov Models with Continuous\n  Observations", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.SY eess.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of filtering problems for large populations where each\nindividual is modeled by the same hidden Markov model (HMM). In this paper, we\nfocus on aggregate inference problems in HMMs with discrete state space and\ncontinuous observation space. The continuous observations are aggregated in a\nway such that the individuals are indistinguishable from measurements. We\npropose an aggregate inference algorithm called continuous observation\ncollective forward-backward algorithm. It extends the recently proposed\ncollective forward-backward algorithm for aggregate inference in HMMs with\ndiscrete observations to the case of continuous observations. The efficacy of\nthis algorithm is illustrated through several numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 20:05:36 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 04:35:35 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Zhang", "Qinsheng", ""], ["Singh", "Rahul", ""], ["Chen", "Yongxin", ""]]}, {"id": "2011.02522", "submitter": "Anuran Makur", "authors": "Ali Jadbabaie and Anuran Makur and Devavrat Shah", "title": "Gradient-Based Empirical Risk Minimization using Local Polynomial\n  Regression", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of empirical risk minimization (ERM)\nof smooth, strongly convex loss functions using iterative gradient-based\nmethods. A major goal of this literature has been to compare different\nalgorithms, such as gradient descent (GD) or stochastic gradient descent (SGD),\nby analyzing their rates of convergence to $\\epsilon$-approximate solutions.\nFor example, the oracle complexity of GD is $O(n\\log(\\epsilon^{-1}))$, where\n$n$ is the number of training samples. When $n$ is large, this can be expensive\nin practice, and SGD is preferred due to its oracle complexity of\n$O(\\epsilon^{-1})$. Such standard analyses only utilize the smoothness of the\nloss function in the parameter being optimized. In contrast, we demonstrate\nthat when the loss function is smooth in the data, we can learn the oracle at\nevery iteration and beat the oracle complexities of both GD and SGD in\nimportant regimes. Specifically, at every iteration, our proposed algorithm\nperforms local polynomial regression to learn the gradient of the loss\nfunction, and then estimates the true gradient of the ERM objective function.\nWe establish that the oracle complexity of our algorithm scales like\n$\\tilde{O}((p \\epsilon^{-1})^{d/(2\\eta)})$ (neglecting sub-dominant factors),\nwhere $d$ and $p$ are the data and parameter space dimensions, respectively,\nand the gradient of the loss function belongs to a $\\eta$-H\\\"{o}lder class with\nrespect to the data. Our proof extends the analysis of local polynomial\nregression in non-parametric statistics to provide interpolation guarantees in\nmultivariate settings, and also exploits tools from the inexact GD literature.\nUnlike GD and SGD, the complexity of our method depends on $d$ and $p$.\nHowever, when $d$ is small and the loss function exhibits modest smoothness in\nthe data, our algorithm beats GD and SGD in oracle complexity for a very broad\nrange of $p$ and $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 20:10:31 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Jadbabaie", "Ali", ""], ["Makur", "Anuran", ""], ["Shah", "Devavrat", ""]]}, {"id": "2011.02538", "submitter": "Jingfeng Wu", "authors": "Jingfeng Wu, Difan Zou, Vladimir Braverman, Quanquan Gu", "title": "Direction Matters: On the Implicit Bias of Stochastic Gradient Descent\n  with Moderate Learning Rate", "comments": "ICLR 2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the algorithmic bias of \\emph{stochastic gradient descent}\n(SGD) is one of the key challenges in modern machine learning and deep learning\ntheory. Most of the existing works, however, focus on \\emph{very small or even\ninfinitesimal} learning rate regime, and fail to cover practical scenarios\nwhere the learning rate is \\emph{moderate and annealing}. In this paper, we\nmake an initial attempt to characterize the particular regularization effect of\nSGD in the moderate learning rate regime by studying its behavior for\noptimizing an overparameterized linear regression problem. In this case, SGD\nand GD are known to converge to the unique minimum-norm solution; however, with\nthe moderate and annealing learning rate, we show that they exhibit different\n\\emph{directional bias}: SGD converges along the large eigenvalue directions of\nthe data matrix, while GD goes after the small eigenvalue directions.\nFurthermore, we show that such directional bias does matter when early stopping\nis adopted, where the SGD output is nearly optimal but the GD output is\nsuboptimal. Finally, our theory explains several folk arts in practice used for\nSGD hyperparameter tuning, such as (1) linearly scaling the initial learning\nrate with batch size; and (2) overrunning SGD with high learning rate even when\nthe loss stops decreasing.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:07:52 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 17:24:24 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wu", "Jingfeng", ""], ["Zou", "Difan", ""], ["Braverman", "Vladimir", ""], ["Gu", "Quanquan", ""]]}, {"id": "2011.02614", "submitter": "Tanmay Gangwani", "authors": "Tanmay Gangwani, Jian Peng, Yuan Zhou", "title": "Harnessing Distribution Ratio Estimators for Learning Agents with\n  Quality and Diversity", "comments": "CoRL 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-Diversity (QD) is a concept from Neuroevolution with some intriguing\napplications to Reinforcement Learning. It facilitates learning a population of\nagents where each member is optimized to simultaneously accumulate high\ntask-returns and exhibit behavioral diversity compared to other members. In\nthis paper, we build on a recent kernel-based method for training a QD policy\nensemble with Stein variational gradient descent. With kernels based on\n$f$-divergence between the stationary distributions of policies, we convert the\nproblem to that of efficient estimation of the ratio of these stationary\ndistributions. We then study various distribution ratio estimators used\npreviously for off-policy evaluation and imitation and re-purpose them to\ncompute the gradients for policies in an ensemble such that the resultant\npopulation is diverse and of high-quality.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 02:02:44 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gangwani", "Tanmay", ""], ["Peng", "Jian", ""], ["Zhou", "Yuan", ""]]}, {"id": "2011.02672", "submitter": "Shushu Zhang", "authors": "Shushu Zhang, Vivak Patel", "title": "Stochastic Approximation for High-frequency Observations in Data\n  Assimilation", "comments": "21 pages, 5 figures, submitted to SIAM/ASA Journal on Uncertainty\n  Quantification (JUQ)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing penetration of high-frequency sensors across a number of\nbiological and physical systems, the abundance of the resulting observations\noffers opportunities for higher statistical accuracy of down-stream estimates,\nbut their frequency results in a plethora of computational problems in data\nassimilation tasks. The high-frequency of these observations has been\ntraditionally dealt with by using data modification strategies such as\naccumulation, averaging, and sampling. However, these data modification\nstrategies will reduce the quality of the estimates, which may be untenable for\nmany systems. Therefore, to ensure high-quality estimates, we adapt stochastic\napproximation methods to address the unique challenges of high-frequency\nobservations in data assimilation. As a result, we are able to produce\nestimates that leverage all of the observations in a manner that avoids the\naforementioned computational problems and preserves the statistical accuracy of\nthe estimates.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 06:02:27 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Zhang", "Shushu", ""], ["Patel", "Vivak", ""]]}, {"id": "2011.02683", "submitter": "Jason Klusowski M", "authors": "Jason M. Klusowski and Peter M. Tian", "title": "Nonparametric Variable Screening with Optimal Decision Stumps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees and their ensembles are endowed with a rich set of diagnostic\ntools for ranking and screening variables in a predictive model. Despite the\nwidespread use of tree based variable importance measures, pinning down their\ntheoretical properties has been challenging and therefore largely unexplored.\nTo address this gap between theory and practice, we derive finite sample\nperformance guarantees for variable selection in nonparametric models using a\nsingle-level CART decision tree (a decision stump). Under standard operating\nassumptions in variable screening literature, we find that the marginal signal\nstrength of each variable and ambient dimensionality can be considerably weaker\nand higher, respectively, than state-of-the-art nonparametric variable\nselection methods. Furthermore, unlike previous marginal screening methods that\nattempt to directly estimate each marginal projection via a truncated basis\nexpansion, the fitted model used here is a simple, parsimonious decision stump,\nthereby eliminating the need for tuning the number of basis terms. Thus,\nsurprisingly, even though decision stumps are highly inaccurate for estimation\npurposes, they can still be used to perform consistent model selection.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 06:56:12 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 00:38:18 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Klusowski", "Jason M.", ""], ["Tian", "Peter M.", ""]]}, {"id": "2011.02696", "submitter": "Aurick Zhou", "authors": "Aurick Zhou, Sergey Levine", "title": "Amortized Conditional Normalized Maximum Likelihood: Reliable Out of\n  Distribution Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks provide good performance for a range of\nchallenging tasks, calibration and uncertainty estimation remain major\nchallenges, especially under distribution shift. In this paper, we propose the\namortized conditional normalized maximum likelihood (ACNML) method as a\nscalable general-purpose approach for uncertainty estimation, calibration, and\nout-of-distribution robustness with deep networks. Our algorithm builds on the\nconditional normalized maximum likelihood (CNML) coding scheme, which has\nminimax optimal properties according to the minimum description length\nprinciple, but is computationally intractable to evaluate exactly for all but\nthe simplest of model classes. We propose to use approximate Bayesian inference\ntechnqiues to produce a tractable approximation to the CNML distribution. Our\napproach can be combined with any approximate inference algorithm that provides\ntractable posterior densities over model parameters. We demonstrate that ACNML\ncompares favorably to a number of prior techniques for uncertainty estimation\nin terms of calibration on out-of-distribution inputs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 08:04:34 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 21:03:05 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Zhou", "Aurick", ""], ["Levine", "Sergey", ""]]}, {"id": "2011.02761", "submitter": "Kirankumar Shiragur", "authors": "Nima Anari, Moses Charikar, Kirankumar Shiragur, Aaron Sidford", "title": "Instance Based Approximations to Profile Maximum Likelihood", "comments": "Accepted at Thirty-fourth Conference on Neural Information Processing\n  Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a new efficient algorithm for approximately\ncomputing the profile maximum likelihood (PML) distribution, a prominent\nquantity in symmetric property estimation. We provide an algorithm which\nmatches the previous best known efficient algorithms for computing approximate\nPML distributions and improves when the number of distinct observed frequencies\nin the given instance is small. We achieve this result by exploiting new\nsparsity structure in approximate PML distributions and providing a new matrix\nrounding algorithm, of independent interest. Leveraging this result, we obtain\nthe first provable computationally efficient implementation of PseudoPML, a\ngeneral framework for estimating a broad class of symmetric properties.\nAdditionally, we obtain efficient PML-based estimators for distributions with\nsmall profile entropy, a natural instance-based complexity measure. Further, we\nprovide a simpler and more practical PseudoPML implementation that matches the\nbest-known theoretical guarantees of such an estimator and evaluate this method\nempirically.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 11:17:19 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Anari", "Nima", ""], ["Charikar", "Moses", ""], ["Shiragur", "Kirankumar", ""], ["Sidford", "Aaron", ""]]}, {"id": "2011.02764", "submitter": "Manon Romain", "authors": "Manon Romain and Alexandre d'Aspremont", "title": "A Bregman Method for Structure Learning on Sparse Directed Acyclic\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bregman proximal gradient method for structure learning on\nlinear structural causal models. While the problem is non-convex, has high\ncurvature and is in fact NP-hard, Bregman gradient methods allow us to\nneutralize at least part of the impact of curvature by measuring smoothness\nagainst a highly nonlinear kernel. This allows the method to make longer steps\nand significantly improves convergence. Each iteration requires solving a\nBregman proximal step which is convex and efficiently solvable for our\nparticular choice of kernel. We test our method on various synthetic and real\ndata sets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 11:37:44 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Romain", "Manon", ""], ["d'Aspremont", "Alexandre", ""]]}, {"id": "2011.02803", "submitter": "Ting Chen", "authors": "Ting Chen and Calvin Luo and Lala Li", "title": "Intriguing Properties of Contrastive Losses", "comments": "Technical report. Code at\n  https://github.com/google-research/simclr/tree/master/colabs/intriguing_properties", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive loss and its variants have become very popular recently for\nlearning visual representations without supervision. In this work, we study\nthree intriguing properties of contrastive learning. We first generalize the\nstandard contrastive loss to a broader family of losses, and we find that\nvarious instantiations of the generalized loss perform similarly under the\npresence of a multi-layer non-linear projection head. We then study if\ninstance-based contrastive learning (such as in SimCLR, MoCo, BYOL, and so on,\nwhich are based on global image representation) can learn well on images with\nmultiple objects present. We find that meaningful hierarchical local features\ncan be learned despite the fact that these objectives operate on global\ninstance-level features.\n  Finally, we study an intriguing phenomenon of feature suppression among\ncompeting features shared across augmented views, such as \"color distribution\"\nvs \"object class\". We construct datasets with explicit and controllable\ncompeting features, and show that, for contrastive learning, a few bits of\neasy-to-learn shared features can suppress, and even fully prevent, the\nlearning of other sets of competing features. In scenarios where there are\nmultiple objects in an image, the dominant object would suppress the learning\nof smaller objects. Existing contrastive learning methods critically rely on\ndata augmentation to favor certain sets of features over others, and face\npotential limitation for scenarios where existing augmentations cannot fully\naddress the feature suppression. This poses open challenges to existing\ncontrastive learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:19:48 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 01:17:22 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Ting", ""], ["Luo", "Calvin", ""], ["Li", "Lala", ""]]}, {"id": "2011.02829", "submitter": "Felipe Kenji Nakano", "authors": "Felipe Kenji Nakano, Konstantinos Pliakos, Celine Vens", "title": "Deep tree-ensembles for multi-output prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have expanded the state-of-art in various\nscientific fields and provided solutions to long standing problems across\nmultiple application domains. Nevertheless, they also suffer from weaknesses\nsince their optimal performance depends on massive amounts of training data and\nthe tuning of an extended number of parameters. As a countermeasure, some\ndeep-forest methods have been recently proposed, as efficient and low-scale\nsolutions. Despite that, these approaches simply employ label classification\nprobabilities as induced features and primarily focus on traditional\nclassification and regression tasks, leaving multi-output prediction\nunder-explored. Moreover, recent work has demonstrated that tree-embeddings are\nhighly representative, especially in structured output prediction. In this\ndirection, we propose a novel deep tree-ensemble (DTE) model, where every layer\nenriches the original feature set with a representation learning component\nbased on tree-embeddings. In this paper, we specifically focus on two\nstructured output prediction tasks, namely multi-label classification and\nmulti-target regression. We conducted experiments using multiple benchmark\ndatasets and the obtained results confirm that our method provides superior\nresults to state-of-the-art methods in both tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 16:25:54 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Nakano", "Felipe Kenji", ""], ["Pliakos", "Konstantinos", ""], ["Vens", "Celine", ""]]}, {"id": "2011.02832", "submitter": "Stella Biderman", "authors": "Stella Biderman and Walter J. Scheirer", "title": "Pitfalls in Machine Learning Research: Reexamining the Development Cycle", "comments": "NeurIPS \"I Can't Believe It's Not Better!\" Workshop", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has the potential to fuel further advances in data science,\nbut it is greatly hindered by an ad hoc design process, poor data hygiene, and\na lack of statistical rigor in model evaluation. Recently, these issues have\nbegun to attract more attention as they have caused public and embarrassing\nissues in research and development. Drawing from our experience as machine\nlearning researchers, we follow the machine learning process from algorithm\ndesign to data collection to model evaluation, drawing attention to common\npitfalls and providing practical recommendations for improvements. At each\nstep, case studies are introduced to highlight how these pitfalls occur in\npractice, and where things could be improved.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:58:18 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Biderman", "Stella", ""], ["Scheirer", "Walter J.", ""]]}, {"id": "2011.02952", "submitter": "Sebastian Buschj\\\"ager", "authors": "Sebastian Buschj\\\"ager, Lukas Pfahler, Katharina Morik", "title": "Generalized Negative Correlation Learning for Deep Ensembling", "comments": "12 (+8) pages, 1(+1) figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble algorithms offer state of the art performance in many machine\nlearning applications. A common explanation for their excellent performance is\ndue to the bias-variance decomposition of the mean squared error which shows\nthat the algorithm's error can be decomposed into its bias and variance. Both\nquantities are often opposed to each other and ensembles offer an effective way\nto manage them as they reduce the variance through a diverse set of base\nlearners while keeping the bias low at the same time. Even though there have\nbeen numerous works on decomposing other loss functions, the exact mathematical\nconnection is rarely exploited explicitly for ensembling, but merely used as a\nguiding principle. In this paper, we formulate a generalized bias-variance\ndecomposition for arbitrary twice differentiable loss functions and study it in\nthe context of Deep Learning. We use this decomposition to derive a Generalized\nNegative Correlation Learning (GNCL) algorithm which offers explicit control\nover the ensemble's diversity and smoothly interpolates between the two\nextremes of independent training and the joint training of the ensemble. We\nshow how GNCL encapsulates many previous works and discuss under which\ncircumstances training of an ensemble of Neural Networks might fail and what\nensembling method should be favored depending on the choice of the individual\nnetworks. We make our code publicly available under\nhttps://github.com/sbuschjaeger/gncl\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:29:22 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 08:19:49 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Buschj\u00e4ger", "Sebastian", ""], ["Pfahler", "Lukas", ""], ["Morik", "Katharina", ""]]}, {"id": "2011.02966", "submitter": "Marco Cerezo Ph.D", "authors": "Arthur Pesah, M. Cerezo, Samson Wang, Tyler Volkoff, Andrew T.\n  Sornborger, Patrick J. Coles", "title": "Absence of Barren Plateaus in Quantum Convolutional Neural Networks", "comments": "9 + 20 pages, 7 + 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-29031", "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum neural networks (QNNs) have generated excitement around the\npossibility of efficiently analyzing quantum data. But this excitement has been\ntempered by the existence of exponentially vanishing gradients, known as barren\nplateau landscapes, for many QNN architectures. Recently, Quantum Convolutional\nNeural Networks (QCNNs) have been proposed, involving a sequence of\nconvolutional and pooling layers that reduce the number of qubits while\npreserving information about relevant data features. In this work we rigorously\nanalyze the gradient scaling for the parameters in the QCNN architecture. We\nfind that the variance of the gradient vanishes no faster than polynomially,\nimplying that QCNNs do not exhibit barren plateaus. This provides an analytical\nguarantee for the trainability of randomly initialized QCNNs, which singles out\nQCNNs as being trainable unlike many other QNN architectures. To derive our\nresults we introduce a novel graph-based method to analyze expectation values\nover Haar-distributed unitaries, which will likely be useful in other contexts.\nFinally, we perform numerical simulations to verify our analytical results.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:46:13 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pesah", "Arthur", ""], ["Cerezo", "M.", ""], ["Wang", "Samson", ""], ["Volkoff", "Tyler", ""], ["Sornborger", "Andrew T.", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2011.03030", "submitter": "Nathan Kallus", "authors": "Yichun Hu, Nathan Kallus, Xiaojie Mao", "title": "Fast Rates for Contextual Linear Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating side observations in decision making can reduce uncertainty and\nboost performance, but it also requires we tackle a potentially complex\npredictive relationship. While one may use off-the-shelf machine learning\nmethods to separately learn a predictive model and plug it in, a variety of\nrecent methods instead integrate estimation and optimization by fitting the\nmodel to directly optimize downstream decision performance. Surprisingly, in\nthe case of contextual linear optimization, we show that the naive plug-in\napproach actually achieves regret convergence rates that are significantly\nfaster than methods that directly optimize downstream decision performance. We\nshow this by leveraging the fact that specific problem instances do not have\narbitrarily bad near-dual-degeneracy. While there are other pros and cons to\nconsider as we discuss and illustrate numerically, our results highlight a\nnuanced landscape for the enterprise to integrate estimation and optimization.\nOur results are overall positive for practice: predictive models are easy and\nfast to train using existing tools, simple to interpret, and, as we show, lead\nto decisions that perform very well.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:43:59 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:53:47 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hu", "Yichun", ""], ["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""]]}, {"id": "2011.03074", "submitter": "Stefan Richter", "authors": "Moritz Haas, Stefan Richter", "title": "Statistical analysis of Wasserstein GANs with applications to time\n  series forecasting", "comments": "47 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide statistical theory for conditional and unconditional Wasserstein\ngenerative adversarial networks (WGANs) in the framework of dependent\nobservations. We prove upper bounds for the excess Bayes risk of the WGAN\nestimators with respect to a modified Wasserstein-type distance. Furthermore,\nwe formalize and derive statements on the weak convergence of the estimators\nand use them to develop confidence intervals for new observations. The theory\nis applied to the special case of high-dimensional time series forecasting. We\nanalyze the behavior of the estimators in simulations based on synthetic data\nand investigate a real data example with temperature data. The dependency of\nthe data is quantified with absolutely regular beta-mixing coefficients.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 19:45:59 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Haas", "Moritz", ""], ["Richter", "Stefan", ""]]}, {"id": "2011.03089", "submitter": "Razvan Bunescu", "authors": "Kaiyu Shen, Razvan Bunescu and Sarah E. Wyatt", "title": "Mining Functionally Related Genes with Semi-Supervised Learning", "comments": "Submitted for publication in 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of biological processes can greatly benefit from tools that\nautomatically predict gene functions or directly cluster genes based on shared\nfunctionality. Existing data mining methods predict protein functionality by\nexploiting data obtained from high-throughput experiments or meta-scale\ninformation from public databases. Most existing prediction tools are targeted\nat predicting protein functions that are described in the gene ontology (GO).\nHowever, in many cases biologists wish to discover functionally related genes\nfor which GO terms are inadequate. In this paper, we introduce a rich set of\nfeatures and use them in conjunction with semisupervised learning approaches in\norder to expand an initial set of seed genes to a larger cluster of\nfunctionally related genes. Among all the semi-supervised methods that were\nevaluated, the framework of learning with positive and unlabeled examples (LPU)\nis shown to be especially appropriate for mining functionally related genes.\nWhen evaluated on experimentally validated benchmark data, the LPU approaches1\nsignificantly outperform a standard supervised learning algorithm as well as an\nestablished state-of-the-art method. Given an initial set of seed genes, our\nbest performing approach could be used to mine functionally related genes in a\nwide range of organisms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 20:34:09 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Shen", "Kaiyu", ""], ["Bunescu", "Razvan", ""], ["Wyatt", "Sarah E.", ""]]}, {"id": "2011.03151", "submitter": "Lindon Roberts", "authors": "Matthias J. Ehrhardt, Lindon Roberts", "title": "Efficient Hyperparameter Tuning with Dynamic Accuracy Derivative-Free\n  Optimization", "comments": "Accepted to the 12th OPT Workshop on Optimization for Machine\n  Learning at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning solutions are framed as optimization problems which\nrely on good hyperparameters. Algorithms for tuning these hyperparameters\nusually assume access to exact solutions to the underlying learning problem,\nwhich is typically not practical. Here, we apply a recent dynamic accuracy\nderivative-free optimization method to hyperparameter tuning, which allows\ninexact evaluations of the learning problem while retaining convergence\nguarantees. We test the method on the problem of learning elastic net weights\nfor a logistic classifier, and demonstrate its robustness and efficiency\ncompared to a fixed accuracy approach. This demonstrates a promising approach\nfor hyperparameter tuning, with both convergence guarantees and practical\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 00:59:51 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Ehrhardt", "Matthias J.", ""], ["Roberts", "Lindon", ""]]}, {"id": "2011.03172", "submitter": "Salman Jahani", "authors": "Salman Jahani, Shiyu Zhou, Dharmaraj Veeramani and Jeff Schmidt", "title": "Multi-output Gaussian Process Modulated Poisson Processes for Event\n  Prediction", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of events such as part replacement and failure events plays a\ncritical role in reliability engineering. Event stream data are commonly\nobserved in manufacturing and teleservice systems. Designing predictive models\nfor individual units based on such event streams is challenging and an\nunder-explored problem. In this work, we propose a non-parametric prognostic\nframework for individualized event prediction based on the inhomogeneous\nPoisson processes with a multivariate Gaussian convolution process (MGCP) prior\non the intensity functions. The MGCP prior on the intensity functions of the\ninhomogeneous Poisson processes maps data from similar historical units to the\ncurrent unit under study which facilitates sharing of information and allows\nfor analysis of flexible event patterns. To facilitate inference, we derive a\nvariational inference scheme for learning and estimation of parameters in the\nresulting MGCP modulated Poisson process model. Experimental results are shown\non both synthetic data as well as real-world data for fleet based event\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:19:08 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Jahani", "Salman", ""], ["Zhou", "Shiyu", ""], ["Veeramani", "Dharmaraj", ""], ["Schmidt", "Jeff", ""]]}, {"id": "2011.03173", "submitter": "Subha Maity", "authors": "Subha Maity, Debarghya Mukherjee, Mikhail Yurochkin and Yuekai Sun", "title": "There is no trade-off: enforcing fairness can improve accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main barriers to the broader adoption of algorithmic fairness in\nmachine learning is the trade-off between fairness and performance of ML\nmodels: many practitioners are unwilling to sacrifice the performance of their\nML model for fairness. In this paper, we show that this trade-off may not be\nnecessary. If the algorithmic biases in an ML model are due to sampling biases\nin the training data, then enforcing algorithmic fairness may improve the\nperformance of the ML model on unbiased test data. We study conditions under\nwhich enforcing algorithmic fairness helps practitioners learn the Bayes\ndecision rule for (unbiased) test data from biased training data. We also\ndemonstrate the practical implications of our theoretical results in real-world\nML tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:22:52 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Maity", "Subha", ""], ["Mukherjee", "Debarghya", ""], ["Yurochkin", "Mikhail", ""], ["Sun", "Yuekai", ""]]}, {"id": "2011.03176", "submitter": "Krishnakumar Balasubramanian", "authors": "Ye He, Krishnakumar Balasubramanian, Murat A. Erdogdu", "title": "On the Ergodicity, Bias and Asymptotic Normality of Randomized Midpoint\n  Sampling Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The randomized midpoint method, proposed by [SL19], has emerged as an optimal\ndiscretization procedure for simulating the continuous time Langevin\ndiffusions. Focusing on the case of strong-convex and smooth potentials, in\nthis paper, we analyze several probabilistic properties of the randomized\nmidpoint discretization method for both overdamped and underdamped Langevin\ndiffusions. We first characterize the stationary distribution of the discrete\nchain obtained with constant step-size discretization and show that it is\nbiased away from the target distribution. Notably, the step-size needs to go to\nzero to obtain asymptotic unbiasedness. Next, we establish the asymptotic\nnormality for numerical integration using the randomized midpoint method and\nhighlight the relative advantages and disadvantages over other discretizations.\nOur results collectively provide several insights into the behavior of the\nrandomized midpoint discretization method, including obtaining confidence\nintervals for numerical integrations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:39:23 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["He", "Ye", ""], ["Balasubramanian", "Krishnakumar", ""], ["Erdogdu", "Murat A.", ""]]}, {"id": "2011.03178", "submitter": "Chaoqi Wang", "authors": "Chaoqi Wang, Shengyang Sun, Roger Grosse", "title": "Beyond Marginal Uncertainty: How Accurately can Bayesian Regression\n  Models Estimate Posterior Predictive Correlations?", "comments": "AISTATS 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While uncertainty estimation is a well-studied topic in deep learning, most\nsuch work focuses on marginal uncertainty estimates, i.e. the predictive mean\nand variance at individual input locations. But it is often more useful to\nestimate predictive correlations between the function values at different input\nlocations. In this paper, we consider the problem of benchmarking how\naccurately Bayesian models can estimate predictive correlations. We first\nconsider a downstream task which depends on posterior predictive correlations:\ntransductive active learning (TAL). We find that TAL makes better use of\nmodels' uncertainty estimates than ordinary active learning, and recommend this\nas a benchmark for evaluating Bayesian models. Since TAL is too expensive and\nindirect to guide development of algorithms, we introduce two metrics which\nmore directly evaluate the predictive correlations and which can be computed\nefficiently: meta-correlations (i.e. the correlations between the models\ncorrelation estimates and the true values), and cross-normalized likelihoods\n(XLL). We validate these metrics by demonstrating their consistency with TAL\nperformance and obtain insights about the relative performance of current\nBayesian neural net and Gaussian process models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:48:59 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 03:05:37 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wang", "Chaoqi", ""], ["Sun", "Shengyang", ""], ["Grosse", "Roger", ""]]}, {"id": "2011.03231", "submitter": "Alex Boyd", "authors": "Alex Boyd, Robert Bamler, Stephan Mandt, and Padhraic Smyth", "title": "User-Dependent Neural Sequence Models for Continuous-Time Event Data", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time event data are common in applications such as individual\nbehavior data, financial transactions, and medical health records. Modeling\nsuch data can be very challenging, in particular for applications with many\ndifferent types of events, since it requires a model to predict the event types\nas well as the time of occurrence. Recurrent neural networks that parameterize\ntime-varying intensity functions are the current state-of-the-art for\npredictive modeling with such data. These models typically assume that all\nevent sequences come from the same data distribution. However, in many\napplications event sequences are generated by different sources, or users, and\ntheir characteristics can be very different. In this paper, we extend the broad\nclass of neural marked point process models to mixtures of latent embeddings,\nwhere each mixture component models the characteristic traits of a given user.\nOur approach relies on augmenting these models with a latent variable that\nencodes user characteristics, represented by a mixture model over user behavior\nthat is trained via amortized variational inference. We evaluate our methods on\nfour large real-world datasets and demonstrate systematic improvements from our\napproach over existing work for a variety of predictive metrics such as\nlog-likelihood, next event ranking, and source-of-sequence identification.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 08:32:57 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Boyd", "Alex", ""], ["Bamler", "Robert", ""], ["Mandt", "Stephan", ""], ["Smyth", "Padhraic", ""]]}, {"id": "2011.03243", "submitter": "Sourin Chakrabarti", "authors": "Bagesh Kumar, Ayush Sinha, Sourin Chakrabarti, Prof. O.P.Vyas", "title": "A fast learning algorithm for One-Class Slab Support Vector Machines", "comments": "This version of the manuscript has been updated and is being reviewed\n  by https://www.journals.elsevier.com/knowledge-based-systems", "journal-ref": "Knowledge-Based Systems, Volume 228, 27 September 2021, 107267", "doi": "10.1016/j.knosys.2021.107267", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One Class Slab Support Vector Machines (OCSSVM) have turned out to be better\nin terms of accuracy in certain classes of classification problems than the\ntraditional SVMs and One Class SVMs or even other One class classifiers. This\npaper proposes fast training method for One Class Slab SVMs using an updated\nSequential Minimal Optimization (SMO) which divides the multi variable\noptimization problem to smaller sub problems of size two that can then be\nsolved analytically. The results indicate that this training method scales\nbetter to large sets of training data than other Quadratic Programming (QP)\nsolvers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 09:16:39 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 15:08:31 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kumar", "Bagesh", ""], ["Sinha", "Ayush", ""], ["Chakrabarti", "Sourin", ""], ["Vyas", "Prof. O. P.", ""]]}, {"id": "2011.03274", "submitter": "Dennis Ulmer", "authors": "Dennis Ulmer, Lotta Meijerink and Giovanni Cin\\`a", "title": "Trust Issues: Uncertainty Estimation Does Not Enable Reliable OOD\n  Detection On Medical Tabular Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When deploying machine learning models in high-stakes real-world environments\nsuch as health care, it is crucial to accurately assess the uncertainty\nconcerning a model's prediction on abnormal inputs. However, there is a\nscarcity of literature analyzing this problem on medical data, especially on\nmixed-type tabular data such as Electronic Health Records. We close this gap by\npresenting a series of tests including a large variety of contemporary\nuncertainty estimation techniques, in order to determine whether they are able\nto identify out-of-distribution (OOD) patients. In contrast to previous work,\nwe design tests on realistic and clinically relevant OOD groups, and run\nexperiments on real-world medical data. We find that almost all techniques fail\nto achieve convincing results, partly disagreeing with earlier findings.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 10:41:39 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Ulmer", "Dennis", ""], ["Meijerink", "Lotta", ""], ["Cin\u00e0", "Giovanni", ""]]}, {"id": "2011.03320", "submitter": "Chieh T Wu", "authors": "Chieh Wu, Aria Masoomi, Arthur Gretton, Jennifer Dy", "title": "Kernel Dependence Network", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.08539", "journal-ref": "NeurIPS2020 Workshop (Beyond Backprop)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a greedy strategy to spectrally train a deep network for\nmulti-class classification. Each layer is defined as a composition of linear\nweights with the feature map of a Gaussian kernel acting as the activation\nfunction. At each layer, the linear weights are learned by maximizing the\ndependence between the layer output and the labels using the Hilbert Schmidt\nIndependence Criterion (HSIC). By constraining the solution space on the\nStiefel Manifold, we demonstrate how our network construct (Kernel Dependence\nNetwork or KNet) can be solved spectrally while leveraging the eigenvalues to\nautomatically find the width and the depth of the network. We theoretically\nguarantee the existence of a solution for the global optimum while providing\ninsight into our network's ability to generalize.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 20:11:24 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 23:27:51 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wu", "Chieh", ""], ["Masoomi", "Aria", ""], ["Gretton", "Arthur", ""], ["Dy", "Jennifer", ""]]}, {"id": "2011.03321", "submitter": "Ben Adlam", "authors": "Ben Adlam and Jeffrey Pennington", "title": "Understanding Double Descent Requires a Fine-Grained Bias-Variance\n  Decomposition", "comments": "Published as a conference paper in the Proceedings of the\n  Thirty-fourth Conference on Neural Information Processing Systems; 54 pages;\n  5 figures. arXiv admin note: text overlap with arXiv:2008.06786", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical learning theory suggests that the optimal generalization\nperformance of a machine learning model should occur at an intermediate model\ncomplexity, with simpler models exhibiting high bias and more complex models\nexhibiting high variance of the predictive function. However, such a simple\ntrade-off does not adequately describe deep learning models that simultaneously\nattain low bias and variance in the heavily overparameterized regime. A primary\nobstacle in explaining this behavior is that deep learning algorithms typically\ninvolve multiple sources of randomness whose individual contributions are not\nvisible in the total variance. To enable fine-grained analysis, we describe an\ninterpretable, symmetric decomposition of the variance into terms associated\nwith the randomness from sampling, initialization, and the labels. Moreover, we\ncompute the high-dimensional asymptotic behavior of this decomposition for\nrandom feature kernel regression, and analyze the strikingly rich phenomenology\nthat arises. We find that the bias decreases monotonically with the network\nwidth, but the variance terms exhibit non-monotonic behavior and can diverge at\nthe interpolation boundary, even in the absence of label noise. The divergence\nis caused by the \\emph{interaction} between sampling and initialization and can\ntherefore be eliminated by marginalizing over samples (i.e. bagging) \\emph{or}\nover the initial parameters (i.e. ensemble learning).\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:04:02 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Adlam", "Ben", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "2011.03395", "submitter": "Alexander D'Amour", "authors": "Alexander D'Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak\n  Alipanahi, Alex Beutel, Christina Chen, Jonathan Deaton, Jacob Eisenstein,\n  Matthew D. Hoffman, Farhad Hormozdiari, Neil Houlsby, Shaobo Hou, Ghassen\n  Jerfel, Alan Karthikesalingam, Mario Lucic, Yian Ma, Cory McLean, Diana\n  Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan,\n  Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim Ramasamy, Rory\n  Sayres, Jessica Schrouff, Martin Seneviratne, Shannon Sequeira, Harini\n  Suresh, Victor Veitch, Max Vladymyrov, Xuezhi Wang, Kellie Webster, Steve\n  Yadlowsky, Taedong Yun, Xiaohua Zhai, D. Sculley", "title": "Underspecification Presents Challenges for Credibility in Modern Machine\n  Learning", "comments": "Updates: Updated statistical analysis in Section 6; Additional\n  citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML models often exhibit unexpectedly poor behavior when they are deployed in\nreal-world domains. We identify underspecification as a key reason for these\nfailures. An ML pipeline is underspecified when it can return many predictors\nwith equivalently strong held-out performance in the training domain.\nUnderspecification is common in modern ML pipelines, such as those based on\ndeep learning. Predictors returned by underspecified pipelines are often\ntreated as equivalent based on their training domain performance, but we show\nhere that such predictors can behave very differently in deployment domains.\nThis ambiguity can lead to instability and poor model behavior in practice, and\nis a distinct failure mode from previously identified issues arising from\nstructural mismatch between training and deployment domains. We show that this\nproblem appears in a wide variety of practical ML pipelines, using examples\nfrom computer vision, medical imaging, natural language processing, clinical\nrisk prediction based on electronic health records, and medical genomics. Our\nresults show the need to explicitly account for underspecification in modeling\npipelines that are intended for real-world deployment in any domain.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 14:53:13 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 19:16:02 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["D'Amour", "Alexander", ""], ["Heller", "Katherine", ""], ["Moldovan", "Dan", ""], ["Adlam", "Ben", ""], ["Alipanahi", "Babak", ""], ["Beutel", "Alex", ""], ["Chen", "Christina", ""], ["Deaton", "Jonathan", ""], ["Eisenstein", "Jacob", ""], ["Hoffman", "Matthew D.", ""], ["Hormozdiari", "Farhad", ""], ["Houlsby", "Neil", ""], ["Hou", "Shaobo", ""], ["Jerfel", "Ghassen", ""], ["Karthikesalingam", "Alan", ""], ["Lucic", "Mario", ""], ["Ma", "Yian", ""], ["McLean", "Cory", ""], ["Mincu", "Diana", ""], ["Mitani", "Akinori", ""], ["Montanari", "Andrea", ""], ["Nado", "Zachary", ""], ["Natarajan", "Vivek", ""], ["Nielson", "Christopher", ""], ["Osborne", "Thomas F.", ""], ["Raman", "Rajiv", ""], ["Ramasamy", "Kim", ""], ["Sayres", "Rory", ""], ["Schrouff", "Jessica", ""], ["Seneviratne", "Martin", ""], ["Sequeira", "Shannon", ""], ["Suresh", "Harini", ""], ["Veitch", "Victor", ""], ["Vladymyrov", "Max", ""], ["Wang", "Xuezhi", ""], ["Webster", "Kellie", ""], ["Yadlowsky", "Steve", ""], ["Yun", "Taedong", ""], ["Zhai", "Xiaohua", ""], ["Sculley", "D.", ""]]}, {"id": "2011.03452", "submitter": "Xuan Bi", "authors": "Xuan Bi, Gediminas Adomavicius, William Li, Annie Qu", "title": "Improving Sales Forecasting Accuracy: A Tensor Factorization Approach\n  with Demand Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to accessible big data collections from consumers, products, and stores,\nadvanced sales forecasting capabilities have drawn great attention from many\ncompanies especially in the retail business because of its importance in\ndecision making. Improvement of the forecasting accuracy, even by a small\npercentage, may have a substantial impact on companies' production and\nfinancial planning, marketing strategies, inventory controls, supply chain\nmanagement, and eventually stock prices. Specifically, our research goal is to\nforecast the sales of each product in each store in the near future. Motivated\nby tensor factorization methodologies for personalized context-aware\nrecommender systems, we propose a novel approach called the Advanced Temporal\nLatent-factor Approach to Sales forecasting (ATLAS), which achieves accurate\nand individualized prediction for sales by building a single\ntensor-factorization model across multiple stores and products. Our\ncontribution is a combination of: tensor framework (to leverage information\nacross stores and products), a new regularization function (to incorporate\ndemand dynamics), and extrapolation of tensor into future time periods using\nstate-of-the-art statistical (seasonal auto-regressive integrated\nmoving-average models) and machine-learning (recurrent neural networks) models.\nThe advantages of ATLAS are demonstrated on eight product category datasets\ncollected by the Information Resource, Inc., where a total of 165 million\nweekly sales transactions from more than 1,500 grocery stores over 15,560\nproducts are analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 16:04:40 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bi", "Xuan", ""], ["Adomavicius", "Gediminas", ""], ["Li", "William", ""], ["Qu", "Annie", ""]]}, {"id": "2011.03535", "submitter": "Simon Osindero", "authors": "Simon Osindero", "title": "Contrastive Topographic Models: Energy-based density models applied to\n  the understanding of sensory coding and cortical topography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of building theoretical models that help elucidate the\nfunction of the visual brain at computational/algorithmic and\nstructural/mechanistic levels. We seek to understand how the receptive fields\nand topographic maps found in visual cortical areas relate to underlying\ncomputational desiderata. We view the development of sensory systems from the\npopular perspective of probability density estimation; this is motivated by the\nnotion that an effective internal representational scheme is likely to reflect\nthe statistical structure of the environment in which an organism lives. We\napply biologically based constraints on elements of the model.\n  The thesis begins by surveying the relevant literature from the fields of\nneurobiology, theoretical neuroscience, and machine learning. After this review\nwe present our main theoretical and algorithmic developments: we propose a\nclass of probabilistic models, which we refer to as \"energy-based models\", and\nshow equivalences between this framework and various other types of\nprobabilistic model such as Markov random fields and factor graphs; we also\ndevelop and discuss approximate algorithms for performing maximum likelihood\nlearning and inference in our energy based models. The rest of the thesis is\nthen concerned with exploring specific instantiations of such models. By\nperforming constrained optimisation of model parameters to maximise the\nlikelihood of appropriate, naturalistic datasets we are able to qualitatively\nreproduce many of the receptive field and map properties found in vivo, whilst\nsimultaneously learning about statistical regularities in the data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:36:43 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Osindero", "Simon", ""]]}, {"id": "2011.03598", "submitter": "Linjun Zhang", "authors": "Linjun Zhang, Rong Ma, T. Tony Cai and Hongzhe Li", "title": "Estimation, Confidence Intervals, and Large-Scale Hypotheses Testing for\n  High-Dimensional Mixed Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the high-dimensional mixed linear regression (MLR) where\nthe output variable comes from one of the two linear regression models with an\nunknown mixing proportion and an unknown covariance structure of the random\ncovariates. Building upon a high-dimensional EM algorithm, we propose an\niterative procedure for estimating the two regression vectors and establish\ntheir rates of convergence. Based on the iterative estimators, we further\nconstruct debiased estimators and establish their asymptotic normality. For\nindividual coordinates, confidence intervals centered at the debiased\nestimators are constructed.\n  Furthermore, a large-scale multiple testing procedure is proposed for testing\nthe regression coefficients and is shown to control the false discovery rate\n(FDR) asymptotically. Simulation studies are carried out to examine the\nnumerical performance of the proposed methods and their superiority over\nexisting methods. The proposed methods are further illustrated through an\nanalysis of a dataset of multiplex image cytometry, which investigates the\ninteraction networks among the cellular phenotypes that include the expression\nlevels of 20 epitopes or combinations of markers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 21:17:41 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhang", "Linjun", ""], ["Ma", "Rong", ""], ["Cai", "T. Tony", ""], ["Li", "Hongzhe", ""]]}, {"id": "2011.03607", "submitter": "Charlie Dickens", "authors": "Charlie Dickens", "title": "Ridge Regression with Frequent Directions: Statistical and Optimization\n  Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its impressive theory \\& practical performance, Frequent Directions\n(\\acrshort{fd}) has not been widely adopted for large-scale regression tasks.\nPrior work has shown randomized sketches (i) perform worse in estimating the\ncovariance matrix of the data than \\acrshort{fd}; (ii) incur high error when\nestimating the bias and/or variance on sketched ridge regression. We give the\nfirst constant factor relative error bounds on the bias \\& variance for\nsketched ridge regression using \\acrshort{fd}. We complement these statistical\nresults by showing that \\acrshort{fd} can be used in the optimization setting\nthrough an iterative scheme which yields high-accuracy solutions. This improves\non randomized approaches which need to compromise the need for a new sketch\nevery iteration with speed of convergence. In both settings, we also show using\n\\emph{Robust Frequent Directions} further enhances performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 21:40:38 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Dickens", "Charlie", ""]]}, {"id": "2011.03610", "submitter": "Chandler Squires", "authors": "Chandler Squires, Joshua Amaniampong, Caroline Uhler", "title": "Efficient Permutation Discovery in Causal DAGs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning a directed acyclic graph (DAG) up to Markov\nequivalence is equivalent to the problem of finding a permutation of the\nvariables that induces the sparsest graph. Without additional assumptions, this\ntask is known to be NP-hard. Building on the minimum degree algorithm for\nsparse Cholesky decomposition, but utilizing DAG-specific problem structure, we\nintroduce an efficient algorithm for finding such sparse permutations. We show\nthat on jointly Gaussian distributions, our method with depth $w$ runs in\n$O(p^{w+3})$ time. We compare our method with $w = 1$ to algorithms for finding\nsparse elimination orderings of undirected graphs, and show that taking\nadvantage of DAG-specific problem structure leads to a significant improvement\nin the discovered permutation. We also compare our algorithm to provably\nconsistent causal structure learning algorithms, such as the PC algorithm, GES,\nand GSP, and show that our method achieves comparable performance with a\nshorter runtime. Thus, our method can be used on its own for causal structure\ndiscovery. Finally, we show that there exist dense graphs on which our method\nachieves almost perfect performance, so that unlike most existing causal\nstructure learning algorithms, the situations in which our algorithm achieves\nboth good performance and good runtime are not limited to sparse graphs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 21:56:41 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Squires", "Chandler", ""], ["Amaniampong", "Joshua", ""], ["Uhler", "Caroline", ""]]}, {"id": "2011.03622", "submitter": "Allen Liu", "authors": "Allen Liu, Ankur Moitra", "title": "Settling the Robust Learnability of Mixtures of Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work represents a natural coalescence of two important lines of work:\nlearning mixtures of Gaussians and algorithmic robust statistics. In particular\nwe give the first provably robust algorithm for learning mixtures of any\nconstant number of Gaussians. We require only mild assumptions on the mixing\nweights (bounded fractionality) and that the total variation distance between\ncomponents is bounded away from zero. At the heart of our algorithm is a new\nmethod for proving dimension-independent polynomial identifiability through\napplying a carefully chosen sequence of differential operations to certain\ngenerating functions that not only encode the parameters we would like to learn\nbut also the system of polynomial equations we would like to solve. We show how\nthe symbolic identities we derive can be directly used to analyze a natural\nsum-of-squares relaxation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 22:36:00 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 17:49:01 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 20:46:03 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Allen", ""], ["Moitra", "Ankur", ""]]}, {"id": "2011.03623", "submitter": "Ian Covert", "authors": "Ian Covert, Scott Lundberg, Su-In Lee", "title": "Feature Removal Is a Unifying Principle for Model Explanation Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have proposed a wide variety of model explanation approaches, but\nit remains unclear how most methods are related or when one method is\npreferable to another. We examine the literature and find that many methods are\nbased on a shared principle of explaining by removing - essentially, measuring\nthe impact of removing sets of features from a model. These methods vary in\nseveral respects, so we develop a framework for removal-based explanations that\ncharacterizes each method along three dimensions: 1) how the method removes\nfeatures, 2) what model behavior the method explains, and 3) how the method\nsummarizes each feature's influence. Our framework unifies 25 existing methods,\nincluding several of the most widely used approaches (SHAP, LIME, Meaningful\nPerturbations, permutation tests). Exposing the fundamental similarities\nbetween these methods empowers users to reason about which tools to use and\nsuggests promising directions for ongoing research in model explainability.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 22:37:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Covert", "Ian", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "2011.03628", "submitter": "Mert Nakip", "authors": "Mert Nak{\\i}p, Onur \\c{C}opur, C\\\"uneyt G\\\"uzeli\\c{s}", "title": "Curse of Small Sample Size in Forecasting of the Active Cases in\n  COVID-19 Outbreak", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 pandemic, a massive number of attempts on the predictions\nof the number of cases and the other future trends of this pandemic have been\nmade. However, they fail to predict, in a reliable way, the medium and long\nterm evolution of fundamental features of COVID-19 outbreak within acceptable\naccuracy. This paper gives an explanation for the failure of machine learning\nmodels in this particular forecasting problem. The paper shows that simple\nlinear regression models provide high prediction accuracy values reliably but\nonly for a 2-weeks period and that relatively complex machine learning models,\nwhich have the potential of learning long term predictions with low errors,\ncannot achieve to obtain good predictions with possessing a high generalization\nability. It is suggested in the paper that the lack of a sufficient number of\nsamples is the source of low prediction performance of the forecasting models.\nThe reliability of the forecasting results about the active cases is measured\nin terms of the cross-validation prediction errors, which are used as\nexpectations for the generalization errors of the forecasters. To exploit the\ninformation, which is of most relevant with the active cases, we perform\nfeature selection over a variety of variables. We apply different feature\nselection methods, namely the Pairwise Correlation, Recursive Feature\nSelection, and feature selection by using the Lasso regression and compare them\nto each other and also with the models not employing any feature selection.\nFurthermore, we compare Linear Regression, Multi-Layer Perceptron, and\nLong-Short Term Memory models each of which is used for prediction active cases\ntogether with the mentioned feature selection methods. Our results show that\nthe accurate forecasting of the active cases with high generalization ability\nis possible up to 3 days only because of the small sample size of COVID-19\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 23:13:34 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 09:23:51 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Nak\u0131p", "Mert", ""], ["\u00c7opur", "Onur", ""], ["G\u00fczeli\u015f", "C\u00fcneyt", ""]]}, {"id": "2011.03639", "submitter": "Hunter Lang", "authors": "Hunter Lang, David Sontag, Aravindan Vijayaraghavan", "title": "Graph cuts always find a global optimum for Potts models (with a catch)", "comments": "Published at ICML 2021. 18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the $\\alpha$-expansion algorithm for MAP inference always\nreturns a globally optimal assignment for Markov Random Fields with Potts\npairwise potentials, with a catch: the returned assignment is only guaranteed\nto be optimal for an instance within a small perturbation of the original\nproblem instance. In other words, all local minima with respect to expansion\nmoves are global minima to slightly perturbed versions of the problem. On\n\"real-world\" instances, MAP assignments of small perturbations of the problem\nshould be very similar to the MAP assignment(s) of the original problem\ninstance. We design an algorithm that can certify whether this is the case in\npractice. On several MAP inference problem instances from computer vision, this\nalgorithm certifies that MAP solutions to all of these perturbations are very\nclose to solutions of the original instance. These results taken together give\na cohesive explanation for the good performance of \"graph cuts\" algorithms in\npractice. Every local expansion minimum is a global minimum in a small\nperturbation of the problem, and all of these global minima are close to the\noriginal solution.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 00:01:06 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 01:33:06 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Lang", "Hunter", ""], ["Sontag", "David", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "2011.03654", "submitter": "Jessica Dai", "authors": "Jessica Dai, Sina Fazelpour, Zachary C. Lipton", "title": "Fair Machine Learning Under Partial Compliance", "comments": "Presented at AIES 2021. Previously at the NeurIPS 2020 Workshop on\n  Consequential Decision Making in Dynamic Environments and the NeurIPS 2020\n  Workshop on ML for Economic Policy", "journal-ref": null, "doi": "10.1145/3461702.3462521", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, fair machine learning research focuses on a single decisionmaker\nand assumes that the underlying population is stationary. However, many of the\ncritical domains motivating this work are characterized by competitive\nmarketplaces with many decisionmakers. Realistically, we might expect only a\nsubset of them to adopt any non-compulsory fairness-conscious policy, a\nsituation that political philosophers call partial compliance. This possibility\nraises important questions: how does the strategic behavior of decision\nsubjects in partial compliance settings affect the allocation outcomes? If k%\nof employers were to voluntarily adopt a fairness-promoting intervention,\nshould we expect k% progress (in aggregate) towards the benefits of universal\nadoption, or will the dynamics of partial compliance wash out the hoped-for\nbenefits? How might adopting a global (versus local) perspective impact the\nconclusions of an auditor? In this paper, we propose a simple model of an\nemployment market, leveraging simulation as a tool to explore the impact of\nboth interaction effects and incentive effects on outcomes and auditing\nmetrics. Our key findings are that at equilibrium: (1) partial compliance (k%\nof employers) can result in far less than proportional (k%) progress towards\nthe full compliance outcomes; (2) the gap is more severe when fair employers\nmatch global (vs local) statistics; (3) choices of local vs global statistics\ncan paint dramatically different pictures of the performance vis-a-vis fairness\ndesiderata of compliant versus non-compliant employers; and (4) partial\ncompliance to local parity measures can induce extreme segregation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 01:46:53 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 06:55:54 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 17:17:16 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Dai", "Jessica", ""], ["Fazelpour", "Sina", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2011.03687", "submitter": "Jiaheng Wei", "authors": "Jiaheng Wei, Yang Liu", "title": "When Optimizing $f$-divergence is Robust with Label Noise", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show when maximizing a properly defined $f$-divergence measure with\nrespect to a classifier's predictions and the supervised labels is robust with\nlabel noise. Leveraging its variational form, we derive a nice decoupling\nproperty for a family of $f$-divergence measures when label noise presents,\nwhere the divergence is shown to be a linear combination of the variational\ndifference defined on the clean distribution and a bias term introduced due to\nthe noise. The above derivation helps us analyze the robustness of different\n$f$-divergence functions. With established robustness, this family of\n$f$-divergence functions arises as useful metrics for the problem of learning\nwith noisy labels, which do not require the specification of the labels' noise\nrate. When they are possibly not robust, we propose fixes to make them so. In\naddition to the analytical results, we present thorough experimental evidence.\nOur code is available at\nhttps://github.com/UCSC-REAL/Robust-f-divergence-measures.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 04:31:33 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 07:32:28 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Wei", "Jiaheng", ""], ["Liu", "Yang", ""]]}, {"id": "2011.03729", "submitter": "Aashi Jindal", "authors": "Aashi Jindal, Prashant Gupta, Debarka Sengupta and Jayadeva", "title": "Enhash: A Fast Streaming Algorithm For Concept Drift Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Enhash, a fast ensemble learner that detects \\textit{concept\ndrift} in a data stream. A stream may consist of abrupt, gradual, virtual, or\nrecurring events, or a mixture of various types of drift. Enhash employs\nprojection hash to insert an incoming sample. We show empirically that the\nproposed method has competitive performance to existing ensemble learners in\nmuch lesser time. Also, Enhash has moderate resource requirements. Experiments\nrelevant to performance comparison were performed on 6 artificial and 4 real\ndata sets consisting of various types of drifts.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:07:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Jindal", "Aashi", ""], ["Gupta", "Prashant", ""], ["Sengupta", "Debarka", ""], ["Jayadeva", "", ""]]}, {"id": "2011.03731", "submitter": "Hongyan Chang", "authors": "Hongyan Chang, Reza Shokri", "title": "On the Privacy Risks of Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness and privacy are essential pillars of trustworthy machine\nlearning. Fair machine learning aims at minimizing discrimination against\nprotected groups by, for example, imposing a constraint on models to equalize\ntheir behavior across different groups. This can subsequently change the\ninfluence of training data points on the fair model, in a disproportionate way.\nWe study how this can change the information leakage of the model about its\ntraining data. We analyze the privacy risks of group fairness (e.g., equalized\nodds) through the lens of membership inference attacks: inferring whether a\ndata point is used for training a model. We show that fairness comes at the\ncost of privacy, and this cost is not distributed equally: the information\nleakage of fair models increases significantly on the unprivileged subgroups,\nwhich are the ones for whom we need fair learning. We show that the more biased\nthe training data is, the higher the privacy cost of achieving fairness for the\nunprivileged subgroups will be. We provide comprehensive empirical analysis for\ngeneral machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:15:31 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 01:45:56 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 08:36:27 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 05:43:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Chang", "Hongyan", ""], ["Shokri", "Reza", ""]]}, {"id": "2011.03737", "submitter": "Jun Wen", "authors": "Jun Wen, Changjian Shui, Kun Kuang, Junsong Yuan, Zenan Huang, Zhefeng\n  Gong, Nenggan Zheng", "title": "Interventional Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) aims to transfer discriminative features learned from\nsource domain to target domain. Most of DA methods focus on enhancing feature\ntransferability through domain-invariance learning. However, source-learned\ndiscriminability itself might be tailored to be biased and unsafely\ntransferable by spurious correlations, \\emph{i.e.}, part of source-specific\nfeatures are correlated with category labels. We find that standard\ndomain-invariance learning suffers from such correlations and incorrectly\ntransfers the source-specifics. To address this issue, we intervene in the\nlearning of feature discriminability using unlabeled target data to guide it to\nget rid of the domain-specific part and be safely transferable. Concretely, we\ngenerate counterfactual features that distinguish the domain-specifics from\ndomain-sharable part through a novel feature intervention strategy. To prevent\nthe residence of domain-specifics, the feature discriminability is trained to\nbe invariant to the mutations in the domain-specifics of counterfactual\nfeatures. Experimenting on typical \\emph{one-to-one} unsupervised domain\nadaptation and challenging domain-agnostic adaptation tasks, the consistent\nperformance improvements of our method over state-of-the-art approaches\nvalidate that the learned discriminative features are more safely transferable\nand generalize well to novel domains.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:53:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wen", "Jun", ""], ["Shui", "Changjian", ""], ["Kuang", "Kun", ""], ["Yuan", "Junsong", ""], ["Huang", "Zenan", ""], ["Gong", "Zhefeng", ""], ["Zheng", "Nenggan", ""]]}, {"id": "2011.03842", "submitter": "Brosnan Yuen", "authors": "Brosnan Yuen, Minh Tu Hoang, Xiaodai Dong, and Tao Lu", "title": "Universal Activation Function For Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a Universal Activation Function (UAF) that achieves\nnear optimal performance in quantification, classification, and reinforcement\nlearning (RL) problems. For any given problem, the optimization algorithms are\nable to evolve the UAF to a suitable activation function by tuning the UAF's\nparameters. For the CIFAR-10 classification and VGG-8, the UAF converges to the\nMish like activation function, which has near optimal performance $F_{1} =\n0.9017\\pm0.0040$ when compared to other activation functions. For the\nquantification of simulated 9-gas mixtures in 30 dB signal-to-noise ratio (SNR)\nenvironments, the UAF converges to the identity function, which has near\noptimal root mean square error of $0.4888 \\pm 0.0032$ $\\mu M$. In the\nBipedalWalker-v2 RL dataset, the UAF achieves the 250 reward in $961 \\pm 193$\nepochs, which proves that the UAF converges in the lowest number of epochs.\nFurthermore, the UAF converges to a new activation function in the\nBipedalWalker-v2 RL dataset.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 20:13:31 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Yuen", "Brosnan", ""], ["Hoang", "Minh Tu", ""], ["Dong", "Xiaodai", ""], ["Lu", "Tao", ""]]}, {"id": "2011.03853", "submitter": "Usman Khan", "authors": "Ran Xin and Usman A. Khan and Soummya Kar", "title": "A fast randomized incremental gradient method for decentralized\n  non-convex optimization", "comments": "Added more numerical experiments, expanded discussion on technical\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study decentralized non-convex finite-sum minimization problems described\nover a network of nodes, where each node possesses a local batch of data\nsamples. In this context, we analyze a single-timescale randomized incremental\ngradient method, called GT-SAGA. GT-SAGA is computationally efficient as it\nevaluates one component gradient per node per iteration and achieves provably\nfast and robust performance by leveraging node-level variance reduction and\nnetwork-level gradient tracking. For general smooth non-convex problems, we\nshow the almost sure and mean-squared convergence of GT-SAGA to a first-order\nstationary point and further describe regimes of practical significance where\nit outperforms the existing approaches and achieves a network\ntopology-independent iteration complexity respectively. When the global\nfunction satisfies the Polyak-Lojaciewisz condition, we show that GT-SAGA\nexhibits linear convergence to an optimal solution in expectation and describe\nregimes of practical interest where the performance is network\ntopology-independent and improves upon the existing methods. Numerical\nexperiments are included to highlight the main convergence aspects of GT-SAGA\nin non-convex settings.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 21:30:42 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 16:48:23 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2011.03854", "submitter": "Leslie O'Bray", "authors": "Karsten Borgwardt, Elisabetta Ghisu, Felipe Llinares-L\\'opez, Leslie\n  O'Bray, Bastian Rieck", "title": "Graph Kernels: State-of-the-Art and Future Challenges", "comments": "Accepted by Foundations and Trends in Machine Learning, 2020", "journal-ref": null, "doi": "10.1561/2200000076", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data are an integral part of many application domains,\nincluding chemoinformatics, computational biology, neuroimaging, and social\nnetwork analysis. Over the last two decades, numerous graph kernels, i.e.\nkernel functions between graphs, have been proposed to solve the problem of\nassessing the similarity between graphs, thereby making it possible to perform\npredictions in both classification and regression settings. This manuscript\nprovides a review of existing graph kernels, their applications, software plus\ndata resources, and an empirical comparison of state-of-the-art graph kernels.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 21:44:53 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 11:48:53 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Borgwardt", "Karsten", ""], ["Ghisu", "Elisabetta", ""], ["Llinares-L\u00f3pez", "Felipe", ""], ["O'Bray", "Leslie", ""], ["Rieck", "Bastian", ""]]}, {"id": "2011.03880", "submitter": "Zijie Huang", "authors": "Zijie Huang, Yizhou Sun, Wei Wang", "title": "Learning Continuous System Dynamics from Irregularly-Sampled Partial\n  Observations", "comments": "Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world systems, such as moving planets, can be considered as\nmulti-agent dynamic systems, where objects interact with each other and\nco-evolve along with the time. Such dynamics is usually difficult to capture,\nand understanding and predicting the dynamics based on observed trajectories of\nobjects become a critical research problem in many domains. Most existing\nalgorithms, however, assume the observations are regularly sampled and all the\nobjects can be fully observed at each sampling time, which is impractical for\nmany applications. In this paper, we propose to learn system dynamics from\nirregularly-sampled partial observations with underlying graph structure for\nthe first time. To tackle the above challenge, we present LG-ODE, a latent\nordinary differential equation generative model for modeling multi-agent\ndynamic system with known graph structure. It can simultaneously learn the\nembedding of high dimensional trajectories and infer continuous latent system\ndynamics. Our model employs a novel encoder parameterized by a graph neural\nnetwork that can infer initial states in an unsupervised way from\nirregularly-sampled partial observations of structural objects and utilizes\nneuralODE to infer arbitrarily complex continuous-time latent dynamics.\nExperiments on motion capture, spring system, and charged particle datasets\ndemonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 01:02:22 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Huang", "Zijie", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "2011.03896", "submitter": "Mark Sellke", "authors": "S\\'ebastien Bubeck, Thomas Budzinski, Mark Sellke", "title": "Cooperative and Stochastic Multi-Player Multi-Armed Bandit: Optimal\n  Regret With Neither Communication Nor Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the cooperative multi-player version of the stochastic\nmulti-armed bandit problem. We study the regime where the players cannot\ncommunicate but have access to shared randomness. In prior work by the first\ntwo authors, a strategy for this regime was constructed for two players and\nthree arms, with regret $\\tilde{O}(\\sqrt{T})$, and with no collisions at all\nbetween the players (with very high probability). In this paper we show that\nthese properties (near-optimal regret and no collisions at all) are achievable\nfor any number of players and arms. At a high level, the previous strategy\nheavily relied on a $2$-dimensional geometric intuition that was difficult to\ngeneralize in higher dimensions, while here we take a more combinatorial route\nto build the new strategy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 03:14:19 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Budzinski", "Thomas", ""], ["Sellke", "Mark", ""]]}, {"id": "2011.03900", "submitter": "Yichen Wang", "authors": "T. Tony Cai, Yichen Wang, Linjun Zhang", "title": "The Cost of Privacy in Generalized Linear Models: Algorithms and Minimax\n  Lower Bounds", "comments": "56 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose differentially private algorithms for parameter estimation in both\nlow-dimensional and high-dimensional sparse generalized linear models (GLMs) by\nconstructing private versions of projected gradient descent. We show that the\nproposed algorithms are nearly rate-optimal by characterizing their statistical\nperformance and establishing privacy-constrained minimax lower bounds for GLMs.\nThe lower bounds are obtained via a novel technique, which is based on Stein's\nLemma and generalizes the tracing attack technique for privacy-constrained\nlower bounds. This lower bound argument can be of independent interest as it is\napplicable to general parametric models. Simulated and real data experiments\nare conducted to demonstrate the numerical performance of our algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 04:27:21 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 00:30:30 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Cai", "T. Tony", ""], ["Wang", "Yichen", ""], ["Zhang", "Linjun", ""]]}, {"id": "2011.03902", "submitter": "Ricky T. Q. Chen", "authors": "Ricky T. Q. Chen, Brandon Amos, Maximilian Nickel", "title": "Learning Neural Event Functions for Ordinary Differential Equations", "comments": null, "journal-ref": "ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing Neural ODE formulation relies on an explicit knowledge of the\ntermination time. We extend Neural ODEs to implicitly defined termination\ncriteria modeled by neural event functions, which can be chained together and\ndifferentiated through. Neural Event ODEs are capable of modeling discrete and\ninstantaneous changes in a continuous-time system, without prior knowledge of\nwhen these changes should occur or how many such changes should exist. We test\nour approach in modeling hybrid discrete- and continuous- systems such as\nswitching dynamical systems and collision in multi-body systems, and we propose\nsimulation-based training of point processes with applications in discrete\ncontrol.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 04:33:54 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 18:36:31 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 00:02:40 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Chen", "Ricky T. Q.", ""], ["Amos", "Brandon", ""], ["Nickel", "Maximilian", ""]]}, {"id": "2011.03904", "submitter": "Jan Philip G\\\"opfert", "authors": "Jan Philip G\\\"opfert and Heiko Wersing and Barbara Hammer", "title": "Locally Adaptive Nearest Neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training automated systems, it has been shown to be beneficial to adapt\nthe representation of data by learning a problem-specific metric. This metric\nis global. We extend this idea and, for the widely used family of k nearest\nneighbors algorithms, develop a method that allows learning locally adaptive\nmetrics. To demonstrate important aspects of how our approach works, we conduct\na number of experiments on synthetic data sets, and we show its usefulness on\nreal-world benchmark data sets.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 05:27:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["G\u00f6pfert", "Jan Philip", ""], ["Wersing", "Heiko", ""], ["Hammer", "Barbara", ""]]}, {"id": "2011.03996", "submitter": "Marcelo Medeiros", "authors": "Jianqing Fan, Ricardo P. Masini, Marcelo C. Medeiros", "title": "Do We Exploit all Information for Counterfactual Analysis? Benefits of\n  Factor Models and Idiosyncratic Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurement of treatment (intervention) effects on a single (or just a\nfew) treated unit(s) based on counterfactuals constructed from artificial\ncontrols has become a popular practice in applied statistics and economics\nsince the proposal of the synthetic control method. In high-dimensional\nsetting, we often use principal component or (weakly) sparse regression to\nestimate counterfactuals. Do we use enough data information? To better estimate\nthe effects of price changes on the sales in our case study, we propose a\ngeneral framework on counterfactual analysis for high dimensional dependent\ndata. The framework includes both principal component regression and sparse\nlinear regression as specific cases. It uses both factor and idiosyncratic\ncomponents as predictors for improved counterfactual analysis, resulting a\nmethod called Factor-Adjusted Regularized Method for Treatment (FarmTreat)\nevaluation. We demonstrate convincingly that using either factors or sparse\nregression is inadequate for counterfactual analysis in many applications and\nthe case for information gain can be made through the use of idiosyncratic\ncomponents. We also develop theory and methods to formally answer the question\nif common factors are adequate for estimating counterfactuals. Furthermore, we\nconsider a simple resampling approach to conduct inference on the treatment\neffect as well as bootstrap test to access the relevance of the idiosyncratic\ncomponents. We apply the proposed method to evaluate the effects of price\nchanges on the sales of a set of products based on a novel large panel of sale\ndata from a major retail chain in Brazil and demonstrate the benefits of using\nadditional idiosyncratic components in the treatment effect evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:07:48 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 12:27:40 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Fan", "Jianqing", ""], ["Masini", "Ricardo P.", ""], ["Medeiros", "Marcelo C.", ""]]}, {"id": "2011.04018", "submitter": "Botao Hao", "authors": "Botao Hao, Tor Lattimore, Csaba Szepesv\\'ari, Mengdi Wang", "title": "Online Sparse Reinforcement Learning", "comments": "Accepted at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the hardness of online reinforcement learning in fixed\nhorizon, sparse linear Markov decision process (MDP), with a special focus on\nthe high-dimensional regime where the ambient dimension is larger than the\nnumber of episodes. Our contribution is two-fold. First, we provide a lower\nbound showing that linear regret is generally unavoidable in this case, even if\nthere exists a policy that collects well-conditioned data. The lower bound\nconstruction uses an MDP with a fixed number of states while the number of\nactions scales with the ambient dimension. Note that when the horizon is fixed\nto one, the case of linear stochastic bandits, the linear regret can be\navoided. Second, we show that if the learner has oracle access to a policy that\ncollects well-conditioned data then a variant of Lasso fitted Q-iteration\nenjoys a nearly dimension-free regret of $\\tilde{O}( s^{2/3} N^{2/3})$ where\n$N$ is the number of episodes and $s$ is the sparsity level. This shows that in\nthe large-action setting, the difficulty of learning can be attributed to the\ndifficulty of finding a good exploratory policy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 16:47:42 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 21:18:24 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 15:37:53 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 15:55:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Hao", "Botao", ""], ["Lattimore", "Tor", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Wang", "Mengdi", ""]]}, {"id": "2011.04019", "submitter": "Botao Hao", "authors": "Botao Hao, Yaqi Duan, Tor Lattimore, Csaba Szepesv\\'ari, Mengdi Wang", "title": "Sparse Feature Selection Makes Batch Reinforcement Learning More Sample\n  Efficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a statistical analysis of high-dimensional batch\nReinforcement Learning (RL) using sparse linear function approximation. When\nthere is a large number of candidate features, our result sheds light on the\nfact that sparsity-aware methods can make batch RL more sample efficient. We\nfirst consider the off-policy policy evaluation problem. To evaluate a new\ntarget policy, we analyze a Lasso fitted Q-evaluation method and establish a\nfinite-sample error bound that has no polynomial dependence on the ambient\ndimension. To reduce the Lasso bias, we further propose a post model-selection\nestimator that applies fitted Q-evaluation to the features selected via group\nLasso. Under an additional signal strength assumption, we derive a sharper\ninstance-dependent error bound that depends on a divergence function measuring\nthe distribution mismatch between the data distribution and occupancy measure\nof the target policy. Further, we study the Lasso fitted Q-iteration for batch\npolicy optimization and establish a finite-sample error bound depending on the\nratio between the number of relevant features and restricted minimal eigenvalue\nof the data's covariance. In the end, we complement the results with minimax\nlower bounds for batch-data policy evaluation/optimization that nearly match\nour upper bounds. The results suggest that having well-conditioned data is\ncrucial for sparse batch policy learning.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 16:48:02 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hao", "Botao", ""], ["Duan", "Yaqi", ""], ["Lattimore", "Tor", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Wang", "Mengdi", ""]]}, {"id": "2011.04020", "submitter": "Botao Hao", "authors": "Botao Hao, Tor Lattimore, Mengdi Wang", "title": "High-Dimensional Sparse Linear Bandits", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic linear bandits with high-dimensional sparse features are a\npractical model for a variety of domains, including personalized medicine and\nonline advertising. We derive a novel $\\Omega(n^{2/3})$ dimension-free minimax\nregret lower bound for sparse linear bandits in the data-poor regime where the\nhorizon is smaller than the ambient dimension and where the feature vectors\nadmit a well-conditioned exploration distribution. This is complemented by a\nnearly matching upper bound for an explore-then-commit algorithm showing that\nthat $\\Theta(n^{2/3})$ is the optimal rate in the data-poor regime. The results\ncomplement existing bounds for the data-rich regime and provide another example\nwhere carefully balancing the trade-off between information and regret is\nnecessary. Finally, we prove a dimension-free $O(\\sqrt{n})$ regret upper bound\nunder an additional assumption on the magnitude of the signal for relevant\nfeatures.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 16:48:11 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hao", "Botao", ""], ["Lattimore", "Tor", ""], ["Wang", "Mengdi", ""]]}, {"id": "2011.04026", "submitter": "Alexander Terenin", "authors": "James T. Wilson, Viacheslav Borovitskiy, Alexander Terenin, Peter\n  Mostowsky, and Marc Peter Deisenroth", "title": "Pathwise Conditioning of Gaussian Processes", "comments": null, "journal-ref": "Journal of Machine Learning Research (2021)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Gaussian processes are used to answer increasingly complex questions,\nanalytic solutions become scarcer and scarcer. Monte Carlo methods act as a\nconvenient bridge for connecting intractable mathematical expressions with\nactionable estimates via sampling. Conventional approaches for simulating\nGaussian process posteriors view samples as draws from marginal distributions\nof process values at finite sets of input locations. This distribution-centric\ncharacterization leads to generative strategies that scale cubically in the\nsize of the desired random vector. These methods are prohibitively expensive in\ncases where we would, ideally, like to draw high-dimensional vectors or even\ncontinuous sample paths. In this work, we investigate a different line of\nreasoning: rather than focusing on distributions, we articulate Gaussian\nconditionals at the level of random variables. We show how this pathwise\ninterpretation of conditioning gives rise to a general family of approximations\nthat lend themselves to efficiently sampling Gaussian process posteriors.\nStarting from first principles, we derive these methods and analyze the\napproximation errors they introduce. We, then, ground these results by\nexploring the practical implications of pathwise conditioning in various\napplied settings, such as global optimization and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 17:09:37 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:38:11 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wilson", "James T.", ""], ["Borovitskiy", "Viacheslav", ""], ["Terenin", "Alexander", ""], ["Mostowsky", "Peter", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2011.04041", "submitter": "Aijun Zhang", "authors": "Agus Sudjianto, William Knauth, Rahul Singh, Zebin Yang, Aijun Zhang", "title": "Unwrapping The Black Box of Deep ReLU Networks: Interpretability,\n  Diagnostics, and Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep neural networks (DNNs) have achieved great success in learning\ncomplex patterns with strong predictive power, but they are often thought of as\n\"black box\" models without a sufficient level of transparency and\ninterpretability. It is important to demystify the DNNs with rigorous\nmathematics and practical tools, especially when they are used for\nmission-critical applications. This paper aims to unwrap the black box of deep\nReLU networks through local linear representation, which utilizes the\nactivation pattern and disentangles the complex network into an equivalent set\nof local linear models (LLMs). We develop a convenient LLM-based toolkit for\ninterpretability, diagnostics, and simplification of a pre-trained deep ReLU\nnetwork. We propose the local linear profile plot and other visualization\nmethods for interpretation and diagnostics, and an effective merging strategy\nfor network simplification. The proposed methods are demonstrated by simulation\nexamples, benchmark datasets, and a real case study in home lending credit risk\nassessment.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 18:09:36 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Sudjianto", "Agus", ""], ["Knauth", "William", ""], ["Singh", "Rahul", ""], ["Yang", "Zebin", ""], ["Zhang", "Aijun", ""]]}, {"id": "2011.04102", "submitter": "Jie Wang", "authors": "Jie Wang, Rui Gao, Hongyuan Zha", "title": "Reliable Off-policy Evaluation for Reinforcement Learning", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a sequential decision-making problem, off-policy evaluation estimates the\nexpected cumulative reward of a target policy using logged trajectory data\ngenerated from a different behavior policy, without execution of the target\npolicy. Reinforcement learning in high-stake environments, such as healthcare\nand education, is often limited to off-policy settings due to safety or ethical\nconcerns, or inability of exploration. Hence it is imperative to quantify the\nuncertainty of the off-policy estimate before deployment of the target policy.\nIn this paper, we propose a novel framework that provides robust and optimistic\ncumulative reward estimates using one or multiple logged trajectories data.\nLeveraging methodologies from distributionally robust optimization, we show\nthat with proper selection of the size of the distributional uncertainty set,\nthese estimates serve as confidence bounds with non-asymptotic and asymptotic\nguarantees under stochastic or adversarial environments. Our results are also\ngeneralized to batch reinforcement learning and are supported by empirical\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 23:16:19 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 16:34:42 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wang", "Jie", ""], ["Gao", "Rui", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2011.04116", "submitter": "Colin Daly", "authors": "Colin Daly", "title": "An Embedded Model Estimator for Non-Stationary Random Functions using\n  Multiple Secondary Variables", "comments": "29 pages; 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for non-stationary spatial modelling using multiple secondary\nvariables is developed. It combines Geostatistics with Quantile Random Forests\nto give a new interpolation and stochastic simulation algorithm. This paper\nintroduces the method and shows that it has consistency results that are\nsimilar in nature to those applying to geostatistical modelling and to Quantile\nRandom Forests. The method allows for embedding of simpler interpolation\ntechniques, such as Kriging, to further condition the model. The algorithm\nworks by estimating a conditional distribution for the target variable at each\ntarget location. The family of such distributions is called the envelope of the\ntarget variable. From this, it is possible to obtain spatial estimates,\nquantiles and uncertainty. An algorithm to produce conditional simulations from\nthe envelope is also developed. As they sample from the envelope, realizations\nare therefore locally influenced by relative changes of importance of secondary\nvariables, trends and variability.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 00:14:24 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 20:15:18 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 13:17:19 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Daly", "Colin", ""]]}, {"id": "2011.04128", "submitter": "Elias Chaibub Neto", "authors": "Elias Chaibub Neto, Phil Snyder, Solveig K Sieberts, Larsson Omberg", "title": "Stable predictions for health related anticausal prediction tasks\n  affected by selection biases: the need to deconfound the test set features", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract. This workshop paper draws some material from arXiv:2001.03998 and\n  arXiv:2004.09466", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In health related machine learning applications, the training data often\ncorresponds to a non-representative sample from the target populations where\nthe learners will be deployed. In anticausal prediction tasks, selection biases\noften make the associations between confounders and the outcome variable\nunstable across different target environments. As a consequence, the\npredictions from confounded learners are often unstable, and might fail to\ngeneralize in shifted test environments. Stable prediction approaches aim to\nsolve this problem by producing predictions that are stable across unknown test\nenvironments. These approaches, however, are sometimes applied to the training\ndata alone with the hope that training an unconfounded model will be enough to\ngenerate stable predictions in shifted test sets. Here, we show that this is\ninsufficient, and that improved stability can be achieved by deconfounding the\ntest set features as well. We illustrate these observations using both\nsynthetic data and real world data from a mobile health study.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 01:17:58 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Neto", "Elias Chaibub", ""], ["Snyder", "Phil", ""], ["Sieberts", "Solveig K", ""], ["Omberg", "Larsson", ""]]}, {"id": "2011.04162", "submitter": "Zebang Shen", "authors": "Zebang Shen and Zhenfu Wang and Alejandro Ribeiro and Hamed Hassani", "title": "Sinkhorn Natural Gradient for Generative Models", "comments": "accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a functional over a parametric family\nof probability measures, where the parameterization is characterized via a\npush-forward structure. An important application of this problem is in training\ngenerative adversarial networks. In this regard, we propose a novel Sinkhorn\nNatural Gradient (SiNG) algorithm which acts as a steepest descent method on\nthe probability space endowed with the Sinkhorn divergence. We show that the\nSinkhorn information matrix (SIM), a key component of SiNG, has an explicit\nexpression and can be evaluated accurately in complexity that scales\nlogarithmically with respect to the desired accuracy. This is in sharp contrast\nto existing natural gradient methods that can only be carried out\napproximately. Moreover, in practical applications when only Monte-Carlo type\nintegration is available, we design an empirical estimator for SIM and provide\nthe stability analysis. In our experiments, we quantitatively compare SiNG with\nstate-of-the-art SGD-type solvers on generative tasks to demonstrate its\nefficiency and efficacy of our method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 02:51:17 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Shen", "Zebang", ""], ["Wang", "Zhenfu", ""], ["Ribeiro", "Alejandro", ""], ["Hassani", "Hamed", ""]]}, {"id": "2011.04171", "submitter": "Liao Zhu", "authors": "Liao Zhu, Robert A. Jarrow, Martin T. Wells", "title": "Time-Invariance Coefficients Tests with the Adaptive Multi-Factor Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to test the time-invariance of the beta\ncoefficients estimated by the Adaptive Multi-Factor (AMF) model. The AMF model\nis implied by the generalized arbitrage pricing theory (GAPT), which implies\nconstant beta coefficients. The AMF model utilizes a Groupwise Interpretable\nBasis Selection (GIBS) algorithm to identify the relevant factors from among\nall traded ETFs. We compare the AMF model with the Fama-French 5-factor (FF5)\nmodel. We show that for nearly all time periods with length less than 6 years,\nthe beta coefficients are time-invariant for the AMF model, but not for the FF5\nmodel. This implies that the AMF model with a rolling window (such as 5 years)\nis more consistent with realized asset returns than is the FF5 model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 03:41:02 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 00:53:33 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhu", "Liao", ""], ["Jarrow", "Robert A.", ""], ["Wells", "Martin T.", ""]]}, {"id": "2011.04185", "submitter": "Zhengling Qi", "authors": "Zhengling Qi, Peng Liao", "title": "Robust Batch Policy Learning in Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sequential decision making problem in Markov decision process\n(MDP) where each policy is evaluated by a set containing average rewards over\ndifferent horizon lengths and with different initial distributions. Given a\npre-collected dataset of multiple trajectories generated by some behavior\npolicy, our goal is to learn a robust policy in a pre-specified policy class\nthat can maximize the smallest value of this set. Leveraging the\nsemi-parametric efficiency theory from statistics, we develop a policy learning\nmethod for estimating the defined robust optimal policy that can efficiently\nbreak the curse of horizon under mild technical conditions. A rate-optimal\nregret bound up to a logarithmic factor is established in terms of the number\nof trajectories and the number of decision points.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:41:21 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 06:04:47 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 03:58:48 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Qi", "Zhengling", ""], ["Liao", "Peng", ""]]}, {"id": "2011.04219", "submitter": "Anay Mehrotra", "authors": "Anay Mehrotra and L. Elisa Celis", "title": "Mitigating Bias in Set Selection with Noisy Protected Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subset selection algorithms are ubiquitous in AI-driven applications,\nincluding, online recruiting portals and image search engines, so it is\nimperative that these tools are not discriminatory on the basis of protected\nattributes such as gender or race. Currently, fair subset selection algorithms\nassume that the protected attributes are known as part of the dataset. However,\nprotected attributes may be noisy due to errors during data collection or if\nthey are imputed (as is often the case in real-world settings). While a wide\nbody of work addresses the effect of noise on the performance of machine\nlearning algorithms, its effect on fairness remains largely unexamined. We find\nthat in the presence of noisy protected attributes, in attempting to increase\nfairness without considering noise, one can, in fact, decrease the fairness of\nthe result!\n  Towards addressing this, we consider an existing noise model in which there\nis probabilistic information about the protected attributes (e.g., [58, 34, 20,\n46]), and ask is fair selection possible under noisy conditions? We formulate a\n``denoised'' selection problem which functions for a large class of fairness\nmetrics; given the desired fairness goal, the solution to the denoised problem\nviolates the goal by at most a small multiplicative amount with high\nprobability. Although this denoised problem turns out to be NP-hard, we give a\nlinear-programming based approximation algorithm for it. We evaluate this\napproach on both synthetic and real-world datasets. Our empirical results show\nthat this approach can produce subsets which significantly improve the fairness\nmetrics despite the presence of noisy protected attributes, and, compared to\nprior noise-oblivious approaches, has better Pareto-tradeoffs between utility\nand fairness.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 06:45:15 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 17:56:05 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mehrotra", "Anay", ""], ["Celis", "L. Elisa", ""]]}, {"id": "2011.04232", "submitter": "Kamalesh Palanisamy", "authors": "Kamalesh Palanisamy, Vivek Khimani, Moin Hussain Moti, Dimitris\n  Chatzopoulos", "title": "SplitEasy: A Practical Approach for Training ML models on Mobile Devices", "comments": "7 pages, 4 figures, Accepted at the ACM HotMobile workshop", "journal-ref": null, "doi": "10.1145/3446382.3448362", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern mobile devices, although resourceful, cannot train state-of-the-art\nmachine learning models without the assistance of servers, which require access\nto, potentially, privacy-sensitive user data. Split learning has recently\nemerged as a promising technique for training complex deep learning (DL) models\non low-powered mobile devices. The core idea behind this technique is to train\nthe sensitive layers of a DL model on mobile devices while offloading the\ncomputationally intensive layers to a server. Although a lot of works have\nalready explored the effectiveness of split learning in simulated settings, a\nusable toolkit for this purpose does not exist. In this work, we highlight the\ntheoretical and technical challenges that need to be resolved to develop a\nfunctional framework that trains ML models in mobile devices without\ntransferring raw data to a server. Focusing on these challenges, we propose\nSplitEasy, a framework for training ML models on mobile devices using split\nlearning. Using the abstraction provided by SplitEasy, developers can run\nvarious DL models under split learning setting by making minimal modifications.\nWe provide a detailed explanation of SplitEasy and perform experiments with six\nstate-of-the-art neural networks. We demonstrate how SplitEasy can train models\nthat cannot be trained solely by a mobile device while incurring nearly\nconstant time per data sample.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 07:41:43 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 18:58:24 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Palanisamy", "Kamalesh", ""], ["Khimani", "Vivek", ""], ["Moti", "Moin Hussain", ""], ["Chatzopoulos", "Dimitris", ""]]}, {"id": "2011.04315", "submitter": "Elias Raninen", "authors": "Elias Raninen and Esa Ollila", "title": "Coupled regularized sample covariance matrix estimator for multiple\n  classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of covariance matrices of multiple classes with limited\ntraining data is a difficult problem. The sample covariance matrix (SCM) is\nknown to perform poorly when the number of variables is large compared to the\navailable number of samples. In order to reduce the mean squared error (MSE) of\nthe SCM, regularized (shrinkage) SCM estimators are often used. In this work,\nwe consider regularized SCM (RSCM) estimators for multiclass problems that\ncouple together two different target matrices for regularization: the pooled\n(average) SCM of the classes and the scaled identity matrix. Regularization\ntoward the pooled SCM is beneficial when the population covariances are\nsimilar, whereas regularization toward the identity matrix guarantees that the\nestimators are positive definite. We derive the MSE optimal tuning parameters\nfor the estimators as well as propose a method for their estimation under the\nassumption that the class populations follow (unspecified) elliptical\ndistributions with finite fourth-order moments. The MSE performance of the\nproposed coupled RSCMs are evaluated with simulations and in a regularized\ndiscriminant analysis (RDA) classification set-up on real data. The results\nbased on three different real data sets indicate comparable performance to\ncross-validation but with a significant speed-up in computation time.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:39:53 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Raninen", "Elias", ""], ["Ollila", "Esa", ""]]}, {"id": "2011.04345", "submitter": "Tamara AlShammari", "authors": "Tamara Alshammari and Sumudu Samarakoon and Anis Elgabli and Mehdi\n  Bennis", "title": "BayGo: Joint Bayesian Learning and Information-Aware Graph Optimization", "comments": "6 pages, 5 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with the problem of distributed machine learning, in which\nagents update their models based on their local datasets, and aggregate the\nupdated models collaboratively and in a fully decentralized manner. In this\npaper, we tackle the problem of information heterogeneity arising in\nmulti-agent networks where the placement of informative agents plays a crucial\nrole in the learning dynamics. Specifically, we propose BayGo, a novel fully\ndecentralized joint Bayesian learning and graph optimization framework with\nproven fast convergence over a sparse graph. Under our framework, agents are\nable to learn and communicate with the most informative agent to their own\nlearning. Unlike prior works, our framework assumes no prior knowledge of the\ndata distribution across agents nor does it assume any knowledge of the true\nparameter of the system. The proposed alternating minimization based framework\nensures global connectivity in a fully decentralized way while minimizing the\nnumber of communication links. We theoretically show that by optimizing the\nproposed objective function, the estimation error of the posterior probability\ndistribution decreases exponentially at each iteration. Via extensive\nsimulations, we show that our framework achieves faster convergence and higher\naccuracy compared to fully-connected and star topology graphs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 11:16:55 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 19:47:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Alshammari", "Tamara", ""], ["Samarakoon", "Sumudu", ""], ["Elgabli", "Anis", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2011.04369", "submitter": "Steffen Betsch", "authors": "Steffen Betsch, Bruno Ebner, Franz Nestmann", "title": "Characterizations of non-normalized discrete probability distributions\n  and their application in statistics", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the distributional characterizations that lie at the heart of Stein's\nmethod we derive explicit formulae for the mass functions of discrete\nprobability laws that identify those distributions. These identities are\napplied to develop tools for the solution of statistical problems. Our\ncharacterizations, and hence the applications built on them, do not require any\nknowledge about normalization constants of the probability laws. We discuss\nseveral examples where this lack of feasibility of the normalization constant\nis a built-in feature. To demonstrate that our statistical methods are sound,\nwe provide comparative simulation studies for the testing of fit to the Poisson\ndistribution and for parameter estimation of the negative binomial family when\nboth parameters are unknown. We also consider the problem of parameter\nestimation for discrete exponential-polynomial models which generally are\nnon-normalized.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:08:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Betsch", "Steffen", ""], ["Ebner", "Bruno", ""], ["Nestmann", "Franz", ""]]}, {"id": "2011.04377", "submitter": "Jingli Wang", "authors": "Huan Qing and Jingli Wang", "title": "Community Detection by Principal Components Clustering Methods", "comments": "33 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the classical Degree Corrected Stochastic Blockmodel (DCSBM) model\nfor network community detection problem, we propose two novel approaches:\nprincipal component clustering (PCC) and normalized principal component\nclustering (NPCC). Without any parameters to be estimated, the PCC method is\nsimple to be implemented. Under mild conditions, we show that PCC yields\nconsistent community detection. NPCC is designed based on the combination of\nthe PCC and the RSC method (Qin & Rohe 2013). Population analysis for NPCC\nshows that NPCC returns perfect clustering for the ideal case under DCSBM. PCC\nand NPCC is illustrated through synthetic and real-world datasets. Numerical\nresults show that NPCC provides a significant improvement compare with PCC and\nRSC. Moreover, NPCC inherits nice properties of PCC and RSC such that NPCC is\ninsensitive to the number of eigenvectors to be clustered and the choosing of\nthe tuning parameter. When dealing with two weak signal networks Simmons and\nCaltech, by considering one more eigenvectors for clustering, we provide two\nrefinements PCC+ and NPCC+ of PCC and NPCC, respectively. Both two refinements\nalgorithms provide improvement performances compared with their original\nalgorithms. Especially, NPCC+ provides satisfactory performances on Simmons and\nCaltech, with error rates of 121/1137 and 96/590, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:24:42 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 02:35:46 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Qing", "Huan", ""], ["Wang", "Jingli", ""]]}, {"id": "2011.04391", "submitter": "Tadeu Ferreira", "authors": "Tadeu A. Ferreira", "title": "Reinforced Deep Markov Models With Applications in Automatic Trading", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the developments in deep generative models, we propose a\nmodel-based RL approach, coined Reinforced Deep Markov Model (RDMM), designed\nto integrate desirable properties of a reinforcement learning algorithm acting\nas an automatic trading system. The network architecture allows for the\npossibility that market dynamics are partially visible and are potentially\nmodified by the agent's actions. The RDMM filters incomplete and noisy data, to\ncreate better-behaved input data for RL planning. The policy search\noptimisation also properly accounts for state uncertainty. Due to the\ncomplexity of the RKDF model architecture, we performed ablation studies to\nunderstand the contributions of individual components of the approach better.\nTo test the financial performance of the RDMM we implement policies using\nvariants of Q-Learning, DynaQ-ARIMA and DynaQ-LSTM algorithms. The experiments\nshow that the RDMM is data-efficient and provides financial gains compared to\nthe benchmarks in the optimal execution problem. The performance improvement\nbecomes more pronounced when price dynamics are more complex, and this has been\ndemonstrated using real data sets from the limit order book of Facebook, Intel,\nVodafone and Microsoft.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:46:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ferreira", "Tadeu A.", ""]]}, {"id": "2011.04392", "submitter": "Jingli Wang", "authors": "Huan Qing and Jingli Wang", "title": "Dual regularized Laplacian spectral clustering methods on community\n  detection", "comments": "43 pages, 10 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering methods are widely used for detecting clusters in\nnetworks for community detection, while a small change on the graph Laplacian\nmatrix could bring a dramatic improvement. In this paper, we propose a dual\nregularized graph Laplacian matrix and then employ it to three classical\nspectral clustering approaches under the degree-corrected stochastic block\nmodel. If the number of communities is known as $K$, we consider more than $K$\nleading eigenvectors and weight them by their corresponding eigenvalues in the\nspectral clustering procedure to improve the performance. Three improved\nspectral clustering methods are dual regularized spectral clustering (DRSC)\nmethod, dual regularized spectral clustering on Ratios-of-eigenvectors\n(DRSCORE) method, and dual regularized symmetrized Laplacian inverse matrix\n(DRSLIM) method. Theoretical analysis of DRSC and DRSLIM show that under mild\nconditions DRSC and DRSLIM yield stable consistent community detection,\nmoreover, DRSCORE returns perfect clustering under the ideal case. We compare\nthe performances of DRSC, DRSCORE and DRSLIM with several spectral methods by\nsubstantial simulated networks and eight real-world networks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:49:25 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Qing", "Huan", ""], ["Wang", "Jingli", ""]]}, {"id": "2011.04418", "submitter": "Lijing Shao", "authors": "Heming Xia, Lijing Shao, Junjie Zhao, Zhoujian Cao", "title": "Improved deep learning techniques in gravitational-wave data analysis", "comments": "13 pages, 11 figures; accepted by PRD", "journal-ref": "Phys. Rev. D 103, 024040 (2021)", "doi": "10.1103/PhysRevD.103.024040", "report-no": null, "categories": "astro-ph.HE cs.LG gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, convolutional neural network (CNN) and other deep learning\nmodels have been gradually introduced into the area of gravitational-wave (GW)\ndata processing. Compared with the traditional matched-filtering techniques,\nCNN has significant advantages in efficiency in GW signal detection tasks. In\naddition, matched-filtering techniques are based on the template bank of the\nexisting theoretical waveform, which makes it difficult to find GW signals\nbeyond theoretical expectation. In this paper, based on the task of GW\ndetection of binary black holes, we introduce the optimization techniques of\ndeep learning, such as batch normalization and dropout, to CNN models. Detailed\nstudies of model performance are carried out. Through this study, we recommend\nto use batch normalization and dropout techniques in CNN models in GW signal\ndetection tasks. Furthermore, we investigate the generalization ability of CNN\nmodels on different parameter ranges of GW signals. We point out that CNN\nmodels are robust to the variation of the parameter range of the GW waveform.\nThis is a major advantage of deep learning models over matched-filtering\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 13:40:00 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 23:52:18 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Xia", "Heming", ""], ["Shao", "Lijing", ""], ["Zhao", "Junjie", ""], ["Cao", "Zhoujian", ""]]}, {"id": "2011.04419", "submitter": "Vikas Verma", "authors": "Vikas Verma, Minh-Thang Luong, Kenji Kawaguchi, Hieu Pham, Quoc V. Le", "title": "Towards Domain-Agnostic Contrastive Learning", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent success, most contrastive self-supervised learning methods are\ndomain-specific, relying heavily on data augmentation techniques that require\nknowledge about a particular domain, such as image cropping and rotation. To\novercome such limitation, we propose a novel domain-agnostic approach to\ncontrastive learning, named DACL, that is applicable to domains where\ninvariances, and thus, data augmentation techniques, are not readily available.\nKey to our approach is the use of Mixup noise to create similar and dissimilar\nexamples by mixing data samples differently either at the input or hidden-state\nlevels. To demonstrate the effectiveness of DACL, we conduct experiments across\nvarious domains such as tabular data, images, and graphs. Our results show that\nDACL not only outperforms other domain-agnostic noising methods, such as\nGaussian-noise, but also combines well with domain-specific methods, such as\nSimCLR, to improve self-supervised visual representation learning. Finally, we\ntheoretically analyze our method and show advantages over the Gaussian-noise\nbased contrastive learning approach.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 13:41:56 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 20:59:14 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Verma", "Vikas", ""], ["Luong", "Minh-Thang", ""], ["Kawaguchi", "Kenji", ""], ["Pham", "Hieu", ""], ["Le", "Quoc V.", ""]]}, {"id": "2011.04447", "submitter": "Vayer Titouan", "authors": "Titouan Vayer", "title": "A contribution to Optimal Transport on incomparable spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Transport is a theory that allows to define geometrical notions of\ndistance between probability distributions and to find correspondences,\nrelationships, between sets of points. Many machine learning applications are\nderived from this theory, at the frontier between mathematics and optimization.\nThis thesis proposes to study the complex scenario in which the different data\nbelong to incomparable spaces. In particular we address the following\nquestions: how to define and apply Optimal Transport between graphs, between\nstructured data? How can it be adapted when the data are varied and not\nembedded in the same metric space? This thesis proposes a set of Optimal\nTransport tools for these different cases. An important part is notably devoted\nto the study of the Gromov-Wasserstein distance whose properties allow to\ndefine interesting transport problems on incomparable spaces. More broadly, we\nanalyze the mathematical properties of the various proposed tools, we establish\nalgorithmic solutions to compute them and we study their applicability in\nnumerous machine learning scenarii which cover, in particular, classification,\nsimplification, partitioning of structured data, as well as heterogeneous\ndomain adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:13:52 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Vayer", "Titouan", ""]]}, {"id": "2011.04468", "submitter": "Nikolaos Tsilivis", "authors": "Nikos Tsilivis, Anastasios Tsiamis, Petros Maragos", "title": "Sparse Approximate Solutions to Max-Plus Equations with Application to\n  Multivariate Convex Regression", "comments": "20 pages, 5 figures, 5 tables. Introduction revision and typos\n  correction", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.RA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of finding approximate, with minimum\nsupport set, solutions to matrix max-plus equations, which we call sparse\napproximate solutions. We show how one can obtain such solutions efficiently\nand in polynomial time for any $\\ell_p$ approximation error. Based on these\nresults, we propose a novel method for piecewise-linear fitting of convex\nmultivariate functions, with optimality guarantees for the model parameters and\nan approximately minimum number of affine regions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 15:17:00 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 17:54:22 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Tsilivis", "Nikos", ""], ["Tsiamis", "Anastasios", ""], ["Maragos", "Petros", ""]]}, {"id": "2011.04483", "submitter": "Steve Hanneke", "authors": "Olivier Bousquet, Steve Hanneke, Shay Moran, Ramon van Handel, Amir\n  Yehudayoff", "title": "A Theory of Universal Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How quickly can a given class of concepts be learned from examples? It is\ncommon to measure the performance of a supervised machine learning algorithm by\nplotting its \"learning curve\", that is, the decay of the error rate as a\nfunction of the number of training examples. However, the classical theoretical\nframework for understanding learnability, the PAC model of Vapnik-Chervonenkis\nand Valiant, does not explain the behavior of learning curves: the\ndistribution-free PAC model of learning can only bound the upper envelope of\nthe learning curves over all possible data distributions. This does not match\nthe practice of machine learning, where the data source is typically fixed in\nany given scenario, while the learner may choose the number of training\nexamples on the basis of factors such as computational resources and desired\naccuracy.\n  In this paper, we study an alternative learning model that better captures\nsuch practical aspects of machine learning, but still gives rise to a complete\ntheory of the learnable in the spirit of the PAC model. More precisely, we\nconsider the problem of universal learning, which aims to understand the\nperformance of learning algorithms on every data distribution, but without\nrequiring uniformity over the distribution. The main result of this paper is a\nremarkable trichotomy: there are only three possible rates of universal\nlearning. More precisely, we show that the learning curves of any given concept\nclass decay either at an exponential, linear, or arbitrarily slow rates.\nMoreover, each of these cases is completely characterized by appropriate\ncombinatorial parameters, and we exhibit optimal learning algorithms that\nachieve the best possible rate in each case.\n  For concreteness, we consider in this paper only the realizable case, though\nanalogous results are expected to extend to more general learning scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:10:32 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bousquet", "Olivier", ""], ["Hanneke", "Steve", ""], ["Moran", "Shay", ""], ["van Handel", "Ramon", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "2011.04517", "submitter": "Hassan Arbabi", "authors": "Hassan Arbabi and Ioannis Kevrekidis", "title": "Particles to Partial Differential Equations Parsimoniously", "comments": null, "journal-ref": null, "doi": "10.1063/5.0037837", "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equations governing physico-chemical processes are usually known at\nmicroscopic spatial scales, yet one suspects that there exist equations, e.g.\nin the form of Partial Differential Equations (PDEs), that can explain the\nsystem evolution at much coarser, meso- or macroscopic length scales.\nDiscovering those coarse-grained effective PDEs can lead to considerable\nsavings in computation-intensive tasks like prediction or control. We propose a\nframework combining artificial neural networks with multiscale computation, in\nthe form of equation-free numerics, for efficient discovery of such macro-scale\nPDEs directly from microscopic simulations. Gathering sufficient microscopic\ndata for training neural networks can be computationally prohibitive;\nequation-free numerics enable a more parsimonious collection of training data\nby only operating in a sparse subset of the space-time domain. We also propose\nusing a data-driven approach, based on manifold learning and unnormalized\noptimal transport of distributions, to identify macro-scale dependent\nvariable(s) suitable for the data-driven discovery of said PDEs. This approach\ncan corroborate physically motivated candidate variables, or introduce new\ndata-driven variables, in terms of which the coarse-grained effective PDE can\nbe formulated. We illustrate our approach by extracting coarse-grained\nevolution equations from particle-based simulations with a priori unknown\nmacro-scale variable(s), while significantly reducing the requisite data\ncollection computational effort.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:51:24 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Arbabi", "Hassan", ""], ["Kevrekidis", "Ioannis", ""]]}, {"id": "2011.04538", "submitter": "Hao Chen Dr.", "authors": "Hao Chen, Lanshan Han and Alvin Lim", "title": "Estimating Linear Mixed Effects Models with Truncated Normally\n  Distributed Random Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linear Mixed Effects (LME) models have been widely applied in clustered data\nanalysis in many areas including marketing research, clinical trials, and\nbiomedical studies. Inference can be conducted using maximum likelihood\napproach if assuming Normal distributions on the random effects. However, in\nmany applications of economy, business and medicine, it is often essential to\nimpose constraints on the regression parameters after taking their real-world\ninterpretations into account. Therefore, in this paper we extend the classical\n(unconstrained) LME models to allow for sign constraints on its overall\ncoefficients. We propose to assume a symmetric doubly truncated Normal (SDTN)\ndistribution on the random effects instead of the unconstrained Normal\ndistribution which is often found in classical literature. With the\naforementioned change, difficulty has dramatically increased as the exact\ndistribution of the dependent variable becomes analytically intractable. We\nthen develop likelihood-based approaches to estimate the unknown model\nparameters utilizing the approximation of its exact distribution. Simulation\nstudies have shown that the proposed constrained model not only improves\nreal-world interpretations of results, but also achieves satisfactory\nperformance on model fits as compared to the existing model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 16:17:35 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 16:41:06 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 14:22:47 GMT"}, {"version": "v4", "created": "Thu, 15 Jul 2021 14:43:44 GMT"}, {"version": "v5", "created": "Sat, 17 Jul 2021 23:29:36 GMT"}, {"version": "v6", "created": "Wed, 21 Jul 2021 00:15:39 GMT"}, {"version": "v7", "created": "Thu, 22 Jul 2021 21:01:52 GMT"}, {"version": "v8", "created": "Thu, 29 Jul 2021 02:02:51 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Hao", ""], ["Han", "Lanshan", ""], ["Lim", "Alvin", ""]]}, {"id": "2011.04558", "submitter": "Francesco Sanna Passino", "authors": "Francesco Sanna Passino, Nicholas A. Heard and Patrick Rubin-Delanchy", "title": "Spectral clustering on spherical coordinates under the degree-corrected\n  stochastic blockmodel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is a popular method for community detection in networks\nunder the assumption of the standard stochastic blockmodel. Taking a matrix\nrepresentation of the graph such as the adjacency matrix, the nodes are\nclustered on a low dimensional projection obtained from a truncated spectral\ndecomposition of the matrix. Estimating the number of communities and the\ndimension of the reduced latent space well is crucial for good performance of\nspectral clustering algorithms. Real-world networks, such as computer networks\nstudied in cyber-security applications, often present heterogeneous\nwithin-community degree distributions which are better addressed by the\ndegree-corrected stochastic blockmodel. A novel, model-based method is proposed\nin this article for simultaneous and automated selection of the number of\ncommunities and latent dimension for spectral clustering under the\ndegree-corrected stochastic blockmodel. The method is based on a transformation\nto spherical coordinates of the spectral embedding, and on a novel modelling\nassumption in the transformed space, which is then embedded into an existing\nmodel selection framework for estimating the number of communities and the\nlatent dimension. Results show improved performance over competing methods on\nsimulated and real-world computer network data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 16:55:38 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 11:04:22 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Passino", "Francesco Sanna", ""], ["Heard", "Nicholas A.", ""], ["Rubin-Delanchy", "Patrick", ""]]}, {"id": "2011.04585", "submitter": "Felipe Tobar Dr", "authors": "Felipe Tobar and Lerko Araya-Hern\\'andez and Pablo Huijse and Petar M.\n  Djuri\\'c", "title": "Bayesian Reconstruction of Fourier Pairs", "comments": "14 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a number of data-driven applications such as detection of arrhythmia,\ninterferometry or audio compression, observations are acquired indistinctly in\nthe time or frequency domains: temporal observations allow us to study the\nspectral content of signals (e.g., audio), while frequency-domain observations\nare used to reconstruct temporal/spatial data (e.g., MRI). Classical approaches\nfor spectral analysis rely either on i) a discretisation of the time and\nfrequency domains, where the fast Fourier transform stands out as the\n\\textit{de facto} off-the-shelf resource, or ii) stringent parametric models\nwith closed-form spectra. However, the general literature fails to cater for\nmissing observations and noise-corrupted data. Our aim is to address the lack\nof a principled treatment of data acquired indistinctly in the temporal and\nfrequency domains in a way that is robust to missing or noisy observations, and\nthat at the same time models uncertainty effectively. To achieve this aim, we\nfirst define a joint probabilistic model for the temporal and spectral\nrepresentations of signals, to then perform a Bayesian model update in the\nlight of observations, thus jointly reconstructing the complete (latent) time\nand frequency representations. The proposed model is analysed from a classical\nspectral analysis perspective, and its implementation is illustrated through\nintuitive examples. Lastly, we show that the proposed model is able to perform\njoint time and frequency reconstruction of real-world audio, healthcare and\nastronomy signals, while successfully dealing with missing data and handling\nuncertainty (noise) naturally against both classical and modern approaches for\nspectral estimation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:30:24 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Tobar", "Felipe", ""], ["Araya-Hern\u00e1ndez", "Lerko", ""], ["Huijse", "Pablo", ""], ["Djuri\u0107", "Petar M.", ""]]}, {"id": "2011.04586", "submitter": "Steve Hanneke", "authors": "Steve Hanneke, Aryeh Kontorovich", "title": "Stable Sample Compression Schemes: New Applications and an Optimal SVM\n  Margin Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a family of supervised learning algorithms based on sample\ncompression schemes that are stable, in the sense that removing points from the\ntraining set which were not selected for the compression set does not alter the\nresulting classifier. We use this technique to derive a variety of novel or\nimproved data-dependent generalization bounds for several learning algorithms.\nIn particular, we prove a new margin bound for SVM, removing a log factor. The\nnew bound is provably optimal. This resolves a long-standing open question\nabout the PAC margin bounds achievable by SVM.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:30:49 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hanneke", "Steve", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "2011.04588", "submitter": "Ankan Dutta", "authors": "Ankan Dutta and Arnab Rakshit", "title": "Geometry Perspective Of Estimating Learning Capability Of Neural\n  Networks", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper uses statistical and differential geometric motivation to acquire\nprior information about the learning capability of an artificial neural network\non a given dataset. The paper considers a broad class of neural networks with\ngeneralized architecture performing simple least square regression with\nstochastic gradient descent (SGD). The system characteristics at two critical\nepochs in the learning trajectory are analyzed. During some epochs of the\ntraining phase, the system reaches equilibrium with the generalization\ncapability attaining a maximum. The system can also be coherent with localized,\nnon-equilibrium states, which is characterized by the stabilization of the\nHessian matrix. The paper proves that neural networks with higher\ngeneralization capability will have a slower convergence rate. The relationship\nbetween the generalization capability with the stability of the neural network\nhas also been discussed. By correlating the principles of high-energy physics\nwith the learning theory of neural networks, the paper establishes a variant of\nthe Complexity-Action conjecture from an artificial neural network perspective.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 12:03:19 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 07:32:38 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Dutta", "Ankan", ""], ["Rakshit", "Arnab", ""]]}, {"id": "2011.04602", "submitter": "Julius Berner", "authors": "Julius Berner, Markus Dablander, Philipp Grohs", "title": "Numerically Solving Parametric Families of High-Dimensional Kolmogorov\n  Partial Differential Equations via Deep Learning", "comments": "Accepted at NeurIPS 2020", "journal-ref": "Advances in Neural Information Processing Systems 33, 2020, pp.\n  16615-16627", "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning algorithm for the numerical solution of parametric\nfamilies of high-dimensional linear Kolmogorov partial differential equations\n(PDEs). Our method is based on reformulating the numerical approximation of a\nwhole family of Kolmogorov PDEs as a single statistical learning problem using\nthe Feynman-Kac formula. Successful numerical experiments are presented, which\nempirically confirm the functionality and efficiency of our proposed algorithm\nin the case of heat equations and Black-Scholes option pricing models\nparametrized by affine-linear coefficient functions. We show that a single deep\nneural network trained on simulated data is capable of learning the solution\nfunctions of an entire family of PDEs on a full space-time region. Most\nnotably, our numerical observations and theoretical results also demonstrate\nthat the proposed method does not suffer from the curse of dimensionality,\ndistinguishing it from almost all standard numerical methods for PDEs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:57:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Berner", "Julius", ""], ["Dablander", "Markus", ""], ["Grohs", "Philipp", ""]]}, {"id": "2011.04605", "submitter": "Elias Chaibub Neto", "authors": "Elias Chaibub Neto", "title": "Causality-aware counterfactual confounding adjustment as an alternative\n  to linear residualization in anticausal prediction tasks based on linear\n  learners", "comments": "This paper draws some material from arXiv:2001.03998", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear residualization is a common practice for confounding adjustment in\nmachine learning (ML) applications. Recently, causality-aware predictive\nmodeling has been proposed as an alternative causality-inspired approach for\nadjusting for confounders. The basic idea is to simulate counterfactual data\nthat is free from the spurious associations generated by the observed\nconfounders. In this paper, we compare the linear residualization approach\nagainst the causality-aware confounding adjustment in anticausal prediction\ntasks, and show that the causality-aware approach tends to (asymptotically)\noutperform the residualization adjustment in terms of predictive performance in\nlinear learners. Importantly, our results still holds even when the true model\nis not linear. We illustrate our results in both regression and classification\ntasks, where we compared the causality-aware and residualization approaches\nusing mean squared errors and classification accuracy in synthetic data\nexperiments where the linear regression model is mispecified, as well as, when\nthe linear model is correctly specified. Furthermore, we illustrate how the\ncausality-aware approach is more stable than residualization with respect to\ndataset shifts in the joint distribution of the confounders and outcome\nvariables.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:59:57 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Neto", "Elias Chaibub", ""]]}, {"id": "2011.04622", "submitter": "Zhuoran Yang", "authors": "Zhuoran Yang, Chi Jin, Zhaoran Wang, Mengdi Wang, Michael I. Jordan", "title": "On Function Approximation in Reinforcement Learning: Optimism in the\n  Face of Large State Spaces", "comments": "76 pages. The short version of this work appears in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical theory of reinforcement learning (RL) has focused on tabular\nand linear representations of value functions. Further progress hinges on\ncombining RL with modern function approximators such as kernel functions and\ndeep neural networks, and indeed there have been many empirical successes that\nhave exploited such combinations in large-scale applications. There are\nprofound challenges, however, in developing a theory to support this\nenterprise, most notably the need to take into consideration the\nexploration-exploitation tradeoff at the core of RL in conjunction with the\ncomputational and statistical tradeoffs that arise in modern\nfunction-approximation-based learning systems. We approach these challenges by\nstudying an optimistic modification of the least-squares value iteration\nalgorithm, in the context of the action-value function\n  represented by a kernel function or an overparameterized neural network. We\nestablish both polynomial runtime complexity and polynomial sample complexity\nfor this algorithm, without additional assumptions on the data-generating\nmodel. In particular, we prove that the algorithm incurs an\n$\\tilde{\\mathcal{O}}(\\delta_{\\mathcal{F}} H^2 \\sqrt{T})$ regret, where\n$\\delta_{\\mathcal{F}}$ characterizes the intrinsic complexity of the function\nclass $\\mathcal{F}$, $H$ is the length of each episode, and $T$ is the total\nnumber of episodes. Our regret bounds are independent of the number of states,\na result which exhibits clearly the benefit of function approximation in RL.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:32:22 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 17:24:48 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yang", "Zhuoran", ""], ["Jin", "Chi", ""], ["Wang", "Zhaoran", ""], ["Wang", "Mengdi", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.04720", "submitter": "Frithjof Gressmann", "authors": "Frithjof Gressmann, Zach Eaton-Rosen, Carlo Luschi", "title": "Improving Neural Network Training in Low Dimensional Random Bases", "comments": "Published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) has proven to be remarkably effective in\noptimizing deep neural networks that employ ever-larger numbers of parameters.\nYet, improving the efficiency of large-scale optimization remains a vital and\nhighly active area of research. Recent work has shown that deep neural networks\ncan be optimized in randomly-projected subspaces of much smaller dimensionality\nthan their native parameter space. While such training is promising for more\nefficient and scalable optimization schemes, its practical application is\nlimited by inferior optimization performance. Here, we improve on recent random\nsubspace approaches as follows: Firstly, we show that keeping the random\nprojection fixed throughout training is detrimental to optimization. We propose\nre-drawing the random subspace at each step, which yields significantly better\nperformance. We realize further improvements by applying independent\nprojections to different parts of the network, making the approximation more\nefficient as network dimensionality grows. To implement these experiments, we\nleverage hardware-accelerated pseudo-random number generation to construct the\nrandom projections on-demand at every optimization step, allowing us to\ndistribute the computation of independent random directions across multiple\nworkers with shared random seeds. This yields significant reductions in memory\nand is up to 10 times faster for the workloads in question.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:50:19 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gressmann", "Frithjof", ""], ["Eaton-Rosen", "Zach", ""], ["Luschi", "Carlo", ""]]}, {"id": "2011.04765", "submitter": "Stefan Richthofer", "authors": "Stefan Richthofer, Laurenz Wiskott", "title": "Singular Sturm-Liouville Problems with Zero Potential (q=0) and Singular\n  Slow Feature Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Sturm-Liouville problem ($\\lambda wy=(ry')'+qy$) is singular if its domain\nis unbounded or if $r$ or $w$ vanish at the boundary. Then it is difficult to\ntell whether profound results from regular Sturm-Liouville theory apply.\nExisting criteria are often difficult to apply, e.g. because they are\nformulated in terms of the solution function.\n  We study the special case that the potential $q$ is zero under Neumann\nboundary conditions and give simple and explicit criteria, solely in terms of\nthe coefficient functions, to assess whether various properties of the regular\ncase apply. Specifically, these properties are discreteness of the spectrum\n(BD), self-adjointness, oscillation ($i$th solution has $i$ zeros) and that the\n$i$th eigenvalue equals the SFA delta value (the total energy) of the $i$th\nsolution. We further prove that stationary points of each solution strictly\ninterlace with its zeros (in singular or regular case, regardless of the\nboundary condition, for zero potential or if $q < \\lambda w$ everywhere). If\n$\\frac{r}{w}$ is bounded and of bounded variation, the criterion simplifies to\nrequiring $\\frac{|w'|}{w} \\to \\infty$ at singular boundary points.\n  This research is motivated by Slow Feature Analysis (SFA), a data processing\nalgorithm that extracts the slowest uncorrelated signals from a\nhigh-dimensional input signal and has notable success in computer vision,\ncomputational neuroscience and blind source separation. From [Sprekeler et al.,\n2014] it is known that for an important class of scenarios (statistically\nindependent input), an analytic formulation of SFA reduces to a Sturm-Liouville\nproblem with zero potential and Neumann boundary conditions. So far, the\nmathematical SFA theory has only considered the regular case, except for a\nspecial case that is solved by Hermite Polynomials. This work generalizes SFA\ntheory to the singular case, i.e. open-space scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:09:38 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Richthofer", "Stefan", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "2011.04770", "submitter": "Arunesh Mittal", "authors": "Arunesh Mittal, Paul Sajda, John Paisley", "title": "Deep Bayesian Nonparametric Factor Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a deep generative factor analysis model with beta process prior\nthat can approximate complex non-factorial distributions over the latent codes.\nWe outline a stochastic EM algorithm for scalable inference in a specific\ninstantiation of this model and present some preliminary results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:14:22 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Mittal", "Arunesh", ""], ["Sajda", "Paul", ""], ["Paisley", "John", ""]]}, {"id": "2011.04798", "submitter": "Ding Zhou", "authors": "Ding Zhou, Xue-Xin Wei", "title": "Learning identifiable and interpretable latent models of\n  high-dimensional neural activity using pi-VAE", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The ability to record activities from hundreds of neurons simultaneously in\nthe brain has placed an increasing demand for developing appropriate\nstatistical techniques to analyze such data. Recently, deep generative models\nhave been proposed to fit neural population responses. While these methods are\nflexible and expressive, the downside is that they can be difficult to\ninterpret and identify. To address this problem, we propose a method that\nintegrates key ingredients from latent models and traditional neural encoding\nmodels. Our method, pi-VAE, is inspired by recent progress on identifiable\nvariational auto-encoder, which we adapt to make appropriate for neuroscience\napplications. Specifically, we propose to construct latent variable models of\nneural activity while simultaneously modeling the relation between the latent\nand task variables (non-neural variables, e.g. sensory, motor, and other\nexternally observable states). The incorporation of task variables results in\nmodels that are not only more constrained, but also show qualitative\nimprovements in interpretability and identifiability. We validate pi-VAE using\nsynthetic data, and apply it to analyze neurophysiological datasets from rat\nhippocampus and macaque motor cortex. We demonstrate that pi-VAE not only fits\nthe data better, but also provides unexpected novel insights into the structure\nof the neural codes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:00:38 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhou", "Ding", ""], ["Wei", "Xue-Xin", ""]]}, {"id": "2011.04802", "submitter": "Kamran Kowsari", "authors": "Jinghe Zhang, Kamran Kowsari, Mehdi Boukhechba, James Harrison,\n  Jennifer Lobo, Laura Barnes", "title": "Sparse Longitudinal Representations of Electronic Health Record Data for\n  the Early Detection of Chronic Kidney Disease in Diabetic Patients", "comments": "Accepted in IEEE BIBM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.PE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic kidney disease (CKD) is a gradual loss of renal function over time,\nand it increases the risk of mortality, decreased quality of life, as well as\nserious complications. The prevalence of CKD has been increasing in the last\ncouple of decades, which is partly due to the increased prevalence of diabetes\nand hypertension. To accurately detect CKD in diabetic patients, we propose a\nnovel framework to learn sparse longitudinal representations of patients'\nmedical records. The proposed method is also compared with widely used\nbaselines such as Aggregated Frequency Vector and Bag-of-Pattern in Sequences\non real EHR data, and the experimental results indicate that the proposed model\nachieves higher predictive performance. Additionally, the learned\nrepresentations are interpreted and visualized to bring clinical insights.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:07:25 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 18:33:56 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Zhang", "Jinghe", ""], ["Kowsari", "Kamran", ""], ["Boukhechba", "Mehdi", ""], ["Harrison", "James", ""], ["Lobo", "Jennifer", ""], ["Barnes", "Laura", ""]]}, {"id": "2011.04832", "submitter": "Tavor Baharav", "authors": "Govinda M. Kamath and Tavor Z. Baharav and Ilan Shomorony", "title": "Adaptive Learning of Rank-One Models for Efficient Pairwise Sequence\n  Alignment", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT q-bio.GN stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pairwise alignment of DNA sequencing data is a ubiquitous task in\nbioinformatics and typically represents a heavy computational burden.\nState-of-the-art approaches to speed up this task use hashing to identify short\nsegments (k-mers) that are shared by pairs of reads, which can then be used to\nestimate alignment scores. However, when the number of reads is large,\naccurately estimating alignment scores for all pairs is still very costly.\nMoreover, in practice, one is only interested in identifying pairs of reads\nwith large alignment scores. In this work, we propose a new approach to\npairwise alignment estimation based on two key new ingredients. The first\ningredient is to cast the problem of pairwise alignment estimation under a\ngeneral framework of rank-one crowdsourcing models, where the workers'\nresponses correspond to k-mer hash collisions. These models can be accurately\nsolved via a spectral decomposition of the response matrix. The second\ningredient is to utilise a multi-armed bandit algorithm to adaptively refine\nthis spectral estimator only for read pairs that are likely to have large\nalignments. The resulting algorithm iteratively performs a spectral\ndecomposition of the response matrix for adaptively chosen subsets of the read\npairs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 23:31:56 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 02:01:40 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kamath", "Govinda M.", ""], ["Baharav", "Tavor Z.", ""], ["Shomorony", "Ilan", ""]]}, {"id": "2011.04868", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Bo Ji, Yixin Shi, Tianyu Ding, Biyi Fang, Sheng Yi, Xiao\n  Tu", "title": "Neural Network Compression Via Sparse Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The compression of deep neural networks (DNNs) to reduce inference cost\nbecomes increasingly important to meet realistic deployment requirements of\nvarious applications. There have been a significant amount of work regarding\nnetwork compression, while most of them are heuristic rule-based or typically\nnot friendly to be incorporated into varying scenarios. On the other hand,\nsparse optimization yielding sparse solutions naturally fits the compression\nrequirement, but due to the limited study of sparse optimization in stochastic\nlearning, its extension and application onto model compression is rarely well\nexplored. In this work, we propose a model compression framework based on the\nrecent progress on sparse stochastic optimization. Compared to existing model\ncompression techniques, our method is effective and requires fewer extra\nengineering efforts to incorporate with varying applications, and has been\nnumerically demonstrated on benchmark compression tasks. Particularly, we\nachieve up to 7.2 and 2.9 times FLOPs reduction with the same level of\nevaluation accuracy on VGG16 for CIFAR10 and ResNet50 for ImageNet compared to\nthe baseline heavy models, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 03:03:55 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 06:03:55 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Chen", "Tianyi", ""], ["Ji", "Bo", ""], ["Shi", "Yixin", ""], ["Ding", "Tianyu", ""], ["Fang", "Biyi", ""], ["Yi", "Sheng", ""], ["Tu", "Xiao", ""]]}, {"id": "2011.04907", "submitter": "Paxton Turner", "authors": "Paxton Turner, Jingbo Liu, Philippe Rigollet", "title": "A Statistical Perspective on Coreset Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Coresets have emerged as a powerful tool to summarize data by selecting a\nsmall subset of the original observations while retaining most of its\ninformation. This approach has led to significant computational speedups but\nthe performance of statistical procedures run on coresets is largely\nunexplored. In this work, we develop a statistical framework to study coresets\nand focus on the canonical task of nonparameteric density estimation. Our\ncontributions are twofold. First, we establish the minimax rate of estimation\nachievable by coreset-based estimators. Second, we show that the practical\ncoreset kernel density estimators are near-minimax optimal over a large class\nof H\\\"{o}lder-smooth densities.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 05:18:43 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 21:05:08 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Turner", "Paxton", ""], ["Liu", "Jingbo", ""], ["Rigollet", "Philippe", ""]]}, {"id": "2011.04922", "submitter": "Paxton Turner", "authors": "Paxton Turner, Jingbo Liu, and Philippe Rigollet", "title": "Efficient Interpolation of Density Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of space and time efficient evaluation of a\nnonparametric estimator that approximates an unknown density. In the regime\nwhere consistent estimation is possible, we use a piecewise multivariate\npolynomial interpolation scheme to give a computationally efficient\nconstruction that converts the original estimator to a new estimator that can\nbe queried efficiently and has low space requirements, all without adversely\ndeteriorating the original approximation quality. Our result gives a new\nstatistical perspective on the problem of fast evaluation of kernel density\nestimators in the presence of underlying smoothness. As a corollary, we give a\nsuccinct derivation of a classical result of Kolmogorov---Tikhomirov on the\nmetric entropy of H\\\"{o}lder classes of smooth functions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 06:05:00 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Turner", "Paxton", ""], ["Liu", "Jingbo", ""], ["Rigollet", "Philippe", ""]]}, {"id": "2011.04923", "submitter": "Steve Dias Da Cruz", "authors": "Hans-Peter Beise, Steve Dias Da Cruz", "title": "Expressiveness of Neural Networks Having Width Equal or Below the Input\n  Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding about the minimum width of deep neural networks needed to\nensure universal approximation for different activation functions has\nprogressively been extended (Park et al., 2020). In particular, with respect to\napproximation on general compact sets in the input space, a network width less\nthan or equal to the input dimension excludes universal approximation. In this\nwork, we focus on network functions of width less than or equal to the latter\ncritical bound. We prove that in this regime, the exact fit of partially\nconstant functions on disjoint compact sets is still possible for ReLU network\nfunctions under some conditions on the mutual location of these components. We\nshow that with cosine as activation function, a three layer network of width\none is sufficient to approximate any function on arbitrary finite sets.\nConversely, we prove a maximum principle from which we conclude that for all\ncontinuous and monotonic activation functions, universal approximation of\narbitrary continuous functions is impossible on sets that coincide with the\nboundary of an open set plus an inner point.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 06:06:02 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 12:55:09 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 09:18:18 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Beise", "Hans-Peter", ""], ["Da Cruz", "Steve Dias", ""]]}, {"id": "2011.04998", "submitter": "Lior Kamma", "authors": "Allan Gr{\\o}nlund, Lior Kamma, Kasper Green Larsen", "title": "Margins are Insufficient for Explaining Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Boosting is one of the most successful ideas in machine learning, achieving\ngreat practical performance with little fine-tuning. The success of boosted\nclassifiers is most often attributed to improvements in margins. The focus on\nmargin explanations was pioneered in the seminal work by Schapire et al. (1998)\nand has culminated in the $k$'th margin generalization bound by Gao and Zhou\n(2013), which was recently proved to be near-tight for some data distributions\n(Gronlund et al. 2019). In this work, we first demonstrate that the $k$'th\nmargin bound is inadequate in explaining the performance of state-of-the-art\ngradient boosters. We then explain the short comings of the $k$'th margin bound\nand prove a stronger and more refined margin-based generalization bound for\nboosted classifiers that indeed succeeds in explaining the performance of\nmodern gradient boosters. Finally, we improve upon the recent generalization\nlower bound by Gr{\\o}nlund et al. (2019).\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 09:28:03 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gr\u00f8nlund", "Allan", ""], ["Kamma", "Lior", ""], ["Larsen", "Kasper Green", ""]]}, {"id": "2011.05041", "submitter": "Lac Tran", "authors": "Gia-Lac Tran, Dimitrios Milios, Pietro Michiardi and Maurizio\n  Filippone", "title": "Sparse within Sparse Gaussian Processes using Neighbor Information", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximations to Gaussian processes based on inducing variables, combined\nwith variational inference techniques, enable state-of-the-art sparse\napproaches to infer GPs at scale through mini batch-based learning. In this\nwork, we address one limitation of sparse GPs, which is due to the challenge in\ndealing with a large number of inducing variables without imposing a special\nstructure on the inducing inputs. In particular, we introduce a novel\nhierarchical prior, which imposes sparsity on the set of inducing variables. We\ntreat our model variationally, and we experimentally show considerable\ncomputational gains compared to standard sparse GPs when sparsity on the\ninducing variables is realized considering the nearest inducing inputs of a\nrandom mini-batch of the data. We perform an extensive experimental validation\nthat demonstrates the effectiveness of our approach compared to the\nstate-of-the-art. Our approach enables the possibility to use sparse GPs using\na large number of inducing points without incurring a prohibitive computational\ncost.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 11:07:53 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 00:22:08 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 05:13:14 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Tran", "Gia-Lac", ""], ["Milios", "Dimitrios", ""], ["Michiardi", "Pietro", ""], ["Filippone", "Maurizio", ""]]}, {"id": "2011.05053", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Yingbin Liang", "title": "Sample Complexity Bounds for Two Timescale Value-based Reinforcement\n  Learning Algorithms", "comments": "Submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two timescale stochastic approximation (SA) has been widely used in\nvalue-based reinforcement learning algorithms. In the policy evaluation\nsetting, it can model the linear and nonlinear temporal difference learning\nwith gradient correction (TDC) algorithms as linear SA and nonlinear SA,\nrespectively. In the policy optimization setting, two timescale nonlinear SA\ncan also model the greedy gradient-Q (Greedy-GQ) algorithm. In previous\nstudies, the non-asymptotic analysis of linear TDC and Greedy-GQ has been\nstudied in the Markovian setting, with diminishing or accuracy-dependent\nstepsize. For the nonlinear TDC algorithm, only the asymptotic convergence has\nbeen established. In this paper, we study the non-asymptotic convergence rate\nof two timescale linear and nonlinear TDC and Greedy-GQ under Markovian\nsampling and with accuracy-independent constant stepsize. For linear TDC, we\nprovide a novel non-asymptotic analysis and show that it attains an\n$\\epsilon$-accurate solution with the optimal sample complexity of\n$\\mathcal{O}(\\epsilon^{-1}\\log(1/\\epsilon))$ under a constant stepsize. For\nnonlinear TDC and Greedy-GQ, we show that both algorithms attain\n$\\epsilon$-accurate stationary solution with sample complexity\n$\\mathcal{O}(\\epsilon^{-2})$. It is the first non-asymptotic convergence result\nestablished for nonlinear TDC under Markovian sampling and our result for\nGreedy-GQ outperforms the previous result orderwisely by a factor of\n$\\mathcal{O}(\\epsilon^{-1}\\log(1/\\epsilon))$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 11:36:30 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Xu", "Tengyu", ""], ["Liang", "Yingbin", ""]]}, {"id": "2011.05064", "submitter": "Herman Ho-Man Yau", "authors": "Herman Yau, Chris Russell, Simon Hadfield,", "title": "What Did You Think Would Happen? Explaining Agent Behaviour Through\n  Intended Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel form of explanation for Reinforcement Learning, based\naround the notion of intended outcome. These explanations describe the outcome\nan agent is trying to achieve by its actions. We provide a simple proof that\ngeneral methods for post-hoc explanations of this nature are impossible in\ntraditional reinforcement learning. Rather, the information needed for the\nexplanations must be collected in conjunction with training the agent. We\nderive approaches designed to extract local explanations based on intention for\nseveral variants of Q-function approximation and prove consistency between the\nexplanations and the Q-values learned. We demonstrate our method on multiple\nreinforcement learning problems, and provide code to help researchers\nintrospecting their RL environments and algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:05:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Yau", "Herman", ""], ["Russell", "Chris", ""], ["Hadfield", "Simon", ""]]}, {"id": "2011.05068", "submitter": "Ilmun Kim", "authors": "Ilmun Kim, Aaditya Ramdas", "title": "Dimension-agnostic inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classical asymptotic theory for statistical inference usually involves\ncalibrating a statistic by fixing the dimension $d$ while letting the sample\nsize $n$ increase to infinity. Recently, much effort has been dedicated towards\nunderstanding how these methods behave in high-dimensional settings, where\n$d_n$ and $n$ both increase to infinity together at some prescribed relative\nrate. This often leads to different inference procedures, depending on the\nassumptions about the dimensionality, leaving the practitioner in a bind: given\na dataset with 100 samples in 20 dimensions, should they calibrate by assuming\n$n \\gg d$, or $d_n/n \\approx 0.2$? This paper considers the goal of\ndimension-agnostic inference -- developing methods whose validity does not\ndepend on any assumption on $d_n$. We introduce a new, generic approach that\nuses variational representations of existing test statistics along with sample\nsplitting and self-normalization to produce a new test statistic with a\nGaussian limiting distribution. The resulting statistic can be viewed as a\ncareful modification of degenerate U-statistics, dropping diagonal blocks and\nretaining off-diagonals. We exemplify our technique for a handful of classical\nproblems including one-sample mean and covariance testing. Our tests are shown\nto have minimax rate-optimal power against appropriate local alternatives, and\nwithout explicitly targeting the high-dimensional setting their power is\noptimal up to a $\\sqrt 2$ factor. A hidden advantage is that our proofs are\nsimple and transparent. We end by describing several fruitful open directions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:21:34 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 23:50:28 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Kim", "Ilmun", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2011.05072", "submitter": "Juliette Achddou", "authors": "Juliette Achddou (VALDA), Olivier Capp\\'e (VALDA), Aur\\'elien Garivier\n  (UMPA-ENSL)", "title": "Efficient Algorithms for Stochastic Repeated Second-price Auctions", "comments": null, "journal-ref": "ALT 2021, Mar 2021, Paris, France", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient sequential bidding strategies for repeated auctions is\nan important practical challenge in various marketing tasks. In this setting,\nthe bidding agent obtains information, on both the value of the item at sale\nand the behavior of the other bidders, only when she wins the auction. Standard\nbandit theory does not apply to this problem due to the presence of\naction-dependent censoring. In this work, we consider second-price auctions and\npropose novel, efficient UCB-like algorithms for this task. These algorithms\nare analyzed in the stochastic setting, assuming regularity of the distribution\nof the opponents' bids. We provide regret upper bounds that quantify the\nimprovement over the baseline algorithm proposed in the literature. The\nimprovement is particularly significant in cases when the value of the\nauctioned item is low, yielding a spectacular reduction in the order of the\nworst-case regret. We further provide the first parametric lower bound for this\nproblem that applies to generic UCB-like strategies. As an alternative, we\npropose more explainable strategies which are reminiscent of the Explore Then\nCommit bandit algorithm. We provide a critical analysis of this class of\nstrategies, showing both important advantages and limitations. In particular,\nwe provide a minimax lower bound and propose a nearly minimax-optimal instance\nof this class.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:45:02 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 08:04:20 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Achddou", "Juliette", "", "VALDA"], ["Capp\u00e9", "Olivier", "", "VALDA"], ["Garivier", "Aur\u00e9lien", "", "UMPA-ENSL"]]}, {"id": "2011.05074", "submitter": "Martin Gubri", "authors": "Martin Gubri, Maxime Cordy, Mike Papadakis, Yves Le Traon", "title": "Efficient and Transferable Adversarial Examples from Bayesian Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An established way to improve the transferability of black-box evasion\nattacks is to craft the adversarial examples on a surrogate ensemble model.\nUnfortunately, such methods involve heavy computation costs to train the models\nforming the ensemble. Based on a state-of-the-art Bayesian Neural Network\ntechnique, we propose a new method to efficiently build such surrogates by\nsampling from the posterior distribution of neural network weights during a\nsingle training process. Our experiments on ImageNet and CIFAR-10 show that our\napproach improves the transfer rates of four state-of-the-art attacks\nsignificantly (between 2.5 and 44.4 percentage points), in both\nintra-architecture and inter-architecture cases. On ImageNet, our approach can\nreach 94% of transfer rate while reducing training time from 387 to 136 hours\non our infrastructure, compared to an ensemble of independently trained DNNs.\nFurthermore, our approach can be combined with test-time techniques improving\ntransferability, further increasing their effectiveness by up to 25.1\npercentage points.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:46:52 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 12:33:17 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Gubri", "Martin", ""], ["Cordy", "Maxime", ""], ["Papadakis", "Mike", ""], ["Traon", "Yves Le", ""]]}, {"id": "2011.05097", "submitter": "Manh Tuan Do", "authors": "Manh Tuan Do, Noseong Park, Kijung Shin", "title": "Two-stage Training of Graph Neural Networks for Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks (GNNs) have received massive attention in the field of\nmachine learning on graphs. Inspired by the success of neural networks, a line\nof research has been conducted to train GNNs to deal with various tasks, such\nas node classification, graph classification, and link prediction. In this\nwork, our task of interest is graph classification. Several GNN models have\nbeen proposed and shown great accuracy in this task. However, the question is\nwhether usual training methods fully realize the capacity of the GNN models.\n  In this work, we propose a two-stage training framework based on triplet\nloss. In the first stage, GNN is trained to map each graph to a Euclidean-space\nvector so that graphs of the same class are close while those of different\nclasses are mapped far apart. Once graphs are well-separated based on labels, a\nclassifier is trained to distinguish between different classes. This method is\ngeneric in the sense that it is compatible with any GNN model. By adapting five\nGNN models to our method, we demonstrate the consistent improvement in accuracy\nand utilization of each GNN's allocated capacity over the original training\nmethod of each model up to 5.4\\% points in 12 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 13:47:28 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 05:07:08 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 05:34:15 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Do", "Manh Tuan", ""], ["Park", "Noseong", ""], ["Shin", "Kijung", ""]]}, {"id": "2011.05231", "submitter": "Elliott Gordon-Rodriguez", "authors": "Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, Geoff Pleiss, John P.\n  Cunningham", "title": "Uses and Abuses of the Cross-Entropy Loss: Case Studies in Modern Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning is primarily an experimental science, in which empirical\nadvances occasionally come at the expense of probabilistic rigor. Here we focus\non one such example; namely the use of the categorical cross-entropy loss to\nmodel data that is not strictly categorical, but rather takes values on the\nsimplex. This practice is standard in neural network architectures with label\nsmoothing and actor-mimic reinforcement learning, amongst others. Drawing on\nthe recently discovered continuous-categorical distribution, we propose\nprobabilistically-inspired alternatives to these models, providing an approach\nthat is more principled and theoretically appealing. Through careful\nexperimentation, including an ablation study, we identify the potential for\noutperformance in these models, thereby highlighting the importance of a proper\nprobabilistic treatment, as well as illustrating some of the failure modes\nthereof.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:44:35 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gordon-Rodriguez", "Elliott", ""], ["Loaiza-Ganem", "Gabriel", ""], ["Pleiss", "Geoff", ""], ["Cunningham", "John P.", ""]]}, {"id": "2011.05309", "submitter": "Alexander Ritchie", "authors": "Alexander Ritchie, Laura Balzano, Daniel Kessler, Chandra S. Sripada,\n  Clayton Scott", "title": "Supervised PCA: A Multiobjective Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for supervised principal component analysis (SPCA) aim to incorporate\nlabel information into principal component analysis (PCA), so that the\nextracted features are more useful for a prediction task of interest. Prior\nwork on SPCA has focused primarily on optimizing prediction error, and has\nneglected the value of maximizing variance explained by the extracted features.\nWe propose a new method for SPCA that addresses both of these objectives\njointly, and demonstrate empirically that our approach dominates existing\napproaches, i.e., outperforms them with respect to both prediction error and\nvariation explained. Our approach accommodates arbitrary supervised learning\nlosses and, through a statistical reformulation, provides a novel low-rank\nextension of generalized linear models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:46:58 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 21:15:41 GMT"}, {"version": "v3", "created": "Sat, 13 Mar 2021 18:33:37 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ritchie", "Alexander", ""], ["Balzano", "Laura", ""], ["Kessler", "Daniel", ""], ["Sripada", "Chandra S.", ""], ["Scott", "Clayton", ""]]}, {"id": "2011.05348", "submitter": "Raed Al Kontar", "authors": "Xubo Yue, Maher Nouiehed, Raed Al Kontar", "title": "SALR: Sharpness-aware Learning Rates for Improved Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In an effort to improve generalization in deep learning, we propose SALR: a\nsharpness-aware learning rate update technique designed to recover flat\nminimizers. Our method dynamically updates the learning rate of gradient-based\noptimizers based on the local sharpness of the loss function. This allows\noptimizers to automatically increase learning rates at sharp valleys to\nincrease the chance of escaping them. We demonstrate the effectiveness of SALR\nwhen adopted by various algorithms over a broad range of networks. Our\nexperiments indicate that SALR improves generalization, converges faster, and\ndrives solutions to significantly flatter regions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 19:00:52 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Yue", "Xubo", ""], ["Nouiehed", "Maher", ""], ["Kontar", "Raed Al", ""]]}, {"id": "2011.05381", "submitter": "Guillaume Coqueret", "authors": "Eric Andr\\'e and Guillaume Coqueret", "title": "Dirichlet policies for reinforced factor portfolios", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.MF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article aims to combine factor investing and reinforcement learning\n(RL). The agent learns through sequential random allocations which rely on\nfirms' characteristics. Using Dirichlet distributions as the driving policy, we\nderive closed forms for the policy gradients and analytical properties of the\nperformance measure. This enables the implementation of REINFORCE methods,\nwhich we perform on a large dataset of US equities. Across a large range of\nparametric choices, our result indicates that RL-based portfolios are very\nclose to the equally-weighted (1/N) allocation. This implies that the agent\nlearns to be *agnostic* with regard to factors, which can partly be explained\nby cross-sectional regressions showing a strong time variation in the\nrelationship between returns and firm characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 20:25:41 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 08:25:15 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 13:51:07 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Andr\u00e9", "Eric", ""], ["Coqueret", "Guillaume", ""]]}, {"id": "2011.05476", "submitter": "Seyed Amin Fadaee", "authors": "Seyed Amin Fadaee, Maryam Amir Haeri", "title": "Multi-Label Classification Using Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving classification with graph methods has gained huge popularity in\nrecent years. This is due to the fact that the data can be intuitively modeled\nwith graphs to utilize high level features to aid in solving the classification\nproblem. CULP which is short for Classification Using Link Prediction is a\ngraph-based classifier. This classifier utilizes the graph representation of\nthe data and transforms the problem to that of link prediction where we try to\nfind the link between an unlabeled node and the proper class node for it. CULP\nproved to be highly accurate classifier and it has the power to predict the\nlabels in near constant time. A variant of the classification problem is\nmulti-label classification which tackles this problem for multi-label data\nwhere an instance can have multiple labels associated to it. In this work, we\nextend the CULP algorithm to address this problem. Our proposed extensions\nconveys the powers of CULP and its intuitive representation of the data in to\nthe multi-label domain and in comparison to some of the cutting edge\nmulti-label classifiers, yield competitive results.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 00:20:52 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Fadaee", "Seyed Amin", ""], ["Haeri", "Maryam Amir", ""]]}, {"id": "2011.05493", "submitter": "Muxuan Liang", "authors": "Muxuan Liang, Xiang Zhong, Jaeyoung Park", "title": "Learning a high-dimensional classification rule using auxiliary outcomes", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlated outcomes are common in many practical problems. Based on a\ndecomposition of estimation bias into two types, within-subspace and\nagainst-subspace, we develop a robust approach to estimating the classification\nrule for the outcome of interest with the presence of auxiliary outcomes in\nhigh-dimensional settings. The proposed method includes a pooled estimation\nstep using all outcomes to gain efficiency, and a subsequent calibration step\nusing only the outcome of interest to correct both types of biases. We show\nthat when the pooled estimator has a low estimation error and a sparse\nagainst-subspace bias, the calibrated estimator can achieve a lower estimation\nerror than that when using only the single outcome of interest. An inference\nprocedure for the calibrated estimator is also provided. Simulations and a real\ndata analysis are conducted to justify the superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 01:14:33 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Liang", "Muxuan", ""], ["Zhong", "Xiang", ""], ["Park", "Jaeyoung", ""]]}, {"id": "2011.05507", "submitter": "Chun-Na Li", "authors": "Yan-Ru Guo, Yan-Qin Bai, Chun-Na Li, Lan Bai, Yuan-Hai Shao", "title": "Two-dimensional Bhattacharyya bound linear discriminant analysis with\n  its applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed L2-norm linear discriminant analysis criterion via the\nBhattacharyya error bound estimation (L2BLDA) is an effective improvement of\nlinear discriminant analysis (LDA) for feature extraction. However, L2BLDA is\nonly proposed to cope with vector input samples. When facing with\ntwo-dimensional (2D) inputs, such as images, it will lose some useful\ninformation, since it does not consider intrinsic structure of images. In this\npaper, we extend L2BLDA to a two-dimensional Bhattacharyya bound linear\ndiscriminant analysis (2DBLDA). 2DBLDA maximizes the matrix-based between-class\ndistance which is measured by the weighted pairwise distances of class means\nand meanwhile minimizes the matrix-based within-class distance. The weighting\nconstant between the between-class and within-class terms is determined by the\ninvolved data that makes the proposed 2DBLDA adaptive. In addition, the\ncriterion of 2DBLDA is equivalent to optimizing an upper bound of the\nBhattacharyya error. The construction of 2DBLDA makes it avoid the small sample\nsize problem while also possess robustness, and can be solved through a simple\nstandard eigenvalue decomposition problem. The experimental results on image\nrecognition and face image reconstruction demonstrate the effectiveness of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 01:56:42 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Guo", "Yan-Ru", ""], ["Bai", "Yan-Qin", ""], ["Li", "Chun-Na", ""], ["Bai", "Lan", ""], ["Shao", "Yuan-Hai", ""]]}, {"id": "2011.05601", "submitter": "Katherine Tsai", "authors": "Katherine Tsai, Mladen Kolar, Oluwasanmi Koyejo", "title": "A Nonconvex Framework for Structured Dynamic Covariance Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flexible yet interpretable model for high-dimensional data with\ntime-varying second order statistics, motivated and applied to functional\nneuroimaging data. Motivated by the neuroscience literature, we factorize the\ncovariances into sparse spatial and smooth temporal components. While this\nfactorization results in both parsimony and domain interpretability, the\nresulting estimation problem is nonconvex. To this end, we design a two-stage\noptimization scheme with a carefully tailored spectral initialization, combined\nwith iteratively refined alternating projected gradient descent. We prove a\nlinear convergence rate up to a nontrivial statistical error for the proposed\ndescent scheme and establish sample complexity guarantees for the estimator. We\nfurther quantify the statistical error for the multivariate Gaussian case.\nEmpirical results using simulated and real brain imaging data illustrate that\nour approach outperforms existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 07:09:44 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 19:42:15 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 01:46:08 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Tsai", "Katherine", ""], ["Kolar", "Mladen", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "2011.05625", "submitter": "Guorui Zhou", "authors": "Guorui Zhou, Weijie Bian, Kailun Wu, Lejian Ren, Qi Pi, Yujing Zhang,\n  Can Xiao, Xiang-Rong Sheng, Na Mou, Xinchen Luo, Chi Zhang, Xianjie Qiao,\n  Shiming Xiang, Kun Gai, Xiaoqiang Zhu, Jian Xu", "title": "CAN: Revisiting Feature Co-Action for Click-Through Rate Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of deep learning, recent industrial Click-Through\nRate (CTR) prediction models have made the transition from traditional shallow\napproaches to deep approaches. Deep Neural Networks (DNNs) are known for its\nability to learn non-linear interactions from raw feature automatically,\nhowever, the non-linear feature interaction is learned in an implicit manner.\nThe non-linear interaction may be hard to capture and explicitly model the\n\\textit{co-action} of raw feature is beneficial for CTR prediction.\n\\textit{Co-action} refers to the collective effects of features toward final\nprediction.\n  In this paper, we argue that current CTR models do not fully explore the\npotential of feature co-action. We conduct experiments and show that the effect\nof feature co-action is underestimated seriously. Motivated by our observation,\nwe propose feature Co-Action Network (CAN) to explore the potential of feature\nco-action. The proposed model can efficiently and effectively capture the\nfeature co-action, which improves the model performance while reduce the\nstorage and computation consumption. Experiment results on public and\nindustrial datasets show that CAN outperforms state-of-the-art CTR models by a\nlarge margin. Up to now, CAN has been deployed in the Alibaba display\nadvertisement system, obtaining averaging 12\\% improvement on CTR and 8\\% on\nRPM.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 08:33:07 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zhou", "Guorui", ""], ["Bian", "Weijie", ""], ["Wu", "Kailun", ""], ["Ren", "Lejian", ""], ["Pi", "Qi", ""], ["Zhang", "Yujing", ""], ["Xiao", "Can", ""], ["Sheng", "Xiang-Rong", ""], ["Mou", "Na", ""], ["Luo", "Xinchen", ""], ["Zhang", "Chi", ""], ["Qiao", "Xianjie", ""], ["Xiang", "Shiming", ""], ["Gai", "Kun", ""], ["Zhu", "Xiaoqiang", ""], ["Xu", "Jian", ""]]}, {"id": "2011.05748", "submitter": "Hao Wen", "authors": "Hao Wen, Xiongjie Chen, Georgios Papagiannis, Conghui Hu and Yunpeng\n  Li", "title": "End-To-End Semi-supervised Learning for Differentiable Particle Filters", "comments": "Accepted in ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in incorporating neural networks into particle filters\nprovide the desired flexibility to apply particle filters in large-scale\nreal-world applications. The dynamic and measurement models in this framework\nare learnable through the differentiable implementation of particle filters.\nPast efforts in optimising such models often require the knowledge of true\nstates which can be expensive to obtain or even unavailable in practice. In\nthis paper, in order to reduce the demand for annotated data, we present an\nend-to-end learning objective based upon the maximisation of a\npseudo-likelihood function which can improve the estimation of states when\nlarge portion of true states are unknown. We assess performance of the proposed\nmethod in state estimation tasks in robotics with simulated and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 13:10:11 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 14:15:04 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wen", "Hao", ""], ["Chen", "Xiongjie", ""], ["Papagiannis", "Georgios", ""], ["Hu", "Conghui", ""], ["Li", "Yunpeng", ""]]}, {"id": "2011.05791", "submitter": "Pratik Shah", "authors": "Sambuddha Ghosal and Pratik Shah", "title": "Interpretable and synergistic deep learning for visual explanation and\n  statistical estimations of segmentation of disease features from medical\n  images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) models for disease classification or segmentation from\nmedical images are increasingly trained using transfer learning (TL) from\nunrelated natural world images. However, shortcomings and utility of TL for\nspecialized tasks in the medical imaging domain remain unknown and are based on\nassumptions that increasing training data will improve performance. We report\ndetailed comparisons, rigorous statistical analysis and comparisons of widely\nused DL architecture for binary segmentation after TL with ImageNet\ninitialization (TII-models) with supervised learning with only medical\nimages(LMI-models) of macroscopic optical skin cancer, microscopic prostate\ncore biopsy and Computed Tomography (CT) DICOM images. Through visual\ninspection of TII and LMI model outputs and their Grad-CAM counterparts, our\nresults identify several counter intuitive scenarios where automated\nsegmentation of one tumor by both models or the use of individual segmentation\noutput masks in various combinations from individual models leads to 10%\nincrease in performance. We also report sophisticated ensemble DL strategies\nfor achieving clinical grade medical image segmentation and model explanations\nunder low data regimes. For example; estimating performance, explanations and\nreplicability of LMI and TII models described by us can be used for situations\nin which sparsity promotes better learning. A free GitHub repository of TII and\nLMI models, code and more than 10,000 medical images and their Grad-CAM output\nfrom this study can be used as starting points for advanced computational\nmedicine and DL research for biomedical discovery and applications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:08:17 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Ghosal", "Sambuddha", ""], ["Shah", "Pratik", ""]]}, {"id": "2011.05804", "submitter": "Padraig Corcoran", "authors": "Padraig Corcoran, Bailin Deng", "title": "Regularization of Persistent Homology Gradient Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Persistent homology is a method for computing the topological features\npresent in a given data. Recently, there has been much interest in the\nintegration of persistent homology as a computational step in neural networks\nor deep learning. In order for a given computation to be integrated in such a\nway, the computation in question must be differentiable. Computing the\ngradients of persistent homology is an ill-posed inverse problem with\ninfinitely many solutions. Consequently, it is important to perform\nregularization so that the solution obtained agrees with known priors. In this\nwork we propose a novel method for regularizing persistent homology gradient\ncomputation through the addition of a grouping term. This has the effect of\nhelping to ensure gradients are defined with respect to larger entities and not\nindividual points.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:16:33 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 12:50:13 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Corcoran", "Padraig", ""], ["Deng", "Bailin", ""]]}, {"id": "2011.05824", "submitter": "Philipp Kopper", "authors": "Philipp Kopper, Sebastian P\\\"olsterl, Christian Wachinger, Bernd\n  Bischl, Andreas Bender, David R\\\"ugamer", "title": "Semi-Structured Deep Piecewise Exponential Models", "comments": "8 pages, 3 figures, Accepted at the AAAI spring symposium: Survival\n  Prediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a versatile framework for survival analysis that combines advanced\nconcepts from statistics with deep learning. The presented framework is based\non piecewise exponential models and thereby supports various survival tasks,\nsuch as competing risks and multi-state modeling, and further allows for\nestimation of time-varying effects and time-varying features. To also include\nmultiple data sources and higher-order interaction effects into the model, we\nembed the model class in a neural network and thereby enable the simultaneous\nestimation of both inherently interpretable structured regression inputs as\nwell as deep neural network components which can potentially process additional\nunstructured data sources. A proof of concept is provided by using the\nframework to predict Alzheimer's disease progression based on tabular and 3D\npoint cloud data and applying it to synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:41:19 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 20:28:54 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 13:32:38 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kopper", "Philipp", ""], ["P\u00f6lsterl", "Sebastian", ""], ["Wachinger", "Christian", ""], ["Bischl", "Bernd", ""], ["Bender", "Andreas", ""], ["R\u00fcgamer", "David", ""]]}, {"id": "2011.05836", "submitter": "Maxime Vandegar", "authors": "Maxime Vandegar, Michael Kagan, Antoine Wehenkel, Gilles Louppe", "title": "Neural Empirical Bayes: Source Distribution Estimation and its\n  Applications to Simulation-Based Inference", "comments": "Camera-ready version presented at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ex hep-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit empirical Bayes in the absence of a tractable likelihood function,\nas is typical in scientific domains relying on computer simulations. We\ninvestigate how the empirical Bayesian can make use of neural density\nestimators first to use all noise-corrupted observations to estimate a prior or\nsource distribution over uncorrupted samples, and then to perform\nsingle-observation posterior inference using the fitted source distribution. We\npropose an approach based on the direct maximization of the log-marginal\nlikelihood of the observations, examining both biased and de-biased estimators,\nand comparing to variational approaches. We find that, up to symmetries, a\nneural empirical Bayes approach recovers ground truth source distributions.\nWith the learned source distribution in hand, we show the applicability to\nlikelihood-free inference and examine the quality of the resulting posterior\nestimates. Finally, we demonstrate the applicability of Neural Empirical Bayes\non an inverse problem from collider physics.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:59:34 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 22:26:52 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Vandegar", "Maxime", ""], ["Kagan", "Michael", ""], ["Wehenkel", "Antoine", ""], ["Louppe", "Gilles", ""]]}, {"id": "2011.05869", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Yingbin Liang, Guanghui Lan", "title": "CRPO: A New Approach for Safe Reinforcement Learning with Convergence\n  Guarantee", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In safe reinforcement learning (SRL) problems, an agent explores the\nenvironment to maximize an expected total reward and meanwhile avoids violation\nof certain constraints on a number of expected total costs. In general, such\nSRL problems have nonconvex objective functions subject to multiple nonconvex\nconstraints, and hence are very challenging to solve, particularly to provide a\nglobally optimal policy. Many popular SRL algorithms adopt a primal-dual\nstructure which utilizes the updating of dual variables for satisfying the\nconstraints. In contrast, we propose a primal approach, called\nconstraint-rectified policy optimization (CRPO), which updates the policy\nalternatingly between objective improvement and constraint satisfaction. CRPO\nprovides a primal-type algorithmic framework to solve SRL problems, where each\npolicy update can take any variant of policy optimization step. To demonstrate\nthe theoretical performance of CRPO, we adopt natural policy gradient (NPG) for\neach policy update step and show that CRPO achieves an\n$\\mathcal{O}(1/\\sqrt{T})$ convergence rate to the global optimal policy in the\nconstrained policy set and an $\\mathcal{O}(1/\\sqrt{T})$ error bound on\nconstraint satisfaction. This is the first finite-time analysis of primal SRL\nalgorithms with global optimality guarantee. Our empirical results demonstrate\nthat CRPO can outperform the existing primal-dual baseline algorithms\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:05:14 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 21:24:18 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 04:41:09 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Tengyu", ""], ["Liang", "Yingbin", ""], ["Lan", "Guanghui", ""]]}, {"id": "2011.05885", "submitter": "Xinjian Huang", "authors": "Xinjian Huang and Weiwei Liu and Bo Du", "title": "Matrix Completion with Noise via Leveraged Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many matrix completion methods assume that the data follows the uniform\ndistribution. To address the limitation of this assumption, Chen et al.\n\\cite{Chen20152999} propose to recover the matrix where the data follows the\nspecific biased distribution. Unfortunately, in most real-world applications,\nthe recovery of a data matrix appears to be incomplete, and perhaps even\ncorrupted information. This paper considers the recovery of a low-rank matrix,\nwhere some observed entries are sampled in a \\emph{biased distribution}\nsuitably dependent on \\emph{leverage scores} of a matrix, and some observed\nentries are uniformly corrupted. Our theoretical findings show that we can\nprovably recover an unknown $n\\times n$ matrix of rank $r$ from just about\n$O(nr\\log^2 n)$ entries even when the few observed entries are corrupted with a\nsmall amount of noisy information. Empirical studies verify our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:25:45 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Huang", "Xinjian", ""], ["Liu", "Weiwei", ""], ["Du", "Bo", ""]]}, {"id": "2011.05900", "submitter": "Marta Avalos", "authors": "Marta Avalos-Fernandez and Helene Touchais and Marcela\n  Henriquez-Henriquez", "title": "A decision-making tool to fine-tune abnormal levels in the complete\n  blood count tests", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The complete blood count (CBC) performed by automated hematology analyzers is\none of the most ordered laboratory tests. It is a first-line tool for assessing\na patient's general health status, or diagnosing and monitoring disease\nprogression. When the analysis does not fit an expected setting, technologists\nmanually review a blood smear using a microscope. The International Consensus\nGroup for Hematology Review published in 2005 a set of criteria for reviewing\nCBCs. Commonly, adjustments are locally needed to account for laboratory\nresources and populations characteristics. Our objective is to provide a\ndecision support tool to identify which CBC variables are associated with\nhigher risks of abnormal smear and at which cutoff values. We propose a\ncost-sensitive Lasso-penalized additive logistic regression combined with\nstability selection. Using simulated and real CBC data, we demonstrate that our\ntool correctly identify the true cutoff values, provided that there is enough\navailable data in their neighbourhood.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:47:03 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 16:11:54 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Avalos-Fernandez", "Marta", ""], ["Touchais", "Helene", ""], ["Henriquez-Henriquez", "Marcela", ""]]}, {"id": "2011.05934", "submitter": "Di Wang", "authors": "Di Wang and Marco Gaboardi and Adam Smith and Jinhui Xu", "title": "Empirical Risk Minimization in the Non-interactive Local Model of\n  Differential Privacy", "comments": "Appeared at Journal of Machine Learning Research. The journal version\n  of arXiv:1802.04085, fixed a bug in arXiv:1812.06825", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we study the Empirical Risk Minimization (ERM) problem in the\nnon-interactive Local Differential Privacy (LDP) model. Previous research on\nthis problem \\citep{smith2017interaction} indicates that the sample complexity,\nto achieve error $\\alpha$, needs to be exponentially depending on the\ndimensionality $p$ for general loss functions. In this paper, we make two\nattempts to resolve this issue by investigating conditions on the loss\nfunctions that allow us to remove such a limit. In our first attempt, we show\nthat if the loss function is $(\\infty, T)$-smooth, by using the Bernstein\npolynomial approximation we can avoid the exponential dependency in the term of\n$\\alpha$. We then propose player-efficient algorithms with $1$-bit\ncommunication complexity and $O(1)$ computation cost for each player. The error\nbound of these algorithms is asymptotically the same as the original one. With\nsome additional assumptions, we also give an algorithm which is more efficient\nfor the server. In our second attempt, we show that for any $1$-Lipschitz\ngeneralized linear convex loss function, there is an $(\\epsilon, \\delta)$-LDP\nalgorithm whose sample complexity for achieving error $\\alpha$ is only linear\nin the dimensionality $p$. Our results use a polynomial of inner product\napproximation technique. Finally, motivated by the idea of using polynomial\napproximation and based on different types of polynomial approximations, we\npropose (efficient) non-interactive locally differentially private algorithms\nfor learning the set of k-way marginal queries and the set of smooth queries.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:48:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Di", ""], ["Gaboardi", "Marco", ""], ["Smith", "Adam", ""], ["Xu", "Jinhui", ""]]}, {"id": "2011.05944", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner, Tor Lattimore, Claire Vernade, Csaba Szepesv\\'ari", "title": "Asymptotically Optimal Information-Directed Sampling", "comments": "Accepted at COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and efficient algorithm for stochastic linear bandits\nwith finitely many actions that is asymptotically optimal and (nearly)\nworst-case optimal in finite time. The approach is based on the frequentist\ninformation-directed sampling (IDS) framework, with a surrogate for the\ninformation gain that is informed by the optimization problem that defines the\nasymptotic lower bound. Our analysis sheds light on how IDS balances the\ntrade-off between regret and information and uncovers a surprising connection\nbetween the recently proposed primal-dual methods and the IDS algorithm. We\ndemonstrate empirically that IDS is competitive with UCB in finite-time, and\ncan be significantly better in the asymptotic regime.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:01:59 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 11:45:07 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 13:27:00 GMT"}, {"version": "v4", "created": "Fri, 2 Jul 2021 08:21:07 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kirschner", "Johannes", ""], ["Lattimore", "Tor", ""], ["Vernade", "Claire", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2011.05953", "submitter": "Jeremiah Birrell", "authors": "Jeremiah Birrell, Paul Dupuis, Markos A. Katsoulakis, Yannis Pantazis,\n  Luc Rey-Bellet", "title": "$(f,\\Gamma)$-Divergences: Interpolating between $f$-Divergences and\n  Integral Probability Metrics", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a rigorous and general framework for constructing\ninformation-theoretic divergences that subsume both $f$-divergences and\nintegral probability metrics (IPMs), such as the $1$-Wasserstein distance. We\nprove under which assumptions these divergences, hereafter referred to as\n$(f,\\Gamma)$-divergences, provide a notion of `distance' between probability\nmeasures and show that they can be expressed as a two-stage\nmass-redistribution/mass-transport process. The $(f,\\Gamma)$-divergences\ninherit features from IPMs, such as the ability to compare distributions which\nare not absolutely continuous, as well as from $f$-divergences, namely the\nstrict concavity of their variational representations and the ability to\ncontrol heavy-tailed distributions for particular choices of $f$. When\ncombined, these features establish a divergence with improved properties for\nestimation, statistical learning, and uncertainty quantification applications.\nUsing statistical learning as an example, we demonstrate their advantage in\ntraining generative adversarial networks (GANs) for heavy-tailed,\nnot-absolutely continuous sample distributions and we also show improved\nperformance and stability over gradient-penalized Wasserstein GAN in image\ngeneration.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:17:09 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 19:21:56 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Birrell", "Jeremiah", ""], ["Dupuis", "Paul", ""], ["Katsoulakis", "Markos A.", ""], ["Pantazis", "Yannis", ""], ["Rey-Bellet", "Luc", ""]]}, {"id": "2011.05985", "submitter": "Kamil Adamczewski", "authors": "Kamil Adamczewski, Mijung Park", "title": "Dirichlet Pruning for Neural Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Dirichlet pruning, a novel post-processing technique to\ntransform a large neural network model into a compressed one. Dirichlet pruning\nis a form of structured pruning that assigns the Dirichlet distribution over\neach layer's channels in convolutional layers (or neurons in fully-connected\nlayers) and estimates the parameters of the distribution over these units using\nvariational inference. The learned distribution allows us to remove unimportant\nunits, resulting in a compact architecture containing only crucial features for\na task at hand. The number of newly introduced Dirichlet parameters is only\nlinear in the number of channels, which allows for rapid training, requiring as\nlittle as one epoch to converge. We perform extensive experiments, in\nparticular on larger architectures such as VGG and ResNet (45% and 58%\ncompression rate, respectively) where our method achieves the state-of-the-art\ncompression performance and provides interpretable features as a by-product.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:04:37 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 16:06:04 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 23:37:45 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Adamczewski", "Kamil", ""], ["Park", "Mijung", ""]]}, {"id": "2011.05991", "submitter": "Niall Jeffrey", "authors": "Niall Jeffrey and Benjamin D. Wandelt", "title": "Solving high-dimensional parameter inference: marginal posterior\n  densities & Moment Networks", "comments": "Accepted in the Third Workshop on Machine Learning and the Physical\n  Sciences, NeurIPS 2020, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional probability density estimation for inference suffers from\nthe \"curse of dimensionality\". For many physical inference problems, the full\nposterior distribution is unwieldy and seldom used in practice. Instead, we\npropose direct estimation of lower-dimensional marginal distributions,\nbypassing high-dimensional density estimation or high-dimensional Markov chain\nMonte Carlo (MCMC) sampling. By evaluating the two-dimensional marginal\nposteriors we can unveil the full-dimensional parameter covariance structure.\nWe additionally propose constructing a simple hierarchy of fast neural\nregression models, called Moment Networks, that compute increasing moments of\nany desired lower-dimensional marginal posterior density; these reproduce exact\nresults from analytic posteriors and those obtained from Masked Autoregressive\nFlows. We demonstrate marginal posterior density estimation using\nhigh-dimensional LIGO-like gravitational wave time series and describe\napplications for problems of fundamental cosmology.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:00:00 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Jeffrey", "Niall", ""], ["Wandelt", "Benjamin D.", ""]]}, {"id": "2011.06042", "submitter": "Radoslav Paulen", "authors": "Anwesh Reddy Gottu Mukkula, Michal Mate\\'a\\v{s}, Miroslav Fikar,\n  Radoslav Paulen", "title": "Robust multi-stage model-based design of optimal experiments for\n  nonlinear estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study approaches to robust model-based design of experiments in the\ncontext of maximum-likelihood estimation. These approaches provide\nrobustification of model-based methodologies for the design of optimal\nexperiments by accounting for the effect of the parametric uncertainty. We\nstudy the problem of robust optimal design of experiments in the framework of\nnonlinear least-squares parameter estimation using linearized confidence\nregions. We investigate several well-known robustification frameworks in this\nrespect and propose a novel methodology based on multi-stage robust\noptimization. The proposed methodology aims at problems, where the experiments\nare designed sequentially with a possibility of re-estimation in-between the\nexperiments. The multi-stage formalism aids in identifying experiments that are\nbetter conducted in the early phase of experimentation, where parameter\nknowledge is poor. We demonstrate the findings and effectiveness of the\nproposed methodology using four case studies of varying complexity.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:50:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Mukkula", "Anwesh Reddy Gottu", ""], ["Mate\u00e1\u0161", "Michal", ""], ["Fikar", "Miroslav", ""], ["Paulen", "Radoslav", ""]]}, {"id": "2011.06043", "submitter": "Joshua Tobin Mr.", "authors": "Joshua Tobin, Mimi Zhang", "title": "Clustering of Big Data with Mixed Features", "comments": "22 pages, 9 figures, for associated Python library, see\n  https://pypi.org/project/CPFcluster/ , submitted to SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering large, mixed data is a central problem in data mining. Many\napproaches adopt the idea of k-means, and hence are sensitive to\ninitialisation, detect only spherical clusters, and require a priori the\nunknown number of clusters. We here develop a new clustering algorithm for\nlarge data of mixed type, aiming at improving the applicability and efficiency\nof the peak-finding technique. The improvements are threefold: (1) the new\nalgorithm is applicable to mixed data; (2) the algorithm is capable of\ndetecting outliers and clusters of relatively lower density values; (3) the\nalgorithm is competent at deciding the correct number of clusters. The\ncomputational complexity of the algorithm is greatly reduced by applying a fast\nk-nearest neighbors method and by scaling down to component sets. We present\nexperimental results to verify that our algorithm works well in practice.\nKeywords: Clustering; Big Data; Mixed Attribute; Density Peaks;\nNearest-Neighbor Graph; Conductance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:54:38 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Tobin", "Joshua", ""], ["Zhang", "Mimi", ""]]}, {"id": "2011.06064", "submitter": "Nils M\\\"uller", "authors": "Nils M\\\"uller and Tobias Glasmachers", "title": "Non-local Optimization: Imposing Structure on Optimization Problems by\n  Relaxation", "comments": "19 pages, 1 figure, final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In stochastic optimization, particularly in evolutionary computation and\nreinforcement learning, the optimization of a function $f: \\Omega \\to\n\\mathbb{R}$ is often addressed through optimizing a so-called relaxation\n$\\theta \\in \\Theta \\mapsto \\mathbb{E}_\\theta(f)$ of $f$, where $\\Theta$\nresembles the parameters of a family of probability measures on $\\Omega$. We\ninvestigate the structure of such relaxations by means of measure theory and\nFourier analysis, enabling us to shed light on the success of many associated\nstochastic optimization methods. The main structural traits we derive and that\nallow fast and reliable optimization of relaxations are the consistency of\noptimal values of $f$, Lipschitzness of gradients, and convexity. We emphasize\nsettings where $f$ itself is not differentiable or convex, e.g., in the\npresence of (stochastic) disturbance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 20:45:47 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 15:27:50 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 13:20:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["M\u00fcller", "Nils", ""], ["Glasmachers", "Tobias", ""]]}, {"id": "2011.06186", "submitter": "Yunbei Xu", "authors": "Yunbei Xu, Assaf Zeevi", "title": "Towards Optimal Problem Dependent Generalization Error Bounds in\n  Statistical Learning Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study problem-dependent rates, i.e., generalization errors that scale\nnear-optimally with the variance, the effective loss, or the gradient norms\nevaluated at the \"best hypothesis.\" We introduce a principled framework dubbed\n\"uniform localized convergence,\" and characterize sharp problem-dependent rates\nfor central statistical learning problems. From a methodological viewpoint, our\nframework resolves several fundamental limitations of existing uniform\nconvergence and localization analysis approaches. It also provides improvements\nand some level of unification in the study of localized complexities, one-sided\nuniform inequalities, and sample-based iterative algorithms. In the so-called\n\"slow rate\" regime, we provides the first (moment-penalized) estimator that\nachieves the optimal variance-dependent rate for general \"rich\" classes; we\nalso establish improved loss-dependent rate for standard empirical risk\nminimization. In the \"fast rate\" regime, we establish finite-sample\nproblem-dependent bounds that are comparable to precise asymptotics. In\naddition, we show that iterative algorithms like gradient descent and\nfirst-order Expectation-Maximization can achieve optimal generalization error\nin several representative problems across the areas of non-convex learning,\nstochastic optimization, and learning with missing data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:07:29 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 21:01:35 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 23:01:58 GMT"}, {"version": "v4", "created": "Thu, 24 Dec 2020 03:10:54 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Xu", "Yunbei", ""], ["Zeevi", "Assaf", ""]]}, {"id": "2011.06223", "submitter": "Saurav Prakash", "authors": "Saurav Prakash, Sagar Dhakal, Mustafa Akdeniz, Yair Yona, Shilpa\n  Talwar, Salman Avestimehr, Nageen Himayat", "title": "Coded Computing for Low-Latency Federated Learning over Wireless Edge\n  Networks", "comments": "Final version to appear in the first issue of the IEEE JSAC Series on\n  Machine Learning for Communications and Networks", "journal-ref": null, "doi": "10.1109/JSAC.2020.3036961", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables training a global model from data located at the\nclient nodes, without data sharing and moving client data to a centralized\nserver. Performance of federated learning in a multi-access edge computing\n(MEC) network suffers from slow convergence due to heterogeneity and stochastic\nfluctuations in compute power and communication link qualities across clients.\nWe propose a novel coded computing framework, CodedFedL, that injects\nstructured coding redundancy into federated learning for mitigating stragglers\nand speeding up the training procedure. CodedFedL enables coded computing for\nnon-linear federated learning by efficiently exploiting distributed kernel\nembedding via random Fourier features that transforms the training task into\ncomputationally favourable distributed linear regression. Furthermore, clients\ngenerate local parity datasets by coding over their local datasets, while the\nserver combines them to obtain the global parity dataset. Gradient from the\nglobal parity dataset compensates for straggling gradients during training, and\nthereby speeds up convergence. For minimizing the epoch deadline time at the\nMEC server, we provide a tractable approach for finding the amount of coding\nredundancy and the number of local data points that a client processes during\ntraining, by exploiting the statistical properties of compute as well as\ncommunication delays. We also characterize the leakage in data privacy when\nclients share their local parity datasets with the server. We analyze the\nconvergence rate and iteration complexity of CodedFedL under simplifying\nassumptions, by treating CodedFedL as a stochastic gradient descent algorithm.\nFurthermore, we conduct numerical experiments using practical network\nparameters and benchmark datasets, where CodedFedL speeds up the overall\ntraining time by up to $15\\times$ in comparison to the benchmark schemes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 06:21:59 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 19:46:31 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Prakash", "Saurav", ""], ["Dhakal", "Sagar", ""], ["Akdeniz", "Mustafa", ""], ["Yona", "Yair", ""], ["Talwar", "Shilpa", ""], ["Avestimehr", "Salman", ""], ["Himayat", "Nageen", ""]]}, {"id": "2011.06278", "submitter": "Babacar Mbaye Ndiaye", "authors": "Mouhamed M. Fall, Babacar M. Ndiaye, Ousmane Seydi, Diaraf Seck", "title": "Analysis of COVID-19 evolution in Senegal: impact of health care\n  capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a compartmental model from which we incorporate a time-dependent\nhealth care capacity having a logistic growth. This allows us to take into\naccount the Senegalese authorities response in anticipating the growing number\nof infected cases. We highlight the importance of anticipation and timing to\navoid overwhelming that could impact considerably the treatment of patients and\nthe well-being of health care workers. A condition, depending on the health\ncare capacity and the flux of new hospitalized individuals, to avoid possible\noverwhelming is provided. We also use machine learning approach to project\nforward the cumulative number of cases from March 02, 2020, until 1st December,\n2020.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 09:33:59 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Fall", "Mouhamed M.", ""], ["Ndiaye", "Babacar M.", ""], ["Seydi", "Ousmane", ""], ["Seck", "Diaraf", ""]]}, {"id": "2011.06295", "submitter": "Dominik \\.Zurek", "authors": "Marcin Pietro\\'n Dominik \\.Zurek", "title": "When deep learning models on GPU can be accelerated by taking advantage\n  of unstructured sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is focused on the improvement the efficiency of the sparse\nconvolutional neural networks (CNNs) layers on graphic processing units (GPU).\nThe Nvidia deep neural network (cuDnn) library provides the most effective\nimplementation of deep learning (DL) algorithms for GPUs. GPUs are one of the\nmost efficient and commonly used accelerators for deep learning computations.\nThe modern CNN models need megabytes of coefficients and needed millions MAC\noperations to perform convolution. One of the most common techniques for\ncompressing CNN models is weight pruning. There are two main types of pruning:\nstructural (based on removing whole weight channels) and non-structural\n(removing individual weights). The first enables much easier acceleration, but\nwith this type it is difficult to achieve a sparsity level and accuracy as high\nas that obtained with the second type. Non-structural pruning with retraining\ncan generate a matrix-weight up to $\\sim90\\%$ or more of sparsity in some deep\nCNN models. This work shows when is worth using a direct sparse operation to\nspeed-up the calculation of the convolution layers. The VGG-16, CNN-non-static\nand 1x1 layers from ResNet models were used as a benchmarks. In addition, we\npresent the impact of using reduced precision on time efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:13:48 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 11:26:46 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["\u017burek", "Marcin Pietro\u0144 Dominik", ""]]}, {"id": "2011.06317", "submitter": "Shuai Yang", "authors": "Shuai Yang, Kui Yu, Fuyuan Cao, Lin Liu, Hao Wang, Jiuyong Li", "title": "Learning causal representations for robust domain adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain adaptation solves the learning problem in a target domain by\nleveraging the knowledge in a relevant source domain. While remarkable advances\nhave been made, almost all existing domain adaptation methods heavily require\nlarge amounts of unlabeled target domain data for learning domain invariant\nrepresentations to achieve good generalizability on the target domain. In fact,\nin many real-world applications, target domain data may not always be\navailable. In this paper, we study the cases where at the training phase the\ntarget domain data is unavailable and only well-labeled source domain data is\navailable, called robust domain adaptation. To tackle this problem, under the\nassumption that causal relationships between features and the class variable\nare robust across domains, we propose a novel Causal AutoEncoder (CAE), which\nintegrates deep autoencoder and causal structure learning into a unified model\nto learn causal representations only using data from a single source domain.\nSpecifically, a deep autoencoder model is adopted to learn low-dimensional\nrepresentations, and a causal structure learning model is designed to separate\nthe low-dimensional representations into two groups: causal representations and\ntask-irrelevant representations. Using three real-world datasets the extensive\nexperiments have validated the effectiveness of CAE compared to eleven\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:24:03 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Yang", "Shuai", ""], ["Yu", "Kui", ""], ["Cao", "Fuyuan", ""], ["Liu", "Lin", ""], ["Wang", "Hao", ""], ["Li", "Jiuyong", ""]]}, {"id": "2011.06337", "submitter": "Jong Chul Ye", "authors": "Gyutaek Oh, Jeong Eun Lee, and Jong Chul Ye", "title": "Unsupervised MR Motion Artifact Deep Learning using Outlier-Rejecting\n  Bootstrap Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, deep learning approaches for MR motion artifact correction have\nbeen extensively studied. Although these approaches have shown high performance\nand reduced computational complexity compared to classical methods, most of\nthem require supervised training using paired artifact-free and\nartifact-corrupted images, which may prohibit its use in many important\nclinical applications. For example, transient severe motion (TSM) due to acute\ntransient dyspnea in Gd-EOB-DTPA-enhanced MR is difficult to control and model\nfor paired data generation. To address this issue, here we propose a novel\nunsupervised deep learning scheme through outlier-rejecting bootstrap\nsubsampling and aggregation. This is inspired by the observation that motions\nusually cause sparse k-space outliers in the phase encoding direction, so\nk-space subsampling along the phase encoding direction can remove some outliers\nand the aggregation step can further improve the results from the\nreconstruction network. Our method does not require any paired data because the\ntraining step only requires artifact-free images. Furthermore, to address the\nsmoothing from potential bias to the artifact-free images, the network is\ntrained in an unsupervised manner using optimal transport driven cycleGAN. We\nverify that our method can be applied for artifact correction from simulated\nmotion as well as real motion from TSM successfully, outperforming existing\nstate-of-the-art deep learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:10:58 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Oh", "Gyutaek", ""], ["Lee", "Jeong Eun", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2011.06374", "submitter": "Huan Qing", "authors": "Huan Qing and Jingli Wang", "title": "An improved spectral clustering method for community detection under the\n  degree-corrected stochastic blockmodel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For community detection problem, spectral clustering is a widely used method\nfor detecting clusters in networks. In this paper, we propose an improved\nspectral clustering (ISC) approach under the degree corrected stochastic block\nmodel (DCSBM). ISC is designed based on the k-means clustering algorithm on the\nweighted leading K + 1 eigenvectors of a regularized Laplacian matrix where the\nweights are their corresponding eigenvalues. Theoretical analysis of ISC shows\nthat under mild conditions the ISC yields stable consistent community\ndetection. Numerical results show that ISC outperforms classical spectral\nclustering methods for community detection on both simulated and eight\nempirical networks. Especially, ISC provides a significant improvement on two\nweak signal networks Simmons and Caltech, with error rates of 121/1137 and\n96/590, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 13:35:11 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Qing", "Huan", ""], ["Wang", "Jingli", ""]]}, {"id": "2011.06445", "submitter": "Ren\\'ata N\\'emeth", "authors": "Anna Farkas and Ren\\'ata N\\'emeth", "title": "How to Measure Gender Bias in Machine Translation: Optimal Translators,\n  Multiple Reference Points", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, as a case study, we present a systematic study of gender bias\nin machine translation with Google Translate. We translated sentences\ncontaining names of occupations from Hungarian, a language with gender-neutral\npronouns, into English. Our aim was to present a fair measure for bias by\ncomparing the translations to an optimal non-biased translator. When assessing\nbias, we used the following reference points: (1) the distribution of men and\nwomen among occupations in both the source and the target language countries,\nas well as (2) the results of a Hungarian survey that examined if certain jobs\nare generally perceived as feminine or masculine. We also studied how expanding\nsentences with adjectives referring to occupations effect the gender of the\ntranslated pronouns. As a result, we found bias against both genders, but\nbiased results against women are much more frequent. Translations are closer to\nour perception of occupations than to objective occupational statistics.\nFinally, occupations have a greater effect on translation than adjectives.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 15:39:22 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Farkas", "Anna", ""], ["N\u00e9meth", "Ren\u00e1ta", ""]]}, {"id": "2011.06461", "submitter": "Saptarshi Chakraborty", "authors": "Debolina Paul, Saptarshi Chakraborty, Swagatam Das and Jason Xu", "title": "Kernel k-Means, By All Means: Algorithms and Strong Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel $k$-means clustering is a powerful tool for unsupervised learning of\nnon-linearly separable data. Since the earliest attempts, researchers have\nnoted that such algorithms often become trapped by local minima arising from\nnon-convexity of the underlying objective function. In this paper, we\ngeneralize recent results leveraging a general family of means to combat\nsub-optimal local solutions to the kernel and multi-kernel settings. Called\nKernel Power $k$-Means, our algorithm makes use of majorization-minimization\n(MM) to better solve this non-convex problem. We show the method implicitly\nperforms annealing in kernel feature space while retaining efficient,\nclosed-form updates, and we rigorously characterize its convergence properties\nboth from computational and statistical points of view. In particular, we\ncharacterize the large sample behavior of the proposed method by establishing\nstrong consistency guarantees. Its merits are thoroughly validated on a suite\nof simulated datasets and real data benchmarks that feature non-linear and\nmulti-view separation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:07:18 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Paul", "Debolina", ""], ["Chakraborty", "Saptarshi", ""], ["Das", "Swagatam", ""], ["Xu", "Jason", ""]]}, {"id": "2011.06531", "submitter": "Felix Hensel", "authors": "Sarah C. Br\\\"uningk, Felix Hensel, Catherine R. Jutzeler, Bastian\n  Rieck", "title": "Image analysis for Alzheimer's disease prediction: Embracing\n  pathological hallmarks for model architecture design", "comments": "8 pages, 1 figure, Machine Learning for Health (ML4H) at NeurIPS 2020\n  - Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is associated with local (e.g. brain tissue atrophy)\nand global brain changes (loss of cerebral connectivity), which can be detected\nby high-resolution structural magnetic resonance imaging. Conventionally, these\nchanges and their relation to AD are investigated independently. Here, we\nintroduce a novel, highly-scalable approach that simultaneously captures\n$\\textit{local}$ and $\\textit{global}$ changes in the diseased brain. It is\nbased on a neural network architecture that combines patch-based,\nhigh-resolution 3D-CNNs with global topological features, evaluating\nmulti-scale brain tissue connectivity. Our local-global approach reached\ncompetitive results with an average precision score of $0.95\\pm0.03$ for the\nclassification of cognitively normal subjects and AD patients (prevalence\n$\\approx 55\\%$).\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:42:49 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 13:49:31 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 08:50:41 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Br\u00fcningk", "Sarah C.", ""], ["Hensel", "Felix", ""], ["Jutzeler", "Catherine R.", ""], ["Rieck", "Bastian", ""]]}, {"id": "2011.06550", "submitter": "Elvis Dohmatob", "authors": "Elvis Dohmatob", "title": "Implicit bias of any algorithm: bounding bias via margin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $n$ points $x_1,\\ldots,x_n$ in finite-dimensional euclidean space,\neach having one of two colors. Suppose there exists a separating hyperplane\n(identified with its unit normal vector $w)$ for the points, i.e a hyperplane\nsuch that points of same color lie on the same side of the hyperplane. We\nmeasure the quality of such a hyperplane by its margin $\\gamma(w)$, defined as\nminimum distance between any of the points $x_i$ and the hyperplane. In this\npaper, we prove that the margin function $\\gamma$ satisfies a nonsmooth\nKurdyka-Lojasiewicz inequality with exponent $1/2$. This result has\nfar-reaching consequences. For example, let $\\gamma^{opt}$ be the maximum\npossible margin for the problem and let $w^{opt}$ be the parameter for the\nhyperplane which attains this value. Given any other separating hyperplane with\nparameter $w$, let $d(w):=\\|w-w^{opt}\\|$ be the euclidean distance between $w$\nand $w^{opt}$, also called the bias of $w$. From the previous KL-inequality, we\ndeduce that $(\\gamma^{opt}-\\gamma(w)) / R \\le d(w) \\le\n2\\sqrt{(\\gamma^{opt}-\\gamma(w))/\\gamma^{opt}}$, where $R:=\\max_i \\|x_i\\|$ is\nthe maximum distance of the points $x_i$ from the origin. Consequently, for any\noptimization algorithm (gradient-descent or not), the bias of the iterates\nconverges at least as fast as the square-root of the rate of their convergence\nof the margin. Thus, our work provides a generic tool for analyzing the\nimplicit bias of any algorithm in terms of its margin, in situations where a\nspecialized analysis might not be available: it is sufficient to establish a\ngood rate for converge of the margin, a task which is usually much easier.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:09:46 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 10:52:59 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 18:59:22 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 17:12:06 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Dohmatob", "Elvis", ""]]}, {"id": "2011.06557", "submitter": "Hayden Helm", "authors": "Hayden S. Helm, Ronak D. Mehta, Brandon Duderstadt, Weiwei Yang,\n  Christoper M. White, Ali Geisa, Joshua T. Vogelstein, Carey E. Priebe", "title": "A partition-based similarity for classification distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein we define a measure of similarity between classification distributions\nthat is both principled from the perspective of statistical pattern recognition\nand useful from the perspective of machine learning practitioners. In\nparticular, we propose a novel similarity on classification distributions,\ndubbed task similarity, that quantifies how an optimally-transformed optimal\nrepresentation for a source distribution performs when applied to inference\nrelated to a target distribution. The definition of task similarity allows for\nnatural definitions of adversarial and orthogonal distributions. We highlight\nlimiting properties of representations induced by (universally) consistent\ndecision rules and demonstrate in simulation that an empirical estimate of task\nsimilarity is a function of the decision rule deployed for inference. We\ndemonstrate that for a given target distribution, both transfer efficiency and\nsemantic similarity of candidate source distributions correlate with empirical\ntask similarity.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:21:11 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Helm", "Hayden S.", ""], ["Mehta", "Ronak D.", ""], ["Duderstadt", "Brandon", ""], ["Yang", "Weiwei", ""], ["White", "Christoper M.", ""], ["Geisa", "Ali", ""], ["Vogelstein", "Joshua T.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2011.06706", "submitter": "Youngjoo Cho", "authors": "Youngjoo Cho, Annette M. Molinaro, Chen Hu, and Robert L. Strawderman", "title": "Regression Trees for Cumulative Incidence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of cumulative incidence functions for characterizing the risk of one\ntype of event in the presence of others has become increasingly popular over\nthe past decade. The problems of modeling, estimation and inference have been\ntreated using parametric, nonparametric and semi-parametric methods. Efforts to\ndevelop suitable extensions of machine learning methods, such as regression\ntrees and related ensemble methods, have begun only recently. In this paper, we\ndevelop a novel approach to building regression trees for estimating cumulative\nincidence curves in a competing risks setting. The proposed methods employ\naugmented estimators of the Brier score risk as the primary basis for building\nand pruning trees. The proposed methods are easily implemented using the R\nstatistical software package. Simulation studies demonstrate the utility of our\napproach in the competing risks setting. Data from the Radiation Therapy\nOncology Group (trial 9410) is used to illustrate these new methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 00:37:12 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Cho", "Youngjoo", ""], ["Molinaro", "Annette M.", ""], ["Hu", "Chen", ""], ["Strawderman", "Robert L.", ""]]}, {"id": "2011.06709", "submitter": "David Krueger", "authors": "David Krueger, Jan Leike, Owain Evans, John Salvatier", "title": "Active Reinforcement Learning: Observing Rewards at a Cost", "comments": "Originally appeared at the NeurIPS 2016 \"Future of Interactive\n  Learning Machines (FILM)\" workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active reinforcement learning (ARL) is a variant on reinforcement learning\nwhere the agent does not observe the reward unless it chooses to pay a query\ncost c > 0. The central question of ARL is how to quantify the long-term value\nof reward information. Even in multi-armed bandits, computing the value of this\ninformation is intractable and we have to rely on heuristics. We propose and\nevaluate several heuristic approaches for ARL in multi-armed bandits and\n(tabular) Markov decision processes, and discuss and illustrate some\nchallenging aspects of the ARL problem.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 01:01:13 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 21:47:29 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Krueger", "David", ""], ["Leike", "Jan", ""], ["Evans", "Owain", ""], ["Salvatier", "John", ""]]}, {"id": "2011.06741", "submitter": "Liu Leqi", "authors": "Liu Leqi, Fatma Kilinc-Karzan, Zachary C. Lipton, Alan L. Montgomery", "title": "Rebounding Bandits for Modeling Satiation Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of psychological research shows that enjoyment of many goods is\nsubject to satiation, with short-term satisfaction declining after repeated\nexposures to the same item. Nevertheless, proposed algorithms for powering\nrecommender systems seldom model these dynamics, instead proceeding as though\nuser preferences were fixed in time. In this work, we adopt a multi-armed\nbandit setup, modeling satiation dynamics as a time-invariant linear dynamical\nsystem. In our model, the expected rewards for each arm decline monotonically\nwith consecutive exposures to the same item and rebound towards the initial\nreward whenever that arm is not pulled. We analyze this model, showing that\nwhen the arms exhibit identical deterministic dynamics, our problem is\nequivalent to a specific instance of Max K-Cut. In this case, a greedy policy,\nwhich plays the arms in a cyclic order, is optimal. To handle the case when the\nparameters governing the satiation dynamics can vary across arms, we propose a\nlookahead policy that generalizes the greedy policy. When the satiation\ndynamics are stochastic and governed by different (unknown) parameters, we\npropose an algorithm that first uses offline data to identify an affine\ndynamical system specified by the reward model and then plans using the\nlookahead policy.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 03:17:29 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 15:56:57 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Leqi", "Liu", ""], ["Kilinc-Karzan", "Fatma", ""], ["Lipton", "Zachary C.", ""], ["Montgomery", "Alan L.", ""]]}, {"id": "2011.06794", "submitter": "Gilles Blanchard", "authors": "Hannah Marienwald (TUB), Jean-Baptiste Fermanian (ENS Rennes), Gilles\n  Blanchard (DATASHAPE, LMO, CNRS)", "title": "High-Dimensional Multi-Task Averaging and Application to Kernel Mean\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an improved estimator for the multi-task averaging problem, whose\ngoal is the joint estimation of the means of multiple distributions using\nseparate, independent data sets. The naive approach is to take the empirical\nmean of each data set individually, whereas the proposed method exploits\nsimilarities between tasks, without any related information being known in\nadvance. First, for each data set, similar or neighboring means are determined\nfrom the data by multiple testing. Then each naive estimator is shrunk towards\nthe local average of its neighbors. We prove theoretically that this approach\nprovides a reduction in mean squared error. This improvement can be significant\nwhen the dimension of the input space is large, demonstrating a \"blessing of\ndimensionality\" phenomenon. An application of this approach is the estimation\nof multiple kernel mean embeddings, which plays an important role in many\nmodern applications. The theoretical results are verified on artificial and\nreal world data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 07:31:30 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Marienwald", "Hannah", "", "TUB"], ["Fermanian", "Jean-Baptiste", "", "ENS Rennes"], ["Blanchard", "Gilles", "", "DATASHAPE, LMO, CNRS"]]}, {"id": "2011.06796", "submitter": "Lijing Wang", "authors": "Lijing Wang, Dipanjan Ghosh, Maria Teresa Gonzalez Diaz, Ahmed\n  Farahat, Mahbubul Alam, Chetan Gupta, Jiangzhuo Chen, Madhav Marathe", "title": "Wisdom of the Ensemble: Improving Consistency of Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning classifiers are assisting humans in making decisions and hence\nthe user's trust in these models is of paramount importance. Trust is often a\nfunction of constant behavior. From an AI model perspective it means given the\nsame input the user would expect the same output, especially for correct\noutputs, or in other words consistently correct outputs. This paper studies a\nmodel behavior in the context of periodic retraining of deployed models where\nthe outputs from successive generations of the models might not agree on the\ncorrect labels assigned to the same input. We formally define consistency and\ncorrect-consistency of a learning model. We prove that consistency and\ncorrect-consistency of an ensemble learner is not less than the average\nconsistency and correct-consistency of individual learners and\ncorrect-consistency can be improved with a probability by combining learners\nwith accuracy not less than the average accuracy of ensemble component\nlearners. To validate the theory using three datasets and two state-of-the-art\ndeep learning classifiers we also propose an efficient dynamic snapshot\nensemble method and demonstrate its value.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 07:47:01 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Wang", "Lijing", ""], ["Ghosh", "Dipanjan", ""], ["Diaz", "Maria Teresa Gonzalez", ""], ["Farahat", "Ahmed", ""], ["Alam", "Mahbubul", ""], ["Gupta", "Chetan", ""], ["Chen", "Jiangzhuo", ""], ["Marathe", "Madhav", ""]]}, {"id": "2011.06835", "submitter": "Otmane Sakhi", "authors": "Otmane Sakhi, Louis Faury, Flavian Vasile", "title": "Improving Offline Contextual Bandits with Distributional Robustness", "comments": "In Proceedings of the ACM RecSys Workshop on Reinforcement Learning\n  and Robust Estimators for Recommendation Systems (REVEAL 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper extends the Distributionally Robust Optimization (DRO) approach\nfor offline contextual bandits. Specifically, we leverage this framework to\nintroduce a convex reformulation of the Counterfactual Risk Minimization\nprinciple. Besides relying on convex programs, our approach is compatible with\nstochastic optimization, and can therefore be readily adapted tothe large data\nregime. Our approach relies on the construction of asymptotic confidence\nintervals for offline contextual bandits through the DRO framework. By\nleveraging known asymptotic results of robust estimators, we also show how to\nautomatically calibrate such confidence intervals, which in turn removes the\nburden of hyper-parameter selection for policy optimization. We present\npreliminary empirical results supporting the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 09:52:16 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Sakhi", "Otmane", ""], ["Faury", "Louis", ""], ["Vasile", "Flavian", ""]]}, {"id": "2011.06848", "submitter": "Oleg Szehr", "authors": "Oleg Szehr, Dario Azzimonti, Laura Azzimonti", "title": "An exact kernel framework for spatio-temporal dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A kernel-based framework for spatio-temporal data analysis is introduced that\napplies in situations when the underlying system dynamics are governed by a\ndynamic equation. The key ingredient is a representer theorem that involves\ntime-dependent kernels. Such kernels occur commonly in the expansion of\nsolutions of partial differential equations. The representer theorem is applied\nto find among all solutions of a dynamic equation the one that minimizes the\nerror with given spatio-temporal samples. This is motivated by the fact that\nvery often a differential equation is given a priori (e.g.~by the laws of\nphysics) and a practitioner seeks the best solution that is compatible with her\nnoisy measurements. Our guiding example is the Fokker-Planck equation, which\ndescribes the evolution of density in stochastic diffusion processes. A\nregression and density estimation framework is introduced for spatio-temporal\nmodeling under Fokker-Planck dynamics with initial and boundary conditions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:32:34 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Szehr", "Oleg", ""], ["Azzimonti", "Dario", ""], ["Azzimonti", "Laura", ""]]}, {"id": "2011.06887", "submitter": "Sakshi Arya", "authors": "Anuj Abhishek and Sakshi Arya", "title": "Adaptive estimation of a function from its Exponential Radon Transform\n  in presence of noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a locally adaptive strategy for estimating a\nfunction from its Exponential Radon Transform (ERT) data, without prior\nknowledge of the smoothness of functions that are to be estimated. We build a\nnon-parametric kernel type estimator and show that for a class of functions\ncomprising a wide Sobolev regularity scale, our proposed strategy follows the\nminimax optimal rate up to a $\\log{n}$ factor. We also show that there does not\nexist an optimal adaptive estimator on the Sobolev scale when the pointwise\nrisk is used and in fact the rate achieved by the proposed estimator is the\nadaptive rate of convergence.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 12:54:09 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Abhishek", "Anuj", ""], ["Arya", "Sakshi", ""]]}, {"id": "2011.06964", "submitter": "Micha\\\"el Fanuel", "authors": "Micha\\\"el Fanuel, Joachim Schreurs, Johan A.K. Suykens", "title": "Determinantal Point Processes Implicitly Regularize Semi-parametric\n  Regression Problems", "comments": "26 pages. Extended results. Typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-parametric regression models are used in several applications which\nrequire comprehensibility without sacrificing accuracy. Typical examples are\nspline interpolation in geophysics, or non-linear time series problems, where\nthe system includes a linear and non-linear component. We discuss here the use\nof a finite Determinantal Point Process (DPP) for approximating semi-parametric\nmodels. Recently, Barthelm\\'e, Tremblay, Usevich, and Amblard introduced a\nnovel representation of some finite DPPs. These authors formulated extended\nL-ensembles that can conveniently represent partial-projection DPPs and suggest\ntheir use for optimal interpolation. With the help of this formalism, we derive\na key identity illustrating the implicit regularization effect of determinantal\nsampling for semi-parametric regression and interpolation. Also, a novel\nprojected Nystr\\\"om approximation is defined and used to derive a bound on the\nexpected risk for the corresponding approximation of semi-parametric\nregression. This work naturally extends similar results obtained for kernel\nridge regression.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:22:16 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 13:47:11 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2011.06982", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan, Silas {\\O}rting, Erik B Dam", "title": "Multi-layered tensor networks for image classification", "comments": "Updated version with exact computation costs. 6 pages. Accepted to\n  the First Workshop on Quantum Tensor Networks in Machine Learning. In\n  conjunction with 34th NeurIPS, 2020. Source code at\n  https://github.com/raghavian/mltn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recently introduced locally orderless tensor network (LoTeNet) for\nsupervised image classification uses matrix product state (MPS) operations on\ngrids of transformed image patches. The resulting patch representations are\ncombined back together into the image space and aggregated hierarchically using\nmultiple MPS blocks per layer to obtain the final decision rules. In this work,\nwe propose a non-patch based modification to LoTeNet that performs one MPS\noperation per layer, instead of several patch-level operations. The spatial\ninformation in the input images to MPS blocks at each layer is squeezed into\nthe feature dimension, similar to LoTeNet, to maximise retained spatial\ncorrelation between pixels when images are flattened into 1D vectors. The\nproposed multi-layered tensor network (MLTN) is capable of learning linear\ndecision boundaries in high dimensional spaces in a multi-layered setting,\nwhich results in a reduction in the computation cost compared to LoTeNet\nwithout any degradation in performance.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:01:26 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 11:37:15 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Selvan", "Raghavendra", ""], ["\u00d8rting", "Silas", ""], ["Dam", "Erik B", ""]]}, {"id": "2011.07006", "submitter": "Mohammad Bakhtiari", "authors": "Reza Nasirigerdeh, Mohammad Bakhtiari, Reihaneh Torkzadehmahani,\n  Amirhossein Bayat, Markus List, David B. Blumenthal and Jan Baumbach", "title": "Federated Multi-Mini-Batch: An Efficient Training Approach to Federated\n  Learning in Non-IID Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has faced performance and network communication\nchallenges, especially in the environments where the data is not independent\nand identically distributed (IID) across the clients. To address the former\nchallenge, we introduce the federated-centralized concordance property and show\nthat the federated single-mini-batch training approach can achieve comparable\nperformance as the corresponding centralized training in the Non-IID\nenvironments. To deal with the latter, we present the federated\nmulti-mini-batch approach and illustrate that it can establish a trade-off\nbetween the performance and communication efficiency and outperforms federated\naveraging in the Non-IID settings.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:39:27 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 23:07:12 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nasirigerdeh", "Reza", ""], ["Bakhtiari", "Mohammad", ""], ["Torkzadehmahani", "Reihaneh", ""], ["Bayat", "Amirhossein", ""], ["List", "Markus", ""], ["Blumenthal", "David B.", ""], ["Baumbach", "Jan", ""]]}, {"id": "2011.07016", "submitter": "Riad Akrour", "authors": "Riad Akrour, Asma Atamna, Jan Peters", "title": "Convex Optimization with an Interpolation-based Projection and its\n  Application to Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convex optimizers have known many applications as differentiable layers\nwithin deep neural architectures. One application of these convex layers is to\nproject points into a convex set. However, both forward and backward passes of\nthese convex layers are significantly more expensive to compute than those of a\ntypical neural network. We investigate in this paper whether an inexact, but\ncheaper projection, can drive a descent algorithm to an optimum. Specifically,\nwe propose an interpolation-based projection that is computationally cheap and\neasy to compute given a convex, domain defining, function. We then propose an\noptimization algorithm that follows the gradient of the composition of the\nobjective and the projection and prove its convergence for linear objectives\nand arbitrary convex and Lipschitz domain defining inequality constraints. In\naddition to the theoretical contributions, we demonstrate empirically the\npractical interest of the interpolation projection when used in conjunction\nwith neural networks in a reinforcement learning and a supervised learning\nsetting.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:52:50 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Akrour", "Riad", ""], ["Atamna", "Asma", ""], ["Peters", "Jan", ""]]}, {"id": "2011.07122", "submitter": "Riccardo Grazzi", "authors": "Riccardo Grazzi, Massimiliano Pontil, Saverio Salzo", "title": "Convergence Properties of Stochastic Hypergradients", "comments": "added experiments, a table of notation and some comments. 22 pages", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2021), PMLR 130:3826-3834", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization problems are receiving increasing attention in machine\nlearning as they provide a natural framework for hyperparameter optimization\nand meta-learning. A key step to tackle these problems is the efficient\ncomputation of the gradient of the upper-level objective (hypergradient). In\nthis work, we study stochastic approximation schemes for the hypergradient,\nwhich are important when the lower-level problem is empirical risk minimization\non a large dataset. The method that we propose is a stochastic variant of the\napproximate implicit differentiation approach in (Pedregosa, 2016). We provide\nbounds for the mean square error of the hypergradient approximation, under the\nassumption that the lower-level problem is accessible only through a stochastic\nmapping which is a contraction in expectation. In particular, our main bound is\nagnostic to the choice of the two stochastic solvers employed by the procedure.\nWe provide numerical experiments to support our theoretical analysis and to\nshow the advantage of using stochastic hypergradients in practice.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:50:36 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 10:48:16 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Grazzi", "Riccardo", ""], ["Pontil", "Massimiliano", ""], ["Salzo", "Saverio", ""]]}, {"id": "2011.07142", "submitter": "Alec Koppel", "authors": "Abhishek Chakraborty, Ketan Rajawat, Alec Koppel", "title": "Sparse Representations of Positive Functions via Projected Pseudo-Mirror\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of expected risk minimization when the population\nloss is strongly convex and the target domain of the decision variable is\nrequired to be nonnegative, motivated by the settings of maximum likelihood\nestimation (MLE) and trajectory optimization. We restrict focus to the case\nthat the decision variable belongs to a nonparametric Reproducing Kernel\nHilbert Space (RKHS). To solve it, we consider stochastic mirror descent that\nemploys (i) pseudo-gradients and (ii) projections. Compressive projections are\nexecuted via kernel orthogonal matching pursuit (KOMP), and overcome the fact\nthat the vanilla RKHS parameterization grows unbounded with time. Moreover,\npseudo-gradients are needed, e.g., when stochastic gradients themselves define\nintegrals over unknown quantities that must be evaluated numerically, as in\nestimating the intensity parameter of an inhomogeneous Poisson Process, and\nmulti-class kernel logistic regression with latent multi-kernels. We establish\ntradeoffs between accuracy of convergence in mean and the projection budget\nparameter under constant step-size and compression budget, as well as\nnon-asymptotic bounds on the model complexity. Experiments demonstrate that we\nachieve state-of-the-art accuracy and complexity tradeoffs for inhomogeneous\nPoisson Process intensity estimation and multi-class kernel logistic\nregression.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 21:54:28 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chakraborty", "Abhishek", ""], ["Rajawat", "Ketan", ""], ["Koppel", "Alec", ""]]}, {"id": "2011.07158", "submitter": "Nicolas Schreuder", "authors": "Evgenii Chzhen and Nicolas Schreuder", "title": "An example of prediction which complies with Demographic Parity and\n  equalizes group-wise risks in the context of regression", "comments": "Presented at the NeurIPS 2020 Workshop on Algorithmic Fairness\n  through the Lens of Causality and Interpretability", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(X, S, Y) \\in \\mathbb{R}^p \\times \\{1, 2\\} \\times \\mathbb{R}$ be a\ntriplet following some joint distribution $\\mathbb{P}$ with feature vector $X$,\nsensitive attribute $S$ , and target variable $Y$. The Bayes optimal prediction\n$f^*$ which does not produce Disparate Treatment is defined as $f^*(x) =\n\\mathbb{E}[Y | X = x]$. We provide a non-trivial example of a prediction $x \\to\nf(x)$ which satisfies two common group-fairness notions: Demographic Parity\n\\begin{align} (f(X) | S = 1) &\\stackrel{d}{=} (f(X) | S = 2) \\end{align} and\nEqual Group-Wise Risks \\begin{align}\n  \\mathbb{E}[(f^*(X) - f(X))^2 | S = 1] = \\mathbb{E}[(f^*(X) - f(X))^2 | S =\n2]. \\end{align} To the best of our knowledge this is the first explicit\nconstruction of a non-constant predictor satisfying the above. We discuss\nseveral implications of this result on better understanding of mathematical\nnotions of algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 22:46:05 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chzhen", "Evgenii", ""], ["Schreuder", "Nicolas", ""]]}, {"id": "2011.07218", "submitter": "Mohammad Taha Toghani", "authors": "Mohammad Taha Toghani, Genevera I. Allen", "title": "MP-Boost: Minipatch Boosting via Adaptive Feature and Observation\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting methods are among the best general-purpose and off-the-shelf machine\nlearning approaches, gaining widespread popularity. In this paper, we seek to\ndevelop a boosting method that yields comparable accuracy to popular AdaBoost\nand gradient boosting methods, yet is faster computationally and whose solution\nis more interpretable. We achieve this by developing MP-Boost, an algorithm\nloosely based on AdaBoost that learns by adaptively selecting small subsets of\ninstances and features, or what we term minipatches (MP), at each iteration. By\nsequentially learning on tiny subsets of the data, our approach is\ncomputationally faster than other classic boosting algorithms. Also as it\nprogresses, MP-Boost adaptively learns a probability distribution on the\nfeatures and instances that upweight the most important features and\nchallenging instances, hence adaptively selecting the most relevant minipatches\nfor learning. These learned probability distributions also aid in\ninterpretation of our method. We empirically demonstrate the interpretability,\ncomparative accuracy, and computational time of our approach on a variety of\nbinary classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 04:26:13 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Toghani", "Mohammad Taha", ""], ["Allen", "Genevera I.", ""]]}, {"id": "2011.07248", "submitter": "Thomas Keller", "authors": "T. Anderson Keller, Jorn W.T. Peters, Priyank Jaini, Emiel Hoogeboom,\n  Patrick Forr\\'e, Max Welling", "title": "Self Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient gradient computation of the Jacobian determinant term is a core\nproblem in many machine learning settings, and especially so in the normalizing\nflow framework. Most proposed flow models therefore either restrict to a\nfunction class with easy evaluation of the Jacobian determinant, or an\nefficient estimator thereof. However, these restrictions limit the performance\nof such density models, frequently requiring significant depth to reach desired\nperformance levels. In this work, we propose Self Normalizing Flows, a flexible\nframework for training normalizing flows by replacing expensive terms in the\ngradient by learned approximate inverses at each layer. This reduces the\ncomputational complexity of each layer's exact update from $\\mathcal{O}(D^3)$\nto $\\mathcal{O}(D^2)$, allowing for the training of flow architectures which\nwere otherwise computationally infeasible, while also providing efficient\nsampling. We show experimentally that such models are remarkably stable and\noptimize to similar data likelihood values as their exact gradient\ncounterparts, while training more quickly and surpassing the performance of\nfunctionally constrained counterparts.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 09:51:51 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 12:14:06 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Keller", "T. Anderson", ""], ["Peters", "Jorn W. T.", ""], ["Jaini", "Priyank", ""], ["Hoogeboom", "Emiel", ""], ["Forr\u00e9", "Patrick", ""], ["Welling", "Max", ""]]}, {"id": "2011.07255", "submitter": "Metod Jazbec", "authors": "Metod Jazbec, Michael Pearce, Vincent Fortuin", "title": "Factorized Gaussian Process Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational autoencoders often assume isotropic Gaussian priors and\nmean-field posteriors, hence do not exploit structure in scenarios where we may\nexpect similarity or consistency across latent variables. Gaussian process\nvariational autoencoders alleviate this problem through the use of a latent\nGaussian process, but lead to a cubic inference time complexity. We propose a\nmore scalable extension of these models by leveraging the independence of the\nauxiliary features, which is present in many datasets. Our model factorizes the\nlatent kernel across these features in different dimensions, leading to a\nsignificant speed-up (in theory and practice), while empirically performing\ncomparably to existing non-scalable approaches. Moreover, our approach allows\nfor additional modeling of global latent information and for more general\nextrapolation to unseen input combinations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 10:24:10 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jazbec", "Metod", ""], ["Pearce", "Michael", ""], ["Fortuin", "Vincent", ""]]}, {"id": "2011.07271", "submitter": "Mahdi Boloursaz Mashhadi", "authors": "Mahdi Boloursaz Mashhadi, Nir Shlezinger, Yonina C. Eldar, and Deniz\n  Gunduz", "title": "FedRec: Federated Learning of Universal Receivers over Fading Channels", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless communications is often subject to channel fading. Various\nstatistical models have been proposed to capture the inherent randomness in\nfading, and conventional model-based receiver designs rely on accurate\nknowledge of this underlying distribution, which, in practice, may be complex\nand intractable. In this work, we propose a neural network-based symbol\ndetection technique for downlink fading channels, which is based on the maximum\na-posteriori probability (MAP) detector. To enable training on a diverse\nensemble of fading realizations, we propose a federated training scheme, in\nwhich multiple users collaborate to jointly learn a universal data-driven\ndetector, hence the name FedRec. The performance of the resulting receiver is\nshown to approach the MAP performance in diverse channel conditions without\nrequiring knowledge of the fading statistics, while inducing a substantially\nreduced communication overhead in its training procedure compared to\ncentralized training.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 11:29:55 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 19:31:34 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mashhadi", "Mahdi Boloursaz", ""], ["Shlezinger", "Nir", ""], ["Eldar", "Yonina C.", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2011.07312", "submitter": "Fabian Beigang", "authors": "Fabian Beigang", "title": "Shortcomings of Counterfactual Fairness and a Proposed Modification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I argue that counterfactual fairness does not constitute a\nnecessary condition for an algorithm to be fair, and subsequently suggest how\nthe constraint can be modified in order to remedy this shortcoming. To this\nend, I discuss a hypothetical scenario in which counterfactual fairness and an\nintuitive judgment of fairness come apart. Then, I turn to the question how the\nconcept of discrimination can be explicated in order to examine the\nshortcomings of counterfactual fairness as a necessary condition of algorithmic\nfairness in more detail. I then incorporate the insights of this analysis into\na novel fairness constraint, causal relevance fairness, which is a modification\nof the counterfactual fairness constraint that seems to circumvent its\nshortcomings.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 14:49:51 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Beigang", "Fabian", ""]]}, {"id": "2011.07332", "submitter": "Nihal Acharya Adde", "authors": "Nihal Acharya Adde, Thilo Moshagen", "title": "Classification based on invisible features and thereby finding the\n  effect of tuberculosis vaccine on COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the case of clustered data, an artificial neural network with logcosh loss\nfunction learns the bigger cluster rather than the mean of the two. Even more\nso, the ANN when used for regression of a set-valued function, will learn a\nvalue close to one of the choices, in other words, it learns one branch of the\nset-valued function with high accuracy. This work suggests a method that uses\nartificial neural networks with logcosh loss to find the branches of set-valued\nmappings in parameter-outcome sample sets and classifies the samples according\nto those branches. The method not only classifies the data based on these\nbranches but also provides an accurate prediction for the majority cluster. The\nmethod successfully classifies the data based on an invisible feature. A neural\nnetwork was successfully established to predict the total number of cases, the\nlogarithmic total number of cases, deaths, active cases and other relevant data\nof the coronavirus for each German district from a number of input variables.\nAs it has been speculated that the Tuberculosis vaccine provides protection\nagainst the virus and since East Germany was vaccinated before reunification,\nan attempt was made to classify the Eastern and Western German districts by\nconsidering the vaccine information as an invisible feature.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 16:42:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Adde", "Nihal Acharya", ""], ["Moshagen", "Thilo", ""]]}, {"id": "2011.07365", "submitter": "Arunesh Mittal", "authors": "Arunesh Mittal, Scott Linderman, John Paisley, Paul Sajda", "title": "Bayesian recurrent state space model for rs-fMRI", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a hierarchical Bayesian recurrent state space model for modeling\nswitching network connectivity in resting state fMRI data. Our model allows us\nto uncover shared network patterns across disease conditions. We evaluate our\nmethod on the ADNI2 dataset by inferring latent state patterns corresponding to\naltered neural circuits in individuals with Mild Cognitive Impairment (MCI). In\naddition to states shared across healthy and individuals with MCI, we discover\nlatent states that are predominantly observed in individuals with MCI. Our\nmodel outperforms current state of the art deep learning method on ADNI2\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 18:53:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mittal", "Arunesh", ""], ["Linderman", "Scott", ""], ["Paisley", "John", ""], ["Sajda", "Paul", ""]]}, {"id": "2011.07435", "submitter": "Dan Shiebler", "authors": "Dan Shiebler", "title": "Functorial Manifold Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We adapt previous research on category theory and topological unsupervised\nlearning to develop a functorial perspective on manifold learning. We first\ncharacterize manifold learning algorithms as functors that map pseudometric\nspaces to optimization objectives and factor through hierachical clustering\nfunctors. We then use this characterization to prove refinement bounds on\nmanifold learning loss functions and construct a hierarchy of manifold learning\nalgorithms based on their invariants. We express several popular manifold\nlearning algorithms as functors at different levels of this hierarchy,\nincluding Metric Multidimensional Scaling, IsoMap, and UMAP. Next, we use\ninterleaving distance to study the stability of a broad class of manifold\nlearning algorithms. We present bounds on how closely the embeddings these\nalgorithms produce from noisy data approximate the embeddings they would learn\nfrom noiseless data. Finally, we use our framework to derive a set of novel\nmanifold learning algorithms, which we experimentally demonstrate are\ncompetitive with the state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 02:30:23 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 03:48:38 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 14:45:23 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 14:09:09 GMT"}, {"version": "v5", "created": "Sat, 12 Jun 2021 21:35:14 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Shiebler", "Dan", ""]]}, {"id": "2011.07439", "submitter": "Jincheng Bai", "authors": "Jincheng Bai, Qifan Song, Guang Cheng", "title": "Efficient Variational Inference for Sparse Deep Learning with\n  Theoretical Guarantee", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse deep learning aims to address the challenge of huge storage\nconsumption by deep neural networks, and to recover the sparse structure of\ntarget functions. Although tremendous empirical successes have been achieved,\nmost sparse deep learning algorithms are lacking of theoretical support. On the\nother hand, another line of works have proposed theoretical frameworks that are\ncomputationally infeasible. In this paper, we train sparse deep neural networks\nwith a fully Bayesian treatment under spike-and-slab priors, and develop a set\nof computationally efficient variational inferences via continuous relaxation\nof Bernoulli distribution. The variational posterior contraction rate is\nprovided, which justifies the consistency of the proposed variational Bayes\nmethod. Notably, our empirical results demonstrate that this variational\nprocedure provides uncertainty quantification in terms of Bayesian predictive\ndistribution and is also capable to accomplish consistent variable selection by\ntraining a sparse multi-layer neural network.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 03:27:54 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bai", "Jincheng", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "2011.07451", "submitter": "Baharan Mirzasoleiman", "authors": "Baharan Mirzasoleiman, Kaidi Cao, Jure Leskovec", "title": "Coresets for Robust Training of Neural Networks against Noisy Labels", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks have the capacity to overfit noisy labels frequently\nfound in real-world datasets. Although great progress has been made, existing\ntechniques are limited in providing theoretical guarantees for the performance\nof the neural networks trained with noisy labels. Here we propose a novel\napproach with strong theoretical guarantees for robust training of deep\nnetworks trained with noisy labels. The key idea behind our method is to select\nweighted subsets (coresets) of clean data points that provide an approximately\nlow-rank Jacobian matrix. We then prove that gradient descent applied to the\nsubsets do not overfit the noisy labels. Our extensive experiments corroborate\nour theory and demonstrate that deep networks trained on our subsets achieve a\nsignificantly superior performance compared to state-of-the art, e.g., 6%\nincrease in accuracy on CIFAR-10 with 80% noisy labels, and 7% increase in\naccuracy on mini Webvision.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 04:58:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mirzasoleiman", "Baharan", ""], ["Cao", "Kaidi", ""], ["Leskovec", "Jure", ""]]}, {"id": "2011.07458", "submitter": "Zahra Esmaeilbeig", "authors": "Zahra Esmaeilbeig, Shahin Khobahi, Mojtaba Soltanalian", "title": "Deep-RLS: A Model-Inspired Deep Learning Approach to Nonlinear PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the application of model-based deep learning in\nnonlinear principal component analysis (PCA). Inspired by the deep unfolding\nmethodology, we propose a task-based deep learning approach, referred to as\nDeep-RLS, that unfolds the iterations of the well-known recursive least squares\n(RLS) algorithm into the layers of a deep neural network in order to perform\nnonlinear PCA. In particular, we formulate the nonlinear PCA for the blind\nsource separation (BSS) problem and show through numerical analysis that\nDeep-RLS results in a significant improvement in the accuracy of recovering the\nsource signals in BSS when compared to the traditional RLS algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 06:05:51 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 04:45:01 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Esmaeilbeig", "Zahra", ""], ["Khobahi", "Shahin", ""], ["Soltanalian", "Mojtaba", ""]]}, {"id": "2011.07466", "submitter": "Xin Ding", "authors": "Xin Ding and Yongwei Wang and Zuheng Xu and William J. Welch and Z.\n  Jane Wang", "title": "Continuous Conditional Generative Adversarial Networks for Image\n  Generation: Novel Losses and Label Input Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work proposes the continuous conditional generative adversarial network\n(CcGAN), the first generative model for image generation conditional on\ncontinuous, scalar conditions (termed regression labels). Existing conditional\nGANs (cGANs) are mainly designed for categorical conditions (eg, class labels);\nconditioning on regression labels is mathematically distinct and raises two\nfundamental problems:(P1) Since there may be very few (even zero) real images\nfor some regression labels, minimizing existing empirical versions of cGAN\nlosses (aka empirical cGAN losses) often fails in practice;(P2) Since\nregression labels are scalar and infinitely many, conventional label input\nmethods are not applicable. The proposed CcGAN solves the above problems,\nrespectively, by (S1) reformulating existing empirical cGAN losses to be\nappropriate for the continuous scenario; and (S2) proposing a naive label input\n(NLI) method and an improved label input (ILI) method to incorporate regression\nlabels into the generator and the discriminator. The reformulation in (S1)\nleads to two novel empirical discriminator losses, termed the hard vicinal\ndiscriminator loss (HVDL) and the soft vicinal discriminator loss (SVDL)\nrespectively, and a novel empirical generator loss. The error bounds of a\ndiscriminator trained with HVDL and SVDL are derived under mild assumptions in\nthis work. Two new benchmark datasets (RC-49 and Cell-200) and a novel\nevaluation metric (Sliding Fr\\'echet Inception Distance) are also proposed for\nthis continuous scenario. Our experiments on the Circular 2-D Gaussians, RC-49,\nUTKFace, Cell-200, and Steering Angle datasets show that CcGAN is able to\ngenerate diverse, high-quality samples from the image distribution conditional\non a given regression label. Moreover, in these experiments, CcGAN\nsubstantially outperforms cGAN both visually and quantitatively.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 07:29:41 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 00:05:12 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 22:34:54 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 02:33:02 GMT"}, {"version": "v5", "created": "Sun, 9 May 2021 06:30:47 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ding", "Xin", ""], ["Wang", "Yongwei", ""], ["Xu", "Zuheng", ""], ["Welch", "William J.", ""], ["Wang", "Z. Jane", ""]]}, {"id": "2011.07476", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao, Stefano Ermon", "title": "Right Decisions from Wrong Predictions: A Mechanism Design Alternative\n  to Individual Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision makers often need to rely on imperfect probabilistic forecasts.\nWhile average performance metrics are typically available, it is difficult to\nassess the quality of individual forecasts and the corresponding utilities. To\nconvey confidence about individual predictions to decision-makers, we propose a\ncompensation mechanism ensuring that the forecasted utility matches the\nactually accrued utility. While a naive scheme to compensate decision-makers\nfor prediction errors can be exploited and might not be sustainable in the long\nrun, we propose a mechanism based on fair bets and online learning that\nprovably cannot be exploited. We demonstrate an application showing how\npassengers could confidently optimize individual travel plans based on flight\ndelay probabilities estimated by an airline.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 08:22:39 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 06:03:57 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "2011.07478", "submitter": "Shuai Li", "authors": "Yuxin Wen, Shuai Li, Kui Jia", "title": "Towards Understanding the Regularization of Adversarial Robustness on\n  Neural Networks", "comments": "Published as a conference paper at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adversarial examples has shown that modern Neural Network (NN)\nmodels could be rather fragile. Among the more established techniques to solve\nthe problem, one is to require the model to be {\\it $\\epsilon$-adversarially\nrobust} (AR); that is, to require the model not to change predicted labels when\nany given input examples are perturbed within a certain range. However, it is\nobserved that such methods would lead to standard performance degradation,\ni.e., the degradation on natural examples. In this work, we study the\ndegradation through the regularization perspective. We identify quantities from\ngeneralization analysis of NNs; with the identified quantities we empirically\nfind that AR is achieved by regularizing/biasing NNs towards less confident\nsolutions by making the changes in the feature space (induced by changes in the\ninstance space) of most layers smoother uniformly in all directions; so to a\ncertain extent, it prevents sudden change in prediction w.r.t. perturbations.\nHowever, the end result of such smoothing concentrates samples around decision\nboundaries, resulting in less confident solutions, and leads to worse standard\nperformance. Our studies suggest that one might consider ways that build AR\ninto NNs in a gentler way to avoid the problematic regularization.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 08:32:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wen", "Yuxin", ""], ["Li", "Shuai", ""], ["Jia", "Kui", ""]]}, {"id": "2011.07489", "submitter": "Minh Ha Quang", "authors": "Minh Ha Quang", "title": "Entropic regularization of Wasserstein distance between\n  infinite-dimensional Gaussian measures and Gaussian processes", "comments": "revised version, 88 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the entropic regularization formulation of the\n2-Wasserstein distance on an infinite-dimensional Hilbert space, in particular\nfor the Gaussian setting. We first present the Minimum Mutual Information\nproperty, namely the joint measures of two Gaussian measures on Hilbert space\nwith the smallest mutual information are joint Gaussian measures. This is the\ninfinite-dimensional generalization of the Maximum Entropy property of Gaussian\ndensities on Euclidean space. We then give closed form formulas for the optimal\nentropic transport plan, entropic 2-Wasserstein distance, and Sinkhorn\ndivergence between two Gaussian measures on a Hilbert space, along with the\nfixed point equations for the barycenter of a set of Gaussian measures. Our\nformulations fully exploit the regularization aspect of the entropic\nformulation and are valid both in singular and nonsingular settings. In the\ninfinite-dimensional setting, both the entropic 2-Wasserstein distance and\nSinkhorn divergence are Fr\\'echet differentiable, in contrast to the exact\n2-Wasserstein distance, which is not differentiable. Our Sinkhorn barycenter\nequation is new and always has a unique solution. In contrast, the\nfinite-dimensional barycenter equation for the entropic 2-Wasserstein distance\nfails to generalize to the Hilbert space setting. In the setting of reproducing\nkernel Hilbert spaces (RKHS), our distance formulas are given explicitly in\nterms of the corresponding kernel Gram matrices, providing an interpolation\nbetween the kernel Maximum Mean Discrepancy (MMD) and the kernel 2-Wasserstein\ndistance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 10:03:12 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 02:24:29 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Quang", "Minh Ha", ""]]}, {"id": "2011.07495", "submitter": "Andrija Petrovic", "authors": "Andrija Petrovi\\'c, Mladen Nikoli\\'c, Sandro Radovanovi\\'c, Boris\n  Deliba\\v{s}i\\'c, Milo\\v{s} Jovanovi\\'c", "title": "FAIR: Fair Adversarial Instance Re-weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With growing awareness of societal impact of artificial intelligence,\nfairness has become an important aspect of machine learning algorithms. The\nissue is that human biases towards certain groups of population, defined by\nsensitive features like race and gender, are introduced to the training data\nthrough data collection and labeling. Two important directions of fairness\nensuring research have focused on (i) instance weighting in order to decrease\nthe impact of more biased instances and (ii) adversarial training in order to\nconstruct data representations informative of the target variable, but\nuninformative of the sensitive attributes. In this paper we propose a Fair\nAdversarial Instance Re-weighting (FAIR) method, which uses adversarial\ntraining to learn instance weighting function that ensures fair predictions.\nMerging the two paradigms, it inherits desirable properties from both --\ninterpretability of reweighting and end-to-end trainability of adversarial\ntraining. We propose four different variants of the method and, among other\nthings, demonstrate how the method can be cast in a fully probabilistic\nframework. Additionally, theoretical analysis of FAIR models' properties have\nbeen studied extensively. We compare FAIR models to 7 other related and\nstate-of-the-art models and demonstrate that FAIR is able to achieve a better\ntrade-off between accuracy and unfairness. To the best of our knowledge, this\nis the first model that merges reweighting and adversarial approaches by means\nof a weighting function that can provide interpretable information about\nfairness of individual instances.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 10:48:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Petrovi\u0107", "Andrija", ""], ["Nikoli\u0107", "Mladen", ""], ["Radovanovi\u0107", "Sandro", ""], ["Deliba\u0161i\u0107", "Boris", ""], ["Jovanovi\u0107", "Milo\u0161", ""]]}, {"id": "2011.07530", "submitter": "Kazuhisa Fujita Dr.", "authors": "Kazuhisa Fujita", "title": "Estimation of the number of clusters on d-dimensional sphere", "comments": null, "journal-ref": "Artificial Intelligence Research, 10, 57-63 (2021)", "doi": "10.5430/air.v10n1p57", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical data is distributed on the sphere. The data appears in various\nfields such as meteorology, biology, and natural language processing. However,\na method for analysis of spherical data does not develop enough yet. One of the\nimportant issues is an estimation of the number of clusters in spherical data.\nTo address the issue, I propose a new method called the Spherical X-means\n(SX-means) that can estimate the number of clusters on d-dimensional sphere.\nThe SX-means is the model-based method assuming that the data is generated from\na mixture of von Mises-Fisher distributions. The present paper explains the\nproposed method and shows its performance of estimation of the number of\nclusters.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 13:42:39 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 15:24:47 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Fujita", "Kazuhisa", ""]]}, {"id": "2011.07551", "submitter": "Alexey Kurochkin", "authors": "Alexey Kurochkin", "title": "Discovering long term dependencies in noisy time series data using deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series modelling is essential for solving tasks such as predictive\nmaintenance, quality control and optimisation. Deep learning is widely used for\nsolving such problems. When managing complex manufacturing process with neural\nnetworks, engineers need to know why machine learning model made specific\ndecision and what are possible outcomes of following model recommendation. In\nthis paper we develop framework for capturing and explaining temporal\ndependencies in time series data using deep neural networks and test it on\nvarious synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 15:10:57 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kurochkin", "Alexey", ""]]}, {"id": "2011.07568", "submitter": "Zijian Guo", "authors": "Zijian Guo", "title": "Inference for High-dimensional Maximin Effects in Heterogeneous\n  Regression Models Using a Sampling Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneity is an important feature of modern data sets and a central task\nis to extract information from large-scale and heterogeneous data. In this\npaper, we consider multiple high-dimensional linear models and adopt the\ndefinition of maximin effect (Meinshausen, B{\\\"u}hlmann, AoS, 43(4),\n1801--1830) to summarize the information contained in this heterogeneous model.\nWe define the maximin effect for a targeted population whose covariate\ndistribution is possibly different from that of the observed data. We further\nintroduce a ridge-type maximin effect to simultaneously account for reward\noptimality and statistical stability. To identify the high-dimensional maximin\neffect, we estimate the regression covariance matrix by a debiased estimator\nand use it to construct the aggregation weights for the maximin effect. A main\nchallenge for statistical inference is that the estimated weights might have a\nmixture distribution and the resulted maximin effect estimator is not\nnecessarily asymptotic normal. To address this, we devise a novel sampling\napproach to construct the confidence interval for any linear contrast of\nhigh-dimensional maximin effects. The coverage and precision properties of the\nproposed confidence interval are studied. The proposed method is demonstrated\nover simulations and a genetic data set on yeast colony growth under different\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 16:15:10 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 10:50:51 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Guo", "Zijian", ""]]}, {"id": "2011.07595", "submitter": "Kushal Chakrabarti", "authors": "Kushal Chakrabarti, Nirupam Gupta and Nikhil Chopra", "title": "Accelerating Distributed SGD for Linear Regression using Iterative\n  Pre-Conditioning", "comments": "Changes in the replacement: Application to distributed state\n  estimation problem has been added in Appendix B. Related articles:\n  arXiv:2003.07180v2 [math.OC] and arXiv:2008.02856v1 [math.OC]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the multi-agent distributed linear least-squares\nproblem. The system comprises multiple agents, each agent with a locally\nobserved set of data points, and a common server with whom the agents can\ninteract. The agents' goal is to compute a linear model that best fits the\ncollective data points observed by all the agents. In the server-based\ndistributed settings, the server cannot access the data points held by the\nagents. The recently proposed Iteratively Pre-conditioned Gradient-descent\n(IPG) method has been shown to converge faster than other existing distributed\nalgorithms that solve this problem. In the IPG algorithm, the server and the\nagents perform numerous iterative computations. Each of these iterations relies\non the entire batch of data points observed by the agents for updating the\ncurrent estimate of the solution. Here, we extend the idea of iterative\npre-conditioning to the stochastic settings, where the server updates the\nestimate and the iterative pre-conditioning matrix based on a single randomly\nselected data point at every iteration. We show that our proposed Iteratively\nPre-conditioned Stochastic Gradient-descent (IPSG) method converges linearly in\nexpectation to a proximity of the solution. Importantly, we empirically show\nthat the proposed IPSG method's convergence rate compares favorably to\nprominent stochastic algorithms for solving the linear least-squares problem in\nserver-based networks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 18:09:13 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 08:05:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chakrabarti", "Kushal", ""], ["Gupta", "Nirupam", ""], ["Chopra", "Nikhil", ""]]}, {"id": "2011.07607", "submitter": "Uri Shaham", "authors": "Uri Shaham, Jonathan Svirsky", "title": "Deep Ordinal Regression using Optimal Transport Loss and Unimodal Output\n  Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for deep ordinal regression, based on unimodal output\ndistribution and optimal transport loss. Despite being seemingly appropriate,\nin many recent works the unimodality requirement is either absent, or\nimplemented using soft targets, which do not guarantee unimodal outputs at\ninference. In addition, we argue that the standard maximum likelihood objective\nis not suitable for ordinal regression problems, and that optimal transport is\nbetter suited for this task, as it naturally captures the order of the classes.\nInspired by the well-known Proportional Odds model, we propose to modify its\ndesign by using an architectural mechanism which guarantees that the model\noutput distribution will be unimodal. We empirically analyze the different\ncomponents of our propose approach and demonstrate their contribution to the\nperformance of the model. Experimental results on three real-world datasets\ndemonstrate that our proposed approach performs on par with several recently\nproposed deep learning approaches for deep ordinal regression with unimodal\noutput probabilities, while having guarantee on the output unimodality. In\naddition, we demonstrate that the level of prediction uncertainty of the model\ncorrelates with its accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 19:19:40 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Shaham", "Uri", ""], ["Svirsky", "Jonathan", ""]]}, {"id": "2011.07614", "submitter": "Paul Roediger", "authors": "Paul A. Roediger", "title": "A Picture's Worth a Thousand Words: Visualizing n-dimensional Overlap in\n  Logistic Regression Models with Empirical Likelihood", "comments": "Contains 1 pdf file consisting of 22 pages, 12 tables, 10 figures,\n  and 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note, conditions for the existence and uniqueness of the maximum\nlikelihood estimate for multidimensional predictor, binary response models are\nintroduced from a sensitivity testing point of view. The well known condition\nof Silvapulle is translated to be an empirical likelihood maximization which,\nwith existing R code, mechanizes the process of assessing overlap status. The\ntranslation shifts the meaning of overlap, defined by geometrical properties of\nthe two-predictor groups, from the intersection of their convex cones is\nnon-empty to the more understandable requirement that the convex hull of their\ndifferences contains zero. The code is applied to reveal the character of\noverlap by examining minimal overlapping structures and cataloging them in\ndimensions fewer than four. Rules to generate minimal higher dimensional\nstructures which account for overlap are provided. Supplementary materials are\navailable online.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 19:39:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Roediger", "Paul A.", ""]]}, {"id": "2011.07640", "submitter": "Jiaju Miao", "authors": "Jiaju Miao, Wei Zhu", "title": "Precision-Recall Curve (PRC) Classification Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of imbalanced data has presented a significant challenge\nfor most well-known classification algorithms that were often designed for data\nwith relatively balanced class distributions. Nevertheless skewed class\ndistribution is a common feature in real world problems. It is especially\nprevalent in certain application domains with great need for machine learning\nand better predictive analysis such as disease diagnosis, fraud detection,\nbankruptcy prediction, and suspect identification. In this paper, we propose a\nnovel tree-based algorithm based on the area under the precision-recall curve\n(AUPRC) for variable selection in the classification context. Our algorithm,\nnamed as the \"Precision-Recall Curve classification tree\", or simply the \"PRC\nclassification tree\" modifies two crucial stages in tree building. The first\nstage is to maximize the area under the precision-recall curve in node variable\nselection. The second stage is to maximize the harmonic mean of recall and\nprecision (F-measure) for threshold selection. We found the proposed PRC\nclassification tree, and its subsequent extension, the PRC random forest, work\nwell especially for class-imbalanced data sets. We have demonstrated that our\nmethods outperform their classic counterparts, the usual CART and random forest\nfor both synthetic and real data. Furthermore, the ROC classification tree\nproposed by our group previously has shown good performance in imbalanced data.\nThe combination of them, the PRC-ROC tree, also shows great promise in\nidentifying the minority class.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 22:31:06 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Miao", "Jiaju", ""], ["Zhu", "Wei", ""]]}, {"id": "2011.07683", "submitter": "Deepak Maurya Mr", "authors": "Deepak Maurya and Balaraman Ravindran", "title": "Hypergraph Partitioning using Tensor Eigenvalue Decomposition", "comments": "22 pages with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hypergraphs have gained increasing attention in the machine learning\ncommunity lately due to their superiority over graphs in capturing super-dyadic\ninteractions among entities. In this work, we propose a novel approach for the\npartitioning of k-uniform hypergraphs. Most of the existing methods work by\nreducing the hypergraph to a graph followed by applying standard graph\npartitioning algorithms. The reduction step restricts the algorithms to\ncapturing only some weighted pairwise interactions and hence loses essential\ninformation about the original hypergraph. We overcome this issue by utilizing\nthe tensor-based representation of hypergraphs, which enables us to capture\nactual super-dyadic interactions. We prove that the hypergraph to graph\nreduction is a special case of tensor contraction. We extend the notion of\nminimum ratio-cut and normalized-cut from graphs to hypergraphs and show the\nrelaxed optimization problem is equivalent to tensor eigenvalue decomposition.\nThis novel formulation also enables us to capture different ways of cutting a\nhyperedge, unlike the existing reduction approaches. We propose a hypergraph\npartitioning algorithm inspired from spectral graph theory that can accommodate\nthis notion of hyperedge cuts. We also derive a tighter upper bound on the\nminimum positive eigenvalue of even-order hypergraph Laplacian tensor in terms\nof its conductance, which is utilized in the partitioning algorithm to\napproximate the normalized cut. The efficacy of the proposed method is\ndemonstrated numerically on simple hypergraphs. We also show improvement for\nthe min-cut solution on 2-uniform hypergraphs (graphs) over the standard\nspectral partitioning algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:55:43 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Maurya", "Deepak", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "2011.07687", "submitter": "Mridul Agarwal", "authors": "Mridul Agarwal, Vaneet Aggarwal, Christopher J. Quinn, Abhishek\n  Umrawal", "title": "DART: aDaptive Accept RejecT for non-linear top-K subset identification", "comments": null, "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the bandit problem of selecting $K$ out of $N$ arms at each time\nstep. The reward can be a non-linear function of the rewards of the selected\nindividual arms. The direct use of a multi-armed bandit algorithm requires\nchoosing among $\\binom{N}{K}$ options, making the action space large. To\nsimplify the problem, existing works on combinatorial bandits {typically}\nassume feedback as a linear function of individual rewards. In this paper, we\nprove the lower bound for top-$K$ subset selection with bandit feedback with\npossibly correlated rewards. We present a novel algorithm for the combinatorial\nsetting without using individual arm feedback or requiring linearity of the\nreward function. Additionally, our algorithm works on correlated rewards of\nindividual arms. Our algorithm, aDaptive Accept RejecT (DART), sequentially\nfinds good arms and eliminates bad arms based on confidence bounds. DART is\ncomputationally efficient and uses storage linear in $N$. Further, DART\nachieves a regret bound of $\\tilde{\\mathcal{O}}(K\\sqrt{KNT})$ for a time\nhorizon $T$, which matches the lower bound in bandit feedback up to a factor of\n$\\sqrt{\\log{2NT}}$. When applied to the problem of cross-selling optimization\nand maximizing the mean of individual rewards, the performance of the proposed\nalgorithm surpasses that of state-of-the-art algorithms. We also show that DART\nsignificantly outperforms existing methods for both linear and non-linear joint\nreward environments.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 02:10:06 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""], ["Quinn", "Christopher J.", ""], ["Umrawal", "Abhishek", ""]]}, {"id": "2011.07720", "submitter": "Udari Madhushani", "authors": "Udari Madhushani and Naomi Ehrich Leonard", "title": "Distributed Bandits: Probabilistic Communication on $d$-regular Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the decentralized multi-agent multi-armed bandit problem for agents\nthat communicate with probability over a network defined by a $d$-regular\ngraph. Every edge in the graph has probabilistic weight $p$ to account for the\n($1\\!-\\!p$) probability of a communication link failure. At each time step,\neach agent chooses an arm and receives a numerical reward associated with the\nchosen arm. After each choice, each agent observes the last obtained reward of\neach of its neighbors with probability $p$. We propose a new Upper Confidence\nBound (UCB) based algorithm and analyze how agent-based strategies contribute\nto minimizing group regret in this probabilistic communication setting. We\nprovide theoretical guarantees that our algorithm outperforms state-of-the-art\nalgorithms. We illustrate our results and validate the theoretical claims using\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 04:53:54 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Madhushani", "Udari", ""], ["Leonard", "Naomi Ehrich", ""]]}, {"id": "2011.07721", "submitter": "Sanjay Chaudhuri", "authors": "Sanjay Chaudhuri and Subhroshekhar Ghosh and David J. Nott and Kim Cuc\n  Pham", "title": "On a Variational Approximation based Empirical Likelihood ABC Method", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.01675", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientifically well-motivated statistical models in natural,\nengineering, and environmental sciences are specified through a generative\nprocess. However, in some cases, it may not be possible to write down the\nlikelihood for these models analytically. Approximate Bayesian computation\n(ABC) methods allow Bayesian inference in such situations. The procedures are\nnonetheless typically computationally intensive. Recently, computationally\nattractive empirical likelihood-based ABC methods have been suggested in the\nliterature. All of these methods rely on the availability of several suitable\nanalytically tractable estimating equations, and this is sometimes problematic.\nWe propose an easy-to-use empirical likelihood ABC method in this article.\nFirst, by using a variational approximation argument as a motivation, we show\nthat the target log-posterior can be approximated as a sum of an expected joint\nlog-likelihood and the differential entropy of the data generating density. The\nexpected log-likelihood is then estimated by an empirical likelihood where the\nonly inputs required are a choice of summary statistic, it's observed value,\nand the ability to simulate the chosen summary statistics for any parameter\nvalue under the model. The differential entropy is estimated from the simulated\nsummaries using traditional methods. Posterior consistency is established for\nthe method, and we discuss the bounds for the required number of simulated\nsummaries in detail. The performance of the proposed method is explored in\nvarious examples.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 21:24:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chaudhuri", "Sanjay", ""], ["Ghosh", "Subhroshekhar", ""], ["Nott", "David J.", ""], ["Pham", "Kim Cuc", ""]]}, {"id": "2011.07729", "submitter": "Christos Thrampoulidis", "authors": "Christos Thrampoulidis, Samet Oymak, Mahdi Soltanolkotabi", "title": "Theoretical Insights Into Multiclass Classification: A High-dimensional\n  Asymptotic View", "comments": "To Appear at NeurIPS 2020. 62 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Contemporary machine learning applications often involve classification tasks\nwith many classes. Despite their extensive use, a precise understanding of the\nstatistical properties and behavior of classification algorithms is still\nmissing, especially in modern regimes where the number of classes is rather\nlarge. In this paper, we take a step in this direction by providing the first\nasymptotically precise analysis of linear multiclass classification. Our\ntheoretical analysis allows us to precisely characterize how the test error\nvaries over different training algorithms, data distributions, problem\ndimensions as well as number of classes, inter/intra class correlations and\nclass priors. Specifically, our analysis reveals that the classification\naccuracy is highly distribution-dependent with different algorithms achieving\noptimal performance for different data distributions and/or training/features\nsizes. Unlike linear regression/binary classification, the test error in\nmulticlass classification relies on intricate functions of the trained model\n(e.g., correlation between some of the trained weights) whose asymptotic\nbehavior is difficult to characterize. This challenge is already present in\nsimple classifiers, such as those minimizing a square loss. Our novel\ntheoretical techniques allow us to overcome some of these challenges. The\ninsights gained may pave the way for a precise understanding of other\nclassification algorithms beyond those studied in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 05:17:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Thrampoulidis", "Christos", ""], ["Oymak", "Samet", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2011.07770", "submitter": "Min Yang", "authors": "Yufeng Wang, Dan Li, Xiang Li, Min Yang", "title": "PC-GAIN: Pseudo-label Conditional Generative Adversarial Imputation\n  Networks for Incomplete Data", "comments": "18pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets with missing values are very common in real world applications.\nGAIN, a recently proposed deep generative model for missing data imputation,\nhas been proved to outperform many state-of-the-art methods. But GAIN only uses\na reconstruction loss in the generator to minimize the imputation error of the\nnon-missing part, ignoring the potential category information which can reflect\nthe relationship between samples. In this paper, we propose a novel\nunsupervised missing data imputation method named PC-GAIN, which utilizes\npotential category information to further enhance the imputation power.\nSpecifically, we first propose a pre-training procedure to learn potential\ncategory information contained in a subset of low-missing-rate data. Then an\nauxiliary classifier is determined using the synthetic pseudo-labels. Further,\nthis classifier is incorporated into the generative adversarial framework to\nhelp the generator to yield higher quality imputation results. The proposed\nmethod can improve the imputation quality of GAIN significantly. Experimental\nresults on various benchmark datasets show that our method is also superior to\nother baseline approaches. Our code is available at\n\\url{https://github.com/WYu-Feng/pc-gain}.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 08:08:26 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 08:41:36 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wang", "Yufeng", ""], ["Li", "Dan", ""], ["Li", "Xiang", ""], ["Yang", "Min", ""]]}, {"id": "2011.07805", "submitter": "Guoqiang Wu", "authors": "Guoqiang Wu, Jun Zhu", "title": "Multi-label classification: do Hamming loss and subset accuracy really\n  conflict with each other?", "comments": "To Appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various evaluation measures have been developed for multi-label\nclassification, including Hamming Loss (HL), Subset Accuracy (SA) and Ranking\nLoss (RL). However, there is a gap between empirical results and the existing\ntheories: 1) an algorithm often empirically performs well on some measure(s)\nwhile poorly on others, while a formal theoretical analysis is lacking; and 2)\nin small label space cases, the algorithms optimizing HL often have comparable\nor even better performance on the SA measure than those optimizing SA directly,\nwhile existing theoretical results show that SA and HL are conflicting\nmeasures. This paper provides an attempt to fill up this gap by analyzing the\nlearning guarantees of the corresponding learning algorithms on both SA and HL\nmeasures. We show that when a learning algorithm optimizes HL with its\nsurrogate loss, it enjoys an error bound for the HL measure independent of $c$\n(the number of labels), while the bound for the SA measure depends on at most\n$O(c)$. On the other hand, when directly optimizing SA with its surrogate loss,\nit has learning guarantees that depend on $O(\\sqrt{c})$ for both HL and SA\nmeasures. This explains the observation that when the label space is not large,\noptimizing HL with its surrogate loss can have promising performance for SA. We\nfurther show that our techniques are applicable to analyze the learning\nguarantees of algorithms on other measures, such as RL. Finally, the\ntheoretical analyses are supported by experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 09:13:16 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wu", "Guoqiang", ""], ["Zhu", "Jun", ""]]}, {"id": "2011.07835", "submitter": "Bhagyashree Puranik", "authors": "Bhagyashree Puranik, Upamanyu Madhow, Ramtin Pedarsani", "title": "Adversarially Robust Classification based on GLRT", "comments": "Submitted to the International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial attacks that can often\ncause misclassification by introducing small but well designed perturbations.\nIn this paper, we explore, in the setting of classical composite hypothesis\ntesting, a defense strategy based on the generalized likelihood ratio test\n(GLRT), which jointly estimates the class of interest and the adversarial\nperturbation. We evaluate the GLRT approach for the special case of binary\nhypothesis testing in white Gaussian noise under $\\ell_{\\infty}$ norm-bounded\nadversarial perturbations, a setting for which a minimax strategy optimizing\nfor the worst-case attack is known. We show that the GLRT approach yields\nperformance competitive with that of the minimax approach under the worst-case\nattack, and observe that it yields a better robustness-accuracy trade-off under\nweaker attacks, depending on the values of signal components relative to the\nattack budget. We also observe that the GLRT defense generalizes naturally to\nmore complex models for which optimal minimax classifiers are not known.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 10:16:05 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Puranik", "Bhagyashree", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "2011.07866", "submitter": "Benjamin Guedj", "authors": "Arthur Leroy and Pierre Latouche and Benjamin Guedj and Servane Gey", "title": "Cluster-Specific Predictions with Multi-Task Gaussian Processes", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A model involving Gaussian processes (GPs) is introduced to simultaneously\nhandle multi-task learning, clustering, and prediction for multiple functional\ndata. This procedure acts as a model-based clustering method for functional\ndata as well as a learning step for subsequent predictions for new tasks. The\nmodel is instantiated as a mixture of multi-task GPs with common mean\nprocesses. A variational EM algorithm is derived for dealing with the\noptimisation of the hyper-parameters along with the hyper-posteriors'\nestimation of latent variables and processes. We establish explicit formulas\nfor integrating the mean processes and the latent clustering variables within a\npredictive distribution, accounting for uncertainty on both aspects. This\ndistribution is defined as a mixture of cluster-specific GP predictions, which\nenhances the performances when dealing with group-structured data. The model\nhandles irregular grid of observations and offers different hypotheses on the\ncovariance structure for sharing additional information across tasks. The\nperformances on both clustering and prediction tasks are assessed through\nvarious simulated scenarios and real datasets. The overall algorithm, called\nMagmaClust, is publicly available as an R package.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:08:59 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 13:45:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Leroy", "Arthur", ""], ["Latouche", "Pierre", ""], ["Guedj", "Benjamin", ""], ["Gey", "Servane", ""]]}, {"id": "2011.07876", "submitter": "Marco Huber", "authors": "Nadia Burkart and Marco F. Huber", "title": "A Survey on the Explainability of Supervised Machine Learning", "comments": "Accepted for publication at the Journal of Artificial Intelligence\n  Research (JAIR)", "journal-ref": "Journal of Artificial Intelligence Research (JAIR), 70:245-317,\n  2021", "doi": "10.1613/jair.1.12228", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions obtained by, e.g., artificial neural networks have a high\naccuracy but humans often perceive the models as black boxes. Insights about\nthe decision making are mostly opaque for humans. Particularly understanding\nthe decision making in highly sensitive areas such as healthcare or fifinance,\nis of paramount importance. The decision-making behind the black boxes requires\nit to be more transparent, accountable, and understandable for humans. This\nsurvey paper provides essential definitions, an overview of the different\nprinciples and methodologies of explainable Supervised Machine Learning (SML).\nWe conduct a state-of-the-art survey that reviews past and recent explainable\nSML approaches and classifies them according to the introduced definitions.\nFinally, we illustrate principles by means of an explanatory case study and\ndiscuss important future directions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:25:39 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Burkart", "Nadia", ""], ["Huber", "Marco F.", ""]]}, {"id": "2011.07932", "submitter": "Siyeong Lee", "authors": "Kwanghee Choi and Siyeong Lee", "title": "Regularized Mutual Information Neural Estimation", "comments": "18 pages, 15 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the variational lower bound of mutual information (MI), the estimation\nof MI can be understood as an optimization task via stochastic gradient\ndescent. In this work, we start by showing how Mutual Information Neural\nEstimator (MINE) searches for the optimal function $T$ that maximizes the\nDonsker-Varadhan representation. With our synthetic dataset, we directly\nobserve the neural network outputs during the optimization to investigate why\nMINE succeeds or fails: We discover the drifting phenomenon, where the constant\nterm of $T$ is shifting through the optimization process, and analyze the\ninstability caused by the interaction between the $logsumexp$ and the\ninsufficient batch size. Next, through theoretical and experimental evidence,\nwe propose a novel lower bound that effectively regularizes the neural network\nto alleviate the problems of MINE. We also introduce an averaging strategy that\nproduces an unbiased estimate by utilizing multiple batches to mitigate the\nbatch size limitation. Finally, we show that $L^2$ regularization achieves\nsignificant improvements in both discrete and continuous settings.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:29:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Choi", "Kwanghee", ""], ["Lee", "Siyeong", ""]]}, {"id": "2011.07989", "submitter": "Alexander Galozy", "authors": "Alexander Galozy, Slawomir Nowaczyk, Mattias Ohlsson", "title": "Corrupted Contextual Bandits with Action Order Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the novel contextual bandit problem with corrupted\ncontext, which we call the contextual bandit problem with corrupted context and\naction correlation, where actions exhibit a relationship structure that can be\nexploited to guide the exploration of viable next decisions. Our setting is\nprimarily motivated by adaptive mobile health interventions and related\napplications, where users might transitions through different stages requiring\nmore targeted action selection approaches. In such settings, keeping user\nengagement is paramount for the success of interventions and therefore it is\nvital to provide relevant recommendations in a timely manner. The context\nprovided by users might not always be informative at every decision point and\nstandard contextual approaches to action selection will incur high regret. We\npropose a meta-algorithm using a referee that dynamically combines the policies\nof a contextual bandit and multi-armed bandit, similar to previous work, as\nwells as a simple correlation mechanism that captures action to action\ntransition probabilities allowing for more efficient exploration of\ntime-correlated actions. We evaluate empirically the performance of said\nalgorithm on a simulation where the sequence of best actions is determined by a\nhidden state that evolves in a Markovian manner. We show that the proposed\nmeta-algorithm improves upon regret in situations where the performance of both\npolicies varies such that one is strictly superior to the other for a given\ntime period. To demonstrate that our setting has relevant practical\napplicability, we evaluate our method on several real world data sets, clearly\nshowing better empirical performance compared to a set of simple algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:35:37 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Galozy", "Alexander", ""], ["Nowaczyk", "Slawomir", ""], ["Ohlsson", "Mattias", ""]]}, {"id": "2011.08046", "submitter": "Qiuyu Zhu", "authors": "Joel Q. L. Chang, Qiuyu Zhu and Vincent Y. F. Tan", "title": "Risk-Constrained Thompson Sampling for CVaR Bandits", "comments": "7 pages main paper with 11 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multi-armed bandit (MAB) problem is a ubiquitous decision-making problem\nthat exemplifies the exploration-exploitation tradeoff. Standard formulations\nexclude risk in decision making. Risk notably complicates the basic\nreward-maximising objective, in part because there is no universally agreed\ndefinition of it. In this paper, we consider a popular risk measure in\nquantitative finance known as the Conditional Value at Risk (CVaR). We explore\nthe performance of a Thompson Sampling-based algorithm CVaR-TS under this risk\nmeasure. We provide comprehensive comparisons between our regret bounds with\nstate-of-the-art L/UCB-based algorithms in comparable settings and demonstrate\ntheir clear improvement in performance. We also include numerical simulations\nto empirically verify that CVaR-TS outperforms other L/UCB-based algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:53:22 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 01:59:02 GMT"}, {"version": "v3", "created": "Sun, 20 Dec 2020 14:54:21 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 05:43:04 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Chang", "Joel Q. L.", ""], ["Zhu", "Qiuyu", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2011.08102", "submitter": "Fabio Carrara PhD", "authors": "Fabio Carrara (1), Giuseppe Amato (1), Luca Brombin, Fabrizio Falchi\n  (1), Claudio Gennaro (1) ((1) ISTI CNR, Pisa, Italy)", "title": "Combining GANs and AutoEncoders for Efficient Anomaly Detection", "comments": "8 pages, 5 figures, 3 tables, pre-print, to be published in the\n  proceedings of the 25th International Conference on Pattern Recognition\n  (ICPR2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose CBiGAN -- a novel method for anomaly detection in\nimages, where a consistency constraint is introduced as a regularization term\nin both the encoder and decoder of a BiGAN. Our model exhibits fairly good\nmodeling power and reconstruction consistency capability. We evaluate the\nproposed method on MVTec AD -- a real-world benchmark for unsupervised anomaly\ndetection on high-resolution images -- and compare against standard baselines\nand state-of-the-art approaches. Experiments show that the proposed method\nimproves the performance of BiGAN formulations by a large margin and performs\ncomparably to expensive state-of-the-art iterative methods while reducing the\ncomputational cost. We also observe that our model is particularly effective in\ntexture-type anomaly detection, as it sets a new state of the art in this\ncategory. Our code is available at https://github.com/fabiocarrara/cbigan-ad/.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 17:07:55 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 16:09:50 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Carrara", "Fabio", "", "ISTI CNR, Pisa, Italy"], ["Amato", "Giuseppe", "", "ISTI CNR, Pisa, Italy"], ["Brombin", "Luca", "", "ISTI CNR, Pisa, Italy"], ["Falchi", "Fabrizio", "", "ISTI CNR, Pisa, Italy"], ["Gennaro", "Claudio", "", "ISTI CNR, Pisa, Italy"]]}, {"id": "2011.08138", "submitter": "Hassan Arbabi", "authors": "Hassan Arbabi, Felix P. Kemeth, Tom Bertalan and Ioannis Kevrekidis", "title": "Coarse-grained and emergent distributed parameter systems from data", "comments": "specified the corresponding author", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We explore the derivation of distributed parameter system evolution laws (and\nin particular, partial differential operators and associated partial\ndifferential equations, PDEs) from spatiotemporal data. This is, of course, a\nclassical identification problem; our focus here is on the use of manifold\nlearning techniques (and, in particular, variations of Diffusion Maps) in\nconjunction with neural network learning algorithms that allow us to attempt\nthis task when the dependent variables, and even the independent variables of\nthe PDE are not known a priori and must be themselves derived from the data.\nThe similarity measure used in Diffusion Maps for dependent coarse variable\ndetection involves distances between local particle distribution observations;\nfor independent variable detection we use distances between local short-time\ndynamics. We demonstrate each approach through an illustrative established PDE\nexample. Such variable-free, emergent space identification algorithms connect\nnaturally with equation-free multiscale computation tools.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:02:01 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 02:32:05 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Arbabi", "Hassan", ""], ["Kemeth", "Felix P.", ""], ["Bertalan", "Tom", ""], ["Kevrekidis", "Ioannis", ""]]}, {"id": "2011.08181", "submitter": "Diego Granziol", "authors": "Diego Granziol, Xingchen Wan, Samuel Albanie, Stephen Roberts", "title": "Explaining the Adaptive Generalisation Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conjecture that the inherent difference in generalisation between adaptive\nand non-adaptive gradient methods stems from the increased estimation noise in\nthe flattest directions of the true loss surface. We demonstrate that typical\nschedules used for adaptive methods (with low numerical stability or damping\nconstants) serve to bias relative movement towards flat directions relative to\nsharp directions, effectively amplifying the noise-to-signal ratio and harming\ngeneralisation. We further demonstrate that the numerical stability/damping\nconstant used in these methods can be decomposed into a learning rate reduction\nand linear shrinkage of the estimated curvature matrix. We then demonstrate\nsignificant generalisation improvements by increasing the shrinkage\ncoefficient, closing the generalisation gap entirely in both Logistic\nRegression and Deep Neural Network experiments. Finally, we show that other\npopular modifications to adaptive methods, such as decoupled weight decay and\npartial adaptivity can be shown to calibrate parameter updates to make better\nuse of sharper, more reliable directions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 18:19:42 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 09:37:16 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 12:02:20 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 11:23:25 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Granziol", "Diego", ""], ["Wan", "Xingchen", ""], ["Albanie", "Samuel", ""], ["Roberts", "Stephen", ""]]}, {"id": "2011.08225", "submitter": "Noy Cohen-Shapira", "authors": "Noy Cohen-Shapira and Lior Rokach", "title": "Automatic selection of clustering algorithms using supervised graph\n  embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The widespread adoption of machine learning (ML) techniques and the extensive\nexpertise required to apply them have led to increased interest in automated ML\nsolutions that reduce the need for human intervention. One of the main\nchallenges in applying ML to previously unseen problems is algorithm selection\n- the identification of high-performing algorithm(s) for a given dataset, task,\nand evaluation measure. This study addresses the algorithm selection challenge\nfor data clustering, a fundamental task in data mining that is aimed at\ngrouping similar objects. We present MARCO-GE, a novel meta-learning approach\nfor the automated recommendation of clustering algorithms. MARCO-GE first\ntransforms datasets into graphs and then utilizes a graph convolutional neural\nnetwork technique to extract their latent representation. Using the embedding\nrepresentations obtained, MARCO-GE trains a ranking meta-model capable of\naccurately recommending top-performing algorithms for a new dataset and\nclustering evaluation measure. Extensive evaluation on 210 datasets, 13\nclustering algorithms, and 10 clustering measures demonstrates the\neffectiveness of our approach and its superiority in terms of predictive and\ngeneralization performance over state-of-the-art clustering meta-learning\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 19:13:20 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 19:09:22 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Cohen-Shapira", "Noy", ""], ["Rokach", "Lior", ""]]}, {"id": "2011.08299", "submitter": "Harrison Wilde", "authors": "Harrison Wilde, Jack Jewson, Sebastian Vollmer and Chris Holmes", "title": "Foundations of Bayesian Learning from Synthetic Data", "comments": "43 pages (10 main text, 33 supplement), 32 figures (4 main text, 28\n  supplement)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is significant growth and interest in the use of synthetic data as an\nenabler for machine learning in environments where the release of real data is\nrestricted due to privacy or availability constraints. Despite a large number\nof methods for synthetic data generation, there are comparatively few results\non the statistical properties of models learnt on synthetic data, and fewer\nstill for situations where a researcher wishes to augment real data with\nanother party's synthesised data. We use a Bayesian paradigm to characterise\nthe updating of model parameters when learning in these settings, demonstrating\nthat caution should be taken when applying conventional learning algorithms\nwithout appropriate consideration of the synthetic data generating process and\nlearning task. Recent results from general Bayesian updating support a novel\nand robust approach to Bayesian synthetic-learning founded on decision theory\nthat outperforms standard approaches across repeated experiments on supervised\nlearning and inference problems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:49:17 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 15:01:22 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wilde", "Harrison", ""], ["Jewson", "Jack", ""], ["Vollmer", "Sebastian", ""], ["Holmes", "Chris", ""]]}, {"id": "2011.08360", "submitter": "Yuetian Luo", "authors": "Yuetian Luo, Wen Huang, Xudong Li, Anru R. Zhang", "title": "Recursive Importance Sketching for Rank Constrained Least Squares:\n  Algorithms and High-order Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new {\\it \\underline{R}ecursive} {\\it\n\\underline{I}mportance} {\\it \\underline{S}ketching} algorithm for {\\it\n\\underline{R}ank} constrained least squares {\\it \\underline{O}ptimization}\n(RISRO). As its name suggests, the algorithm is based on a new sketching\nframework, recursive importance sketching. Several existing algorithms in the\nliterature can be reinterpreted under the new sketching framework and RISRO\noffers clear advantages over them. RISRO is easy to implement and\ncomputationally efficient, where the core procedure in each iteration is only\nsolving a dimension reduced least squares problem. Different from numerous\nexisting algorithms with locally geometric convergence rate, we establish the\nlocal quadratic-linear and quadratic rate of convergence for RISRO under some\nmild conditions. In addition, we discover a deep connection of RISRO to\nRiemannian manifold optimization on fixed rank matrices. The effectiveness of\nRISRO is demonstrated in two applications in machine learning and statistics:\nlow-rank matrix trace regression and phase retrieval. Simulation studies\ndemonstrate the superior numerical performance of RISRO.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 01:32:59 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 00:30:34 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Luo", "Yuetian", ""], ["Huang", "Wen", ""], ["Li", "Xudong", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2011.08384", "submitter": "Jasper C.H. Lee", "authors": "Jasper C.H. Lee, Paul Valiant", "title": "Optimal Sub-Gaussian Mean Estimation in $\\mathbb{R}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of estimating the mean of a real-valued distribution,\npresenting a novel estimator with sub-Gaussian convergence: intuitively, \"our\nestimator, on any distribution, is as accurate as the sample mean is for the\nGaussian distribution of matching variance.\" Crucially, in contrast to prior\nworks, our estimator does not require prior knowledge of the variance, and\nworks across the entire gamut of distributions with bounded variance, including\nthose without any higher moments. Parameterized by the sample size $n$, the\nfailure probability $\\delta$, and the variance $\\sigma^2$, our estimator is\naccurate to within $\\sigma\\cdot(1+o(1))\\sqrt{\\frac{2\\log\\frac{1}{\\delta}}{n}}$,\ntight up to the $1+o(1)$ factor. Our estimator construction and analysis gives\na framework generalizable to other problems, tightly analyzing a sum of\ndependent random variables by viewing the sum implicitly as a 2-parameter\n$\\psi$-estimator, and constructing bounds using mathematical programming and\nduality techniques.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 02:47:24 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lee", "Jasper C. H.", ""], ["Valiant", "Paul", ""]]}, {"id": "2011.08432", "submitter": "Hai Pham", "authors": "Quang Minh Hoang, Trong Nghia Hoang, Hai Pham, David P. Woodruff", "title": "Revisiting the Sample Complexity of Sparse Spectrum Approximation of\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new scalable approximation for Gaussian processes with\nprovable guarantees which hold simultaneously over its entire parameter space.\nOur approximation is obtained from an improved sample complexity analysis for\nsparse spectrum Gaussian processes (SSGPs). In particular, our analysis shows\nthat under a certain data disentangling condition, an SSGP's prediction and\nmodel evidence (for training) can well-approximate those of a full GP with low\nsample complexity. We also develop a new auto-encoding algorithm that finds a\nlatent space to disentangle latent input coordinates into well-separated\nclusters, which is amenable to our sample complexity analysis. We validate our\nproposed method on several benchmarks with promising results supporting our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 05:41:50 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hoang", "Quang Minh", ""], ["Hoang", "Trong Nghia", ""], ["Pham", "Hai", ""], ["Woodruff", "David P.", ""]]}, {"id": "2011.08474", "submitter": "Honglin Yuan", "authors": "Honglin Yuan, Manzil Zaheer, Sashank Reddi", "title": "Federated Composite Optimization", "comments": "Accepted to ICML 2021. Code repository see\n  https://github.com/hongliny/FCO-ICML21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a distributed learning paradigm that scales\non-device learning collaboratively and privately. Standard FL algorithms such\nas FedAvg are primarily geared towards smooth unconstrained settings. In this\npaper, we study the Federated Composite Optimization (FCO) problem, in which\nthe loss function contains a non-smooth regularizer. Such problems arise\nnaturally in FL applications that involve sparsity, low-rank, monotonicity, or\nmore general constraints. We first show that straightforward extensions of\nprimal algorithms such as FedAvg are not well-suited for FCO since they suffer\nfrom the \"curse of primal averaging,\" resulting in poor convergence. As a\nsolution, we propose a new primal-dual algorithm, Federated Dual Averaging\n(FedDualAvg), which by employing a novel server dual averaging procedure\ncircumvents the curse of primal averaging. Our theoretical analysis and\nempirical experiments demonstrate that FedDualAvg outperforms the other\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:54:06 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 18:46:15 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 06:32:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yuan", "Honglin", ""], ["Zaheer", "Manzil", ""], ["Reddi", "Sashank", ""]]}, {"id": "2011.08475", "submitter": "Sai Kumar Popuri", "authors": "Sai K. Popuri, Nagaraj K. Neerchal, Amita Mehta, and Ahmad Mousavi", "title": "Density Estimation using Entropy Maximization for Semi-continuous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-continuous data comes from a distribution that is a mixture of the point\nmass at zero and a continuous distribution with support on the positive real\nline. A clear example is the daily rainfall data. In this paper, we present a\nnovel algorithm to estimate the density function for semi-continuous data using\nthe principle of maximum entropy. Unlike existing methods in the literature,\nour algorithm needs only the sample values of the constraint functions in the\nentropy maximization problem and does not need the entire sample. Using\nsimulations, we show that the estimate of the entropy produced by our algorithm\nhas significantly less bias compared to existing methods. An application to the\ndaily rainfall data is provided.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:57:33 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 22:26:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Popuri", "Sai K.", ""], ["Neerchal", "Nagaraj K.", ""], ["Mehta", "Amita", ""], ["Mousavi", "Ahmad", ""]]}, {"id": "2011.08485", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Cyrus Rashtchian, Ruslan Salakhutdinov, Kamalika\n  Chaudhuri", "title": "Robustness and Generalization to Nearest Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness has emerged as a desirable property for neural\nnetworks. Prior work shows that robust networks perform well in some\nout-of-distribution generalization tasks, such as transfer learning and outlier\ndetection. We uncover a different kind of out-of-distribution generalization\nproperty of such networks, and find that they also do well in a task that we\ncall nearest category generalization (NCG) - given an out-of-distribution\ninput, they tend to predict the same label as that of the closest training\nexample. We empirically show that this happens even when the\nout-of-distribution inputs lie outside the robustness radius of the training\ndata, which suggests that these networks may generalize better along unseen\ndirections on the natural image manifold than arbitrary unseen directions. We\nexamine how performance changes when we change the robustness regions during\ntraining. We then design experiments to investigate the connection between\nout-of-distribution detection and nearest category generalization. Taken\ntogether, our work provides evidence that robust neural networks may resemble\nnearest neighbor classifiers in their behavior on out-of-distribution data. The\ncode is available at\nhttps://github.com/yangarbiter/nearest-category-generalization\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 07:42:27 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 06:38:12 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 20:30:05 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Rashtchian", "Cyrus", ""], ["Salakhutdinov", "Ruslan", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2011.08544", "submitter": "Minyoung Kim", "authors": "Minyoung Kim, Vladimir Pavlovic", "title": "Recursive Inference for Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference networks of traditional Variational Autoencoders (VAEs) are\ntypically amortized, resulting in relatively inaccurate posterior approximation\ncompared to instance-wise variational optimization. Recent semi-amortized\napproaches were proposed to address this drawback; however, their iterative\ngradient update procedures can be computationally demanding. To address these\nissues, in this paper we introduce an accurate amortized inference algorithm.\nWe propose a novel recursive mixture estimation algorithm for VAEs that\niteratively augments the current mixture with new components so as to maximally\nreduce the divergence between the variational and the true posteriors. Using\nthe functional gradient approach, we devise an intuitive learning criteria for\nselecting a new mixture component: the new component has to improve the data\nlikelihood (lower bound) and, at the same time, be as divergent from the\ncurrent mixture distribution as possible, thus increasing representational\ndiversity. Compared to recently proposed boosted variational inference (BVI),\nour method relies on amortized inference in contrast to BVI's non-amortized\nsingle optimization instance. A crucial benefit of our approach is that the\ninference at test time requires a single feed-forward pass through the mixture\ninference network, making it significantly faster than the semi-amortized\napproaches. We show that our approach yields higher test data likelihood than\nthe state-of-the-art on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:22:12 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kim", "Minyoung", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "2011.08578", "submitter": "Jakiw Pidstrigach", "authors": "Jakiw Pidstrigach", "title": "Convergence of Preconditioned Hamiltonian Monte Carlo on Hilbert Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider the preconditioned Hamiltonian Monte Carlo\n(pHMC) algorithm defined directly on an infinite-dimensional Hilbert space. In\nthis context, and under a condition reminiscent of strong log-concavity of the\ntarget measure, we prove convergence bounds for adjusted pHMC in the standard\n1-Wasserstein distance. The arguments rely on a synchronous coupling of two\ncopies of pHMC, which is controlled by adapting elements from arXiv:1805.00452.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 11:53:29 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Pidstrigach", "Jakiw", ""]]}, {"id": "2011.08595", "submitter": "Jiyang Xie", "authors": "Jiyang Xie and Zhanyu Ma and Jing-Hao Xue and Guoqiang Zhang and Jun\n  Guo", "title": "DS-UI: Dual-Supervised Mixture of Gaussian Mixture Models for\n  Uncertainty Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a dual-supervised uncertainty inference (DS-UI) framework\nfor improving Bayesian estimation-based uncertainty inference (UI) in deep\nneural network (DNN)-based image recognition. In the DS-UI, we combine the\nclassifier of a DNN, i.e., the last fully-connected (FC) layer, with a mixture\nof Gaussian mixture models (MoGMM) to obtain an MoGMM-FC layer. Unlike existing\nUI methods for DNNs, which only calculate the means or modes of the DNN\noutputs' distributions, the proposed MoGMM-FC layer acts as a probabilistic\ninterpreter for the features that are inputs of the classifier to directly\ncalculate the probability density of them for the DS-UI. In addition, we\npropose a dual-supervised stochastic gradient-based variational Bayes (DS-SGVB)\nalgorithm for the MoGMM-FC layer optimization. Unlike conventional SGVB and\noptimization algorithms in other UI methods, the DS-SGVB not only models the\nsamples in the specific class for each Gaussian mixture model (GMM) in the\nMoGMM, but also considers the negative samples from other classes for the GMM\nto reduce the intra-class distances and enlarge the inter-class margins\nsimultaneously for enhancing the learning ability of the MoGMM-FC layer in the\nDS-UI. Experimental results show the DS-UI outperforms the state-of-the-art UI\nmethods in misclassification detection. We further evaluate the DS-UI in\nopen-set out-of-domain/-distribution detection and find statistically\nsignificant improvements. Visualizations of the feature spaces demonstrate the\nsuperiority of the DS-UI.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 12:35:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Xie", "Jiyang", ""], ["Ma", "Zhanyu", ""], ["Xue", "Jing-Hao", ""], ["Zhang", "Guoqiang", ""], ["Guo", "Jun", ""]]}, {"id": "2011.08618", "submitter": "Dongxiao Zhang", "authors": "Nanzhe Wang, Haibin Chang, Dongxiao Zhang", "title": "Theory-guided Auto-Encoder for Surrogate Construction and Inverse\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A Theory-guided Auto-Encoder (TgAE) framework is proposed for surrogate\nconstruction and is further used for uncertainty quantification and inverse\nmodeling tasks. The framework is built based on the Auto-Encoder (or\nEncoder-Decoder) architecture of convolutional neural network (CNN) via a\ntheory-guided training process. In order to achieve the theory-guided training,\nthe governing equations of the studied problems can be discretized and the\nfinite difference scheme of the equations can be embedded into the training of\nCNN. The residual of the discretized governing equations as well as the data\nmismatch constitute the loss function of the TgAE. The trained TgAE can be used\nto construct a surrogate that approximates the relationship between the model\nparameters and responses with limited labeled data. In order to test the\nperformance of the TgAE, several subsurface flow cases are introduced. The\nresults show the satisfactory accuracy of the TgAE surrogate and efficiency of\nuncertainty quantification tasks can be improved with the TgAE surrogate. The\nTgAE also shows good extrapolation ability for cases with different correlation\nlengths and variances. Furthermore, the parameter inversion task has been\nimplemented with the TgAE surrogate and satisfactory results can be obtained.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:23:03 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wang", "Nanzhe", ""], ["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2011.08644", "submitter": "Sebastian Schmon", "authors": "Sebastian M Schmon, Patrick W Cannon, Jeremias Knoblauch", "title": "Generalized Posteriors in Approximate Bayesian Computation", "comments": "Accepted at Advances in Approximate Bayesian Inference, AABI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex simulators have become a ubiquitous tool in many scientific\ndisciplines, providing high-fidelity, implicit probabilistic models of natural\nand social phenomena. Unfortunately, they typically lack the tractability\nrequired for conventional statistical analysis. Approximate Bayesian\ncomputation (ABC) has emerged as a key method in simulation-based inference,\nwherein the true model likelihood and posterior are approximated using samples\nfrom the simulator. In this paper, we draw connections between ABC and\ngeneralized Bayesian inference (GBI). First, we re-interpret the accept/reject\nstep in ABC as an implicitly defined error model. We then argue that these\nimplicit error models will invariably be misspecified. While ABC posteriors are\noften treated as a necessary evil for approximating the standard Bayesian\nposterior, this allows us to re-interpret ABC as a potential robustification\nstrategy. This leads us to suggest the use of GBI within ABC, a use case we\nexplore empirically.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 14:08:59 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 18:16:36 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Schmon", "Sebastian M", ""], ["Cannon", "Patrick W", ""], ["Knoblauch", "Jeremias", ""]]}, {"id": "2011.08698", "submitter": "Zaccharie Ramzi", "authors": "Zaccharie Ramzi, Benjamin Remy, Francois Lanusse, Jean-Luc Starck,\n  Philippe Ciuciu", "title": "Denoising Score-Matching for Uncertainty Quantification in Inverse\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.SP physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have proven extremely efficient at solving a wide\nrangeof inverse problems, but most often the uncertainty on the solution they\nprovideis hard to quantify. In this work, we propose a generic Bayesian\nframework forsolving inverse problems, in which we limit the use of deep neural\nnetworks tolearning a prior distribution on the signals to recover. We adopt\nrecent denoisingscore matching techniques to learn this prior from data, and\nsubsequently use it aspart of an annealed Hamiltonian Monte-Carlo scheme to\nsample the full posteriorof image inverse problems. We apply this framework to\nMagnetic ResonanceImage (MRI) reconstruction and illustrate how this approach\nnot only yields highquality reconstructions but can also be used to assess the\nuncertainty on particularfeatures of a reconstructed image.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:33:06 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ramzi", "Zaccharie", ""], ["Remy", "Benjamin", ""], ["Lanusse", "Francois", ""], ["Starck", "Jean-Luc", ""], ["Ciuciu", "Philippe", ""]]}, {"id": "2011.08711", "submitter": "Alexander Alemi", "authors": "Alexander A Alemi and Warren R Morningstar and Ben Poole and Ian\n  Fischer and Joshua V Dillon", "title": "VIB is Half Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In discriminative settings such as regression and classification there are\ntwo random variables at play, the inputs X and the targets Y. Here, we\ndemonstrate that the Variational Information Bottleneck can be viewed as a\ncompromise between fully empirical and fully Bayesian objectives, attempting to\nminimize the risks due to finite sampling of Y only. We argue that this\napproach provides some of the benefits of Bayes while requiring only some of\nthe work.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 15:36:35 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Alemi", "Alexander A", ""], ["Morningstar", "Warren R", ""], ["Poole", "Ben", ""], ["Fischer", "Ian", ""], ["Dillon", "Joshua V", ""]]}, {"id": "2011.08714", "submitter": "Mizu Nishikawa-Toomey", "authors": "Mizu Nishikawa-Toomey, Lewis Smith, Yarin Gal", "title": "Semi-supervised Learning of Galaxy Morphology using Equivariant\n  Transformer Variational Autoencoders", "comments": "Accepted at the workshop for Machine Learning and the Physical\n  Sciences, 34th Conference on Neural Information Processing Systems (NeurIPS)\n  December 11, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growth in the number of galaxy images is much faster than the speed at\nwhich these galaxies can be labelled by humans. However, by leveraging the\ninformation present in the ever growing set of unlabelled images,\nsemi-supervised learning could be an effective way of reducing the required\nlabelling and increasing classification accuracy. We develop a Variational\nAutoencoder (VAE) with Equivariant Transformer layers with a classifier network\nfrom the latent space. We show that this novel architecture leads to\nimprovements in accuracy when used for the galaxy morphology classification\ntask on the Galaxy Zoo data set. In addition we show that pre-training the\nclassifier network as part of the VAE using the unlabelled data leads to higher\naccuracy with fewer labels compared to exiting approaches. This novel VAE has\nthe potential to automate galaxy morphology classification with reduced human\nlabelling efforts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 15:41:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Nishikawa-Toomey", "Mizu", ""], ["Smith", "Lewis", ""], ["Gal", "Yarin", ""]]}, {"id": "2011.08753", "submitter": "Xuling Wang", "authors": "Shirly Wang, Seung Eun Yi, Shalmali Joshi, Marzyeh Ghassemi", "title": "Confounding Feature Acquisition for Causal Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable treatment effect estimation from observational data depends on the\navailability of all confounding information. While much work has targeted\ntreatment effect estimation from observational data, there is relatively little\nwork in the setting of confounding variable missingness, where collecting more\ninformation on confounders is often costly or time-consuming. In this work, we\nframe this challenge as a problem of feature acquisition of confounding\nfeatures for causal inference. Our goal is to prioritize acquiring values for a\nfixed and known subset of missing confounders in samples that lead to efficient\naverage treatment effect estimation. We propose two acquisition strategies\nbased on i) covariate balancing (CB), and ii) reducing statistical estimation\nerror on observed factual outcome error (OE). We compare CB and OE on five\ncommon causal effect estimation methods, and demonstrate improved sample\nefficiency of OE over baseline methods under various settings. We also provide\nvisualizations for further analysis on the difference between our proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:28:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wang", "Shirly", ""], ["Yi", "Seung Eun", ""], ["Joshi", "Shalmali", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2011.08763", "submitter": "Enrico Fontana", "authors": "Enrico Fontana, M. Cerezo, Andrew Arrasmith, Ivan Rungger, Patrick J.\n  Coles", "title": "Optimizing parametrized quantum circuits via noise-induced breaking of\n  symmetries", "comments": "11 + 5 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-29359", "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very little is known about the cost landscape for parametrized Quantum\nCircuits (PQCs). Nevertheless, PQCs are employed in Quantum Neural Networks and\nVariational Quantum Algorithms, which may allow for near-term quantum\nadvantage. Such applications require good optimizers to train PQCs. Recent\nworks have focused on quantum-aware optimizers specifically tailored for PQCs.\nHowever, ignorance of the cost landscape could hinder progress towards such\noptimizers. In this work, we analytically prove two results for PQCs: (1) We\nfind an exponentially large symmetry in PQCs, yielding an exponentially large\ndegeneracy of the minima in the cost landscape. (2) We show that noise\n(specifically non-unital noise) can break these symmetries and lift the\ndegeneracy of minima, making many of them local minima instead of global\nminima. Based on these results, we introduce an optimization method called\nSymmetry-based Minima Hopping (SYMH), which exploits the underlying symmetries\nin PQCs to hop between local minima in the cost landscape. The versatility of\nSYMH allows it to be combined with local optimizers (e.g., gradient descent)\nwith minimal overhead. Our numerical simulations show that SYMH improves the\noverall optimizer performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:43:05 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 17:49:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Fontana", "Enrico", ""], ["Cerezo", "M.", ""], ["Arrasmith", "Andrew", ""], ["Rungger", "Ivan", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2011.08784", "submitter": "Alexander Tornede", "authors": "Alexander Tornede, Marcel Wever, Eyke H\\\"ullermeier", "title": "Towards Meta-Algorithm Selection", "comments": "Accepted at 4th Workshop on Meta-Learning at NeurIPS 2020, Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Instance-specific algorithm selection (AS) deals with the automatic selection\nof an algorithm from a fixed set of candidates most suitable for a specific\ninstance of an algorithmic problem class, where \"suitability\" often refers to\nan algorithm's runtime. Over the past years, a plethora of algorithm selectors\nhave been proposed. As an algorithm selector is again an algorithm solving a\nspecific problem, the idea of algorithm selection could also be applied to AS\nalgorithms, leading to a meta-AS approach: Given an instance, the goal is to\nselect an algorithm selector, which is then used to select the actual algorithm\nfor solving the problem instance. We elaborate on consequences of applying AS\non a meta-level and identify possible problems. Empirically, we show that\nmeta-algorithm-selection can indeed prove beneficial in some cases. In general,\nhowever, successful AS approaches have problems with solving the meta-level\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 17:27:33 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Tornede", "Alexander", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2011.08797", "submitter": "Rafael Hanashiro", "authors": "Rafael Hanashiro, Jacob Abernethy", "title": "Linear Separation via Optimism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary linear classification has been explored since the very early days of\nthe machine learning literature. Perhaps the most classical algorithm is the\nPerceptron, where a weight vector used to classify examples is maintained, and\nadditive updates are made as incorrect examples are discovered. The Perceptron\nhas been thoroughly studied and several versions have been proposed over many\ndecades. The key theoretical fact about the Perceptron is that, so long as a\nperfect linear classifier exists with some margin $\\gamma > 0$, the number of\nrequired updates to find such a perfect linear separator is bounded by\n$\\frac{1}{\\gamma^2}$. What has never been fully addressed is: does there exist\nan algorithm that can achieve this with fewer updates? In this paper we answer\nthis in the affirmative: we propose the Optimistic Perceptron algorithm, a\nsimple procedure that finds a separating hyperplane in no more than\n$\\frac{1}{\\gamma}$ updates. We also show experimentally that this procedure can\nsignificantly outperform Perceptron.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 17:44:40 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hanashiro", "Rafael", ""], ["Abernethy", "Jacob", ""]]}, {"id": "2011.08810", "submitter": "Matthew Kunz", "authors": "M. Ross Kunz, Adam Yonge, Zongtang Fang, Andrew J. Medford, Denis\n  Constales, Gregory Yablonsky, Rebecca Fushimi", "title": "Data Driven Reaction Mechanism Estimation via Transient Kinetics and\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the set of elementary steps and kinetics in each reaction is\nextremely valuable to make informed decisions about creating the next\ngeneration of catalytic materials. With physical and mechanistic complexity of\nindustrial catalysts, it is critical to obtain kinetic information through\nexperimental methods. As such, this work details a methodology based on the\ncombination of transient rate/concentration dependencies and machine learning\nto measure the number of active sites, the individual rate constants, and gain\ninsight into the mechanism under a complex set of elementary steps. This new\nmethodology was applied to simulated transient responses to verify its ability\nto obtain correct estimates of the micro-kinetic coefficients. Furthermore,\nexperimental CO oxidation data was analyzed to reveal the Langmuir-Hinshelwood\nmechanism driving the reaction. As oxygen accumulated on the catalyst, a\ntransition in the mechanism was clearly defined in the machine learning\nanalysis due to the large amount of kinetic information available from\ntransient reaction techniques. This methodology is proposed as a new data\ndriven approach to characterize how materials control complex reaction\nmechanisms relying exclusively on experimental data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:14:10 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 14:26:49 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Kunz", "M. Ross", ""], ["Yonge", "Adam", ""], ["Fang", "Zongtang", ""], ["Medford", "Andrew J.", ""], ["Constales", "Denis", ""], ["Yablonsky", "Gregory", ""], ["Fushimi", "Rebecca", ""]]}, {"id": "2011.08895", "submitter": "Alex Lewandowski", "authors": "Varun Ranganathan, Alex Lewandowski", "title": "ZORB: A Derivative-Free Backpropagation Algorithm for Neural Networks", "comments": "To appear in \"Beyond Backpropagation - Novel Ideas for Training\n  Neural Architectures\" Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient descent and backpropagation have enabled neural networks to achieve\nremarkable results in many real-world applications. Despite ongoing success,\ntraining a neural network with gradient descent can be a slow and strenuous\naffair. We present a simple yet faster training algorithm called Zeroth-Order\nRelaxed Backpropagation (ZORB). Instead of calculating gradients, ZORB uses the\npseudoinverse of targets to backpropagate information. ZORB is designed to\nreduce the time required to train deep neural networks without penalizing\nperformance. To illustrate the speed up, we trained a feed-forward neural\nnetwork with 11 layers on MNIST and observed that ZORB converged 300 times\nfaster than Adam while achieving a comparable error rate, without any\nhyperparameter tuning. We also broaden the scope of ZORB to convolutional\nneural networks, and apply it to subsamples of the CIFAR-10 dataset.\nExperiments on standard classification and regression benchmarks demonstrate\nZORB's advantage over traditional backpropagation with Gradient Descent.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:29:47 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ranganathan", "Varun", ""], ["Lewandowski", "Alex", ""]]}, {"id": "2011.08930", "submitter": "Jeongmin Chae", "authors": "Jeongmin Chae, Songnam Hong", "title": "Distributed Online Learning with Multiple Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the Internet-of-Things (IoT) systems, there are plenty of informative data\nprovided by a massive number of IoT devices (e.g., sensors). Learning a\nfunction from such data is of great interest in machine learning tasks for IoT\nsystems. Focusing on streaming (or sequential) data, we present a\nprivacy-preserving distributed online learning framework with multiplekernels\n(named DOMKL). The proposed DOMKL is devised by leveraging the principles of an\nonline alternating direction of multipliers (OADMM) and a distributed Hedge\nalgorithm. We theoretically prove that DOMKL over T time slots can achieve an\noptimal sublinear regret, implying that every learned function achieves the\nperformance of the best function in hindsight as in the state-of-the-art\ncentralized online learning method. Moreover, it is ensured that the learned\nfunctions of any two neighboring learners have a negligible difference as T\ngrows, i.e., the so-called consensus constraints hold. Via experimental tests\nwith various real datasets, we verify the effectiveness of the proposed DOMKL\non regression and time-series prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 20:29:00 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Chae", "Jeongmin", ""], ["Hong", "Songnam", ""]]}, {"id": "2011.08958", "submitter": "Thomas Oliver", "authors": "Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver", "title": "Machine-Learning Number Fields", "comments": "20 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that standard machine-learning algorithms may be trained to predict\ncertain invariants of algebraic number fields to high accuracy. A random-forest\nclassifier that is trained on finitely many Dedekind zeta coefficients is able\nto distinguish between real quadratic fields with class number 1 and 2, to 0.96\nprecision. Furthermore, the classifier is able to extrapolate to fields with\ndiscriminant outside the range of the training data. When trained on the\ncoefficients of defining polynomials for Galois extensions of degrees 2, 6, and\n8, a logistic regression classifier can distinguish between Galois groups and\npredict the ranks of unit groups with precision >0.97.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 21:40:40 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["He", "Yang-Hui", ""], ["Lee", "Kyu-Hwan", ""], ["Oliver", "Thomas", ""]]}, {"id": "2011.08963", "submitter": "Lang Liu", "authors": "Zaid Harchaoui, Lang Liu, Soumik Pal", "title": "Asymptotics of Entropy-Regularized Optimal Transport via Chaos\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of estimating the optimal coupling (i.e., matching)\nbetween $N$ i.i.d. data points sampled from two densities $\\rho_0$ and $\\rho_1$\nin $\\mathbb{R}^d$. The cost of transport is an arbitrary continuous function\nthat satisfies suitable growth and integrability assumptions. For both\ncomputational efficiency and smoothness, often a regularization term using\nentropy is added to this discrete problem. We introduce a modification of the\ncommonly used discrete entropic regularization (Cuturi '13) such that the\noptimal coupling for the regularized problem can be thought of as the static\nSchr\\\"odinger bridge with $N$ particles. This paper is on the asymptotic\nproperties of this discrete Schr\\\"odinger bridge as $N$ tends to infinity. We\nshow that it converges to the continuum Schr\\\"odinger bridge and derive the\nfirst two error terms of orders $N^{-1/2}$ and $N^{-1}$, respectively. This\ngives us functional CLT, including for the cost of transport, and second order\nGaussian chaos limits when the limiting Gaussian variance is zero, extending\nsimilar recent results derived for finite state spaces and the quadratic cost.\nThe proofs are based on a novel chaos decomposition of the discrete\nSchr\\\"odinger bridge by polynomial functions of the pair of empirical\ndistributions as a first and second order Taylor approximations in the space of\nmeasures. This is achieved by extending the Hoeffding decomposition from the\nclassical theory of U-statistics. The kernels corresponding to the first and\nsecond order chaoses are given by Markov operators which have natural\ninterpretations in the Sinkhorn algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 21:55:46 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Harchaoui", "Zaid", ""], ["Liu", "Lang", ""], ["Pal", "Soumik", ""]]}, {"id": "2011.08968", "submitter": "Qiwei Yuan", "authors": "Qiwei Yuan, Weizhe Hua, Yi Zhou, Cunxi Yu", "title": "Contrastive Weight Regularization for Large Minibatch SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minibatch stochastic gradient descent method (SGD) is widely applied in\ndeep learning due to its efficiency and scalability that enable training deep\nnetworks with a large volume of data. Particularly in the distributed setting,\nSGD is usually applied with large batch size. However, as opposed to\nsmall-batch SGD, neural network models trained with large-batch SGD can hardly\ngeneralize well, i.e., the validation accuracy is low. In this work, we\nintroduce a novel regularization technique, namely distinctive regularization\n(DReg), which replicates a certain layer of the deep network and encourages the\nparameters of both layers to be diverse. The DReg technique introduces very\nlittle computation overhead. Moreover, we empirically show that optimizing the\nneural network with DReg using large-batch SGD achieves a significant boost in\nthe convergence and improved generalization performance. We also demonstrate\nthat DReg can boost the convergence of large-batch SGD with momentum. We\nbelieve that DReg can be used as a simple regularization trick to accelerate\nlarge-batch training in deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 22:07:38 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Yuan", "Qiwei", ""], ["Hua", "Weizhe", ""], ["Zhou", "Yi", ""], ["Yu", "Cunxi", ""]]}, {"id": "2011.08991", "submitter": "Tamara Fernandez", "authors": "Tamara Fern\\'andez, Wenkai Xu, Marc Ditzhaus and Arthur Gretton", "title": "A kernel test for quasi-independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider settings in which the data of interest correspond to pairs of\nordered times, e.g, the birth times of the first and second child, the times at\nwhich a new user creates an account and makes the first purchase on a website,\nand the entry and survival times of patients in a clinical trial. In these\nsettings, the two times are not independent (the second occurs after the\nfirst), yet it is still of interest to determine whether there exists\nsignificant dependence {\\em beyond} their ordering in time. We refer to this\nnotion as \"quasi-(in)dependence\". For instance, in a clinical trial, to avoid\nbiased selection, we might wish to verify that recruitment times are\nquasi-independent of survival times, where dependencies might arise due to\nseasonal effects. In this paper, we propose a nonparametric statistical test of\nquasi-independence. Our test considers a potentially infinite space of\nalternatives, making it suitable for complex data where the nature of the\npossible quasi-dependence is not known in advance. Standard parametric\napproaches are recovered as special cases, such as the classical conditional\nKendall's tau, and log-rank tests. The tests apply in the right-censored\nsetting: an essential feature in clinical trials, where patients can withdraw\nfrom the study. We provide an asymptotic analysis of our test-statistic, and\ndemonstrate in experiments that our test obtains better power than existing\napproaches, while being more computationally efficient.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 22:42:45 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Fern\u00e1ndez", "Tamara", ""], ["Xu", "Wenkai", ""], ["Ditzhaus", "Marc", ""], ["Gretton", "Arthur", ""]]}, {"id": "2011.09038", "submitter": "Manuel Florez", "authors": "Manuel A. Florez, Michaelangelo Caporale, Pakpoom Buabthong, Zachary\n  E. Ross, Domniki Asimaki and Men-Andrin Meier", "title": "Data-driven Accelerogram Synthesis using Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust estimation of ground motions generated by scenario earthquakes is\ncritical for many engineering applications. We leverage recent advances in\nGenerative Adversarial Networks (GANs) to develop a new framework for\nsynthesizing earthquake acceleration time histories. Our approach extends the\nWasserstein GAN formulation to allow for the generation of ground-motions\nconditioned on a set of continuous physical variables. Our model is trained to\napproximate the intrinsic probability distribution of a massive set of\nstrong-motion recordings from Japan. We show that the trained generator model\ncan synthesize realistic 3-Component accelerograms conditioned on magnitude,\ndistance, and $V_{s30}$. Our model captures the expected statistical features\nof the acceleration spectra and waveform envelopes. The output seismograms\ndisplay clear P and S-wave arrivals with the appropriate energy content and\nrelative onset timing. The synthesized Peak Ground Acceleration (PGA) estimates\nare also consistent with observations. We develop a set of metrics that allow\nus to assess the training process's stability and tune model hyperparameters.\nWe further show that the trained generator network can interpolate to\nconditions where no earthquake ground motion recordings exist. Our approach\nallows the on-demand synthesis of accelerograms for engineering purposes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 02:12:14 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Florez", "Manuel A.", ""], ["Caporale", "Michaelangelo", ""], ["Buabthong", "Pakpoom", ""], ["Ross", "Zachary E.", ""], ["Asimaki", "Domniki", ""], ["Meier", "Men-Andrin", ""]]}, {"id": "2011.09148", "submitter": "Ke Wang", "authors": "Ke Wang, Christos Thrampoulidis", "title": "Binary Classification of Gaussian Mixtures: Abundance of Support\n  Vectors, Benign Overfitting and Regularization", "comments": "New results: Extensions to correlated features and\n  ridge-regularization; Additional numerical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep neural networks generalize well despite being exceedingly\noverparameterized and being trained without explicit regularization. This\ncurious phenomenon, often termed benign overfitting, has inspired extensive\nresearch activity in establishing its statistical principles: Under what\nconditions is the phenomenon observed? How do these depend on the data and on\nthe training algorithm? When does regularization benefit generalization? While\nthese questions remain wide open for deep neural nets, recent works have\nattempted gaining insights by studying simpler, often linear, models. Our paper\ncontributes to this growing line of work by examining binary linear\nclassification under the popular generative Gaussian mixture model. Motivated\nby recent results on the implicit bias of gradient descent, we study both\nmax-margin SVM classifiers (corresponding to logistic loss) and min-norm\ninterpolating classifiers (corresponding to least-squares loss). First, we\nleverage an idea introduced in [V. Muthukumar et al., arXiv:2005.08054, (2020)]\nto relate the SVM solution to the least-squares (LS) interpolating solution.\nSecond, we derive novel non-asymptotic bounds on the classification error of\nthe LS solution. Combining the two, we present novel sufficient conditions on\nthe overparameterization ratio and on the signal-to-noise ratio (SNR) for\nbenign overfitting to occur. Contrary to previously studied discriminative data\nmodels, our results emphasize the crucial role of the SNR. Moreover, we\ninvestigate the role of regularization and identify precise conditions under\nwhich the interpolating estimator performs better than the regularized\nestimates. We corroborate our theoretical findings with numerical simulations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 07:59:55 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2021 04:35:42 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 01:07:30 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Wang", "Ke", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2011.09172", "submitter": "Nontawat Charoenphakdee", "authors": "Nontawat Charoenphakdee, Jayakorn Vongkulbhisal, Nuttapong\n  Chairatanakul, Masashi Sugiyama", "title": "On Focal Loss for Class-Posterior Probability Estimation: A Theoretical\n  Perspective", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focal loss has demonstrated its effectiveness in many real-world\napplications such as object detection and image classification, but its\ntheoretical understanding has been limited so far. In this paper, we first\nprove that the focal loss is classification-calibrated, i.e., its minimizer\nsurely yields the Bayes-optimal classifier and thus the use of the focal loss\nin classification can be theoretically justified. However, we also prove a\nnegative fact that the focal loss is not strictly proper, i.e., the confidence\nscore of the classifier obtained by focal loss minimization does not match the\ntrue class-posterior probability and thus it is not reliable as a\nclass-posterior probability estimator. To mitigate this problem, we next prove\nthat a particular closed-form transformation of the confidence score allows us\nto recover the true class-posterior probability. Through experiments on\nbenchmark datasets, we demonstrate that our proposed transformation\nsignificantly improves the accuracy of class-posterior probability estimation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 09:36:52 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 04:15:40 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Charoenphakdee", "Nontawat", ""], ["Vongkulbhisal", "Jayakorn", ""], ["Chairatanakul", "Nuttapong", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2011.09288", "submitter": "Ingvar Ziemann", "authors": "Ingvar Ziemann, Henrik Sandberg", "title": "On Uninformative Optimal Policies in Adaptive LQR with Unknown B-Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents local asymptotic minimax regret lower bounds for adaptive\nLinear Quadratic Regulators (LQR). We consider affinely parametrized\n$B$-matrices and known $A$-matrices and aim to understand when logarithmic\nregret is impossible even in the presence of structural side information. After\ndefining the intrinsic notion of an uninformative optimal policy in terms of a\nsingularity condition for Fisher information we obtain local minimax regret\nlower bounds for such uninformative instances of LQR by appealing to van Trees'\ninequality (Bayesian Cram\\'er-Rao) and a representation of regret in terms of a\nquadratic form (Bellman error). It is shown that if the parametrization induces\nan uninformative optimal policy, logarithmic regret is impossible and the rate\nis at least order square root in the time horizon. We explicitly characterize\nthe notion of an uninformative optimal policy in terms of the nullspaces of\nsystem-theoretic quantities and the particular instance parametrization.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:50:31 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 11:54:03 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 05:37:21 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ziemann", "Ingvar", ""], ["Sandberg", "Henrik", ""]]}, {"id": "2011.09349", "submitter": "A. Max Reppen", "authors": "A. Max Reppen and H. Mete Soner", "title": "Bias-Variance Trade-off and Overlearning in Dynamic Decision Problems", "comments": "22 pages, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Monte Carlo-type approaches to dynamic decision problems are\nreformulated as empirical loss minimization, allowing direct applications of\nclassical results from statistical machine learning. These computational\nmethods are then analyzed in this framework to demonstrate their effectiveness\nas well as their susceptibility to generalization error. Standard uses of\nclassical results prove potential overlearning, thus bias-variance trade-off,\nby connecting over-trained networks to anticipating controls. On the other\nhand, non-asymptotic estimates based on Rademacher complexity show the\nconvergence of these algorithms for sufficiently large training sets. A\nnumerically studied stylized example illustrates these possibilities, including\nthe importance of problem dimension in the degree of overlearning, and the\neffectiveness of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:36:22 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 16:37:06 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Reppen", "A. Max", ""], ["Soner", "H. Mete", ""]]}, {"id": "2011.09363", "submitter": "Philipp Petersen", "authors": "Andrei Caragea, Philipp Petersen, Felix Voigtlaender", "title": "Neural network approximation and estimation of classifiers with\n  classification boundary in a Barron class", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove bounds for the approximation and estimation of certain\nclassification functions using ReLU neural networks. Our estimation bounds\nprovide a priori performance guarantees for empirical risk minimization using\nnetworks of a suitable size, depending on the number of training samples\navailable. The obtained approximation and estimation rates are independent of\nthe dimension of the input, showing that the curse of dimension can be overcome\nin this setting; in fact, the input dimension only enters in the form of a\npolynomial factor. Regarding the regularity of the target classification\nfunction, we assume the interfaces between the different classes to be locally\nof Barron-type. We complement our results by studying the relations between\nvarious Barron-type spaces that have been proposed in the literature. These\nspaces differ substantially more from each other than the current literature\nsuggests.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:00:31 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Caragea", "Andrei", ""], ["Petersen", "Philipp", ""], ["Voigtlaender", "Felix", ""]]}, {"id": "2011.09370", "submitter": "Gurcan Comert", "authors": "Gurcan Comert, Negash Begashaw", "title": "Cycle-to-Cycle Queue Length Estimation from Connected Vehicles with\n  Filtering on Primary Parameters", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimation models from connected vehicles often assume low level parameters\nsuch as arrival rates and market penetration rates as known or estimate them in\nreal-time. At low market penetration rates, such parameter estimators produce\nlarge errors making estimated queue lengths inefficient for control or\noperations applications. In order to improve accuracy of low level parameter\nestimations, this study investigates the impact of connected vehicles\ninformation filtering on queue length estimation models. Filters are used as\nmultilevel real-time estimators. Accuracy is tested against known arrival rate\nand market penetration rate scenarios using microsimulations. To understand the\neffectiveness for short-term or for dynamic processes, arrival rates, and\nmarket penetration rates are changed every 15 minutes. The results show that\nwith Kalman and Particle filters, parameter estimators are able to find the\ntrue values within 15 minutes and meet and surpass the accuracy of known\nparameter scenarios especially for low market penetration rates. In addition,\nusing last known estimated queue lengths when no connected vehicle is present\nperforms better than inputting average estimated values. Moreover, the study\nshows that both filtering algorithms are suitable for real-time applications\nthat require less than 0.1 second computational time.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:09:45 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Comert", "Gurcan", ""], ["Begashaw", "Negash", ""]]}, {"id": "2011.09388", "submitter": "Osman Musa", "authors": "Osman Musa, Peter Jung and Giuseppe Caire", "title": "Plug-And-Play Learned Gaussian-mixture Approximate Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unfolding showed to be a very successful approach for accelerating and\ntuning classical signal processing algorithms. In this paper, we propose\nlearned Gaussian-mixture AMP (L-GM-AMP) - a plug-and-play compressed sensing\n(CS) recovery algorithm suitable for any i.i.d. source prior. Our algorithm\nbuilds upon Borgerding's learned AMP (LAMP), yet significantly improves it by\nadopting a universal denoising function within the algorithm. The robust and\nflexible denoiser is a byproduct of modelling source prior with a\nGaussian-mixture (GM), which can well approximate continuous, discrete, as well\nas mixture distributions. Its parameters are learned using standard\nbackpropagation algorithm. To demonstrate robustness of the proposed algorithm,\nwe conduct Monte-Carlo (MC) simulations for both mixture and discrete\ndistributions. Numerical evaluation shows that the L-GM-AMP algorithm achieves\nstate-of-the-art performance without any knowledge of the source prior.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:40:45 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Musa", "Osman", ""], ["Jung", "Peter", ""], ["Caire", "Giuseppe", ""]]}, {"id": "2011.09416", "submitter": "Bohdan Kivva", "authors": "Bohdan Kivva and Aaron Potechin", "title": "Exact nuclear norm, completion and decomposition for random overcomplete\n  tensors via degree-4 SOS", "comments": "132 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that simple semidefinite programs inspired by degree\n$4$ SOS can exactly solve the tensor nuclear norm, tensor decomposition, and\ntensor completion problems on tensors with random asymmetric components. More\nprecisely, for tensor nuclear norm and tensor decomposition, we show that\nw.h.p. these semidefinite programs can exactly find the nuclear norm and\ncomponents of an $(n\\times n\\times n)$-tensor $\\mathcal{T}$ with $m\\leq\nn^{3/2}/polylog(n)$ random asymmetric components. For tensor completion, we\nshow that w.h.p. the semidefinite program introduced by Potechin \\& Steurer\n(2017) can exactly recover an $(n\\times n\\times n)$-tensor $\\mathcal{T}$ with\n$m$ random asymmetric components from only $n^{3/2}m\\, polylog(n)$ randomly\nobserved entries. This gives the first theoretical guarantees for exact tensor\ncompletion in the overcomplete regime.\n  This matches the best known results for approximate versions of these\nproblems given by Barak \\& Moitra (2015) for tensor completion, and Ma, Shi \\&\nSteurer (2016) for tensor decomposition.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:27:36 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kivva", "Bohdan", ""], ["Potechin", "Aaron", ""]]}, {"id": "2011.09421", "submitter": "Sebastian Ober", "authors": "David R. Burt, Sebastian W. Ober, Adri\\`a Garriga-Alonso, Mark van der\n  Wilk", "title": "Understanding Variational Inference in Function-Space", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has attempted to directly approximate the `function-space' or\npredictive posterior distribution of Bayesian models, without approximating the\nposterior distribution over the parameters. This is appealing in e.g. Bayesian\nneural networks, where we only need the former, and the latter is hard to\nrepresent. In this work, we highlight some advantages and limitations of\nemploying the Kullback-Leibler divergence in this setting. For example, we show\nthat minimizing the KL divergence between a wide class of parametric\ndistributions and the posterior induced by a (non-degenerate) Gaussian process\nprior leads to an ill-defined objective function. Then, we propose (featurized)\nBayesian linear regression as a benchmark for `function-space' inference\nmethods that directly measures approximation quality. We apply this methodology\nto assess aspects of the objective function and inference scheme considered in\nSun, Zhang, Shi, and Grosse (2018), emphasizing the quality of approximation to\nBayesian inference as opposed to predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:42:01 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Burt", "David R.", ""], ["Ober", "Sebastian W.", ""], ["Garriga-Alonso", "Adri\u00e0", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2011.09458", "submitter": "Austin Dulaney", "authors": "Austin R. Dulaney and John F. Brady", "title": "Machine Learning for Phase Behavior in Active Matter Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that deep learning techniques can be used to predict motility\ninduced phase separation (MIPS) in suspensions of active Brownian particles\n(ABPs) by creating a notion of phase at the particle level. Using a fully\nconnected network in conjunction with a graph neural network we use individual\nparticle features to predict to which phase a particle belongs. From this, we\nare able to compute the fraction of dilute particles to determine if the system\nis in the homogeneous dilute, dense, or coexistence region. Our predictions are\ncompared against the MIPS binodal computed from simulation. The strong\nagreement between the two suggests that machine learning provides an effective\nway to determine the phase behavior of ABPs and could prove useful for\ndetermining more complex phase diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:35:23 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Dulaney", "Austin R.", ""], ["Brady", "John F.", ""]]}, {"id": "2011.09465", "submitter": "Shintaro Fukushima", "authors": "Shintaro Fukushima and Kenji Yamanishi", "title": "Detecting Hierarchical Changes in Latent Variable Models", "comments": "12pages, Accepted to 20th IEEE International Conference on Data\n  Mining (ICDM2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the issue of detecting hierarchical changes in latent\nvariable models (HCDL) from data streams. There are three different levels of\nchanges for latent variable models: 1) the first level is the change in data\ndistribution for fixed latent variables, 2) the second one is that in the\ndistribution over latent variables, and 3) the third one is that in the number\nof latent variables. It is important to detect these changes because we can\nanalyze the causes of changes by identifying which level a change comes from\n(change interpretability). This paper proposes an information-theoretic\nframework for detecting changes of the three levels in a hierarchical way. The\nkey idea to realize it is to employ the MDL (minimum description length) change\nstatistics for measuring the degree of change, in combination with DNML\n(decomposed normalized maximum likelihood) code-length calculation. We give a\ntheoretical basis for making reliable alarms for changes. Focusing on\nstochastic block models, we employ synthetic and benchmark datasets to\nempirically demonstrate the effectiveness of our framework in terms of change\ninterpretability as well as change detection.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:46:10 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 19:29:55 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 01:34:53 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Fukushima", "Shintaro", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "2011.09468", "submitter": "Mohammad Pezeshki", "authors": "Mohammad Pezeshki, S\\'ekou-Oumar Kaba, Yoshua Bengio, Aaron Courville,\n  Doina Precup, Guillaume Lajoie", "title": "Gradient Starvation: A Learning Proclivity in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify and formalize a fundamental gradient descent phenomenon resulting\nin a learning proclivity in over-parameterized neural networks. Gradient\nStarvation arises when cross-entropy loss is minimized by capturing only a\nsubset of features relevant for the task, despite the presence of other\npredictive features that fail to be discovered. This work provides a\ntheoretical explanation for the emergence of such feature imbalance in neural\nnetworks. Using tools from Dynamical Systems theory, we identify simple\nproperties of learning dynamics during gradient descent that lead to this\nimbalance, and prove that such a situation can be expected given certain\nstatistical structure in training data. Based on our proposed formalism, we\ndevelop guarantees for a novel regularization method aimed at decoupling\nfeature learning dynamics, improving accuracy and robustness in cases hindered\nby gradient starvation. We illustrate our findings with simple and real-world\nout-of-distribution (OOD) generalization experiments.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:52:08 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 18:17:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pezeshki", "Mohammad", ""], ["Kaba", "S\u00e9kou-Oumar", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""], ["Precup", "Doina", ""], ["Lajoie", "Guillaume", ""]]}, {"id": "2011.09471", "submitter": "Leslie Smith", "authors": "Helena E. Liu and Leslie N. Smith", "title": "FROST: Faster and more Robust One-shot Semi-supervised Training", "comments": "Withdrawn because the results reported were due to an error in our\n  code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in one-shot semi-supervised learning have lowered the barrier\nfor deep learning of new applications. However, the state-of-the-art for\nsemi-supervised learning is slow to train and the performance is sensitive to\nthe choices of the labeled data and hyper-parameter values. In this paper, we\npresent a one-shot semi-supervised learning method that trains up to an order\nof magnitude faster and is more robust than state-of-the-art methods.\nSpecifically, we show that by combining semi-supervised learning with a\none-stage, single network version of self-training, our FROST methodology\ntrains faster and is more robust to choices for the labeled samples and changes\nin hyper-parameters. Our experiments demonstrate FROST's capability to perform\nwell when the composition of the unlabeled data is unknown; that is when the\nunlabeled data contain unequal numbers of each class and can contain\nout-of-distribution examples that don't belong to any of the training classes.\nHigh performance, speed of training, and insensitivity to hyper-parameters make\nFROST the most practical method for one-shot semi-supervised training. Our code\nis available at https://github.com/HelenaELiu/FROST.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:56:03 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 11:29:58 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 23:45:56 GMT"}, {"version": "v4", "created": "Fri, 4 Dec 2020 14:04:18 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Liu", "Helena E.", ""], ["Smith", "Leslie N.", ""]]}, {"id": "2011.09588", "submitter": "Youngseog Chung", "authors": "Youngseog Chung, Willie Neiswanger, Ian Char, Jeff Schneider", "title": "Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty\n  Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the many ways of quantifying uncertainty in a regression setting,\nspecifying the full quantile function is attractive, as quantiles are amenable\nto interpretation and evaluation. A model that predicts the true conditional\nquantiles for each input, at all quantile levels, presents a correct and\nefficient representation of the underlying uncertainty. To achieve this, many\ncurrent quantile-based methods focus on optimizing the so-called pinball loss.\nHowever, this loss restricts the scope of applicable regression models, limits\nthe ability to target many desirable properties (e.g. calibration, sharpness,\ncentered intervals), and may produce poor conditional quantiles. In this work,\nwe develop new quantile methods that address these shortcomings. In particular,\nwe propose methods that can apply to any class of regression model, allow for\nselecting a trade-off between calibration and sharpness, optimize for\ncalibration of centered intervals, and produce more accurate conditional\nquantiles. We provide a thorough experimental evaluation of our methods, which\nincludes a high dimensional uncertainty quantification task in nuclear fusion.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 23:51:23 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 23:41:04 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 10:10:50 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chung", "Youngseog", ""], ["Neiswanger", "Willie", ""], ["Char", "Ian", ""], ["Schneider", "Jeff", ""]]}, {"id": "2011.09592", "submitter": "Shrijita Bhattacharya", "authors": "Shrijita Bhattacharya, Zihuan Liu, Tapabrata Maiti", "title": "Variational Bayes Neural Network: Posterior Consistency, Classification\n  Accuracy and Computational Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Bayesian neural network models (BNN) have re-surged in recent years due to\nthe advancement of scalable computations and its utility in solving complex\nprediction problems in a wide variety of applications. Despite the popularity\nand usefulness of BNN, the conventional Markov Chain Monte Carlo based\nimplementation suffers from high computational cost, limiting the use of this\npowerful technique in large scale studies. The variational Bayes inference has\nbecome a viable alternative to circumvent some of the computational issues.\nAlthough the approach is popular in machine learning, its application in\nstatistics is somewhat limited. This paper develops a variational Bayesian\nneural network estimation methodology and related statistical theory. The\nnumerical algorithms and their implementational are discussed in detail. The\ntheory for posterior consistency, a desirable property in nonparametric\nBayesian statistics, is also developed. This theory provides an assessment of\nprediction accuracy and guidelines for characterizing the prior distributions\nand variational family. The loss of using a variational posterior over the true\nposterior has also been quantified. The development is motivated by an\nimportant biomedical engineering application, namely building predictive tools\nfor the transition from mild cognitive impairment to Alzheimer's disease. The\npredictors are multi-modal and may involve complex interactive relations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 00:11:27 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Bhattacharya", "Shrijita", ""], ["Liu", "Zihuan", ""], ["Maiti", "Tapabrata", ""]]}, {"id": "2011.09682", "submitter": "Sabrina Enriquez", "authors": "Sabrina Enriquez, Fushing Hsieh", "title": "Categorical exploratory data analysis on goodness-of-fit issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If the aphorism \"All models are wrong\"- George Box, continues to be true in\ndata analysis, particularly when analyzing real-world data, then we should\nannotate this wisdom with visible and explainable data-driven patterns. Such\nannotations can critically shed invaluable light on validity as well as\nlimitations of statistical modeling as a data analysis approach. In an effort\nto avoid holding our real data to potentially unattainable or even unrealistic\ntheoretical structures, we propose to utilize the data analysis paradigm called\nCategorical Exploratory Data Analysis (CEDA). We illustrate the merits of this\nproposal with two real-world data sets from the perspective of goodness-of-fit.\nIn both data sets, the Normal distribution's bell shape seemingly fits rather\nwell by first glance. We apply CEDA to bring out where and how each data fits\nor deviates from the model shape via several important distributional aspects.\nWe also demonstrate that CEDA affords a version of tree-based p-value, and\ncompare it with p-values based on traditional statistical approaches. Along our\ndata analysis, we invest computational efforts in making graphic display to\nilluminate the advantages of using CEDA as one primary way of data analysis in\nData Science education.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 06:11:06 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 01:41:15 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Enriquez", "Sabrina", ""], ["Hsieh", "Fushing", ""]]}, {"id": "2011.09707", "submitter": "Yizhou Qian", "authors": "Yizhou Qian, Mojtaba Forghani, Jonghyun Harry Lee, Matthew Farthing,\n  Tyler Hesser, Peter Kitanidis, Eric Darve", "title": "Application of Deep Learning-based Interpolation Methods to Nearshore\n  Bathymetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nearshore bathymetry, the topography of the ocean floor in coastal zones, is\nvital for predicting the surf zone hydrodynamics and for route planning to\navoid subsurface features. Hence, it is increasingly important for a wide\nvariety of applications, including shipping operations, coastal management, and\nrisk assessment. However, direct high resolution surveys of nearshore\nbathymetry are rarely performed due to budget constraints and logistical\nrestrictions. Another option when only sparse observations are available is to\nuse Gaussian Process regression (GPR), also called Kriging. But GPR has\ndifficulties recognizing patterns with sharp gradients, like those found around\nsand bars and submerged objects, especially when observations are sparse. In\nthis work, we present several deep learning-based techniques to estimate\nnearshore bathymetry with sparse, multi-scale measurements. We propose a Deep\nNeural Network (DNN) to compute posterior estimates of the nearshore\nbathymetry, as well as a conditional Generative Adversarial Network (cGAN) that\nsamples from the posterior distribution. We train our neural networks based on\nsynthetic data generated from nearshore surveys provided by the U.S.\\ Army\nCorps of Engineer Field Research Facility (FRF) in Duck, North Carolina. We\ncompare our methods with Kriging on real surveys as well as surveys with\nartificially added sharp gradients. Results show that direct estimation by DNN\ngives better predictions than Kriging in this application. We use bootstrapping\nwith DNN for uncertainty quantification. We also propose a method, named\nDNN-Kriging, that combines deep learning with Kriging and shows further\nimprovement of the posterior estimates.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 08:22:00 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Qian", "Yizhou", ""], ["Forghani", "Mojtaba", ""], ["Lee", "Jonghyun Harry", ""], ["Farthing", "Matthew", ""], ["Hesser", "Tyler", ""], ["Kitanidis", "Peter", ""], ["Darve", "Eric", ""]]}, {"id": "2011.09719", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, Evgenios M. Kornaropoulos, Dawn Song, David Wagner", "title": "Adversarial Examples for $k$-Nearest Neighbor Classifiers Based on\n  Higher-Order Voronoi Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples are a widely studied phenomenon in machine learning\nmodels. While most of the attention has been focused on neural networks, other\npractical models also suffer from this issue. In this work, we propose an\nalgorithm for evaluating the adversarial robustness of $k$-nearest neighbor\nclassification, i.e., finding a minimum-norm adversarial example. Diverging\nfrom previous proposals, we take a geometric approach by performing a search\nthat expands outwards from a given input point. On a high level, the search\nradius expands to the nearby Voronoi cells until we find a cell that classifies\ndifferently from the input point. To scale the algorithm to a large $k$, we\nintroduce approximation steps that find perturbations with smaller norm,\ncompared to the baselines, in a variety of datasets. Furthermore, we analyze\nthe structural properties of a dataset where our approach outperforms the\ncompetition.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 08:49:10 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Kornaropoulos", "Evgenios M.", ""], ["Song", "Dawn", ""], ["Wagner", "David", ""]]}, {"id": "2011.09733", "submitter": "Maryam MeshkinKiya", "authors": "Maryam MeshkinKiya, Riccardo Paolini", "title": "Preparing Weather Data for Real-Time Building Energy Simulation", "comments": "eSIM2021 accepted article", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study introduces a framework for quality control of measured weather\ndata, including anomaly detection, and infilling missing values. Weather data\nis a fundamental input to building performance simulations, in which anomalous\nvalues defect the results while missing data lead to an unexpected termination\nof the simulation process. Traditionally, infilling missing values in weather\ndata is performed through periodic or linear interpolations. However, when\nmissing values exceed many consecutive hours, the accuracy of traditional\nmethods is subject to debate. This study demonstrates how Neural Networks can\nincrease the accuracy of data imputation when compared to other supervised\nlearning methods. The framework is validated by predicting missing temperature\nand relative humidity data for an observation site, through a network of nearby\nweather stations in Milan, Italy. Results show that the proposed method can\nfacilitate real-time building simulations with accurate and rapid quality\ncontrol.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 09:18:07 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["MeshkinKiya", "Maryam", ""], ["Paolini", "Riccardo", ""]]}, {"id": "2011.09750", "submitter": "Jonathan Lee", "authors": "Jonathan N. Lee, Aldo Pacchiano, Vidya Muthukumar, Weihao Kong, Emma\n  Brunskill", "title": "Online Model Selection for Reinforcement Learning with Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved impressive successes yet often\nrequires a very large amount of interaction data. This result is perhaps\nunsurprising, as using complicated function approximation often requires more\ndata to fit, and early theoretical results on linear Markov decision processes\nprovide regret bounds that scale with the dimension of the linear\napproximation. Ideally, we would like to automatically identify the minimal\ndimension of the approximation that is sufficient to encode an optimal policy.\nTowards this end, we consider the problem of model selection in RL with\nfunction approximation, given a set of candidate RL algorithms with known\nregret guarantees. The learner's goal is to adapt to the complexity of the\noptimal algorithm without knowing it \\textit{a priori}. We present a\nmeta-algorithm that successively rejects increasingly complex models using a\nsimple statistical test. Given at least one candidate that satisfies\nrealizability, we prove the meta-algorithm adapts to the optimal complexity\nwith $\\tilde{O}(L^{5/6} T^{2/3})$ regret compared to the optimal candidate's\n$\\tilde{O}(\\sqrt T)$ regret, where $T$ is the number of episodes and $L$ is the\nnumber of algorithms. The dimension and horizon dependencies remain optimal\nwith respect to the best candidate, and our meta-algorithmic approach is\nflexible to incorporate multiple candidate algorithms and models. Finally, we\nshow that the meta-algorithm automatically admits significantly improved\ninstance-dependent regret bounds that depend on the gaps between the maximal\nvalues attainable by the candidates.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 10:00:54 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lee", "Jonathan N.", ""], ["Pacchiano", "Aldo", ""], ["Muthukumar", "Vidya", ""], ["Kong", "Weihao", ""], ["Brunskill", "Emma", ""]]}, {"id": "2011.09815", "submitter": "Lijing Lin", "authors": "Lijing Lin, Matthew Sperrin, David A. Jenkins, Glen P. Martin, Niels\n  Peek", "title": "A scoping review of causal methods enabling predictions under\n  hypothetical interventions", "comments": null, "journal-ref": "Diagnostic and Prognostic Research, 2021", "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Aims: The methods with which prediction models are usually\ndeveloped mean that neither the parameters nor the predictions should be\ninterpreted causally. However, when prediction models are used to support\ndecision making, there is often a need for predicting outcomes under\nhypothetical interventions. We aimed to identify published methods for\ndeveloping and validating prediction models that enable risk estimation of\noutcomes under hypothetical interventions, utilizing causal inference: their\nmain methodological approaches, underlying assumptions, targeted estimands, and\npotential pitfalls and challenges with using the method, and unresolved\nmethodological challenges.\n  Methods: We systematically reviewed literature published by December 2019,\nconsidering papers in the health domain that used causal considerations to\nenable prediction models to be used for predictions under hypothetical\ninterventions.\n  Results: We identified 4919 papers through database searches and a further\n115 papers through manual searches, of which 13 were selected for inclusion,\nfrom both the statistical and the machine learning literature. Most of the\nidentified methods for causal inference from observational data were based on\nmarginal structural models and g-estimation.\n  Conclusions: There exist two broad methodological approaches for allowing\nprediction under hypothetical intervention into clinical prediction models: 1)\nenriching prediction models derived from observational studies with estimated\ncausal effects from clinical trials and meta-analyses; and 2) estimating\nprediction models and causal effects directly from observational data. These\nmethods require extending to dynamic treatment regimes, and consideration of\nmultiple interventions to operationalise a clinical decision support system.\nTechniques for validating 'causal prediction models' are still in their\ninfancy.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:36:26 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 15:31:04 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Lin", "Lijing", ""], ["Sperrin", "Matthew", ""], ["Jenkins", "David A.", ""], ["Martin", "Glen P.", ""], ["Peek", "Niels", ""]]}, {"id": "2011.09841", "submitter": "Chen Lu", "authors": "Chen Lu, Subhabrata Sen", "title": "Contextual Stochastic Block Model: Sharp Thresholds and Contiguity", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study community detection in the contextual stochastic block model\narXiv:1807.09596 [cs.SI], arXiv:1607.02675 [stat.ME]. In arXiv:1807.09596\n[cs.SI], the second author studied this problem in the setting of sparse graphs\nwith high-dimensional node-covariates. Using the non-rigorous cavity method\nfrom statistical physics, they conjectured the sharp limits for community\ndetection in this setting. Further, the information theoretic threshold was\nverified, assuming that the average degree of the observed graph is large. It\nis expected that the conjecture holds as soon as the average degree exceeds\none, so that the graph has a giant component. We establish this conjecture, and\ncharacterize the sharp threshold for detection and weak recovery.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 16:14:14 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lu", "Chen", ""], ["Sen", "Subhabrata", ""]]}, {"id": "2011.09973", "submitter": "Kevin Tian", "authors": "Ilias Diakonikolas, Daniel M. Kane, Daniel Kongsgaard, Jerry Li, Kevin\n  Tian", "title": "List-Decodable Mean Estimation in Nearly-PCA Time", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, robust statistics has focused on designing estimators tolerant\nto a minority of contaminated data. Robust list-decodable learning focuses on\nthe more challenging regime where only a minority $\\frac 1 k$ fraction of the\ndataset is drawn from the distribution of interest, and no assumptions are made\non the remaining data. We study the fundamental task of list-decodable mean\nestimation in high dimensions. Our main result is a new list-decodable mean\nestimation algorithm for bounded covariance distributions with optimal sample\ncomplexity and error rate, running in nearly-PCA time. Assuming the ground\ntruth distribution on $\\mathbb{R}^d$ has bounded covariance, our algorithm\noutputs a list of $O(k)$ candidate means, one of which is within distance\n$O(\\sqrt{k})$ from the truth. Our algorithm runs in time $\\widetilde{O}(ndk)$\nfor all $k = O(\\sqrt{d}) \\cup \\Omega(d)$, where $n$ is the size of the dataset.\nWe also show that a variant of our algorithm has runtime $\\widetilde{O}(ndk)$\nfor all $k$, at the expense of an $O(\\sqrt{\\log k})$ factor in the recovery\nguarantee. This runtime matches up to logarithmic factors the cost of\nperforming a single $k$-PCA on the data, which is a natural bottleneck of known\nalgorithms for (very) special cases of our problem, such as clustering\nwell-separated mixtures. Prior to our work, the fastest list-decodable mean\nestimation algorithms had runtimes $\\widetilde{O}(n^2 d k^2)$ and\n$\\widetilde{O}(nd k^{\\ge 6})$.\n  Our approach builds on a novel soft downweighting method, $\\mathsf{SIFT}$,\nwhich is arguably the simplest known polynomial-time mean estimation technique\nin the list-decodable learning setting. To develop our fast algorithms, we\nboost the computational cost of $\\mathsf{SIFT}$ via a careful \"win-win-win\"\nanalysis of an approximate Ky Fan matrix multiplicative weights procedure we\ndevelop, which we believe may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:21:37 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Kongsgaard", "Daniel", ""], ["Li", "Jerry", ""], ["Tian", "Kevin", ""]]}, {"id": "2011.10006", "submitter": "Holden Lee", "authors": "Holden Lee", "title": "Improved rates for identification of partially observed linear dynamical\n  systems", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of a linear time-invariant dynamical system from partial\nobservations is a fundamental problem in control theory. A natural question is\nhow to do so with non-asymptotic statistical rates depending on the inherent\ndimensionality (order) $d$ of the system, rather than on the sufficient rollout\nlength or on $\\frac1{1-\\rho(A)}$, where $\\rho(A)$ is the spectral radius of the\ndynamics matrix. We develop the first algorithm that given a single trajectory\nof length $T$ with gaussian observation noise, achieves a near-optimal rate of\n$\\widetilde O\\left(\\sqrt\\frac{d}{T}\\right)$ in $\\mathcal{H}_2$ error for the\nlearned system. We also give bounds under process noise and improved bounds for\nlearning a realization of the system. Our algorithm is based on low-rank\napproximation of Hankel matrices of geometrically increasing sizes.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:04:18 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lee", "Holden", ""]]}, {"id": "2011.10007", "submitter": "Jiayuan Mao", "authors": "Yikai Li, Jiayuan Mao, Xiuming Zhang, William T. Freeman, Joshua B.\n  Tenenbaum, Noah Snavely, Jiajun Wu", "title": "Multi-Plane Program Induction with 3D Box Priors", "comments": "NeurIPS 2020. First two authors contributed equally. Project page:\n  http://bpi.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two important aspects in understanding and editing images:\nmodeling regular, program-like texture or patterns in 2D planes, and 3D posing\nof these planes in the scene. Unlike prior work on image-based program\nsynthesis, which assumes the image contains a single visible 2D plane, we\npresent Box Program Induction (BPI), which infers a program-like scene\nrepresentation that simultaneously models repeated structure on multiple 2D\nplanes, the 3D position and orientation of the planes, and camera parameters,\nall from a single image. Our model assumes a box prior, i.e., that the image\ncaptures either an inner view or an outer view of a box in 3D. It uses neural\nnetworks to infer visual cues such as vanishing points, wireframe lines to\nguide a search-based algorithm to find the program that best explains the\nimage. Such a holistic, structured scene representation enables 3D-aware\ninteractive image editing operations such as inpainting missing pixels,\nchanging camera parameters, and extrapolate the image contents.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:07:46 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:13:03 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Yikai", ""], ["Mao", "Jiayuan", ""], ["Zhang", "Xiuming", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Snavely", "Noah", ""], ["Wu", "Jiajun", ""]]}, {"id": "2011.10065", "submitter": "Mathurin Massias", "authors": "Quentin Bertrand and Mathurin Massias", "title": "Anderson acceleration of coordinate descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acceleration of first order methods is mainly obtained via inertial\ntechniques \\`a la Nesterov, or via nonlinear extrapolation. The latter has\nknown a recent surge of interest, with successful applications to gradient and\nproximal gradient techniques. On multiple Machine Learning problems, coordinate\ndescent achieves performance significantly superior to full-gradient methods.\nSpeeding up coordinate descent in practice is not easy: inertially accelerated\nversions of coordinate descent are theoretically accelerated, but might not\nalways lead to practical speed-ups. We propose an accelerated version of\ncoordinate descent using extrapolation, showing considerable speed up in\npractice, compared to inertial accelerated coordinate descent and extrapolated\n(proximal) gradient descent. Experiments on least squares, Lasso, elastic net\nand logistic regression validate the approach.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 19:01:48 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 08:43:43 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Bertrand", "Quentin", ""], ["Massias", "Mathurin", ""]]}, {"id": "2011.10117", "submitter": "Ryan McGranaghan", "authors": "Ryan M. McGranaghan, Jack Ziegler, T\\'eo Bloch, Spencer Hatch, Enrico\n  Camporeale, Kristina Lynch, Mathew Owens, Jesper Gjerloev, Binzheng Zhang,\n  Susan Skone", "title": "Toward a Next Generation Particle Precipitation Model: Mesoscale\n  Prediction Through Machine Learning (a Case Study and Framework for Progress)", "comments": "Published in Space Weather Journal", "journal-ref": "Space Weather, 19, e2020SW002684 (2021)", "doi": "10.1029/2020SW002684", "report-no": null, "categories": "physics.space-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advance the modeling capability of electron particle precipitation from\nthe magnetosphere to the ionosphere through a new database and use of machine\nlearning (ML) tools to gain utility from those data. We have compiled, curated,\nanalyzed, and made available a new and more capable database of particle\nprecipitation data that includes 51 satellite years of Defense Meteorological\nSatellite Program (DMSP) observations temporally aligned with solar wind and\ngeomagnetic activity data. The new total electron energy flux particle\nprecipitation nowcast model, a neural network called PrecipNet, takes advantage\nof increased expressive power afforded by ML approaches to appropriately\nutilize diverse information from the solar wind and geomagnetic activity and,\nimportantly, their time histories. With a more capable representation of the\norganizing parameters and the target electron energy flux observations,\nPrecipNet achieves a >50% reduction in errors from a current state-of-the-art\nmodel oval variation, assessment, tracking, intensity, and online nowcasting\n(OVATION Prime), better captures the dynamic changes of the auroral flux, and\nprovides evidence that it can capably reconstruct mesoscale phenomena. We\ncreate and apply a new framework for space weather model evaluation that\nculminates previous guidance from across the solar-terrestrial research\ncommunity. The research approach and results are representative of the \"new\nfrontier\" of space weather research at the intersection of traditional and data\nscience-driven discovery and provides a foundation for future efforts.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 21:54:36 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 18:19:33 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["McGranaghan", "Ryan M.", ""], ["Ziegler", "Jack", ""], ["Bloch", "T\u00e9o", ""], ["Hatch", "Spencer", ""], ["Camporeale", "Enrico", ""], ["Lynch", "Kristina", ""], ["Owens", "Mathew", ""], ["Gjerloev", "Jesper", ""], ["Zhang", "Binzheng", ""], ["Skone", "Susan", ""]]}, {"id": "2011.10218", "submitter": "Ryan Burn", "authors": "Ryan Burn", "title": "Optimizing Approximate Leave-one-out Cross-validation to Tune\n  Hyperparameters", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a large class of regularized models, leave-one-out cross-validation can\nbe efficiently estimated with an approximate leave-one-out formula (ALO). We\nconsider the problem of adjusting hyperparameters so as to optimize ALO. We\nderive efficient formulas to compute the gradient and hessian of ALO and show\nhow to apply a second-order optimizer to find hyperparameters. We demonstrate\nthe usefulness of the proposed approach by finding hyperparameters for\nregularized logistic regression and ridge regression on various real-world data\nsets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 04:57:41 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Burn", "Ryan", ""]]}, {"id": "2011.10254", "submitter": "Xiang Fang", "authors": "Xiang Fang, Yuchong Hu, Pan Zhou, and Dapeng Oliver Wu", "title": "Unbalanced Incomplete Multi-view Clustering via the Scheme of View\n  Evolution: Weak Views are Meat; Strong Views do Eat", "comments": "Accepted by IEEE Transactions on Emerging Topics in Computational\n  Intelligence", "journal-ref": "IEEE Transactions on Emerging Topics in Computational Intelligence\n  2021", "doi": "10.1109/TETCI.2021.3077909", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incomplete multi-view clustering is an important technique to deal with\nreal-world incomplete multi-view data. Previous works assume that all views\nhave the same incompleteness, i.e., balanced incompleteness. However, different\nviews often have distinct incompleteness, i.e., unbalanced incompleteness,\nwhich results in strong views (low-incompleteness views) and weak views\n(high-incompleteness views). The unbalanced incompleteness prevents us from\ndirectly using the previous methods for clustering. In this paper, inspired by\nthe effective biological evolution theory, we design the novel scheme of view\nevolution to cluster strong and weak views. Moreover, we propose an Unbalanced\nIncomplete Multi-view Clustering method (UIMC), which is the first effective\nmethod based on view evolution for unbalanced incomplete multi-view clustering.\nCompared with previous methods, UIMC has two unique advantages: 1) it proposes\nweighted multi-view subspace clustering to integrate these unbalanced\nincomplete views, which effectively solves the unbalanced incomplete multi-view\nproblem; 2) it designs the low-rank and robust representation to recover the\ndata, which diminishes the impact of the incompleteness and noises. Extensive\nexperimental results demonstrate that UIMC improves the clustering performance\nby up to 40% on three evaluation metrics over other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:00:25 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 08:51:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Fang", "Xiang", ""], ["Hu", "Yuchong", ""], ["Zhou", "Pan", ""], ["Wu", "Dapeng Oliver", ""]]}, {"id": "2011.10334", "submitter": "Tal Shapira", "authors": "Yaniv Fogel, Tal Shapira and Meir Feder", "title": "Efficient Data-Dependent Learnability", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictive normalized maximum likelihood (pNML) approach has recently\nbeen proposed as the min-max optimal solution to the batch learning problem\nwhere both the training set and the test data feature are individuals, known\nsequences. This approach has yields a learnability measure that can also be\ninterpreted as a stability measure. This measure has shown some potential in\ndetecting out-of-distribution examples, yet it has considerable computational\ncosts. In this project, we propose and analyze an approximation of the pNML,\nwhich is based on influence functions. Combining both theoretical analysis and\nexperiments, we show that when applied to neural networks, this approximation\ncan detect out-of-distribution examples effectively. We also compare its\nperformance to that achieved by conducting a single gradient step for each\npossible label.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 10:44:55 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Fogel", "Yaniv", ""], ["Shapira", "Tal", ""], ["Feder", "Meir", ""]]}, {"id": "2011.10443", "submitter": "Ali Unlu", "authors": "Ali Unlu, Laurence Aitchison", "title": "Gradient Regularisation as Approximate Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference in Bayesian neural networks is usually performed using\nstochastic sampling which gives very high-variance gradients, and hence slow\nlearning. Here, we show that it is possible to obtain a deterministic\napproximation of the ELBO for a Bayesian neural network by doing a\nTaylor-series expansion around the mean of the current variational\ndistribution. The resulting approximate ELBO is the training-log-likelihood\nplus a squared gradient regulariser. In addition to learning the approximate\nposterior variance, we also consider a uniform-variance approximate posterior,\ninspired by the stationary distribution of SGD. The corresponding approximate\nELBO has a simple form, as the log-likelihood plus a simple squared-gradient\nregulariser. We argue that this squared-gradient regularisation may at the root\nof the excellent empirical performance of SGD.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:16:18 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Unlu", "Ali", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2011.10464", "submitter": "Xinyi Xu Mr", "authors": "Xinyi Xu and Lingjuan Lyu", "title": "A Reputation Mechanism Is All You Need: Collaborative Fairness and\n  Adversarial Robustness in Federated Learning", "comments": "Accepted as Oral presentation at International Workshop on Federated\n  Learning for User Privacy and Data Confidentiality in Conjunction with ICML\n  2021 (FL-ICML'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging practical framework for effective and\nscalable machine learning among multiple participants, such as end users,\norganizations and companies. However, most existing FL or distributed learning\nframeworks have not well addressed two important issues together: collaborative\nfairness and adversarial robustness (e.g. free-riders and malicious\nparticipants). In conventional FL, all participants receive the global model\n(equal rewards), which might be unfair to the high-contributing participants.\nFurthermore, due to the lack of a safeguard mechanism, free-riders or malicious\nadversaries could game the system to access the global model for free or to\nsabotage it. In this paper, we propose a novel Robust and Fair Federated\nLearning (RFFL) framework to achieve collaborative fairness and adversarial\nrobustness simultaneously via a reputation mechanism. RFFL maintains a\nreputation for each participant by examining their contributions via their\nuploaded gradients (using vector similarity) and thus identifies\nnon-contributing or malicious participants to be removed. Our approach\ndifferentiates itself by not requiring any auxiliary/validation dataset.\nExtensive experiments on benchmark datasets show that RFFL can achieve high\nfairness and is very robust to different types of adversaries while achieving\ncompetitive predictive accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:52:45 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 12:39:59 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Xu", "Xinyi", ""], ["Lyu", "Lingjuan", ""]]}, {"id": "2011.10475", "submitter": "Jong Chul Ye", "authors": "Eunju Cha, Chanseok Lee, Mooseok Jang, and Jong Chul Ye", "title": "DeepPhaseCut: Deep Relaxation in Phase for Unsupervised Fourier Phase\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier phase retrieval is a classical problem of restoring a signal only\nfrom the measured magnitude of its Fourier transform. Although Fienup-type\nalgorithms, which use prior knowledge in both spatial and Fourier domains, have\nbeen widely used in practice, they can often stall in local minima. Modern\nmethods such as PhaseLift and PhaseCut may offer performance guarantees with\nthe help of convex relaxation. However, these algorithms are usually\ncomputationally intensive for practical use. To address this problem, we\npropose a novel, unsupervised, feed-forward neural network for Fourier phase\nretrieval which enables immediate high quality reconstruction. Unlike the\nexisting deep learning approaches that use a neural network as a regularization\nterm or an end-to-end blackbox model for supervised training, our algorithm is\na feed-forward neural network implementation of PhaseCut algorithm in an\nunsupervised learning framework. Specifically, our network is composed of two\ngenerators: one for the phase estimation using PhaseCut loss, followed by\nanother generator for image reconstruction, all of which are trained\nsimultaneously using a cycleGAN framework without matched data. The link to the\nclassical Fienup-type algorithms and the recent symmetry-breaking learning\napproach is also revealed. Extensive experiments demonstrate that the proposed\nmethod outperforms all existing approaches in Fourier phase retrieval problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:10:08 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Cha", "Eunju", ""], ["Lee", "Chanseok", ""], ["Jang", "Mooseok", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2011.10480", "submitter": "Zhongyang Li", "authors": "Zhongyang Li and Fei Lu", "title": "On the coercivity condition in the learning of interacting particle\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the learning of systems of interacting particles or agents, coercivity\ncondition ensures identifiability of the interaction functions, providing the\nfoundation of learning by nonparametric regression. The coercivity condition is\nequivalent to the strictly positive definiteness of an integral kernel arising\nin the learning. We show that for a class of interaction functions such that\nthe system is ergodic, the integral kernel is strictly positive definite, and\nhence the coercivity condition holds true.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:20:06 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Li", "Zhongyang", ""], ["Lu", "Fei", ""]]}, {"id": "2011.10487", "submitter": "Konstantinos Spiliopoulos", "authors": "Jiahui Yu and Konstantinos Spiliopoulos", "title": "Normalization effects on shallow neural networks and related asymptotic\n  expansions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider shallow (single hidden layer) neural networks and characterize\ntheir performance when trained with stochastic gradient descent as the number\nof hidden units $N$ and gradient descent steps grow to infinity. In particular,\nwe investigate the effect of different scaling schemes, which lead to different\nnormalizations of the neural network, on the network's statistical output,\nclosing the gap between the $1/\\sqrt{N}$ and the mean-field $1/N$\nnormalization. We develop an asymptotic expansion for the neural network's\nstatistical output pointwise with respect to the scaling parameter as the\nnumber of hidden units grows to infinity. Based on this expansion, we\ndemonstrate mathematically that to leading order in $N$, there is no\nbias-variance trade off, in that both bias and variance (both explicitly\ncharacterized) decrease as the number of hidden units increases and time grows.\nIn addition, we show that to leading order in $N$, the variance of the neural\nnetwork's statistical output decays as the implied normalization by the scaling\nparameter approaches the mean field normalization. Numerical studies on the\nMNIST and CIFAR10 datasets show that test and train accuracy monotonically\nimprove as the neural network's normalization gets closer to the mean field\nnormalization.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:33:28 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 17:59:19 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Yu", "Jiahui", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "2011.10545", "submitter": "Evaldas Vaiciukynas Dr.", "authors": "Evaldas Vaiciukynas, Paulius Danenas, Vilius Kontrimas, Rimantas\n  Butleris", "title": "Meta-Learning for Time Series Forecasting Ensemble", "comments": "Submitted for review to Journal of Forecasting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amounts of historical data collected increase together with business\nintelligence applicability and demands for automatic forecasting of time\nseries. While no single time series modeling method is universal to all types\nof dynamics, forecasting using ensemble of several methods is often seen as a\ncompromise. Instead of fixing ensemble diversity and size we propose to\nadaptively predict these aspects using meta-learning. Meta-learning here\nconsiders two separate random forest regression models, built on 390 time\nseries features, to rank 22 univariate forecasting methods and to recommend\nensemble size. Forecasting ensemble is consequently formed from methods ranked\nas the best and forecasts are pooled using either simple or weighted average\n(with weight corresponding to reciprocal rank). Proposed approach was tested on\n12561 micro-economic time series (expanded to 38633 for various forecasting\nhorizons) of M4 competition where meta-learning outperformed Theta and Comb\nbenchmarks by relative forecasting errors for all data types and horizons. Best\noverall results were achieved by weighted pooling with symmetric mean absolute\npercentage error of 9.21% versus 11.05% obtained using Theta method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 18:35:02 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Vaiciukynas", "Evaldas", ""], ["Danenas", "Paulius", ""], ["Kontrimas", "Vilius", ""], ["Butleris", "Rimantas", ""]]}, {"id": "2011.10575", "submitter": "Ruby Sedgwick", "authors": "Ruby Sedgwick, John Goertz, Molly Stevens, Ruth Misener, Mark van der\n  Wilk", "title": "Design of Experiments for Verifying Biomolecular Networks", "comments": "Comment: Updated to correct typo \"that that\" => \"that\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a growing trend in molecular and synthetic biology of using\nmechanistic (non machine learning) models to design biomolecular networks. Once\ndesigned, these networks need to be validated by experimental results to ensure\nthe theoretical network correctly models the true system. However, these\nexperiments can be expensive and time consuming. We propose a design of\nexperiments approach for validating these networks efficiently. Gaussian\nprocesses are used to construct a probabilistic model of the discrepancy\nbetween experimental results and the designed response, then a Bayesian\noptimization strategy used to select the next sample points. We compare\ndifferent design criteria and develop a stopping criterion based on a metric\nthat quantifies this discrepancy over the whole surface, and its uncertainty.\nWe test our strategy on simulated data from computer models of biochemical\nprocesses.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:39:45 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:51:24 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Sedgwick", "Ruby", ""], ["Goertz", "John", ""], ["Stevens", "Molly", ""], ["Misener", "Ruth", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2011.10607", "submitter": "Christopher Dean", "authors": "Christopher L. Dean, Stephen J. Lee, Jason Pacheco, John W. Fisher III", "title": "Lightweight Data Fusion with Conjugate Mappings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to data fusion that combines the interpretability of\nstructured probabilistic graphical models with the flexibility of neural\nnetworks. The proposed method, lightweight data fusion (LDF), emphasizes\nposterior analysis over latent variables using two types of information:\nprimary data, which are well-characterized but with limited availability, and\nauxiliary data, readily available but lacking a well-characterized statistical\nrelationship to the latent quantity of interest. The lack of a forward model\nfor the auxiliary data precludes the use of standard data fusion approaches,\nwhile the inability to acquire latent variable observations severely limits\ndirect application of most supervised learning methods. LDF addresses these\nissues by utilizing neural networks as conjugate mappings of the auxiliary\ndata: nonlinear transformations into sufficient statistics with respect to the\nlatent variables. This facilitates efficient inference by preserving the\nconjugacy properties of the primary data and leads to compact representations\nof the latent variable posterior distributions. We demonstrate the LDF\nmethodology on two challenging inference problems: (1) learning electrification\nrates in Rwanda from satellite imagery, high-level grid infrastructure, and\nother sources; and (2) inferring county-level homicide rates in the USA by\nintegrating socio-economic data using a mixture model of multiple conjugate\nmappings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 19:47:13 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Dean", "Christopher L.", ""], ["Lee", "Stephen J.", ""], ["Pacheco", "Jason", ""], ["Fisher", "John W.", "III"]]}, {"id": "2011.10643", "submitter": "Abolfazl Hashemi", "authors": "Abolfazl Hashemi, Anish Acharya, Rudrajit Das, Haris Vikalo, Sujay\n  Sanghavi, Inderjit Dhillon", "title": "On the Benefits of Multiple Gossip Steps in Communication-Constrained\n  Decentralized Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized optimization, it is common algorithmic practice to have\nnodes interleave (local) gradient descent iterations with gossip (i.e.\naveraging over the network) steps. Motivated by the training of large-scale\nmachine learning models, it is also increasingly common to require that\nmessages be {\\em lossy compressed} versions of the local parameters. In this\npaper, we show that, in such compressed decentralized optimization settings,\nthere are benefits to having {\\em multiple} gossip steps between subsequent\ngradient iterations, even when the cost of doing so is appropriately accounted\nfor e.g. by means of reducing the precision of compressed information. In\nparticular, we show that having $O(\\log\\frac{1}{\\epsilon})$ gradient iterations\n{with constant step size} - and $O(\\log\\frac{1}{\\epsilon})$ gossip steps\nbetween every pair of these iterations - enables convergence to within\n$\\epsilon$ of the optimal value for smooth non-convex objectives satisfying\nPolyak-\\L{}ojasiewicz condition. This result also holds for smooth strongly\nconvex objectives. To our knowledge, this is the first work that derives\nconvergence results for nonconvex optimization under arbitrary communication\ncompression.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:17:32 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Hashemi", "Abolfazl", ""], ["Acharya", "Anish", ""], ["Das", "Rudrajit", ""], ["Vikalo", "Haris", ""], ["Sanghavi", "Sujay", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2011.10695", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Zhenyu Liao, Edgar Dobriban and Michael W.\n  Mahoney", "title": "Sparse sketches with small inversion bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a tall $n\\times d$ matrix $A$ and a random $m\\times n$ sketching matrix\n$S$, the sketched estimate of the inverse covariance matrix $(A^\\top A)^{-1}$\nis typically biased: $E[(\\tilde A^\\top\\tilde A)^{-1}]\\ne(A^\\top A)^{-1}$, where\n$\\tilde A=SA$. This phenomenon, which we call inversion bias, arises, e.g., in\nstatistics and distributed optimization, when averaging multiple independently\nconstructed estimates of quantities that depend on the inverse covariance. We\ndevelop a framework for analyzing inversion bias, based on our proposed concept\nof an $(\\epsilon,\\delta)$-unbiased estimator for random matrices. We show that\nwhen the sketching matrix $S$ is dense and has i.i.d. sub-gaussian entries,\nthen after simple rescaling, the estimator $(\\frac m{m-d}\\tilde A^\\top\\tilde\nA)^{-1}$ is $(\\epsilon,\\delta)$-unbiased for $(A^\\top A)^{-1}$ with a sketch of\nsize $m=O(d+\\sqrt d/\\epsilon)$. This implies that for $m=O(d)$, the inversion\nbias of this estimator is $O(1/\\sqrt d)$, which is much smaller than the\n$\\Theta(1)$ approximation error obtained as a consequence of the subspace\nembedding guarantee for sub-gaussian sketches. We then propose a new sketching\ntechnique, called LEverage Score Sparsified (LESS) embeddings, which uses ideas\nfrom both data-oblivious sparse embeddings as well as data-aware leverage-based\nrow sampling methods, to get $\\epsilon$ inversion bias for sketch size\n$m=O(d\\log d+\\sqrt d/\\epsilon)$ in time $O(\\text{nnz}(A)\\log n+md^2)$, where\nnnz is the number of non-zeros. The key techniques enabling our analysis\ninclude an extension of a classical inequality of Bai and Silverstein for\nrandom quadratic forms, which we call the Restricted Bai-Silverstein\ninequality; and anti-concentration of the Binomial distribution via the\nPaley-Zygmund inequality, which we use to prove a lower bound showing that\nleverage score sampling sketches generally do not achieve small inversion bias.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 01:33:15 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 01:24:51 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Liao", "Zhenyu", ""], ["Dobriban", "Edgar", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2011.10741", "submitter": "Kaixin Gao", "authors": "Kai-Xin Gao, Xiao-Lei Liu, Zheng-Hai Huang, Min Wang, Zidong Wang,\n  Dachuan Xu, Fan Yu", "title": "A Trace-restricted Kronecker-Factored Approximation to Natural Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Second-order optimization methods have the ability to accelerate convergence\nby modifying the gradient through the curvature matrix. There have been many\nattempts to use second-order optimization methods for training deep neural\nnetworks. Inspired by diagonal approximations and factored approximations such\nas Kronecker-Factored Approximate Curvature (KFAC), we propose a new\napproximation to the Fisher information matrix (FIM) called Trace-restricted\nKronecker-factored Approximate Curvature (TKFAC) in this work, which can hold\nthe certain trace relationship between the exact and the approximate FIM. In\nTKFAC, we decompose each block of the approximate FIM as a Kronecker product of\ntwo smaller matrices and scaled by a coefficient related to trace. We\ntheoretically analyze TKFAC's approximation error and give an upper bound of\nit. We also propose a new damping technique for TKFAC on convolutional neural\nnetworks to maintain the superiority of second-order optimization methods\nduring training. Experiments show that our method has better performance\ncompared with several state-of-the-art algorithms on some deep network\narchitectures.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 07:47:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Gao", "Kai-Xin", ""], ["Liu", "Xiao-Lei", ""], ["Huang", "Zheng-Hai", ""], ["Wang", "Min", ""], ["Wang", "Zidong", ""], ["Xu", "Dachuan", ""], ["Yu", "Fan", ""]]}, {"id": "2011.10797", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos and Ryan Murray", "title": "Adversarial Classification: Necessary conditions and geometric flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a version of adversarial classification where an adversary is\nempowered to corrupt data inputs up to some distance $\\varepsilon$, using tools\nfrom variational analysis. In particular, we describe necessary conditions\nassociated with the optimal classifier subject to such an adversary. Using the\nnecessary conditions, we derive a geometric evolution equation which can be\nused to track the change in classification boundaries as $\\varepsilon$ varies.\nThis evolution equation may be described as an uncoupled system of differential\nequations in one dimension, or as a mean curvature type equation in higher\ndimension. In one dimension we rigorously prove that one can use the initial\nvalue problem starting from $\\varepsilon=0$, which is simply the Bayes\nclassifier, in order to solve for the global minimizer of the adversarial\nproblem. Numerical examples illustrating these ideas are also presented.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 14:14:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Murray", "Ryan", ""]]}, {"id": "2011.10801", "submitter": "Gi-Ren Liu", "authors": "Gi-Ren Liu, Yuan-Chung Sheu, Hau-Tieng Wu", "title": "Central and Non-central Limit Theorems arising from the Scattering\n  Transform and its Neural Activation Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by analyzing complicated and non-stationary time series, we study a\ngeneralization of the scattering transform (ST) that includes broad neural\nactivation functions, which is called neural activation ST (NAST). On the\nwhole, NAST is a transform that comprises a sequence of ``neural processing\nunits'', each of which applies a high pass filter to the input from the\nprevious layer followed by a composition with a nonlinear function as the\noutput to the next neuron. Here, the nonlinear function models how a neuron\ngets excited by the input signal. In addition to showing properties like\nnon-expansion, horizontal translational invariability and insensitivity to\nlocal deformation, the statistical properties of the second order NAST of a\nGaussian process with various dependence and (non-)stationarity structure and\nits interaction with the chosen high pass filters and activation functions are\nexplored and central limit theorem (CLT) and non-CLT results are provided.\nNumerical simulations are also provided. The results explain how NAST processes\ncomplicated and non-stationary time series, and pave a way towards statistical\ninference based on NAST under the non-null case.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 14:31:57 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Liu", "Gi-Ren", ""], ["Sheu", "Yuan-Chung", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "2011.10861", "submitter": "Xiaowei Yue", "authors": "Cheolhei Lee, Jianguo Wu, Wenjia Wang, Xiaowei Yue", "title": "Neural Network Gaussian Process Considering Input Uncertainty for\n  Composite Structures Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing machine learning enabled smart manufacturing is promising for\ncomposite structures assembly process. To improve production quality and\nefficiency of the assembly process, accurate predictive analysis on dimensional\ndeviations and residual stress of the composite structures is required. The\nnovel composite structures assembly involves two challenges: (i) the highly\nnonlinear and anisotropic properties of composite materials; and (ii)\ninevitable uncertainty in the assembly process. To overcome those problems, we\npropose a neural network Gaussian process model considering input uncertainty\nfor composite structures assembly. Deep architecture of our model allows us to\napproximate a complex process better, and consideration of input uncertainty\nenables robust modeling with complete incorporation of the process uncertainty.\nBased on simulation and case study, the NNGPIU can outperform other benchmark\nmethods when the response function is nonsmooth and nonlinear. Although we use\ncomposite structure assembly as an example, the proposed methodology can be\napplicable to other engineering systems with intrinsic uncertainties.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 20:21:28 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lee", "Cheolhei", ""], ["Wu", "Jianguo", ""], ["Wang", "Wenjia", ""], ["Yue", "Xiaowei", ""]]}, {"id": "2011.10925", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Locally Linear Embedding and its Variants: Tutorial and Survey", "comments": "To appear as a part of an upcoming textbook on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a tutorial and survey paper for Locally Linear Embedding (LLE) and\nits variants. The idea of LLE is fitting the local structure of manifold in the\nembedding space. In this paper, we first cover LLE, kernel LLE, inverse LLE,\nand feature fusion with LLE. Then, we cover out-of-sample embedding using\nlinear reconstruction, eigenfunctions, and kernel mapping. Incremental LLE is\nexplained for embedding streaming data. Landmark LLE methods using the Nystrom\napproximation and locally linear landmarks are explained for big data\nembedding. We introduce the methods for parameter selection of number of\nneighbors using residual variance, Procrustes statistics, preservation\nneighborhood error, and local neighborhood selection. Afterwards, Supervised\nLLE (SLLE), enhanced SLLE, SLLE projection, probabilistic SLLE, supervised\nguided LLE (using Hilbert-Schmidt independence criterion), and semi-supervised\nLLE are explained for supervised and semi-supervised embedding. Robust LLE\nmethods using least squares problem and penalty functions are also introduced\nfor embedding in the presence of outliers and noise. Then, we introduce fusion\nof LLE with other manifold learning methods including Isomap (i.e., ISOLLE),\nprincipal component analysis, Fisher discriminant analysis, discriminant LLE,\nand Isotop. Finally, we explain weighted LLE in which the distances,\nreconstruction weights, or the embeddings are adjusted for better embedding; we\ncover weighted LLE for deformed distributed data, weighted LLE using\nprobability of occurrence, SLLE by adjusting weights, modified LLE, and\niterative LLE.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 03:44:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2011.10955", "submitter": "Tyler Maltba", "authors": "Tyler E. Maltba (1), Hongli Zhao (1), Daniel M. Tartakovsky (2) ((1)\n  UC Berkeley, (2) Stanford University)", "title": "Autonomous learning of nonlocal stochastic neuron dynamics", "comments": "26 pages, 12 figures, First author: Tyler E. Maltba, Corresponding\n  author: Daniel M. Tartakovsky", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NA math.NA q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal dynamics is driven by externally imposed or internally generated\nrandom excitations/noise, and is often described by systems of stochastic\nordinary differential equations. A solution to these equations is the joint\nprobability density function (PDF) of neuron states. It can be used to\ncalculate such information-theoretic quantities as the mutual information\nbetween the stochastic stimulus and various internal states of the neuron\n(e.g., membrane potential), as well as various spiking statistics. When random\nexcitations are modeled as Gaussian white noise, the joint PDF of neuron states\nsatisfies exactly a Fokker-Planck equation. However, most biologically\nplausible noise sources are correlated (colored). In this case, the resulting\nPDF equations require a closure approximation. We propose two methods for\nclosing such equations: a modified nonlocal large-eddy-diffusivity closure and\na data-driven closure relying on sparse regression to learn relevant features.\nThe closures are tested for stochastic leaky integrate-and-fire (LIF) and\nFitzHugh-Nagumo (FHN) neurons driven by sine-Wiener noise. Mutual information\nand total correlation between the random stimulus and the internal states of\nthe neuron are calculated for the FHN neuron.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 06:47:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Maltba", "Tyler E.", ""], ["Zhao", "Hongli", ""], ["Tartakovsky", "Daniel M.", ""]]}, {"id": "2011.11013", "submitter": "Shenglan Liu", "authors": "Shenglan Liu, Yang Yu", "title": "Angular Embedding: A New Angular Robust Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a widely used method in machine learning, principal component analysis\n(PCA) shows excellent properties for dimensionality reduction. It is a serious\nproblem that PCA is sensitive to outliers, which has been improved by numerous\nRobust PCA (RPCA) versions. However, the existing state-of-the-art RPCA\napproaches cannot easily remove or tolerate outliers by a non-iterative manner.\nTo tackle this issue, this paper proposes Angular Embedding (AE) to formulate a\nstraightforward RPCA approach based on angular density, which is improved for\nlarge scale or high-dimensional data. Furthermore, a trimmed AE (TAE) is\nintroduced to deal with data with large scale outliers. Extensive experiments\non both synthetic and real-world datasets with vector-level or pixel-level\noutliers demonstrate that the proposed AE/TAE outperforms the state-of-the-art\nRPCA based methods.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 13:36:56 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Liu", "Shenglan", ""], ["Yu", "Yang", ""]]}, {"id": "2011.11057", "submitter": "Zhaozhou Li", "authors": "Zhao-Zhou Li, Lu Li, Zhengyi Shao", "title": "Robust Gaussian Process Regression Based on Iterative Trimming", "comments": "major revision, 11 pages, 8 figures, 2 tables; accepted by Astronomy\n  and Computing; code available at https://github.com/syrte/robustgp/", "journal-ref": null, "doi": "10.1016/j.ascom.2021.100483", "report-no": null, "categories": "cs.LG astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian process (GP) regression can be severely biased when the data are\ncontaminated by outliers. This paper presents a new robust GP regression\nalgorithm that iteratively trims the most extreme data points. While the new\nalgorithm retains the attractive properties of the standard GP as a\nnonparametric and flexible regression method, it can greatly improve the model\naccuracy for contaminated data even in the presence of extreme or abundant\noutliers. It is also easier to implement compared with previous robust GP\nvariants that rely on approximate inference. Applied to a wide range of\nexperiments with different contamination levels, the proposed method\nsignificantly outperforms the standard GP and the popular robust GP variant\nwith the Student-t likelihood in most test cases. In addition, as a practical\nexample in the astrophysical study, we show that this method can precisely\ndetermine the main-sequence ridge line in the color-magnitude diagram of star\nclusters.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 16:43:35 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 13:49:02 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Zhao-Zhou", ""], ["Li", "Lu", ""], ["Shao", "Zhengyi", ""]]}, {"id": "2011.11063", "submitter": "Eli Sennesh", "authors": "Eli Sennesh", "title": "Learning a Deep Generative Model like a Program: the Free Category Prior", "comments": null, "journal-ref": "AAAI Symposium on Conceptual Abstraction and Analogy in Natural\n  and Artificial Intelligence, Fall 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans surpass the cognitive abilities of most other animals in our ability\nto \"chunk\" concepts into words, and then combine the words to combine the\nconcepts. In this process, we make \"infinite use of finite means\", enabling us\nto learn new concepts quickly and nest concepts within each-other. While\nprogram induction and synthesis remain at the heart of foundational theories of\nartificial intelligence, only recently has the community moved forward in\nattempting to use program learning as a benchmark task itself. The cognitive\nscience community has thus often assumed that if the brain has simulation and\nreasoning capabilities equivalent to a universal computer, then it must employ\na serialized, symbolic representation. Here we confront that assumption, and\nprovide a counterexample in which compositionality is expressed via network\nstructure: the free category prior over programs. We show how our formalism\nallows neural networks to serve as primitives in probabilistic programs. We\nlearn both program structure and model parameters end-to-end.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:16:17 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sennesh", "Eli", ""]]}, {"id": "2011.11066", "submitter": "Nicolas Nadisic", "authors": "Nicolas Nadisic, Arnaud Vandaele, Nicolas Gillis", "title": "A Homotopy-based Algorithm for Sparse Multiple Right-hand Sides\n  Nonnegative Least Squares", "comments": "20 pages + 7 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative least squares (NNLS) problems arise in models that rely on\nadditive linear combinations. In particular, they are at the core of\nnonnegative matrix factorization (NMF) algorithms. The nonnegativity constraint\nis known to naturally favor sparsity, that is, solutions with few non-zero\nentries. However, it is often useful to further enhance this sparsity, as it\nimproves the interpretability of the results and helps reducing noise. While\nthe $\\ell_0$-\"norm\", equal to the number of non-zeros entries in a vector, is a\nnatural sparsity measure, its combinatorial nature makes it difficult to use in\npractical optimization schemes. Most existing approaches thus rely either on\nits convex surrogate, the $\\ell_1$-norm, or on heuristics such as greedy\nalgorithms. In the case of multiple right-hand sides NNLS (MNNLS), which are\nused within NMF algorithms, sparsity is often enforced column- or row-wise, and\nthe fact that the solution is a matrix is not exploited. In this paper, we\nfirst introduce a novel formulation for sparse MNNLS, with a matrix-wise\n$\\ell_0$ sparsity constraint. Then, we present a two-step algorithm to tackle\nthis problem. The first step uses a homotopy algorithm to produce the whole\nregularization path for all the $\\ell_1$-penalized NNLS problems arising in\nMNNLS, that is, to produce a set of solutions representing different tradeoffs\nbetween reconstruction error and sparsity. The second step selects solutions\namong these paths in order to build a sparsity-constrained matrix that\nminimizes the reconstruction error. We illustrate the advantages of our\nproposed algorithm for the unmixing of facial and hyperspectral images.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:21:16 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 08:11:36 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Nadisic", "Nicolas", ""], ["Vandaele", "Arnaud", ""], ["Gillis", "Nicolas", ""]]}, {"id": "2011.11096", "submitter": "Braxton Osting", "authors": "Ryeongkyung Yoon, Harish S. Bhat, Braxton Osting", "title": "A non-autonomous equation discovery method for time signal\n  classification", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Certain neural network architectures, in the infinite-layer limit, lead to\nsystems of nonlinear differential equations. Motivated by this idea, we develop\na framework for analyzing time signals based on non-autonomous dynamical\nequations. We view the time signal as a forcing function for a dynamical system\nthat governs a time-evolving hidden variable. As in equation discovery, the\ndynamical system is represented using a dictionary of functions and the\ncoefficients are learned from data. This framework is applied to the time\nsignal classification problem. We show how gradients can be efficiently\ncomputed using the adjoint method, and we apply methods from dynamical systems\nto establish stability of the classifier. Through a variety of experiments, on\nboth synthetic and real datasets, we show that the proposed method uses orders\nof magnitude fewer parameters than competing methods, while achieving\ncomparable accuracy. We created the synthetic datasets using dynamical systems\nof increasing complexity; though the ground truth vector fields are often\npolynomials, we find consistently that a Fourier dictionary yields the best\nresults. We also demonstrate how the proposed method yields graphical\ninterpretability in the form of phase portraits.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 20:03:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yoon", "Ryeongkyung", ""], ["Bhat", "Harish S.", ""], ["Osting", "Braxton", ""]]}, {"id": "2011.11117", "submitter": "El Mehdi Saad", "authors": "El Mehdi Saad, Gilles Blanchard, Sylvain Arlot", "title": "Online Orthogonal Matching Pursuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy algorithms for feature selection are widely used for recovering sparse\nhigh-dimensional vectors in linear models. In classical procedures, the main\nemphasis was put on the sample complexity, with little or no consideration of\nthe computation resources required. We present a novel online algorithm: Online\nOrthogonal Matching Pursuit (OOMP) for online support recovery in the random\ndesign setting of sparse linear regression. Our procedure selects features\nsequentially, alternating between allocation of samples only as needed to\ncandidate features, and optimization over the selected set of variables to\nestimate the regression coefficients. Theoretical guarantees about the output\nof this algorithm are proven and its computational complexity is analysed.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 21:59:05 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 12:44:51 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Saad", "El Mehdi", ""], ["Blanchard", "Gilles", ""], ["Arlot", "Sylvain", ""]]}, {"id": "2011.11124", "submitter": "Li Wang", "authors": "Li Wang, Lei-Hong Zhang, Chungen Shen, and Ren-Cang Li", "title": "Uncorrelated Semi-paired Subspace Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view datasets are increasingly collected in many real-world\napplications, and we have seen better learning performance by existing\nmulti-view learning methods than by conventional single-view learning methods\napplied to each view individually. But, most of these multi-view learning\nmethods are built on the assumption that at each instance no view is missing\nand all data points from all views must be perfectly paired. Hence they cannot\nhandle unpaired data but ignore them completely from their learning process.\nHowever, unpaired data can be more abundant in reality than paired ones and\nsimply ignoring all unpaired data incur tremendous waste in resources. In this\npaper, we focus on learning uncorrelated features by semi-paired subspace\nlearning, motivated by many existing works that show great successes of\nlearning uncorrelated features. Specifically, we propose a generalized\nuncorrelated multi-view subspace learning framework, which can naturally\nintegrate many proven learning criteria on the semi-paired data. To showcase\nthe flexibility of the framework, we instantiate five new semi-paired models\nfor both unsupervised and semi-supervised learning. We also design a successive\nalternating approximation (SAA) method to solve the resulting optimization\nproblem and the method can be combined with the powerful Krylov subspace\nprojection technique if needed. Extensive experimental results on multi-view\nfeature extraction and multi-modality classification show that our proposed\nmodels perform competitively to or better than the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 22:14:20 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Li", ""], ["Zhang", "Lei-Hong", ""], ["Shen", "Chungen", ""], ["Li", "Ren-Cang", ""]]}, {"id": "2011.11150", "submitter": "Ignavier Ng", "authors": "Ignavier Ng, S\\'ebastien Lachapelle, Nan Rosemary Ke, Simon\n  Lacoste-Julien", "title": "On the Convergence of Continuous Constrained Optimization for Structure\n  Learning", "comments": "NeurIPS 2020 Workshop on Causal Discovery and Causality-Inspired\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure learning of directed acyclic graphs (DAGs) is a fundamental problem\nin many scientific endeavors. A new line of work, based on NOTEARS (Zheng et\nal., 2018), reformulates the structure learning problem as a continuous\noptimization one by leveraging an algebraic characterization of DAG constraint.\nThe constrained problem is typically solved using the augmented Lagrangian\nmethod (ALM) which is often preferred to the quadratic penalty method (QPM) by\nvirtue of its convergence result that does not require the penalty coefficient\nto go to infinity, hence avoiding ill-conditioning. In this work, we review the\nstandard convergence result of the ALM and show that the required conditions\nare not satisfied in the recent continuous constrained formulation for learning\nDAGs. We demonstrate empirically that its behavior is akin to that of the QPM\nwhich is prone to ill-conditioning, thus motivating the use of second-order\nmethod in this setting. We also establish the convergence guarantee of QPM to a\nDAG solution, under mild conditions, based on a property of the DAG constraint\nterm.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 00:29:37 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 21:04:44 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Ng", "Ignavier", ""], ["Lachapelle", "S\u00e9bastien", ""], ["Ke", "Nan Rosemary", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2011.11177", "submitter": "Paul Roediger", "authors": "Paul A. Roediger", "title": "Gonogo: An R Implementation of Test Methods to Perform, Analyze and\n  Simulate Sensitivity Experiments", "comments": "This documentation is 58 pages in length and contains 31 figures, 40\n  tables and 2 flow diagrams. The subject of much of the paper, the gonogo.R\n  file, contains 118 functions plus 2 constants and is available online", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME stat.ML stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work provides documentation for a suite of R functions contained in\ngonogo.R. The functions provide sensitivity testing practitioners and\nresearchers with an ability to conduct, analyze and simulate various\nsensitivity experiments involving binary responses and a single stimulus level\n(e.g., drug dosage, drop height, velocity, etc.). Included are the modern Neyer\nand 3pod adaptive procedures, as well as the Bruceton and Langlie. The latter\ntwo benchmark procedures are capable of being performed according to\ngeneralized up-down transformed-response rules. Each procedure is designated\nphase-one of a three-phase experiment. The goal of phase-one is to achieve\noverlapping data. The two additional (and optional) refinement phases utilize\nthe D-optimal criteria and the Robbins-Monro-Joseph procedure. The goals of the\ntwo refinement phases are to situate testing in the vicinity of the median and\ntails of the latent response distribution, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:28:29 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Roediger", "Paul A.", ""]]}, {"id": "2011.11181", "submitter": "Sitan Chen", "authors": "Sitan Chen, Xiaoxiao Li, Zhao Song, Danyang Zhuo", "title": "On InstaHide, Phase Retrieval, and Sparse Matrix Factorization", "comments": "30 pages, to appear in ICLR 2021, v2: updated discussion of follow-up\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the security of InstaHide, a scheme recently\nproposed by [Huang, Song, Li and Arora, ICML'20] for preserving the security of\nprivate datasets in the context of distributed learning. To generate a\nsynthetic training example to be shared among the distributed learners,\nInstaHide takes a convex combination of private feature vectors and randomly\nflips the sign of each entry of the resulting vector with probability 1/2. A\nsalient question is whether this scheme is secure in any provable sense,\nperhaps under a plausible hardness assumption and assuming the distributions\ngenerating the public and private data satisfy certain properties.\n  We show that the answer to this appears to be quite subtle and closely\nrelated to the average-case complexity of a new multi-task, missing-data\nversion of the classic problem of phase retrieval. Motivated by this\nconnection, we design a provable algorithm that can recover private vectors\nusing only the public vectors and synthetic vectors generated by InstaHide,\nunder the assumption that the private and public vectors are isotropic\nGaussian.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:47:08 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 00:08:38 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Chen", "Sitan", ""], ["Li", "Xiaoxiao", ""], ["Song", "Zhao", ""], ["Zhuo", "Danyang", ""]]}, {"id": "2011.11186", "submitter": "Ziliang Zhong", "authors": "Ziliang Zhong, Muhang Zheng, Huafeng Mai, Jianan Zhao, Xinyi Liu", "title": "Cancer image classification based on DenseNet model", "comments": null, "journal-ref": "2004-present Journal of Physics: Conference Series", "doi": "10.1088/1742-6596/1651/1/012143", "report-no": null, "categories": "cs.CV stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-aided diagnosis establishes methods for robust assessment of medical\nimage-based examination. Image processing introduced a promising strategy to\nfacilitate disease classification and detection while diminishing unnecessary\nexpenses. In this paper, we propose a novel metastatic cancer image\nclassification model based on DenseNet Block, which can effectively identify\nmetastatic cancer in small image patches taken from larger digital pathology\nscans. We evaluate the proposed approach to the slightly modified version of\nthe PatchCamelyon (PCam) benchmark dataset. The dataset is the slightly\nmodified version of the PatchCamelyon (PCam) benchmark dataset provided by\nKaggle competition, which packs the clinically-relevant task of metastasis\ndetection into a straight-forward binary image classification task. The\nexperiments indicated that our model outperformed other classical methods like\nResnet34, Vgg19. Moreover, we also conducted data augmentation experiment and\nstudy the relationship between Batches processed and loss value during the\ntraining and validation process.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 03:05:42 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Zhong", "Ziliang", ""], ["Zheng", "Muhang", ""], ["Mai", "Huafeng", ""], ["Zhao", "Jianan", ""], ["Liu", "Xinyi", ""]]}, {"id": "2011.11199", "submitter": "Mehrdad Farajtabar", "authors": "Mehrdad Farajtabar, Andrew Lee, Yuanjian Feng, Vishal Gupta, Peter\n  Dolan, Harish Chandran, Martin Szummer", "title": "Balance Regularized Neural Network Models for Causal Effect Estimation", "comments": "Causal Discovery & Causality-Inspired Machine Learning Workshop at\n  Neural Information Processing Systems, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating individual and average treatment effects from observational data\nis an important problem in many domains such as healthcare and e-commerce. In\nthis paper, we advocate balance regularization of multi-head neural network\narchitectures. Our work is motivated by representation learning techniques to\nreduce differences between treated and untreated distributions that potentially\narise due to confounding factors. We further regularize the model by\nencouraging it to predict control outcomes for individuals in the treatment\ngroup that are similar to control outcomes in the control group. We empirically\nstudy the bias-variance trade-off between different weightings of the\nregularizers, as well as between inductive and transductive inference.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 04:03:55 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Farajtabar", "Mehrdad", ""], ["Lee", "Andrew", ""], ["Feng", "Yuanjian", ""], ["Gupta", "Vishal", ""], ["Dolan", "Peter", ""], ["Chandran", "Harish", ""], ["Szummer", "Martin", ""]]}, {"id": "2011.11222", "submitter": "Lalit Jain", "authors": "Kwang-Sung Jun, Lalit Jain, Blake Mason, Houssam Nassif", "title": "Improved Confidence Bounds for the Linear Logistic Model and\n  Applications to Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose improved fixed-design confidence bounds for the linear logistic\nmodel. Our bounds significantly improve upon the state-of-the-art bound by Li\net al. (2017) via recent developments of the self-concordant analysis of the\nlogistic loss (Faury et al., 2020). Specifically, our confidence bound avoids a\ndirect dependence on $1/\\kappa$, where $\\kappa$ is the minimal variance over\nall arms' reward distributions. In general, $1/\\kappa$ scales exponentially\nwith the norm of the unknown linear parameter $\\theta^*$. Instead of relying on\nthis worst-case quantity, our confidence bound for the reward of any given arm\ndepends directly on the variance of that arm's reward distribution. We present\ntwo applications of our novel bounds to pure exploration and regret\nminimization logistic bandits improving upon state-of-the-art performance\nguarantees. For pure exploration, we also provide a lower bound highlighting a\ndependence on $1/\\kappa$ for a family of instances.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 05:44:26 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 04:45:43 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Jain", "Lalit", ""], ["Mason", "Blake", ""], ["Nassif", "Houssam", ""]]}, {"id": "2011.11248", "submitter": "Morgane Austern", "authors": "Morgane Austern, Vasilis Syrgkanis", "title": "Asymptotics of the Empirical Bootstrap Method Beyond Asymptotic\n  Normality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most commonly used methods for forming confidence intervals for\nstatistical inference is the empirical bootstrap, which is especially expedient\nwhen the limiting distribution of the estimator is unknown. However, despite\nits ubiquitous role, its theoretical properties are still not well understood\nfor non-asymptotically normal estimators. In this paper, under stability\nconditions, we establish the limiting distribution of the empirical bootstrap\nestimator, derive tight conditions for it to be asymptotically consistent, and\nquantify the speed of convergence. Moreover, we propose three alternative ways\nto use the bootstrap method to build confidence intervals with coverage\nguarantees. Finally, we illustrate the generality and tightness of our results\nby a series of examples, including uniform confidence bands, two-sample kernel\ntests, minmax stochastic programs and the empirical risk of stacked estimators.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 07:14:30 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Austern", "Morgane", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "2011.11435", "submitter": "Quentin Duchemin", "authors": "Quentin Duchemin (LAMA), Yohann de Castro (ICJ), Claire Lacour (LAMA)", "title": "Concentration inequality for U-statistics of order two for uniformly\n  ergodic Markov chains", "comments": "In this second revised version, we decided to focus on our main\n  results and the applications will be the purpose of another paper. We improve\n  our results compared to the previous version by providing a Bernstein-type\n  concentration inequality. This allows to benefit from small variance terms to\n  get faster convergence rates", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a new concentration inequality for U-statistics of order two for\nuniformly ergodic Markov chains. Working with bounded and $\\pi$-canonical\nkernels, we show that we can recover the convergence rate of Arcones and\nGin{\\'e} who proved a concentration result for U-statistics of independent\nrandom variables and canonical kernels. Our result allows for a dependence of\nthe kernels $h_{i,j}$ with the indexes in the sums, which prevents the use of\nstandard blocking tools. Our proof relies on an inductive analysis where we use\nmartingale techniques, uniform ergodicity, Nummelin splitting and Bernstein's\ntype inequality. Assuming further that the Markov chain starts from its\ninvariant distribution, we prove a Bernstein-type concentration inequality that\nprovides sharper convergence rate for small variance terms.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:14:34 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 08:08:29 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 13:43:30 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Duchemin", "Quentin", "", "LAMA"], ["de Castro", "Yohann", "", "ICJ"], ["Lacour", "Claire", "", "LAMA"]]}, {"id": "2011.11439", "submitter": "Leonid Pastur", "authors": "L. Pastur and V. Slavin", "title": "On Random Matrices Arising in Deep Neural Networks: General I.I.D. Case", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.06188", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the distribution of singular values of product of random matrices\npertinent to the analysis of deep neural networks. The matrices resemble the\nproduct of the sample covariance matrices, however, an important difference is\nthat the population covariance matrices assumed to be non-random or random but\nindependent of the random data matrix in statistics and random matrix theory\nare now certain functions of random data matrices (synaptic weight matrices in\nthe deep neural network terminology). The problem has been treated in recent\nwork [25, 13] by using the techniques of free probability theory. Since,\nhowever, free probability theory deals with population covariance matrices\nwhich are independent of the data matrices, its applicability has to be\njustified. The justification has been given in [22] for Gaussian data matrices\nwith independent entries, a standard analytical model of free probability, by\nusing a version of the techniques of random matrix theory. In this paper we use\nanother, more streamlined, version of the techniques of random matrix theory to\ngeneralize the results of [22] to the case where the entries of the synaptic\nweight matrices are just independent identically distributed random variables\nwith zero mean and finite fourth moment. This, in particular, extends the\nproperty of the so-called macroscopic universality on the considered random\nmatrices.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 14:39:24 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pastur", "L.", ""], ["Slavin", "V.", ""]]}, {"id": "2011.11441", "submitter": "Fengqi You", "authors": "Chao Ning, Fengqi You", "title": "Online Learning Based Risk-Averse Stochastic MPC of Constrained Linear\n  Uncertain Systems", "comments": null, "journal-ref": "Automatica, Volume 125, March 2021, 109402", "doi": "10.1016/j.automatica.2020.109402", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of designing data-driven stochastic Model\nPredictive Control (MPC) for linear time-invariant systems under additive\nstochastic disturbance, whose probability distribution is unknown but can be\npartially inferred from data. We propose a novel online learning based\nrisk-averse stochastic MPC framework in which Conditional Value-at-Risk (CVaR)\nconstraints on system states are required to hold for a family of distributions\ncalled an ambiguity set. The ambiguity set is constructed from disturbance data\nby leveraging a Dirichlet process mixture model that is self-adaptive to the\nunderlying data structure and complexity. Specifically, the structural property\nof multimodality is exploit-ed, so that the first- and second-order moment\ninformation of each mixture component is incorporated into the ambiguity set. A\nnovel constraint tightening strategy is then developed based on an equivalent\nreformulation of distributionally ro-bust CVaR constraints over the proposed\nambiguity set. As more data are gathered during the runtime of the controller,\nthe ambiguity set is updated online using real-time disturbance data, which\nenables the risk-averse stochastic MPC to cope with time-varying disturbance\ndistributions. The online variational inference algorithm employed does not\nrequire all collected data be learned from scratch, and therefore the proposed\nMPC is endowed with the guaranteed computational complexity of online learning.\nThe guarantees on recursive feasibility and closed-loop stability of the\nproposed MPC are established via a safe update scheme. Numerical examples are\nused to illustrate the effectiveness and advantages of the proposed MPC.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:00:28 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ning", "Chao", ""], ["You", "Fengqi", ""]]}, {"id": "2011.11456", "submitter": "Gauthier Guinet", "authors": "Gauthier Guinet, Valerio Perrone and C\\'edric Archambeau", "title": "Pareto-efficient Acquisition Functions for Cost-Aware Bayesian\n  Optimization", "comments": "11 pages, 9 figures, 4th Workshop on Meta-Learning at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular method to optimize expensive\nblack-box functions. It efficiently tunes machine learning algorithms under the\nimplicit assumption that hyperparameter evaluations cost approximately the\nsame. In reality, the cost of evaluating different hyperparameters, be it in\nterms of time, dollars or energy, can span several orders of magnitude of\ndifference. While a number of heuristics have been proposed to make BO\ncost-aware, none of these have been proven to work robustly. In this work, we\nreformulate cost-aware BO in terms of Pareto efficiency and introduce the cost\nPareto Front, a mathematical object allowing us to highlight the shortcomings\nof commonly used acquisition functions. Based on this, we propose a novel\nPareto-efficient adaptation of the expected improvement. On 144 real-world\nblack-box function optimization problems we show that our Pareto-efficient\nacquisition functions significantly outperform previous solutions, bringing up\nto 50% speed-ups while providing finer control over the cost-accuracy\ntrade-off. We also revisit the common choice of Gaussian process cost models,\nshowing that simple, low-variance cost models predict training times\neffectively.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:06:07 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 14:50:28 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Guinet", "Gauthier", ""], ["Perrone", "Valerio", ""], ["Archambeau", "C\u00e9dric", ""]]}, {"id": "2011.11472", "submitter": "Jonathan Raiman", "authors": "Jonathan Raiman", "title": "Generative Adversarial Simulator", "comments": "Presented at the Beyond \"Tabula Rasa\" in Reinforcement Learning\n  (BeTR-RL): Agents that remember, adapt, and generalize ICLR 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Knowledge distillation between machine learning models has opened many new\navenues for parameter count reduction, performance improvements, or amortizing\ntraining time when changing architectures between the teacher and student\nnetwork. In the case of reinforcement learning, this technique has also been\napplied to distill teacher policies to students. Until now, policy distillation\nrequired access to a simulator or real world trajectories.\n  In this paper we introduce a simulator-free approach to knowledge\ndistillation in the context of reinforcement learning. A key challenge is\nhaving the student learn the multiplicity of cases that correspond to a given\naction. While prior work has shown that data-free knowledge distillation is\npossible with supervised learning models by generating synthetic examples,\nthese approaches to are vulnerable to only producing a single prototype example\nfor each class. We propose an extension to explicitly handle multiple\nobservations per output class that seeks to find as many exemplars as possible\nfor a given output class by reinitializing our data generator and making use of\nan adversarial loss.\n  To the best of our knowledge, this is the first demonstration of\nsimulator-free knowledge distillation between a teacher and a student policy.\nThis new approach improves over the state of the art on data-free learning of\nstudent networks on benchmark datasets (MNIST, Fashion-MNIST, CIFAR-10), and we\nalso demonstrate that it specifically tackles issues with multiple input modes.\nWe also identify open problems when distilling agents trained in high\ndimensional environments such as Pong, Breakout, or Seaquest.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:31:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Raiman", "Jonathan", ""]]}, {"id": "2011.11477", "submitter": "Soledad Villar", "authors": "Ningyuan Huang and David W. Hogg and Soledad Villar", "title": "Dimensionality reduction, regularization, and generalization in\n  overparameterized regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterization in deep learning is powerful: Very large models fit the\ntraining data perfectly and yet generalize well. This realization brought back\nthe study of linear models for regression, including ordinary least squares\n(OLS), which, like deep learning, shows a \"double descent\" behavior. This\ninvolves two features: (1) The risk (out-of-sample prediction error) can grow\narbitrarily when the number of samples $n$ approaches the number of parameters\n$p$, and (2) the risk decreases with $p$ at $p>n$, sometimes achieving a lower\nvalue than the lowest risk at $p<n$. The divergence of the risk for OLS at\n$p\\approx n$ is related to the condition number of the empirical covariance in\nthe feature set. For this reason, it can be avoided with regularization. In\nthis work we show that it can also be avoided with a PCA-based dimensionality\nreduction. We provide a finite upper bound for the risk of the PCA-based\nestimator. This result is in contrast to recent work that shows that a\ndifferent form of dimensionality reduction -- one based on the population\ncovariance instead of the empirical covariance -- does not avoid the\ndivergence. We connect these results to an analysis of adversarial attacks,\nwhich become more effective as they raise the condition number of the empirical\ncovariance of the features. We show that OLS is arbitrarily susceptible to\ndata-poisoning attacks in the overparameterized regime -- unlike the\nunderparameterized regime -- and that regularization and dimensionality\nreduction improve the robustness.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:38:50 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Huang", "Ningyuan", ""], ["Hogg", "David W.", ""], ["Villar", "Soledad", ""]]}, {"id": "2011.11507", "submitter": "Yu-Li Ni", "authors": "HyeongChan Jo (1), Juhyun Kim (2), Tzu-Chen Huang (3), Yu-Li Ni (1)\n  ((1) Division of Biology and Biological Engineering, Caltech, (2) The\n  Division of Physics Mathematics and Astronomy, Caltech, (3) Walter Burke\n  Institute for Theoretical Physics, Caltech)", "title": "condLSTM-Q: A novel deep learning model for predicting Covid-19\n  mortality in fine geographical Scale", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive models with a focus on different spatial-temporal scales benefit\ngovernments and healthcare systems to combat the COVID-19 pandemic. Here we\npresent the conditional Long Short-Term Memory networks with Quantile output\n(condLSTM-Q), a well-performing model for making quantile predictions on\nCOVID-19 death tolls at the county level with a two-week forecast window. This\nfine geographical scale is a rare but useful feature in publicly available\npredictive models, which would especially benefit state-level officials to\ncoordinate resources within the state. The quantile predictions from condLSTM-Q\ninform people about the distribution of the predicted death tolls, allowing\nbetter evaluation of possible trajectories of the severity. Given the\nscalability and generalizability of neural network models, this model could\nincorporate additional data sources with ease, and could be further developed\nto generate other useful predictions such as new cases or hospitalizations\nintuitively.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:14:48 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jo", "HyeongChan", ""], ["Kim", "Juhyun", ""], ["Huang", "Tzu-Chen", ""], ["Ni", "Yu-Li", ""]]}, {"id": "2011.11555", "submitter": "Cansu Alakus", "authors": "Cansu Alakus, Denis Larocque, Sebastien Jacquemont, Fanny Barlaam,\n  Charles-Olivier Martin, Kristian Agbogba, Sarah Lippe, Aurelie Labbe", "title": "Conditional canonical correlation estimation based on covariates with\n  random forests", "comments": "27 pages, 8 figures, 1 table", "journal-ref": null, "doi": "10.1093/bioinformatics/btab158", "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigating the relationships between two sets of variables helps to\nunderstand their interactions and can be done with canonical correlation\nanalysis (CCA). However, the correlation between the two sets can sometimes\ndepend on a third set of covariates, often subject-related ones such as age,\ngender, or other clinical measures. In this case, applying CCA to the whole\npopulation is not optimal and methods to estimate conditional CCA, given the\ncovariates, can be useful. We propose a new method called Random Forest with\nCanonical Correlation Analysis (RFCCA) to estimate the conditional canonical\ncorrelations between two sets of variables given subject-related covariates.\nThe individual trees in the forest are built with a splitting rule specifically\ndesigned to partition the data to maximize the canonical correlation\nheterogeneity between child nodes. We also propose a significance test to\ndetect the global effect of the covariates on the relationship between two sets\nof variables. The performance of the proposed method and the global\nsignificance test is evaluated through simulation studies that show it provides\naccurate canonical correlation estimations and well-controlled Type-1 error. We\nalso show an application of the proposed method with EEG data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:09:46 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 22:55:03 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Alakus", "Cansu", ""], ["Larocque", "Denis", ""], ["Jacquemont", "Sebastien", ""], ["Barlaam", "Fanny", ""], ["Martin", "Charles-Olivier", ""], ["Agbogba", "Kristian", ""], ["Lippe", "Sarah", ""], ["Labbe", "Aurelie", ""]]}, {"id": "2011.11566", "submitter": "Quanquan Gu", "authors": "Jiafan He and Dongruo Zhou and Quanquan Gu", "title": "Logarithmic Regret for Reinforcement Learning with Linear Function\n  Approximation", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) with linear function approximation has received\nincreasing attention recently. However, existing work has focused on obtaining\n$\\sqrt{T}$-type regret bound, where $T$ is the number of interactions with the\nMDP. In this paper, we show that logarithmic regret is attainable under two\nrecently proposed linear MDP assumptions provided that there exists a positive\nsub-optimality gap for the optimal action-value function. More specifically,\nunder the linear MDP assumption (Jin et al. 2019), the LSVI-UCB algorithm can\nachieve $\\tilde{O}(d^{3}H^5/\\text{gap}_{\\text{min}}\\cdot \\log(T))$ regret; and\nunder the linear mixture MDP assumption (Ayoub et al. 2020), the UCRL-VTR\nalgorithm can achieve $\\tilde{O}(d^{2}H^5/\\text{gap}_{\\text{min}}\\cdot\n\\log^3(T))$ regret, where $d$ is the dimension of feature mapping, $H$ is the\nlength of episode, $\\text{gap}_{\\text{min}}$ is the minimal sub-optimality gap,\nand $\\tilde O$ hides all logarithmic terms except $\\log(T)$. To the best of our\nknowledge, these are the first logarithmic regret bounds for RL with linear\nfunction approximation. We also establish gap-dependent lower bounds for the\ntwo linear MDP models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:25:00 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 16:35:54 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["He", "Jiafan", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "2011.11576", "submitter": "James Brooks", "authors": "J.P. Brooks and D.J. Edwards and C.E. Larson and N. Van Cleemput", "title": "Conjecturing-Based Computational Discovery of Patterns in Data", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern machine learning methods are designed to exploit complex patterns in\ndata regardless of their form, while not necessarily revealing them to the\ninvestigator. Here we demonstrate situations where modern machine learning\nmethods are ill-equipped to reveal feature interaction effects and other\nnonlinear relationships. We propose the use of a conjecturing machine that\ngenerates feature relationships in the form of bounds for numerical features\nand boolean expressions for nominal features that are ignored by machine\nlearning algorithms. The proposed framework is demonstrated for a\nclassification problem with an interaction effect and a nonlinear regression\nproblem. In both settings, true underlying relationships are revealed and\ngeneralization performance improves. The framework is then applied to\npatient-level data regarding COVID-19 outcomes to suggest possible risk\nfactors.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:38:16 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Brooks", "J. P.", ""], ["Edwards", "D. J.", ""], ["Larson", "C. E.", ""], ["Van Cleemput", "N.", ""]]}, {"id": "2011.11583", "submitter": "Geoffrey Johnson", "authors": "Geoffrey S Johnson", "title": "Tolerance and Prediction Intervals for Non-normal Models", "comments": "Clinical Trial Recruitment, Time on Treatment, Probability of\n  Success, Prediction Interval, Tolerance Interval", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prediction interval covers a future observation from a random process in\nrepeated sampling, and is typically constructed by identifying a pivotal\nquantity that is also an ancillary statistic. Analogously, a tolerance interval\ncovers a population percentile in repeated sampling and is often based on a\npivotal quantity. One approach we consider in non-normal models leverages a\nlink function resulting in a pivotal quantity that is approximately normally\ndistributed. In settings where this normal approximation does not hold we\nconsider a second approach for tolerance and prediction based on a confidence\ninterval for the mean. These methods are intuitive, simple to implement, have\nproper operating characteristics, and are computationally efficient compared to\nBayesian, re-sampling, and machine learning methods. This is demonstrated in\nthe context of multi-site clinical trial recruitment with staggered site\ninitiation, real-world time on treatment, and end-of-study success for a\nclinical endpoint.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:48:09 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 15:07:05 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 00:34:36 GMT"}, {"version": "v4", "created": "Mon, 7 Jun 2021 18:43:56 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Johnson", "Geoffrey S", ""]]}, {"id": "2011.11660", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er and Dan Boneh", "title": "Differentially Private Learning Needs Better Features (or Much More\n  Data)", "comments": "ICLR 2021. Code available at\n  https://github.com/ftramer/Handcrafted-DP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that differentially private machine learning has not yet\nreached its \"AlexNet moment\" on many canonical vision tasks: linear models\ntrained on handcrafted features significantly outperform end-to-end deep neural\nnetworks for moderate privacy budgets. To exceed the performance of handcrafted\nfeatures, we show that private learning requires either much more private data,\nor access to features learned on public data from a similar domain. Our work\nintroduces simple yet strong baselines for differentially private learning that\ncan inform the evaluation of future progress in this area.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:00:52 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 18:17:16 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 02:56:42 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Boneh", "Dan", ""]]}, {"id": "2011.11761", "submitter": "Florent Pled", "authors": "Florent Pled (MSME), Christophe Desceliers (MSME), Tianyu Zhang (MSME)", "title": "A robust solution of a statistical inverse problem in multiscale\n  computational mechanics using an artificial neural network", "comments": null, "journal-ref": "Computer Methods in Applied Mechanics and Engineering, Elsevier,\n  2021, 373, pp.113540", "doi": "10.1016/j.cma.2020.113540", "report-no": null, "categories": "cs.LG eess.SP physics.class-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the inverse identification of apparent elastic properties\nof random heterogeneous materials using machine learning based on artificial\nneural networks. The proposed neural network-based identification method\nrequires the construction of a database from which an artificial neural network\ncan be trained to learn the nonlinear relationship between the hyperparameters\nof a prior stochastic model of the random compliance field and some relevant\nquantities of interest of an ad hoc multiscale computational model. An initial\ndatabase made up with input and target data is first generated from the\ncomputational model, from which a processed database is deduced by conditioning\nthe input data with respect to the target data using the nonparametric\nstatistics. Two-and three-layer feedforward artificial neural networks are then\ntrained from each of the initial and processed databases to construct an\nalgebraic representation of the nonlinear mapping between the hyperparameters\n(network outputs) and the quantities of interest (network inputs). The\nperformances of the trained artificial neural networks are analyzed in terms of\nmean squared error, linear regression fit and probability distribution between\nnetwork outputs and targets for both databases. An ad hoc probabilistic model\nof the input random vector is finally proposed in order to take into account\nuncertainties on the network input and to perform a robustness analysis of the\nnetwork output with respect to the input uncertainties level. The capability of\nthe proposed neural network-based identification method to efficiently solve\nthe underlying statistical inverse problem is illustrated through two numerical\nexamples developed within the framework of 2D plane stress linear elasticity,\nnamely a first validation example on synthetic data obtained through\ncomputational simulations and a second application example on real experimental\ndata obtained through a physical experiment monitored by digital image\ncorrelation on a real heterogeneous biological material (beef cortical bone).\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 09:37:27 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:36:36 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Pled", "Florent", "", "MSME"], ["Desceliers", "Christophe", "", "MSME"], ["Zhang", "Tianyu", "", "MSME"]]}, {"id": "2011.11780", "submitter": "Anindya Bhaduri", "authors": "Anindya Bhaduri, Christopher S. Meyer, John W. Gillespie Jr., Bazle Z.\n  Haque, Michael D. Shields, Lori Graham-Brady", "title": "Probabilistic modeling of discrete structural response with application\n  to composite plate penetration models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete response of structures is often a key probabilistic quantity of\ninterest. For example, one may need to identify the probability of a binary\nevent, such as, whether a structure has buckled or not. In this study, an\nadaptive domain-based decomposition and classification method, combined with\nsparse grid sampling, is used to develop an efficient classification surrogate\nmodeling algorithm for such discrete outputs. An assumption of monotonic\nbehaviour of the output with respect to all model parameters, based on the\nphysics of the problem, helps to reduce the number of model evaluations and\nmakes the algorithm more efficient. As an application problem, this paper deals\nwith the development of a computational framework for generation of\nprobabilistic penetration response of S-2 glass/SC-15 epoxy composite plates\nunder ballistic impact. This enables the computationally feasible generation of\nthe probabilistic velocity response (PVR) curve or the $V_0-V_{100}$ curve as a\nfunction of the impact velocity, and the ballistic limit velocity prediction as\na function of the model parameters. The PVR curve incorporates the variability\nof the model input parameters and describes the probability of penetration of\nthe plate as a function of impact velocity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 22:45:09 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Bhaduri", "Anindya", ""], ["Meyer", "Christopher S.", ""], ["Gillespie", "John W.", "Jr."], ["Haque", "Bazle Z.", ""], ["Shields", "Michael D.", ""], ["Graham-Brady", "Lori", ""]]}, {"id": "2011.11820", "submitter": "Benjamin Guedj", "authors": "Florent Dewez and Benjamin Guedj and Arthur Talpaert and Vincent\n  Vandewalle", "title": "An end-to-end data-driven optimisation framework for constrained\n  trajectories", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many real-world problems require to optimise trajectories under constraints.\nClassical approaches are based on optimal control methods but require an exact\nknowledge of the underlying dynamics, which could be challenging or even out of\nreach. In this paper, we leverage data-driven approaches to design a new\nend-to-end framework which is dynamics-free for optimised and realistic\ntrajectories. We first decompose the trajectories on function basis, trading\nthe initial infinite dimension problem on a multivariate functional space for a\nparameter optimisation problem. A maximum \\emph{a posteriori} approach which\nincorporates information from data is used to obtain a new optimisation problem\nwhich is regularised. The penalised term focuses the search on a region\ncentered on data and includes estimated linear constraints in the problem. We\napply our data-driven approach to two settings in aeronautics and sailing\nroutes optimisation, yielding commanding results. The developed approach has\nbeen implemented in the Python library PyRotor.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 00:54:17 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 09:24:54 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Dewez", "Florent", ""], ["Guedj", "Benjamin", ""], ["Talpaert", "Arthur", ""], ["Vandewalle", "Vincent", ""]]}, {"id": "2011.11877", "submitter": "Ruizhe Zhang", "authors": "Baihe Huang, Zhao Song, Runzhou Tao, Ruizhe Zhang, Danyang Zhuo", "title": "InstaHide's Sample Complexity When Mixing Two Private Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inspired by InstaHide challenge [Huang, Song, Li and Arora'20], [Chen, Song\nand Zhuo'20] recently provides one mathematical formulation of InstaHide attack\nproblem under Gaussian images distribution. They show that it suffices to use\n$O(n_{\\mathsf{priv}}^{k_{\\mathsf{priv}} - 2/(k_{\\mathsf{priv}} + 1)})$ samples\nto recover one private image in $n_{\\mathsf{priv}}^{O(k_{\\mathsf{priv}})} +\n\\mathrm{poly}(n_{\\mathsf{pub}})$ time for any integer $k_{\\mathsf{priv}}$,\nwhere $n_{\\mathsf{priv}}$ and $n_{\\mathsf{pub}}$ denote the number of images\nused in the private and the public dataset to generate a mixed image sample.\n  Under the current setup for the InstaHide challenge of mixing two private\nimages ($k_{\\mathsf{priv}} = 2$), this means $n_{\\mathsf{priv}}^{4/3}$ samples\nare sufficient to recover a private image. In this work, we show that\n$n_{\\mathsf{priv}} \\log ( n_{\\mathsf{priv}} )$ samples are sufficient\n(information-theoretically) for recovering all the private images.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 03:41:03 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Huang", "Baihe", ""], ["Song", "Zhao", ""], ["Tao", "Runzhou", ""], ["Zhang", "Ruizhe", ""], ["Zhuo", "Danyang", ""]]}, {"id": "2011.11884", "submitter": "Trang Tran", "authors": "Trang H. Tran, Lam M. Nguyen, Quoc Tran-Dinh", "title": "SMG: A Shuffling Gradient-Based Method with Momentum", "comments": "The 38th International Conference on Machine Learning (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine two advanced ideas widely used in optimization for machine\nlearning: shuffling strategy and momentum technique to develop a novel\nshuffling gradient-based method with momentum, coined Shuffling Momentum\nGradient (SMG), for non-convex finite-sum optimization problems. While our\nmethod is inspired by momentum techniques, its update is fundamentally\ndifferent from existing momentum-based methods. We establish state-of-the-art\nconvergence rates of SMG for any shuffling strategy using either constant or\ndiminishing learning rate under standard assumptions (i.e.$L$-smoothness and\nbounded variance). When the shuffling strategy is fixed, we develop another new\nalgorithm that is similar to existing momentum methods, and prove the same\nconvergence rates for this algorithm under the $L$-smoothness and bounded\ngradient assumptions. We demonstrate our algorithms via numerical simulations\non standard datasets and compare them with existing shuffling methods. Our\ntests have shown encouraging performance of the new algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 04:12:35 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:08:20 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 13:50:24 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Tran", "Trang H.", ""], ["Nguyen", "Lam M.", ""], ["Tran-Dinh", "Quoc", ""]]}, {"id": "2011.11966", "submitter": "Nicolas Gillis", "authors": "Christophe Kervazo, Nicolas Gillis, Nicolas Dobigeon", "title": "Provably robust blind source separation of linear-quadratic\n  near-separable mixtures", "comments": "23 pages + 24 pages of Appendix containing the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NA eess.IV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of blind source separation (BSS) by\ndeparting from the usual linear model and focusing on the linear-quadratic (LQ)\nmodel. We propose two provably robust and computationally tractable algorithms\nto tackle this problem under separability assumptions which require the sources\nto appear as samples in the data set. The first algorithm generalizes the\nsuccessive nonnegative projection algorithm (SNPA), designed for linear BSS,\nand is referred to as SNPALQ. By explicitly modeling the product terms inherent\nto the LQ model along the iterations of the SNPA scheme, the nonlinear\ncontributions of the mixing are mitigated, thus improving the separation\nquality. SNPALQ is shown to be able to recover the ground truth factors that\ngenerated the data, even in the presence of noise. The second algorithm is a\nbrute-force (BF) algorithm, which is used as a post-processing step for SNPALQ.\nIt enables to discard the spurious (mixed) samples extracted by SNPALQ, thus\nbroadening its applicability. The BF is in turn shown to be robust to noise\nunder easier-to-check and milder conditions than SNPALQ. We show that SNPALQ\nwith and without the BF postprocessing is relevant in realistic numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 08:53:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kervazo", "Christophe", ""], ["Gillis", "Nicolas", ""], ["Dobigeon", "Nicolas", ""]]}, {"id": "2011.11981", "submitter": "Dongxiao Zhang", "authors": "Hao Xu, Dongxiao Zhang, Nanzhe Wang", "title": "Deep-learning based discovery of partial differential equations in\n  integral form from sparse and noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data-driven discovery of partial differential equations (PDEs) has attracted\nincreasing attention in recent years. Although significant progress has been\nmade, certain unresolved issues remain. For example, for PDEs with high-order\nderivatives, the performance of existing methods is unsatisfactory, especially\nwhen the data are sparse and noisy. It is also difficult to discover\nheterogeneous parametric PDEs where heterogeneous parameters are embedded in\nthe partial differential operators. In this work, a new framework combining\ndeep-learning and integral form is proposed to handle the above-mentioned\nproblems simultaneously, and improve the accuracy and stability of PDE\ndiscovery. In the framework, a deep neural network is firstly trained with\nobservation data to generate meta-data and calculate derivatives. Then, a\nunified integral form is defined, and the genetic algorithm is employed to\ndiscover the best structure. Finally, the value of parameters is calculated,\nand whether the parameters are constants or variables is identified. Numerical\nexperiments proved that our proposed algorithm is more robust to noise and more\naccurate compared with existing methods due to the utilization of integral\nform. Our proposed algorithm is also able to discover PDEs with high-order\nderivatives or heterogeneous parameters accurately with sparse and noisy data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 09:18:39 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Xu", "Hao", ""], ["Zhang", "Dongxiao", ""], ["Wang", "Nanzhe", ""]]}, {"id": "2011.12151", "submitter": "Heejune Sheen", "authors": "Heejune Sheen, Xiaonan Zhu, Yao Xie", "title": "Tensor Kernel Recovery for Spatio-Temporal Hawkes Processes", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the general influence functions for spatio-temporal Hawkes\nprocesses using a tensor recovery approach by formulating the location\ndependent influence function that captures the influence of historical events\nas a tensor kernel. We assume a low-rank structure for the tensor kernel and\ncast the estimation problem as a convex optimization problem using the Fourier\ntransformed nuclear norm (TNN). We provide theoretical performance guarantees\nfor our approach and present an algorithm to solve the optimization problem.\nMoreover, we demonstrate the efficiency of our estimation with numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:05:26 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 12:46:55 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sheen", "Heejune", ""], ["Zhu", "Xiaonan", ""], ["Xie", "Yao", ""]]}, {"id": "2011.12160", "submitter": "Prathamesh Mayekar", "authors": "Prathamesh Mayekar, Ananda Theertha Suresh, and Himanshu Tyagi", "title": "Wyner-Ziv Estimators: Efficient Distributed Mean Estimation with Side\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Communication efficient distributed mean estimation is an important primitive\nthat arises in many distributed learning and optimization scenarios such as\nfederated learning. Without any probabilistic assumptions on the underlying\ndata, we study the problem of distributed mean estimation where the server has\naccess to side information. We propose \\emph{Wyner-Ziv estimators}, which are\ncommunication and computationally efficient and near-optimal when an upper\nbound for the distance between the side information and the data is known. As a\ncorollary, we also show that our algorithms provide efficient schemes for the\nclassic Wyner-Ziv problem in information theory. In a different direction, when\nthere is no knowledge assumed about the distance between side information and\nthe data, we present an alternative Wyner-Ziv estimator that uses correlated\nsampling. This latter setting offers {\\em universal recovery guarantees}, and\nperhaps will be of interest in practice when the number of users is large and\nkeeping track of the distances between the data and the side information may\nnot be possible.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:19:55 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mayekar", "Prathamesh", ""], ["Suresh", "Ananda Theertha", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "2011.12216", "submitter": "Shuang Li", "authors": "Shuang Li, Yilun Du, Gido M. van de Ven, Igor Mordatch", "title": "Energy-Based Models for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate Energy-Based Models (EBMs) as a promising model class for\ncontinual learning problems. Instead of tackling continual learning via the use\nof external memory, growing models, or regularization, EBMs have a natural way\nto support a dynamically-growing number of tasks or classes that causes less\ninterference with previously learned information. Our proposed version of EBMs\nfor continual learning is simple, efficient and outperforms baseline methods by\na large margin on several benchmarks. Moreover, our proposed contrastive\ndivergence based training objective can be applied to other continual learning\nmethods, resulting in substantial boosts in their performance. We also show\nthat EBMs are adaptable to a more general continual learning setting where the\ndata distribution changes without the notion of explicitly delineated tasks.\nThese observations point towards EBMs as a class of models naturally inclined\ntowards the continual learning regime.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:08:13 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 05:00:33 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Li", "Shuang", ""], ["Du", "Yilun", ""], ["van de Ven", "Gido M.", ""], ["Mordatch", "Igor", ""]]}, {"id": "2011.12239", "submitter": "Jingli Wang", "authors": "Huan Qing and Jingli Wang", "title": "Estimating network memberships by mixed regularized spectral clustering", "comments": "17 pages; 2 figures; 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed membership community detection is a challenge problem in network\nanalysis. Here, under the degree-corrected mixed membership (DCMM) model, we\npropose an efficient approach called mixed regularized spectral clustering\n(Mixed-RSC for short) to estimate the memberships. Mixed-RSC is an extension of\nthe RSC method (Qin and Rohe, 2013) to deal with the mixed membership community\ndetection problem. We show that the algorithm is asymptotically consistent\nunder mild conditions. The approach is successfully applied to a small scale of\nsimulations and substantial empirical networks with encouraging results\ncompared to a number of benchmark methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:30:53 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Qing", "Huan", ""], ["Wang", "Jingli", ""]]}, {"id": "2011.12245", "submitter": "Andrew Arrasmith", "authors": "Andrew Arrasmith, M. Cerezo, Piotr Czarnik, Lukasz Cincio, Patrick J.\n  Coles", "title": "Effect of barren plateaus on gradient-free optimization", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-29699", "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Barren plateau landscapes correspond to gradients that vanish exponentially\nin the number of qubits. Such landscapes have been demonstrated for variational\nquantum algorithms and quantum neural networks with either deep circuits or\nglobal cost functions. For obvious reasons, it is expected that gradient-based\noptimizers will be significantly affected by barren plateaus. However, whether\nor not gradient-free optimizers are impacted is a topic of debate, with some\narguing that gradient-free approaches are unaffected by barren plateaus. Here\nwe show that, indeed, gradient-free optimizers do not solve the barren plateau\nproblem. Our main result proves that cost function differences, which are the\nbasis for making decisions in a gradient-free optimization, are exponentially\nsuppressed in a barren plateau. Hence, without exponential precision,\ngradient-free optimizers will not make progress in the optimization. We\nnumerically confirm this by training in a barren plateau with several\ngradient-free optimizers (Nelder-Mead, Powell, and COBYLA algorithms), and show\nthat the numbers of shots required in the optimization grows exponentially with\nthe number of qubits.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:41:13 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Arrasmith", "Andrew", ""], ["Cerezo", "M.", ""], ["Czarnik", "Piotr", ""], ["Cincio", "Lukasz", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2011.12328", "submitter": "Noel Loo", "authors": "Noel Loo, Siddharth Swaroop, Richard E. Turner", "title": "Generalized Variational Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning deals with training models on new tasks and datasets in an\nonline fashion. One strand of research has used probabilistic regularization\nfor continual learning, with two of the main approaches in this vein being\nOnline Elastic Weight Consolidation (Online EWC) and Variational Continual\nLearning (VCL). VCL employs variational inference, which in other settings has\nbeen improved empirically by applying likelihood-tempering. We show that\napplying this modification to VCL recovers Online EWC as a limiting case,\nallowing for interpolation between the two approaches. We term the general\nalgorithm Generalized VCL (GVCL). In order to mitigate the observed overpruning\neffect of VI, we take inspiration from a common multi-task architecture, neural\nnetworks with task-specific FiLM layers, and find that this addition leads to\nsignificant performance gains, specifically for variational methods. In the\nsmall-data regime, GVCL strongly outperforms existing baselines. In larger\ndatasets, GVCL with FiLM layers outperforms or is competitive with existing\nbaselines in terms of accuracy, whilst also providing significantly better\ncalibration.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 19:07:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Loo", "Noel", ""], ["Swaroop", "Siddharth", ""], ["Turner", "Richard E.", ""]]}, {"id": "2011.12363", "submitter": "Gabriel Loaiza-Ganem", "authors": "Panteha Naderian, Gabriel Loaiza-Ganem, Harry J. Braviner, Anthony L.\n  Caterini, Jesse C. Cresswell, Tong Li, Animesh Garg", "title": "C-Learning: Horizon-Aware Cumulative Accessibility Estimation", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-goal reaching is an important problem in reinforcement learning needed\nto achieve algorithmic generalization. Despite recent advances in this field,\ncurrent algorithms suffer from three major challenges: high sample complexity,\nlearning only a single way of reaching the goals, and difficulties in solving\ncomplex motion planning tasks. In order to address these limitations, we\nintroduce the concept of cumulative accessibility functions, which measure the\nreachability of a goal from a given state within a specified horizon. We show\nthat these functions obey a recurrence relation, which enables learning from\noffline interactions. We also prove that optimal cumulative accessibility\nfunctions are monotonic in the planning horizon. Additionally, our method can\ntrade off speed and reliability in goal-reaching by suggesting multiple paths\nto a single goal depending on the provided horizon. We evaluate our approach on\na set of multi-goal discrete and continuous control tasks. We show that our\nmethod outperforms state-of-the-art goal-reaching algorithms in success rate,\nsample complexity, and path optimality. Our code is available at\nhttps://github.com/layer6ai-labs/CAE, and additional visualizations can be\nfound at https://sites.google.com/view/learning-cae/.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:34:31 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:20:47 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 03:05:38 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Naderian", "Panteha", ""], ["Loaiza-Ganem", "Gabriel", ""], ["Braviner", "Harry J.", ""], ["Caterini", "Anthony L.", ""], ["Cresswell", "Jesse C.", ""], ["Li", "Tong", ""], ["Garg", "Animesh", ""]]}, {"id": "2011.12378", "submitter": "Qiyao Wang", "authors": "Qiyao Wang, Haiyan Wang, Chetan Gupta, Aniruddha Rajendra Rao, Hamed\n  Khorasgani", "title": "A Non-linear Function-on-Function Model for Regression with Time Series\n  Data", "comments": "Accepted by IEEE Big Data 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last few decades, building regression models for non-scalar variables,\nincluding time series, text, image, and video, has attracted increasing\ninterests of researchers from the data analytic community. In this paper, we\nfocus on a multivariate time series regression problem. Specifically, we aim to\nlearn mathematical mappings from multiple chronologically measured numerical\nvariables within a certain time interval S to multiple numerical variables of\ninterest over time interval T. Prior arts, including the multivariate\nregression model, the Seq2Seq model, and the functional linear models, suffer\nfrom several limitations. The first two types of models can only handle\nregularly observed time series. Besides, the conventional multivariate\nregression models tend to be biased and inefficient, as they are incapable of\nencoding the temporal dependencies among observations from the same time\nseries. The sequential learning models explicitly use the same set of\nparameters along time, which has negative impacts on accuracy. The\nfunction-on-function linear model in functional data analysis (a branch of\nstatistics) is insufficient to capture complex correlations among the\nconsidered time series and suffer from underfitting easily. In this paper, we\npropose a general functional mapping that embraces the function-on-function\nlinear model as a special case. We then propose a non-linear\nfunction-on-function model using the fully connected neural network to learn\nthe mapping from data, which addresses the aforementioned concerns in the\nexisting approaches. For the proposed model, we describe in detail the\ncorresponding numerical implementation procedures. The effectiveness of the\nproposed model is demonstrated through the application to two real-world\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:51:27 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Qiyao", ""], ["Wang", "Haiyan", ""], ["Gupta", "Chetan", ""], ["Rao", "Aniruddha Rajendra", ""], ["Khorasgani", "Hamed", ""]]}, {"id": "2011.12379", "submitter": "Claudia Shi", "authors": "Claudia Shi, Victor Veitch, David Blei", "title": "Invariant Representation Learning for Treatment Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The defining challenge for causal inference from observational data is the\npresence of `confounders', covariates that affect both treatment assignment and\nthe outcome. To address this challenge, practitioners collect and adjust for\nthe covariates, hoping that they adequately correct for confounding. However,\nincluding every observed covariate in the adjustment runs the risk of including\n`bad controls', variables that induce bias when they are conditioned on. The\nproblem is that we do not always know which variables in the covariate set are\nsafe to adjust for and which are not. To address this problem, we develop\nNearly Invariant Causal Estimation (NICE). NICE uses invariant risk\nminimization (IRM) [Arj19] to learn a representation of the covariates that,\nunder some assumptions, strips out bad controls but preserves sufficient\ninformation to adjust for confounding. Adjusting for the learned\nrepresentation, rather than the covariates themselves, avoids the induced bias\nand provides valid causal inferences. We evaluate NICE on both synthetic and\nsemi-synthetic data. When the covariates contain unknown collider variables and\nother bad controls, NICE performs better than adjusting for all the covariates.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:53:24 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 06:45:08 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Shi", "Claudia", ""], ["Veitch", "Victor", ""], ["Blei", "David", ""]]}, {"id": "2011.12382", "submitter": "Denis Belomestny", "authors": "Christian Bayer, Denis Belomestny, Paul Hager, Paolo Pigato, John\n  Schoenmakers, Vladimir Spokoiny", "title": "Reinforced optimal control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Least squares Monte Carlo methods are a popular numerical approximation\nmethod for solving stochastic control problems. Based on dynamic programming,\ntheir key feature is the approximation of the conditional expectation of future\nrewards by linear least squares regression. Hence, the choice of basis\nfunctions is crucial for the accuracy of the method. Earlier work by some of us\n[Belomestny, Schoenmakers, Spokoiny, Zharkynbay. Commun.~Math.~Sci.,\n18(1):109-121, 2020] proposes to \\emph{reinforce} the basis functions in the\ncase of optimal stopping problems by already computed value functions for later\ntimes, thereby considerably improving the accuracy with limited additional\ncomputational cost. We extend the reinforced regression method to a general\nclass of stochastic control problems, while considerably improving the method's\nefficiency, as demonstrated by substantial numerical examples as well as\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:57:44 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Bayer", "Christian", ""], ["Belomestny", "Denis", ""], ["Hager", "Paul", ""], ["Pigato", "Paolo", ""], ["Schoenmakers", "John", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "2011.12392", "submitter": "Gersende Fort", "authors": "Gersende Fort (IMT), Eric Moulines (X-DEP-MATHAPP), Hoi-To Wai", "title": "Geom-SPIDER-EM: Faster Variance Reduced Stochastic Expectation\n  Maximization for Nonconvex Finite-Sum Optimization", "comments": "Submitted to an International conference, with reviewing process", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation Maximization (EM) algorithm is a key reference for inference\nin latent variable models; unfortunately, its computational cost is prohibitive\nin the large scale learning setting. In this paper, we propose an extension of\nthe Stochastic Path-Integrated Differential EstimatoR EM (SPIDER-EM) and derive\ncomplexity bounds for this novel algorithm, designed to solve smooth nonconvex\nfinite-sum optimization problems. We show that it reaches the same state of the\nart complexity bounds as SPIDER-EM; and provide conditions for a linear rate of\nconvergence. Numerical results support our findings.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 21:20:53 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Fort", "Gersende", "", "IMT"], ["Moulines", "Eric", "", "X-DEP-MATHAPP"], ["Wai", "Hoi-To", ""]]}, {"id": "2011.12413", "submitter": "Leonardo Zepeda-N\\'u\\~nez", "authors": "Matthew Li and Laurent Demanet and Leonardo Zepeda-N\\'u\\~nez", "title": "Wide-band butterfly network: stable and efficient inversion via\n  multi-frequency neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an end-to-end deep learning architecture called the wide-band\nbutterfly network (WideBNet) for approximating the inverse scattering map from\nwide-band scattering data. This architecture incorporates tools from\ncomputational harmonic analysis, such as the butterfly factorization, and\ntraditional multi-scale methods, such as the Cooley-Tukey FFT algorithm, to\ndrastically reduce the number of trainable parameters to match the inherent\ncomplexity of the problem. As a result WideBNet is efficient: it requires fewer\ntraining points than off-the-shelf architectures, and has stable training\ndynamics, thus it can rely on standard weight initialization strategies. The\narchitecture automatically adapts to the dimensions of the data with only a few\nhyper-parameters that the user must specify. WideBNet is able to produce images\nthat are competitive with optimization-based approaches, but at a fraction of\nthe cost, and we also demonstrate numerically that it learns to super-resolve\nscatterers in the full aperture scattering setup.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 21:48:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Li", "Matthew", ""], ["Demanet", "Laurent", ""], ["Zepeda-N\u00fa\u00f1ez", "Leonardo", ""]]}, {"id": "2011.12428", "submitter": "Sebastian Goldt", "authors": "Maria Refinetti, St\\'ephane d'Ascoli, Ruben Ohana, Sebastian Goldt", "title": "Align, then memorise: the dynamics of learning with feedback alignment", "comments": "The accompanying code for this paper is available at\n  https://github.com/sdascoli/dfa-dynamics", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning (ICML), PMLR 139, 2021", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct Feedback Alignment (DFA) is emerging as an efficient and biologically\nplausible alternative to the ubiquitous backpropagation algorithm for training\ndeep neural networks. Despite relying on random feedback weights for the\nbackward pass, DFA successfully trains state-of-the-art models such as\nTransformers. On the other hand, it notoriously fails to train convolutional\nnetworks. An understanding of the inner workings of DFA to explain these\ndiverging results remains elusive. Here, we propose a theory for the success of\nDFA. We first show that learning in shallow networks proceeds in two steps: an\nalignment phase, where the model adapts its weights to align the approximate\ngradient with the true gradient of the loss function, is followed by a\nmemorisation phase, where the model focuses on fitting the data. This two-step\nprocess has a degeneracy breaking effect: out of all the low-loss solutions in\nthe landscape, a network trained with DFA naturally converges to the solution\nwhich maximises gradient alignment. We also identify a key quantity underlying\nalignment in deep linear networks: the conditioning of the alignment matrices.\nThe latter enables a detailed understanding of the impact of data structure on\nalignment, and suggests a simple explanation for the well-known failure of DFA\nto train convolutional neural networks. Numerical experiments on MNIST and\nCIFAR10 clearly demonstrate degeneracy breaking in deep non-linear networks and\nshow that the align-then-memorise process occurs sequentially from the bottom\nlayers of the network to the top.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:21:27 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 14:20:37 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Refinetti", "Maria", ""], ["d'Ascoli", "St\u00e9phane", ""], ["Ohana", "Ruben", ""], ["Goldt", "Sebastian", ""]]}, {"id": "2011.12433", "submitter": "Yeshwanth Cherapanamjeri", "authors": "Yeshwanth Cherapanamjeri, Nilesh Tripuraneni, Peter L. Bartlett,\n  Michael I. Jordan", "title": "Optimal Mean Estimation without a Variance", "comments": "Fixed typographical errors in Theorem 1.2, Lemmas 4.3 and C.8", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of heavy-tailed mean estimation in settings where the\nvariance of the data-generating distribution does not exist. Concretely, given\na sample $\\mathbf{X} = \\{X_i\\}_{i = 1}^n$ from a distribution $\\mathcal{D}$\nover $\\mathbb{R}^d$ with mean $\\mu$ which satisfies the following\n\\emph{weak-moment} assumption for some ${\\alpha \\in [0, 1]}$: \\begin{equation*}\n\\forall \\|v\\| = 1: \\mathbb{E}_{X \\thicksim \\mathcal{D}}[\\lvert \\langle X - \\mu,\nv\\rangle \\rvert^{1 + \\alpha}] \\leq 1, \\end{equation*} and given a target\nfailure probability, $\\delta$, our goal is to design an estimator which attains\nthe smallest possible confidence interval as a function of $n,d,\\delta$. For\nthe specific case of $\\alpha = 1$, foundational work of Lugosi and Mendelson\nexhibits an estimator achieving subgaussian confidence intervals, and\nsubsequent work has led to computationally efficient versions of this\nestimator. Here, we study the case of general $\\alpha$, and establish the\nfollowing information-theoretic lower bound on the optimal attainable\nconfidence interval: \\begin{equation*} \\Omega \\left(\\sqrt{\\frac{d}{n}} +\n\\left(\\frac{d}{n}\\right)^{\\frac{\\alpha}{(1 + \\alpha)}} + \\left(\\frac{\\log 1 /\n\\delta}{n}\\right)^{\\frac{\\alpha}{(1 + \\alpha)}}\\right). \\end{equation*}\nMoreover, we devise a computationally-efficient estimator which achieves this\nlower bound.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:39:21 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 20:31:46 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Cherapanamjeri", "Yeshwanth", ""], ["Tripuraneni", "Nilesh", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.12478", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro and Phong Alain Chau", "title": "Minimax Estimation of Distances on a Surface and Minimax Manifold\n  Learning in the Isometric-to-Convex Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start by considering the problem of estimating intrinsic distances on a\nsmooth surface. We show that sharper estimates can be obtained via a\nreconstruction of the surface, and discuss the use of the tangential Delaunay\ncomplex for that purpose. We further show that the resulting approximation rate\nis in fact optimal in an information-theoretic (minimax) sense. We then turn to\nmanifold learning and argue that a variant of Isomap where the distances are\ninstead computed on a reconstructed surface is minimax optimal for the problem\nof isometric manifold embedding.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 01:57:51 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Chau", "Phong Alain", ""]]}, {"id": "2011.12508", "submitter": "Xueying Ding", "authors": "Ye Yuan, Xueying Ding, Ziv Bar-Joseph", "title": "Causal inference using deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference from observation data is a core problem in many scientific\nfields. Here we present a general supervised deep learning framework that\ninfers causal interactions by transforming the input vectors to an image-like\nrepresentation for every pair of inputs. Given a training dataset we first\nconstruct a normalized empirical probability density distribution (NEPDF)\nmatrix. We then train a convolutional neural network (CNN) on NEPDFs for\ncausality predictions. We tested the method on several different simulated and\nreal world data and compared it to prior methods for causal inference. As we\nshow, the method is general, can efficiently handle very large datasets and\nimproves upon prior methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:22:14 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Yuan", "Ye", ""], ["Ding", "Xueying", ""], ["Bar-Joseph", "Ziv", ""]]}, {"id": "2011.12509", "submitter": "Aniruddha Rajendra Rao", "authors": "Aniruddha Rajendra Rao, Matthew Reimherr", "title": "Modern Multiple Imputation with Functional Data", "comments": "7 figures (including supplementary material), 8 tables (including\n  supplementary material), 14 pages (including supplementary material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work considers the problem of fitting functional models with sparsely\nand irregularly sampled functional data. It overcomes the limitations of the\nstate-of-the-art methods, which face major challenges in the fitting of more\ncomplex non-linear models. Currently, many of these models cannot be\nconsistently estimated unless the number of observed points per curve grows\nsufficiently quickly with the sample size, whereas, we show numerically that a\nmodified approach with more modern multiple imputation methods can produce\nbetter estimates in general. We also propose a new imputation approach that\ncombines the ideas of {\\it MissForest} with {\\it Local Linear Forest} and\ncompare their performance with {\\it PACE} and several other multivariate\nmultiple imputation methods. This work is motivated by a longitudinal study on\nsmoking cessation, in which the Electronic Health Records (EHR) from Penn State\nPaTH to Health allow for the collection of a great deal of data, with highly\nvariable sampling. To illustrate our approach, we explore the relation between\nrelapse and diastolic blood pressure. We also consider a variety of simulation\nschemes with varying levels of sparsity to validate our methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:22:30 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Rao", "Aniruddha Rajendra", ""], ["Reimherr", "Matthew", ""]]}, {"id": "2011.12532", "submitter": "Hiroyuki Kasai", "authors": "Mitsuhiko Horie and Hiroyuki Kasai", "title": "Consistency-aware and Inconsistency-aware Graph-based Multi-view\n  Clustering", "comments": "Accepted in EUSIPCO2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-view data analysis has gained increasing popularity because multi-view\ndata are frequently encountered in machine learning applications. A simple but\npromising approach for clustering of multi-view data is multi-view clustering\n(MVC), which has been developed extensively to classify given subjects into\nsome clustered groups by learning latent common features that are shared across\nmulti-view data. Among existing approaches, graph-based multi-view clustering\n(GMVC) achieves state-of-the-art performance by leveraging a shared graph\nmatrix called the unified matrix. However, existing methods including GMVC do\nnot explicitly address inconsistent parts of input graph matrices.\nConsequently, they are adversely affected by unacceptable clustering\nperformance. To this end, this paper proposes a new GMVC method that\nincorporates consistent and inconsistent parts lying across multiple views.\nThis proposal is designated as CI-GMVC. Numerical evaluations of real-world\ndatasets demonstrate the effectiveness of the proposed CI-GMVC.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:00:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Horie", "Mitsuhiko", ""], ["Kasai", "Hiroyuki", ""]]}, {"id": "2011.12542", "submitter": "Hiroyuki Kasai", "authors": "Takumi Fukunaga, Hiroyuki Kasai", "title": "Wasserstein k-means with sparse simplex projection", "comments": "Accepted in ICPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a proposal of a faster Wasserstein $k$-means algorithm\nfor histogram data by reducing Wasserstein distance computations and exploiting\nsparse simplex projection. We shrink data samples, centroids, and the ground\ncost matrix, which leads to considerable reduction of the computations used to\nsolve optimal transport problems without loss of clustering quality.\nFurthermore, we dynamically reduced the computational complexity by removing\nlower-valued data samples and harnessing sparse simplex projection while\nkeeping the degradation of clustering quality lower. We designate this proposed\nalgorithm as sparse simplex projection based Wasserstein $k$-means, or SSPW\n$k$-means. Numerical evaluations conducted with comparison to results obtained\nusing Wasserstein $k$-means algorithm demonstrate the effectiveness of the\nproposed SSPW $k$-means for real-world datasets\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:37:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Fukunaga", "Takumi", ""], ["Kasai", "Hiroyuki", ""]]}, {"id": "2011.12547", "submitter": "Wei Huang", "authors": "Wei Huang, Weitao Du, Richard Yi Da Xu, and Chunrui Liu", "title": "Implicit bias of deep linear networks in the large learning rate phase", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most theoretical studies explaining the regularization effect in deep\nlearning have only focused on gradient descent with a sufficient small learning\nrate or even gradient flow (infinitesimal learning rate). Such researches,\nhowever, have neglected a reasonably large learning rate applied in most\npractical applications. In this work, we characterize the implicit bias effect\nof deep linear networks for binary classification using the logistic loss in\nthe large learning rate regime, inspired by the seminal work by Lewkowycz et\nal. [26] in a regression setting with squared loss. They found a learning rate\nregime with a large stepsize named the catapult phase, where the loss grows at\nthe early stage of training and eventually converges to a minimum that is\nflatter than those found in the small learning rate regime. We claim that\ndepending on the separation conditions of data, the gradient descent iterates\nwill converge to a flatter minimum in the catapult phase. We rigorously prove\nthis claim under the assumption of degenerate data by overcoming the difficulty\nof the non-constant Hessian of logistic loss and further characterize the\nbehavior of loss and Hessian for non-separable data. Finally, we demonstrate\nthat flatter minima in the space spanned by non-separable data along with the\nlearning rate in the catapult phase can lead to better generalization\nempirically.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:50:30 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 13:38:29 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Huang", "Wei", ""], ["Du", "Weitao", ""], ["Da Xu", "Richard Yi", ""], ["Liu", "Chunrui", ""]]}, {"id": "2011.12574", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh and Liang Zheng", "title": "Enhanced Scene Specificity with Sparse Dynamic Value Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-scene reinforcement learning involves training the RL agent across\nmultiple scenes / levels from the same task, and has become essential for many\ngeneralization applications. However, the inclusion of multiple scenes leads to\nan increase in sample variance for policy gradient computations, often\nresulting in suboptimal performance with the direct application of traditional\nmethods (e.g. PPO, A3C). One strategy for variance reduction is to consider\neach scene as a distinct Markov decision process (MDP) and learn a joint value\nfunction dependent on both state (s) and MDP (M). However, this is non-trivial\nas the agent is usually unaware of the underlying level at train / test times\nin multi-scene RL. Recently, Singh et al. [1] tried to address this by\nproposing a dynamic value estimation approach that models the true joint value\nfunction distribution as a Gaussian mixture model (GMM). In this paper, we\nargue that the error between the true scene-specific value function and the\npredicted dynamic estimate can be further reduced by progressively enforcing\nsparse cluster assignments once the agent has explored most of the state space.\nThe resulting agents not only show significant improvements in the final reward\nscore across a range of OpenAI ProcGen environments, but also exhibit increased\nnavigation efficiency while completing a game level.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 08:35:16 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2011.12581", "submitter": "Yunfei Teng", "authors": "Yunfei Teng, Anna Choromanska, Murray Campbell", "title": "Continual learning with direction-constrained optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a new design of the optimization algorithm for training\ndeep learning models with a fixed architecture of the classification network in\na continual learning framework, where the training data is non-stationary and\nthe non-stationarity is imposed by a sequence of distinct tasks. This setting\nimplies the existence of a manifold of network parameters that correspond to\ngood performance of the network on all tasks. Our algorithm is derived from the\ngeometrical properties of this manifold. We first analyze a deep model trained\non only one learning task in isolation and identify a region in network\nparameter space, where the model performance is close to the recovered optimum.\nWe provide empirical evidence that this region resembles a cone that expands\nalong the convergence direction. We study the principal directions of the\ntrajectory of the optimizer after convergence and show that traveling along a\nfew top principal directions can quickly bring the parameters outside the cone\nbut this is not the case for the remaining directions. We argue that\ncatastrophic forgetting in a continual learning setting can be alleviated when\nthe parameters are constrained to stay within the intersection of the plausible\ncones of individual tasks that were so far encountered during training.\nEnforcing this is equivalent to preventing the parameters from moving along the\ntop principal directions of convergence corresponding to the past tasks. For\neach task we introduce a new linear autoencoder to approximate its\ncorresponding top forbidden principal directions. They are then incorporated\ninto the loss function in the form of a regularization term for the purpose of\nlearning the coming tasks without forgetting. We empirically demonstrate that\nour algorithm performs favorably compared to other state-of-art\nregularization-based continual learning methods, including EWC and SI.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 08:45:21 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Teng", "Yunfei", ""], ["Choromanska", "Anna", ""], ["Campbell", "Murray", ""]]}, {"id": "2011.12596", "submitter": "Muhammad Huzaifah Md Shahrin", "authors": "M. Huzaifah, L. Wyse", "title": "MTCRNN: A multi-scale RNN for directed audio texture synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Audio textures are a subset of environmental sounds, often defined as having\nstable statistical characteristics within an adequately large window of time\nbut may be unstructured locally. They include common everyday sounds such as\nfrom rain, wind, and engines. Given that these complex sounds contain patterns\non multiple timescales, they are a challenge to model with traditional methods.\nWe introduce a novel modelling approach for textures, combining recurrent\nneural networks trained at different levels of abstraction with a conditioning\nstrategy that allows for user-directed synthesis. We demonstrate the model's\nperformance on a variety of datasets, examine its performance on various\nmetrics, and discuss some potential applications.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 09:13:53 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Huzaifah", "M.", ""], ["Wyse", "L.", ""]]}, {"id": "2011.12651", "submitter": "Stefan Klus", "authors": "Patrick Gel{\\ss}, Stefan Klus, Ingmar Schuster, Christof Sch\\\"utte", "title": "Feature space approximation for kernel-based supervised learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2021.106935", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for the approximation of high- or even\ninfinite-dimensional feature vectors, which play an important role in\nsupervised learning. The goal is to reduce the size of the training data,\nresulting in lower storage consumption and computational complexity.\nFurthermore, the method can be regarded as a regularization technique, which\nimproves the generalizability of learned target functions. We demonstrate\nsignificant improvements in comparison to the computation of data-driven\npredictions involving the full training data set. The method is applied to\nclassification and regression problems from different application areas such as\nimage recognition, system identification, and oceanographic time series\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:23:58 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 17:06:34 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gel\u00df", "Patrick", ""], ["Klus", "Stefan", ""], ["Schuster", "Ingmar", ""], ["Sch\u00fctte", "Christof", ""]]}, {"id": "2011.12659", "submitter": "Francesco Tonin", "authors": "Francesco Tonin, Panagiotis Patrinos, Johan A. K. Suykens", "title": "Unsupervised learning of disentangled representations in deep restricted\n  kernel machines with orthogonality constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Constr-DRKM, a deep kernel method for the unsupervised learning\nof disentangled data representations. We propose augmenting the original deep\nrestricted kernel machine formulation for kernel PCA by orthogonality\nconstraints on the latent variables to promote disentanglement and to make it\npossible to carry out optimization without first defining a stabilized\nobjective. After illustrating an end-to-end training procedure based on a\nquadratic penalty optimization algorithm with warm start, we quantitatively\nevaluate the proposed method's effectiveness in disentangled feature learning.\nWe demonstrate on four benchmark datasets that this approach performs similarly\noverall to $\\beta$-VAE on a number of disentanglement metrics when few training\npoints are available, while being less sensitive to randomness and\nhyperparameter selection than $\\beta$-VAE. We also present a deterministic\ninitialization of Constr-DRKM's training algorithm that significantly improves\nthe reproducibility of the results. Finally, we empirically evaluate and\ndiscuss the role of the number of layers in the proposed methodology, examining\nthe influence of each principal component in every layer and showing that\ncomponents in lower layers act as local feature detectors capturing the broad\ntrends of the data distribution, while components in deeper layers use the\nrepresentation learned by previous layers and more accurately reproduce\nhigher-level features.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:40:10 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Tonin", "Francesco", ""], ["Patrinos", "Panagiotis", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2011.12747", "submitter": "Gregor Simm", "authors": "Gregor N. C. Simm, Robert Pinsler, G\\'abor Cs\\'anyi and Jos\\'e Miguel\n  Hern\\'andez-Lobato", "title": "Symmetry-Aware Actor-Critic for 3D Molecular Design", "comments": null, "journal-ref": "International Conference on Learning Representations, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating molecular design using deep reinforcement learning (RL) has the\npotential to greatly accelerate the search for novel materials. Despite recent\nprogress on leveraging graph representations to design molecules, such methods\nare fundamentally limited by the lack of three-dimensional (3D) information. In\nlight of this, we propose a novel actor-critic architecture for 3D molecular\ndesign that can generate molecular structures unattainable with previous\napproaches. This is achieved by exploiting the symmetries of the design process\nthrough a rotationally covariant state-action representation based on a\nspherical harmonics series expansion. We demonstrate the benefits of our\napproach on several 3D molecular design tasks, where we find that building in\nsuch symmetries significantly improves generalization and the quality of\ngenerated molecules.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 14:04:33 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Simm", "Gregor N. C.", ""], ["Pinsler", "Robert", ""], ["Cs\u00e1nyi", "G\u00e1bor", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2011.12829", "submitter": "Simone Rossi", "authors": "Ba-Hien Tran and Simone Rossi and Dimitrios Milios and Maurizio\n  Filippone", "title": "All You Need is a Good Functional Prior for Bayesian Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Bayesian treatment of neural networks dictates that a prior distribution\nis specified over their weight and bias parameters. This poses a challenge\nbecause modern neural networks are characterized by a large number of\nparameters, and the choice of these priors has an uncontrolled effect on the\ninduced functional prior, which is the distribution of the functions obtained\nby sampling the parameters from their prior distribution. We argue that this is\na hugely limiting aspect of Bayesian deep learning, and this work tackles this\nlimitation in a practical and effective way. Our proposal is to reason in terms\nof functional priors, which are easier to elicit, and to \"tune\" the priors of\nneural network parameters in a way that they reflect such functional priors.\nGaussian processes offer a rigorous framework to define prior distributions\nover functions, and we propose a novel and robust framework to match their\nprior with the functional prior of neural networks based on the minimization of\ntheir Wasserstein distance. We provide vast experimental evidence that coupling\nthese priors with scalable Markov chain Monte Carlo sampling offers\nsystematically large performance improvements over alternative choices of\npriors and state-of-the-art approximate Bayesian deep learning approaches. We\nconsider this work a considerable step in the direction of making the\nlong-standing challenge of carrying out a fully Bayesian treatment of neural\nnetworks, including convolutional neural networks, a concrete possibility.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:36:16 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Tran", "Ba-Hien", ""], ["Rossi", "Simone", ""], ["Milios", "Dimitrios", ""], ["Filippone", "Maurizio", ""]]}, {"id": "2011.12913", "submitter": "Yoshitomo Matsubara", "authors": "Yoshitomo Matsubara", "title": "torchdistill: A Modular, Configuration-Driven Framework for Knowledge\n  Distillation", "comments": "Accepted to the 3rd Workshop on Reproducible Research in Pattern\n  Recognition at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While knowledge distillation (transfer) has been attracting attentions from\nthe research community, the recent development in the fields has heightened the\nneed for reproducible studies and highly generalized frameworks to lower\nbarriers to such high-quality, reproducible deep learning research. Several\nresearchers voluntarily published frameworks used in their knowledge\ndistillation studies to help other interested researchers reproduce their\noriginal work. Such frameworks, however, are usually neither well generalized\nnor maintained, thus researchers are still required to write a lot of code to\nrefactor/build on the frameworks for introducing new methods, models, datasets\nand designing experiments. In this paper, we present our developed open-source\nframework built on PyTorch and dedicated for knowledge distillation studies.\nThe framework is designed to enable users to design experiments by declarative\nPyYAML configuration files, and helps researchers complete the recently\nproposed ML Code Completeness Checklist. Using the developed framework, we\ndemonstrate its various efficient training strategies, and implement a variety\nof knowledge distillation methods. We also reproduce some of their original\nexperimental results on the ImageNet and COCO datasets presented at major\nmachine learning conferences such as ICLR, NeurIPS, CVPR and ECCV, including\nrecent state-of-the-art methods. All the source code, configurations, log files\nand trained model weights are publicly available at\nhttps://github.com/yoshitomo-matsubara/torchdistill .\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 17:51:30 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 19:13:21 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Matsubara", "Yoshitomo", ""]]}, {"id": "2011.12916", "submitter": "Peter Holderrieth", "authors": "Peter Holderrieth, Michael Hutchinson, Yee Whye Teh", "title": "Equivariant Learning of Stochastic Fields: Gaussian Processes and\n  Steerable Conditional Neural Processes", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by objects such as electric fields or fluid streams, we study the\nproblem of learning stochastic fields, i.e. stochastic processes whose samples\nare fields like those occurring in physics and engineering. Considering general\ntransformations such as rotations and reflections, we show that spatial\ninvariance of stochastic fields requires an inference model to be equivariant.\nLeveraging recent advances from the equivariance literature, we study\nequivariance in two classes of models. Firstly, we fully characterise\nequivariant Gaussian processes. Secondly, we introduce Steerable Conditional\nNeural Processes (SteerCNPs), a new, fully equivariant member of the Neural\nProcess family. In experiments with Gaussian process vector fields, images, and\nreal-world weather data, we observe that SteerCNPs significantly improve the\nperformance of previous models and equivariance leads to improvements in\ntransfer learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 18:00:40 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 22:11:32 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 13:09:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Holderrieth", "Peter", ""], ["Hutchinson", "Michael", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2011.12919", "submitter": "Keshav Ganapathy", "authors": "David Tran, Alex Valtchanov, Keshav Ganapathy, Raymond Feng, Eric\n  Slud, Micah Goldblum, Tom Goldstein", "title": "Analyzing the Machine Learning Conference Review Process", "comments": "NeurIPS Workshop on Navigating the Broader Impacts of AI Research.\n  Full version at arXiv:2010.05137", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mainstream machine learning conferences have seen a dramatic increase in the\nnumber of participants, along with a growing range of perspectives, in recent\nyears. Members of the machine learning community are likely to overhear\nallegations ranging from randomness of acceptance decisions to institutional\nbias. In this work, we critically analyze the review process through a\ncomprehensive study of papers submitted to ICLR between 2017 and 2020. We\nquantify reproducibility/randomness in review scores and acceptance decisions,\nand examine whether scores correlate with paper impact. Our findings suggest\nstrong institutional bias in accept/reject decisions, even after controlling\nfor paper quality. Furthermore, we find evidence for a gender gap, with female\nauthors receiving lower scores, lower acceptance rates, and fewer citations per\npaper than their male counterparts. We conclude our work with recommendations\nfor future conference organizers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:40:27 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 01:34:24 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Tran", "David", ""], ["Valtchanov", "Alex", ""], ["Ganapathy", "Keshav", ""], ["Feng", "Raymond", ""], ["Slud", "Eric", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""]]}, {"id": "2011.12946", "submitter": "Dena Firoozi", "authors": "Dena Firoozi and Sebastian Jaimungal", "title": "Exploratory LQG Mean Field Games with Entropy Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.SY eess.SY math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a general class of entropy-regularized multi-variate LQG mean field\ngames (MFGs) in continuous time with $K$ distinct sub-population of agents. We\nextend the notion of actions to action distributions (exploratory actions), and\nexplicitly derive the optimal action distributions for individual agents in the\nlimiting MFG. We demonstrate that the optimal set of action distributions\nyields an $\\epsilon$-Nash equilibrium for the finite-population\nentropy-regularized MFG. Furthermore, we compare the resulting solutions with\nthose of classical LQG MFGs and establish the equivalence of their existence.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 18:51:09 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 00:17:57 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Firoozi", "Dena", ""], ["Jaimungal", "Sebastian", ""]]}, {"id": "2011.13034", "submitter": "Jingfeng Wu", "authors": "Jingfeng Wu, Vladimir Braverman, Lin F. Yang", "title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity\n  for Multi-Objective Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider multi-objective reinforcement learning where the\nobjectives are balanced using preferences. In practice, the preferences are\noften given in an adversarial manner, e.g., customers can be picky in many\napplications. We formalize this problem as an episodic learning problem on a\nMarkov decision process, where transitions are unknown and a reward function is\nthe inner product of a preference vector with pre-specified multi-objective\nreward functions. We consider two settings. In the online setting, the agent\nreceives a (adversarial) preference every episode and proposes policies to\ninteract with the environment. We provide a model-based algorithm that achieves\na nearly minimax optimal regret bound\n$\\widetilde{\\mathcal{O}}\\bigl(\\sqrt{\\min\\{d,S\\}\\cdot H^2 SAK}\\bigr)$, where $d$\nis the number of objectives, $S$ is the number of states, $A$ is the number of\nactions, $H$ is the length of the horizon, and $K$ is the number of episodes.\nFurthermore, we consider preference-free exploration, i.e., the agent first\ninteracts with the environment without specifying any preference and then is\nable to accommodate arbitrary preference vector up to $\\epsilon$ error. Our\nproposed algorithm is provably efficient with a nearly optimal trajectory\ncomplexity $\\widetilde{\\mathcal{O}}\\bigl({\\min\\{d,S\\}\\cdot H^3\nSA}/{\\epsilon^2}\\bigr)$. This result partly resolves an open problem raised by\n\\citet{jin2020reward}.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 21:45:04 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 01:33:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wu", "Jingfeng", ""], ["Braverman", "Vladimir", ""], ["Yang", "Lin F.", ""]]}, {"id": "2011.13077", "submitter": "Jordan Trinka", "authors": "Jordan Trinka and Hossein Haghbin and Mehdi Maadooliat", "title": "Functional Time Series Forecasting: Functional Singular Spectrum\n  Analysis Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose two nonparametric methods used in the forecasting\nof functional time-dependent data, namely functional singular spectrum analysis\nrecurrent forecasting and vector forecasting. Both algorithms utilize the\nresults of functional singular spectrum analysis and past observations in order\nto predict future data points where recurrent forecasting predicts one function\nat a time and the vector forecasting makes predictions using functional\nvectors. We compare our forecasting methods to a gold standard algorithm used\nin the prediction of functional, time-dependent data by way of simulation and\nreal data and we find our techniques do better for periodic stochastic\nprocesses.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 00:36:57 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 05:41:48 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 19:25:31 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 20:38:44 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Trinka", "Jordan", ""], ["Haghbin", "Hossein", ""], ["Maadooliat", "Mehdi", ""]]}, {"id": "2011.13094", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim, Minsu Cho, Seungjin Choi", "title": "Combinatorial Bayesian Optimization with Random Mapping Functions to\n  Convex Polytope", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a popular method for solving the problem of global\noptimization of an expensive-to-evaluate black-box function. It relies on a\nprobabilistic surrogate model of the objective function, upon which an\nacquisition function is built to determine where next to evaluate the objective\nfunction. In general, Bayesian optimization with Gaussian process regression\noperates on a continuous space. When input variables are categorical or\ndiscrete, an extra care is needed. A common approach is to use one-hot encoded\nor Boolean representation for categorical variables which might yield a {\\em\ncombinatorial explosion} problem. In this paper we present a method for\nBayesian optimization in a combinatorial space, which can operate well in a\nlarge combinatorial space. The main idea is to use a random mapping which\nembeds the combinatorial space into a convex polytope in a continuous space, on\nwhich all essential process is performed to determine a solution to the\nblack-box optimization in the combinatorial space. We describe our {\\em\ncombinatorial Bayesian optimization} algorithm and present its regret analysis.\nNumerical experiments demonstrate that our method outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 02:22:41 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kim", "Jungtaek", ""], ["Cho", "Minsu", ""], ["Choi", "Seungjin", ""]]}, {"id": "2011.13161", "submitter": "Takahiro Hoshino", "authors": "Tomoki Toyabe, Yasuhiro Hasegawa, and Takahiro Hoshino", "title": "Positive-Unlabelled Survival Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider a novel framework of positive-unlabeled data in\nwhich as positive data survival times are observed for subjects who have events\nduring the observation time as positive data and as unlabeled data censoring\ntimes are observed but whether the event occurs or not are unknown for some\nsubjects. We consider two cases: (1) when censoring time is observed in\npositive data, and (2) when it is not observed. For both cases, we developed\nparametric models, nonparametric models, and machine learning models and the\nestimation strategies for these models. Simulation studies show that under this\ndata setup, traditional survival analysis may yield severely biased results,\nwhile the proposed estimation method can provide valid results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 07:11:41 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Toyabe", "Tomoki", ""], ["Hasegawa", "Yasuhiro", ""], ["Hoshino", "Takahiro", ""]]}, {"id": "2011.13219", "submitter": "Qingbiao Li", "authors": "Qingbiao Li, Weizhe Lin, Zhe Liu, Amanda Prorok", "title": "Message-Aware Graph Attention Networks for Large-Scale Multi-Robot Path\n  Planning", "comments": "This work has been accepted to the IEEE Robotics and Automation\n  Letters (RA-L) for publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domains of transport and logistics are increasingly relying on autonomous\nmobile robots for the handling and distribution of passengers or resources. At\nlarge system scales, finding decentralized path planning and coordination\nsolutions is key to efficient system performance. Recently, Graph Neural\nNetworks (GNNs) have become popular due to their ability to learn communication\npolicies in decentralized multi-agent systems. Yet, vanilla GNNs rely on\nsimplistic message aggregation mechanisms that prevent agents from prioritizing\nimportant information. To tackle this challenge, in this paper, we extend our\nprevious work that utilizes GNNs in multi-agent path planning by incorporating\na novel mechanism to allow for message-dependent attention. Our Message-Aware\nGraph Attention neTwork (MAGAT) is based on a key-query-like mechanism that\ndetermines the relative importance of features in the messages received from\nvarious neighboring robots. We show that MAGAT is able to achieve a performance\nclose to that of a coupled centralized expert algorithm. Further, ablation\nstudies and comparisons to several benchmark models show that our attention\nmechanism is very effective across different robot densities and performs\nstably in different constraints in communication bandwidth. Experiments\ndemonstrate that our model is able to generalize well in previously unseen\nproblem instances, and that it achieves a 47\\% improvement over the benchmark\nsuccess rate, even in very large-scale instances that are $\\times$100 larger\nthan the training instances.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:37:13 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 11:40:52 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Li", "Qingbiao", ""], ["Lin", "Weizhe", ""], ["Liu", "Zhe", ""], ["Prorok", "Amanda", ""]]}, {"id": "2011.13456", "submitter": "Yang Song", "authors": "Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar,\n  Stefano Ermon and Ben Poole", "title": "Score-Based Generative Modeling through Stochastic Differential\n  Equations", "comments": "ICLR 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating noise from data is easy; creating data from noise is generative\nmodeling. We present a stochastic differential equation (SDE) that smoothly\ntransforms a complex data distribution to a known prior distribution by slowly\ninjecting noise, and a corresponding reverse-time SDE that transforms the prior\ndistribution back into the data distribution by slowly removing the noise.\nCrucially, the reverse-time SDE depends only on the time-dependent gradient\nfield (\\aka, score) of the perturbed data distribution. By leveraging advances\nin score-based generative modeling, we can accurately estimate these scores\nwith neural networks, and use numerical SDE solvers to generate samples. We\nshow that this framework encapsulates previous approaches in score-based\ngenerative modeling and diffusion probabilistic modeling, allowing for new\nsampling procedures and new modeling capabilities. In particular, we introduce\na predictor-corrector framework to correct errors in the evolution of the\ndiscretized reverse-time SDE. We also derive an equivalent neural ODE that\nsamples from the same distribution as the SDE, but additionally enables exact\nlikelihood computation, and improved sampling efficiency. In addition, we\nprovide a new way to solve inverse problems with score-based models, as\ndemonstrated with experiments on class-conditional generation, image\ninpainting, and colorization. Combined with multiple architectural\nimprovements, we achieve record-breaking performance for unconditional image\ngeneration on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a\ncompetitive likelihood of 2.99 bits/dim, and demonstrate high fidelity\ngeneration of 1024 x 1024 images for the first time from a score-based\ngenerative model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 19:39:10 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 18:17:04 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Song", "Yang", ""], ["Sohl-Dickstein", "Jascha", ""], ["Kingma", "Diederik P.", ""], ["Kumar", "Abhishek", ""], ["Ermon", "Stefano", ""], ["Poole", "Ben", ""]]}, {"id": "2011.13600", "submitter": "Junhao Hua", "authors": "Junhao Hua, Chunguang Li", "title": "Distributed Variational Bayesian Algorithms Over Sensor Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2015.2493979", "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed inference/estimation in Bayesian framework in the context of\nsensor networks has recently received much attention due to its broad\napplicability. The variational Bayesian (VB) algorithm is a technique for\napproximating intractable integrals arising in Bayesian inference. In this\npaper, we propose two novel distributed VB algorithms for general Bayesian\ninference problem, which can be applied to a very general class of\nconjugate-exponential models. In the first approach, the global natural\nparameters at each node are optimized using a stochastic natural gradient that\nutilizes the Riemannian geometry of the approximation space, followed by an\ninformation diffusion step for cooperation with the neighbors. In the second\nmethod, a constrained optimization formulation for distributed estimation is\nestablished in natural parameter space and solved by alternating direction\nmethod of multipliers (ADMM). An application of the distributed\ninference/estimation of a Bayesian Gaussian mixture model is then presented, to\nevaluate the effectiveness of the proposed algorithms. Simulations on both\nsynthetic and real datasets demonstrate that the proposed algorithms have\nexcellent performance, which are almost as good as the corresponding\ncentralized VB algorithm relying on all data available in a fusion center.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 08:12:18 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hua", "Junhao", ""], ["Li", "Chunguang", ""]]}, {"id": "2011.13680", "submitter": "Miguel Tierz", "authors": "Leonardo Santilli and Miguel Tierz", "title": "Riemannian Gaussian distributions, random matrix ensembles and diffusion\n  kernels", "comments": "26 pages, 9 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Riemannian Gaussian distributions on symmetric spaces,\nintroduced in recent years, are of standard random matrix type. We exploit this\nto compute analytically marginals of the probability density functions. This\ncan be done fully, using Stieltjes-Wigert orthogonal polynomials, for the case\nof the space of Hermitian matrices, where the distributions have already\nappeared in the physics literature. For the case when the symmetric space is\nthe space of $m \\times m$ symmetric positive definite matrices, we show how to\nefficiently compute by evaluating Pfaffians at specific values of $m$.\nEquivalently, we can obtain the same result by constructing specific skew\northogonal polynomials with regards to the log-normal weight function (skew\nStieltjes-Wigert polynomials). Other symmetric spaces are studied and the same\ntype of result is obtained for the quaternionic case. Moreover, we show how the\nprobability density functions are a particular case of diffusion reproducing\nkernels of the Karlin-McGregor type, describing non-intersecting Brownian\nmotions, which are also diffusion processes in the Weyl chamber of Lie groups.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 11:41:29 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Santilli", "Leonardo", ""], ["Tierz", "Miguel", ""]]}, {"id": "2011.13694", "submitter": "Vincent Audigier", "authors": "Vincent Audigier, Nd\\`eye Niang", "title": "Clustering with missing data: which equivalent for Rubin's rules?", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple imputation (MI) is a popular method for dealing with missing values.\nHowever, the suitable way for applying clustering after MI remains unclear: how\nto pool partitions? How to assess the clustering instability when data are\nincomplete? By answering both questions, this paper proposed a complete view of\nclustering with missing data using MI. The problem of partitions pooling is\nhere addressed using consensus clustering while, based on the bootstrap theory,\nwe explain how to assess the instability related to observed and missing data.\nThe new rules for pooling partitions and instability assessment are\ntheoretically argued and extensively studied by simulation. Partitions pooling\nimproves accuracy while measuring instability with missing data enlarges the\ndata analysis possibilities: it allows assessment of the dependence of the\nclustering to the imputation model, as well as a convenient way for choosing\nthe number of clusters when data are incomplete, as illustrated on a real data\nset.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 12:09:31 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Audigier", "Vincent", ""], ["Niang", "Nd\u00e8ye", ""]]}, {"id": "2011.13704", "submitter": "J\\\"org L\\\"ucke", "authors": "Enrico Guiraud, Jakob Drefs, J\\\"org L\\\"ucke", "title": "Direct Evolutionary Optimization of Variational Autoencoders With Binary\n  Latents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discrete latent variables are considered important for real world data, which\nhas motivated research on Variational Autoencoders (VAEs) with discrete\nlatents. However, standard VAE-training is not possible in this case, which has\nmotivated different strategies to manipulate discrete distributions in order to\ntrain discrete VAEs similarly to conventional ones. Here we ask if it is also\npossible to keep the discrete nature of the latents fully intact by applying a\ndirect discrete optimization for the encoding model. The approach is\nconsequently strongly diverting from standard VAE-training by sidestepping\nsampling approximation, reparameterization trick and amortization. Discrete\noptimization is realized in a variational setting using truncated posteriors in\nconjunction with evolutionary algorithms. For VAEs with binary latents, we (A)\nshow how such a discrete variational method ties into gradient ascent for\nnetwork weights, and (B) how the decoder is used to select latent states for\ntraining. Conventional amortized training is more efficient and applicable to\nlarge neural networks. However, using smaller networks, we here find direct\ndiscrete optimization to be efficiently scalable to hundreds of latents. More\nimportantly, we find the effectiveness of direct optimization to be highly\ncompetitive in `zero-shot' learning. In contrast to large supervised networks,\nthe here investigated VAEs can, e.g., denoise a single image without previous\ntraining on clean data and/or training on large image datasets. More generally,\nthe studied approach shows that training of VAEs is indeed possible without\nsampling-based approximation and reparameterization, which may be interesting\nfor the analysis of VAE-training in general. For `zero-shot' settings a direct\noptimization, furthermore, makes VAEs competitive where they have previously\nbeen outperformed by non-generative approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 12:42:12 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Guiraud", "Enrico", ""], ["Drefs", "Jakob", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "2011.13719", "submitter": "Ran Wang", "authors": "Haojing Shen, Sihong Chen, Ran Wang", "title": "A Study on the Uncertainty of Convolutional Layers in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper shows a Min-Max property existing in the connection weights of the\nconvolutional layers in a neural network structure, i.e., the LeNet.\nSpecifically, the Min-Max property means that, during the back\npropagation-based training for LeNet, the weights of the convolutional layers\nwill become far away from their centers of intervals, i.e., decreasing to their\nminimum or increasing to their maximum. From the perspective of uncertainty, we\ndemonstrate that the Min-Max property corresponds to minimizing the fuzziness\nof the model parameters through a simplified formulation of convolution. It is\nexperimentally confirmed that the model with the Min-Max property has a\nstronger adversarial robustness, thus this property can be incorporated into\nthe design of loss function. This paper points out a changing tendency of\nuncertainty in the convolutional layers of LeNet structure, and gives some\ninsights to the interpretability of convolution.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 13:06:36 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Shen", "Haojing", ""], ["Chen", "Sihong", ""], ["Wang", "Ran", ""]]}, {"id": "2011.13831", "submitter": "Pierre Ablin", "authors": "Pierre Ablin", "title": "Deep orthogonal linear networks are shallow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of training a deep orthogonal linear network, which\nconsists of a product of orthogonal matrices, with no non-linearity in-between.\nWe show that training the weights with Riemannian gradient descent is\nequivalent to training the whole factorization by gradient descent. This means\nthat there is no effect of overparametrization and implicit bias at all in this\nsetting: training such a deep, overparametrized, network is perfectly\nequivalent to training a one-layer shallow network.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 16:57:19 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ablin", "Pierre", ""]]}, {"id": "2011.13863", "submitter": "Clemens Hutter", "authors": "Clemens Hutter, Moritz von Stosch, Mariano Nicolas Cruz Bournazou,\n  Alessandro Butt\\'e", "title": "Knowledge transfer across cell lines using Hybrid Gaussian Process\n  models with entity embedding vectors", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To date, a large number of experiments are performed to develop a biochemical\nprocess. The generated data is used only once, to take decisions for\ndevelopment. Could we exploit data of already developed processes to make\npredictions for a novel process, we could significantly reduce the number of\nexperiments needed. Processes for different products exhibit differences in\nbehaviour, typically only a subset behave similar. Therefore, effective\nlearning on multiple product spanning process data requires a sensible\nrepresentation of the product identity. We propose to represent the product\nidentity (a categorical feature) by embedding vectors that serve as input to a\nGaussian Process regression model. We demonstrate how the embedding vectors can\nbe learned from process data and show that they capture an interpretable notion\nof product similarity. The improvement in performance is compared to\ntraditional one-hot encoding on a simulated cross product learning task. All in\nall, the proposed method could render possible significant reductions in\nwet-lab experiments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 17:38:15 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hutter", "Clemens", ""], ["von Stosch", "Moritz", ""], ["Bournazou", "Mariano Nicolas Cruz", ""], ["Butt\u00e9", "Alessandro", ""]]}, {"id": "2011.13885", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Alexander Novikov, Ksenia Konyushkova, Caglar Gulcehre,\n  Ziyu Wang, Yusuf Aytar, Misha Denil, Nando de Freitas, Scott Reed", "title": "Offline Learning from Demonstrations and Unlabeled Experience", "comments": "Accepted to Offline Reinforcement Learning Workshop at Neural\n  Information Processing Systems (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior cloning (BC) is often practical for robot learning because it allows\na policy to be trained offline without rewards, by supervised learning on\nexpert demonstrations. However, BC does not effectively leverage what we will\nrefer to as unlabeled experience: data of mixed and unknown quality without\nreward annotations. This unlabeled data can be generated by a variety of\nsources such as human teleoperation, scripted policies and other agents on the\nsame robot. Towards data-driven offline robot learning that can use this\nunlabeled experience, we introduce Offline Reinforced Imitation Learning\n(ORIL). ORIL first learns a reward function by contrasting observations from\ndemonstrator and unlabeled trajectories, then annotates all data with the\nlearned reward, and finally trains an agent via offline reinforcement learning.\nAcross a diverse set of continuous control and simulated robotic manipulation\ntasks, we show that ORIL consistently outperforms comparable BC agents by\neffectively leveraging unlabeled experience.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:20:04 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zolna", "Konrad", ""], ["Novikov", "Alexander", ""], ["Konyushkova", "Ksenia", ""], ["Gulcehre", "Caglar", ""], ["Wang", "Ziyu", ""], ["Aytar", "Yusuf", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""], ["Reed", "Scott", ""]]}, {"id": "2011.13897", "submitter": "Homanga Bharadhwaj", "authors": "Kevin Xie, Homanga Bharadhwaj, Danijar Hafner, Animesh Garg, Florian\n  Shkurti", "title": "Latent Skill Planning for Exploration and Transfer", "comments": "First two authors contributed equally. Published as a conference\n  paper in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To quickly solve new tasks in complex environments, intelligent agents need\nto build up reusable knowledge. For example, a learned world model captures\nknowledge about the environment that applies to new tasks. Similarly, skills\ncapture general behaviors that can apply to new tasks. In this paper, we\ninvestigate how these two approaches can be integrated into a single\nreinforcement learning agent. Specifically, we leverage the idea of partial\namortization for fast adaptation at test time. For this, actions are produced\nby a policy that is learned over time while the skills it conditions on are\nchosen using online planning. We demonstrate the benefits of our design\ndecisions across a suite of challenging locomotion tasks and demonstrate\nimproved sample efficiency in single tasks as well as in transfer from one task\nto another, as compared to competitive baselines. Videos are available at:\nhttps://sites.google.com/view/latent-skill-planning/\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:40:03 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 15:53:04 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Xie", "Kevin", ""], ["Bharadhwaj", "Homanga", ""], ["Hafner", "Danijar", ""], ["Garg", "Animesh", ""], ["Shkurti", "Florian", ""]]}, {"id": "2011.13967", "submitter": "Zejian Liu", "authors": "Zejian Liu and Meng Li", "title": "Equivalence of Convergence Rates of Posterior Distributions and Bayes\n  Estimators for Functions and Nonparametric Functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the posterior contraction rates of a Bayesian method with Gaussian\nprocess priors in nonparametric regression and its plug-in property for\ndifferential operators. For a general class of kernels, we establish\nconvergence rates of the posterior measure of the regression function and its\nderivatives, which are both minimax optimal up to a logarithmic factor for\nfunctions in certain classes. Our calculation shows that the rate-optimal\nestimation of the regression function and its derivatives share the same choice\nof hyperparameter, indicating that the Bayes procedure remarkably adapts to the\norder of derivatives and enjoys a generalized plug-in property that extends\nreal-valued functionals to function-valued functionals. This leads to a\npractically simple method for estimating the regression function and its\nderivatives, whose finite sample performance is assessed using simulations.\n  Our proof shows that, under certain conditions, to any convergence rate of\nBayes estimators there corresponds the same convergence rate of the posterior\ndistributions (i.e., posterior contraction rate), and vice versa. This\nequivalence holds for a general class of Gaussian processes and covers the\nregression function and its derivative functionals, under both the $L_2$ and\n$L_{\\infty}$ norms. In addition to connecting these two fundamental large\nsample properties in Bayesian and non-Bayesian regimes, such equivalence\nenables a new routine to establish posterior contraction rates by calculating\nconvergence rates of nonparametric point estimators.\n  At the core of our argument is an operator-theoretic framework for kernel\nridge regression and equivalent kernel techniques. We derive a range of sharp\nnon-asymptotic bounds that are pivotal in establishing convergence rates of\nnonparametric point estimators and the equivalence theory, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 19:11:56 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Liu", "Zejian", ""], ["Li", "Meng", ""]]}, {"id": "2011.14006", "submitter": "Patricia Pauli", "authors": "Patricia Pauli, Johannes K\\\"ohler, Julian Berberich, Anne Koch and\n  Frank Allg\\\"ower", "title": "Offset-free setpoint tracking using neural network controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method to analyze local and global stability in\noffset-free setpoint tracking using neural network controllers and we provide\nellipsoidal inner approximations of the corresponding region of attraction. We\nconsider a feedback interconnection of a linear plant in connection with a\nneural network controller and an integrator, which allows for offset-free\ntracking of a desired piecewise constant reference that enters the controller\nas an external input. Exploiting the fact that activation functions used in\nneural networks are slope-restricted, we derive linear matrix inequalities to\nverify stability using Lyapunov theory. After stating a global stability\nresult, we present less conservative local stability conditions (i) for a given\nreference and (ii) for any reference from a certain set. The latter result even\nenables guaranteed tracking under setpoint changes using a reference governor\nwhich can lead to a significant increase of the region of attraction. Finally,\nwe demonstrate the applicability of our analysis by verifying stability and\noffset-free tracking of a neural network controller that was trained to\nstabilize a linearized inverted pendulum.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:13:13 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 17:10:14 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Pauli", "Patricia", ""], ["K\u00f6hler", "Johannes", ""], ["Berberich", "Julian", ""], ["Koch", "Anne", ""], ["Allg\u00f6wer", "Frank", ""]]}, {"id": "2011.14031", "submitter": "Fnu Devvrit", "authors": "Devvrit, Minhao Cheng, Cho-Jui Hsieh, Inderjit Dhillon", "title": "Voting based ensemble improves robustness of defensive models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing robust models against adversarial perturbations has been an active\narea of research and many algorithms have been proposed to train individual\nrobust models. Taking these pretrained robust models, we aim to study whether\nit is possible to create an ensemble to further improve robustness. Several\nprevious attempts tackled this problem by ensembling the soft-label prediction\nand have been proved vulnerable based on the latest attack methods. In this\npaper, we show that if the robust training loss is diverse enough, a simple\nhard-label based voting ensemble can boost the robust error over each\nindividual model. Furthermore, given a pool of robust models, we develop a\nprincipled way to select which models to ensemble. Finally, to verify the\nimproved robustness, we conduct extensive experiments to study how to attack a\nvoting-based ensemble and develop several new white-box attacks. On CIFAR-10\ndataset, by ensembling several state-of-the-art pre-trained defense models, our\nmethod can achieve a 59.8% robust accuracy, outperforming all the existing\ndefensive models without using additional data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:08:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Devvrit", "", ""], ["Cheng", "Minhao", ""], ["Hsieh", "Cho-Jui", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2011.14032", "submitter": "Sebastiano Barbieri", "authors": "Sebastiano Barbieri, Suneela Mehta, Billy Wu, Chrianna Bharat, Katrina\n  Poppe, Louisa Jorm, Rod Jackson", "title": "Predicting cardiovascular risk from national administrative databases\n  using a combined survival analysis and deep learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AIMS. This study compared the performance of deep learning extensions of\nsurvival analysis models with traditional Cox proportional hazards (CPH) models\nfor deriving cardiovascular disease (CVD) risk prediction equations in national\nhealth administrative datasets. METHODS. Using individual person linkage of\nmultiple administrative datasets, we constructed a cohort of all New Zealand\nresidents aged 30-74 years who interacted with publicly funded health services\nduring 2012, and identified hospitalisations and deaths from CVD over five\nyears of follow-up. After excluding people with prior CVD or heart failure,\nsex-specific deep learning and CPH models were developed to estimate the risk\nof fatal or non-fatal CVD events within five years. The proportion of explained\ntime-to-event occurrence, calibration, and discrimination were compared between\nmodels across the whole study population and in specific risk groups. FINDINGS.\nFirst CVD events occurred in 61,927 of 2,164,872 people. Among diagnoses and\nprocedures, the largest 'local' hazard ratios were associated by the deep\nlearning models with tobacco use in women (2.04, 95%CI: 1.99-2.10) and with\nchronic obstructive pulmonary disease with acute lower respiratory infection in\nmen (1.56, 95%CI: 1.50-1.62). Other identified predictors (e.g. hypertension,\nchest pain, diabetes) aligned with current knowledge about CVD risk predictors.\nThe deep learning models significantly outperformed the CPH models on the basis\nof proportion of explained time-to-event occurrence (Royston and Sauerbrei's\nR-squared: 0.468 vs. 0.425 in women and 0.383 vs. 0.348 in men), calibration,\nand discrimination (all p<0.0001). INTERPRETATION. Deep learning extensions of\nsurvival analysis models can be applied to large health administrative\ndatabases to derive interpretable CVD risk prediction equations that are more\naccurate than traditional CPH models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:10:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Barbieri", "Sebastiano", ""], ["Mehta", "Suneela", ""], ["Wu", "Billy", ""], ["Bharat", "Chrianna", ""], ["Poppe", "Katrina", ""], ["Jorm", "Louisa", ""], ["Jackson", "Rod", ""]]}, {"id": "2011.14033", "submitter": "Priyank Agrawal", "authors": "Priyank Agrawal, Vashist Avadhanula and Theja Tulabandhula", "title": "A Tractable Online Learning Algorithm for the Multinomial Logit\n  Contextual Bandit", "comments": "updated version with convex relaxation result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the contextual variant of the MNL-Bandit problem.\nMore specifically, we consider a dynamic set optimization problem, where in\nevery round a decision maker offers a subset (assortment) of products to a\nconsumer, and observes their response. Consumers purchase products so as to\nmaximize their utility. We assume that the products are described by a set of\nattributes and the mean utility of a product is linear in the values of these\nattributes. We model consumer choice behavior by means of the widely used\nMultinomial Logit (MNL) model, and consider the decision maker's problem of\ndynamically learning the model parameters, while optimizing cumulative revenue\nover the selling horizon $T$. Though this problem has attracted considerable\nattention in recent times, many existing methods often involve solving an\nintractable non-convex optimization problem and their theoretical performance\nguarantees depend on a problem dependent parameter which could be prohibitively\nlarge. In particular, existing algorithms for this problem have regret bounded\nby $O(\\sqrt{\\kappa d T})$, where $\\kappa$ is a problem dependent constant that\ncan have exponential dependency on the number of attributes. In this paper, we\npropose an optimistic algorithm and show that the regret is bounded by\n$O(\\sqrt{dT} + \\kappa)$, significantly improving the performance over existing\nmethods. Further, we propose a convex relaxation of the optimization step which\nallows for tractable decision-making while retaining the favourable regret\nguarantee.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:20:36 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 07:48:58 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 19:53:26 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Agrawal", "Priyank", ""], ["Avadhanula", "Vashist", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "2011.14047", "submitter": "Cesar F. Caiafa", "authors": "Cesar F. Caiafa, Ziyao Wang, Jordi Sol\\'e-Casals, Qibin Zhao", "title": "Learning from Incomplete Features by Simultaneous Training of Neural\n  Networks and Sparse Coding", "comments": "11 pages, 7 figures, paper accepted for presentation at L2ID Workshop\n  at CVPR 2021 (19-25 June, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the problem of training a classifier on a dataset with\nincomplete features is addressed. We assume that different subsets of features\n(random or structured) are available at each data instance. This situation\ntypically occurs in the applications when not all the features are collected\nfor every data sample. A new supervised learning method is developed to train a\ngeneral classifier, such as a logistic regression or a deep neural network,\nusing only a subset of features per sample, while assuming sparse\nrepresentations of data vectors on an unknown dictionary. Sufficient conditions\nare identified, such that, if it is possible to train a classifier on\nincomplete observations so that their reconstructions are well separated by a\nhyperplane, then the same classifier also correctly separates the original\n(unobserved) data samples. Extensive simulation results on synthetic and\nwell-known datasets are presented that validate our theoretical findings and\ndemonstrate the effectiveness of the proposed method compared to traditional\ndata imputation approaches and one state-of-the-art algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 02:20:39 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 20:09:10 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Caiafa", "Cesar F.", ""], ["Wang", "Ziyao", ""], ["Sol\u00e9-Casals", "Jordi", ""], ["Zhao", "Qibin", ""]]}, {"id": "2011.14048", "submitter": "Amrith Setlur", "authors": "Amrith Setlur, Oscar Li, Virginia Smith", "title": "Is Support Set Diversity Necessary for Meta-Learning?", "comments": null, "journal-ref": "NeurIPS 2020 Workshop on Meta-learning", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning is a popular framework for learning with limited data in which\nan algorithm is produced by training over multiple few-shot learning tasks. For\nclassification problems, these tasks are typically constructed by sampling a\nsmall number of support and query examples from a subset of the classes. While\nconventional wisdom is that task diversity should improve the performance of\nmeta-learning, in this work we find evidence to the contrary: we propose a\nmodification to traditional meta-learning approaches in which we keep the\nsupport sets fixed across tasks, thus reducing task diversity. Surprisingly, we\nfind that not only does this modification not result in adverse effects, it\nalmost always improves the performance for a variety of datasets and\nmeta-learning methods. We also provide several initial analyses to understand\nthis phenomenon. Our work serves to: (i) more closely investigate the effect of\nsupport set construction for the problem of meta-learning, and (ii) suggest a\nsimple, general, and competitive baseline for few-shot learning.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 02:28:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Setlur", "Amrith", ""], ["Li", "Oscar", ""], ["Smith", "Virginia", ""]]}, {"id": "2011.14066", "submitter": "Vatsal Shah", "authors": "Vatsal Shah, Soumya Basu, Anastasios Kyrillidis, Sujay Sanghavi", "title": "On Generalization of Adaptive Methods for Over-parameterized Linear\n  Regression", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.07055", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterization and adaptive methods have played a crucial role in the\nsuccess of deep learning in the last decade. The widespread use of\nover-parameterization has forced us to rethink generalization by bringing forth\nnew phenomena, such as implicit regularization of optimization algorithms and\ndouble descent with training progression. A series of recent works have started\nto shed light on these areas in the quest to understand -- why do neural\nnetworks generalize well? The setting of over-parameterized linear regression\nhas provided key insights into understanding this mysterious behavior of neural\nnetworks.\n  In this paper, we aim to characterize the performance of adaptive methods in\nthe over-parameterized linear regression setting. First, we focus on two\nsub-classes of adaptive methods depending on their generalization performance.\nFor the first class of adaptive methods, the parameter vector remains in the\nspan of the data and converges to the minimum norm solution like gradient\ndescent (GD). On the other hand, for the second class of adaptive methods, the\ngradient rotation caused by the pre-conditioner matrix results in an in-span\ncomponent of the parameter vector that converges to the minimum norm solution\nand the out-of-span component that saturates. Our experiments on\nover-parameterized linear regression and deep neural networks support this\ntheory.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 04:19:32 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shah", "Vatsal", ""], ["Basu", "Soumya", ""], ["Kyrillidis", "Anastasios", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "2011.14126", "submitter": "Zakaria Mhammedi", "authors": "Zakaria Mhammedi and Hisham Husain", "title": "Risk-Monotonicity in Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquisition of data is a difficult task in many applications of machine\nlearning, and it is only natural that one hopes and expects the populating risk\nto decrease (better performance) monotonically with increasing data points. It\nturns out, somewhat surprisingly, that this is not the case even for the most\nstandard algorithms such as empirical risk minimization. Non-monotonic\nbehaviour of the risk and instability in training have manifested and appeared\nin the popular deep learning paradigm under the description of double descent.\nThese problems highlight bewilderment in our understanding of learning\nalgorithms and generalization. It is, therefore, crucial to pursue this concern\nand provide a characterization of such behaviour. In this paper, we derive the\nfirst consistent and risk-monotonic algorithms for a general statistical\nlearning setting under weak assumptions, consequently resolving an open problem\n(Viering et al. 2019) on how to avoid non-monotonic behaviour of risk curves.\nOur work makes a significant contribution to the topic of risk-monotonicity,\nwhich may be key in resolving empirical phenomena such as double descent.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 12:52:12 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 07:21:06 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 04:26:33 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Mhammedi", "Zakaria", ""], ["Husain", "Hisham", ""]]}, {"id": "2011.14145", "submitter": "Feng Bao", "authors": "Richard Archibald, Feng Bao, Yanzhao Cao, and He Zhang", "title": "A Backward SDE Method for Uncertainty Quantification in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a probabilistic machine learning method, which formulates a class\nof stochastic neural networks by a stochastic optimal control problem. An\nefficient stochastic gradient descent algorithm is introduced under the\nstochastic maximum principle framework. Numerical experiments for applications\nof stochastic neural networks are carried out to validate the effectiveness of\nour methodology.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 15:19:36 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 01:42:45 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Archibald", "Richard", ""], ["Bao", "Feng", ""], ["Cao", "Yanzhao", ""], ["Zhang", "He", ""]]}, {"id": "2011.14185", "submitter": "Yang Ning", "authors": "Siyi Deng, Yang Ning, Jiwei Zhao, Heping Zhang", "title": "Optimal Semi-supervised Estimation and Inference for High-dimensional\n  Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There are many scenarios such as the electronic health records where the\noutcome is much more difficult to collect than the covariates. In this paper,\nwe consider the linear regression problem with such a data structure under the\nhigh dimensionality. Our goal is to investigate when and how the unlabeled data\ncan be exploited to improve the estimation and inference of the regression\nparameters in linear models, especially in light of the fact that such linear\nmodels may be misspecified in data analysis. In particular, we address the\nfollowing two important questions. (1) Can we use the labeled data as well as\nthe unlabeled data to construct a semi-supervised estimator such that its\nconvergence rate is faster than the supervised estimators? (2) Can we construct\nconfidence intervals or hypothesis tests that are guaranteed to be more\nefficient or powerful than the supervised estimators? To address the first\nquestion, we establish the minimax lower bound for parameter estimation in the\nsemi-supervised setting. We show that the upper bound from the supervised\nestimators that only use the labeled data cannot attain this lower bound. We\nclose this gap by proposing a new semi-supervised estimator which attains the\nlower bound. To address the second question, based on our proposed\nsemi-supervised estimator, we propose two additional estimators for\nsemi-supervised inference, the efficient estimator and the safe estimator. The\nformer is fully efficient if the unknown conditional mean function is estimated\nconsistently, but may not be more efficient than the supervised approach\notherwise. The latter usually does not aim to provide fully efficient\ninference, but is guaranteed to be no worse than the supervised approach, no\nmatter whether the linear model is correctly specified or the conditional mean\nfunction is consistently estimated.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 18:26:46 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Deng", "Siyi", ""], ["Ning", "Yang", ""], ["Zhao", "Jiwei", ""], ["Zhang", "Heping", ""]]}, {"id": "2011.14204", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Yue Wu, Pradeep Natarajan, Premkumar Natarajan", "title": "Class-agnostic Object Detection", "comments": "To appear in Proceedings of WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection models perform well at localizing and classifying objects\nthat they are shown during training. However, due to the difficulty and cost\nassociated with creating and annotating detection datasets, trained models\ndetect a limited number of object types with unknown objects treated as\nbackground content. This hinders the adoption of conventional detectors in\nreal-world applications like large-scale object matching, visual grounding,\nvisual relation prediction, obstacle detection (where it is more important to\ndetermine the presence and location of objects than to find specific types),\netc. We propose class-agnostic object detection as a new problem that focuses\non detecting objects irrespective of their object-classes. Specifically, the\ngoal is to predict bounding boxes for all objects in an image but not their\nobject-classes. The predicted boxes can then be consumed by another system to\nperform application-specific classification, retrieval, etc. We propose\ntraining and evaluation protocols for benchmarking class-agnostic detectors to\nadvance future research in this domain. Finally, we propose (1) baseline\nmethods and (2) a new adversarial learning framework for class-agnostic\ndetection that forces the model to exclude class-specific information from\nfeatures used for predictions. Experimental results show that adversarial\nlearning improves class-agnostic detection efficacy.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 19:22:38 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Wu", "Yue", ""], ["Natarajan", "Pradeep", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "2011.14211", "submitter": "Bingzhe Wei", "authors": "Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Chunxu Zhang, Bo\n  Yang", "title": "Curvature Regularization to Prevent Distortion in Graph Embedding", "comments": "Published as a conference paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on graph embedding has achieved success in various\napplications. Most graph embedding methods preserve the proximity in a graph\ninto a manifold in an embedding space. We argue an important but neglected\nproblem about this proximity-preserving strategy: Graph topology patterns,\nwhile preserved well into an embedding manifold by preserving proximity, may\ndistort in the ambient embedding Euclidean space, and hence to detect them\nbecomes difficult for machine learning models. To address the problem, we\npropose curvature regularization, to enforce flatness for embedding manifolds,\nthereby preventing the distortion. We present a novel angle-based sectional\ncurvature, termed ABS curvature, and accordingly three kinds of curvature\nregularization to induce flat embedding manifolds during graph embedding. We\nintegrate curvature regularization into five popular proximity-preserving\nembedding methods, and empirical results in two applications show significant\nimprovements on a wide range of open graph datasets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 20:16:24 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Pei", "Hongbin", ""], ["Wei", "Bingzhe", ""], ["Chang", "Kevin Chen-Chuan", ""], ["Zhang", "Chunxu", ""], ["Yang", "Bo", ""]]}, {"id": "2011.14238", "submitter": "Amy Zhang", "authors": "Amy X. Zhang, Le Bao, Michael J. Daniels", "title": "Approximate Cross-validated Mean Estimates for Bayesian Hierarchical\n  Regression Models", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel procedure for obtaining cross-validated predictive\nestimates for Bayesian hierarchical regression models (BHRMs). Bayesian\nhierarchical models are popular for their ability to model complex dependence\nstructures and provide probabilistic uncertainty estimates, but can be\ncomputationally expensive to run. Cross-validation (CV) is therefore not a\ncommon practice to evaluate the predictive performance of BHRMs. Our method\ncircumvents the need to re-run computationally costly estimation methods for\neach cross-validation fold and makes CV more feasible for large BHRMs. By\nconditioning on the variance-covariance parameters, we shift the CV problem\nfrom probability-based sampling to a simple and familiar optimization problem.\nIn many cases, this produces estimates which are equivalent to full CV. We\nprovide theoretical results and demonstrate its efficacy on publicly available\ndata and in simulations.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 00:00:20 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 20:45:30 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhang", "Amy X.", ""], ["Bao", "Le", ""], ["Daniels", "Michael J.", ""]]}, {"id": "2011.14267", "submitter": "Qiwen Cui", "authors": "Qiwen Cui and Lin F. Yang", "title": "Minimax Sample Complexity for Turn-based Stochastic Game", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The empirical success of Multi-agent reinforcement learning is encouraging,\nwhile few theoretical guarantees have been revealed. In this work, we prove\nthat the plug-in solver approach, probably the most natural reinforcement\nlearning algorithm, achieves minimax sample complexity for turn-based\nstochastic game (TBSG). Specifically, we plan in an empirical TBSG by utilizing\na `simulator' that allows sampling from arbitrary state-action pair. We show\nthat the empirical Nash equilibrium strategy is an approximate Nash equilibrium\nstrategy in the true TBSG and give both problem-dependent and\nproblem-independent bound. We develop absorbing TBSG and reward perturbation\ntechniques to tackle the complex statistical dependence. The key idea is\nartificially introducing a suboptimality gap in TBSG and then the Nash\nequilibrium strategy lies in a finite set.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 03:58:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cui", "Qiwen", ""], ["Yang", "Lin F.", ""]]}, {"id": "2011.14269", "submitter": "Hongkang Yang", "authors": "Hongkang Yang and Weinan E", "title": "Generalization and Memorization: The Bias Potential Model", "comments": "Added new section on regularized model", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models for learning probability distributions such as generative models and\ndensity estimators behave quite differently from models for learning functions.\nOne example is found in the memorization phenomenon, namely the ultimate\nconvergence to the empirical distribution, that occurs in generative\nadversarial networks (GANs). For this reason, the issue of generalization is\nmore subtle than that for supervised learning. For the bias potential model, we\nshow that dimension-independent generalization accuracy is achievable if early\nstopping is adopted, despite that in the long term, the model either memorizes\nthe samples or diverges.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 04:04:54 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 03:38:28 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 04:29:13 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 03:57:31 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Yang", "Hongkang", ""], ["E", "Weinan", ""]]}, {"id": "2011.14301", "submitter": "Haotian Xie", "authors": "Haotian Xie, Yong Zhang, Jun Wang, Jingjing Zhang, Yifan Ma, Zhaogang\n  Yang", "title": "Automated Prostate Cancer Diagnosis Based on Gleason Grading Using\n  Convolutional Neural Network", "comments": "This article has been removed by arXiv administrators because the\n  submitter did not have the authority to grant the license applied at the time\n  of submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gleason grading system using histological images is the most powerful\ndiagnostic and prognostic predictor of prostate cancer. The current standard\ninspection is evaluating Gleason H&E-stained histopathology images by\npathologists. However, it is complicated, time-consuming, and subject to\nobservers. Deep learning (DL) based-methods that automatically learn image\nfeatures and achieve higher generalization ability have attracted significant\nattention. However, challenges remain especially using DL to train the whole\nslide image (WSI), a predominant clinical source in the current diagnostic\nsetting, containing billions of pixels, morphological heterogeneity, and\nartifacts. Hence, we proposed a convolutional neural network (CNN)-based\nautomatic classification method for accurate grading of PCa using whole slide\nhistopathology images. In this paper, a data augmentation method named\nPatch-Based Image Reconstruction (PBIR) was proposed to reduce the high\nresolution and increase the diversity of WSIs. In addition, a distribution\ncorrection (DC) module was developed to enhance the adaption of pretrained\nmodel to the target dataset by adjusting the data distribution. Besides, a\nQuadratic Weighted Mean Square Error (QWMSE) function was presented to reduce\nthe misdiagnosis caused by equal Euclidean distances. Our experiments indicated\nthe combination of PBIR, DC, and QWMSE function was necessary for achieving\nsuperior expert-level performance, leading to the best results (0.8885\nquadratic-weighted kappa coefficient).\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 06:42:08 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Xie", "Haotian", ""], ["Zhang", "Yong", ""], ["Wang", "Jun", ""], ["Zhang", "Jingjing", ""], ["Ma", "Yifan", ""], ["Yang", "Zhaogang", ""]]}, {"id": "2011.14317", "submitter": "Arindam Bhattacharya", "authors": "Arindam Bhattacharya and Sumanth Varambally and Amitabha Bagchi and\n  Srikanta Bedathur", "title": "FROCC: Fast Random projection-based One-Class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Fast Random projection-based One-Class Classification (FROCC), an\nextremely efficient method for one-class classification. Our method is based on\na simple idea of transforming the training data by projecting it onto a set of\nrandom unit vectors that are chosen uniformly and independently from the unit\nsphere, and bounding the regions based on separation of the data. FROCC can be\nnaturally extended with kernels. We theoretically prove that FROCC generalizes\nwell in the sense that it is stable and has low bias. FROCC achieves up to 3.1\npercent points better ROC, with 1.2--67.8x speedup in training and test times\nover a range of state-of-the-art benchmarks including the SVM and the deep\nlearning based models for the OCC task.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 08:56:59 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 11:10:57 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 14:11:48 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bhattacharya", "Arindam", ""], ["Varambally", "Sumanth", ""], ["Bagchi", "Amitabha", ""], ["Bedathur", "Srikanta", ""]]}, {"id": "2011.14420", "submitter": "Weijun Luo", "authors": "Weijun Luo", "title": "Improving Neural Network with Uniform Sparse Connectivity", "comments": "paper accepted by IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3040943", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network forms the foundation of deep learning and numerous AI\napplications. Classical neural networks are fully connected, expensive to train\nand prone to overfitting. Sparse networks tend to have convoluted structure\nsearch, suboptimal performance and limited usage. We proposed the novel uniform\nsparse network (USN) with even and sparse connectivity within each layer. USN\nhas one striking property that its performance is independent of the\nsubstantial topology variation and enormous model space, thus offers a\nsearch-free solution to all above mentioned issues of neural networks. USN\nconsistently and substantially outperforms the state-of-the-art sparse network\nmodels in prediction accuracy, speed and robustness. It even achieves higher\nprediction accuracy than the fully connected network with only 0.55% parameters\nand 1/4 computing time and resources. Importantly, USN is conceptually simple\nas a natural generalization of fully connected network with multiple\nimprovements in accuracy, robustness and scalability. USN can replace the\nlatter in a range of applications, data types and deep learning architectures.\nWe have made USN open source at https://github.com/datapplab/sparsenet.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 19:00:05 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 19:45:09 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Luo", "Weijun", ""]]}, {"id": "2011.14439", "submitter": "Sam Greydanus", "authors": "Sam Greydanus", "title": "Scaling down Deep Learning", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Though deep learning models have taken on commercial and political relevance,\nmany aspects of their training and operation remain poorly understood. This has\nsparked interest in \"science of deep learning\" projects, many of which are run\nat scale and require enormous amounts of time, money, and electricity. But how\nmuch of this research really needs to occur at scale? In this paper, we\nintroduce MNIST-1D: a minimalist, low-memory, and low-compute alternative to\nclassic deep learning benchmarks. The training examples are 20 times smaller\nthan MNIST examples yet they differentiate more clearly between linear,\nnonlinear, and convolutional models which attain 32, 68, and 94% accuracy\nrespectively (these models obtain 94, 99+, and 99+% on MNIST). Then we present\nexample use cases which include measuring the spatial inductive biases of\nlottery tickets, observing deep double descent, and metalearning an activation\nfunction.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 20:08:37 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 22:09:02 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 20:09:44 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Greydanus", "Sam", ""]]}, {"id": "2011.14495", "submitter": "Marek Petrik", "authors": "Elita A. Lobo, Mohammad Ghavamzadeh, Marek Petrik", "title": "Soft-Robust Algorithms for Batch Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, robust policies for high-stakes decision-making\nproblems with limited data are usually computed by optimizing the percentile\ncriterion, which minimizes the probability of a catastrophic failure.\nUnfortunately, such policies are typically overly conservative as the\npercentile criterion is non-convex, difficult to optimize, and ignores the mean\nperformance. To overcome these shortcomings, we study the soft-robust\ncriterion, which uses risk measures to balance the mean and percentile\ncriterion better. In this paper, we establish the soft-robust criterion's\nfundamental properties, show that it is NP-hard to optimize, and propose and\nanalyze two algorithms to approximately optimize it. Our theoretical analyses\nand empirical evaluations demonstrate that our algorithms compute much less\nconservative solutions than the existing approximate methods for optimizing the\npercentile-criterion.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 01:36:16 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 17:46:32 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Lobo", "Elita A.", ""], ["Ghavamzadeh", "Mohammad", ""], ["Petrik", "Marek", ""]]}, {"id": "2011.14496", "submitter": "Yikai Wang", "authors": "Yikai Wang and Weijian Li", "title": "Blind signal decomposition of various word embeddings based on join and\n  individual variance explained", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, natural language processing (NLP) has become one of the most\nimportant areas with various applications in human's life. As the most\nfundamental task, the field of word embedding still requires more attention and\nresearch. Currently, existing works about word embedding are focusing on\nproposing novel embedding algorithms and dimension reduction techniques on\nwell-trained word embeddings. In this paper, we propose to use a novel joint\nsignal separation method - JIVE to jointly decompose various trained word\nembeddings into joint and individual components. Through this decomposition\nframework, we can easily investigate the similarity and difference among\ndifferent word embeddings. We conducted extensive empirical study on word2vec,\nFastText and GLoVE trained on different corpus and with different dimensions.\nWe compared the performance of different decomposed components based on\nsentiment analysis on Twitter and Stanford sentiment treebank. We found that by\nmapping different word embeddings into the joint component, sentiment\nperformance can be greatly improved for the original word embeddings with lower\nperformance. Moreover, we found that by concatenating different components\ntogether, the same model can achieve better performance. These findings provide\ngreat insights into the word embeddings and our work offer a new of generating\nword embeddings by fusing.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 01:36:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Yikai", ""], ["Li", "Weijian", ""]]}, {"id": "2011.14549", "submitter": "Amin Jalali", "authors": "Amin Jalali", "title": "Persistent Reductions in Regularized Loss Minimization for Variable\n  Selection", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of regularized loss minimization with polyhedral gauges, we\nshow that for a broad class of loss functions (possibly non-smooth and\nnon-convex) and under a simple geometric condition on the input data it is\npossible to efficiently identify a subset of features which are guaranteed to\nhave zero coefficients in all optimal solutions in all problems with loss\nfunctions from said class, before any iterative optimization has been performed\nfor the original problem. This procedure is standalone, takes only the data as\ninput, and does not require any calls to the loss function. Therefore, we term\nthis procedure as a persistent reduction for the aforementioned class of\nregularized loss minimization problems. This reduction can be efficiently\nimplemented via an extreme ray identification subroutine applied to a\npolyhedral cone formed from the datapoints. We employ an existing\noutput-sensitive algorithm for extreme ray identification which makes our\nguarantee and algorithm applicable in ultra-high dimensional problems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 04:59:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jalali", "Amin", ""]]}, {"id": "2011.14572", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Gradient Sparsification Can Improve Performance of\n  Differentially-Private Convex Machine Learning", "comments": "Fixed typos and a mistake in the proof of Proposition 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use gradient sparsification to reduce the adverse effect of differential\nprivacy noise on performance of private machine learning models. To this aim,\nwe employ compressed sensing and additive Laplace noise to evaluate\ndifferentially-private gradients. Noisy privacy-preserving gradients are used\nto perform stochastic gradient descent for training machine learning models.\nSparsification, achieved by setting the smallest gradient entries to zero, can\nreduce the convergence speed of the training algorithm. However, by\nsparsification and compressed sensing, the dimension of communicated gradient\nand the magnitude of additive noise can be reduced. The interplay between these\neffects determines whether gradient sparsification improves the performance of\ndifferentially-private machine learning models. We investigate this\nanalytically in the paper. We prove that, for small privacy budgets,\ncompression can improve performance of privacy-preserving machine learning\nmodels. However, for large privacy budgets, compression does not necessarily\nimprove the performance. Intuitively, this is because the effect of\nprivacy-preserving noise is minimal in large privacy budget regime and thus\nimprovements from gradient sparsification cannot compensate for its slower\nconvergence.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 06:37:06 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 23:54:09 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2011.14580", "submitter": "Thao Nguyen", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi, Thao Nguyen", "title": "Robust and Private Learning of Halfspaces", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the trade-off between differential privacy and\nadversarial robustness under L2-perturbations in the context of learning\nhalfspaces. We prove nearly tight bounds on the sample complexity of robust\nprivate learning of halfspaces for a large regime of parameters. A highlight of\nour results is that robust and private learning is harder than robust or\nprivate learning alone. We complement our theoretical analysis with\nexperimental results on the MNIST and USPS datasets, for a learning algorithm\nthat is both differentially private and adversarially robust.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 06:59:20 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 23:20:21 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""], ["Nguyen", "Thao", ""]]}, {"id": "2011.14620", "submitter": "Przemys{\\l}aw Spurek", "authors": "Maciej Zi\\k{e}ba, Marcin Przewi\\k{e}\\'zlikowski, Marek \\'Smieja, Jacek\n  Tabor, Tomasz Trzcinski, Przemys{\\l}aw Spurek", "title": "RegFlow: Probabilistic Flow-based Regression for Future Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting future states or actions of a given system remains a fundamental,\nyet unsolved challenge of intelligence, especially in the scope of complex and\nnon-deterministic scenarios, such as modeling behavior of humans. Existing\napproaches provide results under strong assumptions concerning unimodality of\nfuture states, or, at best, assuming specific probability distributions that\noften poorly fit to real-life conditions. In this work we introduce a robust\nand flexible probabilistic framework that allows to model future predictions\nwith virtually no constrains regarding the modality or underlying probability\ndistribution. To achieve this goal, we leverage a hypernetwork architecture and\ntrain a continuous normalizing flow model. The resulting method dubbed RegFlow\nachieves state-of-the-art results on several benchmark datasets, outperforming\ncompeting approaches by a significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 08:45:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zi\u0119ba", "Maciej", ""], ["Przewi\u0119\u017alikowski", "Marcin", ""], ["\u015amieja", "Marek", ""], ["Tabor", "Jacek", ""], ["Trzcinski", "Tomasz", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "2011.14654", "submitter": "Haiwen Huang", "authors": "Haiwen Huang, Zhihan Li, Lulu Wang, Sishuo Chen, Bin Dong, Xinyu Zhou", "title": "Feature Space Singularity for Out-of-Distribution Detection", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-Distribution (OoD) detection is important for building safe artificial\nintelligence systems. However, current OoD detection methods still cannot meet\nthe performance requirements for practical deployment. In this paper, we\npropose a simple yet effective algorithm based on a novel observation: in a\ntrained neural network, OoD samples with bounded norms well concentrate in the\nfeature space. We call the center of OoD features the Feature Space Singularity\n(FSS), and denote the distance of a sample feature to FSS as FSSD. Then, OoD\nsamples can be identified by taking a threshold on the FSSD. Our analysis of\nthe phenomenon reveals why our algorithm works. We demonstrate that our\nalgorithm achieves state-of-the-art performance on various OoD detection\nbenchmarks. Besides, FSSD also enjoys robustness to slight corruption in test\ndata and can be further enhanced by ensembling. These make FSSD a promising\nalgorithm to be employed in real world. We release our code at\n\\url{https://github.com/megvii-research/FSSD_OoD_Detection}.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 09:47:20 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 19:56:16 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Huang", "Haiwen", ""], ["Li", "Zhihan", ""], ["Wang", "Lulu", ""], ["Chen", "Sishuo", ""], ["Dong", "Bin", ""], ["Zhou", "Xinyu", ""]]}, {"id": "2011.14721", "submitter": "Veronica Alvarez", "authors": "Ver\\'onica \\'Alvarez, Santiago Mazuelas, and Jos\\'e A. Lozano", "title": "Probabilistic Load Forecasting Based on Adaptive Online Learning", "comments": "\\c{opyright} 2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": "10.1109/TPWRS.2021.3050837", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Load forecasting is crucial for multiple energy management tasks such as\nscheduling generation capacity, planning supply and demand, and minimizing\nenergy trade costs. Such relevance has increased even more in recent years due\nto the integration of renewable energies, electric cars, and microgrids.\nConventional load forecasting techniques obtain single-value load forecasts by\nexploiting consumption patterns of past load demand. However, such techniques\ncannot assess intrinsic uncertainties in load demand, and cannot capture\ndynamic changes in consumption patterns. To address these problems, this paper\npresents a method for probabilistic load forecasting based on the adaptive\nonline learning of hidden Markov models. We propose learning and forecasting\ntechniques with theoretical guarantees, and experimentally assess their\nperformance in multiple scenarios. In particular, we develop adaptive online\nlearning techniques that update model parameters recursively, and sequential\nprediction techniques that obtain probabilistic forecasts using the most recent\nparameters. The performance of the method is evaluated using multiple datasets\ncorresponding with regions that have different sizes and display assorted\ntime-varying consumption patterns. The results show that the proposed method\ncan significantly improve the performance of existing techniques for a wide\nrange of scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 12:02:26 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 15:40:39 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 09:57:28 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["\u00c1lvarez", "Ver\u00f3nica", ""], ["Mazuelas", "Santiago", ""], ["Lozano", "Jos\u00e9 A.", ""]]}, {"id": "2011.14799", "submitter": "Ramkumar Raghu", "authors": "Ramkumar Raghu, Mahadesh Panju, Vaneet Aggarwal and Vinod Sharma", "title": "Scheduling and Power Control for Wireless Multicast Systems via Deep\n  Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.05308", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multicasting in wireless systems is a natural way to exploit the redundancy\nin user requests in a Content Centric Network. Power control and optimal\nscheduling can significantly improve the wireless multicast network's\nperformance under fading. However, the model based approaches for power control\nand scheduling studied earlier are not scalable to large state space or\nchanging system dynamics. In this paper, we use deep reinforcement learning\nwhere we use function approximation of the Q-function via a deep neural network\nto obtain a power control policy that matches the optimal policy for a small\nnetwork. We show that power control policy can be learnt for reasonably large\nsystems via this approach. Further we use multi-timescale stochastic\noptimization to maintain the average power constraint. We demonstrate that a\nslight modification of the learning algorithm allows tracking of time varying\nsystem statistics. Finally, we extend the multi-timescale approach to\nsimultaneously learn the optimal queueing strategy along with power control. We\ndemonstrate scalability, tracking and cross layer optimization capabilities of\nour algorithms via simulations. The proposed multi-timescale approach can be\nused in general large state space dynamical systems with multiple objectives\nand constraints, and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:59:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Raghu", "Ramkumar", ""], ["Panju", "Mahadesh", ""], ["Aggarwal", "Vaneet", ""], ["Sharma", "Vinod", ""]]}, {"id": "2011.14821", "submitter": "James P. Crutchfield", "authors": "Nicolas Brodu and James P. Crutchfield", "title": "Discovering Causal Structure with Reproducing-Kernel Hilbert Space\n  $\\epsilon$-Machines", "comments": "20 pages, 9 figures, 57 citations;\n  csc.ucdavis.edu/~cmg/compmech/pubs/kem.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We merge computational mechanics' definition of causal states\n(predictively-equivalent histories) with reproducing-kernel Hilbert space\n(RKHS) representation inference. The result is a widely-applicable method that\ninfers causal structure directly from observations of a system's behaviors\nwhether they are over discrete or continuous events or time. A structural\nrepresentation -- a finite- or infinite-state kernel $\\epsilon$-machine -- is\nextracted by a reduced-dimension transform that gives an efficient\nrepresentation of causal states and their topology. In this way, the system\ndynamics are represented by a stochastic (ordinary or partial) differential\nequation that acts on causal states. We introduce an algorithm to estimate the\nassociated evolution operator. Paralleling the Fokker-Plank equation, it\nefficiently evolves causal-state distributions and makes predictions in the\noriginal data space via an RKHS functional mapping. We demonstrate these\ntechniques, together with their predictive abilities, on discrete-time,\ndiscrete-value infinite Markov-order processes generated by finite-state hidden\nMarkov models with (i) finite or (ii) uncountably-infinite causal states and\n(iii) a continuous-time, continuous-value process generated by a\nthermally-driven chaotic flow. The method robustly estimates causal structure\nin the presence of varying external and measurement noise levels.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 23:41:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Brodu", "Nicolas", ""], ["Crutchfield", "James P.", ""]]}, {"id": "2011.14878", "submitter": "Ian Covert", "authors": "Ian Covert, Scott Lundberg, Su-In Lee", "title": "Explaining by Removing: A Unified Framework for Model Explanation", "comments": "arXiv admin note: text overlap with arXiv:2011.03623", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have proposed a wide variety of model explanation approaches, but\nit remains unclear how most methods are related or when one method is\npreferable to another. We establish a new class of methods, removal-based\nexplanations, that are based on the principle of simulating feature removal to\nquantify each feature's influence. These methods vary in several respects, so\nwe develop a framework that characterizes each method along three dimensions:\n1) how the method removes features, 2) what model behavior the method explains,\nand 3) how the method summarizes each feature's influence. Our framework\nunifies 25 existing methods, including several of the most widely used\napproaches (SHAP, LIME, Meaningful Perturbations, permutation tests). This new\nclass of explanation methods has rich connections that we examine using tools\nthat have been largely overlooked by the explainability literature. To anchor\nremoval-based explanations in cognitive psychology, we show that feature\nremoval is a simple application of subtractive counterfactual reasoning. Ideas\nfrom cooperative game theory shed light on the relationships and trade-offs\namong different methods, and we derive conditions under which all removal-based\nexplanations have information-theoretic interpretations. Through this analysis,\nwe develop a unified framework that helps practitioners better understand model\nexplanation tools, and that offers a strong theoretical foundation upon which\nfuture explainability research can build.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 00:47:48 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Covert", "Ian", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "2011.14894", "submitter": "Juan E Arco", "authors": "Juan E. Arco, A. Ortiz, J.Ramirez, F.J. Martinez-Murcia, Yu-Dong\n  Zhang, Juan M. Gorriz", "title": "Uncertainty-driven ensembles of deep architectures for multiclass\n  classification. Application to COVID-19 diagnosis in chest X-ray images", "comments": "1 Table, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Respiratory diseases kill million of people each year. Diagnosis of these\npathologies is a manual, time-consuming process that has inter and\nintra-observer variability, delaying diagnosis and treatment. The recent\nCOVID-19 pandemic has demonstrated the need of developing systems to automatize\nthe diagnosis of pneumonia, whilst Convolutional Neural Network (CNNs) have\nproved to be an excellent option for the automatic classification of medical\nimages. However, given the need of providing a confidence classification in\nthis context it is crucial to quantify the reliability of the model's\npredictions. In this work, we propose a multi-level ensemble classification\nsystem based on a Bayesian Deep Learning approach in order to maximize\nperformance while quantifying the uncertainty of each classification decision.\nThis tool combines the information extracted from different architectures by\nweighting their results according to the uncertainty of their predictions.\nPerformance of the Bayesian network is evaluated in a real scenario where\nsimultaneously differentiating between four different pathologies: control vs\nbacterial pneumonia vs viral pneumonia vs COVID-19 pneumonia. A three-level\ndecision tree is employed to divide the 4-class classification into three\nbinary classifications, yielding an accuracy of 98.06% and overcoming the\nresults obtained by recent literature. The reduced preprocessing needed for\nobtaining this high performance, in addition to the information provided about\nthe reliability of the predictions evidence the applicability of the system to\nbe used as an aid for clinicians.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 14:06:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Arco", "Juan E.", ""], ["Ortiz", "A.", ""], ["Ramirez", "J.", ""], ["Martinez-Murcia", "F. J.", ""], ["Zhang", "Yu-Dong", ""], ["Gorriz", "Juan M.", ""]]}, {"id": "2011.14923", "submitter": "Joeri Hermans", "authors": "Joeri Hermans, Nilanjan Banik, Christoph Weniger, Gianfranco Bertone,\n  Gilles Louppe", "title": "Towards constraining warm dark matter with stellar streams through\n  neural simulation-based inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.GA astro-ph.CO astro-ph.IM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A statistical analysis of the observed perturbations in the density of\nstellar streams can in principle set stringent contraints on the mass function\nof dark matter subhaloes, which in turn can be used to constrain the mass of\nthe dark matter particle. However, the likelihood of a stellar density with\nrespect to the stream and subhaloes parameters involves solving an intractable\ninverse problem which rests on the integration of all possible forward\nrealisations implicitly defined by the simulation model. In order to infer the\nsubhalo abundance, previous analyses have relied on Approximate Bayesian\nComputation (ABC) together with domain-motivated but handcrafted summary\nstatistics. Here, we introduce a likelihood-free Bayesian inference pipeline\nbased on Amortised Approximate Likelihood Ratios (AALR), which automatically\nlearns a mapping between the data and the simulator parameters and obviates the\nneed to handcraft a possibly insufficient summary statistic. We apply the\nmethod to the simplified case where stellar streams are only perturbed by dark\nmatter subhaloes, thus neglecting baryonic substructures, and describe several\ndiagnostics that demonstrate the effectiveness of the new method and the\nstatistical quality of the learned estimator.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:53:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Hermans", "Joeri", ""], ["Banik", "Nilanjan", ""], ["Weniger", "Christoph", ""], ["Bertone", "Gianfranco", ""], ["Louppe", "Gilles", ""]]}, {"id": "2011.14965", "submitter": "Priyabrata Saha", "authors": "Priyabrata Saha and Saibal Mukhopadhyay", "title": "A Deep Learning Approach for Predicting Spatiotemporal Dynamics From\n  Sparsely Observed Data", "comments": "11 pages, 10 figures; Accepted manuscript IEEE Access", "journal-ref": "IEEE Access, vol. 9, pp. 64200-64210, 2021", "doi": "10.1109/ACCESS.2021.3075899", "report-no": null, "categories": "stat.ML cs.LG cs.NA math.AP math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the problem of learning prediction models for\nspatiotemporal physical processes driven by unknown partial differential\nequations (PDEs). We propose a deep learning framework that learns the\nunderlying dynamics and predicts its evolution using sparsely distributed data\nsites. Deep learning has shown promising results in modeling physical dynamics\nin recent years. However, most of the existing deep learning methods for\nmodeling physical dynamics either focus on solving known PDEs or require data\nin a dense grid when the governing PDEs are unknown. In contrast, our method\nfocuses on learning prediction models for unknown PDE-driven dynamics only from\nsparsely observed data. The proposed method is spatial dimension-independent\nand geometrically flexible. We demonstrate our method in the forecasting task\nfor the two-dimensional wave equation and the Burgers-Fisher equation in\nmultiple geometries with different boundary conditions, and the ten-dimensional\nheat equation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:38:00 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 17:27:58 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Saha", "Priyabrata", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2011.15001", "submitter": "Morgane Menz", "authors": "Morgane Menz, Sylvain Dubreuil, J\\'er\\^ome Morio, Christian Gogu,\n  Nathalie Bartoli and Marie Chiron", "title": "Variance based sensitivity analysis for Monte Carlo and importance\n  sampling reliability assessment with Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running a reliability analysis on engineering problems involving complex\nnumerical models can be computationally very expensive, requiring advanced\nsimulation methods to reduce the overall numerical cost. Gaussian process based\nactive learning methods for reliability analysis have emerged as a promising\nway for reducing this computational cost. The learning phase of these methods\nconsists in building a Gaussian process surrogate model of the performance\nfunction and using the uncertainty structure of the Gaussian process to enrich\niteratively this surrogate model. For that purpose a learning criterion has to\nbe defined. Then, the estimation of the probability of failure is typically\nobtained by a classification of a population evaluated on the final surrogate\nmodel. Hence, the estimator of the probability of failure holds two different\nuncertainty sources related to the surrogate model approximation and to the\nsampling based integration technique. In this paper, we propose a methodology\nto quantify the sensitivity of the probability of failure estimator to both\nuncertainty sources. This analysis also enables to control the whole error\nassociated to the failure probability estimate and thus provides an accuracy\ncriterion on the estimation. Thus, an active learning approach integrating this\nanalysis to reduce the main source of error and stopping when the global\nvariability is sufficiently low is introduced. The approach is proposed for\nboth a Monte Carlo based method as well as an importance sampling based method,\nseeking to improve the estimation of rare event probabilities. Performance of\nthe proposed strategy is then assessed on several examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:06:28 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Menz", "Morgane", ""], ["Dubreuil", "Sylvain", ""], ["Morio", "J\u00e9r\u00f4me", ""], ["Gogu", "Christian", ""], ["Bartoli", "Nathalie", ""], ["Chiron", "Marie", ""]]}, {"id": "2011.15007", "submitter": "Brady Neal", "authors": "Brady Neal, Chin-Wei Huang, Sunand Raghupathi", "title": "RealCause: Realistic Causal Inference Benchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many different causal effect estimators in causal inference.\nHowever, it is unclear how to choose between these estimators because there is\nno ground-truth for causal effects. A commonly used option is to simulate\nsynthetic data, where the ground-truth is known. However, the best causal\nestimators on synthetic data are unlikely to be the best causal estimators on\nreal data. An ideal benchmark for causal estimators would both (a) yield\nground-truth values of the causal effects and (b) be representative of real\ndata. Using flexible generative models, we provide a benchmark that both yields\nground-truth and is realistic. Using this benchmark, we evaluate over 1500\ndifferent causal estimators and provide evidence that it is rational to choose\nhyperparameters for causal estimators using predictive metrics.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:12:18 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 14:14:37 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Neal", "Brady", ""], ["Huang", "Chin-Wei", ""], ["Raghupathi", "Sunand", ""]]}, {"id": "2011.15045", "submitter": "Sreyas Mohan", "authors": "Dev Yashpal Sheth, Sreyas Mohan, Joshua L. Vincent, Ramon Manzorro,\n  Peter A. Crozier, Mitesh M. Khapra, Eero P. Simoncelli, Carlos\n  Fernandez-Granda", "title": "Unsupervised Deep Video Denoising", "comments": "Dev and Sreyas contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) currently achieve state-of-the-art\nperformance in denoising videos. They are typically trained with supervision,\nminimizing the error between the network output and ground-truth clean videos.\nHowever, in many applications, such as microscopy, noiseless videos are not\navailable. To address these cases, we build on recent advances in unsupervised\nstill image denoising to develop an Unsupervised Deep Video Denoiser (UDVD).\nUDVD is shown to perform competitively with current state-of-the-art supervised\nmethods on benchmark datasets, even when trained only on a single short noisy\nvideo sequence. Experiments on fluorescence-microscopy and electron-microscopy\ndata illustrate the promise of our approach for imaging modalities where\nground-truth clean data is generally not available. In addition, we study the\nmechanisms used by trained CNNs to perform video denoising. An analysis of the\ngradient of the network output with respect to its input reveals that these\nnetworks perform spatio-temporal filtering that is adapted to the particular\nspatial structures and motion of the underlying content. We interpret this as\nan implicit and highly effective form of motion compensation, a widely used\nparadigm in traditional video denoising, compression, and analysis. Code and\niPython notebooks for our analysis are available in\nhttps://sreyas-mohan.github.io/udvd/ .\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:45:08 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 04:25:50 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sheth", "Dev Yashpal", ""], ["Mohan", "Sreyas", ""], ["Vincent", "Joshua L.", ""], ["Manzorro", "Ramon", ""], ["Crozier", "Peter A.", ""], ["Khapra", "Mitesh M.", ""], ["Simoncelli", "Eero P.", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "2011.15056", "submitter": "Jakub Tomczak", "authors": "Jakub M. Tomczak", "title": "General Invertible Transformations for Flow-based Generative Modeling", "comments": "Code: https://github.com/jmtomczak/git_flow, accepted to INNF+ 2021\n  at ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new class of invertible transformations with an\napplication to flow-based generative models. We indicate that many well-known\ninvertible transformations in reversible logic and reversible neural networks\ncould be derived from our proposition. Next, we propose two new coupling layers\nthat are important building blocks of flow-based generative models. In the\nexperiments on digit data, we present how these new coupling layers could be\nused in Integer Discrete Flows (IDF), and that they achieve better results than\nstandard coupling layers used in IDF and RealNVP.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:54:43 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 13:04:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tomczak", "Jakub M.", ""]]}, {"id": "2011.15091", "submitter": "Anirudh Goyal", "authors": "Anirudh Goyal, Yoshua Bengio", "title": "Inductive Biases for Deep Learning of Higher-Level Cognition", "comments": "This document contains a review of authors research as part of the\n  requirement of AG's predoctoral exam, an overview of the main contributions\n  of the authors few recent papers (co-authored with several other co-authors)\n  as well as a vision of proposed future research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fascinating hypothesis is that human and animal intelligence could be\nexplained by a few principles (rather than an encyclopedic list of heuristics).\nIf that hypothesis was correct, we could more easily both understand our own\nintelligence and build intelligent machines. Just like in physics, the\nprinciples themselves would not be sufficient to predict the behavior of\ncomplex systems like brains, and substantial computation might be needed to\nsimulate human-like intelligence. This hypothesis would suggest that studying\nthe kind of inductive biases that humans and animals exploit could help both\nclarify these principles and provide inspiration for AI research and\nneuroscience theories. Deep learning already exploits several key inductive\nbiases, and this work considers a larger list, focusing on those which concern\nmostly higher-level and sequential conscious processing. The objective of\nclarifying these particular principles is that they could potentially help us\nbuild AI systems benefiting from humans' abilities in terms of flexible\nout-of-distribution and systematic generalization, which is currently an area\nwhere a large gap exists between state-of-the-art machine learning and human\nintelligence.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:29:25 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 17:51:00 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 21:54:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""]]}]