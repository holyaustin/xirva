[{"id": "1106.0134", "submitter": "Jean-Philippe Vert", "authors": "Fantine Mordelet (CBIO, CREST), Jean-Philippe Vert (CBIO)", "title": "ProDiGe: PRioritization Of Disease Genes with multitask machine learning\n  from positive and unlabeled examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elucidating the genetic basis of human diseases is a central goal of genetics\nand molecular biology. While traditional linkage analysis and modern\nhigh-throughput techniques often provide long lists of tens or hundreds of\ndisease gene candidates, the identification of disease genes among the\ncandidates remains time-consuming and expensive. Efficient computational\nmethods are therefore needed to prioritize genes within the list of candidates,\nby exploiting the wealth of information available about the genes in various\ndatabases. Here we propose ProDiGe, a novel algorithm for Prioritization of\nDisease Genes. ProDiGe implements a novel machine learning strategy based on\nlearning from positive and unlabeled examples, which allows to integrate\nvarious sources of information about the genes, to share information about\nknown disease genes across diseases, and to perform genome-wide searches for\nnew disease genes. Experiments on real data show that ProDiGe outperforms\nstate-of-the-art methods for the prioritization of genes in human diseases.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 09:56:49 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Mordelet", "Fantine", "", "CBIO, CREST"], ["Vert", "Jean-Philippe", "", "CBIO"]]}, {"id": "1106.0321", "submitter": "Anatoli Juditsky B.", "authors": "Elmar Diederichs, Anatoli Juditsky, Arkadi Nemirovski, and Vladimir\n  Spokoiny", "title": "Sparse Non Gaussian Component Analysis by Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse non-Gaussian component analysis (SNGCA) is an unsupervised method of\nextracting a linear structure from a high dimensional data based on estimating\na low-dimensional non-Gaussian data component. In this paper we discuss a new\napproach to direct estimation of the projector on the target space based on\nsemidefinite programming which improves the method sensitivity to a broad\nvariety of deviations from normality. We also discuss the procedures which\nallows to recover the structure when its effective dimension is unknown.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 21:04:00 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2011 21:26:58 GMT"}, {"version": "v3", "created": "Fri, 13 Jan 2012 23:32:26 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Diederichs", "Elmar", ""], ["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1106.0474", "submitter": "Takaki Makino", "authors": "Takaki Makino, Shunsuke Takei, Issei Sato, Daichi Mochihashi", "title": "Restricted Collapsed Draw: Accurate Sampling for Hierarchical Chinese\n  Restaurant Process Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a restricted collapsed draw (RCD) sampler, a general Markov chain\nMonte Carlo sampler of simultaneous draws from a hierarchical Chinese\nrestaurant process (HCRP) with restriction. Models that require simultaneous\ndraws from a hierarchical Dirichlet process with restriction, such as infinite\nHidden markov models (iHMM), were difficult to enjoy benefits of \\markerg{the}\nHCRP due to combinatorial explosion in calculating distributions of coupled\ndraws. By constructing a proposal of seating arrangements (partitioning) and\nstochastically accepts the proposal by the Metropolis-Hastings algorithm, the\nRCD sampler makes accurate sampling for complex combination of draws while\nretaining efficiency of HCRP representation. Based on the RCD sampler, we\ndeveloped a series of sophisticated sampling algorithms for iHMMs, including\nblocked Gibbs sampling, beam sampling, and split-merge sampling, that\noutperformed conventional iHMM samplers in experiments\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2011 17:08:36 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Makino", "Takaki", ""], ["Takei", "Shunsuke", ""], ["Sato", "Issei", ""], ["Mochihashi", "Daichi", ""]]}, {"id": "1106.0539", "submitter": "Tamara Broderick", "authors": "Tamara Broderick, Michael I. Jordan, Jim Pitman", "title": "Beta processes, stick-breaking, and power laws", "comments": "37 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The beta-Bernoulli process provides a Bayesian nonparametric prior for models\ninvolving collections of binary-valued features. A draw from the beta process\nyields an infinite collection of probabilities in the unit interval, and a draw\nfrom the Bernoulli process turns these into binary-valued features. Recent work\nhas provided stick-breaking representations for the beta process analogous to\nthe well-known stick-breaking representation for the Dirichlet process. We\nderive one such stick-breaking representation directly from the\ncharacterization of the beta process as a completely random measure. This\napproach motivates a three-parameter generalization of the beta process, and we\nstudy the power laws that can be obtained from this generalized beta process.\nWe present a posterior inference algorithm for the beta-Bernoulli process that\nexploits the stick-breaking representation, and we present experimental results\nfor a discrete factor-analysis model.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 00:08:20 GMT"}, {"version": "v2", "created": "Thu, 15 Sep 2011 04:28:06 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Broderick", "Tamara", ""], ["Jordan", "Michael I.", ""], ["Pitman", "Jim", ""]]}, {"id": "1106.0565", "submitter": "Tong Zhang", "authors": "Tong Zhang", "title": "Multi-stage Convex Relaxation for Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent work studied the effectiveness of feature selection using\nLasso. It is known that under the restricted isometry properties (RIP), Lasso\ndoes not generally lead to the exact recovery of the set of nonzero\ncoefficients, due to the looseness of convex relaxation. This paper considers\nthe feature selection property of nonconvex regularization, where the solution\nis given by a multi-stage convex relaxation scheme. Under appropriate\nconditions, we show that the local solution obtained by this procedure recovers\nthe set of nonzero coefficients without suffering from the bias of Lasso\nrelaxation, which complements parameter estimation results of this procedure.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 04:49:53 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2011 16:43:49 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Zhang", "Tong", ""]]}, {"id": "1106.0730", "submitter": "Daniel McDonald", "authors": "Daniel J. McDonald and Cosma Rohilla Shalizi", "title": "Rademacher complexity of stationary sequences", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to control the generalization error of time series models wherein\npast values of the outcome are used to predict future values. The results are\nbased on a generalization of standard i.i.d. concentration inequalities to\ndependent data without the mixing assumptions common in the time series\nsetting. Our proof and the result are simpler than previous analyses with\ndependent data or stochastic adversaries which use sequential Rademacher\ncomplexities rather than the expected Rademacher complexity for i.i.d.\nprocesses. We also derive empirical Rademacher results without mixing\nassumptions resulting in fully calculable upper bounds.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 19:09:31 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 22:40:23 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["McDonald", "Daniel J.", ""], ["Shalizi", "Cosma Rohilla", ""]]}, {"id": "1106.0762", "submitter": "Andrew Bolstad", "authors": "Andrew Bolstad and Barry Van Veen and Robert Nowak", "title": "Causal Network Inference via Group Sparse Regularization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2011.2129515", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of inferring sparse causal networks modeled\nby multivariate auto-regressive (MAR) processes. Conditions are derived under\nwhich the Group Lasso (gLasso) procedure consistently estimates sparse network\nstructure. The key condition involves a \"false connection score.\" In\nparticular, we show that consistent recovery is possible even when the number\nof observations of the network is far less than the number of parameters\ndescribing the network, provided that the false connection score is less than\none. The false connection score is also demonstrated to be a useful metric of\nrecovery in non-asymptotic regimes. The conditions suggest a modified gLasso\nprocedure which tends to improve the false connection score and reduce the\nchances of reversing the direction of causal influence. Computational\nexperiments and a real network based electrocorticogram (ECoG) simulation study\ndemonstrate the effectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 20:27:39 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Bolstad", "Andrew", ""], ["Van Veen", "Barry", ""], ["Nowak", "Robert", ""]]}, {"id": "1106.0800", "submitter": "Philipp Hennig PhD", "authors": "Philipp Hennig", "title": "Optimal Reinforcement Learning for Gaussian Systems", "comments": "final pre-conference version of this NIPS 2011 paper. Once again,\n  please note some nontrivial changes to exposition and interpretation of the\n  results, in particular in Equation (9) and Eqs. 11-14. The algorithm and\n  results have remained the same, but their theoretical interpretation has\n  changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration-exploitation trade-off is among the central challenges of\nreinforcement learning. The optimal Bayesian solution is intractable in\ngeneral. This paper studies to what extent analytic statements about optimal\nlearning are possible if all beliefs are Gaussian processes. A first order\napproximation of learning of both loss and dynamics, for nonlinear,\ntime-varying systems in continuous time and space, subject to a relatively weak\nrestriction on the dynamics, is described by an infinite-dimensional partial\ndifferential equation. An approximate finite-dimensional projection gives an\nimpression for how this result may be helpful.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2011 08:14:59 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 16:11:15 GMT"}, {"version": "v3", "created": "Fri, 14 Oct 2011 15:01:11 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Hennig", "Philipp", ""]]}, {"id": "1106.0967", "submitter": "Ping Li", "authors": "Ping Li, Anshumali Shrivastava, Joshua Moore, Arnd Christian Konig", "title": "Hashing Algorithms for Large-Scale Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first demonstrate that b-bit minwise hashing, whose\nestimators are positive definite kernels, can be naturally integrated with\nlearning algorithms such as SVM and logistic regression. We adopt a simple\nscheme to transform the nonlinear (resemblance) kernel into linear (inner\nproduct) kernel; and hence large-scale problems can be solved extremely\nefficiently. Our method provides a simple effective solution to large-scale\nlearning in massive and extremely high-dimensional datasets, especially when\ndata do not fit in memory.\n  We then compare b-bit minwise hashing with the Vowpal Wabbit (VW) algorithm\n(which is related the Count-Min (CM) sketch). Interestingly, VW has the same\nvariances as random projections. Our theoretical and empirical comparisons\nillustrate that usually $b$-bit minwise hashing is significantly more accurate\n(at the same storage) than VW (and random projections) in binary data.\nFurthermore, $b$-bit minwise hashing can be combined with VW to achieve further\nimprovements in terms of training speed, especially when $b$ is large.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 06:38:20 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Li", "Ping", ""], ["Shrivastava", "Anshumali", ""], ["Moore", "Joshua", ""], ["Konig", "Arnd Christian", ""]]}, {"id": "1106.1157", "submitter": "Shakir Mohamed", "authors": "Shakir Mohamed, Katherine Heller and Zoubin Ghahramani", "title": "Bayesian and L1 Approaches to Sparse Unsupervised Learning", "comments": "In Proceedings of the 29th International Conference on Machine\n  Learning (ICML), Edinburgh, Scotland, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of L1 regularisation for sparse learning has generated immense\nresearch interest, with successful application in such diverse areas as signal\nacquisition, image coding, genomics and collaborative filtering. While existing\nwork highlights the many advantages of L1 methods, in this paper we find that\nL1 regularisation often dramatically underperforms in terms of predictive\nperformance when compared with other methods for inferring sparsity. We focus\non unsupervised latent variable models, and develop L1 minimising factor\nmodels, Bayesian variants of \"L1\", and Bayesian models with a stronger L0-like\nsparsity induced through spike-and-slab distributions. These spike-and-slab\nBayesian factor models encourage sparsity while accounting for uncertainty in a\nprincipled manner and avoiding unnecessary shrinkage of non-zero values. We\ndemonstrate on a number of data sets that in practice spike-and-slab Bayesian\nmethods outperform L1 minimisation, even on a computational budget. We thus\nhighlight the need to re-assess the wide use of L1 methods in sparsity-reliant\napplications, particularly when we care about generalising to previously unseen\ndata, and provide an alternative that, over many varying conditions, provides\nimproved generalisation performance.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 19:24:44 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2011 00:37:47 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2012 04:15:40 GMT"}], "update_date": "2012-08-20", "authors_parsed": [["Mohamed", "Shakir", ""], ["Heller", "Katherine", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1106.1216", "submitter": "Ohad Shamir", "authors": "Shai Shalev-Shwartz and Ohad Shamir and Eran Tromer", "title": "Using More Data to Speed-up Training Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In many recent applications, data is plentiful. By now, we have a rather\nclear understanding of how more data can be used to improve the accuracy of\nlearning algorithms. Recently, there has been a growing interest in\nunderstanding how more data can be leveraged to reduce the required training\nruntime. In this paper, we study the runtime of learning as a function of the\nnumber of available training examples, and underscore the main high-level\ntechniques. We provide some initial positive results showing that the runtime\ncan decrease exponentially while only requiring a polynomial growth of the\nnumber of examples, and spell-out several interesting open problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 23:55:00 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2011 01:17:56 GMT"}], "update_date": "2011-06-16", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""], ["Tromer", "Eran", ""]]}, {"id": "1106.1622", "submitter": "Shai Shalev-Shwartz", "authors": "Shai Shalev-Shwartz and Alon Gonen and Ohad Shamir", "title": "Large-Scale Convex Minimization with a Low-Rank Constraint", "comments": "ICML 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of minimizing a convex function over the space of\nlarge matrices with low rank. While this optimization problem is hard in\ngeneral, we propose an efficient greedy algorithm and derive its formal\napproximation guarantees. Each iteration of the algorithm involves\n(approximately) finding the left and right singular vectors corresponding to\nthe largest singular value of a certain matrix, which can be calculated in\nlinear time. This leads to an algorithm which can scale to large matrices\narising in several applications such as matrix completion for collaborative\nfiltering and robust low rank matrix approximation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 19:07:09 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Gonen", "Alon", ""], ["Shamir", "Ohad", ""]]}, {"id": "1106.1636", "submitter": "Greg Ver Steeg", "authors": "Greg Ver Steeg and Aram Galstyan", "title": "A Sequence of Relaxations Constraining Hidden Variable Models", "comments": "UAI 2011 Best Paper Runner-Up; Proceedings of the 27th Conference on\n  Uncertainty in Artificial Intelligence (UAI 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI physics.soc-ph quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many widely studied graphical models with latent variables lead to nontrivial\nconstraints on the distribution of the observed variables. Inspired by the Bell\ninequalities in quantum mechanics, we refer to any linear inequality whose\nviolation rules out some latent variable model as a \"hidden variable test\" for\nthat model. Our main contribution is to introduce a sequence of relaxations\nwhich provides progressively tighter hidden variable tests. We demonstrate\napplicability to mixtures of sequences of i.i.d. variables, Bell inequalities,\nand homophily models in social networks. For the last, we demonstrate that our\nmethod provides a test that is able to rule out latent homophily as the sole\nexplanation for correlations on a real social network that are known to be due\nto influence.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 19:53:37 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2011 10:38:52 GMT"}], "update_date": "2011-07-21", "authors_parsed": [["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1106.1674", "submitter": "Art Owen", "authors": "David F. Gleich, Art B. Owen", "title": "Moment based estimation of stochastic Kronecker graph parameters", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Kronecker graphs supply a parsimonious model for large sparse real\nworld graphs. They can specify the distribution of a large random graph using\nonly three or four parameters. Those parameters have however proved difficult\nto choose in specific applications. This article looks at method of moments\nestimators that are computationally much simpler than maximum likelihood. The\nestimators are fast and in our examples, they typically yield Kronecker\nparameters with expected feature counts closer to a given graph than we get\nfrom KronFit. The improvement was especially prominent for the number of\ntriangles in the graph.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 21:26:42 GMT"}], "update_date": "2011-06-10", "authors_parsed": [["Gleich", "David F.", ""], ["Owen", "Art B.", ""]]}, {"id": "1106.1925", "submitter": "Ryan Adams", "authors": "Ryan Prescott Adams, Richard S. Zemel", "title": "Ranking via Sinkhorn Propagation", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of increasing importance to develop learning methods for ranking. In\ncontrast to many learning objectives, however, the ranking problem presents\ndifficulties due to the fact that the space of permutations is not smooth. In\nthis paper, we examine the class of rank-linear objective functions, which\nincludes popular metrics such as precision and discounted cumulative gain. In\nparticular, we observe that expectations of these gains are completely\ncharacterized by the marginals of the corresponding distribution over\npermutation matrices. Thus, the expectations of rank-linear objectives can\nalways be described through locations in the Birkhoff polytope, i.e.,\ndoubly-stochastic matrices (DSMs). We propose a technique for learning\nDSM-based ranking functions using an iterative projection operator known as\nSinkhorn normalization. Gradients of this operator can be computed via\nbackpropagation, resulting in an algorithm we call Sinkhorn propagation, or\nSinkProp. This approach can be combined with a wide range of gradient-based\napproaches to rank learning. We demonstrate the utility of SinkProp on several\ninformation retrieval data sets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 21:57:27 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2011 00:11:51 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Adams", "Ryan Prescott", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1106.2229", "submitter": "Fionn Murtagh", "authors": "Pedro Contreras and Fionn Murtagh", "title": "Fast, Linear Time Hierarchical Clustering using the Baire Metric", "comments": "27 pages, 6 tables, 10 figures", "journal-ref": "Journal of Classification, July 2012, Volume 29, Issue 2, pp\n  118-143", "doi": "10.1007/s00357-012-9106-3", "report-no": null, "categories": "stat.ML cs.IR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Baire metric induces an ultrametric on a dataset and is of linear\ncomputational complexity, contrasted with the standard quadratic time\nagglomerative hierarchical clustering algorithm. In this work we evaluate\nempirically this new approach to hierarchical clustering. We compare\nhierarchical clustering based on the Baire metric with (i) agglomerative\nhierarchical clustering, in terms of algorithm properties; (ii) generalized\nultrametrics, in terms of definition; and (iii) fast clustering through k-means\npartititioning, in terms of quality of results. For the latter, we carry out an\nin depth astronomical study. We apply the Baire distance to spectrometric and\nphotometric redshifts from the Sloan Digital Sky Survey using, in this work,\nabout half a million astronomical objects. We want to know how well the (more\ncostly to determine) spectrometric redshifts can predict the (more easily\nobtained) photometric redshifts, i.e. we seek to regress the spectrometric on\nthe photometric redshifts, and we use clusterwise regression for this.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2011 12:05:43 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Contreras", "Pedro", ""], ["Murtagh", "Fionn", ""]]}, {"id": "1106.2233", "submitter": "Xiaowen Dong", "authors": "Xiaowen Dong, Pascal Frossard, Pierre Vandergheynst and Nikolai\n  Nefedov", "title": "Clustering with Multi-Layer Graphs: A Spectral Perspective", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, vol. 60, no. 11, pp.\n  5820-5831, November 2012", "doi": "10.1109/TSP.2012.2212886", "report-no": null, "categories": "cs.LG cs.CV cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational data usually comes with a multimodal nature, which means that\nit can be naturally represented by a multi-layer graph whose layers share the\nsame set of vertices (users) with different edges (pairwise relationships). In\nthis paper, we address the problem of combining different layers of the\nmulti-layer graph for improved clustering of the vertices compared to using\nlayers independently. We propose two novel methods, which are based on joint\nmatrix factorization and graph regularization framework respectively, to\nefficiently combine the spectrum of the multiple graph layers, namely the\neigenvectors of the graph Laplacian matrices. In each case, the resulting\ncombination, which we call a \"joint spectrum\" of multiple graphs, is used for\nclustering the vertices. We evaluate our approaches by simulations with several\nreal world social network datasets. Results demonstrate the superior or\ncompetitive performance of the proposed methods over state-of-the-art technique\nand common baseline methods, such as co-regularization and summation of\ninformation from individual graphs.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2011 12:43:18 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Dong", "Xiaowen", ""], ["Frossard", "Pascal", ""], ["Vandergheynst", "Pierre", ""], ["Nefedov", "Nikolai", ""]]}, {"id": "1106.2363", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Sham M. Kakade, Tong Zhang", "title": "Random design analysis of ridge regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work gives a simultaneous analysis of both the ordinary least squares\nestimator and the ridge regression estimator in the random design setting under\nmild assumptions on the covariate/response distributions. In particular, the\nanalysis provides sharp results on the ``out-of-sample'' prediction error, as\nopposed to the ``in-sample'' (fixed design) error. The analysis also reveals\nthe effect of errors in the estimated covariance structure, as well as the\neffect of modeling errors, neither of which effects are present in the fixed\ndesign setting. The proofs of the main results are based on a simple\ndecomposition lemma combined with concentration inequalities for random vectors\nand matrices.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 01:08:48 GMT"}, {"version": "v2", "created": "Tue, 25 Mar 2014 02:16:11 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Hsu", "Daniel", ""], ["Kakade", "Sham M.", ""], ["Zhang", "Tong", ""]]}, {"id": "1106.2369", "submitter": "Daniel Hsu", "authors": "Miroslav Dudik, Daniel Hsu, Satyen Kale, Nikos Karampatziakis, John\n  Langford, Lev Reyzin, Tong Zhang", "title": "Efficient Optimal Learning for Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning in an online setting where the learner\nrepeatedly observes features, selects among a set of actions, and receives\nreward for the action taken. We provide the first efficient algorithm with an\noptimal regret. Our algorithm uses a cost sensitive classification learner as\nan oracle and has a running time $\\mathrm{polylog}(N)$, where $N$ is the number\nof classification rules among which the oracle might choose. This is\nexponentially faster than all previous algorithms that achieve optimal regret\nin this setting. Our formulation also enables us to create an algorithm with\nregret that is additive rather than multiplicative in feedback delay as in all\nprevious work.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 01:57:52 GMT"}], "update_date": "2011-06-17", "authors_parsed": [["Dudik", "Miroslav", ""], ["Hsu", "Daniel", ""], ["Kale", "Satyen", ""], ["Karampatziakis", "Nikos", ""], ["Langford", "John", ""], ["Reyzin", "Lev", ""], ["Zhang", "Tong", ""]]}, {"id": "1106.2429", "submitter": "Ohad Shamir", "authors": "Nicol\\`o Cesa-Bianchi and Ohad Shamir", "title": "Efficient Transductive Online Learning via Randomized Rounding", "comments": "To appear in a Festschrift in honor of V.N. Vapnik. Preliminary\n  version presented in NIPS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most traditional online learning algorithms are based on variants of mirror\ndescent or follow-the-leader. In this paper, we present an online algorithm\nbased on a completely different approach, tailored for transductive settings,\nwhich combines \"random playout\" and randomized rounding of loss subgradients.\nAs an application of our approach, we present the first computationally\nefficient online algorithm for collaborative filtering with trace-norm\nconstrained matrices. As a second application, we solve an open question\nlinking batch learning and transductive online learning\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 12:30:05 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 14:22:14 GMT"}, {"version": "v3", "created": "Thu, 24 Nov 2011 05:11:33 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2013 10:55:26 GMT"}], "update_date": "2013-09-12", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", ""], ["Shamir", "Ohad", ""]]}, {"id": "1106.2436", "submitter": "Ohad Shamir", "authors": "Shie Mannor and Ohad Shamir", "title": "From Bandits to Experts: On the Value of Side-Observations", "comments": "Presented at the NIPS 2011 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an adversarial online learning setting where a decision maker can\nchoose an action in every stage of the game. In addition to observing the\nreward of the chosen action, the decision maker gets side observations on the\nreward he would have obtained had he chosen some of the other actions. The\nobservation structure is encoded as a graph, where node i is linked to node j\nif sampling i provides information on the reward of j. This setting naturally\ninterpolates between the well-known \"experts\" setting, where the decision maker\ncan view all rewards, and the multi-armed bandits setting, where the decision\nmaker can only view the reward of the chosen action. We develop practical\nalgorithms with provable regret guarantees, which depend on non-trivial\ngraph-theoretic properties of the information feedback structure. We also\nprovide partially-matching lower bounds.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 13:11:33 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2011 22:33:57 GMT"}, {"version": "v3", "created": "Tue, 25 Oct 2011 15:55:47 GMT"}], "update_date": "2011-10-26", "authors_parsed": [["Mannor", "Shie", ""], ["Shamir", "Ohad", ""]]}, {"id": "1106.2474", "submitter": "Miguel Almeida", "authors": "Miguel Almeida and Jan-Hendrik Schleimer and Jos\\'e Bioucas-Dias and\n  Ricardo Vig\\'ario", "title": "Source Separation and Clustering of Phase-Locked Subspaces: Derivations\n  and Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to space limitations, our submission \"Source Separation and Clustering of\nPhase-Locked Subspaces\", accepted for publication on the IEEE Transactions on\nNeural Networks in 2011, presented some results without proof. Those proofs are\nprovided in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 15:34:38 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Almeida", "Miguel", ""], ["Schleimer", "Jan-Hendrik", ""], ["Bioucas-Dias", "Jos\u00e9", ""], ["Vig\u00e1rio", "Ricardo", ""]]}, {"id": "1106.2494", "submitter": "David Knowles", "authors": "David A. Knowles, Zoubin Ghahramani", "title": "Pitman-Yor Diffusion Trees", "comments": "8 pages, to be presented at UAI 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Pitman Yor Diffusion Tree (PYDT) for hierarchical\nclustering, a generalization of the Dirichlet Diffusion Tree (Neal, 2001) which\nremoves the restriction to binary branching structure. The generative process\nis described and shown to result in an exchangeable distribution over data\npoints. We prove some theoretical properties of the model and then present two\ninference methods: a collapsed MCMC sampler which allows us to model\nuncertainty over tree structures, and a computationally efficient greedy\nBayesian EM search algorithm. Both algorithms use message passing on the tree\nstructure. The utility of the model and algorithms is demonstrated on synthetic\nand real world data, both continuous and binary.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 17:23:50 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2011 11:06:04 GMT"}], "update_date": "2011-06-17", "authors_parsed": [["Knowles", "David A.", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1106.2697", "submitter": "Samuel Gershman", "authors": "Samuel J. Gershman and David M. Blei", "title": "A Tutorial on Bayesian Nonparametric Models", "comments": "28 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in statistical modeling is model selection, how to choose a\nmodel at an appropriate level of complexity. This problem appears in many\nsettings, most prominently in choosing the number ofclusters in mixture models\nor the number of factors in factor analysis. In this tutorial we describe\nBayesian nonparametric methods, a class of methods that side-steps this issue\nby allowing the data to determine the complexity of the model. This tutorial is\na high-level introduction to Bayesian nonparametric methods and contains\nseveral examples of their application.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 12:51:54 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2011 04:04:45 GMT"}], "update_date": "2011-08-05", "authors_parsed": [["Gershman", "Samuel J.", ""], ["Blei", "David M.", ""]]}, {"id": "1106.2774", "submitter": "Ambuj  Tewari", "authors": "Prateek Jain, Ambuj Tewari, Inderjit S. Dhillon", "title": "Orthogonal Matching Pursuit with Replacement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of compressed sensing where the goal\nis to recover almost all the sparse vectors using a small number of fixed\nlinear measurements. For this problem, we propose a novel partial\nhard-thresholding operator that leads to a general family of iterative\nalgorithms. While one extreme of the family yields well known hard thresholding\nalgorithms like ITI (Iterative Thresholding with Inversion) and HTP (Hard\nThresholding Pursuit), the other end of the spectrum leads to a novel algorithm\nthat we call Orthogonal Matching Pursuit with Replacement (OMPR). OMPR, like\nthe classic greedy algorithm OMP, adds exactly one coordinate to the support at\neach iteration, based on the correlation with the current residual. However,\nunlike OMP, OMPR also removes one coordinate from the support. This simple\nchange allows us to prove that OMPR has the best known guarantees for sparse\nrecovery in terms of the Restricted Isometry Property (a condition on the\nmeasurement matrix). In contrast, OMP is known to have very weak performance\nguarantees under RIP. Given its simple structure, we are able to extend OMPR\nusing locality sensitive hashing to get OMPR-Hash, the first provably\nsub-linear (in dimensionality) algorithm for sparse recovery. Our proof\ntechniques are novel and flexible enough to also permit the tightest known\nanalysis of popular iterative algorithms such as CoSaMP and Subspace Pursuit.\nWe provide experimental results on large problems providing recovery for\nvectors of size up to million dimensions. We demonstrate that for large-scale\nproblems our proposed methods are more robust and faster than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 18:13:40 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Jain", "Prateek", ""], ["Tewari", "Ambuj", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1106.2788", "submitter": "Yoon-Sik Cho", "authors": "Yoon-Sik Cho and Greg Ver Steeg and Aram Galstyan", "title": "Co-evolution of Selection and Influence in Social Networks", "comments": "In Proc. of the Twenty-Fifth Conference on Artificial Intelligence\n  (AAAI-11)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many networks are complex dynamical systems, where both attributes of nodes\nand topology of the network (link structure) can change with time. We propose a\nmodel of co-evolving networks where both node at- tributes and network\nstructure evolve under mutual influence. Specifically, we consider a mixed\nmembership stochastic blockmodel, where the probability of observing a link\nbetween two nodes depends on their current membership vectors, while those\nmembership vectors themselves evolve in the presence of a link between the\nnodes. Thus, the network is shaped by the interaction of stochastic processes\ndescribing the nodes, while the processes themselves are influenced by the\nchanging network structure. We derive an efficient variational inference\nprocedure for our model, and validate the model on both synthetic and\nreal-world data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 19:10:49 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Cho", "Yoon-Sik", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1106.3571", "submitter": "Nicolas Durrande", "authors": "Nicolas Durrande (CROCUS-ENSMSE, SoMaS), David Ginsbourger (IMSV),\n  Olivier Roustant (CROCUS-ENSMSE, - M\\'ethodes d'Analyse Stochastique des\n  Codes et Traitements Num\\'eriques), Laurent Carraro (LAMUSE)", "title": "ANOVA kernels and RKHS of zero mean functions for model-based\n  sensitivity analysis", "comments": null, "journal-ref": "Journal of Multivariate Analysis 115 (2013) 57-67", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a reproducing kernel Hilbert space H of real-valued functions and a\nsuitable measure mu over the source space D (subset of R), we decompose H as\nthe sum of a subspace of centered functions for mu and its orthogonal in H.\nThis decomposition leads to a special case of ANOVA kernels, for which the\nfunctional ANOVA representation of the best predictor can be elegantly derived,\neither in an interpolation or regularization framework. The proposed kernels\nappear to be particularly convenient for analyzing the e ffect of each (group\nof) variable(s) and computing sensitivity indices without recursivity.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 20:20:32 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2012 20:53:18 GMT"}], "update_date": "2012-12-10", "authors_parsed": [["Durrande", "Nicolas", "", "CROCUS-ENSMSE, SoMaS"], ["Ginsbourger", "David", "", "IMSV"], ["Roustant", "Olivier", "", "CROCUS-ENSMSE, - M\u00e9thodes d'Analyse Stochastique des\n  Codes et Traitements Num\u00e9riques"], ["Carraro", "Laurent", "", "LAMUSE"]]}, {"id": "1106.3651", "submitter": "Christos Dimitrakakis", "authors": "Christos Dimitrakakis", "title": "Robust Bayesian reinforcement learning through tight lower bounds", "comments": "Corrected version. 12 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Bayesian approach to sequential decision making, exact calculation of\nthe (subjective) utility is intractable. This extends to most special cases of\ninterest, such as reinforcement learning problems. While utility bounds are\nknown to exist for this problem, so far none of them were particularly tight.\nIn this paper, we show how to efficiently calculate a lower bound, which\ncorresponds to the utility of a near-optimal memoryless policy for the decision\nproblem, which is generally different from both the Bayes-optimal policy and\nthe policy which is optimal for the expected MDP under the current belief. We\nthen show how these can be applied to obtain robust exploration policies in a\nBayesian reinforcement learning setting.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 14:39:58 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2011 14:14:12 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Dimitrakakis", "Christos", ""]]}, {"id": "1106.3655", "submitter": "Christos Dimitrakakis", "authors": "Christos Dimitrakakis, Constantin Rothkopf", "title": "Bayesian multitask inverse reinforcement learning", "comments": "Corrected version. 13 pages, 8 figures", "journal-ref": "Recent Advances in Reinforcement Learning LNCS 7188, pp. 273-284,\n  2012", "doi": "10.1007/978-3-642-29946-9_27", "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalise the problem of inverse reinforcement learning to multiple\ntasks, from multiple demonstrations. Each one may represent one expert trying\nto solve a different task, or as different experts trying to solve the same\ntask. Our main contribution is to formalise the problem as statistical\npreference elicitation, via a number of structured priors, whose form captures\nour biases about the relatedness of different tasks or expert policies. In\ndoing so, we introduce a prior on policy optimality, which is more natural to\nspecify. We show that our framework allows us not only to learn to efficiently\nfrom multiple experts but to also effectively differentiate between the goals\nof each. Possible applications include analysing the intrinsic motivations of\nsubjects in behavioural experiments and learning from multiple teachers.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 15:00:45 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2011 15:16:11 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["Dimitrakakis", "Christos", ""], ["Rothkopf", "Constantin", ""]]}, {"id": "1106.3834", "submitter": "Suyong Choi", "authors": "Suyong Choi (Korea University)", "title": "Dimensionally Constrained Symbolic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe dimensionally constrained symbolic regression which has been\ndeveloped for mass measurement in certain classes of events in high-energy\nphysics (HEP). With symbolic regression, we can derive equations that are well\nknown in HEP. However, in problems with large number of variables, we find that\nby constraining the terms allowed in the symbolic regression, convergence\nbehavior is improved. Dimensionally constrained symbolic regression (DCSR)\nfinds solutions with much better fitness than is normally possible with\nsymbolic regression. In some cases, novel solutions are found.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2011 08:04:08 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Choi", "Suyong", "", "Korea University"]]}, {"id": "1106.3915", "submitter": "Song Song", "authors": "Song Song and Peter J. Bickel", "title": "Large Vector Auto Regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-fin.ST stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular approach for nonstructural economic and financial forecasting is\nto include a large number of economic and financial variables, which has been\nshown to lead to significant improvements for forecasting, for example, by the\ndynamic factor models. A challenging issue is to determine which variables and\n(their) lags are relevant, especially when there is a mixture of serial\ncorrelation (temporal dynamics), high dimensional (spatial) dependence\nstructure and moderate sample size (relative to dimensionality and lags). To\nthis end, an \\textit{integrated} solution that addresses these three challenges\nsimultaneously is appealing. We study the large vector auto regressions here\nwith three types of estimates. We treat each variable's own lags different from\nother variables' lags, distinguish various lags over time, and is able to\nselect the variables and lags simultaneously. We first show the consequences of\nusing Lasso type estimate directly for time series without considering the\ntemporal dependence. In contrast, our proposed method can still produce an\nestimate as efficient as an \\textit{oracle} under such scenarios. The tuning\nparameters are chosen via a data driven \"rolling scheme\" method to optimize the\nforecasting performance. A macroeconomic and financial forecasting problem is\nconsidered to illustrate its superiority over existing estimators.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2011 14:24:08 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Song", "Song", ""], ["Bickel", "Peter J.", ""]]}, {"id": "1106.3921", "submitter": "Song Song", "authors": "Song Song", "title": "Dynamic Large Spatial Covariance Matrix Estimation in Application to\n  Semiparametric Model Construction via Variable Clustering: the SCE approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-fin.RM q-fin.ST stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To better understand the spatial structure of large panels of economic and\nfinancial time series and provide a guideline for constructing semiparametric\nmodels, this paper first considers estimating a large spatial covariance matrix\nof the generalized $m$-dependent and $\\beta$-mixing time series (with $J$\nvariables and $T$ observations) by hard thresholding regularization as long as\n${{\\log J \\, \\cx^*(\\ct)}}/{T} = \\Co(1)$ (the former scheme with some time\ndependence measure $\\cx^*(\\ct)$) or $\\log J /{T} = \\Co(1)$ (the latter scheme\nwith some upper bounded mixing coefficient). We quantify the interplay between\nthe estimators' consistency rate and the time dependence level, discuss an\nintuitive resampling scheme for threshold selection, and also prove a general\ncross-validation result justifying this. Given a consistently estimated\ncovariance (correlation) matrix, by utilizing its natural links with graphical\nmodels and semiparametrics, after \"screening\" the (explanatory) variables, we\nimplement a novel forward (and backward) label permutation procedure to cluster\nthe \"relevant\" variables and construct the corresponding semiparametric model,\nwhich is further estimated by the groupwise dimension reduction method with\nsign constraints. We call this the SCE (screen - cluster - estimate) approach\nfor modeling high dimensional data with complex spatial structure. Finally we\napply this method to study the spatial structure of large panels of economic\nand financial time series and find the proper semiparametric structure for\nestimating the consumer price index (CPI) to illustrate its superiority over\nthe linear models.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2011 14:35:52 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2011 06:08:31 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Song", "Song", ""]]}, {"id": "1106.4198", "submitter": "Augustin Lefevre", "authors": "Augustin Lef\\`evre (INRIA Paris - Rocquencourt), Francis Bach (LIENS),\n  C\\'edric F\\'evotte (LTCI)", "title": "Online algorithms for Nonnegative Matrix Factorization with the\n  Itakura-Saito divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is now a common tool for audio source\nseparation. When learning NMF on large audio databases, one major drawback is\nthat the complexity in time is O(FKN) when updating the dictionary (where (F;N)\nis the dimension of the input power spectrograms, and K the number of basis\nspectra), thus forbidding its application on signals longer than an hour. We\nprovide an online algorithm with a complexity of O(FK) in time and memory for\nupdates in the dictionary. We show on audio simulations that the online\napproach is faster for short audio signals and allows to analyze audio signals\nof several hours.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 13:34:06 GMT"}], "update_date": "2011-06-22", "authors_parsed": [["Lef\u00e8vre", "Augustin", "", "INRIA Paris - Rocquencourt"], ["Bach", "Francis", "", "LIENS"], ["F\u00e9votte", "C\u00e9dric", "", "LTCI"]]}, {"id": "1106.4199", "submitter": "Jean-Philippe Vert", "authors": "Kevin Bleakley (INRIA Saclay - Ile de France), Jean-Philippe Vert\n  (CBIO)", "title": "The group fused Lasso for multiple change-point detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the group fused Lasso for detection of multiple change-points\nshared by a set of co-occurring one-dimensional signals. Change-points are\ndetected by approximating the original signals with a constraint on the\nmultidimensional total variation, leading to piecewise-constant approximations.\nFast algorithms are proposed to solve the resulting optimization problems,\neither exactly or approximately. Conditions are given for consistency of both\nalgorithms as the number of signals increases, and empirical evidence is\nprovided to support the results on simulated and array comparative genomic\nhybridization data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 13:34:43 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Bleakley", "Kevin", "", "INRIA Saclay - Ile de France"], ["Vert", "Jean-Philippe", "", "CBIO"]]}, {"id": "1106.4251", "submitter": "Rina Foygel", "authors": "Rina Foygel, Ruslan Salakhutdinov, Ohad Shamir, and Nathan Srebro", "title": "Learning with the Weighted Trace-norm under Arbitrary Sampling\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide rigorous guarantees on learning with the weighted trace-norm under\narbitrary sampling distributions. We show that the standard weighted trace-norm\nmight fail when the sampling distribution is not a product distribution (i.e.\nwhen row and column indexes are not selected independently), present a\ncorrected variant for which we establish strong learning guarantees, and\ndemonstrate that it works better in practice. We provide guarantees when\nweighting by either the true or empirical sampling distribution, and suggest\nthat even if the true distribution is known (or is uniform), weighting by the\nempirical distribution may be beneficial.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 16:16:24 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Foygel", "Rina", ""], ["Salakhutdinov", "Ruslan", ""], ["Shamir", "Ohad", ""], ["Srebro", "Nathan", ""]]}, {"id": "1106.4333", "submitter": "Alfredo A. Kalaitzis Mr", "authors": "Alfredo A. Kalaitzis and Neil D. Lawrence", "title": "Residual Component Analysis", "comments": "9 pages, 8 figures, submitted to NIPS2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic principal component analysis (PPCA) seeks a low dimensional\nrepresentation of a data set in the presence of independent spherical Gaussian\nnoise, Sigma = (sigma^2)*I. The maximum likelihood solution for the model is an\neigenvalue problem on the sample covariance matrix. In this paper we consider\nthe situation where the data variance is already partially explained by other\nfactors, e.g. covariates of interest, or temporal correlations leaving some\nresidual variance. We decompose the residual variance into its components\nthrough a generalized eigenvalue problem, which we call residual component\nanalysis (RCA). We show that canonical covariates analysis (CCA) is a special\ncase of our algorithm and explore a range of new algorithms that arise from the\nframework. We illustrate the ideas on a gene expression time series data set\nand the recovery of human pose from silhouette.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 21:17:51 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Kalaitzis", "Alfredo A.", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1106.4355", "submitter": "Nikhil Rao", "authors": "Nikhil Rao, Benjamin Recht and Robert Nowak", "title": "Tight Measurement Bounds for Exact Recovery of Structured Sparse Signals", "comments": "Refined previous bound and added new experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard compressive sensing results state that to exactly recover an s\nsparse signal in R^p, one requires O(s. log(p)) measurements. While this bound\nis extremely useful in practice, often real world signals are not only sparse,\nbut also exhibit structure in the sparsity pattern. We focus on\ngroup-structured patterns in this paper. Under this model, groups of signal\ncoefficients are active (or inactive) together. The groups are predefined, but\nthe particular set of groups that are active (i.e., in the signal support) must\nbe learned from measurements. We show that exploiting knowledge of groups can\nfurther reduce the number of measurements required for exact signal recovery,\nand derive universal bounds for the number of measurements needed. The bound is\nuniversal in the sense that it only depends on the number of groups under\nconsideration, and not the particulars of the groups (e.g., compositions,\nsizes, extents, overlaps, etc.). Experiments show that our result holds for a\nvariety of overlapping group configurations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 00:45:59 GMT"}, {"version": "v2", "created": "Wed, 27 Jul 2011 02:25:06 GMT"}, {"version": "v3", "created": "Tue, 18 Oct 2011 02:16:55 GMT"}], "update_date": "2011-10-19", "authors_parsed": [["Rao", "Nikhil", ""], ["Recht", "Benjamin", ""], ["Nowak", "Robert", ""]]}, {"id": "1106.4431", "submitter": "Pasi Jyl\\\"anki M. Sc.", "authors": "Pasi Jyl\\\"anki, Jarno Vanhatalo and Aki Vehtari", "title": "Gaussian Process Regression with a Student-t Likelihood", "comments": null, "journal-ref": "Journal of Machine Learning Research 12 (2011) 3227-3257", "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the robust and efficient implementation of Gaussian\nprocess regression with a Student-t observation model. The challenge with the\nStudent-t model is the analytically intractable inference which is why several\napproximative methods have been proposed. The expectation propagation (EP) has\nbeen found to be a very accurate method in many empirical studies but the\nconvergence of the EP is known to be problematic with models containing\nnon-log-concave site functions such as the Student-t distribution. In this\npaper we illustrate the situations where the standard EP fails to converge and\nreview different modifications and alternative algorithms for improving the\nconvergence. We demonstrate that convergence problems may occur during the\ntype-II maximum a posteriori (MAP) estimation of the hyperparameters and show\nthat the standard EP may not converge in the MAP values in some difficult\ncases. We present a robust implementation which relies primarily on parallel EP\nupdates and utilizes a moment-matching-based double-loop algorithm with\nadaptively selected step size in difficult cases. The predictive performance of\nthe EP is compared to the Laplace, variational Bayes, and Markov chain Monte\nCarlo approximations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 12:24:03 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Jyl\u00e4nki", "Pasi", ""], ["Vanhatalo", "Jarno", ""], ["Vehtari", "Aki", ""]]}, {"id": "1106.4487", "submitter": "Tom Schaul", "authors": "Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun and J\\\"urgen\n  Schmidhuber", "title": "Natural Evolution Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Natural Evolution Strategies (NES), a recent family of\nalgorithms that constitute a more principled approach to black-box optimization\nthan established evolutionary algorithms. NES maintains a parameterized\ndistribution on the set of solution candidates, and the natural gradient is\nused to update the distribution's parameters in the direction of higher\nexpected fitness. We introduce a collection of techniques that address issues\nof convergence, robustness, sample complexity, computational complexity and\nsensitivity to hyperparameters. This paper explores a number of implementations\nof the NES family, ranging from general-purpose multi-variate normal\ndistributions to heavy-tailed and separable distributions tailored towards\nglobal optimization and search in high dimensional spaces, respectively.\nExperimental results show best published performance on various standard\nbenchmarks, as well as competitive performance on others.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 15:55:52 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Wierstra", "Daan", ""], ["Schaul", "Tom", ""], ["Glasmachers", "Tobias", ""], ["Sun", "Yi", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1106.4509", "submitter": "Amos Storkey", "authors": "Amos Storkey", "title": "Machine Learning Markets", "comments": "Proceedings of the Fourteenth International Conference on Artificial\n  Intelligence and Statistics 2011", "journal-ref": "Journal of Machine Learning Research W&CP 15(AISTATS):716-724,\n  2011", "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NE q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction markets show considerable promise for developing flexible\nmechanisms for machine learning. Here, machine learning markets for\nmultivariate systems are defined, and a utility-based framework is established\nfor their analysis. This differs from the usual approach of defining static\nbetting functions. It is shown that such markets can implement model\ncombination methods used in machine learning, such as product of expert and\nmixture of expert approaches as equilibrium pricing models, by varying agent\nutility functions. They can also implement models composed of local potentials,\nand message passing methods. Prediction markets also allow for more flexible\ncombinations, by combining multiple different utility functions. Conversely,\nthe market mechanisms implement inference in the relevant probabilistic models.\nThis means that market mechanism can be utilized for implementing parallelized\nmodel building and inference for probabilistic modelling.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 17:12:42 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Storkey", "Amos", ""]]}, {"id": "1106.4729", "submitter": "Makoto Yamada", "authors": "Makoto Yamada, Taiji Suzuki, Takafumi Kanamori, Hirotaka Hachiya,\n  Masashi Sugiyama", "title": "Relative Density-Ratio Estimation for Robust Distribution Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divergence estimators based on direct approximation of density-ratios without\ngoing through separate approximation of numerator and denominator densities\nhave been successfully applied to machine learning tasks that involve\ndistribution comparison such as outlier detection, transfer learning, and\ntwo-sample homogeneity test. However, since density-ratio functions often\npossess high fluctuation, divergence estimation is still a challenging task in\npractice. In this paper, we propose to use relative divergences for\ndistribution comparison, which involves approximation of relative\ndensity-ratios. Since relative density-ratios are always smoother than\ncorresponding ordinary density-ratios, our proposed method is favorable in\nterms of the non-parametric convergence speed. Furthermore, we show that the\nproposed divergence estimator has asymptotic variance independent of the model\ncomplexity under a parametric setup, implying that the proposed estimator\nhardly overfits even with complex models. Through experiments, we demonstrate\nthe usefulness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2011 14:05:34 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Yamada", "Makoto", ""], ["Suzuki", "Taiji", ""], ["Kanamori", "Takafumi", ""], ["Hachiya", "Hirotaka", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1106.5175", "submitter": "Suvrit Sra", "authors": "Suvrit Sra and Dongmin Kim", "title": "Sparse Inverse Covariance Estimation via an Adaptive Gradient-Based\n  Method", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating from data, a sparse approximation to the\ninverse covariance matrix. Estimating a sparsity constrained inverse covariance\nmatrix is a key component in Gaussian graphical model learning, but one that is\nnumerically very challenging. We address this challenge by developing a new\nadaptive gradient-based method that carefully combines gradient information\nwith an adaptive step-scaling strategy, which results in a scalable, highly\ncompetitive method. Our algorithm, like its predecessors, maximizes an\n$\\ell_1$-norm penalized log-likelihood and has the same per iteration\narithmetic complexity as the best methods in its class. Our experiments reveal\nthat our approach outperforms state-of-the-art competitors, often significantly\nso, for large problems.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2011 21:38:55 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Sra", "Suvrit", ""], ["Kim", "Dongmin", ""]]}, {"id": "1106.5236", "submitter": "Andreas Argyriou", "authors": "Andreas Argyriou and Luca Baldassarre and Jean Morales and\n  Massimiliano Pontil", "title": "A General Framework for Structured Sparsity via Proximal Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalized framework for structured sparsity. It extends the\nwell-known methods of Lasso and Group Lasso by incorporating additional\nconstraints on the variables as part of a convex optimization problem. This\nframework provides a straightforward way of favouring prescribed sparsity\npatterns, such as orderings, contiguous regions and overlapping groups, among\nothers. Existing optimization methods are limited to specific constraint sets\nand tend to not scale well with sample size and dimensionality. We propose a\nnovel first order proximal method, which builds upon results on fixed points\nand successive approximations. The algorithm can be applied to a general class\nof conic and norm constraints sets and relies on a proximity operator\nsubproblem which can be computed explicitly. Experiments on different\nregression problems demonstrate the efficiency of the optimization algorithm\nand its scalability with the size of the problem. They also demonstrate state\nof the art statistical performance, which improves over Lasso and StructOMP.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2011 17:03:44 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Argyriou", "Andreas", ""], ["Baldassarre", "Luca", ""], ["Morales", "Jean", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1106.5826", "submitter": "Ali Jalali", "authors": "Ali Jalali and Pradeep Ravikumar and Sujay Sanghavi", "title": "A Dirty Model for Multiple Sparse Regression", "comments": "The primary result is accepted to NIPS 2010 for Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear regression -- finding an unknown vector from linear\nmeasurements -- is now known to be possible with fewer samples than variables,\nvia methods like the LASSO. We consider the multiple sparse linear regression\nproblem, where several related vectors -- with partially shared support sets --\nhave to be recovered. A natural question in this setting is whether one can use\nthe sharing to further decrease the overall number of samples required. A line\nof recent research has studied the use of \\ell_1/\\ell_q norm\nblock-regularizations with q>1 for such problems; however these could actually\nperform worse in sample complexity -- vis a vis solving each problem separately\nignoring sharing -- depending on the level of sharing.\n  We present a new method for multiple sparse linear regression that can\nleverage support and parameter overlap when it exists, but not pay a penalty\nwhen it does not. A very simple idea: we decompose the parameters into two\ncomponents and regularize these differently. We show both theoretically and\nempirically, our method strictly and noticeably outperforms both \\ell_1 or\n\\ell_1/\\ell_q methods, over the entire range of possible overlaps (except at\nboundary cases, where we match the best method). We also provide theoretical\nguarantees that the method performs well under high-dimensional scaling.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 00:53:15 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Jalali", "Ali", ""], ["Ravikumar", "Pradeep", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1106.6002", "submitter": "Ulrike Schneider", "authors": "Benedikt M. P\\\"otscher, Ulrike Schneider", "title": "Distributional Results for Thresholding Estimators in High-Dimensional\n  Gaussian Regression Models", "comments": "minor corrections", "journal-ref": "Electron. J. Statist. 5 (2011), 1876-1934", "doi": "10.1214/11-EJS659", "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the distribution of hard-, soft-, and adaptive soft-thresholding\nestimators within a linear regression model where the number of parameters k\ncan depend on sample size n and may diverge with n. In addition to the case of\nknown error-variance, we define and study versions of the estimators when the\nerror-variance is unknown. We derive the finite-sample distribution of each\nestimator and study its behavior in the large-sample limit, also investigating\nthe effects of having to estimate the variance when the degrees of freedom n-k\ndoes not tend to infinity or tends to infinity very slowly. Our analysis\nencompasses both the case where the estimators are tuned to perform consistent\nmodel selection and the case where the estimators are tuned to perform\nconservative model selection. Furthermore, we discuss consistency, uniform\nconsistency and derive the uniform convergence rate under either type of\ntuning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 17:06:24 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2011 14:57:35 GMT"}, {"version": "v3", "created": "Fri, 16 Dec 2011 18:46:33 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["P\u00f6tscher", "Benedikt M.", ""], ["Schneider", "Ulrike", ""]]}, {"id": "1106.6024", "submitter": "Indraneel Mukherjee", "authors": "Indraneel Mukherjee and Cynthia Rudin and Robert E. Schapire", "title": "The Rate of Convergence of AdaBoost", "comments": "A preliminary version will appear in COLT 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AdaBoost algorithm was designed to combine many \"weak\" hypotheses that\nperform slightly better than random guessing into a \"strong\" hypothesis that\nhas very low error. We study the rate at which AdaBoost iteratively converges\nto the minimum of the \"exponential loss.\" Unlike previous work, our proofs do\nnot require a weak-learning assumption, nor do they require that minimizers of\nthe exponential loss are finite. Our first result shows that at iteration $t$,\nthe exponential loss of AdaBoost's computed parameter vector will be at most\n$\\epsilon$ more than that of any parameter vector of $\\ell_1$-norm bounded by\n$B$ in a number of rounds that is at most a polynomial in $B$ and $1/\\epsilon$.\nWe also provide lower bounds showing that a polynomial dependence on these\nparameters is necessary. Our second result is that within $C/\\epsilon$\niterations, AdaBoost achieves a value of the exponential loss that is at most\n$\\epsilon$ more than the best possible value, where $C$ depends on the dataset.\nWe show that this dependence of the rate on $\\epsilon$ is optimal up to\nconstant factors, i.e., at least $\\Omega(1/\\epsilon)$ rounds are necessary to\nachieve within $\\epsilon$ of the optimal exponential loss.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 18:53:46 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Mukherjee", "Indraneel", ""], ["Rudin", "Cynthia", ""], ["Schapire", "Robert E.", ""]]}, {"id": "1106.6251", "submitter": "Lorenzo Rosasco", "authors": "Mauricio A. Alvarez, Lorenzo Rosasco, Neil D. Lawrence", "title": "Kernels for Vector-Valued Functions: a Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods are among the most popular techniques in machine learning.\nFrom a frequentist/discriminative perspective they play a central role in\nregularization theory as they provide a natural choice for the hypotheses space\nand the regularization functional through the notion of reproducing kernel\nHilbert spaces. From a Bayesian/generative perspective they are the key in the\ncontext of Gaussian processes, where the kernel function is also known as the\ncovariance function. Traditionally, kernel methods have been used in supervised\nlearning problem with scalar outputs and indeed there has been a considerable\namount of work devoted to designing and learning kernels. More recently there\nhas been an increasing interest in methods that deal with multiple outputs,\nmotivated partly by frameworks like multitask learning. In this paper, we\nreview different methods to design or learn valid kernel functions for multiple\noutputs, paying particular attention to the connection between probabilistic\nand functional methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 14:48:54 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2012 17:40:40 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Alvarez", "Mauricio A.", ""], ["Rosasco", "Lorenzo", ""], ["Lawrence", "Neil D.", ""]]}]