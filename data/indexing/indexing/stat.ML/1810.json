[{"id": "1810.00004", "submitter": "Sho Yaida", "authors": "Sho Yaida", "title": "Fluctuation-dissipation relations for stochastic gradient descent", "comments": "15 pages, 6 figures; v2: final version accepted at ICLR 2019, with\n  derivations/assumptions clarified and Adam/AMSGrad experiments added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of the stationary equilibrium ensemble has played a central role\nin statistical mechanics. In machine learning as well, training serves as\ngeneralized equilibration that drives the probability distribution of model\nparameters toward stationarity. Here, we derive stationary\nfluctuation-dissipation relations that link measurable quantities and\nhyperparameters in the stochastic gradient descent algorithm. These relations\nhold exactly for any stationary state and can in particular be used to\nadaptively set training schedule. We can further use the relations to\nefficiently extract information pertaining to a loss-function landscape such as\nthe magnitudes of its Hessian and anharmonicity. Our claims are empirically\nverified.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 16:09:27 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Yaida", "Sho", ""]]}, {"id": "1810.00024", "submitter": "Washington Garcia", "authors": "Washington Garcia, Joseph I. Choi, Suman K. Adari, Somesh Jha, Kevin\n  R. B. Butler", "title": "Explainable Black-Box Attacks Against Model-based Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing unique identities for both humans and end systems has been an\nactive research problem in the security community, giving rise to innovative\nmachine learning-based authentication techniques. Although such techniques\noffer an automated method to establish identity, they have not been vetted\nagainst sophisticated attacks that target their core machine learning\ntechnique. This paper demonstrates that mimicking the unique signatures\ngenerated by host fingerprinting and biometric authentication systems is\npossible. We expose the ineffectiveness of underlying machine learning\nclassification models by constructing a blind attack based around the query\nsynthesis framework and utilizing Explainable-AI (XAI) techniques. We launch an\nattack in under 130 queries on a state-of-the-art face authentication system,\nand under 100 queries on a host authentication system. We examine how these\nattacks can be defended against and explore their limitations. XAI provides an\neffective means for adversaries to infer decision boundaries and provides a new\nway forward in constructing attacks against systems using machine learning\nmodels for authentication.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:13:26 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Garcia", "Washington", ""], ["Choi", "Joseph I.", ""], ["Adari", "Suman K.", ""], ["Jha", "Somesh", ""], ["Butler", "Kevin R. B.", ""]]}, {"id": "1810.00045", "submitter": "Ali Farshchian", "authors": "Ali Farshchian, Juan A. Gallego, Joseph P. Cohen, Yoshua Bengio, Lee\n  E. Miller, Sara A. Solla", "title": "Adversarial Domain Adaptation for Stable Brain-Machine Interfaces", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Machine Interfaces (BMIs) have recently emerged as a clinically viable\noption to restore voluntary movements after paralysis. These devices are based\non the ability to extract information about movement intent from neural signals\nrecorded using multi-electrode arrays chronically implanted in the motor\ncortices of the brain. However, the inherent loss and turnover of recorded\nneurons requires repeated recalibrations of the interface, which can\npotentially alter the day-to-day user experience. The resulting need for\ncontinued user adaptation interferes with the natural, subconscious use of the\nBMI. Here, we introduce a new computational approach that decodes movement\nintent from a low-dimensional latent representation of the neural data. We\nimplement various domain adaptation methods to stabilize the interface over\nsignificantly long times. This includes Canonical Correlation Analysis used to\nalign the latent variables across days; this method requires prior\npoint-to-point correspondence of the time series across domains. Alternatively,\nwe match the empirical probability distributions of the latent variables across\ndays through the minimization of their Kullback-Leibler divergence. These two\nmethods provide a significant and comparable improvement in the performance of\nthe interface. However, implementation of an Adversarial Domain Adaptation\nNetwork trained to match the empirical probability distribution of the\nresiduals of the reconstructed neural signals outperforms the two methods based\non latent variables, while requiring remarkably few data points to solve the\ndomain adaptation problem.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:56:46 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 17:59:26 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Farshchian", "Ali", ""], ["Gallego", "Juan A.", ""], ["Cohen", "Joseph P.", ""], ["Bengio", "Yoshua", ""], ["Miller", "Lee E.", ""], ["Solla", "Sara A.", ""]]}, {"id": "1810.00068", "submitter": "Roshan Shariff", "authors": "Roshan Shariff and Or Sheffet", "title": "Differentially Private Contextual Linear Bandits", "comments": "21 pages, 5 figures; to appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the contextual linear bandit problem, a version of the standard\nstochastic multi-armed bandit (MAB) problem where a learner sequentially\nselects actions to maximize a reward which depends also on a user provided\nper-round context. Though the context is chosen arbitrarily or adversarially,\nthe reward is assumed to be a stochastic function of a feature vector that\nencodes the context and selected action. Our goal is to devise private learners\nfor the contextual linear bandit problem.\n  We first show that using the standard definition of differential privacy\nresults in linear regret. So instead, we adopt the notion of joint differential\nprivacy, where we assume that the action chosen on day $t$ is only revealed to\nuser $t$ and thus needn't be kept private that day, only on following days. We\ngive a general scheme converting the classic linear-UCB algorithm into a joint\ndifferentially private algorithm using the tree-based algorithm. We then apply\neither Gaussian noise or Wishart noise to achieve joint-differentially private\nalgorithms and bound the resulting algorithms' regrets. In addition, we give\nthe first lower bound on the additional regret any private algorithms for the\nMAB problem must incur.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 20:04:25 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shariff", "Roshan", ""], ["Sheffet", "Or", ""]]}, {"id": "1810.00069", "submitter": "Manaar Alam", "authors": "Anirban Chakraborty and Manaar Alam and Vishal Dey and Anupam\n  Chattopadhyay and Debdeep Mukhopadhyay", "title": "Adversarial Attacks and Defences: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a strong and efficient framework that can be\napplied to a broad spectrum of complex learning problems which were difficult\nto solve using the traditional machine learning techniques in the past. In the\nlast few years, deep learning has advanced radically in such a way that it can\nsurpass human-level performance on a number of tasks. As a consequence, deep\nlearning is being extensively used in most of the recent day-to-day\napplications. However, security of deep learning systems are vulnerable to\ncrafted adversarial examples, which may be imperceptible to the human eye, but\ncan lead the model to misclassify the output. In recent times, different types\nof adversaries based on their threat model leverage these vulnerabilities to\ncompromise a deep learning system where adversaries have high incentives.\nHence, it is extremely important to provide robustness to deep learning\nalgorithms against these adversaries. However, there are only a few strong\ncountermeasures which can be used in all types of attack scenarios to design a\nrobust deep learning system. In this paper, we attempt to provide a detailed\ndiscussion on different types of adversarial attacks with various threat models\nand also elaborate the efficiency and challenges of recent countermeasures\nagainst them.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 20:09:04 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chakraborty", "Anirban", ""], ["Alam", "Manaar", ""], ["Dey", "Vishal", ""], ["Chattopadhyay", "Anupam", ""], ["Mukhopadhyay", "Debdeep", ""]]}, {"id": "1810.00090", "submitter": "Emanuel Onica", "authors": "Ciprian Amariei, Paul Diac, Emanuel Onica, Valentin Ro\\c{s}ca", "title": "Cell Grid Architecture for Maritime Route Prediction on AIS Data Streams", "comments": null, "journal-ref": "DEBS 2018, Proceedings of the 12th ACM International Conference on\n  Distributed and Event-based Systems, Pages 202-204", "doi": "10.1145/3210284.3220503", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2018 Grand Challenge targets the problem of accurate predictions on data\nstreams produced by automatic identification system (AIS) equipment, describing\nnaval traffic. This paper reports the technical details of a custom solution,\nwhich exposes multiple tuning parameters, making its configurability one of the\nmain strengths. Our solution employs a cell grid architecture essentially based\non a sequence of hash tables, specifically built for the targeted use case.\nThis makes it particularly effective in prediction on AIS data, obtaining a\nhigh accuracy and scalable performance results. Moreover, the architecture\nproposed accommodates also an optionally semi-supervised learning process\nbesides the basic supervised mode.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 21:42:17 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Amariei", "Ciprian", ""], ["Diac", "Paul", ""], ["Onica", "Emanuel", ""], ["Ro\u015fca", "Valentin", ""]]}, {"id": "1810.00096", "submitter": "Emanuel Onica", "authors": "Valentin Ro\\c{s}ca, Emanuel Onica, Paul Diac, Ciprian Amariei", "title": "Predicting Destinations by Nearest Neighbor Search on Training Vessel\n  Routes", "comments": null, "journal-ref": "DEBS 2018, Proceedings of the 12th ACM International Conference on\n  Distributed and Event-based Systems, Pages 224-225", "doi": "10.1145/3210284.3220509", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DEBS Grand Challenge 2018 is set in the context of maritime route\nprediction. Vessel routes are modeled as streams of Automatic Identification\nSystem (AIS) data points selected from real-world tracking data. The challenge\nrequires to correctly estimate the destination ports and arrival times of\nvessel trips, as early as possible. Our proposed solution partitions the\ntraining vessel routes by reported destination port and uses a nearest neighbor\nsearch to find the training routes that are closer to the query AIS point.\nParticular improvements have been included as well, such as a way to avoid\nchanging the predicted ports frequently within one query route and automating\nthe parameters tuning by the use of a genetic algorithm. This leads to\nsignificant improvements on the final score.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 21:52:56 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ro\u015fca", "Valentin", ""], ["Onica", "Emanuel", ""], ["Diac", "Paul", ""], ["Amariei", "Ciprian", ""]]}, {"id": "1810.00110", "submitter": "Karl Ridgeway", "authors": "Karl Ridgeway and Michael C. Mozer", "title": "Open-Ended Content-Style Recombination Via Leakage Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider visual domains in which a class label specifies the content of an\nimage, and class-irrelevant properties that differentiate instances constitute\nthe style. We present a domain-independent method that permits the open-ended\nrecombination of style of one image with the content of another. Open ended\nsimply means that the method generalizes to style and content not present in\nthe training data. The method starts by constructing a content embedding using\nan existing deep metric-learning technique. This trained content encoder is\nincorporated into a variational autoencoder (VAE), paired with a to-be-trained\nstyle encoder. The VAE reconstruction loss alone is inadequate to ensure a\ndecomposition of the latent representation into style and content. Our method\nthus includes an auxiliary loss, leakage filtering, which ensures that no style\ninformation remaining in the content representation is used for reconstruction\nand vice versa. We synthesize novel images by decoding the style representation\nobtained from one image with the content representation from another. Using\nthis method for data-set augmentation, we obtain state-of-the-art performance\non few-shot learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 22:45:40 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ridgeway", "Karl", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1810.00113", "submitter": "Hossein Mobahi", "authors": "Yiding Jiang, Dilip Krishnan, Hossein Mobahi, Samy Bengio", "title": "Predicting the Generalization Gap in Deep Networks with Margin\n  Distributions", "comments": "Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As shown in recent research, deep neural networks can perfectly fit randomly\nlabeled data, but with very poor accuracy on held out data. This phenomenon\nindicates that loss functions such as cross-entropy are not a reliable\nindicator of generalization. This leads to the crucial question of how\ngeneralization gap should be predicted from the training data and network\nparameters. In this paper, we propose such a measure, and conduct extensive\nempirical studies on how well it can predict the generalization gap. Our\nmeasure is based on the concept of margin distribution, which are the distances\nof training points to the decision boundary. We find that it is necessary to\nuse margin distributions at multiple layers of a deep network. On the CIFAR-10\nand the CIFAR-100 datasets, our proposed measure correlates very strongly with\nthe generalization gap. In addition, we find the following other factors to be\nof importance: normalizing margin values for scale independence, using\ncharacterizations of margin distribution rather than just the margin (closest\ndistance to decision boundary), and working in log space instead of linear\nspace (effectively using a product of margins rather than a sum). Our measure\ncan be easily applied to feedforward deep networks with any architecture and\nmay point towards new training loss functions that could enable better\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 23:23:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 07:04:50 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Jiang", "Yiding", ""], ["Krishnan", "Dilip", ""], ["Mobahi", "Hossein", ""], ["Bengio", "Samy", ""]]}, {"id": "1810.00116", "submitter": "Evgeny Andriyash", "authors": "Evgeny Andriyash, Arash Vahdat and Bill Macready", "title": "Improved Gradient-Based Optimization Over Discrete Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications we seek to maximize an expectation with respect to a\ndistribution over discrete variables. Estimating gradients of such objectives\nwith respect to the distribution parameters is a challenging problem. We\nanalyze existing solutions including finite-difference (FD) estimators and\ncontinuous relaxation (CR) estimators in terms of bias and variance. We show\nthat the commonly used Gumbel-Softmax estimator is biased and propose a simple\nmethod to reduce it. We also derive a simpler piece-wise linear continuous\nrelaxation that also possesses reduced bias. We demonstrate empirically that\nreduced bias leads to a better performance in variational inference and on\nbinary optimization tasks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 00:07:28 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 00:19:52 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 23:58:32 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Andriyash", "Evgeny", ""], ["Vahdat", "Arash", ""], ["Macready", "Bill", ""]]}, {"id": "1810.00122", "submitter": "Qianxiao Li", "authors": "Yongqiang Cai, Qianxiao Li, Zuowei Shen", "title": "A Quantitative Analysis of the Effect of Batch Normalization on Gradient\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its empirical success and recent theoretical progress, there\ngenerally lacks a quantitative analysis of the effect of batch normalization\n(BN) on the convergence and stability of gradient descent. In this paper, we\nprovide such an analysis on the simple problem of ordinary least squares (OLS).\nSince precise dynamical properties of gradient descent (GD) is completely known\nfor the OLS problem, it allows us to isolate and compare the additional effects\nof BN. More precisely, we show that unlike GD, gradient descent with BN (BNGD)\nconverges for arbitrary learning rates for the weights, and the convergence\nremains linear under mild conditions. Moreover, we quantify two different\nsources of acceleration of BNGD over GD -- one due to over-parameterization\nwhich improves the effective condition number and another due having a large\nrange of learning rates giving rise to fast descent. These phenomena set BNGD\napart from GD and could account for much of its robustness properties. These\nfindings are confirmed quantitatively by numerical experiments, which further\nshow that many of the uncovered properties of BNGD in OLS are also observed\nqualitatively in more complex supervised learning problems.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 00:50:21 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 03:04:58 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Cai", "Yongqiang", ""], ["Li", "Qianxiao", ""], ["Shen", "Zuowei", ""]]}, {"id": "1810.00123", "submitter": "Marlos C. Machado", "authors": "Jesse Farebrother, Marlos C. Machado, Michael Bowling", "title": "Generalization and Regularization in DQN", "comments": "Earlier versions of this work were presented both at the NeurIPS'18\n  Deep Reinforcement Learning Workshop and the 4th Multidisciplinary Conference\n  on Reinforcement Learning and Decision Making (RLDM'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have shown an impressive ability to\nlearn complex control policies in high-dimensional tasks. However, despite the\never-increasing performance on popular benchmarks, policies learned by deep\nreinforcement learning algorithms can struggle to generalize when evaluated in\nremarkably similar environments. In this paper we propose a protocol to\nevaluate generalization in reinforcement learning through different modes of\nAtari 2600 games. With that protocol we assess the generalization capabilities\nof DQN, one of the most traditional deep reinforcement learning algorithms, and\nwe provide evidence suggesting that DQN overspecializes to the training\nenvironment. We then comprehensively evaluate the impact of dropout and\n$\\ell_2$ regularization, as well as the impact of reusing learned\nrepresentations to improve the generalization capabilities of DQN. Despite\nregularization being largely underutilized in deep reinforcement learning, we\nshow that it can, in fact, help DQN learn more general features. These features\ncan be reused and fine-tuned on similar tasks, considerably improving DQN's\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 00:52:34 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 17:59:21 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 23:25:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Farebrother", "Jesse", ""], ["Machado", "Marlos C.", ""], ["Bowling", "Michael", ""]]}, {"id": "1810.00139", "submitter": "Dahua Gao", "authors": "Guangming Shi, Zhongqiang Zhang, Dahua Gao, Xuemei Xie, Yihao Feng,\n  Xinrui Ma, Danhua Liu", "title": "Knowledge-guided Semantic Computing Network", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is very useful to integrate human knowledge and experience into\ntraditional neural networks for faster learning speed, fewer training samples\nand better interpretability. However, due to the obscured and indescribable\nblack box model of neural networks, it is very difficult to design its\narchitecture, interpret its features and predict its performance. Inspired by\nhuman visual cognition process, we propose a knowledge-guided semantic\ncomputing network which includes two modules: a knowledge-guided semantic tree\nand a data-driven neural network. The semantic tree is pre-defined to describe\nthe spatial structural relations of different semantics, which just corresponds\nto the tree-like description of objects based on human knowledge. The object\nrecognition process through the semantic tree only needs simple forward\ncomputing without training. Besides, to enhance the recognition ability of the\nsemantic tree in aspects of the diversity, randomicity and variability, we use\nthe traditional neural network to aid the semantic tree to learn some\nindescribable features. Only in this case, the training process is needed. The\nexperimental results on MNIST and GTSRB datasets show that compared with the\ntraditional data-driven network, our proposed semantic computing network can\nachieve better performance with fewer training samples and lower computational\ncomplexity. Especially, Our model also has better adversarial robustness than\ntraditional neural network with the help of human knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 03:23:53 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shi", "Guangming", ""], ["Zhang", "Zhongqiang", ""], ["Gao", "Dahua", ""], ["Xie", "Xuemei", ""], ["Feng", "Yihao", ""], ["Ma", "Xinrui", ""], ["Liu", "Danhua", ""]]}, {"id": "1810.00143", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Qingru Zhang, Guansong Lu, Hongwei Wang, Weinan Zhang,\n  Yong Yu", "title": "AdaShift: Decorrelation and Convergence of Adaptive Learning Rate\n  Methods", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam is shown not being able to converge to the optimal solution in certain\ncases. Researchers recently propose several algorithms to avoid the issue of\nnon-convergence of Adam, but their efficiency turns out to be unsatisfactory in\npractice. In this paper, we provide new insight into the non-convergence issue\nof Adam as well as other adaptive learning rate methods. We argue that there\nexists an inappropriate correlation between gradient $g_t$ and the\nsecond-moment term $v_t$ in Adam ($t$ is the timestep), which results in that a\nlarge gradient is likely to have small step size while a small gradient may\nhave a large step size. We demonstrate that such biased step sizes are the\nfundamental cause of non-convergence of Adam, and we further prove that\ndecorrelating $v_t$ and $g_t$ will lead to unbiased step size for each\ngradient, thus solving the non-convergence problem of Adam. Finally, we propose\nAdaShift, a novel adaptive learning rate method that decorrelates $v_t$ and\n$g_t$ by temporal shifting, i.e., using temporally shifted gradient $g_{t-n}$\nto calculate $v_t$. The experiment results demonstrate that AdaShift is able to\naddress the non-convergence issue of Adam, while still maintaining a\ncompetitive performance with Adam in terms of both training speed and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 03:52:20 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 09:02:48 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 13:00:42 GMT"}, {"version": "v4", "created": "Mon, 24 Jun 2019 07:55:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhou", "Zhiming", ""], ["Zhang", "Qingru", ""], ["Lu", "Guansong", ""], ["Wang", "Hongwei", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1810.00144", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Chenchen Liu, Yanzhi Wang, Liang Zhao, Xiang Chen", "title": "Interpreting Adversarial Robustness: A View from Decision Surface in\n  Input Space", "comments": "15 pages, submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular hypothesis of neural network generalization is that the flat\nlocal minima of loss surface in parameter space leads to good generalization.\nHowever, we demonstrate that loss surface in parameter space has no obvious\nrelationship with generalization, especially under adversarial settings.\nThrough visualizing decision surfaces in both parameter space and input space,\nwe instead show that the geometry property of decision surface in input space\ncorrelates well with the adversarial robustness. We then propose an adversarial\nrobustness indicator, which can evaluate a neural network's intrinsic\nrobustness property without testing its accuracy under adversarial attacks.\nGuided by it, we further propose our robust training method. Without involving\nadversarial training, our method could enhance network's intrinsic adversarial\nrobustness against various adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 04:03:08 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 20:54:40 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Yu", "Fuxun", ""], ["Liu", "Chenchen", ""], ["Wang", "Yanzhi", ""], ["Zhao", "Liang", ""], ["Chen", "Xiang", ""]]}, {"id": "1810.00147", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, Yuandong Tian", "title": "M$^3$RL: Mind-aware Multi-agent Management Reinforcement Learning", "comments": "ICLR 2019; 18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the prior work on multi-agent reinforcement learning (MARL) achieves\noptimal collaboration by directly controlling the agents to maximize a common\nreward. In this paper, we aim to address this from a different angle. In\nparticular, we consider scenarios where there are self-interested agents (i.e.,\nworker agents) which have their own minds (preferences, intentions, skills,\netc.) and can not be dictated to perform tasks they do not wish to do. For\nachieving optimal coordination among these agents, we train a super agent\n(i.e., the manager) to manage them by first inferring their minds based on both\ncurrent and past observations and then initiating contracts to assign suitable\ntasks to workers and promise to reward them with corresponding bonuses so that\nthey will agree to work together. The objective of the manager is maximizing\nthe overall productivity as well as minimizing payments made to the workers for\nad-hoc worker teaming. To train the manager, we propose Mind-aware Multi-agent\nManagement Reinforcement Learning (M^3RL), which consists of agent modeling and\npolicy learning. We have evaluated our approach in two environments, Resource\nCollection and Crafting, to simulate multi-agent management problems with\nvarious task settings and multiple designs for the worker agents. The\nexperimental results have validated the effectiveness of our approach in\nmodeling worker agents' minds online, and in achieving optimal ad-hoc teaming\nwith good generalization and fast adaptation.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 04:33:15 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 21:56:03 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 06:02:40 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Shu", "Tianmin", ""], ["Tian", "Yuandong", ""]]}, {"id": "1810.00150", "submitter": "Cheolhyoung Lee", "authors": "Cheolhyoung Lee, Kyunghyun Cho, Wanmo Kang", "title": "Directional Analysis of Stochastic Gradient Descent via von Mises-Fisher\n  Distributions in Deep learning", "comments": "11 pages (+15 pages for references and supplemental material, total\n  26 pages), 12 figures, a single table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although stochastic gradient descent (SGD) is a driving force behind the\nrecent success of deep learning, our understanding of its dynamics in a\nhigh-dimensional parameter space is limited. In recent years, some researchers\nhave used the stochasticity of minibatch gradients, or the signal-to-noise\nratio, to better characterize the learning dynamics of SGD. Inspired from these\nwork, we here analyze SGD from a geometrical perspective by inspecting the\nstochasticity of the norms and directions of minibatch gradients. We propose a\nmodel of the directional concentration for minibatch gradients through von\nMises-Fisher (VMF) distribution, and show that the directional uniformity of\nminibatch gradients increases over the course of SGD. We empirically verify our\nresult using deep convolutional networks and observe a higher correlation\nbetween the gradient stochasticity and the proposed directional uniformity than\nthat against the gradient norm stochasticity, suggesting that the directional\nstatistics of minibatch gradients is a major factor behind SGD.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 05:16:43 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 05:42:33 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Lee", "Cheolhyoung", ""], ["Cho", "Kyunghyun", ""], ["Kang", "Wanmo", ""]]}, {"id": "1810.00223", "submitter": "Shogo Seki", "authors": "Shogo Seki, Hirokazu Kameoka, Li Li, Tomoki Toda, Kazuya Takeda", "title": "Generalized Multichannel Variational Autoencoder for Underdetermined\n  Source Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a multichannel audio source separation problem under\nunderdetermined conditions. Multichannel Non-negative Matrix Factorization\n(MNMF) is one of powerful approaches, which adopts the NMF concept for source\npower spectrogram modeling. This concept is also employed in Independent\nLow-Rank Matrix Analysis (ILRMA), a special class of the MNMF framework\nformulated under determined conditions. While these methods work reasonably\nwell for particular types of sound sources, one limitation is that they can\nfail to work for sources with spectrograms that do not comply with the NMF\nmodel. To address this limitation, an extension of ILRMA called the\nMultichannel Variational Autoencoder (MVAE) method was recently proposed, where\na Conditional VAE (CVAE) is used instead of the NMF model for source power\nspectrogram modeling. This approach has shown to perform impressively in\ndetermined source separation tasks thanks to the representation power of DNNs.\nWhile the original MVAE method was formulated under determined mixing\nconditions, this paper generalizes it so that it can also deal with\nunderdetermined cases. We call the proposed framework the Generalized MVAE\n(GMVAE). The proposed method was evaluated on a underdetermined source\nseparation task of separating out three sources from two microphone inputs.\nExperimental results revealed that the GMVAE method achieved better performance\nthan the MNMF method.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 15:40:11 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Seki", "Shogo", ""], ["Kameoka", "Hirokazu", ""], ["Li", "Li", ""], ["Toda", "Tomoki", ""], ["Takeda", "Kazuya", ""]]}, {"id": "1810.00240", "submitter": "Nicolas Pr\\\"ollochs", "authors": "Nicolas Pr\\\"ollochs, Stefan Feuerriegel", "title": "Reinforcement Learning in R", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning refers to a group of methods from artificial\nintelligence where an agent performs learning through trial and error. It\ndiffers from supervised learning, since reinforcement learning requires no\nexplicit labels; instead, the agent interacts continuously with its\nenvironment. That is, the agent starts in a specific state and then performs an\naction, based on which it transitions to a new state and, depending on the\noutcome, receives a reward. Different strategies (e.g. Q-learning) have been\nproposed to maximize the overall reward, resulting in a so-called policy, which\ndefines the best possible action in each state. Mathematically, this process\ncan be formalized by a Markov decision process and it has been implemented by\npackages in R; however, there is currently no package available for\nreinforcement learning. As a remedy, this paper demonstrates how to perform\nreinforcement learning in R and, for this purpose, introduces the\nReinforcementLearning package. The package provides a remarkably flexible\nframework and is easily applied to a wide range of different problems. We\ndemonstrate its use by drawing upon common examples from the literature (e.g.\nfinding optimal game strategies).\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 17:25:40 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Pr\u00f6llochs", "Nicolas", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1810.00299", "submitter": "Simon Alford", "authors": "Simon Alford, Ryan Robinett, Lauren Milechin, Jeremy Kepner", "title": "Training Behavior of Sparse Neural Network Topologies", "comments": "6 pages. Presented at the 2019 IEEE High Performance Extreme\n  Computing (HPEC) Conference. Received \"Best Paper\" award", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916385", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improvements in the performance of deep neural networks have often come\nthrough the design of larger and more complex networks. As a result, fast\nmemory is a significant limiting factor in our ability to improve network\nperformance. One approach to overcoming this limit is the design of sparse\nneural networks, which can be both very large and efficiently trained. In this\npaper we experiment training on sparse neural network topologies. We test\npruning-based topologies, which are derived from an initially dense network\nwhose connections are pruned, as well as RadiX-Nets, a class of network\ntopologies with proven connectivity and sparsity properties. Results show that\nsparse networks obtain accuracies comparable to dense networks, but extreme\nlevels of sparsity cause instability in training, which merits further study.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 02:41:00 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 22:29:31 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Alford", "Simon", ""], ["Robinett", "Ryan", ""], ["Milechin", "Lauren", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1810.00315", "submitter": "Xiaodong Li", "authors": "Xiaodong Li, Yudong Chen, Jiaming Xu", "title": "Convex Relaxation Methods for Community Detection", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys recent theoretical advances in convex optimization\napproaches for community detection. We introduce some important theoretical\ntechniques and results for establishing the consistency of convex community\ndetection under various statistical models. In particular, we discuss the basic\ntechniques based on the primal and dual analysis. We also present results that\ndemonstrate several distinctive advantages of convex community detection,\nincluding robustness against outlier nodes, consistency under weak\nassortativity, and adaptivity to heterogeneous degrees.\n  This survey is not intended to be a complete overview of the vast literature\non this fast-growing topic. Instead, we aim to provide a big picture of the\nremarkable recent development in this area and to make the survey accessible to\na broad audience. We hope that this expository article can serve as an\nintroductory guide for readers who are interested in using, designing, and\nanalyzing convex relaxation methods in network analysis.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 04:32:32 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Li", "Xiaodong", ""], ["Chen", "Yudong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1810.00319", "submitter": "Seong Joon Oh", "authors": "Seong Joon Oh, Kevin Murphy, Jiyan Pan, Joseph Roth, Florian Schroff,\n  Andrew Gallagher", "title": "Modeling Uncertainty with Hedged Instance Embedding", "comments": "15 pages, 11 figures, updated version of ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance embeddings are an efficient and versatile image representation that\nfacilitates applications like recognition, verification, retrieval, and\nclustering. Many metric learning methods represent the input as a single point\nin the embedding space. Often the distance between points is used as a proxy\nfor match confidence. However, this can fail to represent uncertainty arising\nwhen the input is ambiguous, e.g., due to occlusion or blurriness. This work\naddresses this issue and explicitly models the uncertainty by hedging the\nlocation of each input in the embedding space. We introduce the hedged instance\nembedding (HIB) in which embeddings are modeled as random variables and the\nmodel is trained under the variational information bottleneck principle.\nEmpirical results on our new N-digit MNIST dataset show that our method leads\nto the desired behavior of hedging its bets across the embedding space upon\nencountering ambiguous inputs. This results in improved performance for image\nmatching and classification tasks, more structure in the learned embedding\nspace, and an ability to compute a per-exemplar uncertainty measure that is\ncorrelated with downstream performance.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 04:51:27 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 17:26:22 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 15:41:25 GMT"}, {"version": "v4", "created": "Fri, 21 Dec 2018 23:46:55 GMT"}, {"version": "v5", "created": "Wed, 7 Aug 2019 06:32:15 GMT"}, {"version": "v6", "created": "Tue, 27 Aug 2019 00:31:41 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Oh", "Seong Joon", ""], ["Murphy", "Kevin", ""], ["Pan", "Jiyan", ""], ["Roth", "Joseph", ""], ["Schroff", "Florian", ""], ["Gallagher", "Andrew", ""]]}, {"id": "1810.00322", "submitter": "Micha Feigin-Almon", "authors": "Micha Feigin and Daniel Freedman and Brian W. Anthony", "title": "A Deep Learning Framework for Single-Sided Sound Speed Inversion in\n  Medical Ultrasound", "comments": null, "journal-ref": "IEEE Trans Biomed Eng. 2019 Jul 25", "doi": "10.1109/TBME.2019.2931195", "report-no": null, "categories": "cs.LG eess.SP q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Ultrasound elastography is gaining traction as an accessible and\nuseful diagnostic tool for such things as cancer detection and differentiation\nand thyroid disease diagnostics. Unfortunately, state of the art shear wave\nimaging techniques, essential to promote this goal, are limited to high-end\nultrasound hardware due to high power requirements; are extremely sensitive to\npatient and sonographer motion, and generally, suffer from low frame rates.\nMotivated by research and theory showing that longitudinal wave sound speed\ncarries similar diagnostic abilities to shear wave imaging, we present an\nalternative approach using single sided pressure-wave sound speed measurements\nfrom channel data.\n  Methods: In this paper, we present a single-sided sound speed inversion\nsolution using a fully convolutional deep neural network. We use simulations\nfor training, allowing the generation of limitless ground truth data.\n  Results: We show that it is possible to invert for longitudinal sound speed\nin soft tissue at high frame rates. We validate the method on simulated data.\nWe present highly encouraging results on limited real data.\n  Conclusion: Sound speed inversion on channel data has significant potential,\nmade possible in real time with deep learning technologies.\n  Significance: Specialized shear wave ultrasound systems remain inaccessible\nin many locations. longitudinal sound speed and deep learning technologies\nenable an alternative approach to diagnosis based on tissue elasticity. High\nframe rates are possible.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 06:07:00 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 21:26:04 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 07:42:12 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 15:05:05 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Feigin", "Micha", ""], ["Freedman", "Daniel", ""], ["Anthony", "Brian W.", ""]]}, {"id": "1810.00337", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Yuandong Tian", "title": "Learning to Perform Local Rewriting for Combinatorial Optimization", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-based methods for hard combinatorial optimization are often guided by\nheuristics. Tuning heuristics in various conditions and situations is often\ntime-consuming. In this paper, we propose NeuRewriter that learns a policy to\npick heuristics and rewrite the local components of the current solution to\niteratively improve it until convergence. The policy factorizes into a\nregion-picking and a rule-picking component, each parameterized by a neural\nnetwork trained with actor-critic methods in reinforcement learning.\nNeuRewriter captures the general structure of combinatorial problems and shows\nstrong performance in three versatile tasks: expression simplification, online\njob scheduling and vehicle routing problems. NeuRewriter outperforms the\nexpression simplification component in Z3; outperforms DeepRM and Google\nOR-tools in online job scheduling; and outperforms recent neural baselines and\nGoogle OR-tools in vehicle routing problems.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 08:12:43 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 06:34:28 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 15:09:06 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 10:10:15 GMT"}, {"version": "v5", "created": "Wed, 30 Oct 2019 03:10:40 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Chen", "Xinyun", ""], ["Tian", "Yuandong", ""]]}, {"id": "1810.00361", "submitter": "Manuel Fritsche", "authors": "Gino Brunner, Manuel Fritsche, Oliver Richter, Roger Wattenhofer", "title": "Using State Predictions for Value Regularization in Curiosity Driven\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in sparse reward settings remains a challenge in Reinforcement\nLearning, which is often addressed by using intrinsic rewards. One promising\nstrategy is inspired by human curiosity, requiring the agent to learn to\npredict the future. In this paper a curiosity-driven agent is extended to use\nthese predictions directly for training. To achieve this, the agent predicts\nthe value function of the next state at any point in time. Subsequently, the\nconsistency of this prediction with the current value function is measured,\nwhich is then used as a regularization term in the loss function of the\nalgorithm. Experiments were made on grid-world environments as well as on a 3D\nnavigation task, both with sparse rewards. In the first case the extended agent\nis able to learn significantly faster than the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 11:29:55 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Brunner", "Gino", ""], ["Fritsche", "Manuel", ""], ["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1810.00363", "submitter": "Alberto Bietti", "authors": "Alberto Bietti, Gr\\'egoire Mialon, Dexiong Chen, Julien Mairal", "title": "A Kernel Perspective for Regularizing Deep Neural Networks", "comments": "ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new point of view for regularizing deep neural networks by using\nthe norm of a reproducing kernel Hilbert space (RKHS). Even though this norm\ncannot be computed, it admits upper and lower approximations leading to various\npractical strategies. Specifically, this perspective (i) provides a common\numbrella for many existing regularization principles, including spectral norm\nand gradient penalties, or adversarial training, (ii) leads to new effective\nregularization penalties, and (iii) suggests hybrid strategies combining lower\nand upper bounds to get better approximations of the RKHS norm. We\nexperimentally show this approach to be effective when learning on small\ndatasets, or to obtain adversarially robust models.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 11:40:59 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 17:16:49 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 18:01:25 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 18:04:46 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Bietti", "Alberto", ""], ["Mialon", "Gr\u00e9goire", ""], ["Chen", "Dexiong", ""], ["Mairal", "Julien", ""]]}, {"id": "1810.00368", "submitter": "Matthia Sabatelli", "authors": "Matthia Sabatelli, Gilles Louppe, Pierre Geurts, Marco A. Wiering", "title": "Deep Quality-Value (DQV) Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel Deep Reinforcement Learning (DRL) algorithm called Deep\nQuality-Value (DQV) Learning. DQV uses temporal-difference learning to train a\nValue neural network and uses this network for training a second Quality-value\nnetwork that learns to estimate state-action values. We first test DQV's update\nrules with Multilayer Perceptrons as function approximators on two classic RL\nproblems, and then extend DQV with the use of Deep Convolutional Neural\nNetworks, `Experience Replay' and `Target Neural Networks' for tackling four\ngames of the Atari Arcade Learning environment. Our results show that DQV\nlearns significantly faster and better than Deep Q-Learning and Double Deep\nQ-Learning, suggesting that our algorithm can potentially be a better\nperforming synchronous temporal difference algorithm than what is currently\npresent in DRL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 12:52:31 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 07:47:00 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Sabatelli", "Matthia", ""], ["Louppe", "Gilles", ""], ["Geurts", "Pierre", ""], ["Wiering", "Marco A.", ""]]}, {"id": "1810.00378", "submitter": "Marcello De Bernardi", "authors": "Marcello De Bernardi, MHR Khouzani, Pasquale Malacaria", "title": "Pseudo-Random Number Generation using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-random number generators (PRNG) are a fundamental element of many\nsecurity algorithms. We introduce a novel approach to their implementation, by\nproposing the use of generative adversarial networks (GAN) to train a neural\nnetwork to behave as a PRNG. Furthermore, we showcase a number of interesting\nmodifications to the standard GAN architecture. The most significant is\npartially concealing the output of the GAN's generator, and training the\nadversary to discover a mapping from the overt part to the concealed part. The\ngenerator therefore learns to produce values the adversary cannot predict,\nrather than to approximate an explicit reference distribution. We demonstrate\nthat a GAN can effectively train even a small feed-forward fully connected\nneural network to produce pseudo-random number sequences with good statistical\nproperties. At best, subjected to the NIST test suite, the trained generator\npassed around 99% of test instances and 98% of overall tests, outperforming a\nnumber of standard non-cryptographic PRNGs.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 13:46:16 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["De Bernardi", "Marcello", ""], ["Khouzani", "MHR", ""], ["Malacaria", "Pasquale", ""]]}, {"id": "1810.00383", "submitter": "Bo Han", "authors": "Bo Han, Ivor W. Tsang, Xiaokui Xiao, Ling Chen, Sai-fu Fung, Celina P.\n  Yu", "title": "Privacy-preserving Stochastic Gradual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging for stochastic optimizations to handle large-scale\nsensitive data safely. Recently, Duchi et al. proposed private sampling\nstrategy to solve privacy leakage in stochastic optimizations. However, this\nstrategy leads to robustness degeneration, since this strategy is equal to the\nnoise injection on each gradient, which adversely affects updates of the primal\nvariable. To address this challenge, we introduce a robust stochastic\noptimization under the framework of local privacy, which is called\nPrivacy-pREserving StochasTIc Gradual lEarning (PRESTIGE). PRESTIGE bridges\nprivate updates of the primal variable (by private sampling) with the gradual\ncurriculum learning (CL). Specifically, the noise injection leads to the issue\nof label noise, but the robust learning process of CL can combat with label\nnoise. Thus, PRESTIGE yields \"private but robust\" updates of the primal\nvariable on the private curriculum, namely an reordered label sequence provided\nby CL. In theory, we reveal the convergence rate and maximum complexity of\nPRESTIGE. Empirical results on six datasets show that, PRESTIGE achieves a good\ntradeoff between privacy preservation and robustness over baselines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 14:10:11 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Han", "Bo", ""], ["Tsang", "Ivor W.", ""], ["Xiao", "Xiaokui", ""], ["Chen", "Ling", ""], ["Fung", "Sai-fu", ""], ["Yu", "Celina P.", ""]]}, {"id": "1810.00386", "submitter": "Scott Gigante", "authors": "Jay S. Stanley III, Scott Gigante, Guy Wolf, and Smita Krishnaswamy", "title": "Harmonic Alignment", "comments": "Published in SIAM Data Mining 2020. Double column, 18 pages, 4\n  figures", "journal-ref": "SIAM Data Mining 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for combining datasets via alignment of their\nintrinsic geometry. This alignment can be used to fuse data originating from\ndisparate modalities, or to correct batch effects while preserving intrinsic\ndata structure. Importantly, we do not assume any pointwise correspondence\nbetween datasets, but instead rely on correspondence between a (possibly\nunknown) subset of data features. We leverage this assumption to construct an\nisometric alignment between the data. This alignment is obtained by relating\nthe expansion of data features in harmonics derived from diffusion operators\ndefined over each dataset. These expansions encode each feature as a function\nof the data geometry. We use this to relate the diffusion coordinates of each\ndataset through our assumption of partial feature correspondence. Then, a\nunified diffusion geometry is constructed over the aligned data, which can also\nbe used to correct the original data measurements. We demonstrate our method on\nseveral datasets, showing in particular its effectiveness in biological\napplications including fusion of single-cell RNA sequencing (scRNA-seq) and\nsingle-cell ATAC sequencing (scATAC-seq) data measured on the same population\nof cells, and removal of batch effect between biological samples.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 14:23:10 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 19:42:03 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 15:24:03 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 16:14:18 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Stanley", "Jay S.", "III"], ["Gigante", "Scott", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1810.00393", "submitter": "Jesse Johnson", "authors": "Jesse Johnson", "title": "Deep, Skinny Neural Networks are not Universal Approximators", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to choose a neural network architecture that will be effective for a\nparticular modeling problem, one must understand the limitations imposed by\neach of the potential options. These limitations are typically described in\nterms of information theoretic bounds, or by comparing the relative complexity\nneeded to approximate example functions between different architectures. In\nthis paper, we examine the topological constraints that the architecture of a\nneural network imposes on the level sets of all the functions that it is able\nto approximate. This approach is novel for both the nature of the limitations\nand the fact that they are independent of network depth for a broad family of\nactivation functions.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 14:55:41 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Johnson", "Jesse", ""]]}, {"id": "1810.00396", "submitter": "Dmitry Podviaznikov", "authors": "Roman Khudorozhkov, Dmitry Podvyaznikov", "title": "Benchmarks of ResNet Architecture for Atrial Fibrillation Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we apply variations of ResNet architecture to the task of atrial\nfibrillation classification. Variations differ in number of filter after first\nconvolution, ResNet block layout, number of filters in block convolutions and\nnumber of ResNet blocks between downsampling operations. We have found a range\nof model size in which models with quite different configurations show similar\nperformance. It is likely that overall number of parameters plays dominant role\nin model performance. However, configuration parameters like layout have values\nthat constantly lead to better results, which allows to suggest that these\nparameters should be defined and fixed in the first place, while others may be\nvaried in a reasonable range to satisfy any existing constraints.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 15:09:42 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Khudorozhkov", "Roman", ""], ["Podvyaznikov", "Dmitry", ""]]}, {"id": "1810.00398", "submitter": "Kapil Ahuja", "authors": "Aditya A. Shastri, Kapil Ahuja, Milind B. Ratnaparkhe, Aditya Shah,\n  Aishwary Gagrani, and Anant Lal", "title": "Vector Quantized Spectral Clustering applied to Soybean Whole Genome\n  Sequences", "comments": "10 Pages, 3 Tables, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Vector Quantized Spectral Clustering (VQSC) algorithm that is a\ncombination of Spectral Clustering (SC) and Vector Quantization (VQ) sampling\nfor grouping Soybean genomes. The inspiration here is to use SC for its\naccuracy and VQ to make the algorithm computationally cheap (the complexity of\nSC is cubic in-terms of the input size). Although the combination of SC and VQ\nis not new, the novelty of our work is in developing the crucial similarity\nmatrix in SC as well as use of k-medoids in VQ, both adapted for the Soybean\ngenome data. We compare our approach with commonly used techniques like UPGMA\n(Un-weighted Pair Graph Method with Arithmetic Mean) and NJ (Neighbour\nJoining). Experimental results show that our approach outperforms both these\ntechniques significantly in terms of cluster quality (up to 25% better cluster\nquality) and time complexity (order of magnitude faster).\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 15:13:33 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shastri", "Aditya A.", ""], ["Ahuja", "Kapil", ""], ["Ratnaparkhe", "Milind B.", ""], ["Shah", "Aditya", ""], ["Gagrani", "Aishwary", ""], ["Lal", "Anant", ""]]}, {"id": "1810.00412", "submitter": "Edgar Dobriban", "authors": "Edgar Dobriban, Yue Sheng", "title": "Distributed linear regression by averaging", "comments": "V2 adds a new section on iterative averaging methods, adds\n  applications of the calculus of deterministic equivalents, and reorganizes\n  the paper", "journal-ref": "Annals of Statistics, 2020+", "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed statistical learning problems arise commonly when dealing with\nlarge datasets. In this setup, datasets are partitioned over machines, which\ncompute locally, and communicate short messages. Communication is often the\nbottleneck. In this paper, we study one-step and iterative weighted parameter\naveraging in statistical linear models under data parallelism. We do linear\nregression on each machine, send the results to a central server, and take a\nweighted average of the parameters. Optionally, we iterate, sending back the\nweighted average and doing local ridge regressions centered at it. How does\nthis work compared to doing linear regression on the full data? Here we study\nthe performance loss in estimation, test error, and confidence interval length\nin high dimensions, where the number of parameters is comparable to the\ntraining data size. We find the performance loss in one-step weighted\naveraging, and also give results for iterative averaging. We also find that\ndifferent problems are affected differently by the distributed framework.\nEstimation error and confidence interval length increase a lot, while\nprediction error increases much less. We rely on recent results from random\nmatrix theory, where we develop a new calculus of deterministic equivalents as\na tool of broader interest.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 15:59:03 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 04:33:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dobriban", "Edgar", ""], ["Sheng", "Yue", ""]]}, {"id": "1810.00421", "submitter": "Siddhartha Dhar Choudhury", "authors": "Siddhartha Dhar Choudhury, Shashank Pandey", "title": "Nth Absolute Root Mean Error", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": "10.35940/ijitee.J9626.119119", "report-no": "J96260881019", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training process takes long time when the size of training\ndata is huge, without the large set of training values the neural network is\nunable to learn features. This dilemma between time and size of data is often\nsolved using fast GPUs, but we present a better solution for a subset of those\nproblems. To reduce the time for training a regression model using neural\nnetwork we introduce a loss function called Nth Absolute Root Mean Error\n(NARME). It helps to train regression models much faster compared to other\nexisting loss functions. Experiments show that in most use cases NARME reduces\nthe required number of epochs to almost one-tenth of that required by other\ncommonly used loss functions, and also achieves great accuracy in the small\namount of time in which it was trained.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 16:59:59 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 13:03:22 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Choudhury", "Siddhartha Dhar", ""], ["Pandey", "Shashank", ""]]}, {"id": "1810.00424", "submitter": "Alexander Tong", "authors": "Alexander Tong, David van Dijk, Jay S. Stanley III, Matthew Amodio,\n  Kristina Yim, Rebecca Muhle, James Noonan, Guy Wolf, and Smita Krishnaswamy", "title": "Interpretable Neuron Structuring with Graph Spectral Regularization", "comments": "12 pages, 6 figures, presented at IDA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks are powerful approximators used to classify or embed\ndata into lower dimensional spaces, they are often regarded as black boxes with\nuninterpretable features. Here we propose Graph Spectral Regularization for\nmaking hidden layers more interpretable without significantly impacting\nperformance on the primary task. Taking inspiration from spatial organization\nand localization of neuron activations in biological networks, we use a graph\nLaplacian penalty to structure the activations within a layer. This penalty\nencourages activations to be smooth either on a predetermined graph or on a\nfeature-space graph learned from the data via co-activations of a hidden layer\nof the neural network. We show numerous uses for this additional structure\nincluding cluster indication and visualization in biological and image data\nsets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 17:18:35 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 02:00:39 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 00:13:46 GMT"}, {"version": "v4", "created": "Mon, 27 May 2019 12:18:58 GMT"}, {"version": "v5", "created": "Fri, 14 Feb 2020 19:55:11 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tong", "Alexander", ""], ["van Dijk", "David", ""], ["Stanley", "Jay S.", "III"], ["Amodio", "Matthew", ""], ["Yim", "Kristina", ""], ["Muhle", "Rebecca", ""], ["Noonan", "James", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1810.00428", "submitter": "Saeed Najafi", "authors": "Saeed Najafi, Colin Cherry, Grzegorz Kondrak", "title": "Efficient Sequence Labeling with Actor-Critic Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural approaches to sequence labeling often use a Conditional Random Field\n(CRF) to model their output dependencies, while Recurrent Neural Networks (RNN)\nare used for the same purpose in other tasks. We set out to establish RNNs as\nan attractive alternative to CRFs for sequence labeling. To do so, we address\none of the RNN's most prominent shortcomings, the fact that it is not exposed\nto its own errors with the maximum-likelihood training. We frame the prediction\nof the output sequence as a sequential decision-making process, where we train\nthe network with an adjusted actor-critic algorithm (AC-RNN). We\ncomprehensively compare this strategy with maximum-likelihood training for both\nRNNs and CRFs on three structured-output tasks. The proposed AC-RNN efficiently\nmatches the performance of the CRF on NER and CCG tagging, and outperforms it\non Machine Transliteration. We also show that our training strategy is\nsignificantly better than other techniques for addressing RNN's exposure bias,\nsuch as Scheduled Sampling, and Self-Critical policy training.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 17:31:52 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Najafi", "Saeed", ""], ["Cherry", "Colin", ""], ["Kondrak", "Grzegorz", ""]]}, {"id": "1810.00440", "submitter": "Marton Havasi", "authors": "Marton Havasi, Robert Peharz, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Minimal Random Code Learning: Getting Bits Back from Compressed Model\n  Parameters", "comments": "Under review as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks are a highly successful model class, their large\nmemory footprint puts considerable strain on energy consumption, communication\nbandwidth, and storage requirements. Consequently, model size reduction has\nbecome an utmost goal in deep learning. A typical approach is to train a set of\ndeterministic weights, while applying certain techniques such as pruning and\nquantization, in order that the empirical weight distribution becomes amenable\nto Shannon-style coding schemes. However, as shown in this paper, relaxing\nweight determinism and using a full variational distribution over weights\nallows for more efficient coding schemes and consequently higher compression\nrates. In particular, following the classical bits-back argument, we encode the\nnetwork weights using a random sample, requiring only a number of bits\ncorresponding to the Kullback-Leibler divergence between the sampled\nvariational distribution and the encoding distribution. By imposing a\nconstraint on the Kullback-Leibler divergence, we are able to explicitly\ncontrol the compression rate, while optimizing the expected loss on the\ntraining set. The employed encoding scheme can be shown to be close to the\noptimal information-theoretical lower bound, with respect to the employed\nvariational family. Our method sets new state-of-the-art in neural network\ncompression, as it strictly dominates previous approaches in a Pareto sense: On\nthe benchmarks LeNet-5/MNIST and VGG-16/CIFAR-10, our approach yields the best\ntest performance for a fixed memory budget, and vice versa, it achieves the\nhighest compression rates for a fixed test performance.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 18:27:30 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Havasi", "Marton", ""], ["Peharz", "Robert", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1810.00466", "submitter": "Rodrigo P\\'erez Dattari", "authors": "Rodrigo P\\'erez-Dattari, Carlos Celemin, Javier Ruiz-del-Solar and\n  Jens Kober", "title": "Interactive Learning with Corrective Feedback for Policies based on Deep\n  Neural Networks", "comments": "10 pages, 7 figures, 1 table, conference (ISER 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has become a powerful strategy to solve\ncomplex decision making problems based on Deep Neural Networks (DNNs). However,\nit is highly data demanding, so unfeasible in physical systems for most\napplications. In this work, we approach an alternative Interactive Machine\nLearning (IML) strategy for training DNN policies based on human corrective\nfeedback, with a method called Deep COACH (D-COACH). This approach not only\ntakes advantage of the knowledge and insights of human teachers as well as the\npower of DNNs, but also has no need of a reward function (which sometimes\nimplies the need of external perception for computing rewards). We combine Deep\nLearning with the COrrective Advice Communicated by Humans (COACH) framework,\nin which non-expert humans shape policies by correcting the agent's actions\nduring execution. The D-COACH framework has the potential to solve complex\nproblems without much data or time required. Experimental results validated the\nefficiency of the framework in three different problems (two simulated, one\nwith a real robot), with state spaces of low and high dimensions, showing the\ncapacity to successfully learn policies for continuous action spaces like in\nthe Car Racing and Cart-Pole problems faster than with DRL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 20:59:04 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["P\u00e9rez-Dattari", "Rodrigo", ""], ["Celemin", "Carlos", ""], ["Ruiz-del-Solar", "Javier", ""], ["Kober", "Jens", ""]]}, {"id": "1810.00468", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias, Sotirios Nikoloutsopoulos", "title": "Bayesian Transfer Reinforcement Learning with Prior Knowledge Rules", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic framework to directly insert prior knowledge in\nreinforcement learning (RL) algorithms by defining the behaviour policy as a\nBayesian posterior distribution. Such a posterior combines task specific\ninformation with prior knowledge, thus allowing to achieve transfer learning\nacross tasks. The resulting method is flexible and it can be easily\nincorporated to any standard off-policy and on-policy algorithms, such as those\nbased on temporal differences and policy gradients. We develop a specific\ninstance of this Bayesian transfer RL framework by expressing prior knowledge\nas general deterministic rules that can be useful in a large variety of tasks,\nsuch as navigation tasks. Also, we elaborate more on recent probabilistic and\nentropy-regularised RL by developing a novel temporal learning algorithm and\nshow how to combine it with Bayesian transfer RL. Finally, we demonstrate our\nmethod for solving mazes and show that significant speed ups can be obtained.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 21:12:44 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Nikoloutsopoulos", "Sotirios", ""]]}, {"id": "1810.00470", "submitter": "Kenneth Co", "authors": "Kenneth T. Co, Luis Mu\\~noz-Gonz\\'alez, Sixte de Maupeou, Emil C. Lupu", "title": "Procedural Noise Adversarial Examples for Black-Box Attacks on Deep\n  Convolutional Networks", "comments": "16 pages, 10 figures. In Proceedings of the 2019 ACM SIGSAC\n  Conference on Computer and Communications Security (CCS '19)", "journal-ref": null, "doi": "10.1145/3319535.3345660", "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Networks (DCNs) have been shown to be vulnerable to\nadversarial examples---perturbed inputs specifically designed to produce\nintentional errors in the learning algorithms at test time. Existing\ninput-agnostic adversarial perturbations exhibit interesting visual patterns\nthat are currently unexplained. In this paper, we introduce a structured\napproach for generating Universal Adversarial Perturbations (UAPs) with\nprocedural noise functions. Our approach unveils the systemic vulnerability of\npopular DCN models like Inception v3 and YOLO v3, with single noise patterns\nable to fool a model on up to 90% of the dataset. Procedural noise allows us to\ngenerate a distribution of UAPs with high universal evasion rates using only a\nfew parameters. Additionally, we propose Bayesian optimization to efficiently\nlearn procedural noise parameters to construct inexpensive untargeted black-box\nattacks. We demonstrate that it can achieve an average of less than 10 queries\nper successful attack, a 100-fold improvement on existing methods. We further\nmotivate the use of input-agnostic defences to increase the stability of models\nto adversarial perturbations. The universality of our attacks suggests that DCN\nmodels may be sensitive to aggregations of low-level class-agnostic features.\nThese findings give insight on the nature of some universal adversarial\nperturbations and how they could be generated in other applications.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 21:45:39 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 17:01:58 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 12:09:48 GMT"}, {"version": "v4", "created": "Sat, 23 Nov 2019 13:02:08 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Co", "Kenneth T.", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["de Maupeou", "Sixte", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1810.00471", "submitter": "Daniel McDuff", "authors": "Daniel McDuff, Roger Cheng, Ashish Kapoor", "title": "Identifying Bias in AI using Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learned models exhibit bias, often because the datasets used to train\nthem are biased. This presents a serious problem for the deployment of such\ntechnology, as the resulting models might perform poorly on populations that\nare minorities within the training set and ultimately present higher risks to\nthem. We propose to use high-fidelity computer simulations to interrogate and\ndiagnose biases within ML classifiers. We present a framework that leverages\nBayesian parameter search to efficiently characterize the high dimensional\nfeature space and more quickly identify weakness in performance. We apply our\napproach to an example domain, face detection, and show that it can be used to\nhelp identify demographic biases in commercial face application programming\ninterfaces (APIs).\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 21:46:58 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["McDuff", "Daniel", ""], ["Cheng", "Roger", ""], ["Kapoor", "Ashish", ""]]}, {"id": "1810.00475", "submitter": "Riddhish Bhalodia", "authors": "Riddhish Bhalodia, Anupama Goparaju, Tim Sodergren, Alan Morris,\n  Evgueni Kholmovski, Nassir Marrouche, Joshua Cates, Ross Whitaker, and\n  Shireen Elhabian", "title": "Deep Learning for End-to-End Atrial Fibrillation Recurrence Estimation", "comments": "Presented at Computing in Cardiology (CinC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Left atrium shape has been shown to be an independent predictor of recurrence\nafter atrial fibrillation (AF) ablation. Shape-based representation is\nimperative to such an estimation process, where correspondence-based\nrepresentation offers the most flexibility and ease-of-computation for\npopulation-level shape statistics. Nonetheless, population-level shape\nrepresentations in the form of image segmentation and correspondence models\nderived from cardiac MRI require significant human resources with sufficient\nanatomy-specific expertise. In this paper, we propose a machine learning\napproach that uses deep networks to estimate AF recurrence by predicting shape\ndescriptors directly from MRI images, with NO image pre-processing involved. We\nalso propose a novel data augmentation scheme to effectively train a deep\nnetwork in a limited training data setting. We compare this new method of\nestimating shape descriptors from images with the state-of-the-art\ncorrespondence-based shape modeling that requires image segmentation and\ncorrespondence optimization. Results show that the proposed method and the\ncurrent state-of-the-art produce statistically similar outcomes on AF\nrecurrence, eliminating the need for expensive pre-processing pipelines and\nassociated human labor.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 22:10:28 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Bhalodia", "Riddhish", ""], ["Goparaju", "Anupama", ""], ["Sodergren", "Tim", ""], ["Morris", "Alan", ""], ["Kholmovski", "Evgueni", ""], ["Marrouche", "Nassir", ""], ["Cates", "Joshua", ""], ["Whitaker", "Ross", ""], ["Elhabian", "Shireen", ""]]}, {"id": "1810.00482", "submitter": "Annie Xie", "authors": "Annie Xie, Avi Singh, Sergey Levine, Chelsea Finn", "title": "Few-Shot Goal Inference for Visuomotor Learning and Planning", "comments": "Videos available at https://sites.google.com/view/few-shot-goals", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning and planning methods require an objective or reward\nfunction that encodes the desired behavior. Yet, in practice, there is a wide\nrange of scenarios where an objective is difficult to provide programmatically,\nsuch as tasks with visual observations involving unknown object positions or\ndeformable objects. In these cases, prior methods use engineered\nproblem-specific solutions, e.g., by instrumenting the environment with\nadditional sensors to measure a proxy for the objective. Such solutions require\na significant engineering effort on a per-task basis, and make it impractical\nfor robots to continuously learn complex skills outside of laboratory settings.\nWe aim to find a more general and scalable solution for specifying goals for\nrobot learning in unconstrained environments. To that end, we formulate the\nfew-shot objective learning problem, where the goal is to learn a task\nobjective from only a few example images of successful end states for that\ntask. We propose a simple solution to this problem: meta-learn a classifier\nthat can recognize new goals from a few examples. We show how this approach can\nbe used with both model-free reinforcement learning and visual model-based\nplanning and show results in three domains: rope manipulation from images in\nsimulation, visual navigation in a simulated 3D environment, and object\narrangement into user-specified configurations on a real robot.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 22:57:58 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Xie", "Annie", ""], ["Singh", "Avi", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.00490", "submitter": "Duc Thanh Anh Luong", "authors": "Duc Thanh Anh Luong and Varun Chandola", "title": "Learning Deep Representations from Clinical Data for Chronic Kidney\n  Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of a Time-Aware Long Short-Term Memory Autoencoder, a\nstate-of-the-art method, in the context of learning latent representations from\nirregularly sampled patient data. We identify a key issue in the way such\nrecurrent neural network models are being currently used and show that the\nsolution of the issue leads to significant improvements in the learnt\nrepresentations on both synthetic and real datasets. A detailed analysis of the\nimproved methodology for representing patients suffering from Chronic Kidney\nDisease (CKD) using clinical data is provided. Experimental results show that\nthe proposed T-LSTM model is able to capture the long-term trends in the data,\nwhile effectively handling the noise in the signal. Finally, we show that by\nusing the latent representations of the CKD patients obtained from the T-LSTM\nautoencoder, one can identify unusual patient profiles from the target\npopulation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 00:34:19 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 05:28:59 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Luong", "Duc Thanh Anh", ""], ["Chandola", "Varun", ""]]}, {"id": "1810.00500", "submitter": "Jong Chul Ye", "authors": "Yoseob Han and Jong Chul Ye", "title": "One Network to Solve All ROIs: Deep Learning CT for Any ROI using\n  Differentiated Backprojection", "comments": "Accepted by Medical Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computed tomography for region-of-interest (ROI) reconstruction has\nadvantages of reducing X-ray radiation dose and using a small detector.\nHowever, standard analytic reconstruction methods suffer from severe cupping\nartifacts, and existing model-based iterative reconstruction methods require\nextensive computations. Recently, we proposed a deep neural network to learn\nthe cupping artifact, but the network is not well generalized for different\nROIs due to the singularities in the corrupted images. Therefore, there is an\nincreasing demand for a neural network that works well for any ROI sizes. In\nthis paper, two types of neural networks are designed. The first type learns\nROI size-specific cupping artifacts from the analytic reconstruction images,\nwhereas the second type network is to learn to invert the finite Hilbert\ntransform from the truncated differentiated backprojection (DBP) data. Their\ngeneralizability for any ROI sizes is then examined. Experimental results show\nthat the new type of neural network significantly outperforms the existing\niterative methods for any ROI size in spite of significantly reduced run-time\ncomplexity. Since the proposed method consistently surpasses existing methods\nfor any ROIs, it can be used as a general CT reconstruction engine for many\npractical applications without compromising possible detector truncation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 01:51:33 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:26:34 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Han", "Yoseob", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1810.00506", "submitter": "Jagdeep Bhatia S", "authors": "Jagdeep Bhatia", "title": "Simple and Fast Algorithms for Interactive Machine Learning with Random\n  Counter-examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes simple and efficient algorithms for interactively\nlearning non-binary concepts in the learning from random counter-examples (LRC)\nmodel. Here, learning takes place from random counter-examples that the learner\nreceives in response to their proper equivalence queries. In this context, the\nlearning time is defined as the number of counter-examples needed by the\nlearner to identify the target concept. Such learning is particularly suited\nfor online ranking, classification, clustering, etc., where machine learning\nmodels must be used before they are fully trained.\n  We provide two simple LRC algorithms, deterministic and randomized, for\nexactly learning non-binary target concepts for any concept class $H$. We show\nthat both of these algorithms have an $\\mathcal{O}(\\log{}|H|)$ asymptotically\noptimal average learning time. This solves an open problem on the existence of\nan efficient LRC randomized algorithm while simplifying and generalizing\nprevious results. We also show that the expected learning time of any arbitrary\nLRC algorithm can be upper bounded by\n$\\mathcal{O}(\\frac{1}{\\epsilon}\\log{\\frac{|H|}{\\delta}})$, where $\\epsilon$ and\n$\\delta$ are the allowed learning error and failure probability respectively.\nThis shows that LRC interactive learning is at least as efficient as\nnon-interactive Probably Approximately Correct (PAC) learning. Our simulations\nshow that in practice, these algorithms outperform their theoretical bounds.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 02:30:00 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 01:11:59 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Bhatia", "Jagdeep", ""]]}, {"id": "1810.00510", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, Caiming Xiong, Ying Nian Wu, Song-Chun Zhu", "title": "Interactive Agent Modeling by Learning to Probe", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of modeling the other agents, such as understanding their\nintentions and skills, is essential to an agent's interactions with other\nagents. Conventional agent modeling relies on passive observation from\ndemonstrations. In this work, we propose an interactive agent modeling scheme\nenabled by encouraging an agent to learn to probe. In particular, the probing\nagent (i.e. a learner) learns to interact with the environment and with a\ntarget agent (i.e., a demonstrator) to maximize the change in the observed\nbehaviors of that agent. Through probing, rich behaviors can be observed and\nare used for enhancing the agent modeling to learn a more accurate mind model\nof the target agent. Our framework consists of two learning processes: i)\nimitation learning for an approximated agent model and ii) pure\ncuriosity-driven reinforcement learning for an efficient probing policy to\ndiscover new behaviors that otherwise can not be observed. We have validated\nour approach in four different tasks. The experimental results suggest that the\nagent model learned by our approach i) generalizes better in novel scenarios\nthan the ones learned by passive observation, random probing, and other\ncuriosity-driven approaches do, and ii) can be used for enhancing performance\nin multiple applications including distilling optimal planning to a policy net,\ncollaboration, and competition. A video demo is available at\nhttps://www.dropbox.com/s/8mz6rd3349tso67/Probing_Demo.mov?dl=0\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 02:55:07 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shu", "Tianmin", ""], ["Xiong", "Caiming", ""], ["Wu", "Ying Nian", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1810.00520", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Dayvid V. R. Oliveira, George D. C. Cavalcanti,\n  Robert Sabourin", "title": "FIRE-DES++: Enhanced Online Pruning of Base Classifiers for Dynamic\n  Ensemble Selection", "comments": "Article published on Pattern Recognition, 2019", "journal-ref": "Pattern Recognition, Volume 85, January 2019, Pages 149-160", "doi": "10.1016/j.patcog.2018.07.037", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being very effective in several classification tasks, Dynamic\nEnsemble Selection (DES) techniques can select classifiers that classify all\nsamples in the region of competence as being from the same class. The Frienemy\nIndecision REgion DES (FIRE-DES) tackles this problem by pre-selecting\nclassifiers that correctly classify at least one pair of samples from different\nclasses in the region of competence of the test sample. However, FIRE-DES\napplies the pre-selection for the classification of a test sample if and only\nif its region of competence is composed of samples from different classes\n(indecision region), even though this criterion is not reliable for determining\nif a test sample is located close to the borders of classes (true indecision\nregion) when the region of competence is obtained using classical nearest\nneighbors approach. Because of that, FIRE-DES mistakes noisy regions for true\nindecision regions, leading to the pre-selection of incompetent classifiers,\nand mistakes true indecision regions for safe regions, leaving samples in such\nregions without any pre-selection. To tackle these issues, we propose the\nFIRE-DES++, an enhanced FIRE-DES that removes noise and reduces the overlap of\nclasses in the validation set; and defines the region of competence using an\nequal number of samples of each class, avoiding selecting a region of\ncompetence with samples of a single class. Experiments are conducted using\nFIRE-DES++ with 8 different dynamic selection techniques on 64 classification\ndatasets. Experimental results show that FIRE-DES++ increases the\nclassification performance of all DES techniques considered in this work,\noutperforming FIRE-DES with 7 out of the 8 DES techniques, and outperforming\nstate-of-the-art DES frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 03:49:46 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 23:17:15 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Oliveira", "Dayvid V. R.", ""], ["Cavalcanti", "George D. C.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1810.00551", "submitter": "Hazrat Ali", "authors": "Talha Iqbal, Hazrat Ali", "title": "Generative Adversarial Network for Medical Images (MI-GAN)", "comments": "Journal of Medical Systems", "journal-ref": "Med Syst (2018) 42: 231", "doi": "10.1007/s10916-018-1072-9", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms produces state-of-the-art results for different\nmachine learning and computer vision tasks. To perform well on a given task,\nthese algorithms require large dataset for training. However, deep learning\nalgorithms lack generalization and suffer from over-fitting whenever trained on\nsmall dataset, especially when one is dealing with medical images. For\nsupervised image analysis in medical imaging, having image data along with\ntheir corresponding annotated ground-truths is costly as well as time consuming\nsince annotations of the data is done by medical experts manually. In this\npaper, we propose a new Generative Adversarial Network for Medical Imaging\n(MI-GAN). The MI-GAN generates synthetic medical images and their segmented\nmasks, which can then be used for the application of supervised analysis of\nmedical images. Particularly, we present MI-GAN for synthesis of retinal\nimages. The proposed method generates precise segmented images better than the\nexisting techniques. The proposed model achieves a dice coefficient of 0.837 on\nSTARE dataset and 0.832 on DRIVE dataset which is state-of-the-art performance\non both the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 06:59:37 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Iqbal", "Talha", ""], ["Ali", "Hazrat", ""]]}, {"id": "1810.00553", "submitter": "Qi Deng", "authors": "Qi Deng and Yi Cheng and Guanghui Lan", "title": "Optimal Adaptive and Accelerated Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (\\textsc{Sgd}) methods are the most powerful\noptimization tools in training machine learning and deep learning models.\nMoreover, acceleration (a.k.a. momentum) methods and diagonal scaling (a.k.a.\nadaptive gradient) methods are the two main techniques to improve the slow\nconvergence of \\textsc{Sgd}. While empirical studies have demonstrated\npotential advantages of combining these two techniques, it remains unknown\nwhether these methods can achieve the optimal rate of convergence for\nstochastic optimization. In this paper, we present a new class of adaptive and\naccelerated stochastic gradient descent methods and show that they exhibit the\noptimal sampling and iteration complexity for stochastic optimization. More\nspecifically, we show that diagonal scaling, initially designed to improve\nvanilla stochastic gradient, can be incorporated into accelerated stochastic\ngradient descent to achieve the optimal rate of convergence for smooth\nstochastic optimization. We also show that momentum, apart from being known to\nspeed up the convergence rate of deterministic optimization, also provides us\nnew ways of designing non-uniform and aggressive moving average schemes in\nstochastic optimization. Finally, we present some heuristics that help to\nimplement adaptive accelerated stochastic gradient descent methods and to\nfurther improve their practical performance for machine learning and deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 07:07:47 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Deng", "Qi", ""], ["Cheng", "Yi", ""], ["Lan", "Guanghui", ""]]}, {"id": "1810.00555", "submitter": "Theofanis Karaletsos", "authors": "Theofanis Karaletsos, Peter Dayan, Zoubin Ghahramani", "title": "Probabilistic Meta-Representations Of Neural Networks", "comments": "presented at UAI 2018 Uncertainty In Deep Learning Workshop (UDL AUG.\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Bayesian treatments of neural networks are typically characterized\nby weak prior and approximate posterior distributions according to which all\nthe weights are drawn independently. Here, we consider a richer prior\ndistribution in which units in the network are represented by latent variables,\nand the weights between units are drawn conditionally on the values of the\ncollection of those variables. This allows rich correlations between related\nweights, and can be seen as realizing a function prior with a Bayesian\ncomplexity regularizer ensuring simple solutions. We illustrate the resulting\nmeta-representations and representations, elucidating the power of this prior.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 07:15:32 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Karaletsos", "Theofanis", ""], ["Dayan", "Peter", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1810.00597", "submitter": "Danilo Jimenez Rezende", "authors": "Danilo Jimenez Rezende and Fabio Viola", "title": "Taming VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of remarkable progress in deep latent variable generative modeling,\ntraining still remains a challenge due to a combination of optimization and\ngeneralization issues. In practice, a combination of heuristic algorithms (such\nas hand-crafted annealing of KL-terms) is often used in order to achieve the\ndesired results, but such solutions are not robust to changes in model\narchitecture or dataset. The best settings can often vary dramatically from one\nproblem to another, which requires doing expensive parameter sweeps for each\nnew case. Here we develop on the idea of training VAEs with additional\nconstraints as a way to control their behaviour. We first present a detailed\ntheoretical analysis of constrained VAEs, expanding our understanding of how\nthese models work. We then introduce and analyze a practical algorithm termed\nGeneralized ELBO with Constrained Optimization, GECO. The main advantage of\nGECO for the machine learning practitioner is a more intuitive, yet principled,\nprocess of tuning the loss. This involves defining of a set of constraints,\nwhich typically have an explicit relation to the desired model performance, in\ncontrast to tweaking abstract hyper-parameters which implicitly affect the\nmodel behavior. Encouraging experimental results in several standard datasets\nindicate that GECO is a very robust and effective tool to balance\nreconstruction and compression constraints.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 09:53:41 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Rezende", "Danilo Jimenez", ""], ["Viola", "Fabio", ""]]}, {"id": "1810.00609", "submitter": "Anbumani Subramanian", "authors": "Adithya Subramanian, Anbumani Subramanian", "title": "One-Click Annotation with Guided Hierarchical Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The increase in data collection has made data annotation an interesting and\nvaluable task in the contemporary world. This paper presents a new methodology\nfor quickly annotating data using click-supervision and hierarchical object\ndetection. The proposed work is semi-automatic in nature where the task of\nannotations is split between the human and a neural network. We show that our\nimproved method of annotation reduces the time, cost and mental stress on a\nhuman annotator. The research also highlights how our method performs better\nthan the current approach in different circumstances such as variation in\nnumber of objects, object size and different datasets. Our approach also\nproposes a new method of using object detectors making it suitable for data\nannotation task. The experiment conducted on PASCAL VOC dataset revealed that\nannotation created from our approach achieves a mAP of 0.995 and a recall of\n0.903. The Our Approach has shown an overall improvement by 8.5%, 18.6% in mean\naverage precision and recall score for KITTI and 69.6%, 36% for CITYSCAPES\ndataset. The proposed framework is 3-4 times faster as compared to the standard\nannotation method.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 10:41:35 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Subramanian", "Adithya", ""], ["Subramanian", "Anbumani", ""]]}, {"id": "1810.00619", "submitter": "Thomas Deselaers", "authors": "Victor Carbune, Thierry Coppey, Alexander Daryin, Thomas Deselaers,\n  Nikhil Sarda, Jay Yagnik", "title": "SmartChoices: Hybridizing Programming and Machine Learning", "comments": "published at the Reinforcement Learning for Real Life (RL4RealLife)\n  Workshop in the 36th International Conference on Machine Learning (ICML),\n  Long Beach, California, USA, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present SmartChoices, an approach to making machine learning (ML) a first\nclass citizen in programming languages which we see as one way to lower the\nentrance cost to applying ML to problems in new domains. There is a growing\ndivide in approaches to building systems: on the one hand, programming\nleverages human experts to define a system while on the other hand behavior is\nlearned from data in machine learning. We propose to hybridize these two by\nproviding a 3-call API which we expose through an object called SmartChoice. We\ndescribe the SmartChoices-interface, how it can be used in programming with\nminimal code changes, and demonstrate that it is an easy to use but still\npowerful tool by demonstrating improvements over not using ML at all on three\nalgorithmic problems: binary search, QuickSort, and caches. In these three\nexamples, we replace the commonly used heuristics with an ML model entirely\nencapsulated within a SmartChoice and thus requiring minimal code changes. As\nopposed to previous work applying ML to algorithmic problems, our proposed\napproach does not require to drop existing implementations but seamlessly\nintegrates into the standard software development workflow and gives full\ncontrol to the software developer over how ML methods are applied. Our\nimplementation relies on standard Reinforcement Learning (RL) methods. To learn\nfaster, we use the heuristic function, which they are replacing, as an initial\nfunction. We show how this initial function can be used to speed up and\nstabilize learning while providing a safety net that prevents performance to\nbecome substantially worse -- allowing for a safe deployment in critical\napplications in real life.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 11:14:22 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 11:24:58 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 18:20:51 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Carbune", "Victor", ""], ["Coppey", "Thierry", ""], ["Daryin", "Alexander", ""], ["Deselaers", "Thomas", ""], ["Sarda", "Nikhil", ""], ["Yagnik", "Jay", ""]]}, {"id": "1810.00656", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Lorenz Linhardt, Walter Karlen", "title": "Perfect Match: A Simple Method for Learning Representations For\n  Counterfactual Inference With Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations for counterfactual inference from observational data\nis of high practical relevance for many domains, such as healthcare, public\npolicy and economics. Counterfactual inference enables one to answer \"What\nif...?\" questions, such as \"What would be the outcome if we gave this patient\ntreatment $t_1$?\". However, current methods for training neural networks for\ncounterfactual inference on observational data are either overly complex,\nlimited to settings with only two available treatments, or both. Here, we\npresent Perfect Match (PM), a method for training neural networks for\ncounterfactual inference that is easy to implement, compatible with any\narchitecture, does not add computational complexity or hyperparameters, and\nextends to any number of treatments. PM is based on the idea of augmenting\nsamples within a minibatch with their propensity-matched nearest neighbours.\nOur experiments demonstrate that PM outperforms a number of more complex\nstate-of-the-art methods in inferring counterfactual outcomes across several\nbenchmarks, particularly in settings with many treatments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 12:31:32 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 11:35:15 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 00:47:27 GMT"}, {"version": "v4", "created": "Sun, 3 Feb 2019 22:46:24 GMT"}, {"version": "v5", "created": "Mon, 27 May 2019 16:47:19 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Schwab", "Patrick", ""], ["Linhardt", "Lorenz", ""], ["Karlen", "Walter", ""]]}, {"id": "1810.00664", "submitter": "Omid Shahmirzadi", "authors": "Omid Shahmirzadi, Adam Lugowski and Kenneth Younge", "title": "Text Similarity in Vector Space Models: A Comparative Study", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic measurement of semantic text similarity is an important task in\nnatural language processing. In this paper, we evaluate the performance of\ndifferent vector space models to perform this task. We address the real-world\nproblem of modeling patent-to-patent similarity and compare TFIDF (and related\nextensions), topic models (e.g., latent semantic indexing), and neural models\n(e.g., paragraph vectors). Contrary to expectations, the added computational\ncost of text embedding methods is justified only when: 1) the target text is\ncondensed; and 2) the similarity comparison is trivial. Otherwise, TFIDF\nperforms surprisingly well in other cases: in particular for longer and more\ntechnical texts or for making finer-grained distinctions between nearest\nneighbors. Unexpectedly, extensions to the TFIDF method, such as adding noun\nphrases or calculating term weights incrementally, were not helpful in our\ncontext.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 10:54:52 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shahmirzadi", "Omid", ""], ["Lugowski", "Adam", ""], ["Younge", "Kenneth", ""]]}, {"id": "1810.00668", "submitter": "Sudhanshu Kasewa", "authors": "Sudhanshu Kasewa and Pontus Stenetorp and Sebastian Riedel", "title": "Wronging a Right: Generating Better Errors to Improve Grammatical Error\n  Detection", "comments": "Accepted as a short paper at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical error correction, like other machine learning tasks, greatly\nbenefits from large quantities of high quality training data, which is\ntypically expensive to produce. While writing a program to automatically\ngenerate realistic grammatical errors would be difficult, one could learn the\ndistribution of naturallyoccurring errors and attempt to introduce them into\nother datasets. Initial work on inducing errors in this way using statistical\nmachine translation has shown promise; we investigate cheaply constructing\nsynthetic samples, given a small corpus of human-annotated data, using an\noff-the-rack attentive sequence-to-sequence model and a straight-forward\npost-processing procedure. Our approach yields error-filled artificial data\nthat helps a vanilla bi-directional LSTM to outperform the previous state of\nthe art at grammatical error detection, and a previously introduced model to\ngain further improvements of over 5% $F_{0.5}$ score. When attempting to\ndetermine if a given sentence is synthetic, a human annotator at best achieves\n39.39 $F_1$ score, indicating that our model generates mostly human-like\ninstances.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 14:25:40 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Kasewa", "Sudhanshu", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1810.00679", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Amanjit Kainth, Siamak Shakeri, Christopher Winestock,\n  Abdel-rahman Mohamed, Ruhi Sarikaya", "title": "Direct optimization of F-measure for retrieval-based personal question\n  answering", "comments": "accepted at SLT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in spoken language technologies and the introduction of many\ncustomer facing products, have given rise to a wide customer reliance on smart\npersonal assistants for many of their daily tasks. In this paper, we present a\nsystem to reduce users' cognitive load by extending personal assistants with\nlong-term personal memory where users can store and retrieve by voice,\narbitrary pieces of information. The problem is framed as a neural retrieval\nbased question answering system where answers are selected from previously\nstored user memories. We propose to directly optimize the end-to-end retrieval\nperformance, measured by the F1-score, using reinforcement learning, leading to\nbetter performance on our experimental test set(s).\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 00:51:24 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Fakoor", "Rasool", ""], ["Kainth", "Amanjit", ""], ["Shakeri", "Siamak", ""], ["Winestock", "Christopher", ""], ["Mohamed", "Abdel-rahman", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1810.00717", "submitter": "Seyed Amin Fadaee", "authors": "Seyed Amin Fadaee, Maryam Amir Haeri", "title": "Classification Using Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction in a graph is the problem of detecting the missing links that\nwould be formed in the near future. Using a graph representation of the data,\nwe can convert the problem of classification to the problem of link prediction\nwhich aims at finding the missing links between the unlabeled data (unlabeled\nnodes) and their classes. To our knowledge, despite the fact that numerous\nalgorithms use the graph representation of the data for classification, none\nare using link prediction as the heart of their classifying procedure. In this\nwork, we propose a novel algorithm called CULP (Classification Using Link\nPrediction) which uses a new structure namely Label Embedded Graph or LEG and a\nlink predictor to find the class of the unlabeled data. Different link\npredictors along with Compatibility Score - a new link predictor we proposed\nthat is designed specifically for our settings - has been used and showed\npromising results for classifying different datasets. This paper further\nimproved CULP by designing an extension called CULM which uses a majority vote\n(hence the M in the acronym) procedure with weights proportional to the\npredictions' confidences to use the predictive power of multiple link\npredictors and also exploits the low level features of the data. Extensive\nexperimental evaluations shows that both CULP and CULM are highly accurate and\ncompetitive with the cutting edge graph classifiers and general classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:21:33 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Fadaee", "Seyed Amin", ""], ["Haeri", "Maryam Amir", ""]]}, {"id": "1810.00737", "submitter": "Adrian Rivera Cardoso", "authors": "Adrian Rivera Cardoso, Huan Xu", "title": "Risk-Averse Stochastic Convex Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in clinical trials and finance, we study the\nproblem of online convex optimization (with bandit feedback) where the decision\nmaker is risk-averse. We provide two algorithms to solve this problem. The\nfirst one is a descent-type algorithm which is easy to implement. The second\nalgorithm, which combines the ellipsoid method and a center point device,\nachieves (almost) optimal regret bounds with respect to the number of rounds.\nTo the best of our knowledge this is the first attempt to address risk-aversion\nin the online convex bandit problem.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:48:42 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Cardoso", "Adrian Rivera", ""], ["Xu", "Huan", ""]]}, {"id": "1810.00740", "submitter": "Chuanbiao Song", "authors": "Chuanbiao Song and Kun He and Liwei Wang and John E. Hopcroft", "title": "Improving the Generalization of Adversarial Training with Domain\n  Adaptation", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By injecting adversarial examples into training data, adversarial training is\npromising for improving the robustness of deep learning models. However, most\nexisting adversarial training approaches are based on a specific type of\nadversarial attack. It may not provide sufficiently representative samples from\nthe adversarial domain, leading to a weak generalization ability on adversarial\nexamples from other attacks. Moreover, during the adversarial training,\nadversarial perturbations on inputs are usually crafted by fast single-step\nadversaries so as to scale to large datasets. This work is mainly focused on\nthe adversarial training yet efficient FGSM adversary. In this scenario, it is\ndifficult to train a model with great generalization due to the lack of\nrepresentative adversarial samples, aka the samples are unable to accurately\nreflect the adversarial domain. To alleviate this problem, we propose a novel\nAdversarial Training with Domain Adaptation (ATDA) method. Our intuition is to\nregard the adversarial training on FGSM adversary as a domain adaption task\nwith limited number of target domain samples. The main idea is to learn a\nrepresentation that is semantically meaningful and domain invariant on the\nclean domain as well as the adversarial domain. Empirical evaluations on\nFashion-MNIST, SVHN, CIFAR-10 and CIFAR-100 demonstrate that ATDA can greatly\nimprove the generalization of adversarial training and the smoothness of the\nlearned models, and outperforms state-of-the-art methods on standard benchmark\ndatasets. To show the transfer ability of our method, we also extend ATDA to\nthe adversarial training on iterative attacks such as PGD-Adversial Training\n(PAT) and the defense performance is improved considerably.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:52:08 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 09:00:02 GMT"}, {"version": "v3", "created": "Wed, 24 Oct 2018 13:29:39 GMT"}, {"version": "v4", "created": "Mon, 10 Dec 2018 08:43:35 GMT"}, {"version": "v5", "created": "Thu, 17 Jan 2019 05:13:22 GMT"}, {"version": "v6", "created": "Mon, 11 Mar 2019 11:22:56 GMT"}, {"version": "v7", "created": "Fri, 15 Mar 2019 08:37:29 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Song", "Chuanbiao", ""], ["He", "Kun", ""], ["Wang", "Liwei", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1810.00760", "submitter": "Gary B\\'ecigneul", "authors": "Gary B\\'ecigneul, Octavian-Eugen Ganea", "title": "Riemannian Adaptive Optimization Methods", "comments": "Accepted at International Conference on Learning Representations\n  (ICLR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several first order stochastic optimization methods commonly used in the\nEuclidean domain such as stochastic gradient descent (SGD), accelerated\ngradient descent or variance reduced methods have already been adapted to\ncertain Riemannian settings. However, some of the most popular of these\noptimization tools - namely Adam , Adagrad and the more recent Amsgrad - remain\nto be generalized to Riemannian manifolds. We discuss the difficulty of\ngeneralizing such adaptive schemes to the most agnostic Riemannian setting, and\nthen provide algorithms and convergence proofs for geodesically convex\nobjectives in the particular case of a product of Riemannian manifolds, in\nwhich adaptivity is implemented across manifolds in the cartesian product. Our\ngeneralization is tight in the sense that choosing the Euclidean space as\nRiemannian manifold yields the same algorithms and regret bounds as those that\nwere already known for the standard algorithms. Experimentally, we show faster\nconvergence and to a lower train loss value for Riemannian adaptive methods\nover their corresponding baselines on the realistic task of embedding the\nWordNet taxonomy in the Poincare ball.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 15:31:36 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 02:32:53 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["B\u00e9cigneul", "Gary", ""], ["Ganea", "Octavian-Eugen", ""]]}, {"id": "1810.00774", "submitter": "Rasmus Jones", "authors": "Rasmus T. Jones, Tobias A. Eriksson, Metodi P. Yankov, Benjamin J.\n  Puttnam, Georg Rademacher, Ruben S. Luis and Darko Zibar", "title": "Geometric Constellation Shaping for Fiber Optic Communication Systems\n  via End-to-end Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an unsupervised machine learning method for geometric\nconstellation shaping is investigated. By embedding a differentiable fiber\nchannel model within two neural networks, the learning algorithm is optimizing\nfor a geometric constellation shape. The learned constellations yield improved\nperformance to state-of-the-art geometrically shaped constellations, and\ninclude an implicit trade-off between amplification noise and nonlinear\neffects. Further, the method allows joint optimization of system parameters,\nsuch as the optimal launch power, simultaneously with the constellation shape.\nAn experimental demonstration validates the findings. Improved performances are\nreported, up to 0.13 bit/4D in simulation and experimentally up to 0.12 bit/4D.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 15:53:19 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Jones", "Rasmus T.", ""], ["Eriksson", "Tobias A.", ""], ["Yankov", "Metodi P.", ""], ["Puttnam", "Benjamin J.", ""], ["Rademacher", "Georg", ""], ["Luis", "Ruben S.", ""], ["Zibar", "Darko", ""]]}, {"id": "1810.00787", "submitter": "Veronika Rockova", "authors": "Veronika Rockova and Enakshi Saha", "title": "On Theory for BART", "comments": "22", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a statistical paradigm built on the premise that many\nweak learners can perform exceptionally well when deployed collectively. The\nBART method of Chipman et al. (2010) is a prominent example of Bayesian\nensemble learning, where each learner is a tree. Due to its impressive\nperformance, BART has received a lot of attention from practitioners. Despite\nits wide popularity, however, theoretical studies of BART have begun emerging\nonly very recently. Laying the foundations for the theoretical analysis of\nBayesian forests, Rockova and van der Pas (2017) showed optimal posterior\nconcentration under conditionally uniform tree priors. These priors deviate\nfrom the actual priors implemented in BART. Here, we study the exact BART prior\nand propose a simple modification so that it also enjoys optimality properties.\nTo this end, we dive into branching process theory. We obtain tail bounds for\nthe distribution of total progeny under heterogeneous Galton-Watson (GW)\nprocesses exploiting their connection to random walks. We conclude with a\nresult stating the optimal rate of posterior convergence for BART.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:18:59 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 17:04:10 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Rockova", "Veronika", ""], ["Saha", "Enakshi", ""]]}, {"id": "1810.00803", "submitter": "Dennis Forster", "authors": "Florian Hirschberger, Dennis Forster, J\\\"org L\\\"ucke", "title": "Large Scale Clustering with Variational EM for Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we efficiently find large numbers of clusters in large data sets with\nhigh-dimensional data points? Our aim is to explore the current efficiency and\nlarge-scale limits in fitting a parametric model for clustering to data\ndistributions. To do so, we combine recent lines of research which have\npreviously focused on separate specific methods for complexity reduction. We\nfirst show theoretically how the clustering objective of variational EM (which\nreduces complexity for many clusters) can be combined with coreset objectives\n(which reduce complexity for many data points). Secondly, we realize a concrete\nhighly efficient iterative procedure which combines and translates the\ntheoretical complexity gains of truncated variational EM and coresets into a\npractical algorithm. For very large scales, the high efficiency of parameter\nupdates then requires (A) highly efficient coreset construction and (B) highly\nefficient initialization procedures (seeding) in order to avoid computational\nbottlenecks. Fortunately very efficient coreset construction has become\navailable in the form of light-weight coresets, and very efficient\ninitialization has become available in the form of AFK-MC$^2$ seeding. The\nresulting algorithm features balanced computational costs across all\nconstituting components. In applications to standard large-scale benchmarks for\nclustering, we investigate the algorithm's efficiency/quality trade-off.\nCompared to the best recent approaches, we observe speedups of up to one order\nof magnitude, and up to two orders of magnitude compared to the $k$-means++\nbaseline. To demonstrate that the observed efficiency enables previously\nconsidered unfeasible applications, we cluster the entire and unscaled 80 Mio.\nTiny Images dataset into up to 32,000 clusters. To the knowledge of the\nauthors, this represents the largest scale fit of a parametric data model for\nclustering reported so far.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:34:51 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 12:09:15 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 16:12:38 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Hirschberger", "Florian", ""], ["Forster", "Dennis", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "1810.00821", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Angjoo Kanazawa, Sam Toyer, Pieter Abbeel, Sergey Levine", "title": "Variational Discriminator Bottleneck: Improving Imitation Learning,\n  Inverse RL, and GANs by Constraining Information Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial learning methods have been proposed for a wide range of\napplications, but the training of adversarial models can be notoriously\nunstable. Effectively balancing the performance of the generator and\ndiscriminator is critical, since a discriminator that achieves very high\naccuracy will produce relatively uninformative gradients. In this work, we\npropose a simple and general technique to constrain information flow in the\ndiscriminator by means of an information bottleneck. By enforcing a constraint\non the mutual information between the observations and the discriminator's\ninternal representation, we can effectively modulate the discriminator's\naccuracy and maintain useful and informative gradients. We demonstrate that our\nproposed variational discriminator bottleneck (VDB) leads to significant\nimprovements across three distinct application areas for adversarial learning\nalgorithms. Our primary evaluation studies the applicability of the VDB to\nimitation learning of dynamic continuous control skills, such as running. We\nshow that our method can learn such skills directly from \\emph{raw} video\ndemonstrations, substantially outperforming prior adversarial imitation\nlearning methods. The VDB can also be combined with adversarial inverse\nreinforcement learning to learn parsimonious reward functions that can be\ntransferred and re-optimized in new settings. Finally, we demonstrate that VDB\ncan train GANs more effectively for image generation, improving upon a number\nof prior stabilization methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:02:24 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 07:18:08 GMT"}, {"version": "v3", "created": "Sat, 29 Dec 2018 00:03:45 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 02:41:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Peng", "Xue Bin", ""], ["Kanazawa", "Angjoo", ""], ["Toyer", "Sam", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.00825", "submitter": "Juho Lee", "authors": "Juho Lee, Yoonho Lee, Jungtaek Kim, Adam R. Kosiorek, Seungjin Choi,\n  Yee Whye Teh", "title": "Set Transformer: A Framework for Attention-based Permutation-Invariant\n  Neural Networks", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning tasks such as multiple instance learning, 3D shape\nrecognition, and few-shot image classification are defined on sets of\ninstances. Since solutions to such problems do not depend on the order of\nelements of the set, models used to address them should be permutation\ninvariant. We present an attention-based neural network module, the Set\nTransformer, specifically designed to model interactions among elements in the\ninput set. The model consists of an encoder and a decoder, both of which rely\non attention mechanisms. In an effort to reduce computational complexity, we\nintroduce an attention scheme inspired by inducing point methods from sparse\nGaussian process literature. It reduces the computation time of self-attention\nfrom quadratic to linear in the number of elements in the set. We show that our\nmodel is theoretically attractive and we evaluate it on a range of tasks,\ndemonstrating the state-of-the-art performance compared to recent methods for\nset-structured data.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:10:03 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 10:19:12 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 06:05:29 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Lee", "Juho", ""], ["Lee", "Yoonho", ""], ["Kim", "Jungtaek", ""], ["Kosiorek", "Adam R.", ""], ["Choi", "Seungjin", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1810.00826", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka", "title": "How Powerful are Graph Neural Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are an effective framework for representation\nlearning of graphs. GNNs follow a neighborhood aggregation scheme, where the\nrepresentation vector of a node is computed by recursively aggregating and\ntransforming representation vectors of its neighboring nodes. Many GNN variants\nhave been proposed and have achieved state-of-the-art results on both node and\ngraph classification tasks. However, despite GNNs revolutionizing graph\nrepresentation learning, there is limited understanding of their\nrepresentational properties and limitations. Here, we present a theoretical\nframework for analyzing the expressive power of GNNs to capture different graph\nstructures. Our results characterize the discriminative power of popular GNN\nvariants, such as Graph Convolutional Networks and GraphSAGE, and show that\nthey cannot learn to distinguish certain simple graph structures. We then\ndevelop a simple architecture that is provably the most expressive among the\nclass of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism\ntest. We empirically validate our theoretical findings on a number of graph\nclassification benchmarks, and demonstrate that our model achieves\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:11:31 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 07:44:16 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 19:15:54 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Xu", "Keyulu", ""], ["Hu", "Weihua", ""], ["Leskovec", "Jure", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1810.00828", "submitter": "Raaz Dwivedi", "authors": "Raaz Dwivedi, Nhat Ho, Koulik Khamaru, Michael I. Jordan, Martin J.\n  Wainwright, Bin Yu", "title": "Singularity, Misspecification, and the Convergence Rate of EM", "comments": "63 pages, 12 figures. The first three authors contributed equally to\n  this work. To appear in Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A line of recent work has analyzed the behavior of the\nExpectation-Maximization (EM) algorithm in the well-specified setting, in which\nthe population likelihood is locally strongly concave around its maximizing\nargument. Examples include suitably separated Gaussian mixture models and\nmixtures of linear regressions. We consider over-specified settings in which\nthe number of fitted components is larger than the number of components in the\ntrue distribution. Such misspecified settings can lead to singularity in the\nFisher information matrix, and moreover, the maximum likelihood estimator based\non $n$ i.i.d. samples in $d$ dimensions can have a non-standard\n$\\mathcal{O}((d/n)^{\\frac{1}{4}})$ rate of convergence. Focusing on the simple\nsetting of two-component mixtures fit to a $d$-dimensional Gaussian\ndistribution, we study the behavior of the EM algorithm both when the mixture\nweights are different (unbalanced case), and are equal (balanced case). Our\nanalysis reveals a sharp distinction between these two cases: in the former,\nthe EM algorithm converges geometrically to a point at Euclidean distance of\n$\\mathcal{O}((d/n)^{\\frac{1}{2}})$ from the true parameter, whereas in the\nlatter case, the convergence rate is exponentially slower, and the fixed point\nhas a much lower $\\mathcal{O}((d/n)^{\\frac{1}{4}})$ accuracy. Analysis of this\nsingular case requires the introduction of some novel techniques: in\nparticular, we make use of a careful form of localization in the associated\nempirical process, and develop a recursive argument to progressively sharpen\nthe statistical rate.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:16:36 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 01:30:19 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Dwivedi", "Raaz", ""], ["Ho", "Nhat", ""], ["Khamaru", "Koulik", ""], ["Jordan", "Michael I.", ""], ["Wainwright", "Martin J.", ""], ["Yu", "Bin", ""]]}, {"id": "1810.00839", "submitter": "Xiang Li", "authors": "Xiang Li, Qitian Chen, Xing Wang, Ning Guo, Nan Wu, Quanzheng Li", "title": "Network Modeling and Pathway Inference from Incomplete Data (\"PathInf\")", "comments": "Xiang Li, Qitian Che and Xing Wang contribute equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we developed a network inference method from incomplete data\n(\"PathInf\") , as massive and non-uniformly distributed missing values is a\ncommon challenge in practical problems. PathInf is a two-stages inference\nmodel. In the first stage, it applies a data summarization model based on\nmaximum likelihood to deal with the massive distributed missing values by\ntransforming the observation-wise items in the data into state matrix. In the\nsecond stage, transition pattern (i.e. pathway) among variables is inferred as\na graph inference problem solved by greedy algorithm with constraints. The\nproposed method was validated and compared with the state-of-art Bayesian\nnetwork method on the simulation data, and shown consistently superior\nperformance. By applying the PathInf on the lymph vascular metastasis data, we\nobtained the holistic pathways of the lymph node metastasis with novel\ndiscoveries on the jumping metastasis among nodes that are physically apart.\nThe discovery indicates the possible presence of sentinel node groups in the\nlung lymph nodes which have been previously speculated yet never found. The\npathway map can also improve the current dissection examination protocol for\nbetter individualized treatment planning, for higher diagnostic accuracy and\nreducing the patients trauma.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:31:34 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Li", "Xiang", ""], ["Chen", "Qitian", ""], ["Wang", "Xing", ""], ["Guo", "Ning", ""], ["Wu", "Nan", ""], ["Li", "Quanzheng", ""]]}, {"id": "1810.00845", "submitter": "Olli Saarikivi", "authors": "Roshan Dathathri, Olli Saarikivi, Hao Chen, Kim Laine, Kristin Lauter,\n  Saeed Maleki, Madanlal Musuvathi, Todd Mytkowicz", "title": "CHET: Compiler and Runtime for Homomorphic Evaluation of Tensor Programs", "comments": "Submitted to ASPLOS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Homomorphic Encryption (FHE) refers to a set of encryption schemes that\nallow computations to be applied directly on encrypted data without requiring a\nsecret key. This enables novel application scenarios where a client can safely\noffload storage and computation to a third-party cloud provider without having\nto trust the software and the hardware vendors with the decryption keys. Recent\nadvances in both FHE schemes and implementations have moved such applications\nfrom theoretical possibilities into the realm of practicalities.\n  This paper proposes a compact and well-reasoned interface called the\nHomomorphic Instruction Set Architecture (HISA) for developing FHE\napplications. Just as the hardware ISA interface enabled hardware advances to\nproceed independent of software advances in the compiler and language runtimes,\nHISA decouples compiler optimizations and runtimes for supporting FHE\napplications from advancements in the underlying FHE schemes.\n  This paper demonstrates the capabilities of HISA by building an end-to-end\nsoftware stack for evaluating neural network models on encrypted data. Our\nstack includes an end-to-end compiler, runtime, and a set of optimizations. Our\napproach shows generated code, on a set of popular neural network\narchitectures, is faster than hand-optimized implementations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:38:53 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Dathathri", "Roshan", ""], ["Saarikivi", "Olli", ""], ["Chen", "Hao", ""], ["Laine", "Kim", ""], ["Lauter", "Kristin", ""], ["Maleki", "Saeed", ""], ["Musuvathi", "Madanlal", ""], ["Mytkowicz", "Todd", ""]]}, {"id": "1810.00846", "submitter": "Yu-Guan Hsieh", "authors": "Yu-Guan Hsieh, Gang Niu, Masashi Sugiyama", "title": "Classification from Positive, Unlabeled and Biased Negative Data", "comments": "In Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In binary classification, there are situations where negative (N) data are\ntoo diverse to be fully labeled and we often resort to positive-unlabeled (PU)\nlearning in these scenarios. However, collecting a non-representative N set\nthat contains only a small portion of all possible N data can often be much\neasier in practice. This paper studies a novel classification framework which\nincorporates such biased N (bN) data in PU learning. We provide a method based\non empirical risk minimization to address this PUbN classification problem. Our\napproach can be regarded as a novel example-weighting algorithm, with the\nweight of each example computed through a preliminary step that draws\ninspiration from PU learning. We also derive an estimation error bound for the\nproposed method. Experimental results demonstrate the effectiveness of our\nalgorithm in not only PUbN learning scenarios but also ordinary PU learning\nscenarios on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:38:58 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 12:16:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Hsieh", "Yu-Guan", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1810.00859", "submitter": "Liu Liu", "authors": "Liu Liu, Lei Deng, Xing Hu, Maohua Zhu, Guoqi Li, Yufei Ding, Yuan Xie", "title": "Dynamic Sparse Graph for Efficient Deep Learning", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to execute deep neural networks (DNNs) with dynamic and sparse\ngraph (DSG) structure for compressive memory and accelerative execution during\nboth training and inference. The great success of DNNs motivates the pursuing\nof lightweight models for the deployment onto embedded devices. However, most\nof the previous studies optimize for inference while neglect training or even\ncomplicate it. Training is far more intractable, since (i) the neurons dominate\nthe memory cost rather than the weights in inference; (ii) the dynamic\nactivation makes previous sparse acceleration via one-off optimization on fixed\nweight invalid; (iii) batch normalization (BN) is critical for maintaining\naccuracy while its activation reorganization damages the sparsity. To address\nthese issues, DSG activates only a small amount of neurons with high\nselectivity at each iteration via a dimension-reduction search (DRS) and\nobtains the BN compatibility via a double-mask selection (DMS). Experiments\nshow significant memory saving (1.7-4.5x) and operation reduction (2.3-4.4x)\nwith little accuracy loss on various benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:55:43 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 02:32:25 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Liu", "Liu", ""], ["Deng", "Lei", ""], ["Hu", "Xing", ""], ["Zhu", "Maohua", ""], ["Li", "Guoqi", ""], ["Ding", "Yufei", ""], ["Xie", "Yuan", ""]]}, {"id": "1810.00861", "submitter": "Yu Bai", "authors": "Yu Bai, Yu-Xiang Wang, Edo Liberty", "title": "ProxQuant: Quantized Neural Networks via Proximal Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make deep neural networks feasible in resource-constrained environments\n(such as mobile devices), it is beneficial to quantize models by using\nlow-precision weights. One common technique for quantizing neural networks is\nthe straight-through gradient method, which enables back-propagation through\nthe quantization mapping. Despite its empirical success, little is understood\nabout why the straight-through gradient method works.\n  Building upon a novel observation that the straight-through gradient method\nis in fact identical to the well-known Nesterov's dual-averaging algorithm on a\nquantization constrained optimization problem, we propose a more principled\nalternative approach, called ProxQuant, that formulates quantized network\ntraining as a regularized learning problem instead and optimizes it via the\nprox-gradient method. ProxQuant does back-propagation on the underlying\nfull-precision vector and applies an efficient prox-operator in between\nstochastic gradient steps to encourage quantizedness. For quantizing ResNets\nand LSTMs, ProxQuant outperforms state-of-the-art results on binary\nquantization and is on par with state-of-the-art on multi-bit quantization. For\nbinary quantization, our analysis shows both theoretically and experimentally\nthat ProxQuant is more stable than the straight-through gradient method (i.e.\nBinaryConnect), challenging the indispensability of the straight-through\ngradient method and providing a powerful alternative.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:57:02 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 17:46:55 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 00:28:48 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Bai", "Yu", ""], ["Wang", "Yu-Xiang", ""], ["Liberty", "Edo", ""]]}, {"id": "1810.00867", "submitter": "Lingwei Xie", "authors": "Lingwei Xie, Song He, Shu Yang, Boyuan Feng, Kun Wan, Zhongnan Zhang,\n  Xiaochen Bo, Yufei Ding", "title": "Domain-Adversarial Multi-Task Framework for Novel Therapeutic Property\n  Prediction of Compounds", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of high-throughput technologies, parallel\nacquisition of large-scale drug-informatics data provides huge opportunities to\nimprove pharmaceutical research and development. One significant application is\nthe purpose prediction of small molecule compounds, aiming to specify\ntherapeutic properties of extensive purpose-unknown compounds and to repurpose\nnovel therapeutic properties of FDA-approved drugs. Such problem is very\nchallenging since compound attributes contain heterogeneous data with various\nfeature patterns such as drug fingerprint, drug physicochemical property, drug\nperturbation gene expression. Moreover, there is complex nonlinear dependency\namong heterogeneous data. In this paper, we propose a novel domain-adversarial\nmulti-task framework for integrating shared knowledge from multiple domains.\nThe framework utilizes the adversarial strategy to effectively learn target\nrepresentations and models their nonlinear dependency. Experiments on two\nreal-world datasets illustrate that the performance of our approach obtains an\nobvious improvement over competitive baselines. The novel therapeutic\nproperties of purpose-unknown compounds we predicted are mostly reported or\nbrought to the clinics. Furthermore, our framework can integrate various\nattributes beyond the three domains examined here and can be applied in the\nindustry for screening the purpose of huge amounts of as yet unidentified\ncompounds. Source codes of this paper are available on Github.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 23:58:23 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Xie", "Lingwei", ""], ["He", "Song", ""], ["Yang", "Shu", ""], ["Feng", "Boyuan", ""], ["Wan", "Kun", ""], ["Zhang", "Zhongnan", ""], ["Bo", "Xiaochen", ""], ["Ding", "Yufei", ""]]}, {"id": "1810.00869", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross", "title": "Training Machine Learning Models by Regularizing their Explanations", "comments": "Harvard CSE master's thesis; includes portions of arxiv:1703.03717\n  and arxiv:1711.09404", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are among the most accurate supervised learning methods in\nuse today. However, their opacity makes them difficult to trust in critical\napplications, especially when conditions in training may differ from those in\npractice. Recent efforts to develop explanations for neural networks and\nmachine learning models more generally have produced tools to shed light on the\nimplicit rules behind predictions. These tools can help us identify when models\nare right for the wrong reasons. However, they do not always scale to\nexplaining predictions for entire datasets, are not always at the right level\nof abstraction, and most importantly cannot correct the problems they reveal.\nIn this thesis, we explore the possibility of training machine learning models\n(with a particular focus on neural networks) using explanations themselves. We\nconsider approaches where models are penalized not only for making incorrect\npredictions but also for providing explanations that are either inconsistent\nwith domain knowledge or overly complex. These methods let us train models\nwhich can not only provide more interpretable rationales for their predictions\nbut also generalize better when training data is confounded or meaningfully\ndifferent from test data (even adversarially so).\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 17:43:21 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Ross", "Andrew Slavin", ""]]}, {"id": "1810.00873", "submitter": "Louis Mandel", "authors": "Guillaume Baudart, Javier Burroni, Martin Hirzel, Louis Mandel,\n  Avraham Shinnar", "title": "Compiling Stan to Generative Probabilistic Languages and Extension to\n  Deep Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stan is a probabilistic programming language that is popular in the\nstatistics community, with a high-level syntax for expressing probabilistic\nmodels. Stan differs by nature from generative probabilistic programming\nlanguages like Church, Anglican, or Pyro. This paper presents a comprehensive\ncompilation scheme to compile any Stan model to a generative language and\nproves its correctness. We use our compilation scheme to build two new backends\nfor the Stanc3 compiler targeting Pyro and NumPyro. Experimental results show\nthat the NumPyro backend yields a 2.3x speedup compared to Stan in geometric\nmean over 26 benchmarks. Building on Pyro we extend Stan with support for\nexplicit variational inference guides and deep probabilistic models. That way,\nusers familiar with Stan get access to new features without having to learn a\nfundamentally new language.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 15:39:53 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 20:45:47 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 16:29:27 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2021 20:51:14 GMT"}, {"version": "v5", "created": "Sun, 11 Apr 2021 15:34:02 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Baudart", "Guillaume", ""], ["Burroni", "Javier", ""], ["Hirzel", "Martin", ""], ["Mandel", "Louis", ""], ["Shinnar", "Avraham", ""]]}, {"id": "1810.00919", "submitter": "Irene Epifanio", "authors": "Jes\\'us Moliner, Irene Epifanio", "title": "Robust multivariate and functional archetypal analysis with application\n  to financial time series analysis", "comments": "Physica A: Statistical Mechanics and its Applications, 2019", "journal-ref": null, "doi": "10.1016/j.physa.2018.12.036", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archetypal analysis approximates data by means of mixtures of actual extreme\ncases (archetypoids) or archetypes, which are a convex combination of cases in\nthe data set. Archetypes lie on the boundary of the convex hull. This makes the\nanalysis very sensitive to outliers. A robust methodology by means of\nM-estimators for classical multivariate and functional data is proposed. This\nunsupervised methodology allows complex data to be understood even by\nnon-experts. The performance of the new procedure is assessed in a simulation\nstudy, where a comparison with a previous methodology for the multivariate case\nis also carried out, and our proposal obtains favorable results. Finally,\nrobust bivariate functional archetypoid analysis is applied to a set of\ncompanies in the S\\&P 500 described by two time series of stock quotes. A new\ngraphic representation is also proposed to visualize the results. The analysis\nshows how the information can be easily interpreted and how even non-experts\ncan gain a qualitative understanding of the data.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 18:48:26 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 17:18:57 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Moliner", "Jes\u00fas", ""], ["Epifanio", "Irene", ""]]}, {"id": "1810.00946", "submitter": "Makoto Onizuka", "authors": "Seiji Maekawa, Koh Takeuch, Makoto Onizuka", "title": "Non-linear Attributed Graph Clustering by Symmetric NMF with PU Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the clustering problem of attributed graphs. Our challenge is how\nwe can design an effective and efficient clustering method that precisely\ncaptures the hidden relationship between the topology and the attributes in\nreal-world graphs. We propose Non-linear Attributed Graph Clustering by\nSymmetric Non-negative Matrix Factorization with Positive Unlabeled Learning.\nThe features of our method are three holds. 1) it learns a non-linear\nprojection function between the different cluster assignments of the topology\nand the attributes of graphs so as to capture the complicated relationship\nbetween the topology and the attributes in real-world graphs, 2) it leverages\nthe positive unlabeled learning to take the effect of partially observed\npositive edges into the cluster assignment, and 3) it achieves efficient\ncomputational complexity, $O((n^2+mn)kt)$, where $n$ is the vertex size, $m$ is\nthe attribute size, $k$ is the number of clusters, and $t$ is the number of\niterations for learning the cluster assignment. We conducted experiments\nextensively for various clustering methods with various real datasets to\nvalidate that our method outperforms the former clustering methods regarding\nthe clustering quality.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 12:05:43 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Maekawa", "Seiji", ""], ["Takeuch", "Koh", ""], ["Onizuka", "Makoto", ""]]}, {"id": "1810.00950", "submitter": "Ashutosh Trivedi", "authors": "Ernst Moritz Hahn and Mateo Perez and Sven Schewe and Fabio Somenzi\n  and Ashutosh Trivedi and Dominik Wojtczak", "title": "Omega-Regular Objectives in Model-Free Reinforcement Learning", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first solution for model-free reinforcement learning of\n{\\omega}-regular objectives for Markov decision processes (MDPs). We present a\nconstructive reduction from the almost-sure satisfaction of {\\omega}-regular\nobjectives to an almost- sure reachability problem and extend this technique to\nlearning how to control an unknown model so that the chance of satisfying the\nobjective is maximized. A key feature of our technique is the compilation of\n{\\omega}-regular properties into limit- deterministic Buechi automata instead\nof the traditional Rabin automata; this choice sidesteps difficulties that have\nmarred previous proposals. Our approach allows us to apply model-free,\noff-the-shelf reinforcement learning algorithms to compute optimal strategies\nfrom the observations of the MDP. We present an experimental evaluation of our\ntechnique on benchmark learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 18:04:56 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Hahn", "Ernst Moritz", ""], ["Perez", "Mateo", ""], ["Schewe", "Sven", ""], ["Somenzi", "Fabio", ""], ["Trivedi", "Ashutosh", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "1810.00953", "submitter": "Adam Oberman", "authors": "Chris Finlay, Adam Oberman, Bilal Abbasi", "title": "Improved robustness to adversarial examples using Lipschitz\n  regularization of the loss", "comments": "Merged with arXiv:1808.09540", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We augment adversarial training (AT) with worst case adversarial training\n(WCAT) which improves adversarial robustness by 11% over the current\nstate-of-the-art result in the $\\ell_2$ norm on CIFAR-10. We obtain verifiable\naverage case and worst case robustness guarantees, based on the expected and\nmaximum values of the norm of the gradient of the loss. We interpret\nadversarial training as Total Variation Regularization, which is a fundamental\ntool in mathematical image processing, and WCAT as Lipschitz regularization.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:02:00 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 16:08:46 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 16:01:04 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 14:56:57 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Finlay", "Chris", ""], ["Oberman", "Adam", ""], ["Abbasi", "Bilal", ""]]}, {"id": "1810.00974", "submitter": "Wenbo Zhao", "authors": "Shahan Ali Memon, Wenbo Zhao, Bhiksha Raj, Rita Singh", "title": "Neural Regression Trees", "comments": "Accepted by The 2019 International Joint Conference on Neural\n  Networks (IJCNN). To be published on IEEE. 8 pages, 4 figures", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852133", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression-via-Classification (RvC) is the process of converting a regression\nproblem to a classification one. Current approaches for RvC use ad-hoc\ndiscretization strategies and are suboptimal. We propose a neural regression\ntree model for RvC. In this model, we employ a joint optimization framework\nwhere we learn optimal discretization thresholds while simultaneously\noptimizing the features for each node in the tree. We empirically show the\nvalidity of our model by testing it on two challenging regression tasks where\nwe establish the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:52:38 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 21:09:38 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Memon", "Shahan Ali", ""], ["Zhao", "Wenbo", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1810.00997", "submitter": "Victor Gabillon", "authors": "Peter L. Bartlett, Victor Gabillon, Michal Valko", "title": "A simple parameter-free and adaptive approach to optimization under a\n  minimal local smoothness assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimizing a function under a \\emph{budgeted number\nof evaluations}. We only assume that the function is \\emph{locally} smooth\naround one of its global optima. The difficulty of optimization is measured in\nterms of 1) the amount of \\emph{noise} $b$ of the function evaluation and 2)\nthe local smoothness, $d$, of the function. A smaller $d$ results in smaller\noptimization error. We come with a new, simple, and parameter-free approach.\nFirst, for all values of $b$ and $d$, this approach recovers at least the\nstate-of-the-art regret guarantees. Second, our approach additionally obtains\nthese results while being \\textit{agnostic} to the values of both $b$ and $d$.\nThis leads to the first algorithm that naturally adapts to an \\textit{unknown}\nrange of noise $b$ and leads to significant improvements in a moderate and\nlow-noise regime. Third, our approach also obtains a remarkable improvement\nover the state-of-the-art SOO algorithm when the noise is very low which\nincludes the case of optimization under deterministic feedback ($b=0$). There,\nunder our minimal local smoothness assumption, this improvement is of\nexponential magnitude and holds for a class of functions that covers the vast\nmajority of functions that practitioners optimize ($d=0$). We show that our\nalgorithmic improvement is borne out in experiments as we empirically show\nfaster convergence on common benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 22:14:43 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 11:13:56 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Gabillon", "Victor", ""], ["Valko", "Michal", ""]]}, {"id": "1810.01008", "submitter": "Martin Loncaric", "authors": "Martin Loncaric and Bowei Liu and Ryan Weber", "title": "Learning Hash Codes via Hamming Distance Targets", "comments": "8 pages, overhaul of our previous submission Convolutional Hashing\n  for Automated Scene Matching", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a powerful new loss function and training scheme for learning\nbinary hash codes with any differentiable model and similarity function. Our\nloss function improves over prior methods by using log likelihood loss on top\nof an accurate approximation for the probability that two inputs fall within a\nHamming distance target. Our novel training scheme obtains a good estimate of\nthe true gradient by better sampling inputs and evaluating loss terms between\nall pairs of inputs in each minibatch. To fully leverage the resulting hashes,\nwe use multi-indexing. We demonstrate that these techniques provide large\nimprovements to a similarity search tasks. We report the best results to date\non competitive information retrieval tasks for ImageNet and SIFT 1M, improving\nMAP from 73% to 84% and reducing query cost by a factor of 2-8, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 23:03:27 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Loncaric", "Martin", ""], ["Liu", "Bowei", ""], ["Weber", "Ryan", ""]]}, {"id": "1810.01018", "submitter": "Zhezhi He", "authors": "Zhezhi He, Deliang Fan", "title": "Simultaneously Optimizing Weight and Quantizer of Ternary Neural Network\n  using Truncated Gaussian Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, Deep convolution neural network has achieved great success\nin many artificial intelligence applications. However, its enormous model size\nand massive computation cost have become the main obstacle for deployment of\nsuch powerful algorithm in the low power and resource-limited mobile systems.\nAs the countermeasure to this problem, deep neural networks with ternarized\nweights (i.e. -1, 0, +1) have been widely explored to greatly reduce the model\nsize and computational cost, with limited accuracy degradation. In this work,\nwe propose a novel ternarized neural network training method which\nsimultaneously optimizes both weights and quantizer during training,\ndifferentiating from prior works. Instead of fixed and uniform weight\nternarization, we are the first to incorporate the thresholds of weight\nternarization into a closed-form representation using the truncated Gaussian\napproximation, enabling simultaneous optimization of weights and quantizer\nthrough back-propagation training. With both of the first and last layer\nternarized, the experiments on the ImageNet classification task show that our\nternarized ResNet-18/34/50 only has 3.9/2.52/2.16% accuracy degradation in\ncomparison to the full-precision counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 00:04:20 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["He", "Zhezhi", ""], ["Fan", "Deliang", ""]]}, {"id": "1810.01021", "submitter": "Amir Gholami", "authors": "Zhewei Yao, Amir Gholami, Daiyaan Arfeen, Richard Liaw, Joseph\n  Gonzalez, Kurt Keutzer, Michael Mahoney", "title": "Large batch size training of neural networks with adversarial training\n  and second-order information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most straightforward method to accelerate Stochastic Gradient Descent\n(SGD) computation is to distribute the randomly selected batch of inputs over\nmultiple processors. To keep the distributed processors fully utilized requires\ncommensurately growing the batch size. However, large batch training often\nleads to poorer generalization. A recently proposed solution for this problem\nis to use adaptive batch sizes in SGD. In this case, one starts with a small\nnumber of processes and scales the processes as training progresses. Two major\nchallenges with this approach are (i) that dynamically resizing the cluster can\nadd non-trivial overhead, in part since it is currently not supported, and (ii)\nthat the overall speed up is limited by the initial phase with smaller batches.\nIn this work, we address both challenges by developing a new adaptive batch\nsize framework, with autoscaling based on the Ray framework. This allows very\nefficient elastic scaling with negligible resizing overhead (0.32\\% of time for\nResNet18 ImageNet training). Furthermore, we propose a new adaptive batch size\ntraining scheme using second order methods and adversarial training. These\nenable increasing batch sizes earlier during training, which leads to better\ntraining time. We extensively evaluate our method on Cifar-10/100, SVHN,\nTinyImageNet, and ImageNet datasets, using multiple neural networks, including\nResNets and smaller networks such as SqueezeNext. Our method exceeds the\nperformance of existing solutions in terms of both accuracy and the number of\nSGD iterations (up to 1\\% and $5\\times$, respectively). Importantly, this is\nachieved without any additional hyper-parameter tuning to tailor our method in\nany of these experiments.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 00:31:46 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 20:56:27 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 00:16:36 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Arfeen", "Daiyaan", ""], ["Liaw", "Richard", ""], ["Gonzalez", "Joseph", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael", ""]]}, {"id": "1810.01032", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Yang Liu, Bo Li", "title": "Reinforcement Learning with Perturbed Rewards", "comments": "AAAI 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that reinforcement learning (RL) models are\nvulnerable in various noisy scenarios. For instance, the observed reward\nchannel is often subject to noise in practice (e.g., when rewards are collected\nthrough sensors), and is therefore not credible. In addition, for applications\nsuch as robotics, a deep reinforcement learning (DRL) algorithm can be\nmanipulated to produce arbitrary errors by receiving corrupted rewards. In this\npaper, we consider noisy RL problems with perturbed rewards, which can be\napproximated with a confusion matrix. We develop a robust RL framework that\nenables agents to learn in noisy environments where only perturbed rewards are\nobserved. Our solution framework builds on existing RL/DRL algorithms and\nfirstly addresses the biased noisy reward setting without any assumptions on\nthe true distribution (e.g., zero-mean Gaussian noise as made in previous\nworks). The core ideas of our solution include estimating a reward confusion\nmatrix and defining a set of unbiased surrogate rewards. We prove the\nconvergence and sample complexity of our approach. Extensive experiments on\ndifferent DRL platforms show that trained policies based on our estimated\nsurrogate reward can achieve higher expected rewards, and converge faster than\nexisting baselines. For instance, the state-of-the-art PPO algorithm is able to\nobtain 84.6% and 80.8% improvements on average score for five Atari games, with\nerror rates as 10% and 30% respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 01:43:45 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 15:47:23 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 22:19:26 GMT"}, {"version": "v4", "created": "Sat, 1 Feb 2020 21:15:52 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Jingkang", ""], ["Liu", "Yang", ""], ["Li", "Bo", ""]]}, {"id": "1810.01061", "submitter": "Diego Nascimento", "authors": "Diego Nascimento, Anderson Ara, Francisco Louzada Neto", "title": "Feature Selection Approach with Missing Values Conducted for Statistical\n  Learning: A Case Study of Entrepreneurship Survival Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we investigate the features which enhanced discriminate the\nsurvival in the micro and small business (MSE) using the approach of data\nmining with feature selection. According to the complexity of the data set, we\nproposed a comparison of three data imputation methods such as mean imputation\n(MI), k-nearest neighbor (KNN) and expectation maximization (EM) using mutually\nthe selection of variables technique, whereby t-test, then through the data\nmining process using logistic regression classification methods, naive Bayes\nalgorithm, linear discriminant analysis and support vector machine hence\ncomparing their respective performances. The experimental results will be\nspread in developing a model to predict the MSE survival, providing a better\nunderstanding in the topic once it is a significant part of the Brazilian' GPA\nand macroeconomy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 04:24:14 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Nascimento", "Diego", ""], ["Ara", "Anderson", ""], ["Neto", "Francisco Louzada", ""]]}, {"id": "1810.01075", "submitter": "Michael Mahoney", "authors": "Charles H. Martin and Michael W. Mahoney", "title": "Implicit Self-Regularization in Deep Neural Networks: Evidence from\n  Random Matrix Theory and Implications for Learning", "comments": "59 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Matrix Theory (RMT) is applied to analyze weight matrices of Deep\nNeural Networks (DNNs), including both production quality, pre-trained models\nsuch as AlexNet and Inception, and smaller models trained from scratch, such as\nLeNet5 and a miniature-AlexNet. Empirical and theoretical results clearly\nindicate that the DNN training process itself implicitly implements a form of\nSelf-Regularization. The empirical spectral density (ESD) of DNN layer matrices\ndisplays signatures of traditionally-regularized statistical models, even in\nthe absence of exogenously specifying traditional forms of explicit\nregularization. Building on relatively recent results in RMT, most notably its\nextension to Universality classes of Heavy-Tailed matrices, we develop a theory\nto identify 5+1 Phases of Training, corresponding to increasing amounts of\nImplicit Self-Regularization. These phases can be observed during the training\nprocess as well as in the final learned DNNs. For smaller and/or older DNNs,\nthis Implicit Self-Regularization is like traditional Tikhonov regularization,\nin that there is a \"size scale\" separating signal from noise. For\nstate-of-the-art DNNs, however, we identify a novel form of Heavy-Tailed\nSelf-Regularization, similar to the self-organization seen in the statistical\nphysics of disordered systems. This results from correlations arising at all\nsize scales, which arises implicitly due to the training process itself. This\nimplicit Self-Regularization can depend strongly on the many knobs of the\ntraining process. By exploiting the generalization gap phenomena, we\ndemonstrate that we can cause a small model to exhibit all 5+1 phases of\ntraining simply by changing the batch size. This demonstrates that---all else\nbeing equal---DNN optimization with larger batch sizes leads to less-well\nimplicitly-regularized models, and it provides an explanation for the\ngeneralization gap phenomena.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 05:27:59 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Martin", "Charles H.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1810.01097", "submitter": "Subhadip Mukherjee", "authors": "Subhadip Mukherjee and Chandra Sekhar Seelamantula", "title": "Quantization-Aware Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of phase retrieval (PR) from quantized measurements.\nThe goal is to reconstruct a signal from quadratic measurements encoded with a\nfinite precision, which is indeed the case in many practical applications. We\ndevelop a rank-1 projection algorithm that recovers the signal subject to\nensuring consistency with the measurement, that is, the recovered signal when\nencoded must yield the same set of measurements that one started with. The\nrank-1 projection stems from the idea of lifting, originally proposed in the\ncontext of PhaseLift. The consistency criterion is enforced using a one-sided\nquadratic cost. We also determine the probability with which different vectors\nlead to the same set of quantized measurements, which makes it impossible to\nresolve them. Naturally, this probability depends on how correlated such\nvectors are, and how coarsely/finely the measurements get quantized. The\nproposed algorithm is also capable of incorporating a sparsity constraint on\nthe signal. An analysis of the cost function reveals that it is bounded, both\nabove and below, by functions that are dependent on how well correlated the\nestimate is with the ground truth. We also derive the Cram\\'er-Rao lower bound\n(CRB) on the achievable reconstruction accuracy. A comparison with the\nstate-of-the- art algorithms shows that the proposed algorithm has a higher\nreconstruction accuracy and is about 2 to 3 dB away from the CRB. The edge, in\nterms of the reconstruction signal-to-noise ratio, over the competing\nalgorithms is higher (about 5 to 6 dB) when the quantization is coarse.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 07:23:05 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Mukherjee", "Subhadip", ""], ["Seelamantula", "Chandra Sekhar", ""]]}, {"id": "1810.01108", "submitter": "Subhajit Chaudhury", "authors": "Subhajit Chaudhury, Daiki Kimura, Asim Munawar and Ryuki Tachibana", "title": "Injective State-Image Mapping facilitates Visual Adversarial Imitation\n  Learning", "comments": "Updated the paper to match with version accepted at IEEE MMSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of virtual autonomous agents in applications like games and\nentertainment demands better control policies for natural-looking movements and\nactions. Unlike the conventional approach of hard-coding motion routines, we\npropose a deep learning method for obtaining control policies by directly\nmimicking raw video demonstrations. Previous methods in this domain rely on\nextracting low-dimensional features from expert videos followed by a separate\nhand-crafted reward estimation step. We propose an imitation learning framework\nthat reduces the dependence on hand-engineered reward functions by jointly\nlearning the feature extraction and reward estimation steps using Generative\nAdversarial Networks (GANs). Our main contribution in this paper is to show\nthat under injective mapping between low-level joint state (angles and\nvelocities) trajectories and corresponding raw video stream, performing\nadversarial imitation learning on video demonstrations is equivalent to\nlearning from the state trajectories. Experimental results show that the\nproposed adversarial learning method from raw videos produces a similar\nperformance to state-of-the-art imitation learning techniques while frequently\noutperforming existing hand-crafted video imitation methods. Furthermore, we\nshow that our method can learn action policies by imitating video\ndemonstrations on YouTube with similar performance to learned agents from true\nreward signals. Please see the supplementary video submission at\nhttps://ibm.biz/BdzzNA.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:22:41 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 09:32:10 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Chaudhury", "Subhajit", ""], ["Kimura", "Daiki", ""], ["Munawar", "Asim", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "1810.01118", "submitter": "Giorgio Patrini", "authors": "Giorgio Patrini, Rianne van den Berg, Patrick Forr\\'e, Marcello\n  Carioni, Samarth Bhargav, Max Welling, Tim Genewein, Frank Nielsen", "title": "Sinkhorn AutoEncoders", "comments": "Accepted for oral presentation at UAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport offers an alternative to maximum likelihood for learning\ngenerative autoencoding models. We show that minimizing the p-Wasserstein\ndistance between the generator and the true data distribution is equivalent to\nthe unconstrained min-min optimization of the p-Wasserstein distance between\nthe encoder aggregated posterior and the prior in latent space, plus a\nreconstruction error. We also identify the role of its trade-off hyperparameter\nas the capacity of the generator: its Lipschitz constant. Moreover, we prove\nthat optimizing the encoder over any class of universal approximators, such as\ndeterministic neural networks, is enough to come arbitrarily close to the\noptimum. We therefore advertise this framework, which holds for any metric\nspace and prior, as a sweet-spot of current generative autoencoding objectives.\nWe then introduce the Sinkhorn auto-encoder (SAE), which approximates and\nminimizes the p-Wasserstein distance in latent space via backprogation through\nthe Sinkhorn algorithm. SAE directly works on samples, i.e. it models the\naggregated posterior as an implicit distribution, with no need for a\nreparameterization trick for gradients estimations. SAE is thus able to work\nwith different metric spaces and priors with minimal adaptations. We\ndemonstrate the flexibility of SAE on latent spaces with different geometries\nand priors and compare with other methods on benchmark data sets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:43:08 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 07:21:35 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 02:04:33 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Patrini", "Giorgio", ""], ["Berg", "Rianne van den", ""], ["Forr\u00e9", "Patrick", ""], ["Carioni", "Marcello", ""], ["Bhargav", "Samarth", ""], ["Welling", "Max", ""], ["Genewein", "Tim", ""], ["Nielsen", "Frank", ""]]}, {"id": "1810.01163", "submitter": "Bharath Bhushan Damodaran", "authors": "Bharath Bhushan Damodaran, R\\'emi Flamary, Viven Seguy, Nicolas Courty", "title": "An Entropic Optimal Transport Loss for Learning Deep Neural Networks\n  under Label Noise in Remote Sensing Images", "comments": "Under Consideration at Computer Vision and Image Understanding", "journal-ref": "Computer Vision and Image Understanding, Volume 191, 2020, 102863,\n  ISSN 1077-3142", "doi": "10.1016/j.cviu.2019.102863", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have established as a powerful tool for large scale\nsupervised classification tasks. The state-of-the-art performances of deep\nneural networks are conditioned to the availability of large number of\naccurately labeled samples. In practice, collecting large scale accurately\nlabeled datasets is a challenging and tedious task in most scenarios of remote\nsensing image analysis, thus cheap surrogate procedures are employed to label\nthe dataset. Training deep neural networks on such datasets with inaccurate\nlabels easily overfits to the noisy training labels and degrades the\nperformance of the classification tasks drastically. To mitigate this effect,\nwe propose an original solution with entropic optimal transportation. It allows\nto learn in an end-to-end fashion deep neural networks that are, to some\nextent, robust to inaccurately labeled samples. We empirically demonstrate on\nseveral remote sensing datasets, where both scene and pixel-based hyperspectral\nimages are considered for classification. Our method proves to be highly\ntolerant to significant amounts of label noise and achieves favorable results\nagainst state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:31:37 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Damodaran", "Bharath Bhushan", ""], ["Flamary", "R\u00e9mi", ""], ["Seguy", "Viven", ""], ["Courty", "Nicolas", ""]]}, {"id": "1810.01165", "submitter": "Tao Li", "authors": "Tao Li, Xudong Liu, Shihan Su", "title": "Semi-supervised Text Regression with Conditional Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/BigData.2018.8622140", "report-no": null, "categories": "cs.CL cs.AI q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enormous online textual information provides intriguing opportunities for\nunderstandings of social and economic semantics. In this paper, we propose a\nnovel text regression model based on a conditional generative adversarial\nnetwork (GAN), with an attempt to associate textual data and social outcomes in\na semi-supervised manner. Besides promising potential of predicting\ncapabilities, our superiorities are twofold: (i) the model works with\nunbalanced datasets of limited labelled data, which align with real-world\nscenarios; and (ii) predictions are obtained by an end-to-end framework,\nwithout explicitly selecting high-level representations. Finally we point out\nrelated datasets for experiments and future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:35:13 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 05:37:37 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Li", "Tao", ""], ["Liu", "Xudong", ""], ["Su", "Shihan", ""]]}, {"id": "1810.01176", "submitter": "Hyoungseok Kim", "authors": "Hyoungseok Kim, Jaekyeom Kim, Yeonwoo Jeong, Sergey Levine, Hyun Oh\n  Song", "title": "EMI: Exploration with Mutual Information", "comments": "Accepted and to appear at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms struggle when the reward signal is very\nsparse. In these cases, naive random exploration methods essentially rely on a\nrandom walk to stumble onto a rewarding state. Recent works utilize intrinsic\nmotivation to guide the exploration via generative models, predictive forward\nmodels, or discriminative modeling of novelty. We propose EMI, which is an\nexploration method that constructs embedding representation of states and\nactions that does not rely on generative decoding of the full observation but\nextracts predictive signals that can be used to guide exploration based on\nforward prediction in the representation space. Our experiments show\ncompetitive results on challenging locomotion tasks with continuous control and\non image-based exploration tasks with discrete actions on Atari. The source\ncode is available at https://github.com/snu-mllab/EMI .\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:33:57 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 15:26:16 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 13:50:56 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 01:07:50 GMT"}, {"version": "v5", "created": "Tue, 14 May 2019 07:06:05 GMT"}, {"version": "v6", "created": "Thu, 13 Jun 2019 05:41:38 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kim", "Hyoungseok", ""], ["Kim", "Jaekyeom", ""], ["Jeong", "Yeonwoo", ""], ["Levine", "Sergey", ""], ["Song", "Hyun Oh", ""]]}, {"id": "1810.01187", "submitter": "Zixin Zhong", "authors": "Zixin Zhong, Wang Chi Cheung, Vincent Y. F. Tan", "title": "Thompson Sampling Algorithms for Cascading Bandits", "comments": "62 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the pressing need for efficient optimization in online\nrecommender systems, we revisit the cascading bandit model proposed by Kveton\net al. (2015). While Thompson sampling (TS) algorithms have been shown to be\nempirically superior to Upper Confidence Bound (UCB) algorithms for cascading\nbandits, theoretical guarantees are only known for the latter. In this paper,\nwe first provide a problem-dependent upper bound on the regret of a TS\nalgorithm with Beta-Bernoulli updates; this upper bound is tighter than a\nrecent derivation under a more general setting by Huyuk and Tekin (2019). Next,\nwe design and analyze another TS algorithm with Gaussian updates, TS-Cascade.\nTS-Cascade achieves the state-of-the-art regret bound for cascading bandits.\nComplementarily, we consider a linear generalization of the cascading bandit\nmodel, which allows efficient learning in large cascading bandit problem\ninstances. We introduce and analyze a TS algorithm, which enjoys a regret bound\nthat depends on the dimension of the linear model but not the number of items.\nFinally, by using information-theoretic techniques and judiciously constructing\ncascading bandit instances, we derive a nearly matching regret lower bound for\nthe standard model. Our paper establishes the first theoretical guarantees on\nTS algorithms for stochastic combinatorial bandit problem model with partial\nfeedback. Numerical experiments demonstrate the superiority of the proposed TS\nalgorithms compared to existing UCB-based ones.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:55:54 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:08:10 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 16:56:18 GMT"}, {"version": "v4", "created": "Sun, 16 May 2021 03:20:10 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhong", "Zixin", ""], ["Cheung", "Wang Chi", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1810.01190", "submitter": "Yura Perov N", "authors": "Yura Perov", "title": "Inference Over Programs That Make Predictions", "comments": "The International Conference on Probabilistic Programming, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This abstract extends on the previous work (arXiv:1407.2646,\narXiv:1606.00075) on program induction using probabilistic programming. It\ndescribes possible further steps to extend that work, such that, ultimately,\nautomatic probabilistic program synthesis can generalise over any reasonable\nset of inputs and outputs, in particular in regard to text, image and video\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 12:00:41 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Perov", "Yura", ""]]}, {"id": "1810.01217", "submitter": "John Martin Jr", "authors": "John Martin, Jinkun Wang, Brendan Englot", "title": "Sparse Gaussian Process Temporal Difference Learning for Marine Robot\n  Navigation", "comments": "2018 Conference on Robot Learning (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a method for Temporal Difference (TD) learning that addresses\nseveral challenges faced by robots learning to navigate in a marine\nenvironment. For improved data efficiency, our method reduces TD updates to\nGaussian Process regression. To make predictions amenable to online settings,\nwe introduce a sparse approximation with improved quality over current\nrejection-based sparse methods. We derive the predictive value function\nposterior and use the moments to obtain a new algorithm for model-free policy\nevaluation, SPGP-SARSA. With simple changes, we show SPGP-SARSA can be reduced\nto a model-based equivalent, SPGP-TD. We perform comprehensive simulation\nstudies and also conduct physical learning trials with an underwater robot. Our\nresults show SPGP-SARSA can outperform the state-of-the-art sparse method,\nreplicate the prediction quality of its exact counterpart, and be applied to\nsolve underwater navigation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:04:47 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Martin", "John", ""], ["Wang", "Jinkun", ""], ["Englot", "Brendan", ""]]}, {"id": "1810.01222", "submitter": "Olivier Sigaud", "authors": "Alo\\\"is Pourchot and Olivier Sigaud", "title": "CEM-RL: Combining evolutionary and gradient-based methods for policy\n  search", "comments": "accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neuroevolution and deep reinforcement learning (deep RL) algorithms are\ntwo popular approaches to policy search. The former is widely applicable and\nrather stable, but suffers from low sample efficiency. By contrast, the latter\nis more sample efficient, but the most sample efficient variants are also\nrather unstable and highly sensitive to hyper-parameter setting. So far, these\nfamilies of methods have mostly been compared as competing tools. However, an\nemerging approach consists in combining them so as to get the best of both\nworlds. Two previously existing combinations use either an ad hoc evolutionary\nalgorithm or a goal exploration process together with the Deep Deterministic\nPolicy Gradient (DDPG) algorithm, a sample efficient off-policy deep RL\nalgorithm. In this paper, we propose a different combination scheme using the\nsimple cross-entropy method (CEM) and Twin Delayed Deep Deterministic policy\ngradient (td3), another off-policy deep RL algorithm which improves over ddpg.\nWe evaluate the resulting method, cem-rl, on a set of benchmarks classically\nused in deep RL. We show that cem-rl benefits from several advantages over its\ncompetitors and offers a satisfactory trade-off between performance and sample\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:12:13 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 13:32:11 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 14:11:24 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Pourchot", "Alo\u00efs", ""], ["Sigaud", "Olivier", ""]]}, {"id": "1810.01240", "submitter": "Cyril Feau", "authors": "R\\'emi Sainct, Cyril Feau, Jean-Marc Martinez, Josselin Garnier", "title": "Efficient Seismic fragility curve estimation by Active Learning on\n  Support Vector Machines", "comments": "24 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fragility curves which express the failure probability of a structure, or\ncritical components, as function of a loading intensity measure are nowadays\nwidely used (i) in Seismic Probabilistic Risk Assessment studies, (ii) to\nevaluate impact of construction details on the structural performance of\ninstallations under seismic excitations or under other loading sources such as\nwind. To avoid the use of parametric models such as lognormal model to estimate\nfragility curves from a reduced number of numerical calculations, a methodology\nbased on Support Vector Machines coupled with an active learning algorithm is\nproposed in this paper. In practice, input excitation is reduced to some\nrelevant parameters and, given these parameters, SVMs are used for a binary\nclassification of the structural responses relative to a limit threshold of\nexceedance. Since the output is not only binary, this is a score, a\nprobabilistic interpretation of the output is exploited to estimate very\nefficiently fragility curves as score functions or as functions of classical\nseismic intensity measures.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 08:22:39 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Sainct", "R\u00e9mi", ""], ["Feau", "Cyril", ""], ["Martinez", "Jean-Marc", ""], ["Garnier", "Josselin", ""]]}, {"id": "1810.01243", "submitter": "Melpomeni Kalofonou", "authors": "Mohammed Khwaja, Melpomeni Kalofonou and Chris Toumazou", "title": "A Deep Autoencoder System for Differentiation of Cancer Types Based on\n  DNA Methylation State", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Deep Autoencoder based content retrieval algorithm is proposed for\nprediction and differentiation of cancer types based on the presence of\nepigenetic patterns of DNA methylation identified in genetic regions known as\nCpG islands. The developed deep learning system uses a CpG island state\nclassification sub-system to complete sets of missing/incomplete island data in\ngiven human cell lines, and is then pipelined with an intricate set of\nstatistical and signal processing methods to accurately predict the presence of\ncancer and further differentiate the type and cell of origin in the event of a\npositive result. The proposed system was trained with previously reported data\nderived from four case groups of cancer cell lines, achieving overall\nSensitivity of 88.24%, Specificity of 83.33%, Accuracy of 84.75% and Matthews\nCorrelation Coefficient of 0.687. The ability to predict and differentiate\ncancer types using epigenetic events as the identifying patterns was\ndemonstrated in previously reported data sets from breast, lung, lymphoblastic\nleukemia and urological cancer cell lines, allowing the pipelined system to be\nrobust and adjustable to other cancer cell lines or epigenetic events.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 13:44:37 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 14:17:49 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Khwaja", "Mohammed", ""], ["Kalofonou", "Melpomeni", ""], ["Toumazou", "Chris", ""]]}, {"id": "1810.01266", "submitter": "Mohit Sharma", "authors": "Arjun Sharma, Mohit Sharma, Nicholas Rhinehart, Kris M. Kitani", "title": "Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented\n  Demonstrations using Directed Information", "comments": "Accepted as conference paper at ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of imitation learning to learn a single policy for a complex task\nthat has multiple modes or hierarchical structure can be challenging. In fact,\nprevious work has shown that when the modes are known, learning separate\npolicies for each mode or sub-task can greatly improve the performance of\nimitation learning. In this work, we discover the interaction between sub-tasks\nfrom their resulting state-action trajectory sequences using a directed\ngraphical model. We propose a new algorithm based on the generative adversarial\nimitation learning framework which automatically learns sub-task policies from\nunsegmented demonstrations. Our approach maximizes the directed information\nflow in the graphical model between sub-task latent variables and their\ngenerated trajectories. We also show how our approach connects with the\nexisting Options framework, which is commonly used to learn hierarchical\npolicies.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 18:40:13 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 02:06:19 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Sharma", "Arjun", ""], ["Sharma", "Mohit", ""], ["Rhinehart", "Nicholas", ""], ["Kitani", "Kris M.", ""]]}, {"id": "1810.01269", "submitter": "Adrian Wills", "authors": "Adrian Wills, Carl Jidling, Thomas Schon", "title": "A fast quasi-Newton-type method for large-scale stochastic optimisation", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.04310", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During recent years there has been an increased interest in stochastic\nadaptations of limited memory quasi-Newton methods, which compared to pure\ngradient-based routines can improve the convergence by incorporating second\norder information. In this work we propose a direct least-squares approach\nconceptually similar to the limited memory quasi-Newton methods, but that\ncomputes the search direction in a slightly different way. This is achieved in\na fast and numerically robust manner by maintaining a Cholesky factor of low\ndimension. This is combined with a stochastic line search relying upon\nfulfilment of the Wolfe condition in a backtracking manner, where the step\nlength is adaptively modified with respect to the optimisation progress. We\nsupport our new algorithm by providing several theoretical results guaranteeing\nits performance. The performance is demonstrated on real-world benchmark\nproblems which shows improved results in comparison with already established\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 20:59:41 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Wills", "Adrian", ""], ["Jidling", "Carl", ""], ["Schon", "Thomas", ""]]}, {"id": "1810.01270", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti and Tsang\n  Ing Ren", "title": "META-DES: A Dynamic Ensemble Selection Framework using Meta-Learning", "comments": "Article published on Pattern Recognition. arXiv admin note: text\n  overlap with arXiv:1509.00825", "journal-ref": "Pattern Recognition Volume 48, Issue 5, Pages 1925-1935", "doi": "10.1016/j.patcog.2014.12.003", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic ensemble selection systems work by estimating the level of competence\nof each classifier from a pool of classifiers. Only the most competent ones are\nselected to classify a given test sample. This is achieved by defining a\ncriterion to measure the level of competence of a base classifier, such as, its\naccuracy in local regions of the feature space around the query instance.\nHowever, using only one criterion about the behavior of a base classifier is\nnot sufficient to accurately estimate its level of competence. In this paper,\nwe present a novel dynamic ensemble selection framework using meta-learning. We\npropose five distinct sets of meta-features, each one corresponding to a\ndifferent criterion to measure the level of competence of a classifier for the\nclassification of input samples. The meta-features are extracted from the\ntraining data and used to train a meta-classifier to predict whether or not a\nbase classifier is competent enough to classify an input instance. During the\ngeneralization phase, the meta-features are extracted from the query instance\nand passed down as input to the meta-classifier. The meta-classifier estimates,\nwhether a base classifier is competent enough to be added to the ensemble.\nExperiments are conducted over several small sample size classification\nproblems, i.e., problems with a high degree of uncertainty due to the lack of\ntraining data. Experimental results show the proposed meta-learning framework\ngreatly improves classification accuracy when compared against current\nstate-of-the-art dynamic ensemble selection techniques.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 00:27:49 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""], ["Ren", "Tsang Ing", ""]]}, {"id": "1810.01279", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Yao Li, Chongruo Wu, Cho-Jui Hsieh", "title": "Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural\n  Network", "comments": "Code will be made available at\n  https://github.com/xuanqing94/BayesianDefense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to train a robust neural network against\nadversarial attacks. Our algorithm is motivated by the following two ideas.\nFirst, although recent work has demonstrated that fusing randomness can improve\nthe robustness of neural networks (Liu 2017), we noticed that adding noise\nblindly to all the layers is not the optimal way to incorporate randomness.\nInstead, we model randomness under the framework of Bayesian Neural Network\n(BNN) to formally learn the posterior distribution of models in a scalable way.\nSecond, we formulate the mini-max problem in BNN to learn the best model\ndistribution under adversarial attacks, leading to an adversarial-trained\nBayesian neural net. Experiment results demonstrate that the proposed algorithm\nachieves state-of-the-art performance under strong attacks. On CIFAR-10 with\nVGG network, our model leads to 14\\% accuracy improvement compared with\nadversarial training (Madry 2017) and random self-ensemble (Liu 2017) under PGD\nattack with $0.035$ distortion, and the gap becomes even larger on a subset of\nImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 05:23:15 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 06:39:11 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Xuanqing", ""], ["Li", "Yao", ""], ["Wu", "Chongruo", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.01316", "submitter": "Paolo Bestagini", "authors": "Paolo Bestagini, Federico Lombardi, Maurizio Lualdi, Francesco\n  Picetti, Stefano Tubaro", "title": "Landmine Detection Using Autoencoders on Multi-polarization GPR\n  Volumetric Data", "comments": "https://github.com/polimi-ispl/landmine_detection_autoencoder", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buried landmines and unexploded remnants of war are a constant threat for the\npopulation of many countries that have been hit by wars in the past years. The\nhuge amount of human lives lost due to this phenomenon has been a strong\nmotivation for the research community toward the development of safe and robust\ntechniques designed for landmine clearance. Nonetheless, being able to detect\nand localize buried landmines with high precision in an automatic fashion is\nstill considered a challenging task due to the many different boundary\nconditions that characterize this problem (e.g., several kinds of objects to\ndetect, different soils and meteorological conditions, etc.). In this paper, we\npropose a novel technique for buried object detection tailored to unexploded\nlandmine discovery. The proposed solution exploits a specific kind of\nconvolutional neural network (CNN) known as autoencoder to analyze volumetric\ndata acquired with ground penetrating radar (GPR) using different\npolarizations. This method works in an anomaly detection framework, indeed we\nonly train the autoencoder on GPR data acquired on landmine-free areas. The\nsystem then recognizes landmines as objects that are dissimilar to the soil\nused during the training step. Experiments conducted on real data show that the\nproposed technique requires little training and no ad-hoc data pre-processing\nto achieve accuracy higher than 93% on challenging datasets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 15:10:31 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Bestagini", "Paolo", ""], ["Lombardi", "Federico", ""], ["Lualdi", "Maurizio", ""], ["Picetti", "Francesco", ""], ["Tubaro", "Stefano", ""]]}, {"id": "1810.01322", "submitter": "L\\'eonard Blier", "authors": "L\\'eonard Blier, Pierre Wolinski, Yann Ollivier", "title": "Learning with Random Learning Rates", "comments": "20 pages, 8 figures, code available on GitHub", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter tuning is a bothersome step in the training of deep learning\nmodels. One of the most sensitive hyperparameters is the learning rate of the\ngradient descent. We present the 'All Learning Rates At Once' (Alrao)\noptimization method for neural networks: each unit or feature in the network\ngets its own learning rate sampled from a random distribution spanning several\norders of magnitude. This comes at practically no computational cost. Perhaps\nsurprisingly, stochastic gradient descent (SGD) with Alrao performs close to\nSGD with an optimally tuned learning rate, for various architectures and\nproblems. Alrao could save time when testing deep learning models: a range of\nmodels could be quickly assessed with Alrao, and the most promising models\ncould then be trained more extensively. This text comes with a PyTorch\nimplementation of the method, which can be plugged on an existing PyTorch\nmodel: https://github.com/leonardblier/alrao .\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 15:21:07 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 21:52:49 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 14:29:19 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Blier", "L\u00e9onard", ""], ["Wolinski", "Pierre", ""], ["Ollivier", "Yann", ""]]}, {"id": "1810.01344", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere and Michael Garcia Ortiz", "title": "Unsupervised Emergence of Spatial Structure from Sensorimotor Prediction", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its omnipresence in robotics application, the nature of spatial\nknowledge and the mechanisms that underlie its emergence in autonomous agents\nare still poorly understood. Recent theoretical work suggests that the concept\nof space can be grounded by capturing invariants induced by the structure of\nspace in an agent's raw sensorimotor experience. Moreover, it is hypothesized\nthat capturing these invariants is beneficial for a naive agent trying to\npredict its sensorimotor experience. Under certain exploratory conditions,\nspatial representations should thus emerge as a byproduct of learning to\npredict. We propose a simple sensorimotor predictive scheme, apply it to\ndifferent agents and types of exploration, and evaluate the pertinence of this\nhypothesis. We show that a naive agent can capture the topology and metric\nregularity of its spatial configuration without any a priori knowledge, nor\nextraneous supervision.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:12:53 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 13:53:15 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Ortiz", "Michael Garcia", ""]]}, {"id": "1810.01363", "submitter": "Rui Zhao", "authors": "Rui Zhao and Volker Tresp", "title": "Energy-Based Hindsight Experience Prioritization", "comments": "Published in Conference on Robot Learning (CoRL 2018) as oral\n  presentation (7%), Zurich, Switzerland", "journal-ref": "PMLR 87:113-122, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Hindsight Experience Replay (HER), a reinforcement learning agent is\ntrained by treating whatever it has achieved as virtual goals. However, in\nprevious work, the experience was replayed at random, without considering which\nepisode might be the most valuable for learning. In this paper, we develop an\nenergy-based framework for prioritizing hindsight experience in robotic\nmanipulation tasks. Our approach is inspired by the work-energy principle in\nphysics. We define a trajectory energy function as the sum of the transition\nenergy of the target object over the trajectory. We hypothesize that replaying\nepisodes that have high trajectory energy is more effective for reinforcement\nlearning in robotics. To verify our hypothesis, we designed a framework for\nhindsight experience prioritization based on the trajectory energy of goal\nstates. The trajectory energy function takes the potential, kinetic, and\nrotational energy into consideration. We evaluate our Energy-Based\nPrioritization (EBP) approach on four challenging robotic manipulation tasks in\nsimulation. Our empirical results show that our proposed method surpasses\nstate-of-the-art approaches in terms of both performance and sample-efficiency\non all four tasks, without increasing computational time. A video showing\nexperimental results is available at https://youtu.be/jtsF2tTeUGQ\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:42:35 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 08:04:51 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 14:44:40 GMT"}, {"version": "v4", "created": "Wed, 20 Feb 2019 10:15:33 GMT"}, {"version": "v5", "created": "Sun, 24 May 2020 07:57:13 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1810.01365", "submitter": "Neil Houlsby", "authors": "Ting Chen, Mario Lucic, Neil Houlsby, Sylvain Gelly", "title": "On Self Modulation for Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training Generative Adversarial Networks (GANs) is notoriously challenging.\nWe propose and study an architectural modification, self-modulation, which\nimproves GAN performance across different data sets, architectures, losses,\nregularizers, and hyperparameter settings. Intuitively, self-modulation allows\nthe intermediate feature maps of a generator to change as a function of the\ninput noise vector. While reminiscent of other conditioning techniques, it\nrequires no labeled data. In a large-scale empirical study we observe a\nrelative decrease of $5\\%-35\\%$ in FID. Furthermore, all else being equal,\nadding this modification to the generator leads to improved performance in\n$124/144$ ($86\\%$) of the studied settings. Self-modulation is a simple\narchitectural change that requires no additional parameter tuning, which\nsuggests that it can be applied readily to any GAN.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:50:28 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 07:20:50 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Chen", "Ting", ""], ["Lucic", "Mario", ""], ["Houlsby", "Neil", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1810.01367", "submitter": "Ricky T. Q. Chen", "authors": "Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, Ilya Sutskever,\n  David Duvenaud", "title": "FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative\n  Models", "comments": "8 Pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising class of generative models maps points from a simple distribution\nto a complex distribution through an invertible neural network.\nLikelihood-based training of these models requires restricting their\narchitectures to allow cheap computation of Jacobian determinants.\nAlternatively, the Jacobian trace can be used if the transformation is\nspecified by an ordinary differential equation. In this paper, we use\nHutchinson's trace estimator to give a scalable unbiased estimate of the\nlog-density. The result is a continuous-time invertible generative model with\nunbiased density estimation and one-pass sampling, while allowing unrestricted\nneural network architectures. We demonstrate our approach on high-dimensional\ndensity estimation, image generation, and variational inference, achieving the\nstate-of-the-art among exact likelihood methods with efficient sampling.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:56:37 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 15:28:48 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 17:56:45 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Grathwohl", "Will", ""], ["Chen", "Ricky T. Q.", ""], ["Bettencourt", "Jesse", ""], ["Sutskever", "Ilya", ""], ["Duvenaud", "David", ""]]}, {"id": "1810.01373", "submitter": "Mingjie Wang", "authors": "Mingjie Wang, Jun Zhou, Wendong Mao, Minglun Gong", "title": "Multi-scale Convolution Aggregation and Stochastic Feature Reuse for\n  DenseNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Convolution Neural Networks (CNNs) obtained huge success in\nnumerous vision tasks. In particular, DenseNets have demonstrated that feature\nreuse via dense skip connections can effectively alleviate the difficulty of\ntraining very deep networks and that reusing features generated by the initial\nlayers in all subsequent layers has strong impact on performance. To feed even\nricher information into the network, a novel adaptive Multi-scale Convolution\nAggregation module is presented in this paper. Composed of layers for\nmulti-scale convolutions, trainable cross-scale aggregation, maxout, and\nconcatenation, this module is highly non-linear and can boost the accuracy of\nDenseNet while using much fewer parameters. In addition, due to high model\ncomplexity, the network with extremely dense feature reuse is prone to\noverfitting. To address this problem, a regularization method named Stochastic\nFeature Reuse is also presented. Through randomly dropping a set of feature\nmaps to be reused for each mini-batch during the training phase, this\nregularization method reduces training costs and prevents co-adaptation.\nExperimental results on CIFAR-10, CIFAR-100 and SVHN benchmarks demonstrated\nthe effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:07:35 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Wang", "Mingjie", ""], ["Zhou", "Jun", ""], ["Mao", "Wendong", ""], ["Gong", "Minglun", ""]]}, {"id": "1810.01392", "submitter": "Eric Jang", "authors": "Hyunsun Choi and Eric Jang and Alexander A. Alemi", "title": "WAIC, but Why? Generative Ensembles for Robust Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models encounter Out-of-Distribution (OoD) errors when the\ndata seen at test time are generated from a different stochastic generator than\nthe one used to generate the training data. One proposal to scale OoD detection\nto high-dimensional data is to learn a tractable likelihood approximation of\nthe training distribution, and use it to reject unlikely inputs. However,\nlikelihood models on natural data are themselves susceptible to OoD errors, and\neven assign large likelihoods to samples from other datasets. To mitigate this\nproblem, we propose Generative Ensembles, which robustify density-based OoD\ndetection by way of estimating epistemic uncertainty of the likelihood model.\nWe present a puzzling observation in need of an explanation -- although\nlikelihood measures cannot account for the typical set of a distribution, and\ntherefore should not be suitable on their own for OoD detection, WAIC performs\nsurprisingly well in practice.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:32:07 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 19:17:06 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 01:04:10 GMT"}, {"version": "v4", "created": "Thu, 23 May 2019 23:48:06 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Choi", "Hyunsun", ""], ["Jang", "Eric", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "1810.01395", "submitter": "Jonathan Le Roux", "authors": "Jonathan Le Roux, Gordon Wichern, Shinji Watanabe, Andy Sarroff, John\n  R. Hershey", "title": "Phasebook and Friends: Leveraging Discrete Representations for Source\n  Separation", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2019.2904183", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based speech enhancement and source separation systems have\nrecently reached unprecedented levels of quality, to the point that performance\nis reaching a new ceiling. Most systems rely on estimating the magnitude of a\ntarget source by estimating a real-valued mask to be applied to a\ntime-frequency representation of the mixture signal. A limiting factor in such\napproaches is a lack of phase estimation: the phase of the mixture is most\noften used when reconstructing the estimated time-domain signal. Here, we\npropose \"magbook\", \"phasebook\", and \"combook\", three new types of layers based\non discrete representations that can be used to estimate complex time-frequency\nmasks. Magbook layers extend classical sigmoidal units and a recently\nintroduced convex softmax activation for mask-based magnitude estimation.\nPhasebook layers use a similar structure to give an estimate of the phase mask\nwithout suffering from phase wrapping issues. Combook layers are an alternative\nto the magbook-phasebook combination that directly estimate complex masks. We\npresent various training and inference schemes involving these representations,\nand explain in particular how to include them in an end-to-end learning\nframework. We also present an oracle study to assess upper bounds on\nperformance for various types of masks using discrete phase representations. We\nevaluate the proposed methods on the wsj0-2mix dataset, a well-studied corpus\nfor single-channel speaker-independent speaker separation, matching the\nperformance of state-of-the-art mask-based approaches without requiring\nadditional phase reconstruction steps.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:36:23 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:26:58 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Roux", "Jonathan Le", ""], ["Wichern", "Gordon", ""], ["Watanabe", "Shinji", ""], ["Sarroff", "Andy", ""], ["Hershey", "John R.", ""]]}, {"id": "1810.01398", "submitter": "Sara Sabour", "authors": "Sara Sabour, William Chan, Mohammad Norouzi", "title": "Optimal Completion Distillation for Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Optimal Completion Distillation (OCD), a training procedure for\noptimizing sequence to sequence models based on edit distance. OCD is\nefficient, has no hyper-parameters of its own, and does not require pretraining\nor joint optimization with conditional log-likelihood. Given a partial sequence\ngenerated by the model, we first identify the set of optimal suffixes that\nminimize the total edit distance, using an efficient dynamic programming\nalgorithm. Then, for each position of the generated sequence, we use a target\ndistribution that puts equal probability on the first token of all the optimal\nsuffixes. OCD achieves the state-of-the-art performance on end-to-end speech\nrecognition, on both Wall Street Journal and Librispeech datasets, achieving\n$9.3\\%$ WER and $4.5\\%$ WER respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:44:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 21:30:20 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Sabour", "Sara", ""], ["Chan", "William", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1810.01400", "submitter": "Joseph Tassarotti", "authors": "Joseph Tassarotti, Jean-Baptiste Tristan, Michael Wick", "title": "Sketching for Latent Dirichlet-Categorical Models", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has explored transforming data sets into smaller, approximate\nsummaries in order to scale Bayesian inference. We examine a related problem in\nwhich the parameters of a Bayesian model are very large and expensive to store\nin memory, and propose more compact representations of parameter values that\ncan be used during inference. We focus on a class of graphical models that we\nrefer to as latent Dirichlet-Categorical models, and show how a combination of\ntwo sketching algorithms known as count-min sketch and approximate counters\nprovide an efficient representation for them. We show that this sketch\ncombination -- which, despite having been used before in NLP applications, has\nnot been previously analyzed -- enjoys desirable properties. We prove that for\nthis class of models, when the sketches are used during Markov Chain Monte\nCarlo inference, the equilibrium of sketched MCMC converges to that of the\nexact chain as sketch parameters are tuned to reduce the error rate.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:47:04 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Tassarotti", "Joseph", ""], ["Tristan", "Jean-Baptiste", ""], ["Wick", "Michael", ""]]}, {"id": "1810.01403", "submitter": "Shubhomoy Das", "authors": "Md Rakibul Islam, Shubhomoy Das, Janardhan Rao Doppa and Sriraam\n  Natarajan", "title": "GLAD: GLocalized Anomaly Detection via Human-in-the-Loop Learning", "comments": "Presented at the ICML-2020 Workshop on Human in the Loop Learning; 8\n  pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human analysts that use anomaly detection systems in practice want to retain\nthe use of simple and explainable global anomaly detectors. In this paper, we\npropose a novel human-in-the-loop learning algorithm called GLAD (GLocalized\nAnomaly Detection) that supports global anomaly detectors. GLAD automatically\nlearns their local relevance to specific data instances using label feedback\nfrom human analysts. The key idea is to place a uniform prior on the relevance\nof each member of the anomaly detection ensemble over the input feature space\nvia a neural network trained on unlabeled instances. Subsequently, weights of\nthe neural network are tuned to adjust the local relevance of each ensemble\nmember using all labeled instances. GLAD also provides explanations which can\nimprove the understanding of end-users about anomalies. Our experiments on\nsynthetic and real-world data show the effectiveness of GLAD in learning the\nlocal relevance of ensemble members and discovering anomalies via label\nfeedback.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:54:15 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 04:03:00 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 21:04:17 GMT"}, {"version": "v4", "created": "Wed, 15 Jul 2020 19:37:15 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Islam", "Md Rakibul", ""], ["Das", "Shubhomoy", ""], ["Doppa", "Janardhan Rao", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1810.01405", "submitter": "Jayaraman J. Thiagarajan", "authors": "Uday Shankar Shanthamallu, Jayaraman J. Thiagarajan, Huan Song and\n  Andreas Spanias", "title": "GrAMME: Semi-Supervised Learning using Multi-layered Graph Attention\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data analysis pipelines are becoming increasingly complex due to the\npresence of multi-view information sources. While graphs are effective in\nmodeling complex relationships, in many scenarios a single graph is rarely\nsufficient to succinctly represent all interactions, and hence multi-layered\ngraphs have become popular. Though this leads to richer representations,\nextending solutions from the single-graph case is not straightforward.\nConsequently, there is a strong need for novel solutions to solve classical\nproblems, such as node classification, in the multi-layered case. In this\npaper, we consider the problem of semi-supervised learning with multi-layered\ngraphs. Though deep network embeddings, e.g. DeepWalk, are widely adopted for\ncommunity discovery, we argue that feature learning with random node\nattributes, using graph neural networks, can be more effective. To this end, we\npropose to use attention models for effective feature learning, and develop two\nnovel architectures, GrAMME-SG and GrAMME-Fusion, that exploit the inter-layer\ndependencies for building multi-layered graph embeddings. Using empirical\nstudies on several benchmark datasets, we evaluate the proposed approaches and\ndemonstrate significant performance improvements in comparison to\nstate-of-the-art network embedding strategies. The results also show that using\nsimple random features is an effective choice, even in cases where explicit\nnode attributes are not available.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:57:20 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 16:57:26 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Shanthamallu", "Uday Shankar", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Song", "Huan", ""], ["Spanias", "Andreas", ""]]}, {"id": "1810.01406", "submitter": "Ke Li", "authors": "Ke Li, Shichong Peng, Jitendra Malik", "title": "Super-Resolution via Conditional Implicit Maximum Likelihood Estimation", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-image super-resolution (SISR) is a canonical problem with diverse\napplications. Leading methods like SRGAN produce images that contain various\nartifacts, such as high-frequency noise, hallucinated colours and shape\ndistortions, which adversely affect the realism of the result. In this paper,\nwe propose an alternative approach based on an extension of the method of\nImplicit Maximum Likelihood Estimation (IMLE). We demonstrate greater\neffectiveness at noise reduction and preservation of the original colours and\nshapes, yielding more realistic super-resolved images.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:58:02 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Li", "Ke", ""], ["Peng", "Shichong", ""], ["Malik", "Jitendra", ""]]}, {"id": "1810.01407", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar and Mohammad Mahmoody", "title": "Can Adversarially Robust Learning Leverage Computational Hardness?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making learners robust to adversarial perturbation at test time (i.e.,\nevasion attacks) or training time (i.e., poisoning attacks) has emerged as a\nchallenging task. It is known that for some natural settings, sublinear\nperturbations in the training phase or the testing phase can drastically\ndecrease the quality of the predictions. These negative results, however, are\ninformation theoretic and only prove the existence of such successful\nadversarial perturbations. A natural question for these settings is whether or\nnot we can make classifiers computationally robust to polynomial-time attacks.\n  In this work, we prove strong barriers against achieving such envisioned\ncomputational robustness both for evasion and poisoning attacks. In particular,\nwe show that if the test instances come from a product distribution (e.g.,\nuniform over $\\{0,1\\}^n$ or $[0,1]^n$, or isotropic $n$-variate Gaussian) and\nthat there is an initial constant error, then there exists a polynomial-time\nattack that finds adversarial examples of Hamming distance $O(\\sqrt n)$. For\npoisoning attacks, we prove that for any learning algorithm with sample\ncomplexity $m$ and any efficiently computable \"predicate\" defining some \"bad\"\nproperty $B$ for the produced hypothesis (e.g., failing on a particular test)\nthat happens with an initial constant probability, there exist polynomial-time\nonline poisoning attacks that tamper with $O (\\sqrt m)$ many examples, replace\nthem with other correctly labeled examples, and increases the probability of\nthe bad event $B$ to $\\approx 1$.\n  Both of our poisoning and evasion attacks are black-box in how they access\ntheir corresponding components of the system (i.e., the hypothesis, the\nconcept, and the learning algorithm) and make no further assumptions about the\nclassifier or the learning algorithm producing the classifier.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:58:23 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 04:53:12 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 04:19:41 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1810.01414", "submitter": "Ramzan Umarov", "authors": "Ramzan Umarov, Hiroyuki Kuwahara, Yu Li, Xin Gao, Victor Solovyev", "title": "PromID: human promoter prediction by deep learning", "comments": "18 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational identification of promoters is notoriously difficult as human\ngenes often have unique promoter sequences that provide regulation of\ntranscription and interaction with transcription initiation complex. While\nthere are many attempts to develop computational promoter identification\nmethods, we have no reliable tool to analyze long genomic sequences. In this\nwork we further develop our deep learning approach that was relatively\nsuccessful to discriminate short promoter and non-promoter sequences. Instead\nof focusing on the classification accuracy, in this work we predict the exact\npositions of the TSS inside the genomic sequences testing every possible\nlocation. We studied human promoters to find effective regions for\ndiscrimination and built corresponding deep learning models. These models use\nadaptively constructed negative set which iteratively improves the models\ndiscriminative ability. The developed promoter identification models\nsignificantly outperform the previously developed promoter prediction programs\nby considerably reducing the number of false positive predictions. The best\nmodel we have built has recall 0.76, precision 0.77 and MCC 0.76, while the\nnext best tool FPROM achieved precision 0.48 and MCC 0.60 for the recall of\n0.75. Our method is available at http://www.cbrc.kaust.edu.sa/PromID/.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:35:46 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Umarov", "Ramzan", ""], ["Kuwahara", "Hiroyuki", ""], ["Li", "Yu", ""], ["Gao", "Xin", ""], ["Solovyev", "Victor", ""]]}, {"id": "1810.01468", "submitter": "Gaurav Singh", "authors": "Gaurav Singh, James Thomas, Iain J. Marshall, John Shawe-Taylor and\n  Byron C. Wallace", "title": "Structured Multi-Label Biomedical Text Tagging via Attentive Neural Tree\n  Decoding", "comments": "Accepted for Publication in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model for tagging unstructured texts with an arbitrary number of\nterms drawn from a tree-structured vocabulary (i.e., an ontology). We treat\nthis as a special case of sequence-to-sequence learning in which the decoder\nbegins at the root node of an ontological tree and recursively elects to expand\nchild nodes as a function of the input text, the current node, and the latent\ndecoder state. In our experiments the proposed method outperforms\nstate-of-the-art approaches on the important task of automatically assigning\nMeSH terms to biomedical abstracts.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 19:32:12 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Singh", "Gaurav", ""], ["Thomas", "James", ""], ["Marshall", "Iain J.", ""], ["Shawe-Taylor", "John", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1810.01477", "submitter": "Houssam Nassif", "authors": "Choon Hui Teo, Houssam Nassif, Daniel Hill, Sriram Srinavasan,\n  Mitchell Goodman, Vijai Mohan, SVN Vishwanathan", "title": "Adaptive, Personalized Diversity for Visual Discovery", "comments": "Best Paper Award", "journal-ref": "Adaptive, Personalized Diversity for Visual Discovery. Teo CH,\n  Nassif H, Hill D, Srinavasan S, Goodman M, Mohan V, and Vishwanathan SVN. ACM\n  Conference on Recommender Systems (RecSys'16), Boston, pp. 35-38, 2016", "doi": "10.1145/2959100.2959171", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search queries are appropriate when users have explicit intent, but they\nperform poorly when the intent is difficult to express or if the user is simply\nlooking to be inspired. Visual browsing systems allow e-commerce platforms to\naddress these scenarios while offering the user an engaging shopping\nexperience. Here we explore extensions in the direction of adaptive\npersonalization and item diversification within Stream, a new form of visual\nbrowsing and discovery by Amazon. Our system presents the user with a diverse\nset of interesting items while adapting to user interactions. Our solution\nconsists of three components (1) a Bayesian regression model for scoring the\nrelevance of items while leveraging uncertainty, (2) a submodular\ndiversification framework that re-ranks the top scoring items based on\ncategory, and (3) personalized category preferences learned from the user's\nbehavior. When tested on live traffic, our algorithms show a strong lift in\nclick-through-rate and session duration.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 19:51:46 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Teo", "Choon Hui", ""], ["Nassif", "Houssam", ""], ["Hill", "Daniel", ""], ["Srinavasan", "Sriram", ""], ["Goodman", "Mitchell", ""], ["Mohan", "Vijai", ""], ["Vishwanathan", "SVN", ""]]}, {"id": "1810.01480", "submitter": "Julia Kreutzer", "authors": "Julia Kreutzer, Artem Sokolov", "title": "Learning to Segment Inputs for NMT Favors Character-Level Processing", "comments": "Technical report for IWSLT 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern neural machine translation (NMT) systems rely on presegmented\ninputs. Segmentation granularity importantly determines the input and output\nsequence lengths, hence the modeling depth, and source and target vocabularies,\nwhich in turn determine model size, computational costs of softmax\nnormalization, and handling of out-of-vocabulary words. However, the current\npractice is to use static, heuristic-based segmentations that are fixed before\nNMT training. This begs the question whether the chosen segmentation is optimal\nfor the translation task. To overcome suboptimal segmentation choices, we\npresent an algorithm for dynamic segmentation based on the Adaptative\nComputation Time algorithm (Graves 2016), that is trainable end-to-end and\ndriven by the NMT objective. In an evaluation on four translation tasks we\nfound that, given the freedom to navigate between different segmentation\nlevels, the model prefers to operate on (almost) character level, providing\nsupport for purely character-level NMT models from a novel angle.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 19:52:38 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 10:21:05 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 09:14:21 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Kreutzer", "Julia", ""], ["Sokolov", "Artem", ""]]}, {"id": "1810.01483", "submitter": "Jo\\~ao Caldeira", "authors": "Jo\\~ao Caldeira, W. L. Kimmy Wu, Brian Nord, Camille Avestruz,\n  Shubhendu Trivedi, Kyle T. Story", "title": "DeepCMB: Lensing Reconstruction of the Cosmic Microwave Background with\n  Deep Neural Networks", "comments": "19 pages; LaTeX; 12 figures; changes to match published version", "journal-ref": "Astronomy and Computing 28 100307 (2019)", "doi": "10.1016/j.ascom.2019.100307", "report-no": "FERMILAB-PUB-18-515-A-CD", "categories": "astro-ph.CO cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation cosmic microwave background (CMB) experiments will have lower\nnoise and therefore increased sensitivity, enabling improved constraints on\nfundamental physics parameters such as the sum of neutrino masses and the\ntensor-to-scalar ratio r. Achieving competitive constraints on these parameters\nrequires high signal-to-noise extraction of the projected gravitational\npotential from the CMB maps. Standard methods for reconstructing the lensing\npotential employ the quadratic estimator (QE). However, the QE performs\nsuboptimally at the low noise levels expected in upcoming experiments. Other\nmethods, like maximum likelihood estimators (MLE), are under active\ndevelopment. In this work, we demonstrate reconstruction of the CMB lensing\npotential with deep convolutional neural networks (CNN) - ie, a ResUNet. The\nnetwork is trained and tested on simulated data, and otherwise has no physical\nparametrization related to the physical processes of the CMB and gravitational\nlensing. We show that, over a wide range of angular scales, ResUNets recover\nthe input gravitational potential with a higher signal-to-noise ratio than the\nQE method, reaching levels comparable to analytic approximations of MLE\nmethods. We demonstrate that the network outputs quantifiably different lensing\nmaps when given input CMB maps generated with different cosmologies. We also\nshow we can use the reconstructed lensing map for cosmological parameter\nestimation. This application of CNN provides a few innovations at the\nintersection of cosmology and machine learning. First, while training and\nregressing on images, we predict a continuous-variable field rather than\ndiscrete classes. Second, we are able to establish uncertainty measures for the\nnetwork output that are analogous to standard methods. We expect this approach\nto excel in capturing hard-to-model non-Gaussian astrophysical foreground and\nnoise contributions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:04:07 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 14:56:24 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 22:33:45 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Caldeira", "Jo\u00e3o", ""], ["Wu", "W. L. Kimmy", ""], ["Nord", "Brian", ""], ["Avestruz", "Camille", ""], ["Trivedi", "Shubhendu", ""], ["Story", "Kyle T.", ""]]}, {"id": "1810.01488", "submitter": "Maruti Mudunuru", "authors": "B. Yuan, Y. J. Tan, M. K. Mudunuru, O. E. Marcillo, A. A. Delorey, P.\n  M. Roberts, J. D. Webster, C. N. L. Gammans, S. Karra, G. D. Guthrie, and P.\n  A. Johnson", "title": "Using Machine Learning to Discern Eruption in Noisy Environments: A Case\n  Study using CO2-driven Cold-Water Geyser in Chimayo, New Mexico", "comments": "16 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.data-an physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach based on machine learning (ML) to distinguish eruption\nand precursory signals of Chimay\\'{o} geyser (New Mexico, USA) under noisy\nenvironments. This geyser can be considered as a natural analog of\n$\\mathrm{CO}_2$ intrusion into shallow water aquifers. By studying this geyser,\nwe can understand upwelling of $\\mathrm{CO}_2$-rich fluids from depth, which\nhas relevance to leak monitoring in a $\\mathrm{CO}_2$ sequestration project. ML\nmethods such as Random Forests (RF) are known to be robust multi-class\nclassifiers and perform well under unfavorable noisy conditions. However, the\nextent of the RF method's accuracy is poorly understood for this\n$\\mathrm{CO}_2$-driven geysering application. The current study aims to\nquantify the performance of RF-classifiers to discern the geyser state. Towards\nthis goal, we first present the data collected from the seismometer that is\ninstalled near the Chimay\\'{o} geyser. The seismic signals collected at this\nsite contain different types of noises such as daily temperature variations,\nseasonal trends, animal movement near the geyser, and human activity. First, we\nfilter the signals from these noises by combining the Butterworth-Highpass\nfilter and an Autoregressive method in a multi-level fashion. We show that by\ncombining these filtering techniques, in a hierarchical fashion, leads to\nreduction in the noise in the seismic data without removing the precursors and\neruption event signals. We then use RF on the filtered data to classify the\nstate of geyser into three classes -- remnant noise, precursor, and eruption\nstates. We show that the classification accuracy using RF on the filtered data\nis greater than 90\\%.These aspects make the proposed ML framework attractive\nfor event discrimination and signal enhancement under noisy conditions, with\nstrong potential for application to monitoring leaks in $\\mathrm{CO}_2$\nsequestration.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 15:47:34 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Yuan", "B.", ""], ["Tan", "Y. J.", ""], ["Mudunuru", "M. K.", ""], ["Marcillo", "O. E.", ""], ["Delorey", "A. A.", ""], ["Roberts", "P. M.", ""], ["Webster", "J. D.", ""], ["Gammans", "C. N. L.", ""], ["Karra", "S.", ""], ["Guthrie", "G. D.", ""], ["Johnson", "P. A.", ""]]}, {"id": "1810.01509", "submitter": "Tianxi Li", "authors": "Tianxi Li, Lihua Lei, Sharmodeep Bhattacharyya, Koen Van den Berge,\n  Purnamrita Sarkar, Peter J. Bickel, Elizaveta Levina", "title": "Hierarchical community detection by recursive partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of community detection in networks is usually formulated as\nfinding a single partition of the network into some \"correct\" number of\ncommunities. We argue that it is more interpretable and in some regimes more\naccurate to construct a hierarchical tree of communities instead. This can be\ndone with a simple top-down recursive partitioning algorithm, starting with a\nsingle community and separating the nodes into two communities by spectral\nclustering repeatedly, until a stopping rule suggests there are no further\ncommunities. This class of algorithms is model-free, computationally efficient,\nand requires no tuning other than selecting a stopping rule. We show that there\nare regimes where this approach outperforms K-way spectral clustering, and\npropose a natural framework for analyzing the algorithm's theoretical\nperformance, the binary tree stochastic block model. Under this model, we prove\nthat the algorithm correctly recovers the entire community tree under\nrelatively mild assumptions. We apply the algorithm to a gene network based on\ngene co-occurrence in 1580 research papers on anemia, and identify six clusters\nof genes in a meaningful hierarchy. We also illustrate the algorithm on a\ndataset of statistics papers.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:58:20 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 06:41:52 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 22:43:37 GMT"}, {"version": "v4", "created": "Thu, 7 Mar 2019 19:46:12 GMT"}, {"version": "v5", "created": "Fri, 13 Sep 2019 04:37:41 GMT"}, {"version": "v6", "created": "Thu, 14 May 2020 05:53:24 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Li", "Tianxi", ""], ["Lei", "Lihua", ""], ["Bhattacharyya", "Sharmodeep", ""], ["Berge", "Koen Van den", ""], ["Sarkar", "Purnamrita", ""], ["Bickel", "Peter J.", ""], ["Levina", "Elizaveta", ""]]}, {"id": "1810.01539", "submitter": "Lawrence Murray", "authors": "Lawrence M. Murray and Thomas B. Sch\\\"on", "title": "Automated learning with a probabilistic programming language: Birch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work offers a broad perspective on probabilistic modeling and inference\nin light of recent advances in probabilistic programming, in which models are\nformally expressed in Turing-complete programming languages. We consider a\ntypical workflow and how probabilistic programming languages can help to\nautomate this workflow, especially in the matching of models with inference\nmethods. We focus on two properties of a model that are critical in this\nmatching: its structure---the conditional dependencies between random\nvariables---and its form---the precise mathematical definition of those\ndependencies. While the structure and form of a probabilistic model are often\nfixed a priori, it is a curiosity of probabilistic programming that they need\nnot be, and may instead vary according to random choices made during program\nexecution. We introduce a formal description of models expressed as programs,\nand discuss some of the ways in which probabilistic programming languages can\nreveal the structure and form of these, in order to tailor inference methods.\nWe demonstrate the ideas with a new probabilistic programming language called\nBirch, with a multiple object tracking example.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 23:00:36 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 00:16:13 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Murray", "Lawrence M.", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1810.01545", "submitter": "Clayton Scott", "authors": "Clayton Scott", "title": "A Generalized Neyman-Pearson Criterion for Optimal Domain Adaptation", "comments": "ALT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of domain adaptation for binary classification, the learner is\npresented with labeled examples from a source domain, and must correctly\nclassify unlabeled examples from a target domain, which may differ from the\nsource. Previous work on this problem has assumed that the performance measure\nof interest is the expected value of some loss function. We introduce a new\nNeyman-Pearson-like criterion and argue that, for this optimality criterion,\nstronger domain adaptation results are possible than what has previously been\nestablished. In particular, we study a class of domain adaptation problems that\ngeneralizes both the covariate shift assumption and a model for\nfeature-dependent label noise, and establish optimal classification on the\ntarget domain despite not having access to labelled data from this domain.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 00:16:41 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 20:43:00 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Scott", "Clayton", ""]]}, {"id": "1810.01566", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Jiajun Wu, Russ Tedrake, Joshua B. Tenenbaum, Antonio\n  Torralba", "title": "Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable\n  Objects, and Fluids", "comments": "Accepted to ICLR 2019. Project Page: http://dpi.csail.mit.edu Video:\n  https://www.youtube.com/watch?v=FrPpP7aW3Lg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-life control tasks involve matters of various substances---rigid or soft\nbodies, liquid, gas---each with distinct physical behaviors. This poses\nchallenges to traditional rigid-body physics engines. Particle-based simulators\nhave been developed to model the dynamics of these complex scenes; however,\nrelying on approximation techniques, their simulation often deviates from\nreal-world physics, especially in the long term. In this paper, we propose to\nlearn a particle-based simulator for complex control tasks. Combining learning\nwith particle-based systems brings in two major benefits: first, the learned\nsimulator, just like other particle-based systems, acts widely on objects of\ndifferent materials; second, the particle-based representation poses strong\ninductive bias for learning: particles of the same type have the same dynamics\nwithin. This enables the model to quickly adapt to new environments of unknown\ndynamics within a few observations. We demonstrate robots achieving complex\nmanipulation tasks using the learned simulator, such as manipulating fluids and\ndeformable foam, with experiments both in simulation and in the real world. Our\nstudy helps lay the foundation for robot learning of dynamic scenes with\nparticle-based representations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 02:10:16 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 00:37:03 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Li", "Yunzhu", ""], ["Wu", "Jiajun", ""], ["Tedrake", "Russ", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""]]}, {"id": "1810.01575", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Guandao Yang, Aditya Prakash, Qiuren Fang, Hanqing\n  Jiang, Bharath Hariharan, Serge Belongie", "title": "Deep Fundamental Matrix Estimation without Correspondences", "comments": "ECCV 2018, Geometry Meets Deep Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating fundamental matrices is a classic problem in computer vision.\nTraditional methods rely heavily on the correctness of estimated key-point\ncorrespondences, which can be noisy and unreliable. As a result, it is\ndifficult for these methods to handle image pairs with large occlusion or\nsignificantly different camera poses. In this paper, we propose novel neural\nnetwork architectures to estimate fundamental matrices in an end-to-end manner\nwithout relying on point correspondences. New modules and layers are introduced\nin order to preserve mathematical properties of the fundamental matrix as a\nhomogeneous rank-2 matrix with seven degrees of freedom. We analyze performance\nof the proposed models using various metrics on the KITTI dataset, and show\nthat they achieve competitive performance with traditional methods without the\nneed for extracting correspondences.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 03:59:15 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Poursaeed", "Omid", ""], ["Yang", "Guandao", ""], ["Prakash", "Aditya", ""], ["Fang", "Qiuren", ""], ["Jiang", "Hanqing", ""], ["Hariharan", "Bharath", ""], ["Belongie", "Serge", ""]]}, {"id": "1810.01588", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe", "title": "Interpreting Layered Neural Networks via Hierarchical Modular\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting the prediction mechanism of complex models is currently one of\nthe most important tasks in the machine learning field, especially with layered\nneural networks, which have achieved high predictive performance with various\npractical data sets. To reveal the global structure of a trained neural network\nin an interpretable way, a series of clustering methods have been proposed,\nwhich decompose the units into clusters according to the similarity of their\ninference roles. The main problems in these studies were that (1) we have no\nprior knowledge about the optimal resolution for the decomposition, or the\nappropriate number of clusters, and (2) there was no method with which to\nacquire knowledge about whether the outputs of each cluster have a positive or\nnegative correlation with the input and output dimension values. In this paper,\nto solve these problems, we propose a method for obtaining a hierarchical\nmodular representation of a layered neural network. The application of a\nhierarchical clustering method to a trained network reveals a tree-structured\nrelationship among hidden layer units, based on their feature vectors defined\nby their correlation with the input and output dimension values.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 05:38:26 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Watanabe", "Chihiro", ""]]}, {"id": "1810.01675", "submitter": "Sanjay Chaudhuri", "authors": "Sanjay Chaudhuri, Subhro Ghosh, David J. Nott, Kim Cuc Pham", "title": "An easy-to-use empirical likelihood ABC method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientifically well-motivated statistical models in natural, engineering\nand environmental sciences are specified through a generative process, but in\nsome cases it may not be possible to write down a likelihood for these models\nanalytically. Approximate Bayesian computation (ABC) methods, which allow\nBayesian inference in these situations, are typically computationally\nintensive. Recently, computationally attractive empirical likelihood based ABC\nmethods have been suggested in the literature. These methods heavily rely on\nthe availability of a set of suitable analytically tractable estimating\nequations. We propose an easy-to-use empirical likelihood ABC method, where the\nonly inputs required are a choice of summary statistic, it's observed value,\nand the ability to simulate summary statistics for any parameter value under\nthe model. It is shown that the posterior obtained using the proposed method is\nconsistent, and its performance is explored using various examples.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 10:37:31 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 11:20:19 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Chaudhuri", "Sanjay", ""], ["Ghosh", "Subhro", ""], ["Nott", "David J.", ""], ["Pham", "Kim Cuc", ""]]}, {"id": "1810.01683", "submitter": "Ichiro Takeuchi Prof.", "authors": "Hiroki Kato, Hiroyuki Hanada, Ichiro Takeuchi", "title": "Learning sparse optimal rule fit by safe screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider linear prediction models in the form of a sparse\nlinear combination of rules, where a rule is an indicator function defined over\na hyperrectangle in the input space. Since the number of all possible rules\ngenerated from the training dataset becomes extremely large, it has been\ndifficult to consider all of them when fitting a sparse model. In this paper,\nwe propose Safe Optimal Rule Fit (SORF) as an approach to resolve this problem,\nwhich is formulated as a convex optimization problem with sparse\nregularization. The proposed SORF method utilizes the fact that the set of all\npossible rules can be represented as a tree. By extending a recently\npopularized convex optimization technique called safe screening, we develop a\nnovel method for pruning the tree such that pruned nodes are guaranteed to be\nirrelevant to the prediction model. This approach allows us to efficiently\nlearn a prediction model constructed from an exponentially large number of all\npossible rules. We demonstrate the usefulness of the proposed method by\nnumerical experiments using several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 10:55:08 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Kato", "Hiroki", ""], ["Hanada", "Hiroyuki", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1810.01720", "submitter": "Tomohiro Nishiyama", "authors": "Tomohiro Nishiyama", "title": "Sum decomposition of divergence into three divergences", "comments": "9pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divergence functions play a key role as to measure the discrepancy between\ntwo points in the field of machine learning, statistics and signal processing.\nWell-known divergences are the Bregman divergences, the Jensen divergences and\nthe f-divergences. In this paper, we show that the symmetric Bregman divergence\ncan be decomposed into the sum of two types of Jensen divergences and the\nBregman divergence. Furthermore, applying this result, we show another sum\ndecomposition of divergence is possible which includes f-divergences\nexplicitly.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:02:19 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 08:17:30 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Nishiyama", "Tomohiro", ""]]}, {"id": "1810.01724", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep (DEEP) Mukhopadhyay and Kaijun Wang", "title": "A Nonparametric Approach to High-dimensional k-sample Comparison\n  Problems", "comments": "Biometrika (in press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional k-sample comparison is a common applied problem. We\nconstruct a class of easy-to-implement nonparametric distribution-free tests\nbased on new tools and unexplored connections with spectral graph theory. The\ntest is shown to possess various desirable properties along with a\ncharacteristic exploratory flavor that has practical consequences. The\nnumerical examples show that our method works surprisingly well under a broad\nrange of realistic situations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:20:28 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 18:40:50 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Subhadeep", "", "", "DEEP"], ["Mukhopadhyay", "", ""], ["Wang", "Kaijun", ""]]}, {"id": "1810.01765", "submitter": "Ramy Baly", "authors": "Ramy Baly (1), Georgi Karadzhov (3), Dimitar Alexandrov (3), James\n  Glass (1), Preslav Nakov (2) ((1) MIT Computer Science and Artificial\n  Intelligence Laboratory, (2) Qatar Computing Research Institute, HBKU, Qatar,\n  (3) Sofia University, Bulgaria)", "title": "Predicting Factuality of Reporting and Bias of News Media Sources", "comments": "Fact-checking, political ideology, news media, EMNLP-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study on predicting the factuality of reporting and bias of news\nmedia. While previous work has focused on studying the veracity of claims or\ndocuments, here we are interested in characterizing entire news media. These\nare under-studied but arguably important research problems, both in their own\nright and as a prior for fact-checking systems. We experiment with a large list\nof news websites and with a rich set of features derived from (i) a sample of\narticles from the target news medium, (ii) its Wikipedia page, (iii) its\nTwitter account, (iv) the structure of its URL, and (v) information about the\nWeb traffic it attracts. The experimental results show sizable performance\ngains over the baselines, and confirm the importance of each feature type.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:27:04 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Baly", "Ramy", ""], ["Karadzhov", "Georgi", ""], ["Alexandrov", "Dimitar", ""], ["Glass", "James", ""], ["Nakov", "Preslav", ""]]}, {"id": "1810.01778", "submitter": "Juho Lee", "authors": "Juho Lee, Lancelot F. James, Seungjin Choi, Fran\\c{c}ois Caron", "title": "A Bayesian model for sparse graphs with flexible degree distribution and\n  overlapping community structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a non-projective class of inhomogeneous random graph models with\ninterpretable parameters and a number of interesting asymptotic properties.\nUsing the results of Bollob\\'as et al. [2007], we show that i) the class of\nmodels is sparse and ii) depending on the choice of the parameters, the model\nis either scale-free, with power-law exponent greater than 2, or with an\nasymptotic degree distribution which is power-law with exponential cut-off. We\npropose an extension of the model that can accommodate an overlapping community\nstructure. Scalable posterior inference can be performed due to the specific\nchoice of the link probability. We present experiments on five different\nreal-world networks with up to 100,000 nodes and edges, showing that the model\ncan provide a good fit to the degree distribution and recovers well the latent\ncommunity structure.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 14:47:18 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Lee", "Juho", ""], ["James", "Lancelot F.", ""], ["Choi", "Seungjin", ""], ["Caron", "Fran\u00e7ois", ""]]}, {"id": "1810.01807", "submitter": "Romain Hennequin", "authors": "Jimena Royo-Letelier, Romain Hennequin, Viet-Anh Tran, Manuel\n  Moussallam", "title": "Disambiguating Music Artists at Scale with Audio Metric Learning", "comments": "published in ISMIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of disambiguating large scale catalogs through the\ndefinition of an unknown artist clustering task. We explore the use of metric\nlearning techniques to learn artist embeddings directly from audio, and using a\ndedicated homonym artists dataset, we compare our method with a recent approach\nthat learn similar embeddings using artist classifiers. While both systems have\nthe ability to disambiguate unknown artists relying exclusively on audio, we\nshow that our system is more suitable in the case when enough audio data is\navailable for each artist in the train dataset. We also propose a new negative\nsampling method for metric learning that takes advantage of side information\nsuch as music genre during the learning phase and shows promising results for\nthe artist clustering task.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 15:49:43 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Royo-Letelier", "Jimena", ""], ["Hennequin", "Romain", ""], ["Tran", "Viet-Anh", ""], ["Moussallam", "Manuel", ""]]}, {"id": "1810.01811", "submitter": "Pratik Jawanpuria", "authors": "Mayank Meghwanshi, Pratik Jawanpuria, Anoop Kunchukuttan, Hiroyuki\n  Kasai, Bamdev Mishra", "title": "McTorch, a manifold optimization library for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce McTorch, a manifold optimization library for deep\nlearning that extends PyTorch. It aims to lower the barrier for users wishing\nto use manifold constraints in deep learning applications, i.e., when the\nparameters are constrained to lie on a manifold. Such constraints include the\npopular orthogonality and rank constraints, and have been recently used in a\nnumber of applications in deep learning. McTorch follows PyTorch's architecture\nand decouples manifold definitions and optimizers, i.e., once a new manifold is\nadded it can be used with any existing optimizer and vice-versa. McTorch is\navailable at https://github.com/mctorch .\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:02:20 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 04:12:12 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Meghwanshi", "Mayank", ""], ["Jawanpuria", "Pratik", ""], ["Kunchukuttan", "Anoop", ""], ["Kasai", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1810.01859", "submitter": "Houssam Nassif", "authors": "Neela Sawant, Chitti Babu Namballa, Narayanan Sadagopan, and Houssam\n  Nassif", "title": "Contextual Multi-Armed Bandits for Causal Marketing", "comments": null, "journal-ref": "Sawant N, Namballa CB, Sadagopan N, and Nassif H. Contextual\n  Multi-Armed Bandits for Causal Marketing. International Conference on Machine\n  Learning (ICML'18) Workshops, Stockholm, Sweden, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the idea of a causal contextual multi-armed bandit\napproach to automated marketing, where we estimate and optimize the causal\n(incremental) effects. Focusing on causal effect leads to better return on\ninvestment (ROI) by targeting only the persuadable customers who wouldn't have\ntaken the action organically. Our approach draws on strengths of causal\ninference, uplift modeling, and multi-armed bandits. It optimizes on causal\ntreatment effects rather than pure outcome, and incorporates counterfactual\ngeneration within data collection. Following uplift modeling results, we\noptimize over the incremental business metric. Multi-armed bandit methods allow\nus to scale to multiple treatments and to perform off-policy policy evaluation\non logged data. The Thompson sampling strategy in particular enables\nexploration of treatments on similar customer contexts and materialization of\ncounterfactual outcomes. Preliminary offline experiments on a retail Fashion\nmarketing dataset show merits of our proposal.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:59:07 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Sawant", "Neela", ""], ["Namballa", "Chitti Babu", ""], ["Sadagopan", "Narayanan", ""], ["Nassif", "Houssam", ""]]}, {"id": "1810.01860", "submitter": "Luke Darlow", "authors": "Luke N. Darlow, Amos J. Storkey", "title": "GINN: Geometric Illustration of Neural Networks", "comments": "8 pages, 9 figures, technical report", "journal-ref": null, "doi": null, "report-no": "EDI-INF-ANC-1901", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This informal technical report details the geometric illustration of decision\nboundaries for ReLU units in a three layer fully connected neural network. The\nnetwork is designed and trained to predict pixel intensity from an (x, y) input\nlocation. The Geometric Illustration of Neural Networks (GINN) tool was built\nto visualise and track the points at which ReLU units switch from being active\nto off (or vice versa) as the network undergoes training. Several phenomenon\nwere observed and are discussed herein. This technical report is a supporting\ndocument to the blog post with online demos and is available at\nhttp://www.bayeswatch.com/2018/09/17/GINN/.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 21:28:00 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Darlow", "Luke N.", ""], ["Storkey", "Amos J.", ""]]}, {"id": "1810.01861", "submitter": "Mateusz Susik", "authors": "Marcin Mo\\.zejko, Mateusz Susik, Rafa{\\l} Karczewski", "title": "Inhibited Softmax for Uncertainty Estimation in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for uncertainty estimation and out-of-distribution\ndetection in neural networks with softmax output. We extend softmax layer with\nan additional constant input. The corresponding additional output is able to\nrepresent the uncertainty of the network. The proposed method requires neither\nadditional parameters nor multiple forward passes nor input preprocessing nor\nout-of-distribution datasets. We show that our method performs comparably to\nmore computationally expensive methods and outperforms baselines on our\nexperiments from image recognition and sentiment analysis domains.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:18:11 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 08:43:59 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Mo\u017cejko", "Marcin", ""], ["Susik", "Mateusz", ""], ["Karczewski", "Rafa\u0142", ""]]}, {"id": "1810.01864", "submitter": "Aryeh Kontorovich", "authors": "Steve Hanneke, Aryeh Kontorovich, Menachem Sadigurschi", "title": "Agnostic Sample Compression for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain the first positive results for bounded sample compression in the\nagnostic regression setting. We show that for p in {1,infinity}, agnostic\nlinear regression with $\\ell_p$ loss admits a bounded sample compression\nscheme. Specifically, we exhibit efficient sample compression schemes for\nagnostic linear regression in $R^d$ of size $d+1$ under the $\\ell_1$ loss and\nsize $d+2$ under the $\\ell_\\infty$ loss. We further show that for every other\n$\\ell_p$ loss (1 < p < infinity), there does not exist an agnostic compression\nscheme of bounded size. This refines and generalizes a negative result of\nDavid, Moran, and Yehudayoff (2016) for the $\\ell_2$ loss. We close by posing a\ngeneral open question: for agnostic regression with $\\ell_1$ loss, does every\nfunction class admit a compression scheme of size equal to its\npseudo-dimension? This question generalizes Warmuth's classic sample\ncompression conjecture for realizable-case classification (Warmuth, 2003).\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 11:46:59 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Hanneke", "Steve", ""], ["Kontorovich", "Aryeh", ""], ["Sadigurschi", "Menachem", ""]]}, {"id": "1810.01865", "submitter": "Federico Pittino", "authors": "Federico Pittino, Roberto Diversi, Luca Benini, Andrea Bartolini", "title": "Robust identification of thermal models for in-production\n  High-Performance-Computing clusters with machine learning-based data\n  selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power and thermal management are critical components of\nHigh-Performance-Computing (HPC) systems, due to their high power density and\nlarge total power consumption. The assessment of thermal dissipation by means\nof compact models directly from the thermal response of the final device\nenables more robust and precise thermal control strategies as well as automated\ndiagnosis. However, when dealing with large scale systems \"in production\", the\naccuracy of learned thermal models depends on the dynamics of the power\nexcitation, which depends also on the executed workload, and measurement\nnonidealities, such as quantization. In this paper we show that, using an\nadvanced system identification algorithm, we are able to generate very accurate\nthermal models (average error lower than our sensors quantization step of\n1{\\deg}C) for a large scale HPC system on real workloads for very long time\nperiods. However, we also show that: 1) not all real workloads allow for the\nidentification of a good model; 2) starting from the theory of system\nidentification it is very difficult to evaluate if a trace of data leads to a\ngood estimated model. We then propose and validate a set of techniques based on\nmachine learning and deep learning algorithms for the choice of data traces to\nbe used for model identification. We also show that deep learning techniques\nare absolutely necessary to correctly choose such traces up to 96% of the\ntimes.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 12:11:20 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 17:09:24 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Pittino", "Federico", ""], ["Diversi", "Roberto", ""], ["Benini", "Luca", ""], ["Bartolini", "Andrea", ""]]}, {"id": "1810.01866", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Alexander V. Terekhov, Bruno Gas, J.Kevin O'Regan", "title": "Learning an internal representation of the end-effector configuration\n  space", "comments": "6 pages, 3 figures, IROS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current machine learning techniques proposed to automatically discover a\nrobot kinematics usually rely on a priori information about the robot's\nstructure, sensors properties or end-effector position. This paper proposes a\nmethod to estimate a certain aspect of the forward kinematics model with no\nsuch information. An internal representation of the end-effector configuration\nis generated from unstructured proprioceptive and exteroceptive data flow under\nvery limited assumptions. A mapping from the proprioceptive space to this\nrepresentational space can then be used to control the robot.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 12:56:08 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Terekhov", "Alexander V.", ""], ["Gas", "Bruno", ""], ["O'Regan", "J. Kevin", ""]]}, {"id": "1810.01867", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Sylvain Argentieri, Olivia Breysse, St\\'ephane\n  Genet, Bruno Gas", "title": "A Non-linear Approach to Space Dimension Perception by a Naive Agent", "comments": "7 pages, 6 images, published at IROS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developmental Robotics offers a new approach to numerous AI features that are\noften taken as granted. Traditionally, perception is supposed to be an inherent\ncapacity of the agent. Moreover, it largely relies on models built by the\nsystem's designer. A new approach is to consider perception as an\nexperimentally acquired ability that is learned exclusively through the\nanalysis of the agent's sensorimotor flow. Previous works, based on\nH.Poincar\\'e's intuitions and the sensorimotor contingencies theory, allow a\nsimulated agent to extract the dimension of geometrical space in which it is\nimmersed without any a priori knowledge. Those results are limited to\ninfinitesimal movement's amplitude of the system. In this paper, a non-linear\ndimension estimation method is proposed to push back this limitation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:09:41 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Argentieri", "Sylvain", ""], ["Breysse", "Olivia", ""], ["Genet", "St\u00e9phane", ""], ["Gas", "Bruno", ""]]}, {"id": "1810.01868", "submitter": "{\\L}ukasz Maziarka", "authors": "{\\L}ukasz Maziarka, Marek \\'Smieja, Aleksandra Nowak, Jacek Tabor,\n  {\\L}ukasz Struski, Przemys{\\l}aw Spurek", "title": "Set Aggregation Network as a Trainable Pooling Layer", "comments": "ICONIP 2019", "journal-ref": "Neural Information Processing. ICONIP 2019", "doi": "10.1007/978-3-030-36711-4_35", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global pooling, such as max- or sum-pooling, is one of the key ingredients in\ndeep neural networks used for processing images, texts, graphs and other types\nof structured data. Based on the recent DeepSets architecture proposed by\nZaheer et al. (NIPS 2017), we introduce a Set Aggregation Network (SAN) as an\nalternative global pooling layer. In contrast to typical pooling operators, SAN\nallows to embed a given set of features to a vector representation of arbitrary\nsize. We show that by adjusting the size of embedding, SAN is capable of\npreserving the whole information from the input. In experiments, we demonstrate\nthat replacing global pooling layer by SAN leads to the improvement of\nclassification accuracy. Moreover, it is less prone to overfitting and can be\nused as a regularizer.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:20:13 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 08:44:25 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 10:25:02 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Maziarka", "\u0141ukasz", ""], ["\u015amieja", "Marek", ""], ["Nowak", "Aleksandra", ""], ["Tabor", "Jacek", ""], ["Struski", "\u0141ukasz", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "1810.01869", "submitter": "David Noever", "authors": "David Noever", "title": "Machine Learning Suites for Online Toxicity Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To identify and classify toxic online commentary, the modern tools of data\nscience transform raw text into key features from which either thresholding or\nlearning algorithms can make predictions for monitoring offensive\nconversations. We systematically evaluate 62 classifiers representing 19 major\nalgorithmic families against features extracted from the Jigsaw dataset of\nWikipedia comments. We compare the classifiers based on statistically\nsignificant differences in accuracy and relative execution time. Among these\nclassifiers for identifying toxic comments, tree-based algorithms provide the\nmost transparently explainable rules and rank-order the predictive contribution\nof each feature. Among 28 features of syntax, sentiment, emotion and outlier\nword dictionaries, a simple bad word list proves most predictive of offensive\ncommentary.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:22:44 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Noever", "David", ""]]}, {"id": "1810.01870", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Nikolas Hemion, Micha\\\"el Garcia Ortiz,\n  Jean-Christophe Baillie", "title": "Grounding Perception: A Developmental Approach to Sensorimotor\n  Contingencies", "comments": "8 pages, 4 figures, workshop at IROS 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensorimotor contingency theory offers a promising account of the nature of\nperception, a topic rarely addressed in the robotics community. We propose a\ndevelopmental framework to address the problem of the autonomous acquisition of\nsensorimotor contingencies by a naive robot. While exploring the world, the\nrobot internally encodes contingencies as predictive models that capture the\nstructure they imply in its sensorimotor experience. Three preliminary\napplications are presented to illustrate our approach to the acquisition of\nperceptive abilities: discovering the environment, discovering objects, and\ndiscovering a visual field.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:31:41 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Hemion", "Nikolas", ""], ["Ortiz", "Micha\u00ebl Garcia", ""], ["Baillie", "Jean-Christophe", ""]]}, {"id": "1810.01871", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere", "title": "Grounding the Experience of a Visual Field through Sensorimotor\n  Contingencies", "comments": "23 pages, 7 figures, published in Neurocomputing", "journal-ref": "Neurocomputing, Volume 268, 13 December 2017, Pages 142-152", "doi": "10.1016/j.neucom.2016.11.085", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial perception is traditionally handled by hand-designing task\nspecific algorithms. However, a truly autonomous robot should develop\nperceptive abilities on its own, by interacting with its environment, and\nadapting to new situations. The sensorimotor contingencies theory proposes to\nground the development of those perceptive abilities in the way the agent can\nactively transform its sensory inputs. We propose a sensorimotor approach,\ninspired by this theory, in which the agent explores the world and discovers\nits properties by capturing the sensorimotor regularities they induce. This\nwork presents an application of this approach to the discovery of a so-called\nvisual field as the set of regularities that a visual sensor imposes on a naive\nagent's experience. A formalism is proposed to describe how those regularities\ncan be captured in a sensorimotor predictive model. Finally, the approach is\nevaluated on a simulated system coarsely inspired from the human retina.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:42:43 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1810.01872", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, J.Kevin O'Regan, Sylvain Argentieri, Bruno Gas,\n  Alexander V. Terekhov", "title": "Learning agent's spatial configuration from sensorimotor invariants", "comments": "26 pages, 5 images, published in Robotics and Autonomous Systems", "journal-ref": "Robotics and Autonomous Systems, Volume 71, September 2015, Pages\n  49-59", "doi": "10.1016/j.robot.2015.01.003", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of robotic systems is largely dictated by our purely human\nintuition about how we perceive the world. This intuition has been proven\nincorrect with regard to a number of critical issues, such as visual change\nblindness. In order to develop truly autonomous robots, we must step away from\nthis intuition and let robotic agents develop their own way of perceiving. The\nrobot should start from scratch and gradually develop perceptual notions, under\nno prior assumptions, exclusively by looking into its sensorimotor experience\nand identifying repetitive patterns and invariants. One of the most fundamental\nperceptual notions, space, cannot be an exception to this requirement. In this\npaper we look into the prerequisites for the emergence of simplified spatial\nnotions on the basis of a robot's sensorimotor flow. We show that the notion of\nspace as environment-independent cannot be deduced solely from exteroceptive\ninformation, which is highly variable and is mainly determined by the contents\nof the environment. The environment-independent definition of space can be\napproached by looking into the functions that link the motor commands to\nchanges in exteroceptive inputs. In a sufficiently rich environment, the\nkernels of these functions correspond uniquely to the spatial configuration of\nthe agent's exteroceptors. We simulate a redundant robotic arm with a retina\ninstalled at its end-point and show how this agent can learn the configuration\nspace of its retina. The resulting manifold has the topology of the Cartesian\nproduct of a plane and a circle, and corresponds to the planar position and\norientation of the retina.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:48:43 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["O'Regan", "J. Kevin", ""], ["Argentieri", "Sylvain", ""], ["Gas", "Bruno", ""], ["Terekhov", "Alexander V.", ""]]}, {"id": "1810.01873", "submitter": "Mustafa Haider", "authors": "Adnan Haider and P.C. Woodland", "title": "Combining Natural Gradient with Hessian Free Methods for Sequence\n  Training", "comments": "in Proc. INTERSPEECH 2018, September 2-6, 2018, Hyderabad, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new optimisation approach to train Deep Neural Networks\n(DNNs) with discriminative sequence criteria. At each iteration, the method\ncombines information from the Natural Gradient (NG) direction with local\ncurvature information of the error surface that enables better paths on the\nparameter manifold to be traversed. The method is derived using an alternative\nderivation of Taylor's theorem using the concepts of manifolds, tangent vectors\nand directional derivatives from the perspective of Information Geometry. The\nefficacy of the method is shown within a Hessian Free (HF) style optimisation\nframework to sequence train both standard fully-connected DNNs and Time Delay\nNeural Networks as speech recognition acoustic models. It is shown that for the\nsame number of updates the proposed approach achieves larger reductions in the\nword error rate (WER) than both NG and HF, and also leads to a lower WER than\nstandard stochastic gradient descent. The paper also addresses the issue of\nover-fitting due to mismatch between training criterion and Word Error Rate\n(WER) that primarily arises during sequence training of ReLU-DNN models.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:58:12 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Haider", "Adnan", ""], ["Woodland", "P. C.", ""]]}, {"id": "1810.01875", "submitter": "Christos Louizos", "authors": "Christos Louizos, Matthias Reisser, Tijmen Blankevoort, Efstratios\n  Gavves, Max Welling", "title": "Relaxed Quantization for Discretized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network quantization has become an important research area due to its\ngreat impact on deployment of large models on resource constrained devices. In\norder to train networks that can be effectively discretized without loss of\nperformance, we introduce a differentiable quantization procedure.\nDifferentiability can be achieved by transforming continuous distributions over\nthe weights and activations of the network to categorical distributions over\nthe quantization grid. These are subsequently relaxed to continuous surrogates\nthat can allow for efficient gradient-based optimization. We further show that\nstochastic rounding can be seen as a special case of the proposed approach and\nthat under this formulation the quantization grid itself can also be optimized\nwith gradient descent. We experimentally validate the performance of our method\non MNIST, CIFAR 10 and Imagenet classification.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 14:17:24 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Louizos", "Christos", ""], ["Reisser", "Matthias", ""], ["Blankevoort", "Tijmen", ""], ["Gavves", "Efstratios", ""], ["Welling", "Max", ""]]}, {"id": "1810.01876", "submitter": "Mehdi Cherti", "authors": "Bal\\'azs K\\'egl, Mehdi Cherti, Ak{\\i}n Kazak\\c{c}{\\i}", "title": "Spurious samples in deep generative models: bug or feature?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional wisdom in generative modeling literature is that spurious samples\nthat a model can generate are errors and they should be avoided. Recent\nresearch, however, has shown interest in studying or even exploiting such\nsamples instead of eliminating them. In this paper, we ask the question whether\nsuch samples can be eliminated all together without sacrificing coverage of the\ngenerating distribution. For the class of models we consider, we experimentally\ndemonstrate that this is not possible without losing the ability to model some\nof the test samples. While our results need to be confirmed on a broader set of\nmodel families, these initial findings provide partial evidence that spurious\nsamples share structural properties with the learned dataset, which, in turn,\nsuggests they are not simply errors but a feature of deep generative nets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:12:26 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["K\u00e9gl", "Bal\u00e1zs", ""], ["Cherti", "Mehdi", ""], ["Kazak\u00e7\u0131", "Ak\u0131n", ""]]}, {"id": "1810.01877", "submitter": "Yixi Xu", "authors": "Yixi Xu, Xiao Wang", "title": "Understanding Weight Normalized Deep Neural Networks with Rectified\n  Linear Units", "comments": null, "journal-ref": "NeurIPS 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general framework for norm-based capacity control for\n$L_{p,q}$ weight normalized deep neural networks. We establish the upper bound\non the Rademacher complexities of this family. With an $L_{p,q}$ normalization\nwhere $q\\le p^*$, and $1/p+1/p^{*}=1$, we discuss properties of a\nwidth-independent capacity control, which only depends on depth by a square\nroot term. We further analyze the approximation properties of $L_{p,q}$ weight\nnormalized deep neural networks. In particular, for an $L_{1,\\infty}$ weight\nnormalized network, the approximation error can be controlled by the $L_1$ norm\nof the output layer, and the corresponding generalization error only depends on\nthe architecture by the square root of the depth.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:45:04 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 16:17:11 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 02:47:36 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Xu", "Yixi", ""], ["Wang", "Xiao", ""]]}, {"id": "1810.01878", "submitter": "Rabindra Lamsal", "authors": "Rabindra Lamsal, Shubham Katiyar", "title": "Determining Optimal Number of k-Clusters based on Predefined\n  Level-of-Similarity", "comments": "2 Figures, 3 Equations", "journal-ref": null, "doi": "10.1007/s42452-020-03582-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a centroid-based clustering algorithm which is capable of\nclustering data-points with n-features, without having to specify the number of\nclusters to be formed. The core logic behind the algorithm is a similarity\nmeasure, which collectively decides whether to assign an incoming data-point to\na pre-existing cluster, or create a new cluster and assign the data-point to\nit. The proposed clustering algorithm is application-specific and is applicable\nwhen the need is to perform clustering analysis of a stream of data-points,\nwhere the similarity measure between an incoming data-point and the cluster to\nwhich the data-point is to be associated with, is greater than the predefined\nLevel-of-Similarity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:46:25 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 12:47:36 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Lamsal", "Rabindra", ""], ["Katiyar", "Shubham", ""]]}, {"id": "1810.01920", "submitter": "Chaosheng Dong", "authors": "Chaosheng Dong, Yiran Chen, Bo Zeng", "title": "Generalized Inverse Optimization through Online Learning", "comments": "14 pages, 10 figures, Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse optimization is a powerful paradigm for learning preferences and\nrestrictions that explain the behavior of a decision maker, based on a set of\nexternal signal and the corresponding decision pairs. However, most inverse\noptimization algorithms are designed specifically in batch setting, where all\nthe data is available in advance. As a consequence, there has been rare use of\nthese methods in an online setting suitable for real-time applications. In this\npaper, we propose a general framework for inverse optimization through online\nlearning. Specifically, we develop an online learning algorithm that uses an\nimplicit update rule which can handle noisy data. Moreover, under additional\nregularity assumptions in terms of the data and the model, we prove that our\nalgorithm converges at a rate of $\\mathcal{O}(1/\\sqrt{T})$ and is statistically\nconsistent. In our experiments, we show the online learning approach can learn\nthe parameters with great accuracy and is very robust to noises, and achieves a\ndramatic improvement in computational efficacy over the batch learning\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 19:11:52 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 17:55:28 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Dong", "Chaosheng", ""], ["Chen", "Yiran", ""], ["Zeng", "Bo", ""]]}, {"id": "1810.01937", "submitter": "Daniel Kang", "authors": "Animesh Koratana, Daniel Kang, Peter Bailis, Matei Zaharia", "title": "LIT: Block-wise Intermediate Representation Training for Model\n  Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a popular method for reducing the\ncomputational overhead of deep network inference, in which the output of a\nteacher model is used to train a smaller, faster student model. Hint training\n(i.e., FitNets) extends KD by regressing a student model's intermediate\nrepresentation to a teacher model's intermediate representation. In this work,\nwe introduce bLock-wise Intermediate representation Training (LIT), a novel\nmodel compression technique that extends the use of intermediate\nrepresentations in deep network compression, outperforming KD and hint\ntraining. LIT has two key ideas: 1) LIT trains a student of the same width (but\nshallower depth) as the teacher by directly comparing the intermediate\nrepresentations, and 2) LIT uses the intermediate representation from the\nprevious block in the teacher model as an input to the current student block\nduring training, avoiding unstable intermediate representations in the student\nnetwork. We show that LIT provides substantial reductions in network depth\nwithout loss in accuracy -- for example, LIT can compress a ResNeXt-110 to a\nResNeXt-20 (5.5x) on CIFAR10 and a VDCNN-29 to a VDCNN-9 (3.2x) on Amazon\nReviews without loss in accuracy, outperforming KD and hint training in network\nsize for a given accuracy. We also show that applying LIT to identical\nstudent/teacher architectures increases the accuracy of the student model above\nthe teacher model, outperforming the recently-proposed Born Again Networks\nprocedure on ResNet, ResNeXt, and VDCNN. Finally, we show that LIT can\neffectively compress GAN generators, which are not supported in the KD\nframework because GANs output pixels as opposed to probabilities.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:27:41 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Koratana", "Animesh", ""], ["Kang", "Daniel", ""], ["Bailis", "Peter", ""], ["Zaharia", "Matei", ""]]}, {"id": "1810.01940", "submitter": "Savinay Nagendra", "authors": "Savinay Nagendra, Nikhil Podila, Rashmi Ugarakhod, Koshy George", "title": "Comparison of Reinforcement Learning algorithms applied to the Cart Pole\n  problem", "comments": null, "journal-ref": "2017 International Conference on Advances in Computing,\n  Communications and Informatics (ICACCI)", "doi": "10.1109/ICACCI.2017.8125811", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing optimal controllers continues to be challenging as systems are\nbecoming complex and are inherently nonlinear. The principal advantage of\nreinforcement learning (RL) is its ability to learn from the interaction with\nthe environment and provide optimal control strategy. In this paper, RL is\nexplored in the context of control of the benchmark cartpole dynamical system\nwith no prior knowledge of the dynamics. RL algorithms such as\ntemporal-difference, policy gradient actor-critic, and value function\napproximation are compared in this context with the standard LQR solution.\nFurther, we propose a novel approach to integrate RL and swing-up controllers.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:10:44 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Nagendra", "Savinay", ""], ["Podila", "Nikhil", ""], ["Ugarakhod", "Rashmi", ""], ["George", "Koshy", ""]]}, {"id": "1810.01963", "submitter": "Hongzi Mao", "authors": "Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili\n  Meng, Mohammad Alizadeh", "title": "Learning Scheduling Algorithms for Data Processing Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently scheduling data processing jobs on distributed compute clusters\nrequires complex algorithms. Current systems, however, use simple generalized\nheuristics and ignore workload characteristics, since developing and tuning a\nscheduling policy for each workload is infeasible. In this paper, we show that\nmodern machine learning techniques can generate highly-efficient policies\nautomatically. Decima uses reinforcement learning (RL) and neural networks to\nlearn workload-specific scheduling algorithms without any human instruction\nbeyond a high-level objective such as minimizing average job completion time.\nOff-the-shelf RL techniques, however, cannot handle the complexity and scale of\nthe scheduling problem. To build Decima, we had to develop new representations\nfor jobs' dependency graphs, design scalable RL models, and invent RL training\nmethods for dealing with continuous stochastic job arrivals. Our prototype\nintegration with Spark on a 25-node cluster shows that Decima improves the\naverage job completion time over hand-tuned scheduling heuristics by at least\n21%, achieving up to 2x improvement during periods of high cluster load.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:43:31 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 20:19:13 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 18:47:37 GMT"}, {"version": "v4", "created": "Wed, 21 Aug 2019 21:53:52 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Mao", "Hongzi", ""], ["Schwarzkopf", "Malte", ""], ["Venkatakrishnan", "Shaileshh Bojja", ""], ["Meng", "Zili", ""], ["Alizadeh", "Mohammad", ""]]}, {"id": "1810.01965", "submitter": "Seyed Mostafa Mousavi", "authors": "S. Mostafa Mousavi, Weiqiang Zhu, Yixiao Sheng, Gregory C. Beroza", "title": "CRED: A Deep Residual Network of Convolutional and Recurrent Units for\n  Earthquake Signal Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earthquake signal detection is at the core of observational seismology. A\ngood detection algorithm should be sensitive to small and weak events with a\nvariety of waveform shapes, robust to background noise and non-earthquake\nsignals, and efficient for processing large data volumes. Here, we introduce\nthe Cnn-Rnn Earthquake Detector (CRED), a detector based on deep neural\nnetworks. The network uses a combination of convolutional layers and\nbi-directional long-short-term memory units in a residual structure. It learns\nthe time-frequency characteristics of the dominant phases in an earthquake\nsignal from three component data recorded on a single station. We train the\nnetwork using 500,000 seismograms (250k associated with tectonic earthquakes\nand 250k identified as noise) recorded in Northern California and tested it\nwith an F-score of 99.95. The robustness of the trained model with respect to\nthe noise level and non-earthquake signals is shown by applying it to a set of\nsemi-synthetic signals. The model is applied to one month of continuous data\nrecorded at Central Arkansas to demonstrate its efficiency, generalization, and\nsensitivity. Our model is able to detect more than 700 microearthquakes as\nsmall as -1.3 ML induced during hydraulic fracturing far away than the training\nregion. The performance of the model is compared with STA/LTA, template\nmatching, and FAST algorithms. Our results indicate an efficient and reliable\nperformance of CRED. This framework holds great promise in lowering the\ndetection threshold while minimizing false positive detection rates.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:45:15 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Mousavi", "S. Mostafa", ""], ["Zhu", "Weiqiang", ""], ["Sheng", "Yixiao", ""], ["Beroza", "Gregory C.", ""]]}, {"id": "1810.02003", "submitter": "Govind Ramnarayan", "authors": "Ran Canetti, Aloni Cohen, Nishanth Dikkala, Govind Ramnarayan, Sarah\n  Scheffler, Adam Smith", "title": "From Soft Classifiers to Hard Decisions: How fair can we be?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular methodology for building binary decision-making classifiers in the\npresence of imperfect information is to first construct a non-binary \"scoring\"\nclassifier that is calibrated over all protected groups, and then to\npost-process this score to obtain a binary decision. We study the feasibility\nof achieving various fairness properties by post-processing calibrated scores,\nand then show that deferring post-processors allow for more fairness conditions\nto hold on the final decision. Specifically, we show:\n  1. There does not exist a general way to post-process a calibrated classifier\nto equalize protected groups' positive or negative predictive value (PPV or\nNPV). For certain \"nice\" calibrated classifiers, either PPV or NPV can be\nequalized when the post-processor uses different thresholds across protected\ngroups, though there exist distributions of calibrated scores for which the two\nmeasures cannot be both equalized. When the post-processing consists of a\nsingle global threshold across all groups, natural fairness properties, such as\nequalizing PPV in a nontrivial way, do not hold even for \"nice\" classifiers.\n  2. When the post-processing is allowed to `defer' on some decisions (that is,\nto avoid making a decision by handing off some examples to a separate process),\nthen for the non-deferred decisions, the resulting classifier can be made to\nequalize PPV, NPV, false positive rate (FPR) and false negative rate (FNR)\nacross the protected groups. This suggests a way to partially evade the\nimpossibility results of Chouldechova and Kleinberg et al., which preclude\nequalizing all of these measures simultaneously. We also present different\ndeferring strategies and show how they affect the fairness properties of the\noverall system.\n  We evaluate our post-processing techniques using the COMPAS data set from\n2016.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 23:16:09 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 16:36:11 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Canetti", "Ran", ""], ["Cohen", "Aloni", ""], ["Dikkala", "Nishanth", ""], ["Ramnarayan", "Govind", ""], ["Scheffler", "Sarah", ""], ["Smith", "Adam", ""]]}, {"id": "1810.02019", "submitter": "Ofer Meshi", "authors": "Irwan Bello, Sayali Kulkarni, Sagar Jain, Craig Boutilier, Ed Chi,\n  Elad Eban, Xiyang Luo, Alan Mackey, Ofer Meshi", "title": "Seq2Slate: Re-ranking and Slate Optimization with RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking is a central task in machine learning and information retrieval. In\nthis task, it is especially important to present the user with a slate of items\nthat is appealing as a whole. This in turn requires taking into account\ninteractions between items, since intuitively, placing an item on the slate\naffects the decision of which other items should be placed alongside it. In\nthis work, we propose a sequence-to-sequence model for ranking called\nseq2slate. At each step, the model predicts the next `best' item to place on\nthe slate given the items already selected. The sequential nature of the model\nallows complex dependencies between the items to be captured directly in a\nflexible and scalable way. We show how to learn the model end-to-end from weak\nsupervision in the form of easily obtained click-through data. We further\ndemonstrate the usefulness of our approach in experiments on standard ranking\nbenchmarks as well as in a real-world recommendation system.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 01:35:14 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 17:38:40 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 18:36:25 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Bello", "Irwan", ""], ["Kulkarni", "Sayali", ""], ["Jain", "Sagar", ""], ["Boutilier", "Craig", ""], ["Chi", "Ed", ""], ["Eban", "Elad", ""], ["Luo", "Xiyang", ""], ["Mackey", "Alan", ""], ["Meshi", "Ofer", ""]]}, {"id": "1810.02022", "submitter": "Sarthak Chatterjee", "authors": "Orlando Romero, Sarthak Chatterjee, S\\'ergio Pequito", "title": "Convergence of the Expectation-Maximization Algorithm Through\n  Discrete-Time Lyapunov Stability Theory", "comments": "Preprint submitted to ACC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a dynamical systems perspective of the\nExpectation-Maximization (EM) algorithm. More precisely, we can analyze the EM\nalgorithm as a nonlinear state-space dynamical system. The EM algorithm is\nwidely adopted for data clustering and density estimation in statistics,\ncontrol systems, and machine learning. This algorithm belongs to a large class\nof iterative algorithms known as proximal point methods. In particular, we\nre-interpret limit points of the EM algorithm and other local maximizers of the\nlikelihood function it seeks to optimize as equilibria in its dynamical system\nrepresentation. Furthermore, we propose to assess its convergence as asymptotic\nstability in the sense of Lyapunov. As a consequence, we proceed by leveraging\nrecent results regarding discrete-time Lyapunov stability theory in order to\nestablish asymptotic stability (and thus, convergence) in the dynamical system\nrepresentation of the EM algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 01:53:11 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Romero", "Orlando", ""], ["Chatterjee", "Sarthak", ""], ["Pequito", "S\u00e9rgio", ""]]}, {"id": "1810.02030", "submitter": "Chao Gao", "authors": "Chao Gao, Jiyi Liu, Yuan Yao, Weizhi Zhu", "title": "Robust Estimation and Generative Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust estimation under Huber's $\\epsilon$-contamination model has become an\nimportant topic in statistics and theoretical computer science. Statistically\noptimal procedures such as Tukey's median and other estimators based on depth\nfunctions are impractical because of their computational intractability. In\nthis paper, we establish an intriguing connection between $f$-GANs and various\ndepth functions through the lens of $f$-Learning. Similar to the derivation of\n$f$-GANs, we show that these depth functions that lead to statistically optimal\nrobust estimators can all be viewed as variational lower bounds of the total\nvariation distance in the framework of $f$-Learning. This connection opens the\ndoor of computing robust estimators using tools developed for training GANs. In\nparticular, we show in both theory and experiments that some appropriate\nstructures of discriminator networks with hidden layers in GANs lead to\nstatistically optimal robust location estimators for both Gaussian distribution\nand general elliptical distributions where first moment may not exist.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 02:37:16 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 01:47:46 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 20:09:43 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gao", "Chao", ""], ["Liu", "Jiyi", ""], ["Yao", "Yuan", ""], ["Zhu", "Weizhi", ""]]}, {"id": "1810.02032", "submitter": "Ziwei Ji", "authors": "Ziwei Ji, Matus Telgarsky", "title": "Gradient descent aligns the layers of deep linear networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes risk convergence and asymptotic weight matrix\nalignment --- a form of implicit regularization --- of gradient flow and\ngradient descent when applied to deep linear networks on linearly separable\ndata. In more detail, for gradient flow applied to strictly decreasing loss\nfunctions (with similar results for gradient descent with particular decreasing\nstep sizes): (i) the risk converges to 0; (ii) the normalized i-th weight\nmatrix asymptotically equals its rank-1 approximation $u_iv_i^{\\top}$; (iii)\nthese rank-1 matrices are aligned across layers, meaning\n$|v_{i+1}^{\\top}u_i|\\to1$. In the case of the logistic loss (binary cross\nentropy), more can be said: the linear function induced by the network --- the\nproduct of its weight matrices --- converges to the same direction as the\nmaximum margin solution. This last property was identified in prior work, but\nonly under assumptions on gradient descent which here are implied by the\nalignment phenomenon.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 02:48:41 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 10:28:05 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1810.02054", "submitter": "Simon Du", "authors": "Simon S. Du, Xiyu Zhai, Barnabas Poczos, Aarti Singh", "title": "Gradient Descent Provably Optimizes Over-parameterized Neural Networks", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the mysteries in the success of neural networks is randomly\ninitialized first order methods like gradient descent can achieve zero training\nloss even though the objective function is non-convex and non-smooth. This\npaper demystifies this surprising phenomenon for two-layer fully connected ReLU\nactivated neural networks. For an $m$ hidden node shallow neural network with\nReLU activation and $n$ training data, we show as long as $m$ is large enough\nand no two inputs are parallel, randomly initialized gradient descent converges\nto a globally optimal solution at a linear convergence rate for the quadratic\nloss function.\n  Our analysis relies on the following observation: over-parameterization and\nrandom initialization jointly restrict every weight vector to be close to its\ninitialization for all iterations, which allows us to exploit a strong\nconvexity-like property to show that gradient descent converges at a global\nlinear rate to the global optimum. We believe these insights are also useful in\nanalyzing deep models and other first order methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 04:47:47 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 01:59:59 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Du", "Simon S.", ""], ["Zhai", "Xiyu", ""], ["Poczos", "Barnabas", ""], ["Singh", "Aarti", ""]]}, {"id": "1810.02068", "submitter": "Cheng Fu", "authors": "Cheng Fu, Shilin Zhu, Hao Su, Ching-En Lee, Jishen Zhao", "title": "Towards Fast and Energy-Efficient Binarized Neural Network Inference on\n  FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized Neural Network (BNN) removes bitwidth redundancy in classical CNN\nby using a single bit (-1/+1) for network parameters and intermediate\nrepresentations, which has greatly reduced the off-chip data transfer and\nstorage overhead. However, a large amount of computation redundancy still\nexists in BNN inference. By analyzing local properties of images and the\nlearned BNN kernel weights, we observe an average of $\\sim$78% input similarity\nand $\\sim$59% weight similarity among weight kernels, measured by our proposed\nmetric in common network architectures. Thus there does exist redundancy that\ncan be exploited to further reduce the amount of on-chip computations.\n  Motivated by the observation, in this paper, we proposed two types of fast\nand energy-efficient architectures for BNN inference. We also provide analysis\nand insights to pick the better strategy of these two for different datasets\nand network models. By reusing the results from previous computation, much\ncycles for data buffer access and computations can be skipped. By experiments,\nwe demonstrate that 80% of the computation and 40% of the buffer access can be\nskipped by exploiting BNN similarity. Thus, our design can achieve 17%\nreduction in total power consumption, 54% reduction in on-chip power\nconsumption and 2.4$\\times$ maximum speedup, compared to the baseline without\napplying our reuse technique. Our design also shows 1.9$\\times$ more\narea-efficiency compared to state-of-the-art BNN inference design. We believe\nour deployment of BNN on FPGA leads to a promising future of running deep\nlearning models on mobile devices.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 06:29:59 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Fu", "Cheng", ""], ["Zhu", "Shilin", ""], ["Su", "Hao", ""], ["Lee", "Ching-En", ""], ["Zhao", "Jishen", ""]]}, {"id": "1810.02069", "submitter": "Taeyoung Kong", "authors": "Dae Hyun Kim, Taeyoung Kong, Seungbin Jeong", "title": "Finding Solutions to Generative Adversarial Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present heuristics for solving the maximin problem induced by the\ngenerative adversarial privacy setting for linear and convolutional neural\nnetwork (CNN) adversaries. In the linear adversary setting, we present a greedy\nalgorithm for approximating the optimal solution for the privatizer, which\nperforms better as the number of instances increases. We also provide an\nanalysis of the algorithm to show that it not only removes the features most\ncorrelated with the private label first, but also preserves the prediction\naccuracy of public labels that are sufficiently independent of the features\nthat are relevant to the private label. In the CNN adversary setting, we\npresent a method of hiding selected information from the adversary while\npreserving the others through alternately optimizing the goals of the\nprivatizer and the adversary using neural network backpropagation. We\nexperimentally show that our method succeeds on a fixed adversary.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 06:36:09 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Kim", "Dae Hyun", ""], ["Kong", "Taeyoung", ""], ["Jeong", "Seungbin", ""]]}, {"id": "1810.02071", "submitter": "Jaehyuk Choi", "authors": "Jeechul Woo, Chenru Liu, Jaehyuk Choi", "title": "Leave-One-Out Least Square Monte Carlo Algorithm for Pricing American\n  Options", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.MF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The least square Monte Carlo (LSM) algorithm proposed by Longstaff and\nSchwartz (2001) is widely used for pricing American options. The LSM estimator\ncontains undesirable look-ahead bias, and the conventional technique of\nremoving it necessitates doubling simulations. We present the leave-one-out LSM\n(LOOLSM) algorithm for efficiently eliminating look-ahead bias. We also show\nthat look-ahead bias is asymptotically proportional to the\nregressors-to-simulation paths ratio. Our findings are demonstrated with\nseveral option examples, including the multi-asset cases that the LSM algorithm\nsignificantly overvalues. The LOOLSM method can be extended to other\nregression-based algorithms improving the LSM method.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 06:49:50 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 14:09:06 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 03:46:44 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Woo", "Jeechul", ""], ["Liu", "Chenru", ""], ["Choi", "Jaehyuk", ""]]}, {"id": "1810.02076", "submitter": "Changhao Chen", "authors": "Changhao Chen, Yishu Miao, Chris Xiaoxuan Lu, Phil Blunsom, Andrew\n  Markham, Niki Trigoni", "title": "Transferring Physical Motion Between Domains for Neural Inertial\n  Tracking", "comments": "NIPS 2018 workshop on Modeling the Physical World: Perception,\n  Learning, and Control. A complete version will be released soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inertial information processing plays a pivotal role in ego-motion awareness\nfor mobile agents, as inertial measurements are entirely egocentric and not\nenvironment dependent. However, they are affected greatly by changes in sensor\nplacement/orientation or motion dynamics, and it is infeasible to collect\nlabelled data from every domain. To overcome the challenges of domain\nadaptation on long sensory sequences, we propose a novel framework that\nextracts domain-invariant features of raw sequences from arbitrary domains, and\ntransforms to new domains without any paired data. Through the experiments, we\ndemonstrate that it is able to efficiently and effectively convert the raw\nsequence from a new unlabelled target domain into an accurate inertial\ntrajectory, benefiting from the physical motion knowledge transferred from the\nlabelled source domain. We also conduct real-world experiments to show our\nframework can reconstruct physically meaningful trajectories from raw IMU\nmeasurements obtained with a standard mobile phone in various attachments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 07:12:47 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Chen", "Changhao", ""], ["Miao", "Yishu", ""], ["Lu", "Chris Xiaoxuan", ""], ["Blunsom", "Phil", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1810.02080", "submitter": "Shonosuke Harada", "authors": "Shonosuke Harada, Hirotaka Akita, Masashi Tsubaki, Yukino Baba,\n  Ichigaku Takigawa, Yoshihiro Yamanishi, Hisashi Kashima", "title": "Dual Convolutional Neural Network for Graph of Graphs Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are general and powerful data representations which can model complex\nreal-world phenomena, ranging from chemical compounds to social networks;\nhowever, effective feature extraction from graphs is not a trivial task, and\nmuch work has been done in the field of machine learning and data mining. The\nrecent advances in graph neural networks have made automatic and flexible\nfeature extraction from graphs possible and have improved the predictive\nperformance significantly. In this paper, we go further with this line of\nresearch and address a more general problem of learning with a graph of graphs\n(GoG) consisting of an external graph and internal graphs, where each node in\nthe external graph has an internal graph structure. We propose a dual\nconvolutional neural network that extracts node representations by combining\nthe external and internal graph structures in an end-to-end manner. Experiments\non link prediction tasks using several chemical network datasets demonstrate\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 07:39:31 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Harada", "Shonosuke", ""], ["Akita", "Hirotaka", ""], ["Tsubaki", "Masashi", ""], ["Baba", "Yukino", ""], ["Takigawa", "Ichigaku", ""], ["Yamanishi", "Yoshihiro", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1810.02112", "submitter": "Edouard Fouch\\'e", "authors": "Edouard Fouch\\'e and Klemens B\\\"ohm", "title": "Monte Carlo Dependency Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the dependency of variables is a fundamental task in data\nanalysis. Identifying the relevant attributes in databases leads to better data\nunderstanding and also improves the performance of learning algorithms, both in\nterms of runtime and quality. In data streams, dependency monitoring provides\nkey insights into the underlying process, but is challenging. In this paper, we\npropose Monte Carlo Dependency Estimation (MCDE), a theoretical framework to\nestimate multivariate dependency in static and dynamic data. MCDE quantifies\ndependency as the average discrepancy between marginal and conditional\ndistributions via Monte Carlo simulations. Based on this framework, we present\nMann-Whitney P (MWP), a novel dependency estimator. We show that MWP satisfies\na number of desirable properties and can accommodate any kind of numerical\ndata. We demonstrate the superiority of our estimator by comparing it to the\nstate-of-the-art multivariate dependency measures.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:16:46 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Fouch\u00e9", "Edouard", ""], ["B\u00f6hm", "Klemens", ""]]}, {"id": "1810.02118", "submitter": "Dirk Surmann", "authors": "Dirk Surmann, Uwe Ligges, Claus Weihs", "title": "Infill Criterion for Multimodal Model-Based Optimisation", "comments": "14 pages, 4 figures, 3 tables, extensive appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical systems are modelled and investigated within simulation software in\nan increasing range of applications. In reality an investigation of the system\nis often performed by empirical test scenarios which are related to typical\nsituations. Our aim is to derive a method which generates diverse test\nscenarios each representing a challenging situation for the corresponding\nphysical system.\n  From a mathematical point of view challenging test scenarios correspond to\nlocal optima. Hence, we focus to identify all local optima within mathematical\nfunctions. Due to the fact that simulation runs are usually expensive we use\nthe model-based optimisation approach with its well-known representative\nefficient global optimisation. We derive an infill criterion which focuses on\nthe identification of local optima. The criterion is checked via fifteen\ndifferent artificial functions in a computer experiment. Our new infill\ncriterion performs better in identifying local optima compared to the expected\nimprovement infill criterion and Latin Hypercube Samples.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:37:53 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Surmann", "Dirk", ""], ["Ligges", "Uwe", ""], ["Weihs", "Claus", ""]]}, {"id": "1810.02176", "submitter": "James Grant", "authors": "James A. Grant, David S. Leslie, Kevin Glazebrook, Roberto Szechtman\n  and Adam N. Letchford", "title": "Adaptive Policies for Perimeter Surveillance Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximising the detection of intrusions is a fundamental and often critical\naim of perimeter surveillance. Commonly, this requires a decision-maker to\noptimally allocate multiple searchers to segments of the perimeter. We consider\na scenario where the decision-maker may sequentially update the searchers'\nallocation, learning from the observed data to improve decisions over time. In\nthis work we propose a formal model and solution methods for this sequential\nperimeter surveillance problem. Our model is a combinatorial multi-armed bandit\n(CMAB) with Poisson rewards and a novel filtered feedback mechanism - arising\nfrom the failure to detect certain intrusions. Our solution method is an upper\nconfidence bound approach and we derive upper and lower bounds on its expected\nperformance. We prove that the gap between these bounds is of constant order,\nand demonstrate empirically that our approach is more reliable in simulated\nproblems than competing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 12:44:34 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 15:44:19 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Grant", "James A.", ""], ["Leslie", "David S.", ""], ["Glazebrook", "Kevin", ""], ["Szechtman", "Roberto", ""], ["Letchford", "Adam N.", ""]]}, {"id": "1810.02180", "submitter": "Aryeh Kontorovich", "authors": "Idan Attias, Aryeh Kontorovich, Yishay Mansour", "title": "Improved Generalization Bounds for Robust Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model of robust learning in an adversarial environment. The\nlearner gets uncorrupted training data with access to possible corruptions that\nmay be effected by the adversary during testing. The learner's goal is to build\na robust classifier, which will be tested on future adversarial examples. The\nadversary is limited to $k$ possible corruptions for each input. We model the\nlearner-adversary interaction as a zero-sum game. This model is closely related\nto the adversarial examples model of Schmidt et al. (2018); Madry et al.\n(2017). Our main results consist of generalization bounds for the binary and\nmulticlass classification, as well as the real-valued case (regression). For\nthe binary classification setting, we both tighten the generalization bound of\nFeige, Mansour, and Schapire (2015), and are also able to handle infinite\nhypothesis classes. The sample complexity is improved from\n$O(\\frac{1}{\\epsilon^4}\\log(\\frac{|\\mathcal{H}|}{\\delta}))$ to\n$O\\big(\\frac{1}{\\epsilon^2}(\\sqrt{k\n\\mathrm{VC}(\\mathcal{H})}\\log^{\\frac{3}{2}+\\alpha}(k\\mathrm{VC}(\\mathcal{H}))+\\log(\\frac{1}{\\delta})\\big)$\nfor any $\\alpha > 0$. Additionally, we extend the algorithm and generalization\nbound from the binary to the multiclass and real-valued cases. Along the way,\nwe obtain results on fat-shattering dimension and Rademacher complexity of\n$k$-fold maxima over function classes; these may be of independent interest.\n  For binary classification, the algorithm of Feige et al. (2015) uses a regret\nminimization algorithm and an ERM oracle as a black box; we adapt it for the\nmulticlass and regression settings. The algorithm provides us with near-optimal\npolicies for the players on a given training sample.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 12:53:41 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 12:29:30 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 12:08:06 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 22:28:57 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Attias", "Idan", ""], ["Kontorovich", "Aryeh", ""], ["Mansour", "Yishay", ""]]}, {"id": "1810.02215", "submitter": "Jingyu He", "authors": "Jingyu He, Saar Yalov, P. Richard Hahn", "title": "XBART: Accelerated Bayesian Additive Regression Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian additive regression trees (BART) (Chipman et. al., 2010) is a\npowerful predictive model that often outperforms alternative models at\nout-of-sample prediction. BART is especially well-suited to settings with\nunstructured predictor variables and substantial sources of unmeasured\nvariation as is typical in the social, behavioral and health sciences. This\npaper develops a modified version of BART that is amenable to fast posterior\nestimation. We present a stochastic hill climbing algorithm that matches the\nremarkable predictive accuracy of previous BART implementations, but is many\ntimes faster and less memory intensive. Simulation studies show that the new\nmethod is comparable in computation time and more accurate at function\nestimation than both random forests and gradient boosting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 13:40:21 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:00:30 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 04:35:25 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["He", "Jingyu", ""], ["Yalov", "Saar", ""], ["Hahn", "P. Richard", ""]]}, {"id": "1810.02225", "submitter": "Fan Zhang", "authors": "Fan Zhang, Miao Hu", "title": "Memristor-based Deep Convolution Neural Network: A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we firstly introduce a method to efficiently implement\nlarge-scale high-dimensional convolution with realistic memristor-based circuit\ncomponents. An experiment verified simulator is adapted for accurate prediction\nof analog crossbar behavior. An improved conversion algorithm is developed to\nconvert convolution kernels to memristor-based circuits, which minimizes the\nerror with consideration of the data and kernel patterns in CNNs. With circuit\nsimulation for all convolution layers in ResNet-20, we found that 8-bit ADC/DAC\nis necessary to preserve software level classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 18:47:34 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Zhang", "Fan", ""], ["Hu", "Miao", ""]]}, {"id": "1810.02244", "submitter": "Christopher Morris", "authors": "Christopher Morris, Martin Ritzert, Matthias Fey, William L. Hamilton,\n  Jan Eric Lenssen, Gaurav Rattan, Martin Grohe", "title": "Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks", "comments": "Extended version with proofs, accepted at AAAI 2019, added units of\n  measurement of QM9 dataset into appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, graph neural networks (GNNs) have emerged as a powerful\nneural architecture to learn vector representations of nodes and graphs in a\nsupervised, end-to-end fashion. Up to now, GNNs have only been evaluated\nempirically---showing promising results. The following work investigates GNNs\nfrom a theoretical point of view and relates them to the $1$-dimensional\nWeisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs have\nthe same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic\n(sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on\nthis, we propose a generalization of GNNs, so-called $k$-dimensional GNNs\n($k$-GNNs), which can take higher-order graph structures at multiple scales\ninto account. These higher-order structures play an essential role in the\ncharacterization of social networks and molecule graphs. Our experimental\nevaluation confirms our theoretical findings as well as confirms that\nhigher-order information is useful in the task of graph classification and\nregression.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:31:57 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 12:52:37 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 15:55:24 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Morris", "Christopher", ""], ["Ritzert", "Martin", ""], ["Fey", "Matthias", ""], ["Hamilton", "William L.", ""], ["Lenssen", "Jan Eric", ""], ["Rattan", "Gaurav", ""], ["Grohe", "Martin", ""]]}, {"id": "1810.02263", "submitter": "Anas Barakat", "authors": "Anas Barakat, Pascal Bianchi", "title": "Convergence and Dynamical Behavior of the ADAM Algorithm for Non-Convex\n  Stochastic Optimization", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.CA math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam is a popular variant of stochastic gradient descent for finding a local\nminimizer of a function. In the constant stepsize regime, assuming that the\nobjective function is differentiable and non-convex, we establish the\nconvergence in the long run of the iterates to a stationary point under a\nstability condition. The key ingredient is the introduction of a\ncontinuous-time version of Adam, under the form of a non-autonomous ordinary\ndifferential equation. This continuous-time system is a relevant approximation\nof the Adam iterates, in the sense that the interpolated Adam process converges\nweakly towards the solution to the ODE. The existence and the uniqueness of the\nsolution are established. We further show the convergence of the solution\ntowards the critical points of the objective function and quantify its\nconvergence rate under a Lojasiewicz assumption. Then, we introduce a novel\ndecreasing stepsize version of Adam. Under mild assumptions, it is shown that\nthe iterates are almost surely bounded and converge almost surely to critical\npoints of the objective function. Finally, we analyze the fluctuations of the\nalgorithm by means of a conditional central limit theorem.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:01:46 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 23:00:29 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 14:23:23 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 18:08:49 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Barakat", "Anas", ""], ["Bianchi", "Pascal", ""]]}, {"id": "1810.02266", "submitter": "Jesse Read", "authors": "Jesse Read", "title": "Concept-drifting Data Streams are Time Series; The Case for Continuous\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from data streams is an increasingly important topic in data mining,\nmachine learning, and artificial intelligence in general. A major focus in the\ndata stream literature is on designing methods that can deal with concept\ndrift, a challenge where the generating distribution changes over time. A\ngeneral assumption in most of this literature is that instances are\nindependently distributed in the stream. In this work we show that, in the\ncontext of concept drift, this assumption is contradictory, and that the\npresence of concept drift necessarily implies temporal dependence; and thus\nsome form of time series. This has important implications on model design and\ndeployment. We explore and highlight the these implications, and show that\nHoeffding-tree based ensembles, which are very popular for learning in streams,\nare not naturally suited to learning \\emph{within} drift; and can perform in\nthis scenario only at significant computational cost of destructive adaptation.\nOn the other hand, we develop and parameterize gradient-descent methods and\ndemonstrate how they can perform \\emph{continuous} adaptation with no explicit\ndrift-detection mechanism, offering major advantages in terms of accuracy and\nefficiency. As a consequence of our theoretical discussion and empirical\nobservations, we outline a number of recommendations for deploying methods in\nconcept-drifting streams.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:04:10 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Read", "Jesse", ""]]}, {"id": "1810.02274", "submitter": "Nikolay Savinov", "authors": "Nikolay Savinov, Anton Raichuk, Rapha\\\"el Marinier, Damien Vincent,\n  Marc Pollefeys, Timothy Lillicrap, Sylvain Gelly", "title": "Episodic Curiosity through Reachability", "comments": "Accepted to ICLR 2019. Code at\n  https://github.com/google-research/episodic-curiosity/. Videos at\n  https://sites.google.com/view/episodic-curiosity/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rewards are sparse in the real world and most of today's reinforcement\nlearning algorithms struggle with such sparsity. One solution to this problem\nis to allow the agent to create rewards for itself - thus making rewards dense\nand more suitable for learning. In particular, inspired by curious behaviour in\nanimals, observing something novel could be rewarded with a bonus. Such bonus\nis summed up with the real task reward - making it possible for RL algorithms\nto learn from the combined reward. We propose a new curiosity method which uses\nepisodic memory to form the novelty bonus. To determine the bonus, the current\nobservation is compared with the observations in memory. Crucially, the\ncomparison is done based on how many environment steps it takes to reach the\ncurrent observation from those in memory - which incorporates rich information\nabout environment dynamics. This allows us to overcome the known \"couch-potato\"\nissues of prior work - when the agent finds a way to instantly gratify itself\nby exploiting actions which lead to hardly predictable consequences. We test\nour approach in visually rich 3D environments in ViZDoom, DMLab and MuJoCo. In\nnavigational tasks from ViZDoom and DMLab, our agent outperforms the\nstate-of-the-art curiosity method ICM. In MuJoCo, an ant equipped with our\ncuriosity module learns locomotion out of the first-person-view curiosity only.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:24:06 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 17:39:39 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 17:02:58 GMT"}, {"version": "v4", "created": "Thu, 9 May 2019 13:10:33 GMT"}, {"version": "v5", "created": "Tue, 6 Aug 2019 17:54:03 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Savinov", "Nikolay", ""], ["Raichuk", "Anton", ""], ["Marinier", "Rapha\u00ebl", ""], ["Vincent", "Damien", ""], ["Pollefeys", "Marc", ""], ["Lillicrap", "Timothy", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1810.02281", "submitter": "Nadav Cohen", "authors": "Sanjeev Arora, Nadav Cohen, Noah Golowich, Wei Hu", "title": "A Convergence Analysis of Gradient Descent for Deep Linear Neural\n  Networks", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze speed of convergence to global optimum for gradient descent\ntraining a deep linear neural network (parameterized as $x \\mapsto W_N W_{N-1}\n\\cdots W_1 x$) by minimizing the $\\ell_2$ loss over whitened data. Convergence\nat a linear rate is guaranteed when the following hold: (i) dimensions of\nhidden layers are at least the minimum of the input and output dimensions; (ii)\nweight matrices at initialization are approximately balanced; and (iii) the\ninitial loss is smaller than the loss of any rank-deficient solution. The\nassumptions on initialization (conditions (ii) and (iii)) are necessary, in the\nsense that violating any one of them may lead to convergence failure. Moreover,\nin the important case of output dimension 1, i.e. scalar regression, they are\nmet, and thus convergence to global optimum holds, with constant probability\nunder a random initialization scheme. Our results significantly extend previous\nanalyses, e.g., of deep linear residual networks (Bartlett et al., 2018).\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:53:32 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 15:40:08 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 06:58:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Arora", "Sanjeev", ""], ["Cohen", "Nadav", ""], ["Golowich", "Noah", ""], ["Hu", "Wei", ""]]}, {"id": "1810.02294", "submitter": "Kayvan Sadeghi", "authors": "Kayvan Sadeghi and Alessandro Rinaldo", "title": "Markov Properties of Discrete Determinantal Point Processes", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) are probabilistic models for repulsion.\nWhen used to represent the occurrence of random subsets of a finite base set,\nDPPs allow to model global negative associations in a mathematically elegant\nand direct way. Discrete DPPs have become popular and computationally tractable\nmodels for solving several machine learning tasks that require the selection of\ndiverse objects, and have been successfully applied in numerous real-life\nproblems. Despite their popularity, the statistical properties of such models\nhave not been adequately explored. In this note, we derive the Markov\nproperties of discrete DPPs and show how they can be expressed using graphical\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 16:18:59 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 00:56:41 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Sadeghi", "Kayvan", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "1810.02309", "submitter": "Anna Thomas", "authors": "Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and\n  Christopher R\\'e", "title": "Learning Compressed Transforms with Low Displacement Rank", "comments": "NeurIPS 2018. Code available at\n  https://github.com/HazyResearch/structured-nets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low displacement rank (LDR) framework for structured matrices represents\na matrix through two displacement operators and a low-rank residual. Existing\nuse of LDR matrices in deep learning has applied fixed displacement operators\nencoding forms of shift invariance akin to convolutions. We introduce a class\nof LDR matrices with more general displacement operators, and explicitly learn\nover both the operators and the low-rank component. This class generalizes\nseveral previous constructions while preserving compression and efficient\ncomputation. We prove bounds on the VC dimension of multi-layer neural networks\nwith structured weight matrices and show empirically that our compact\nparameterization can reduce the sample complexity of learning. When replacing\nweight layers in fully-connected, convolutional, and recurrent neural networks\nfor image classification and language modeling tasks, our new classes exceed\nthe accuracy of existing compression approaches, and on some tasks also\noutperform general unstructured layers while using more than 20x fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 16:44:16 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 22:02:37 GMT"}, {"version": "v3", "created": "Tue, 1 Jan 2019 16:36:35 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Thomas", "Anna T.", ""], ["Gu", "Albert", ""], ["Dao", "Tri", ""], ["Rudra", "Atri", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1810.02321", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang and Ingo Steinwart", "title": "Optimal Learning with Anisotropic Gaussian SVMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the nonparametric regression problem using SVMs with\nanisotropic Gaussian RBF kernels. Under the assumption that the target\nfunctions are resided in certain anisotropic Besov spaces, we establish the\nalmost optimal learning rates, more precisely, optimal up to some logarithmic\nfactor, presented by the effective smoothness. By taking the effective\nsmoothness into consideration, our almost optimal learning rates are faster\nthan those obtained with the underlying RKHSs being certain anisotropic Sobolev\nspaces. Moreover, if the target function depends only on fewer dimensions,\nfaster learning rates can be further achieved.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:09:42 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Hang", "Hanyuan", ""], ["Steinwart", "Ingo", ""]]}, {"id": "1810.02323", "submitter": "Gia-Wei Chern", "authors": "Jianhua Ma, Puhan Zhang, Yaohua Tan, Avik W. Ghosh, Gia-Wei Chern", "title": "Machine learning electron correlation in a disordered medium", "comments": "6 pages, 3 figures", "journal-ref": "Phys. Rev. B 99, 085118 (2019)", "doi": "10.1103/PhysRevB.99.085118", "report-no": null, "categories": "cond-mat.str-el cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from data has led to a paradigm shift in computational materials\nscience. In particular, it has been shown that neural networks can learn the\npotential energy surface and interatomic forces through examples, thus\nbypassing the computationally expensive density functional theory calculations.\nCombining many-body techniques with a deep learning approach, we demonstrate\nthat a fully-connected neural network is able to learn the complex collective\nbehavior of electrons in strongly correlated systems. Specifically, we consider\nthe Anderson-Hubbard (AH) model, which is a canonical system for studying the\ninterplay between electron correlation and strong localization. The ground\nstates of the AH model on a square lattice are obtained using the real-space\nGutzwiller method. The obtained solutions are used to train a multi-task\nmulti-layer neural network, which subsequently can accurately predict\nquantities such as the local probability of double occupation and the\nquasiparticle weight, given the disorder potential in the neighborhood as the\ninput.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:12:00 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Ma", "Jianhua", ""], ["Zhang", "Puhan", ""], ["Tan", "Yaohua", ""], ["Ghosh", "Avik W.", ""], ["Chern", "Gia-Wei", ""]]}, {"id": "1810.02334", "submitter": "Kyle Hsu", "authors": "Kyle Hsu and Sergey Levine and Chelsea Finn", "title": "Unsupervised Learning via Meta-Learning", "comments": "ICLR 2019 camera-ready. 24 pages, 2 figures, links to code available\n  at https://sites.google.com/view/unsupervised-via-meta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal of unsupervised learning is to acquire representations from\nunlabeled data or experience that can be used for more effective learning of\ndownstream tasks from modest amounts of labeled data. Many prior unsupervised\nlearning works aim to do so by developing proxy objectives based on\nreconstruction, disentanglement, prediction, and other metrics. Instead, we\ndevelop an unsupervised meta-learning method that explicitly optimizes for the\nability to learn a variety of tasks from small amounts of data. To do so, we\nconstruct tasks from unlabeled data in an automatic way and run meta-learning\nover the constructed tasks. Surprisingly, we find that, when integrated with\nmeta-learning, relatively simple task construction mechanisms, such as\nclustering embeddings, lead to good performance on a variety of downstream,\nhuman-specified tasks. Our experiments across four image datasets indicate that\nour unsupervised meta-learning approach acquires a learning algorithm without\nany labeled data that is applicable to a wide range of downstream\nclassification tasks, improving upon the embedding learned by four prior\nunsupervised learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:29:17 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 23:39:52 GMT"}, {"version": "v3", "created": "Sat, 13 Oct 2018 23:57:36 GMT"}, {"version": "v4", "created": "Thu, 22 Nov 2018 20:47:45 GMT"}, {"version": "v5", "created": "Fri, 7 Dec 2018 20:38:03 GMT"}, {"version": "v6", "created": "Thu, 21 Mar 2019 23:43:47 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Hsu", "Kyle", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.02358", "submitter": "Hyeonwoo Noh", "authors": "Hyeonwoo Noh, Taehoon Kim, Jonghwan Mun, Bohyung Han", "title": "Transfer Learning via Unsupervised Task Discovery for Visual Question\n  Answering", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to leverage off-the-shelf visual and linguistic data to cope\nwith out-of-vocabulary answers in visual question answering task. Existing\nlarge-scale visual datasets with annotations such as image class labels,\nbounding boxes and region descriptions are good sources for learning rich and\ndiverse visual concepts. However, it is not straightforward how the visual\nconcepts can be captured and transferred to visual question answering models\ndue to missing link between question dependent answering models and visual data\nwithout question. We tackle this problem in two steps: 1) learning a task\nconditional visual classifier, which is capable of solving diverse\nquestion-specific visual recognition tasks, based on unsupervised task\ndiscovery and 2) transferring the task conditional visual classifier to visual\nquestion answering models. Specifically, we employ linguistic knowledge sources\nsuch as structured lexical database (e.g. WordNet) and visual descriptions for\nunsupervised task discovery, and transfer a learned task conditional visual\nclassifier as an answering unit in a visual question answering model. We\nempirically show that the proposed algorithm generalizes to out-of-vocabulary\nanswers successfully using the knowledge transferred from the visual dataset.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 19:48:38 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 11:50:11 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Noh", "Hyeonwoo", ""], ["Kim", "Taehoon", ""], ["Mun", "Jonghwan", ""], ["Han", "Bohyung", ""]]}, {"id": "1810.02363", "submitter": "F\\'elix G. Harvey", "authors": "F\\'elix G. Harvey, Christopher Pal", "title": "Recurrent Transition Networks for Character Locomotion", "comments": "revision fixes: clarity issues in Section 4.4 (text and equations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually authoring transition animations for a complete locomotion system can\nbe a tedious and time-consuming task, especially for large games that allow\ncomplex and constrained locomotion movements, where the number of transitions\ngrows exponentially with the number of states. In this paper, we present a\nnovel approach, based on deep recurrent neural networks, to automatically\ngenerate such transitions given a past context of a few frames and a target\ncharacter state to reach. We present the Recurrent Transition Network (RTN),\nbased on a modified version of the Long-Short-Term-Memory (LSTM) network,\ndesigned specifically for transition generation and trained without any gait,\nphase, contact or action labels. We further propose a simple yet principled way\nto initialize the hidden states of the LSTM layer for a given sequence which\nimproves the performance and generalization to new motions. We both\nquantitatively and qualitatively evaluate our system and show that making the\nnetwork terrain-aware by adding a local terrain representation to the input\nyields better performance for rough-terrain navigation on long transitions. Our\nsystem produces realistic and fluid transitions that rival the quality of\nMotion Capture-based ground-truth motions, even before applying any\ninverse-kinematics postprocess. Direct benefits of our approach could be to\naccelerate the creation of transition variations for large coverage, or even to\nentirely replace transition nodes in an animation graph. We further explore\napplications of this model in a animation super-resolution setting where we\ntemporally decompress animations saved at 1 frame per second and show that the\nnetwork is able to reconstruct motions that are hard to distinguish from\nun-compressed locomotion sequences.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:12:13 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 14:40:10 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 19:44:41 GMT"}, {"version": "v4", "created": "Thu, 17 Jan 2019 21:23:44 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 20:00:10 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Harvey", "F\u00e9lix G.", ""], ["Pal", "Christopher", ""]]}, {"id": "1810.02406", "submitter": "Juho Piironen", "authors": "Juho Piironen, Markus Paasiniemi and Aki Vehtari", "title": "Projective Inference in High-dimensional Problems: Prediction and\n  Feature Selection", "comments": null, "journal-ref": "Electronic Journal of Statistics, 14(1):2155-2197, 2020.\n  https://projecteuclid.org/euclid.ejs/1589335310", "doi": "10.1214/20-EJS1711", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses predictive inference and feature selection for\ngeneralized linear models with scarce but high-dimensional data. We argue that\nin many cases one can benefit from a decision theoretically justified two-stage\napproach: first, construct a possibly non-sparse model that predicts well, and\nthen find a minimal subset of features that characterize the predictions. The\nmodel built in the first step is referred to as the \\emph{reference model} and\nthe operation during the latter step as predictive \\emph{projection}. The key\ncharacteristic of this approach is that it finds an excellent tradeoff between\nsparsity and predictive accuracy, and the gain comes from utilizing all\navailable information including prior and that coming from the left out\nfeatures. We review several methods that follow this principle and provide\nnovel methodological contributions. We present a new projection technique that\nunifies two existing techniques and is both accurate and fast to compute. We\nalso propose a way of evaluating the feature selection process using fast\nleave-one-out cross-validation that allows for easy and intuitive model size\nselection. Furthermore, we prove a theorem that helps to understand the\nconditions under which the projective approach could be beneficial. The\nbenefits are illustrated via several simulated and real world examples.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 19:55:58 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Piironen", "Juho", ""], ["Paasiniemi", "Markus", ""], ["Vehtari", "Aki", ""]]}, {"id": "1810.02419", "submitter": "Zhiwu Huang", "authors": "Dinesh Acharya, Zhiwu Huang, Danda Pani Paudel, Luc Van Gool", "title": "Towards High Resolution Video Generation with Progressive Growing of\n  Sliced Wasserstein GANs", "comments": "Master Thesis from ETH Zurich, May 22, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extension of image generation to video generation turns out to be a very\ndifficult task, since the temporal dimension of videos introduces an extra\nchallenge during the generation process. Besides, due to the limitation of\nmemory and training stability, the generation becomes increasingly challenging\nwith the increase of the resolution/duration of videos. In this work, we\nexploit the idea of progressive growing of Generative Adversarial Networks\n(GANs) for higher resolution video generation. In particular, we begin to\nproduce video samples of low-resolution and short-duration, and then\nprogressively increase both resolution and duration alone (or jointly) by\nadding new spatiotemporal convolutional layers to the current networks.\nStarting from the learning on a very raw-level spatial appearance and temporal\nmovement of the video distribution, the proposed progressive method learns\nspatiotemporal information incrementally to generate higher resolution videos.\nFurthermore, we introduce a sliced version of Wasserstein GAN (SWGAN) loss to\nimprove the distribution learning on the video data of high-dimension and\nmixed-spatiotemporal distribution. SWGAN loss replaces the distance between\njoint distributions by that of one-dimensional marginal distributions, making\nthe loss easier to compute. We evaluate the proposed model on our collected\nface video dataset of 10,900 videos to generate photorealistic face videos of\n256x256x32 resolution. In addition, our model also reaches a record inception\nscore of 14.57 in unsupervised action recognition dataset UCF-101.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 20:41:48 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 15:57:41 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Acharya", "Dinesh", ""], ["Huang", "Zhiwu", ""], ["Paudel", "Danda Pani", ""], ["Van Gool", "Luc", ""]]}, {"id": "1810.02422", "submitter": "Ryan Julian", "authors": "Zhanpeng He, Ryan Julian, Eric Heiden, Hejia Zhang, Stefan Schaal,\n  Joseph J. Lim, Gaurav Sukhatme, Karol Hausman", "title": "Simulator Predictive Control: Using Learned Task Representations and MPC\n  for Zero-Shot Generalization and Sequencing", "comments": "Presented at NeurIPS 2018 Workshop: Deep Reinforcement Learning. See\n  https://youtu.be/te4JWe7LPKw for supplemental video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-to-real transfer is an important strategy for making reinforcement\nlearning practical with real robots. Successful sim-to-real transfer systems\nhave difficulty producing policies which generalize across tasks, despite\ntraining for thousands of hours equivalent real robot time. To address this\nshortcoming, we present a novel approach to efficiently learning new robotic\nskills directly on a real robot, based on model-predictive control (MPC) and an\nalgorithm for learning task representations. In short, we show how to reuse the\nsimulation from the pre-training step of sim-to-real methods as a tool for\nforesight, allowing the sim-to-real policy adapt to unseen tasks. Rather than\nend-to-end learning policies for single tasks and attempting to transfer them,\nwe first use simulation to simultaneously learn (1) a continuous\nparameterization (i.e. a skill embedding or latent) of task-appropriate\nprimitive skills, and (2) a single policy for these skills which is conditioned\non this representation. We then directly transfer our multi-skill policy to a\nreal robot, and actuate the robot by choosing sequences of skill latents which\nactuate the policy, with each latent corresponding to a pre-learned primitive\nskill controller. We complete unseen tasks by choosing new sequences of skill\nlatents to control the robot using MPC, where our MPC model is composed of the\npre-trained skill policy executed in the simulation environment, run in\nparallel with the real robot. We discuss the background and principles of our\nmethod, detail its practical implementation, and evaluate its performance by\nusing our method to train a real Sawyer Robot to achieve motion tasks such as\ndrawing and block pushing.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 20:59:35 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 21:35:14 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 21:59:18 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["He", "Zhanpeng", ""], ["Julian", "Ryan", ""], ["Heiden", "Eric", ""], ["Zhang", "Hejia", ""], ["Schaal", "Stefan", ""], ["Lim", "Joseph J.", ""], ["Sukhatme", "Gaurav", ""], ["Hausman", "Karol", ""]]}, {"id": "1810.02423", "submitter": "Pei Wang", "authors": "Pei Wang, Pushpi Paranamana, and Patrick Shafto", "title": "Generalizing the theory of cooperative inference", "comments": "Publish version for AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation information sharing is important to theories of human learning\nand has potential implications for machine learning. Prior work derived\nconditions for achieving optimal Cooperative Inference given strong, relatively\nrestrictive assumptions. We relax these assumptions by demonstrating\nconvergence for any discrete joint distribution, robustness through equivalence\nclasses and stability under perturbation, and effectiveness by deriving bounds\nfrom structural properties of the original joint distribution. We provide\ngeometric interpretations, connections to and implications for optimal\ntransport, and connections to importance sampling, and conclude by outlining\nopen questions and challenges to realizing the promise of Cooperative\nInference.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 21:04:29 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 21:02:30 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Wang", "Pei", ""], ["Paranamana", "Pushpi", ""], ["Shafto", "Patrick", ""]]}, {"id": "1810.02424", "submitter": "Chihuang Liu", "authors": "Chihuang Liu, Joseph JaJa", "title": "Feature Prioritization and Regularization Improve Standard Accuracy and\n  Adversarial Robustness", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has been successfully applied to build robust models at\na certain cost. While the robustness of a model increases, the standard\nclassification accuracy declines. This phenomenon is suggested to be an\ninherent trade-off. We propose a model that employs feature prioritization by a\nnonlinear attention module and $L_2$ feature regularization to improve the\nadversarial robustness and the standard accuracy relative to adversarial\ntraining. The attention module encourages the model to rely heavily on robust\nfeatures by assigning larger weights to them while suppressing non-robust\nfeatures. The regularizer encourages the model to extract similar features for\nthe natural and adversarial images, effectively ignoring the added\nperturbation. In addition to evaluating the robustness of our model, we provide\njustification for the attention module and propose a novel experimental\nstrategy that quantitatively demonstrates that our model is almost ideally\naligned with salient data characteristics. Additional experimental results\nillustrate the power of our model relative to the state of the art methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 21:10:09 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 19:28:38 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2019 21:56:18 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Liu", "Chihuang", ""], ["JaJa", "Joseph", ""]]}, {"id": "1810.02440", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Glen Mbeng, Stefano Soatto", "title": "Dynamics and Reachability of Learning Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the transition probability between two learning tasks, and show\nthat it decomposes into two factors. The first depends on the geometry of the\nloss landscape of a model trained on each task, independent of any particular\nmodel used. This is related to an information theoretic distance function, but\nis insufficient to predict success in transfer learning, as nearby tasks can be\nunreachable via fine-tuning. The second factor depends on the ease of\ntraversing the path between two tasks. With this dynamic component, we derive\nstrict lower bounds on the complexity necessary to learn a task starting from\nthe solution to another, which is one of the most common forms of transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:14:40 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 04:49:00 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Achille", "Alessandro", ""], ["Mbeng", "Glen", ""], ["Soatto", "Stefano", ""]]}, {"id": "1810.02442", "submitter": "Hao Zhang", "authors": "Haowen Xu, Hao Zhang, Zhiting Hu, Xiaodan Liang, Ruslan Salakhutdinov,\n  Eric Xing", "title": "AutoLoss: Learning Discrete Schedules for Alternate Optimization", "comments": "19-pages manuscripts. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems involve iteratively and alternately optimizing\ndifferent task objectives with respect to different sets of parameters.\nAppropriately scheduling the optimization of a task objective or a set of\nparameters is usually crucial to the quality of convergence. In this paper, we\npresent AutoLoss, a meta-learning framework that automatically learns and\ndetermines the optimization schedule. AutoLoss provides a generic way to\nrepresent and learn the discrete optimization schedule from metadata, allows\nfor a dynamic and data-driven schedule in ML problems that involve alternating\nupdates of different parameters or from different loss objectives. We apply\nAutoLoss on four ML tasks: d-ary quadratic regression, classification using a\nmulti-layer perceptron (MLP), image generation using GANs, and multi-task\nneural machine translation (NMT). We show that the AutoLoss controller is able\nto capture the distribution of better optimization schedules that result in\nhigher quality of convergence on all four tasks. The trained AutoLoss\ncontroller is generalizable -- it can guide and improve the learning of a new\ntask model with different specifications, or on different datasets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:21:55 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Xu", "Haowen", ""], ["Zhang", "Hao", ""], ["Hu", "Zhiting", ""], ["Liang", "Xiaodan", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric", ""]]}, {"id": "1810.02453", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Manfred K. Warmuth, Daniel Hsu", "title": "Correcting the bias in least squares regression with volume-rescaled\n  sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider linear regression where the examples are generated by an unknown\ndistribution on $R^d\\times R$. Without any assumptions on the noise, the linear\nleast squares solution for any i.i.d. sample will typically be biased w.r.t.\nthe least squares optimum over the entire distribution. However, we show that\nif an i.i.d. sample of any size k is augmented by a certain small additional\nsample, then the solution of the combined sample becomes unbiased. We show this\nwhen the additional sample consists of d points drawn jointly according to the\ninput distribution that is rescaled by the squared volume spanned by the\npoints. Furthermore, we propose algorithms to sample from this volume-rescaled\ndistribution when the data distribution is only known through an i.i.d sample.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 23:09:08 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Warmuth", "Manfred K.", ""], ["Hsu", "Daniel", ""]]}, {"id": "1810.02501", "submitter": "Gunwoong Park", "authors": "Gunwoong Park and Sion Park", "title": "High-Dimensional Poisson DAG Model Learning Using $\\ell_1$-Regularized\n  Regression", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new approach to learning high-dimensional Poisson\ndirected acyclic graphical (DAG) models from only observational data without\nstrong assumptions such as faithfulness and strong sparsity. A key component of\nour method is to decouple the ordering estimation or parent search where the\nproblems can be efficiently addressed using $\\ell_1$-regularized regression and\nthe mean-variance relationship. We show that sample size $n = \\Omega( d^{2}\n\\log^{9} p)$ is sufficient for our polynomial time Mean-variance Ratio Scoring\n(MRS) algorithm to recover the true directed graph, where $p$ is the number of\nnodes and $d$ is the maximum indegree. We verify through simulations that our\nalgorithm is statistically consistent in the high-dimensional $p>n$ setting,\nand performs well compared to state-of-the-art ODS, GES, and MMHC algorithms.\nWe also demonstrate through multivariate real count data that our MRS algorithm\nis well-suited to estimating DAG models for multivariate count data in\ncomparison to other methods used for discrete data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 03:12:27 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2018 04:58:25 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 09:58:22 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Park", "Gunwoong", ""], ["Park", "Sion", ""]]}, {"id": "1810.02513", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Samuel Schulter, Manmohan Chandraker", "title": "Learning To Simulate", "comments": "Published at International Conference on Learning Representations\n  (ICLR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation is a useful tool in situations where training data for machine\nlearning models is costly to annotate or even hard to acquire. In this work, we\npropose a reinforcement learning-based method for automatically adjusting the\nparameters of any (non-differentiable) simulator, thereby controlling the\ndistribution of synthesized data in order to maximize the accuracy of a model\ntrained on that data. In contrast to prior art that hand-crafts these\nsimulation parameters or adjusts only parts of the available parameters, our\napproach fully controls the simulator with the actual underlying goal of\nmaximizing accuracy, rather than mimicking the real data distribution or\nrandomly generating a large volume of data. We find that our approach (i)\nquickly converges to the optimal simulation parameters in controlled\nexperiments and (ii) can indeed discover good sets of parameters for an image\nrendering simulator in actual computer vision applications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 04:11:25 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 03:15:27 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Schulter", "Samuel", ""], ["Chandraker", "Manmohan", ""]]}, {"id": "1810.02518", "submitter": "arXiv Admin", "authors": "Rahul Makhijani", "title": "Social Choice Random Utility Models of Intransitive Pairwise Comparisons", "comments": "This article has been withdrawn by arXiv administrators due to an\n  irreconcilable authorship dispute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing need for discrete choice models that account for the\ncomplex nature of human choices, escaping traditional behavioral assumptions\nsuch as the transitivity of pairwise preferences. Recently, several parametric\nmodels of intransitive comparisons have been proposed, but in all cases the\nmaximum likelihood problem is non-concave, making inference difficult. In this\nwork we generalize this trend, showing that there cannot exist any parametric\nmodel with a concave log-likelihood function that can exhibit intransitive\npreferences. Given this result, we motivate a new model for analyzing\nintransitivity in pairwise comparisons, taking inspiration from the Condorcet\nmethod (majority vote) in social choice theory. The Majority Vote model we\nanalyze is defined as a voting process over independent Random Utility Models\n(RUMs). We infer a multidimensional embedding of each object or player, in\ncontrast to the traditional one-dimensional embedding used by models such as\nthe Thurstone or Bradley-Terry-Luce (BTL) models. We show that a\nthree-dimensional majority vote model is capable of modeling arbitrarily strong\nand long intransitive cycles, and can also represent arbitrary pairwise\ncomparison probabilities on any triplet. We provide experimental results that\nsubstantiate our claims regarding the effectiveness of our model in capturing\nintransitivity for various pairwise choice tasks such as predicting choices in\nrecommendation systems, winners in online video games, and elections.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 05:26:29 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 18:51:21 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 15:39:17 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Makhijani", "Rahul", ""]]}, {"id": "1810.02525", "submitter": "Peter Henderson", "authors": "Peter Henderson, Joshua Romoff, Joelle Pineau", "title": "Where Did My Optimum Go?: An Empirical Analysis of Gradient Descent\n  Optimization in Policy Gradient Methods", "comments": "Accepted at the European Workshop on Reinforcement Learning 2018\n  (EWRL14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent analyses of certain gradient descent optimization methods have shown\nthat performance can degrade in some settings - such as with stochasticity or\nimplicit momentum. In deep reinforcement learning (Deep RL), such optimization\nmethods are often used for training neural networks via the temporal difference\nerror or policy gradient. As an agent improves over time, the optimization\ntarget changes and thus the loss landscape (and local optima) change. Due to\nthe failure modes of those methods, the ideal choice of optimizer for Deep RL\nremains unclear. As such, we provide an empirical analysis of the effects that\na wide range of gradient descent optimizers and their hyperparameters have on\npolicy gradient methods, a subset of Deep RL algorithms, for benchmark\ncontinuous control tasks. We find that adaptive optimizers have a narrow window\nof effective learning rates, diverging in other cases, and that the\neffectiveness of momentum varies depending on the properties of the\nenvironment. Our analysis suggests that there is significant interplay between\nthe dynamics of the environment and Deep RL algorithm properties which aren't\nnecessarily accounted for by traditional adaptive gradient methods. We provide\nsuggestions for optimal settings of current methods and further lines of\nresearch based on our findings.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 05:52:49 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Henderson", "Peter", ""], ["Romoff", "Joshua", ""], ["Pineau", "Joelle", ""]]}, {"id": "1810.02528", "submitter": "Cheolhyeong Kim", "authors": "Cheolhyeong Kim, Seungtae Park, Hyung Ju Hwang", "title": "Local Stability and Performance of Simple Gradient Penalty\n  mu-Wasserstein GAN", "comments": "21 pages, 39 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein GAN(WGAN) is a model that minimizes the Wasserstein distance\nbetween a data distribution and sample distribution. Recent studies have\nproposed stabilizing the training process for the WGAN and implementing the\nLipschitz constraint. In this study, we prove the local stability of optimizing\nthe simple gradient penalty $\\mu$-WGAN(SGP $\\mu$-WGAN) under suitable\nassumptions regarding the equilibrium and penalty measure $\\mu$. The measure\nvalued differentiation concept is employed to deal with the derivative of the\npenalty terms, which is helpful for handling abstract singular measures with\nlower dimensional support. Based on this analysis, we claim that penalizing the\ndata manifold or sample manifold is the key to regularizing the original WGAN\nwith a gradient penalty. Experimental results obtained with unintuitive penalty\nmeasures that satisfy our assumptions are also provided to support our\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 06:03:03 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Kim", "Cheolhyeong", ""], ["Park", "Seungtae", ""], ["Hwang", "Hyung Ju", ""]]}, {"id": "1810.02529", "submitter": "Lionel Yelibi", "authors": "Lionel Yelibi, Tim Gebbie", "title": "Fast Super-Paramagnetic Clustering", "comments": "25 pages, 41 Figures and code at\n  https://github.com/tehraio/potts-model-clustering", "journal-ref": "Physica A, Volume 551, 1 August 2020, 124049", "doi": "10.1016/j.physa.2019.124049", "report-no": null, "categories": "q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We map stock market interactions to spin models to recover their hierarchical\nstructure using a simulated annealing based Super-Paramagnetic Clustering (SPC)\nalgorithm. This is directly compared to a modified implementation of a maximum\nlikelihood approach we call Fast Super-Paramagnetic Clustering (f-SPC). The\nmethods are first applied standard toy test-case problems, and then to a\ndata-set of 447 stocks traded on the New York Stock Exchange (NYSE) over 1249\ndays. The signal to noise ratio of stock market correlation matrices is briefly\nconsidered. Our result recover approximately clusters representative of\nstandard economic sectors and mixed ones whose dynamics shine light on the\nadaptive nature of financial markets and raise concerns relating to the\neffectiveness of industry based static financial market classification in the\nworld of real-time data analytics. A key result is that we show that f-SPC\nmaximum likelihood solutions converge to ones found within the\nSuper-Paramagnetic Phase where the entropy is maximum, and those solutions are\nqualitatively better for high dimensionality data-sets.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 06:06:13 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 21:43:08 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yelibi", "Lionel", ""], ["Gebbie", "Tim", ""]]}, {"id": "1810.02541", "submitter": "Amin Babadi", "authors": "Perttu H\\\"am\\\"al\\\"ainen, Amin Babadi, Xiaoxiao Ma, Jaakko Lehtinen", "title": "PPO-CMA: Proximal Policy Optimization with Covariance Matrix Adaptation", "comments": "This paper has been accepted to IEEE International Workshop on\n  Machine Learning for Signal Processing (MLSP 2020). The arxiv version also\n  includes an appendix that covers more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal Policy Optimization (PPO) is a highly popular model-free\nreinforcement learning (RL) approach. However, we observe that in a continuous\naction space, PPO can prematurely shrink the exploration variance, which leads\nto slow progress and may make the algorithm prone to getting stuck in local\noptima. Drawing inspiration from CMA-ES, a black-box evolutionary optimization\nmethod designed for robustness in similar situations, we propose PPO-CMA, a\nproximal policy optimization approach that adaptively expands the exploration\nvariance to speed up progress. With only minor changes to PPO, our algorithm\nconsiderably improves performance in Roboschool continuous control benchmarks.\nOur results also show that PPO-CMA, as opposed to PPO, is significantly less\nsensitive to the choice of hyperparameters, allowing one to use it in complex\nmovement optimization tasks without requiring tedious tuning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 06:59:29 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 07:57:04 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 09:24:26 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2019 09:29:44 GMT"}, {"version": "v5", "created": "Wed, 23 Jan 2019 21:47:31 GMT"}, {"version": "v6", "created": "Fri, 24 May 2019 09:16:37 GMT"}, {"version": "v7", "created": "Tue, 27 Aug 2019 07:34:01 GMT"}, {"version": "v8", "created": "Mon, 3 Aug 2020 07:19:28 GMT"}, {"version": "v9", "created": "Tue, 3 Nov 2020 07:51:49 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""], ["Babadi", "Amin", ""], ["Ma", "Xiaoxiao", ""], ["Lehtinen", "Jaakko", ""]]}, {"id": "1810.02555", "submitter": "Mike Wu", "authors": "Mike Wu, Noah Goodman, Stefano Ermon", "title": "Differentiable Antithetic Sampling for Variance Reduction in Stochastic\n  Variational Inference", "comments": "8 pages with 7 pages appendix; AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization techniques are standard in variational inference\nalgorithms. These methods estimate gradients by approximating expectations with\nindependent Monte Carlo samples. In this paper, we explore a technique that\nuses correlated, but more representative , samples to reduce estimator\nvariance. Specifically, we show how to generate antithetic samples that match\nsample moments with the true moments of an underlying importance distribution.\nCombining a differentiable antithetic sampler with modern stochastic\nvariational inference, we showcase the effectiveness of this approach for\nlearning a deep generative model.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 07:42:15 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 17:24:38 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Wu", "Mike", ""], ["Goodman", "Noah", ""], ["Ermon", "Stefano", ""]]}, {"id": "1810.02561", "submitter": "Simon Olofsson", "authors": "Simon Olofsson and Lukas Hebing and Sebastian Niedenf\\\"uhr and Marc\n  Peter Deisenroth and Ruth Misener", "title": "GPdoemd: a Python package for design of experiments for model\n  discrimination", "comments": null, "journal-ref": "Computers & Chemical Engineering, Volume 125, 2019, Pages 54-70", "doi": "10.1016/j.compchemeng.2019.03.010", "report-no": null, "categories": "cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model discrimination identifies a mathematical model that usefully explains\nand predicts a given system's behaviour. Researchers will often have several\nmodels, i.e. hypotheses, about an underlying system mechanism, but insufficient\nexperimental data to discriminate between the models, i.e. discard inaccurate\nmodels. Given rival mathematical models and an initial experimental data set,\noptimal design of experiments suggests maximally informative experimental\nobservations that maximise a design criterion weighted by prediction\nuncertainty. The model uncertainty requires gradients, which may not be readily\navailable for black-box models. This paper (i) proposes a new design criterion\nusing the Jensen-R\\'enyi divergence, and (ii) develops a novel method replacing\nblack-box models with Gaussian process surrogates. Using the surrogates, we\nmarginalise out the model parameters with approximate inference. Results show\nthese contributions working well for both classical and new test instances. We\nalso (iii) introduce and discuss GPdoemd, the open-source implementation of the\nGaussian process surrogate method.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 08:02:28 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 17:34:03 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2019 15:24:29 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Olofsson", "Simon", ""], ["Hebing", "Lukas", ""], ["Niedenf\u00fchr", "Sebastian", ""], ["Deisenroth", "Marc Peter", ""], ["Misener", "Ruth", ""]]}, {"id": "1810.02567", "submitter": "Shuai Li", "authors": "Shuai Li, Tor Lattimore, Csaba Szepesv\\'ari", "title": "Online Learning to Rank with Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model for online ranking in which the click probability\nfactors into an examination and attractiveness function and the attractiveness\nfunction is a linear function of a feature vector and an unknown parameter.\nOnly relatively mild assumptions are made on the examination function. A novel\nalgorithm for this setup is analysed, showing that the dependence on the number\nof items is replaced by a dependence on the dimension, allowing the new\nalgorithm to handle a large number of items. When reduced to the orthogonal\ncase, the regret of the algorithm improves on the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 08:39:00 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 06:12:48 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Li", "Shuai", ""], ["Lattimore", "Tor", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1810.02658", "submitter": "Ruzhang Zhao", "authors": "Ruzhang Zhao, Pengyu Hong, Jun S Liu", "title": "IMMIGRATE: A Margin-based Feature Selection Method with Interaction\n  Terms", "comments": "R package ('Immigrate') available on CRAN", "journal-ref": "Entropy. 2020; 22(3):291", "doi": "10.3390/e22030291", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relief based algorithms have often been claimed to uncover feature\ninteractions. However, it is still unclear whether and how interaction terms\nwill be differentiated from marginal effects. In this paper, we propose\nIMMIGRATE algorithm by including and training weights for interaction terms.\nBesides applying the large margin principle, we focus on the robustness of the\ncontributors of margin and consider local and global information\nsimultaneously. Moreover, IMMIGRATE has been shown to enjoy attractive\nproperties, such as robustness and combination with Boosting. We evaluate our\nproposed method on several tasks, which achieves state-of-the-art results\nsignificantly.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 13:00:12 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 16:43:00 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 03:04:33 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zhao", "Ruzhang", ""], ["Hong", "Pengyu", ""], ["Liu", "Jun S", ""]]}, {"id": "1810.02677", "submitter": "Yancheng Yuan", "authors": "Defeng Sun, Kim-Chuan Toh and Yancheng Yuan", "title": "Convex Clustering: Model, Theoretical Guarantee and Efficient Algorithm", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.07091", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental problem in unsupervised learning. Popular methods\nlike K-means, may suffer from poor performance as they are prone to get stuck\nin its local minima. Recently, the sum-of-norms (SON) model (also known as the\nclustering path) has been proposed in Pelckmans et al. (2005), Lindsten et al.\n(2011) and Hocking et al. (2011). The perfect recovery properties of the convex\nclustering model with uniformly weighted all pairwise-differences\nregularization have been proved by Zhu et al. (2014) and Panahi et al. (2017).\nHowever, no theoretical guarantee has been established for the general weighted\nconvex clustering model, where better empirical results have been observed. In\nthe numerical optimization aspect, although algorithms like the alternating\ndirection method of multipliers (ADMM) and the alternating minimization\nalgorithm (AMA) have been proposed to solve the convex clustering model (Chi\nand Lange, 2015), it still remains very challenging to solve large-scale\nproblems. In this paper, we establish sufficient conditions for the perfect\nrecovery guarantee of the general weighted convex clustering model, which\ninclude and improve existing theoretical results as special cases. In addition,\nwe develop a semismooth Newton based augmented Lagrangian method for solving\nlarge-scale convex clustering problems. Extensive numerical experiments on both\nsimulated and real data demonstrate that our algorithm is highly efficient and\nrobust for solving large-scale problems. Moreover, the numerical results also\nshow the superior performance and scalability of our algorithm comparing to the\nexisting first-order methods. In particular, our algorithm is able to solve a\nconvex clustering problem with 200,000 points in $\\mathbb{R}^3$ in about 6\nminutes.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:52:42 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Sun", "Defeng", ""], ["Toh", "Kim-Chuan", ""], ["Yuan", "Yancheng", ""]]}, {"id": "1810.02678", "submitter": "Tomi Peltola", "authors": "Tomi Peltola", "title": "Local Interpretable Model-agnostic Explanations of Bayesian Predictive\n  Models via Kullback-Leibler Projections", "comments": "Extended abstract/short paper, Proceedings of the 2nd Workshop on\n  Explainable Artificial Intelligence (XAI 2018) at IJCAI/ECAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method, KL-LIME, for explaining predictions of Bayesian\npredictive models by projecting the information in the predictive distribution\nlocally to a simpler, interpretable explanation model. The proposed approach\ncombines the recent Local Interpretable Model-agnostic Explanations (LIME)\nmethod with ideas from Bayesian projection predictive variable selection\nmethods. The information theoretic basis helps in navigating the trade-off\nbetween explanation fidelity and complexity. We demonstrate the method in\nexplaining MNIST digit classifications made by a Bayesian deep convolutional\nneural network.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 13:43:08 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Peltola", "Tomi", ""]]}, {"id": "1810.02684", "submitter": "Vahid Moosavi", "authors": "Joao P. Leitao, Mohamed Zaghloul and Vahid Moosavi", "title": "Modeling overland flow from local inflows in almost no-time, using Self\n  Organizing Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physically-based overland flow models are computationally demanding,\nhindering their use for real-time applications. Therefore, the development of\nfast (and reasonably accurate) overland flow models is needed if they are to be\nused to support flood mitigation decision making. In this study, we investigate\nthe potential of Self-Organizing Maps to rapidly generate water depth and flood\nextent results. To conduct the study, we developed a flood-simulation specific\nSOM, using cellular automata flood model results and a synthetic DEM and inflow\nhydrograph. The preliminary results showed that water depth and flood extent\nresults produced by the SOM are reasonably accurate and obtained in a very\nshort period of time. Based on this, it seems that SOMs have the potential to\nprovide critical flood information to support real-time flood mitigation\ndecisions. The findings presented would however require further investigations\nto obtain general conclusions; these further investigations may include the\nconsideration of real terrain representations, real water supply networks and\nrealistic inflows from pipe bursts.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 18:54:29 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Leitao", "Joao P.", ""], ["Zaghloul", "Mohamed", ""], ["Moosavi", "Vahid", ""]]}, {"id": "1810.02688", "submitter": "Philippe Besse", "authors": "Philippe Besse (IMT), Brendan Guillouet (IMT), B\\'eatrice Laurent\n  (IMT)", "title": "Wikistat 2.0: Educational Resources for Artificial Intelligence", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data, data science, deep learning, artificial intelligence are the key\nwords of intense hype related with a job market in full evolution, that impose\nto adapt the contents of our university professional trainings. Which\nartificial intelligence is mostly concerned by the job offers? Which\nmethodologies and technologies should be favored in the training programs?\nWhich objectives, tools and educational resources do we needed to put in place\nto meet these pressing needs? We answer these questions in describing the\ncontents and operational resources in the Data Science orientation of the\nspecialty Applied Mathematics at INSA Toulouse. We focus on basic mathematics\ntraining (Optimization, Probability, Statistics), associated with the practical\nimplementation of the most performing statistical learning algorithms, with the\nmost appropriate technologies and on real examples. Considering the huge\nvolatility of the technologies, it is imperative to train students in\nseft-training, this will be their technological watch tool when they will be in\nprofessional activity. This explains the structuring of the educational site\ngithub.com/wikistat into a set of tutorials. Finally, to motivate the thorough\npractice of these tutorials, a serious game is organized each year in the form\nof a prediction contest between students of Master degrees in Applied\nMathematics for IA.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 08:27:59 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 13:07:57 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Besse", "Philippe", "", "IMT"], ["Guillouet", "Brendan", "", "IMT"], ["Laurent", "B\u00e9atrice", "", "IMT"]]}, {"id": "1810.02716", "submitter": "Shuaiwen Wang", "authors": "Shuaiwen Wang, Wenda Zhou, Arian Maleki, Haihao Lu, Vahab Mirrokni", "title": "Approximate Leave-One-Out for High-Dimensional Non-Differentiable\n  Learning Problems", "comments": "63 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1807.02694", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following class of learning schemes: \\begin{equation}\n\\label{eq:main-problem1}\n  \\hat{\\boldsymbol{\\beta}} := \\underset{\\boldsymbol{\\beta} \\in\n\\mathcal{C}}{\\arg\\min} \\;\\sum_{j=1}^n\n\\ell(\\boldsymbol{x}_j^\\top\\boldsymbol{\\beta}; y_j) + \\lambda\nR(\\boldsymbol{\\beta}), \\qquad \\qquad \\qquad (1) \\end{equation} where\n$\\boldsymbol{x}_i \\in \\mathbb{R}^p$ and $y_i \\in \\mathbb{R}$ denote the $i^{\\rm\nth}$ feature and response variable respectively. Let $\\ell$ and $R$ be the\nconvex loss function and regularizer, $\\boldsymbol{\\beta}$ denote the unknown\nweights, and $\\lambda$ be a regularization parameter. $\\mathcal{C} \\subset\n\\mathbb{R}^{p}$ is a closed convex set. Finding the optimal choice of $\\lambda$\nis a challenging problem in high-dimensional regimes where both $n$ and $p$ are\nlarge. We propose three frameworks to obtain a computationally efficient\napproximation of the leave-one-out cross validation (LOOCV) risk for nonsmooth\nlosses and regularizers. Our three frameworks are based on the primal, dual,\nand proximal formulations of (1). Each framework shows its strength in certain\ntypes of problems. We prove the equivalence of the three approaches under\nsmoothness conditions. This equivalence enables us to justify the accuracy of\nthe three methods under such conditions. We use our approaches to obtain a risk\nestimate for several standard problems, including generalized LASSO, nuclear\nnorm regularization, and support vector machines. We empirically demonstrate\nthe effectiveness of our results for non-differentiable cases.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 16:11:27 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Wang", "Shuaiwen", ""], ["Zhou", "Wenda", ""], ["Maleki", "Arian", ""], ["Lu", "Haihao", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1810.02789", "submitter": "Dmitry Molchanov", "authors": "Dmitry Molchanov, Valery Kharitonov, Artem Sobolev, Dmitry Vetrov", "title": "Doubly Semi-Implicit Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the existing framework of semi-implicit variational inference\n(SIVI) and introduce doubly semi-implicit variational inference (DSIVI), a way\nto perform variational inference and learning when both the approximate\nposterior and the prior distribution are semi-implicit. In other words, DSIVI\nperforms inference in models where the prior and the posterior can be expressed\nas an intractable infinite mixture of some analytic density with a highly\nflexible implicit mixing distribution. We provide a sandwich bound on the\nevidence lower bound (ELBO) objective that can be made arbitrarily tight.\nUnlike discriminator-based and kernel-based approaches to implicit variational\ninference, DSIVI optimizes a proper lower bound on ELBO that is asymptotically\nexact. We evaluate DSIVI on a set of problems that benefit from implicit\npriors. In particular, we show that DSIVI gives rise to a simple modification\nof VampPrior, the current state-of-the-art prior for variational autoencoders,\nwhich improves its performance.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 16:54:18 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 13:29:11 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Molchanov", "Dmitry", ""], ["Kharitonov", "Valery", ""], ["Sobolev", "Artem", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.02797", "submitter": "Shiv Ram Dubey", "authors": "S H Shabbeer Basha, Soumen Ghosh, Kancharagunta Kishan Babu, Shiv Ram\n  Dubey, Viswanath Pulabaigari, Snehasis Mukherjee", "title": "RCCNet: An Efficient Convolutional Neural Network for Histological\n  Routine Colon Cancer Nuclei Classification", "comments": "Published in ICARCV 2018", "journal-ref": null, "doi": "10.1109/ICARCV.2018.8581147", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and precise classification of histological cell nuclei is of utmost\nimportance due to its potential applications in the field of medical image\nanalysis. It would facilitate the medical practitioners to better understand\nand explore various factors for cancer treatment. The classification of\nhistological cell nuclei is a challenging task due to the cellular\nheterogeneity. This paper proposes an efficient Convolutional Neural Network\n(CNN) based architecture for classification of histological routine colon\ncancer nuclei named as RCCNet. The main objective of this network is to keep\nthe CNN model as simple as possible. The proposed RCCNet model consists of only\n1,512,868 learnable parameters which are significantly less compared to the\npopular CNN models such as AlexNet, CIFARVGG, GoogLeNet, and WRN. The\nexperiments are conducted over publicly available routine colon cancer\nhistological dataset \"CRCHistoPhenotypes\". The results of the proposed RCCNet\nmodel are compared with five state-of-the-art CNN models in terms of the\naccuracy, weighted average F1 score and training time. The proposed method has\nachieved a classification accuracy of 80.61% and 0.7887 weighted average F1\nscore. The proposed RCCNet is more efficient and generalized terms of the\ntraining time and data over-fitting, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 07:18:58 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 12:09:31 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 05:19:12 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Basha", "S H Shabbeer", ""], ["Ghosh", "Soumen", ""], ["Babu", "Kancharagunta Kishan", ""], ["Dubey", "Shiv Ram", ""], ["Pulabaigari", "Viswanath", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1810.02810", "submitter": "Raef Bassily", "authors": "Raef Bassily", "title": "Linear Queries Estimation with Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating a set of $d$ linear queries with respect\nto some unknown distribution $\\mathbf{p}$ over a domain $\\mathcal{J}=[J]$ based\non a sensitive data set of $n$ individuals under the constraint of local\ndifferential privacy. This problem subsumes a wide range of estimation tasks,\ne.g., distribution estimation and $d$-dimensional mean estimation. We provide\nnew algorithms for both the offline (non-adaptive) and adaptive versions of\nthis problem.\n  In the offline setting, the set of queries are fixed before the algorithm\nstarts. In the regime where $n\\lesssim d^2/\\log(J)$, our algorithms attain\n$L_2$ estimation error that is independent of $d$, and is tight up to a factor\nof $\\tilde{O}\\left(\\log^{1/4}(J)\\right)$. For the special case of distribution\nestimation, we show that projecting the output estimate of an algorithm due to\n[Acharya et al. 2018] on the probability simplex yields an $L_2$ error that\ndepends only sub-logarithmically on $J$ in the regime where $n\\lesssim\nJ^2/\\log(J)$. These results show the possibility of accurate estimation of\nlinear queries in the high-dimensional settings under the $L_2$ error\ncriterion.\n  In the adaptive setting, the queries are generated over $d$ rounds; one query\nat a time. In each round, a query can be chosen adaptively based on all the\nhistory of previous queries and answers. We give an algorithm for this problem\nwith optimal $L_{\\infty}$ estimation error (worst error in the estimated values\nfor the queries w.r.t. the data distribution). Our bound matches a lower bound\non the $L_{\\infty}$ error for the offline version of this problem [Duchi et al.\n2013].\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 17:59:25 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Bassily", "Raef", ""]]}, {"id": "1810.02812", "submitter": "Tiep H. Vu", "authors": "Tiep Vu, Lam Nguyen, Vishal Monga", "title": "Classifying Multi-channel UWB SAR Imagery via Tensor Sparsity Learning\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using low-frequency (UHF to L-band) ultra-wideband (UWB) synthetic aperture\nradar (SAR) technology for detecting buried and obscured targets, e.g. bomb or\nmine, has been successfully demonstrated recently. Despite promising recent\nprogress, a significant open challenge is to distinguish obscured targets from\nother (natural and manmade) clutter sources in the scene. The problem becomes\nexacerbated in the presence of noisy responses from rough ground surfaces. In\nthis paper, we present three novel sparsity-driven techniques, which not only\nexploit the subtle features of raw captured data but also take advantage of the\npolarization diversity and the aspect angle dependence information from\nmulti-channel SAR data. First, the traditional sparse representation-based\nclassification (SRC) is generalized to exploit shared information of classes\nand various sparsity structures of tensor coefficients for multi-channel data.\nCorresponding tensor dictionary learning models are consequently proposed to\nenhance classification accuracy. Lastly, a new tensor sparsity model is\nproposed to model responses from multiple consecutive looks of objects, which\nis a unique characteristic of the dataset we consider. Extensive experimental\nresults on a high-fidelity electromagnetic simulated dataset and radar data\ncollected from the U.S. Army Research Laboratory side-looking SAR demonstrate\nthe advantages of proposed tensor sparsity models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:28:44 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Vu", "Tiep", ""], ["Nguyen", "Lam", ""], ["Monga", "Vishal", ""]]}, {"id": "1810.02814", "submitter": "Guang Cheng", "authors": "Yue Xing, Qifan Song, Guang Cheng", "title": "Statistical Optimality of Interpolated Nearest Neighbor Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of deep learning, understanding over-fitting phenomenon becomes\nincreasingly important. It is observed that carefully designed deep neural\nnetworks achieve small testing error even when the training error is close to\nzero. One possible explanation is that for many modern machine learning\nalgorithms, over-fitting can greatly reduce the estimation bias, while not\nincreasing the estimation variance too much. To illustrate the above idea, we\nprove that the proposed interpolated nearest neighbor algorithm achieves the\nminimax optimal rate in both regression and classification regimes, and observe\nthat they are empirically better than the traditional $k$ nearest neighbor\nmethod in some cases.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 03:15:16 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 20:17:12 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xing", "Yue", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "1810.02837", "submitter": "Arun Sathanur", "authors": "Arun V Sathanur", "title": "Scaling Submodular Optimization Approaches for Control Applications in\n  Networked Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often times, in many design problems, there is a need to select a small set\nof informative or representative elements from a large ground set of entities\nin an optimal fashion. Submodular optimization that provides for a formal way\nto solve such problems, has recently received significant attention from the\ncontrols community where such subset selection problems are abound. However,\nscaling these approaches to large systems can be challenging because of the\nhigh computational complexity of the overall flow, in-part due to the\nhigh-complexity compute-oracles used to determine the objective function\nvalues. In this work, we explore a well-known paradigm, namely leader-selection\nin a multi-agent networked environment to illustrate strategies for scalable\nsubmodular optimization. We study the performance of the state-of-the-art\nstochastic and distributed greedy algorithms as well as explore techniques that\naccelerate the computation oracles within the optimization loop. We finally\npresent results combining accelerated greedy algorithms with accelerated\ncomputation oracles and demonstrate significant speedups with little loss of\noptimality when compared to the baseline ordinary greedy algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:12:06 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Sathanur", "Arun V", ""]]}, {"id": "1810.02840", "submitter": "Alexander Ratner", "authors": "Alexander Ratner, Braden Hancock, Jared Dunnmon, Frederic Sala,\n  Shreyash Pandey, Christopher R\\'e", "title": "Training Complex Models with Multi-Task Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning models continue to increase in complexity, collecting\nlarge hand-labeled training sets has become one of the biggest roadblocks in\npractice. Instead, weaker forms of supervision that provide noisier but cheaper\nlabels are often used. However, these weak supervision sources have diverse and\nunknown accuracies, may output correlated labels, and may label different tasks\nor apply at different levels of granularity. We propose a framework for\nintegrating and modeling such weak supervision sources by viewing them as\nlabeling different related sub-tasks of a problem, which we refer to as the\nmulti-task weak supervision setting. We show that by solving a matrix\ncompletion-style problem, we can recover the accuracies of these multi-task\nsources given their dependency structure, but without any labeled data, leading\nto higher-quality supervision for training an end model. Theoretically, we show\nthat the generalization error of models trained with this approach improves\nwith the number of unlabeled data points, and characterize the scaling with\nrespect to the task and dependency structures. On three fine-grained\nclassification problems, we show that our approach leads to average gains of\n20.2 points in accuracy over a traditional supervised approach, 6.8 points over\na majority vote baseline, and 4.1 points over a previously proposed weak\nsupervision method that models tasks separately.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:30:11 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 18:31:48 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Ratner", "Alexander", ""], ["Hancock", "Braden", ""], ["Dunnmon", "Jared", ""], ["Sala", "Frederic", ""], ["Pandey", "Shreyash", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1810.02845", "submitter": "Salvator Lombardo", "authors": "Jun Han, Salvator Lombardo, Christopher Schroers, Stephan Mandt", "title": "Deep Generative Video Compression", "comments": "Accepted at NeurIPS 2019, 15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usage of deep generative models for image compression has led to\nimpressive performance gains over classical codecs while neural video\ncompression is still in its infancy. Here, we propose an end-to-end, deep\ngenerative modeling approach to compress temporal sequences with a focus on\nvideo. Our approach builds upon variational autoencoder (VAE) models for\nsequential data and combines them with recent work on neural image compression.\nThe approach jointly learns to transform the original sequence into a\nlower-dimensional representation as well as to discretize and entropy code this\nrepresentation according to predictions of the sequential VAE. Rate-distortion\nevaluations on small videos from public data sets with varying complexity and\ndiversity show that our model yields competitive results when trained on\ngeneric video content. Extreme compression performance is achieved when\ntraining the model on specialized content.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:42:02 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 22:48:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Han", "Jun", ""], ["Lombardo", "Salvator", ""], ["Schroers", "Christopher", ""], ["Mandt", "Stephan", ""]]}, {"id": "1810.02876", "submitter": "Onur Atan", "authors": "Onur Atan, William R. Zame, Mihaela van der Schaar", "title": "Adaptive Clinical Trials: Exploiting Sequential Patient Recruitment and\n  Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized Controlled Trials (RCTs) are the gold standard for comparing the\neffectiveness of a new treatment to the current one (the control). Most RCTs\nallocate the patients to the treatment group and the control group by uniform\nrandomization. We show that this procedure can be highly sub-optimal (in terms\nof learning) if -- as is often the case -- patients can be recruited in cohorts\n(rather than all at once), the effects on each cohort can be observed before\nrecruiting the next cohort, and the effects are heterogeneous across\nidentifiable subgroups of patients. We formulate the patient allocation problem\nas a finite stage Markov Decision Process in which the objective is to minimize\na given weighted combination of type-I and type-II errors. Because finding the\nexact solution to this Markov Decision Process is computationally intractable,\nwe propose an algorithm -- \\textit{Knowledge Gradient for Randomized Controlled\nTrials} (RCT-KG) -- that yields an approximate solution. We illustrate our\nalgorithm on a synthetic dataset with Bernoulli outcomes and compare it with\nuniform randomization. For a given size of trial our method achieves\nsignificant reduction in error, and to achieve a prescribed level of confidence\n(in identifying whether the treatment is superior to the control), our method\nrequires many fewer patients. Our approach uses what has been learned from the\neffects on previous cohorts to recruit patients to subgroups and allocate\npatients (to treatment/control) within subgroups in a way that promotes more\nefficient learning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 20:19:33 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 18:38:42 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Atan", "Onur", ""], ["Zame", "William R.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1810.02880", "submitter": "Jared Willard", "authors": "Xiaowei Jia, Anuj Karpatne, Jared Willard, Michael Steinbach, Jordan\n  Read, Paul C Hanson, Hilary A Dugan, Vipin Kumar", "title": "Physics Guided Recurrent Neural Networks For Modeling Dynamical Systems:\n  Application to Monitoring Water Temperature And Quality In Lakes", "comments": "3 pages, 3 figures, 8th International Workshop on Climate Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel framework for combining scientific\nknowledge within physics-based models and recurrent neural networks to advance\nscientific discovery in many dynamical systems. We will first describe the use\nof outputs from physics-based models in learning a hybrid-physics-data model.\nThen, we further incorporate physical knowledge in real-world dynamical systems\nas additional constraints for training recurrent neural networks. We will apply\nthis approach on modeling lake temperature and quality where we take into\naccount the physical constraints along both the depth dimension and time\ndimension. By using scientific knowledge to guide the construction and learning\nthe data-driven model, we demonstrate that this method can achieve better\nprediction accuracy as well as scientific consistency of results.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 20:40:02 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Jia", "Xiaowei", ""], ["Karpatne", "Anuj", ""], ["Willard", "Jared", ""], ["Steinbach", "Michael", ""], ["Read", "Jordan", ""], ["Hanson", "Paul C", ""], ["Dugan", "Hilary A", ""], ["Kumar", "Vipin", ""]]}, {"id": "1810.02894", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Xiaojie Mao, Angela Zhou", "title": "Interval Estimation of Individual-Level Causal Effects Under Unobserved\n  Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning conditional average treatment effects (CATE)\nfrom observational data with unobserved confounders. The CATE function maps\nbaseline covariates to individual causal effect predictions and is key for\npersonalized assessments. Recent work has focused on how to learn CATE under\nunconfoundedness, i.e., when there are no unobserved confounders. Since CATE\nmay not be identified when unconfoundedness is violated, we develop a\nfunctional interval estimator that predicts bounds on the individual causal\neffects under realistic violations of unconfoundedness. Our estimator takes the\nform of a weighted kernel estimator with weights that vary adversarially. We\nprove that our estimator is sharp in that it converges exactly to the tightest\nbounds possible on CATE when there may be unobserved confounders. Further, we\nstudy personalized decision rules derived from our estimator and prove that\nthey achieve optimal minimax regret asymptotically. We assess our approach in a\nsimulation study as well as demonstrate its application in the case of hormone\nreplacement therapy by comparing conclusions from a real observational study\nand clinical trial.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 21:42:40 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""], ["Zhou", "Angela", ""]]}, {"id": "1810.02897", "submitter": "Ye Zhu PhD", "authors": "Ye Zhu, Kai Ming Ting, Mark Carman, Maia Angelova", "title": "CDF Transform-and-Shift: An effective way to deal with datasets of\n  inhomogeneous cluster densities", "comments": "Pattern Recognition (2021)", "journal-ref": null, "doi": "10.1016/j.patcog.2021.107977", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of inhomogeneous cluster densities has been a long-standing issue\nfor distance-based and density-based algorithms in clustering and anomaly\ndetection. These algorithms implicitly assume that all clusters have\napproximately the same density. As a result, they often exhibit a bias towards\ndense clusters in the presence of sparse clusters. Many remedies have been\nsuggested; yet, we show that they are partial solutions which do not address\nthe issue satisfactorily. To match the implicit assumption, we propose to\ntransform a given dataset such that the transformed clusters have approximately\nthe same density while all regions of locally low density become globally low\ndensity -- homogenising cluster density while preserving the cluster structure\nof the dataset. We show that this can be achieved by using a new\nmulti-dimensional Cumulative Distribution Function in a transform-and-shift\nmethod. The method can be applied to every dataset, before the dataset is used\nin many existing algorithms to match their implicit assumption without\nalgorithmic modification. We show that the proposed method performs better than\nexisting remedies.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 22:32:51 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 08:53:59 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 04:27:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhu", "Ye", ""], ["Ting", "Kai Ming", ""], ["Carman", "Mark", ""], ["Angelova", "Maia", ""]]}, {"id": "1810.02906", "submitter": "Dianbin Bao", "authors": "Dianbin Bao, Kisung You and Lizhen Lin", "title": "Network Distance Based on Laplacian Flows on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance plays a fundamental role in measuring similarity between objects.\nVarious visualization techniques and learning tasks in statistics and machine\nlearning such as shape matching, classification, dimension reduction and\nclustering often rely on some distance or similarity measure. It is of\ntremendous importance to have a distance that can incorporate the underlying\nstructure of the object. In this paper, we focus on proposing such a distance\nbetween network objects. Our key insight is to define a distance based on the\nlong term diffusion behavior of the whole network. We first introduce a dynamic\nsystem on graphs called Laplacian flow. Based on this Laplacian flow, a new\nversion of diffusion distance between networks is proposed. We will demonstrate\nthe utility of the distance and its advantage over various existing distances\nthrough explicit examples. The distance is also applied to subsequent learning\ntasks such as clustering network objects.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 23:15:24 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Bao", "Dianbin", ""], ["You", "Kisung", ""], ["Lin", "Lizhen", ""]]}, {"id": "1810.02909", "submitter": "Patrick Hall", "authors": "Patrick Hall", "title": "On the Art and Science of Machine Learning Explanations", "comments": "This manuscript is a preprint of the text for an invited talk at the\n  2019 KDD XAI workshop. A previous version has also appeared in the\n  proceedings of the Joint Statistical Meetings. Errata and updates available\n  here: https://github.com/jphall663/kdd_2019. Version 2 incorporated reviewer\n  feedback. Version 3 includes a minor adjustment to Figure 1. Version 4\n  corrects a minor typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This text discusses several popular explanatory methods that go beyond the\nerror measurements and plots traditionally used to assess machine learning\nmodels. Some of the explanatory methods are accepted tools of the trade while\nothers are rigorously derived and backed by long-standing theory. The methods,\ndecision tree surrogate models, individual conditional expectation (ICE) plots,\nlocal interpretable model-agnostic explanations (LIME), partial dependence\nplots, and Shapley explanations, vary in terms of scope, fidelity, and suitable\napplication domain. Along with descriptions of these methods, this text\npresents real-world usage recommendations supported by a use case and public,\nin-depth software examples for reproducibility.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 23:29:55 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 16:42:11 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 13:37:37 GMT"}, {"version": "v4", "created": "Sun, 31 May 2020 15:09:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hall", "Patrick", ""]]}, {"id": "1810.02912", "submitter": "Shariq Iqbal", "authors": "Shariq Iqbal, Fei Sha", "title": "Actor-Attention-Critic for Multi-Agent Reinforcement Learning", "comments": "ICML 2019 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in multi-agent scenarios is important for real-world\napplications but presents challenges beyond those seen in single-agent\nsettings. We present an actor-critic algorithm that trains decentralized\npolicies in multi-agent settings, using centrally computed critics that share\nan attention mechanism which selects relevant information for each agent at\nevery timestep. This attention mechanism enables more effective and scalable\nlearning in complex multi-agent environments, when compared to recent\napproaches. Our approach is applicable not only to cooperative settings with\nshared rewards, but also individualized reward settings, including adversarial\nsettings, as well as settings that do not provide global states, and it makes\nno assumptions about the action spaces of the agents. As such, it is flexible\nenough to be applied to most multi-agent learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 23:45:14 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 23:28:13 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Iqbal", "Shariq", ""], ["Sha", "Fei", ""]]}, {"id": "1810.02923", "submitter": "Baihan Lin", "authors": "Baihan Lin, Nikolaus Kriegeskorte", "title": "Adaptive Geo-Topological Independence Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing two potentially multivariate variables for statistical dependence on\nthe basis finite samples is a fundamental statistical challenge. Here we\nexplore a family of tests that adapt to the complexity of the relationship\nbetween the variables, promising robust power across scenarios. Building on the\ndistance correlation, we introduce a family of adaptive independence criteria\nbased on nonlinear monotonic transformations of distances. We show that these\ncriteria, like the distance correlation and RKHS-based criteria, provide\ndependence indicators. We propose a class of adaptive (multi-threshold) test\nstatistics, which form the basis for permutation tests. These tests empirically\noutperform some of the established tests in average and worst-case statistical\nsensitivity across a range of univariate and multivariate relationships, offer\nuseful insights to the data and may deserve further exploration.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 02:12:21 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 08:21:04 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 07:14:42 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 05:18:55 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2020 01:30:58 GMT"}, {"version": "v6", "created": "Thu, 22 Oct 2020 03:44:58 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lin", "Baihan", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1810.02927", "submitter": "Fabio Pardo", "authors": "Fabio Pardo, Vitaly Levdik, Petar Kormushev", "title": "Scaling All-Goals Updates in Reinforcement Learning Using Convolutional\n  Neural Networks", "comments": "AAAI 2020, https://sites.google.com/view/q-map-rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to reach any desired location in the environment can be a valuable\nasset for an agent. Learning a policy to navigate between all pairs of states\nindividually is often not feasible. An all-goals updating algorithm uses each\ntransition to learn Q-values towards all goals simultaneously and off-policy.\nHowever the expensive numerous updates in parallel limited the approach to\nsmall tabular cases so far. To tackle this problem we propose to use\nconvolutional network architectures to generate Q-values and updates for a\nlarge number of goals at once. We demonstrate the accuracy and generalization\nqualities of the proposed method on randomly generated mazes and Sokoban\npuzzles. In the case of on-screen goal coordinates the resulting mapping from\nframes to distance-maps directly informs the agent about which places are\nreachable and in how many steps. As an example of application we show that\nreplacing the random actions in epsilon-greedy exploration by several actions\ntowards feasible goals generates better exploratory trajectories on Montezuma's\nRevenge and Super Mario All-Stars games.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 03:26:43 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 19:54:40 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Pardo", "Fabio", ""], ["Levdik", "Vitaly", ""], ["Kormushev", "Petar", ""]]}, {"id": "1810.02950", "submitter": "Saurabh Agrawal", "authors": "Saurabh Agrawal, Michael Steinbach, Daniel Boley, Snigdhansu\n  Chatterjee, Gowtham Atluri, Anh The Dang, Stefan Liess, Vipin Kumar", "title": "Mining Novel Multivariate Relationships in Time Series Data Using\n  Correlation Networks", "comments": "This is the accepted version of article submitted to IEEE\n  Transactions on Knowledge and Data Engineering 2019", "journal-ref": null, "doi": "10.1109/TKDE.2019.2911681", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains, there is significant interest in capturing novel\nrelationships between time series that represent activities recorded at\ndifferent nodes of a highly complex system. In this paper, we introduce\nmultipoles, a novel class of linear relationships between more than two time\nseries. A multipole is a set of time series that have strong linear dependence\namong themselves, with the requirement that each time series makes a\nsignificant contribution to the linear dependence. We demonstrate that most\ninteresting multipoles can be identified as cliques of negative correlations in\na correlation network. Such cliques are typically rare in a real-world\ncorrelation network, which allows us to find almost all multipoles efficiently\nusing a clique-enumeration approach. Using our proposed framework, we\ndemonstrate the utility of multipoles in discovering new physical phenomena in\ntwo scientific domains: climate science and neuroscience. In particular, we\ndiscovered several multipole relationships that are reproducible in multiple\nother independent datasets and lead to novel domain insights.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 07:46:03 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 08:46:48 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Agrawal", "Saurabh", ""], ["Steinbach", "Michael", ""], ["Boley", "Daniel", ""], ["Chatterjee", "Snigdhansu", ""], ["Atluri", "Gowtham", ""], ["Dang", "Anh The", ""], ["Liess", "Stefan", ""], ["Kumar", "Vipin", ""]]}, {"id": "1810.02966", "submitter": "Abhijit Mahalunkar", "authors": "Abhijit Mahalunkar and John D. Kelleher", "title": "Understanding Recurrent Neural Architectures by Analyzing and\n  Synthesizing Long Distance Dependencies in Benchmark Sequential Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to build efficient deep recurrent neural architectures, it is\nessential to analyze the complexityof long distance dependencies (LDDs) of the\ndataset being modeled. In this paper, we presentdetailed analysis of the\ndependency decay curve exhibited by various datasets. The datasets sampledfrom\na similar process (e.g. natural language, sequential MNIST, Strictlyk-Piecewise\nlanguages,etc) display variations in the properties of the dependency decay\ncurve. Our analysis reveal thefactors resulting in these variations; such as\n(i) number of unique symbols in a dataset, (ii) size ofthe dataset, (iii)\nnumber of interacting symbols within a given LDD, and (iv) the distance\nbetweenthe interacting symbols. We test these factors by generating synthesized\ndatasets of the Strictlyk-Piecewise languages. Another advantage of these\nsynthesized datasets is that they enable targetedtesting of deep recurrent\nneural architectures in terms of their ability to model LDDs with\ndifferentcharacteristics. We also demonstrate that analysing dependency decay\ncurves can inform the selectionof optimal hyper-parameters for SOTA deep\nrecurrent neural architectures. This analysis can directlycontribute to the\ndevelopment of more accurate and efficient sequential models.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 09:09:06 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 00:38:36 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 22:10:34 GMT"}, {"version": "v4", "created": "Tue, 8 Dec 2020 18:37:41 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Mahalunkar", "Abhijit", ""], ["Kelleher", "John D.", ""]]}, {"id": "1810.02976", "submitter": "Nuwan Ferdinand", "authors": "Nuwan Ferdinand and Stark Draper", "title": "Anytime Stochastic Gradient Descent: A Time to Hear from all the Workers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on approaches to parallelizing stochastic gradient\ndescent (SGD) wherein data is farmed out to a set of workers, the results of\nwhich, after a number of updates, are then combined at a central master node.\nAlthough such synchronized SGD approaches parallelize well in idealized\ncomputing environments, they often fail to realize their promised computational\nacceleration in practical settings. One cause is slow workers, termed\nstragglers, who can cause the fusion step at the master node to stall, which\ngreatly slowing convergence. In many straggler mitigation approaches work\ncompleted by these nodes, while only partial, is discarded completely. In this\npaper, we propose an approach to parallelizing synchronous SGD that exploits\nthe work completed by all workers. The central idea is to fix the computation\ntime of each worker and then to combine distinct contributions of all workers.\nWe provide a convergence analysis and optimize the combination function. Our\nnumerical results demonstrate an improvement of several factors of magnitude in\ncomparison to existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 10:44:59 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ferdinand", "Nuwan", ""], ["Draper", "Stark", ""]]}, {"id": "1810.03023", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Bhargav Kanuparthi, Giancarlo Kerg, Nan Rosemary Ke,\n  Ioannis Mitliagkas, Yoshua Bengio", "title": "h-detach: Modifying the LSTM Gradient Towards Better Optimization", "comments": "First two authors contributed equally. Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are known for their notorious exploding and\nvanishing gradient problem (EVGP). This problem becomes more evident in tasks\nwhere the information needed to correctly solve them exist over long time\nscales, because EVGP prevents important gradient components from being\nback-propagated adequately over a large number of steps. We introduce a simple\nstochastic algorithm (\\textit{h}-detach) that is specific to LSTM optimization\nand targeted towards addressing this problem. Specifically, we show that when\nthe LSTM weights are large, the gradient components through the linear path\n(cell state) in the LSTM computational graph get suppressed. Based on the\nhypothesis that these components carry information about long term dependencies\n(which we show empirically), their suppression can prevent LSTMs from capturing\nthem. Our algorithm\\footnote{Our code is available at\nhttps://github.com/bhargav104/h-detach.} prevents gradients flowing through\nthis path from getting suppressed, thus allowing the LSTM to capture such\ndependencies better. We show significant improvements over vanilla LSTM\ngradient based training in terms of convergence speed, robustness to seed and\nlearning rate, and generalization using our modification of LSTM gradient on\nvarious benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 16:55:46 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 17:12:59 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Arpit", "Devansh", ""], ["Kanuparthi", "Bhargav", ""], ["Kerg", "Giancarlo", ""], ["Ke", "Nan Rosemary", ""], ["Mitliagkas", "Ioannis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1810.03024", "submitter": "Ruihao Zhu", "authors": "Wang Chi Cheung and David Simchi-Levi and Ruihao Zhu", "title": "Learning to Optimize under Non-Stationarity", "comments": "This version fixed an error in the proof of Lemma 1 with Assumption 4\n  of arXiv:2103.05750", "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce algorithms that achieve state-of-the-art \\emph{dynamic regret}\nbounds for non-stationary linear stochastic bandit setting. It captures natural\napplications such as dynamic pricing and ads allocation in a changing\nenvironment. We show how the difficulty posed by the non-stationarity can be\novercome by a novel marriage between stochastic and adversarial bandits\nlearning algorithms. Defining $d,B_T,$ and $T$ as the problem dimension, the\n\\emph{variation budget}, and the total time horizon, respectively, our main\ncontributions are the tuned Sliding Window UCB (\\texttt{SW-UCB}) algorithm with\noptimal $\\widetilde{O}(d^{2/3}(B_T+1)^{1/3}T^{2/3})$ dynamic regret, and the\ntuning free bandit-over-bandit (\\texttt{BOB}) framework built on top of the\n\\texttt{SW-UCB} algorithm with best\n$\\widetilde{O}(d^{2/3}(B_T+1)^{1/4}T^{3/4})$ dynamic regret.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:04:14 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 15:40:52 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 06:13:38 GMT"}, {"version": "v4", "created": "Mon, 17 Dec 2018 02:10:34 GMT"}, {"version": "v5", "created": "Sun, 3 Mar 2019 02:16:14 GMT"}, {"version": "v6", "created": "Sat, 17 Jul 2021 17:19:12 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Cheung", "Wang Chi", ""], ["Simchi-Levi", "David", ""], ["Zhu", "Ruihao", ""]]}, {"id": "1810.03025", "submitter": "Peter Schulam", "authors": "Peter Schulam and Suchi Saria", "title": "Discretizing Logged Interaction Data Biases Learning for Decision-Making", "comments": "This is a standalone short paper describing a new type of bias that\n  can arise when learning from time series data for sequential decision-making\n  problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data that are not measured at regular intervals are commonly\ndiscretized as a preprocessing step. For example, data about customer arrival\ntimes might be simplified by summing the number of arrivals within hourly\nintervals, which produces a discrete-time time series that is easier to model.\nIn this abstract, we show that discretization introduces a bias that affects\nmodels trained for decision-making. We refer to this phenomenon as\ndiscretization bias, and show that we can avoid it by using continuous-time\nmodels instead.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:08:47 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Schulam", "Peter", ""], ["Saria", "Suchi", ""]]}, {"id": "1810.03032", "submitter": "Maxim Panov", "authors": "Stanislav Tsepa and Maxim Panov", "title": "Constructing Graph Node Embeddings via Discrimination of Similarity\n  Distributions", "comments": null, "journal-ref": "In 2018 IEEE International Conference on Data Mining Workshops\n  (ICDMW), pp. 1050-1053", "doi": "10.1109/ICDMW.2018.00152", "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of unsupervised learning node embeddings in graphs is one of the\nimportant directions in modern network science. In this work we propose a novel\nframework, which is aimed to find embeddings by \\textit{discriminating\ndistributions of similarities (DDoS)} between nodes in the graph. The general\nidea is implemented by maximizing the \\textit{earth mover distance} between\ndistributions of decoded similarities of similar and dissimilar nodes. The\nresulting algorithm generates embeddings which give a state-of-the-art\nperformance in the problem of link prediction in real-world graphs.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:55:26 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tsepa", "Stanislav", ""], ["Panov", "Maxim", ""]]}, {"id": "1810.03037", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Amir Globerson", "title": "Why do Larger Models Generalize Better? A Theoretical Perspective via\n  the XOR Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical evidence suggests that neural networks with ReLU activations\ngeneralize better with over-parameterization. However, there is currently no\ntheoretical analysis that explains this observation. In this work, we provide\ntheoretical and empirical evidence that, in certain cases, overparameterized\nconvolutional networks generalize better than small networks because of an\ninterplay between weight clustering and feature exploration at initialization.\nWe demonstrate this theoretically for a 3-layer convolutional neural network\nwith max-pooling, in a novel setting which extends the XOR problem. We show\nthat this interplay implies that with overparamterization, gradient descent\nconverges to global minima with better generalization performance compared to\nglobal minima of small networks. Empirically, we demonstrate these phenomena\nfor a 3-layer convolutional neural network in the MNIST task.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 18:44:51 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 14:21:01 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Brutzkus", "Alon", ""], ["Globerson", "Amir", ""]]}, {"id": "1810.03044", "submitter": "Casey Bennett", "authors": "Casey C. Bennett", "title": "Artificial Intelligence for Diabetes Case Management: The Intersection\n  of Physical and Mental Health", "comments": "arXiv admin note: This version has been removed by arXiv\n  administrators due to copyright infringement", "journal-ref": "Informatics in Medicine Unlocked, 2019", "doi": "10.1016/j.imu.2019.100191", "report-no": null, "categories": "q-bio.QM cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetes is a major public health problem in the United States, affecting\nroughly 30 million people. Diabetes complications, along with the mental health\ncomorbidities that often co-occur with them, are major drivers of high\nhealthcare costs, poor outcomes, and reduced treatment adherence in diabetes.\nHere, we evaluate in a large state-wide population whether we can use\nartificial intelligence (AI) techniques to identify clusters of patient\ntrajectories within the broader diabetes population in order to create\ncost-effective, narrowly-focused case management intervention strategies to\nreduce development of complications. This approach combined data from: 1)\nclaims, 2) case management notes, and 3) social determinants of health from\n~300,000 real patients between 2014 and 2016. We categorized complications as\nfive types: Cardiovascular, Neuropathy, Opthalmic, Renal, and Other. Modeling\nwas performed combining a variety of machine learning algorithms, including\nsupervised classification, unsupervised clustering, natural language processing\nof unstructured care notes, and feature engineering. The results showed that we\ncan predict development of diabetes complications roughly 83.5% of the time\nusing claims data or social determinants of health data. They also showed we\ncan reveal meaningful clusters in the patient population related to\ncomplications and mental health that can be used to cost-effective screening\nprogram, reducing the number of patients to be screened down by 85%. This study\noutlines creation of an AI framework to develop protocols to better address\nmental health comorbidities that lead to complications development in the\ndiabetes population. Future work is described that outlines potential lines of\nresearch and the need for better addressing the 'people side' of the equation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 19:59:56 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 19:12:44 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 18:59:06 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Bennett", "Casey C.", ""]]}, {"id": "1810.03048", "submitter": "Gilwoo Lee", "authors": "Gilwoo Lee, Sanjiban Choudhury, Brian Hou, Siddhartha S. Srinivasa", "title": "Bayes-CPACE: PAC Optimal Exploration in Continuous Space Bayes-Adaptive\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first PAC optimal algorithm for Bayes-Adaptive Markov Decision\nProcesses (BAMDPs) in continuous state and action spaces, to the best of our\nknowledge. The BAMDP framework elegantly addresses model uncertainty by\nincorporating Bayesian belief updates into long-term expected return. However,\ncomputing an exact optimal Bayesian policy is intractable. Our key insight is\nto compute a near-optimal value function by covering the continuous\nstate-belief-action space with a finite set of representative samples and\nexploiting the Lipschitz continuity of the value function. We prove the\nnear-optimality of our algorithm and analyze a number of schemes that boost the\nalgorithm's efficiency. Finally, we empirically validate our approach on a\nnumber of discrete and continuous BAMDPs and show that the learned policy has\nconsistently competitive performance against baseline approaches.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:37:38 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Lee", "Gilwoo", ""], ["Choudhury", "Sanjiban", ""], ["Hou", "Brian", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "1810.03051", "submitter": "Praneeth Narayanamurthy", "authors": "Praneeth Narayanamurthy and Vahid Daneshpajooh and Namrata Vaswani", "title": "Provable Subspace Tracking from Missing Data and Matrix Completion", "comments": "Writing changes; includes a detailed discussion of noise analysis;\n  contains discussion for Matrix Completion; Accepted to IEEE Transactions on\n  Signal Processing", "journal-ref": "IEEE Transactions on Signal Processing (Volume: 67 , Issue: 16 ,\n  Aug, 15 2019)", "doi": "10.1109/TSP.2019.2924595", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of subspace tracking in the presence of missing data\n(ST-miss). In recent work, we studied a related problem called robust ST. In\nthis work, we show that a simple modification of our robust ST solution also\nprovably solves ST-miss and robust ST-miss. To our knowledge, our result is the\nfirst `complete' guarantee for ST-miss. This means that we can prove that under\nassumptions on only the algorithm inputs, the output subspace estimates are\nclose to the true data subspaces at all times. Our guarantees hold under mild\nand easily interpretable assumptions, and allow the underlying subspace to\nchange with time in a piecewise constant fashion. In contrast, all existing\nguarantees for ST are partial results and assume a fixed unknown subspace.\nExtensive numerical experiments are shown to back up our theoretical claims.\nFinally, our solution can be interpreted as a provably correct mini-batch and\nmemory-efficient solution to low-rank Matrix Completion (MC).\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:54:25 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 04:49:34 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Narayanamurthy", "Praneeth", ""], ["Daneshpajooh", "Vahid", ""], ["Vaswani", "Namrata", ""]]}, {"id": "1810.03052", "submitter": "Kenneth Blomqvist", "authors": "Kenneth Blomqvist, Samuel Kaski, Markus Heinonen", "title": "Deep convolutional Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose deep convolutional Gaussian processes, a deep Gaussian process\narchitecture with convolutional structure. The model is a principled Bayesian\nframework for detecting hierarchical combinations of local features for image\nclassification. We demonstrate greatly improved image classification\nperformance compared to current Gaussian process approaches on the MNIST and\nCIFAR-10 datasets. In particular, we improve CIFAR-10 accuracy by over 10\npercentage points.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:58:05 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Blomqvist", "Kenneth", ""], ["Kaski", "Samuel", ""], ["Heinonen", "Markus", ""]]}, {"id": "1810.03064", "submitter": "Fei Wang", "authors": "Fei Wang, Jinsong Han, Shiyuan Zhang, Xu He, Dong Huang", "title": "CSI-Net: Unified Human Body Characterization and Pose Recognition", "comments": "14 pages, 6 figures and 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build CSI-Net, a unified Deep Neural Network~(DNN), to learn the\nrepresentation of WiFi signals. Using CSI-Net, we jointly solved two body\ncharacterization problems: biometrics estimation (including body fat, muscle,\nwater, and bone rates) and person recognition. We also demonstrated the\napplication of CSI-Net on two distinctive pose recognition tasks: the hand sign\nrecognition (fine-scaled action of the hand) and falling detection\n(coarse-scaled motion of the body).\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 00:51:14 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 18:10:23 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Wang", "Fei", ""], ["Han", "Jinsong", ""], ["Zhang", "Shiyuan", ""], ["He", "Xu", ""], ["Huang", "Dong", ""]]}, {"id": "1810.03068", "submitter": "Matthew Hirn", "authors": "Feng Gao and Guy Wolf and Matthew Hirn", "title": "Geometric Scattering for Graph Data Analysis", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:2122-2131, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the generalization of scattering transforms from traditional\n(e.g., image or audio) signals to graph data, analogous to the generalization\nof ConvNets in geometric deep learning, and the utility of extracted graph\nfeatures in graph data analysis. In particular, we focus on the capacity of\nthese features to retain informative variability and relations in the data\n(e.g., between individual graphs, or in aggregate), while relating our\nconstruction to previous theoretical results that establish the stability of\nsimilar transforms to families of graph deformations. We demonstrate the\napplication the our geometric scattering features in graph classification of\nsocial network data, and in data exploration of biochemistry data.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 01:52:15 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 00:19:05 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Gao", "Feng", ""], ["Wolf", "Guy", ""], ["Hirn", "Matthew", ""]]}, {"id": "1810.03078", "submitter": "Yu-Zhen Janice Chen", "authors": "Xutong Liu, Yu-Zhen Janice Chen, John C.S. Lui, Konstantin Avrachenkov", "title": "Graphlet Count Estimation via Convolutional Neural Networks", "comments": "Extended Abstract Accepted by Complex Networks 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphlets are defined as k-node connected induced subgraph patterns. For an\nundirected graph, 3-node graphlets include close triangle and open triangle.\nWhen k = 4, there are six types of graphlets, e.g., tailed-triangle and clique\nare two possible 4-node graphlets. The number of each graphlet, called graphlet\ncount, is a signature which characterizes the local network structure of a\ngiven graph. Graphlet count plays a prominent role in network analysis of many\nfields, most notably bioinformatics and social science.\n  However, computing exact graphlet count is inherently difficult and\ncomputational expensive because the number of graphlets grows exponentially\nlarge as the graph size and/or graphlet size k grow. To deal with this\ndifficulty, many sampling methods were proposed to estimate graphlet count with\nbounded error. Nevertheless, these methods require large number of samples to\nbe statistically reliable, which is still computationally demanding. Moreover,\nthey have to repeat laborious counting procedure even if a new graph is similar\nor exactly the same as previous studied graphs.\n  Intuitively, learning from historic graphs can make estimation more accurate\nand avoid many repetitive counting to reduce computational cost. Based on this\nidea, we propose a convolutional neural network (CNN) framework and two\npreprocessing techniques to estimate graphlet count. Extensive experiments on\ntwo types of random graphs and real world biochemistry graphs show that our\nframework can offer substantial speedup on estimating graphlet count of new\ngraphs with high accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 03:31:10 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Xutong", ""], ["Chen", "Yu-Zhen Janice", ""], ["Lui", "John C. S.", ""], ["Avrachenkov", "Konstantin", ""]]}, {"id": "1810.03105", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Licheng Jiao, Kaiwen Zhou, James Cheng, Yan Ren, Yufei\n  Jin", "title": "ASVRG: Accelerated Proximal SVRG", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an accelerated proximal stochastic variance reduced\ngradient (ASVRG) method, in which we design a simple and effective momentum\nacceleration trick. Unlike most existing accelerated stochastic variance\nreduction methods such as Katyusha, ASVRG has only one additional variable and\none momentum parameter. Thus, ASVRG is much simpler than those methods, and has\nmuch lower per-iteration complexity. We prove that ASVRG achieves the best\nknown oracle complexities for both strongly convex and non-strongly convex\nobjectives. In addition, we extend ASVRG to mini-batch and non-smooth settings.\nWe also empirically verify our theoretical results and show that the\nperformance of ASVRG is comparable with, and sometimes even better than that of\nthe state-of-the-art stochastic methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 08:43:05 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 17:38:34 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Shang", "Fanhua", ""], ["Jiao", "Licheng", ""], ["Zhou", "Kaiwen", ""], ["Cheng", "James", ""], ["Ren", "Yan", ""], ["Jin", "Yufei", ""]]}, {"id": "1810.03115", "submitter": "Alexandre Quemy", "authors": "Alexandre Quemy", "title": "European Court of Human Right Open Data project", "comments": "Preprint submitted to Data Mining and Knowledge Discovery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents thirteen datasets for binary, multiclass and multilabel\nclassification based on the European Court of Human Rights judgments since its\ncreation. The interest of such datasets is explained through the prism of the\nresearcher, the data scientist, the citizen and the legal practitioner.\nContrarily to many datasets, the creation process, from the collection of raw\ndata to the feature transformation, is provided under the form of a collection\nof fully automated and open-source scripts. It ensures reproducibility and a\nhigh level of confidence in the processed data, which is some of the most\nimportant issues in data governance nowadays. A first experimental campaign is\nperformed to study some predictability properties and to establish baseline\nresults on popular machine learning algorithms. The results are consistently\ngood across the binary datasets with an accuracy comprised between 75.86% and\n98.32% for an average accuracy of 96.45%.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 09:36:27 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 16:09:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Quemy", "Alexandre", ""]]}, {"id": "1810.03124", "submitter": "Jingchang Liu", "authors": "Jingchang Liu and Linli Xu", "title": "Accelerating Stochastic Gradient Descent Using Antithetic Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Mini-batch) Stochastic Gradient Descent is a popular optimization method\nwhich has been applied to many machine learning applications. But a rather high\nvariance introduced by the stochastic gradient in each step may slow down the\nconvergence. In this paper, we propose the antithetic sampling strategy to\nreduce the variance by taking advantage of the internal structure in dataset.\nUnder this new strategy, stochastic gradients in a mini-batch are no longer\nindependent but negatively correlated as much as possible, while the mini-batch\nstochastic gradient is still an unbiased estimator of full gradient. For the\nbinary classification problems, we just need to calculate the antithetic\nsamples in advance, and reuse the result in each iteration, which is practical.\nExperiments are provided to confirm the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 11:42:10 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Jingchang", ""], ["Xu", "Linli", ""]]}, {"id": "1810.03145", "submitter": "Ruohan Wang", "authors": "Ruohan Wang and Pierluigi V. Amadori and Yiannis Demiris", "title": "Real-Time Workload Classification during Driving using HyperNetworks", "comments": "2018 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying human cognitive states from behavioral and physiological signals\nis a challenging problem with important applications in robotics. The problem\nis challenging due to the data variability among individual users, and sensor\nartefacts. In this work, we propose an end-to-end framework for real-time\ncognitive workload classification with mixture Hyper Long Short Term Memory\nNetworks, a novel variant of HyperNetworks. Evaluating the proposed approach on\nan eye-gaze pattern dataset collected from simulated driving scenarios of\ndifferent cognitive demands, we show that the proposed framework outperforms\nprevious baseline methods and achieves 83.9\\% precision and 87.8\\% recall\nduring test. We also demonstrate the merit of our proposed architecture by\nshowing improved performance over other LSTM-based methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 13:57:25 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Wang", "Ruohan", ""], ["Amadori", "Pierluigi V.", ""], ["Demiris", "Yiannis", ""]]}, {"id": "1810.03198", "submitter": "Jitin Kapila", "authors": "Kumarjit Pathak, Jitin Kapila", "title": "Reinforcement Evolutionary Learning Method for self-learning", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In statistical modelling the biggest threat is concept drift which makes the\nmodel gradually showing deteriorating performance over time. There are state of\nthe art methodologies to detect the impact of concept drift, however general\nstrategy considered to overcome the issue in performance is to rebuild or\nre-calibrate the model periodically as the variable patterns for the model\nchanges significantly due to market change or consumer behavior change etc.\nQuantitative research is the most widely spread application of data science in\nMarketing or financial domain where applicability of state of the art\nreinforcement learning for auto-learning is less explored paradigm.\nReinforcement learning is heavily dependent on having a simulated environment\nwhich is majorly available for gaming or online systems, to learn from the live\nfeedback. However, there are some research happened on the area of online\nadvertisement, pricing etc where due to the nature of the online learning\nenvironment scope of reinforcement learning is explored. Our proposed solution\nis a reinforcement learning based, true self-learning algorithm which can adapt\nto the data change or concept drift and auto learn and self-calibrate for the\nnew patterns of the data solving the problem of concept drift.\n  Keywords - Reinforcement learning, Genetic Algorithm, Q-learning,\nClassification modelling, CMA-ES, NES, Multi objective optimization, Concept\ndrift, Population stability index, Incremental learning, F1-measure, Predictive\nModelling, Self-learning, MCTS, AlphaGo, AlphaZero\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 19:25:48 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Pathak", "Kumarjit", ""], ["Kapila", "Jitin", ""]]}, {"id": "1810.03218", "submitter": "Gonzalo Mu\\~noz", "authors": "Daniel Bienstock, Gonzalo Mu\\~noz, Sebastian Pokutta", "title": "Principled Deep Neural Network Training through Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has received significant attention due to its impressive\nperformance in many state-of-the-art learning tasks. Unfortunately, while very\npowerful, Deep Learning is not well understood theoretically and in particular\nonly recently results for the complexity of training deep neural networks have\nbeen obtained. In this work we show that large classes of deep neural networks\nwith various architectures (e.g., DNNs, CNNs, Binary Neural Networks, and\nResNets), activation functions (e.g., ReLUs and leaky ReLUs), and loss\nfunctions (e.g., Hinge loss, Euclidean loss, etc) can be trained to near\noptimality with desired target accuracy using linear programming in time that\nis exponential in the input data and parameter space dimension and polynomial\nin the size of the data set; improvements of the dependence in the input\ndimension are known to be unlikely assuming $P\\neq NP$, and improving the\ndependence on the parameter space dimension remains open. In particular, we\nobtain polynomial time algorithms for training for a given fixed network\narchitecture. Our work applies more broadly to empirical risk minimization\nproblems which allows us to generalize various previous results and obtain new\ncomplexity results for previously unstudied architectures in the proper\nlearning setting.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 22:15:07 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 21:07:59 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Bienstock", "Daniel", ""], ["Mu\u00f1oz", "Gonzalo", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "1810.03222", "submitter": "Ashkan Esmaeili", "authors": "Ashkan Esmaeili, Kayhan Behdin, Sina Al-E-Mohammad, Farokh Marvasti", "title": "Recovering Quantized Data with Missing Information Using Bilinear\n  Factorization and Augmented Lagrangian Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach in order to recover a quantized\nmatrix with missing information. We propose a regularized convex cost function\ncomposed of a log-likelihood term and a Trace norm term. The Bi-factorization\napproach and the Augmented Lagrangian Method (ALM) are applied to find the\nglobal minimizer of the cost function in order to recover the genuine data. We\nprovide mathematical convergence analysis for our proposed algorithm. In the\nNumerical Experiments Section, we show the superiority of our method in\naccuracy and also its robustness in computational complexity compared to the\nstate-of-the-art literature methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 23:06:52 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Esmaeili", "Ashkan", ""], ["Behdin", "Kayhan", ""], ["Al-E-Mohammad", "Sina", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1810.03256", "submitter": "Kayhan Batmanghelich", "authors": "Hadi Salman and Payman Yadollahpour and Tom Fletcher and Kayhan\n  Batmanghelich", "title": "Deep Diffeomorphic Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Normalizing Flow (NF) models a general probability density by estimating\nan invertible transformation applied on samples drawn from a known\ndistribution. We introduce a new type of NF, called Deep Diffeomorphic\nNormalizing Flow (DDNF). A diffeomorphic flow is an invertible function where\nboth the function and its inverse are smooth. We construct the flow using an\nordinary differential equation (ODE) governed by a time-varying smooth vector\nfield. We use a neural network to parametrize the smooth vector field and a\nrecursive neural network (RNN) for approximating the solution of the ODE. Each\ncell in the RNN is a residual network implementing one Euler integration step.\nThe architecture of our flow enables efficient likelihood evaluation,\nstraightforward flow inversion, and results in highly flexible density\nestimation. An end-to-end trained DDNF achieves competitive results with\nstate-of-the-art methods on a suite of density estimation and variational\ninference tasks. Finally, our method brings concepts from Riemannian geometry\nthat, we believe, can open a new research direction for neural density\nestimation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 03:09:41 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 22:33:39 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Salman", "Hadi", ""], ["Yadollahpour", "Payman", ""], ["Fletcher", "Tom", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1810.03264", "submitter": "Wei Dai", "authors": "Wei Dai, Yi Zhou, Nanqing Dong, Hao Zhang, Eric P. Xing", "title": "Toward Understanding the Impact of Staleness in Distributed Machine\n  Learning", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many distributed machine learning (ML) systems adopt the non-synchronous\nexecution in order to alleviate the network communication bottleneck, resulting\nin stale parameters that do not reflect the latest updates. Despite much\ndevelopment in large-scale ML, the effects of staleness on learning are\ninconclusive as it is challenging to directly monitor or control staleness in\ncomplex distributed environments. In this work, we study the convergence\nbehaviors of a wide array of ML models and algorithms under delayed updates.\nOur extensive experiments reveal the rich diversity of the effects of staleness\non the convergence of ML algorithms and offer insights into seemingly\ncontradictory reports in the literature. The empirical findings also inspire a\nnew convergence analysis of stochastic gradient descent in non-convex\noptimization under staleness, matching the best-known convergence rate of\nO(1/\\sqrt{T}).\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 03:57:39 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Dai", "Wei", ""], ["Zhou", "Yi", ""], ["Dong", "Nanqing", ""], ["Zhang", "Hao", ""], ["Xing", "Eric P.", ""]]}, {"id": "1810.03278", "submitter": "Aerin Kim", "authors": "Rohit Pandey, Yifan Chang, Cameron White, Gaurav Jagtiani, Aerin Young\n  Kim, Gil Lapid Shafriri, Sathya Singh", "title": "Optimizing Waiting Thresholds Within A State Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Azure (the cloud service provided by Microsoft) is composed of physical\ncomputing units which are called nodes. These nodes are controlled by a\nsoftware component called Fabric Controller (FC), which can consider the nodes\nto be in one of many different states such as Ready, Unhealthy, Booting, etc.\nSome of these states correspond to a node being unresponsive to FCs requests.\nWhen a node goes unresponsive for more than a set threshold, FC intervenes and\nreboots the node. We minimized the downtime caused by the intervention\nthreshold when a node switches to the Unhealthy state by fitting various\nheavy-tail probability distributions. We consider using features of the node to\ncustomize the organic recovery model to the individual nodes that go unhealthy.\nThis regression approach allows us to use information about the node like\nhardware, software versions, historical performance indicators, etc. to inform\nthe organic recovery model and hence the optimal threshold. In another\ndirection, we consider generalizing this to an arbitrary number of thresholds\nwithin the node state machine (or Markov chain). When the states become\nintertwined in ways that different thresholds start affecting each other, we\ncan't simply optimize each of them in isolation. For best results, we must\nconsider this as an optimization problem in many variables (the number of\nthresholds). We no longer have a nice closed form solution for this more\ncomplex problem like we did with one threshold, but we can still use numerical\ntechniques (gradient descent) to solve it.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 06:25:38 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Pandey", "Rohit", ""], ["Chang", "Yifan", ""], ["White", "Cameron", ""], ["Jagtiani", "Gaurav", ""], ["Kim", "Aerin Young", ""], ["Shafriri", "Gil Lapid", ""], ["Singh", "Sathya", ""]]}, {"id": "1810.03292", "submitter": "Julius Adebayo", "authors": "Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz\n  Hardt, Been Kim", "title": "Sanity Checks for Saliency Maps", "comments": "Updating Guided Backprop experiments due to bug. The results and\n  conclusions remain the same", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency methods have emerged as a popular tool to highlight features in an\ninput deemed relevant for the prediction of a learned model. Several saliency\nmethods have been proposed, often guided by visual appeal on image data. In\nthis work, we propose an actionable methodology to evaluate what kinds of\nexplanations a given method can and cannot provide. We find that reliance,\nsolely, on visual assessment can be misleading. Through extensive experiments\nwe show that some existing saliency methods are independent both of the model\nand of the data generating process. Consequently, methods that fail the\nproposed tests are inadequate for tasks that are sensitive to either data or\nmodel, such as, finding outliers in the data, explaining the relationship\nbetween inputs and outputs that the model learned, and debugging the model. We\ninterpret our findings through an analogy with edge detection in images, a\ntechnique that requires neither training data nor model. Theory in the case of\na linear model and a single-layer convolutional neural network supports our\nexperimental findings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 07:27:11 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 03:39:34 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 13:40:14 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Adebayo", "Julius", ""], ["Gilmer", "Justin", ""], ["Muelly", "Michael", ""], ["Goodfellow", "Ian", ""], ["Hardt", "Moritz", ""], ["Kim", "Been", ""]]}, {"id": "1810.03307", "submitter": "Julius Adebayo", "authors": "Julius Adebayo, Justin Gilmer, Ian Goodfellow, Been Kim", "title": "Local Explanation Methods for Deep Neural Networks Lack Sensitivity to\n  Parameter Values", "comments": "Workshop Track International Conference on Learning Representations\n  (ICLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining the output of a complicated machine learning model like a deep\nneural network (DNN) is a central challenge in machine learning. Several\nproposed local explanation methods address this issue by identifying what\ndimensions of a single input are most responsible for a DNN's output. The goal\nof this work is to assess the sensitivity of local explanations to DNN\nparameter values. Somewhat surprisingly, we find that DNNs with\nrandomly-initialized weights produce explanations that are both visually and\nquantitatively similar to those produced by DNNs with learned weights. Our\nconjecture is that this phenomenon occurs because these explanations are\ndominated by the lower level features of a DNN, and that a DNN's architecture\nprovides a strong prior which significantly affects the representations learned\nat these lower layers. NOTE: This work is now subsumed by our recent\nmanuscript, Sanity Checks for Saliency Maps (to appear NIPS 2018), where we\nexpand on findings and address concerns raised in Sundararajan et. al. (2018).\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 08:18:14 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Adebayo", "Julius", ""], ["Gilmer", "Justin", ""], ["Goodfellow", "Ian", ""], ["Kim", "Been", ""]]}, {"id": "1810.03370", "submitter": "Thiago Serra", "authors": "Thiago Serra, Srikumar Ramalingam", "title": "Empirical Bounds on Linear Regions of Deep Rectifier Networks", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can compare the expressiveness of neural networks that use rectified\nlinear units (ReLUs) by the number of linear regions, which reflect the number\nof pieces of the piecewise linear functions modeled by such networks. However,\nenumerating these regions is prohibitive and the known analytical bounds are\nidentical for networks with same dimensions. In this work, we approximate the\nnumber of linear regions through empirical bounds based on features of the\ntrained network and probabilistic inference. Our first contribution is a method\nto sample the activation patterns defined by ReLUs using universal hash\nfunctions. This method is based on a Mixed-Integer Linear Programming (MILP)\nformulation of the network and an algorithm for probabilistic lower bounds of\nMILP solution sets that we call MIPBound, which is considerably faster than\nexact counting and reaches values in similar orders of magnitude. Our second\ncontribution is a tighter activation-based bound for the maximum number of\nlinear regions, which is particularly stronger in networks with narrow layers.\nCombined, these bounds yield a fast proxy for the number of linear regions of a\ndeep neural network.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:06:50 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:42:04 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 11:34:01 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Serra", "Thiago", ""], ["Ramalingam", "Srikumar", ""]]}, {"id": "1810.03372", "submitter": "Edo Collins", "authors": "Edo Collins, Siavash Arjomand Bigdeli, Sabine S\\\"usstrunk", "title": "Detecting Memorization in ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new notion of `non-linearity' of a network layer with respect to\nan input batch that is based on its proximity to a linear system, which is\nreflected in the non-negative rank of the activation matrix. We measure this\nnon-linearity by applying non-negative factorization to the activation matrix.\nConsidering batches of similar samples, we find that high non-linearity in deep\nlayers is indicative of memorization. Furthermore, by applying our approach\nlayer-by-layer, we find that the mechanism for memorization consists of\ndistinct phases. We perform experiments on fully-connected and convolutional\nneural networks trained on several image and audio datasets. Our results\ndemonstrate that as an indicator for memorization, our technique can be used to\nperform early stopping.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:11:54 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Collins", "Edo", ""], ["Bigdeli", "Siavash Arjomand", ""], ["S\u00fcsstrunk", "Sabine", ""]]}, {"id": "1810.03382", "submitter": "Declan O'Regan", "authors": "Ghalib A. Bello, Timothy J.W. Dawes, Jinming Duan, Carlo Biffi,\n  Antonio de Marvao, Luke S.G.E. Howard, J. Simon R. Gibbs, Martin R. Wilkins,\n  Stuart A. Cook, Daniel Rueckert, and Declan P. O'Regan", "title": "Deep learning cardiac motion analysis for human survival prediction", "comments": null, "journal-ref": "Nature Machine Intelligence, 1, 95-104 (2019)", "doi": "10.1038/s42256-019-0019-2", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motion analysis is used in computer vision to understand the behaviour of\nmoving objects in sequences of images. Optimising the interpretation of dynamic\nbiological systems requires accurate and precise motion tracking as well as\nefficient representations of high-dimensional motion trajectories so that these\ncan be used for prediction tasks. Here we use image sequences of the heart,\nacquired using cardiac magnetic resonance imaging, to create time-resolved\nthree-dimensional segmentations using a fully convolutional network trained on\nanatomical shape priors. This dense motion model formed the input to a\nsupervised denoising autoencoder (4Dsurvival), which is a hybrid network\nconsisting of an autoencoder that learns a task-specific latent code\nrepresentation trained on observed outcome data, yielding a latent\nrepresentation optimised for survival prediction. To handle right-censored\nsurvival outcomes, our network used a Cox partial likelihood loss function. In\na study of 302 patients the predictive accuracy (quantified by Harrell's\nC-index) was significantly higher (p < .0001) for our model C=0.73 (95$\\%$ CI:\n0.68 - 0.78) than the human benchmark of C=0.59 (95$\\%$ CI: 0.53 - 0.65). This\nwork demonstrates how a complex computer vision task using high-dimensional\nmedical image data can efficiently predict human survival.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 11:34:38 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Bello", "Ghalib A.", ""], ["Dawes", "Timothy J. W.", ""], ["Duan", "Jinming", ""], ["Biffi", "Carlo", ""], ["de Marvao", "Antonio", ""], ["Howard", "Luke S. G. E.", ""], ["Gibbs", "J. Simon R.", ""], ["Wilkins", "Martin R.", ""], ["Cook", "Stuart A.", ""], ["Rueckert", "Daniel", ""], ["O'Regan", "Declan P.", ""]]}, {"id": "1810.03389", "submitter": "Yuan Yao", "authors": "Weizhi Zhu, Yifei Huang, Yuan Yao", "title": "Rethinking Breiman's Dilemma in Neural Networks: Phase Transitions of\n  Margin Dynamics", "comments": "36 pages", "journal-ref": "Front. Appl. Math. Stat., 30 October 2020", "doi": "10.3389/fams.2020.575073", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Margin enlargement over training data has been an important strategy since\nperceptrons in machine learning for the purpose of boosting the robustness of\nclassifiers toward a good generalization ability. Yet Breiman (1999) showed a\ndilemma that a uniform improvement on margin distribution does NOT necessarily\nreduces generalization errors. In this paper, we revisit Breiman's dilemma in\ndeep neural networks with recently proposed spectrally normalized margins, from\na novel perspective based on phase transitions of normalized margin\ndistributions in training dynamics. Normalized margin distribution of a\nclassifier over the data, can be divided into two parts: low/small margins such\nas some negative margins for misclassified samples vs. high/large margins for\nhigh confident correctly classified samples, that often behave differently\nduring the training process. Low margins for training and test datasets are\noften effectively reduced in training, along with reductions of training and\ntest errors; while high margins may exhibit different dynamics, reflecting the\ntrade-off between expressive power of models and complexity of data. When data\ncomplexity is comparable to the model expressiveness, high margin distributions\nfor both training and test data undergo similar decrease-increase phase\ntransitions during training. In such cases, one can predict the trend of\ngeneralization or test error by margin-based generalization bounds with\nrestricted Rademacher complexities, shown in two ways in this paper with early\nstopping time exploiting such phase transitions. On the other hand,\nover-expressive models may have both low and high training margins undergoing\nuniform improvements, with a distinct phase transition in test margin dynamics.\nThis reconfirms the Breiman's dilemma associated with overparameterized neural\nnetworks where margins fail to predict overfitting.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:04:39 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 13:50:52 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 14:42:39 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhu", "Weizhi", ""], ["Huang", "Yifei", ""], ["Yao", "Yuan", ""]]}, {"id": "1810.03393", "submitter": "Ye Zhu PhD", "authors": "Ye Zhu, Kai Ming Ting, Yuan Jin, Maia Angelova", "title": "Hierarchical clustering that takes advantage of both density-peak and\n  density-connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on density-based clustering, particularly the Density Peak\n(DP) algorithm and the one based on density-connectivity DBSCAN; and proposes a\nnew method which takes advantage of the individual strengths of these two\nmethods to yield a density-based hierarchical clustering algorithm. Our\ninvestigation begins with formally defining the types of clusters DP and DBSCAN\nare designed to detect; and then identifies the kinds of distributions that DP\nand DBSCAN individually fail to detect all clusters in a dataset. These\nidentified weaknesses inspire us to formally define a new kind of clusters and\npropose a new method called DC-HDP to overcome these weaknesses to identify\nclusters with arbitrary shapes and varied densities. In addition, the new\nmethod produces a richer clustering result in terms of hierarchy or dendrogram\nfor better cluster structures understanding. Our empirical evaluation results\nshow that DC-HDP produces the best clustering results on 14 datasets in\ncomparison with 7 state-of-the-art clustering algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:12:42 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Zhu", "Ye", ""], ["Ting", "Kai Ming", ""], ["Jin", "Yuan", ""], ["Angelova", "Maia", ""]]}, {"id": "1810.03417", "submitter": "Arda Aytekin", "authors": "Arda Aytekin and Martin Biel and Mikael Johansson", "title": "POLO: a POLicy-based Optimization library", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present POLO --- a C++ library for large-scale parallel optimization\nresearch that emphasizes ease-of-use, flexibility and efficiency in algorithm\ndesign. It uses multiple inheritance and template programming to decompose\nalgorithms into essential policies and facilitate code reuse. With its clear\nseparation between algorithm and execution policies, it provides researchers\nwith a simple and powerful platform for prototyping ideas, evaluating them on\ndifferent parallel computing architectures and hardware platforms, and\ngenerating compact and efficient production code. A C-API is included for\ncustomization and data loading in high-level languages. POLO enables users to\nmove seamlessly from serial to multi-threaded shared-memory and multi-node\ndistributed-memory executors. We demonstrate how POLO allows users to implement\nstate-of-the-art asynchronous parallel optimization algorithms in just a few\nlines of code and report experiment results from shared and distributed-memory\ncomputing architectures. We provide both POLO and POLO.jl, a wrapper around\nPOLO written in the Julia language, at https://github.com/pologrp under the\npermissive MIT license.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 12:58:26 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Aytekin", "Arda", ""], ["Biel", "Martin", ""], ["Johansson", "Mikael", ""]]}, {"id": "1810.03419", "submitter": "Jitin Kapila", "authors": "Kumarjit Pathak, Jitin Kapila", "title": "Unique Metric for Health Analysis with Optimization of Clustering\n  Activity and Cross Comparison of Results from Different Approach", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In machine learning and data mining, Cluster analysis is one of the most\nwidely used unsupervised learning technique. Philosophy of this algorithm is to\nfind similar data items and group them together based on any distance function\nin multidimensional space. These methods are suitable for finding groups of\ndata that behave in a coherent fashion. The perspective may vary for clustering\ni.e. the way we want to find similarity, some methods are based on distance\nsuch as K-Means technique and some are probability based, like GMM.\nUnderstanding prominent segment of data is always challenging as multidimension\nspace does not allow us to have a look and feel of the distance or any visual\ncontext on the health of the clustering.\n  While explaining data using clusters, the major problem is to tell how many\ncluster are good enough to explain the data. Generally basic descriptive\nstatistics are used to estimate cluster behaviour like scree plot, dendrogram\netc. We propose a novel method to understand the cluster behaviour which can be\nused not only to find right number of clusters but can also be used to access\nthe difference of health between different clustering methods on same data. Our\ntechnique would also help to also eliminate the noisy variables and optimize\nthe clustering result.\n  keywords - Clustering, Metric, K-means, hierarchical clustering, silhoutte,\nclustering index, measures\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:10:54 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Pathak", "Kumarjit", ""], ["Kapila", "Jitin", ""]]}, {"id": "1810.03435", "submitter": "Ruibo Tu", "authors": "Charles Hamesse, Ruibo Tu, Paul Ackermann, Hedvig Kjellstr\\\"om, Cheng\n  Zhang", "title": "Simultaneous Measurement Imputation and Outcome Prediction for Achilles\n  Tendon Rupture Rehabilitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achilles Tendon Rupture (ATR) is one of the typical soft tissue injuries.\nRehabilitation after such a musculoskeletal injury remains a prolonged process\nwith a very variable outcome. Accurately predicting rehabilitation outcome is\ncrucial for treatment decision support. However, it is challenging to train an\nautomatic method for predicting the ATR rehabilitation outcome from treatment\ndata, due to a massive amount of missing entries in the data recorded from ATR\npatients, as well as complex nonlinear relations between measurements and\noutcomes. In this work, we design an end-to-end probabilistic framework to\nimpute missing data entries and predict rehabilitation outcomes simultaneously.\nWe evaluate our model on a real-life ATR clinical cohort, comparing with\nvarious baselines. The proposed method demonstrates its clear superiority over\ntraditional methods which typically perform imputation and prediction in two\nseparate stages.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 07:25:12 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 09:10:16 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Hamesse", "Charles", ""], ["Tu", "Ruibo", ""], ["Ackermann", "Paul", ""], ["Kjellstr\u00f6m", "Hedvig", ""], ["Zhang", "Cheng", ""]]}, {"id": "1810.03440", "submitter": "Filip Tronarp", "authors": "Filip Tronarp, Hans Kersting, Simo S\\\"arkk\\\"a, Philipp Hennig", "title": "Probabilistic Solutions To Ordinary Differential Equations As Non-Linear\n  Bayesian Filtering: A New Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate probabilistic numerical approximations to solutions of ordinary\ndifferential equations (ODEs) as problems in Gaussian process (GP) regression\nwith non-linear measurement functions. This is achieved by defining the\nmeasurement sequence to consist of the observations of the difference between\nthe derivative of the GP and the vector field evaluated at the GP---which are\nall identically zero at the solution of the ODE. When the GP has a state-space\nrepresentation, the problem can be reduced to a non-linear Bayesian filtering\nproblem and all widely-used approximations to the Bayesian filtering and\nsmoothing problems become applicable. Furthermore, all previous GP-based ODE\nsolvers that are formulated in terms of generating synthetic measurements of\nthe gradient field come out as specific approximations. Based on the non-linear\nBayesian filtering problem posed in this paper, we develop novel Gaussian\nsolvers for which we establish favourable stability properties. Additionally,\nnon-Gaussian approximations to the filtering problem are derived by the\nparticle filter approach. The resulting solvers are compared with other\nprobabilistic solvers in illustrative experiments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:36:24 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 16:30:22 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 12:20:07 GMT"}, {"version": "v4", "created": "Wed, 24 Apr 2019 09:13:11 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Tronarp", "Filip", ""], ["Kersting", "Hans", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Hennig", "Philipp", ""]]}, {"id": "1810.03442", "submitter": "Assya Trofimov", "authors": "Assya Trofimov, Francis Dutil, Claude Perreault, Sebastien Lemieux,\n  Yoshua Bengio and Joseph Paul Cohen", "title": "Towards the Latent Transcriptome", "comments": "7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a method to compute continuous embeddings for kmers\nfrom raw RNA-seq data, without the need for alignment to a reference genome.\nThe approach uses an RNN to transform kmers of the RNA-seq reads into a 2\ndimensional representation that is used to predict abundance of each kmer. We\nreport that our model captures information of both DNA sequence similarity as\nwell as DNA sequence abundance in the embedding latent space, that we call the\nLatent Transcriptome. We confirm the quality of these vectors by comparing them\nto known gene sub-structures and report that the latent space recovers exon\ninformation from raw RNA-Seq data from acute myeloid leukemia patients.\nFurthermore we show that this latent space allows the detection of genomic\nabnormalities such as translocations as well as patient-specific mutations,\nmaking this representation space both useful for visualization as well as\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 14:13:22 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 17:46:47 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Trofimov", "Assya", ""], ["Dutil", "Francis", ""], ["Perreault", "Claude", ""], ["Lemieux", "Sebastien", ""], ["Bengio", "Yoshua", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1810.03445", "submitter": "Zhu Gao", "authors": "Zhu Gao, Yanhui Jiang, Junhui Gao", "title": "Building a language evolution tree based on word vector combination\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we try to explore the evolution of language through case\ncalculations. First, we chose the novels of eleven British writers from 1400 to\n2005 and found the corresponding works; Then, we use the natural language\nprocessing tool to construct the corresponding eleven corpora, and calculate\nthe respective word vectors of 100 high-frequency words in eleven corpora;\nNext, for each corpus, we concatenate the 100 word vectors from beginning to\nend into one; Finally, we use the similarity comparison and hierarchical\nclustering method to generate the relationship tree between the combined eleven\nword vectors. This tree represents the relationship between eleven corpora. We\nfound that in the tree generated by clustering, the distance between the corpus\nand the year corresponding to the corpus are basically the same. This means\nthat we have discovered a specific language evolution tree. To verify the\nstability and versatility of this method, we add three other themes: Dickens's\neight works, the 19th century poets' works, and art criticism of recent 60\nyears. For these four themes, we tested different parameters such as the time\nspan of the corpus, the time interval between the corpora, the dimension of the\nword vector, and the number of high-frequency public words. The results show\nthat this is fairly stable and versatile.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:25:36 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Gao", "Zhu", ""], ["Jiang", "Yanhui", ""], ["Gao", "Junhui", ""]]}, {"id": "1810.03463", "submitter": "Akifumi Okuno", "authors": "Akifumi Okuno, Geewook Kim, Hidetoshi Shimodaira", "title": "Graph Embedding with Shifted Inner Product Similarity and Its Improved\n  Approximation Capability", "comments": "20 pages (with Supplementary Material), 2 figures, AISTATS2019. arXiv\n  admin note: text overlap with arXiv:1805.12332", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose shifted inner-product similarity (SIPS), which is a novel yet very\nsimple extension of the ordinary inner-product similarity (IPS) for\nneural-network based graph embedding (GE). In contrast to IPS, that is limited\nto approximating positive-definite (PD) similarities, SIPS goes beyond the\nlimitation by introducing bias terms in IPS; we theoretically prove that SIPS\nis capable of approximating not only PD but also conditionally PD (CPD)\nsimilarities with many examples such as cosine similarity, negative Poincare\ndistance and negative Wasserstein distance. Since SIPS with sufficiently large\nneural networks learns a variety of similarities, SIPS alleviates the need for\nconfiguring the similarity function of GE. Approximation error rate is also\nevaluated, and experiments on two real-world datasets demonstrate that graph\nembedding using SIPS indeed outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 18:49:03 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 05:39:24 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Okuno", "Akifumi", ""], ["Kim", "Geewook", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1810.03480", "submitter": "Arnaud Mignan", "authors": "Arnaud Mignan", "title": "Text Classification of the Precursory Accelerating Seismicity Corpus:\n  Inference on some Theoretical Trends in Earthquake Predictability Research\n  from 1988 to 2018", "comments": "21 pages, 3 figures, 7 tables", "journal-ref": "Journal of Seismology, 2019", "doi": "10.1007/s10950-019-09833-2", "report-no": null, "categories": "cs.CL physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text analytics based on supervised machine learning classifiers has shown\ngreat promise in a multitude of domains, but has yet to be applied to\nSeismology. We test various standard models (Naive Bayes, k-Nearest Neighbors,\nSupport Vector Machines, and Random Forests) on a seismological corpus of 100\narticles related to the topic of precursory accelerating seismicity, spanning\nfrom 1988 to 2010. This corpus was labelled in Mignan (2011) with the precursor\nwhether explained by critical processes (i.e., cascade triggering) or by other\nprocesses (such as signature of main fault loading). We investigate rather the\nclassification process can be automatized to help analyze larger corpora in\norder to better understand trends in earthquake predictability research. We\nfind that the Naive Bayes model performs best, in agreement with the machine\nlearning literature for the case of small datasets, with cross-validation\naccuracies of 86% for binary classification. For a refined multiclass\nclassification ('non-critical process' < 'agnostic' < 'critical process\nassumed' < 'critical process demonstrated'), we obtain up to 78% accuracy.\nPrediction on a dozen of articles published since 2011 shows however a weak\ngeneralization with a F1-score of 60%, only slightly better than a random\nclassifier, which can be explained by a change of authorship and use of\ndifferent terminologies. Yet, the model shows F1-scores greater than 80% for\nthe two multiclass extremes ('non-critical process' versus 'critical process\ndemonstrated') while it falls to random classifier results (around 25%) for\npapers labelled 'agnostic' or 'critical process assumed'. Those results are\nencouraging in view of the small size of the corpus and of the high degree of\nabstraction of the labelling. Domain knowledge engineering remains essential\nbut can be made transparent by an investigation of Naive Bayes keyword\nposterior probabilities.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 16:15:14 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Mignan", "Arnaud", ""]]}, {"id": "1810.03505", "submitter": "Luke Darlow", "authors": "Luke N. Darlow, Elliot J. Crowley, Antreas Antoniou, Amos J. Storkey", "title": "CINIC-10 is not ImageNet or CIFAR-10", "comments": "Dataset compilation, 9 pages, 11 figures, technical report", "journal-ref": null, "doi": null, "report-no": "EDI-INF-ANC-1802", "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this brief technical report we introduce the CINIC-10 dataset as a plug-in\nextended alternative for CIFAR-10. It was compiled by combining CIFAR-10 with\nimages selected and downsampled from the ImageNet database. We present the\napproach to compiling the dataset, illustrate the example images for different\nclasses, give pixel distributions for each part of the repository, and give\nsome standard benchmarks for well known models. Details for download, usage,\nand compilation can be found in the associated github repository.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 21:20:09 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Darlow", "Luke N.", ""], ["Crowley", "Elliot J.", ""], ["Antoniou", "Antreas", ""], ["Storkey", "Amos J.", ""]]}, {"id": "1810.03527", "submitter": "Jinwoong Kim", "authors": "Jinwoong Kim, Minkyu Kim, Heungseok Park, Ernar Kusdavletov, Dongjun\n  Lee, Adrian Kim, Ji-Hoon Kim, Jung-Woo Ha, Nako Sung", "title": "CHOPT : Automated Hyperparameter Optimization Framework for Cloud-Based\n  Machine Learning Platforms", "comments": "10 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1807.01774 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many hyperparameter optimization (HyperOpt) methods assume restricted\ncomputing resources and mainly focus on enhancing performance. Here we propose\na novel cloud-based HyperOpt (CHOPT) framework which can efficiently utilize\nshared computing resources while supporting various HyperOpt algorithms. We\nincorporate convenient web-based user interfaces, visualization, and analysis\ntools, enabling users to easily control optimization procedures and build up\nvaluable insights with an iterative analysis procedure. Furthermore, our\nframework can be incorporated with any cloud platform, thus complementarily\nincreasing the efficiency of conventional deep learning frameworks. We\ndemonstrate applications of CHOPT with tasks such as image recognition and\nquestion-answering, showing that our framework can find hyperparameter\nconfigurations competitive with previous work. We also show CHOPT is capable of\nproviding interesting observations through its analysing tools\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:24:23 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 08:06:52 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Kim", "Jinwoong", ""], ["Kim", "Minkyu", ""], ["Park", "Heungseok", ""], ["Kusdavletov", "Ernar", ""], ["Lee", "Dongjun", ""], ["Kim", "Adrian", ""], ["Kim", "Ji-Hoon", ""], ["Ha", "Jung-Woo", ""], ["Sung", "Nako", ""]]}, {"id": "1810.03530", "submitter": "Michael Kamp", "authors": "Michael Kamp and Mario Boley and Olana Missura and Thomas G\\\"artner", "title": "Effective Parallelisation for Machine Learning", "comments": "Advances in Neural Information Processing Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel parallelisation scheme that simplifies the adaptation of\nlearning algorithms to growing amounts of data as well as growing needs for\naccurate and confident predictions in critical applications. In contrast to\nother parallelisation techniques, it can be applied to a broad class of\nlearning algorithms without further mathematical derivations and without\nwriting dedicated code, while at the same time maintaining theoretical\nperformance guarantees. Moreover, our parallelisation scheme is able to reduce\nthe runtime of many learning algorithms to polylogarithmic time on\nquasi-polynomially many processing units. This is a significant step towards a\ngeneral answer to an open question on the efficient parallelisation of machine\nlearning algorithms in the sense of Nick's Class (NC). The cost of this\nparallelisation is in the form of a larger sample complexity. Our empirical\nstudy confirms the potential of our parallelisation scheme with fixed numbers\nof processors and instances in realistic application scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:35:07 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Kamp", "Michael", ""], ["Boley", "Mario", ""], ["Missura", "Olana", ""], ["G\u00e4rtner", "Thomas", ""]]}, {"id": "1810.03538", "submitter": "Elias Khalil", "authors": "Elias B. Khalil, Amrita Gupta, Bistra Dilkina", "title": "Combinatorial Attacks on Binarized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized Neural Networks (BNNs) have recently attracted significant interest\ndue to their computational efficiency. Concurrently, it has been shown that\nneural networks may be overly sensitive to \"attacks\" - tiny adversarial changes\nin the input - which may be detrimental to their use in safety-critical\ndomains. Designing attack algorithms that effectively fool trained models is a\nkey step towards learning robust neural networks. The discrete,\nnon-differentiable nature of BNNs, which distinguishes them from their\nfull-precision counterparts, poses a challenge to gradient-based attacks. In\nthis work, we study the problem of attacking a BNN through the lens of\ncombinatorial and integer optimization. We propose a Mixed Integer Linear\nProgramming (MILP) formulation of the problem. While exact and flexible, the\nMILP quickly becomes intractable as the network and perturbation space grow. To\naddress this issue, we propose IProp, a decomposition-based algorithm that\nsolves a sequence of much smaller MILP problems. Experimentally, we evaluate\nboth proposed methods against the standard gradient-based attack (FGSM) on\nMNIST and Fashion-MNIST, and show that IProp performs favorably compared to\nFGSM, while scaling beyond the limits of the MILP.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 15:51:23 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Khalil", "Elias B.", ""], ["Gupta", "Amrita", ""], ["Dilkina", "Bistra", ""]]}, {"id": "1810.03545", "submitter": "Guang Cheng", "authors": "Tianyang Hu, Zixiang Chen, Hanxi Sun, Jincheng Bai, Mao Ye, Guang\n  Cheng", "title": "Stein Neural Sampler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two novel samplers to generate high-quality samples from a given\n(un-normalized) probability density. Motivated by the success of generative\nadversarial networks, we construct our samplers using deep neural networks that\ntransform a reference distribution to the target distribution. Training schemes\nare developed to minimize two variations of the Stein discrepancy, which is\ndesigned to work with un-normalized densities. Once trained, our samplers are\nable to generate samples instantaneously. We show that the proposed methods are\ntheoretically sound and experience fewer convergence issues compared with\ntraditional sampling approaches according to our empirical studies.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:06:40 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 02:57:54 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hu", "Tianyang", ""], ["Chen", "Zixiang", ""], ["Sun", "Hanxi", ""], ["Bai", "Jincheng", ""], ["Ye", "Mao", ""], ["Cheng", "Guang", ""]]}, {"id": "1810.03548", "submitter": "Joaquin Vanschoren", "authors": "Joaquin Vanschoren", "title": "Meta-Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning, or learning to learn, is the science of systematically\nobserving how different machine learning approaches perform on a wide range of\nlearning tasks, and then learning from this experience, or meta-data, to learn\nnew tasks much faster than otherwise possible. Not only does this dramatically\nspeed up and improve the design of machine learning pipelines or neural\narchitectures, it also allows us to replace hand-engineered algorithms with\nnovel approaches learned in a data-driven way. In this chapter, we provide an\noverview of the state of the art in this fascinating and continuously evolving\nfield.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:07:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Vanschoren", "Joaquin", ""]]}, {"id": "1810.03587", "submitter": "Chinmay Hegde", "authors": "Chinmay Hegde", "title": "Algorithmic Aspects of Inverse Problems Using Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The traditional approach of hand-crafting priors (such as sparsity) for\nsolving inverse problems is slowly being replaced by the use of richer learned\npriors (such as those modeled by generative adversarial networks, or GANs). In\nthis work, we study the algorithmic aspects of such a learning-based approach\nfrom a theoretical perspective. For certain generative network architectures,\nwe establish a simple non-convex algorithmic approach that (a) theoretically\nenjoys linear convergence guarantees for certain inverse problems, and (b)\nempirically improves upon conventional techniques such as back-propagation. We\nalso propose an extension of our approach that can handle model mismatch (i.e.,\nsituations where the generative network prior is not exactly applicable.)\nTogether, our contributions serve as building blocks towards a more complete\nalgorithmic understanding of generative models in inverse problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:29:47 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Hegde", "Chinmay", ""]]}, {"id": "1810.03594", "submitter": "Yawei Zhao", "authors": "Yawei Zhao and Shuang Qiu and Ji Liu", "title": "Proximal Online Gradient is Optimum for Dynamic Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online learning, the dynamic regret metric chooses the reference (optimal)\nsolution that may change over time, while the typical (static) regret metric\nassumes the reference solution to be constant over the whole time horizon. The\ndynamic regret metric is particularly interesting for applications such as\nonline recommendation (since the customers' preference always evolves over\ntime). While the online gradient method has been shown to be optimal for the\nstatic regret metric, the optimal algorithm for the dynamic regret remains\nunknown. In this paper, we show that proximal online gradient (a general\nversion of online gradient) is optimum to the dynamic regret by showing that\nthe proved lower bound matches the upper bound that slightly improves existing\nupper bound.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:43:50 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 03:53:08 GMT"}, {"version": "v3", "created": "Fri, 23 Nov 2018 15:16:34 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 22:04:17 GMT"}, {"version": "v5", "created": "Thu, 8 Aug 2019 22:03:37 GMT"}, {"version": "v6", "created": "Tue, 3 Sep 2019 17:37:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhao", "Yawei", ""], ["Qiu", "Shuang", ""], ["Liu", "Ji", ""]]}, {"id": "1810.03608", "submitter": "Yuan Yao", "authors": "Chendi Huang and Yuan Yao", "title": "A Unified Dynamic Approach to Sparse Model Selection", "comments": "24 pages", "journal-ref": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain. PMLR: Volume 84", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse model selection is ubiquitous from linear regression to graphical\nmodels where regularization paths, as a family of estimators upon the\nregularization parameter varying, are computed when the regularization\nparameter is unknown or decided data-adaptively. Traditional computational\nmethods rely on solving a set of optimization problems where the regularization\nparameters are fixed on a grid that might be inefficient. In this paper, we\nintroduce a simple iterative regularization path, which follows the dynamics of\na sparse Mirror Descent algorithm or a generalization of Linearized Bregman\nIterations with nonlinear loss. Its performance is competitive to\n\\texttt{glmnet} with a further bias reduction. A path consistency theory is\npresented that under the Restricted Strong Convexity (RSC) and the\nIrrepresentable Condition (IRR), the path will first evolve in a subspace with\nno false positives and reach an estimator that is sign-consistent or of minimax\noptimal $\\ell_2$ error rate. Early stopping regularization is required to\nprevent overfitting. Application examples are given in sparse logistic\nregression and Ising models for NIPS coauthorship.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:02:02 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Huang", "Chendi", ""], ["Yao", "Yuan", ""]]}, {"id": "1810.03611", "submitter": "Marc-Etienne Brunet", "authors": "Marc-Etienne Brunet, Colleen Alkalay-Houlihan, Ashton Anderson,\n  Richard Zemel", "title": "Understanding the Origins of Bias in Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of machine learning systems not only promises great technical\nprogress, but risks societal harm. As a recent example, researchers have shown\nthat popular word embedding algorithms exhibit stereotypical biases, such as\ngender bias. The widespread use of these algorithms in machine learning\nsystems, from automated translation services to curriculum vitae scanners, can\namplify stereotypes in important contexts. Although methods have been developed\nto measure these biases and alter word embeddings to mitigate their biased\nrepresentations, there is a lack of understanding in how word embedding bias\ndepends on the training data. In this work, we develop a technique for\nunderstanding the origins of bias in word embeddings. Given a word embedding\ntrained on a corpus, our method identifies how perturbing the corpus will\naffect the bias of the resulting embedding. This can be used to trace the\norigins of word embedding bias back to the original training documents. Using\nour method, one can investigate trends in the bias of the underlying corpus and\nidentify subsets of documents whose removal would most reduce bias. We\ndemonstrate our techniques on both a New York Times and Wikipedia corpus and\nfind that our influence function-based approximations are very accurate.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 18:26:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Brunet", "Marc-Etienne", ""], ["Alkalay-Houlihan", "Colleen", ""], ["Anderson", "Ashton", ""], ["Zemel", "Richard", ""]]}, {"id": "1810.03642", "submitter": "Luisa Zintgraf", "authors": "Luisa M Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann,\n  Shimon Whiteson", "title": "Fast Context Adaptation via Meta-Learning", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose CAVIA for meta-learning, a simple extension to MAML that is less\nprone to meta-overfitting, easier to parallelise, and more interpretable. CAVIA\npartitions the model parameters into two parts: context parameters that serve\nas additional input to the model and are adapted on individual tasks, and\nshared parameters that are meta-trained and shared across tasks. At test time,\nonly the context parameters are updated, leading to a low-dimensional task\nrepresentation. We show empirically that CAVIA outperforms MAML for regression,\nclassification, and reinforcement learning. Our experiments also highlight\nweaknesses in current benchmarks, in that the amount of adaptation needed in\nsome cases is small.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:11:01 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 13:38:19 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 14:06:01 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 17:17:53 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zintgraf", "Luisa M", ""], ["Shiarlis", "Kyriacos", ""], ["Kurin", "Vitaly", ""], ["Hofmann", "Katja", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1810.03679", "submitter": "Amit Prasad", "authors": "Amit Prasad and Ivana Dusparic", "title": "Multi-agent Deep Reinforcement Learning for Zero Energy Communities", "comments": "Accepted at ISGT Europe 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in renewable energy generation and introduction of the government\ntargets to improve energy efficiency gave rise to a concept of a Zero Energy\nBuilding (ZEB). A ZEB is a building whose net energy usage over a year is zero,\ni.e., its energy use is not larger than its overall renewables generation. A\ncollection of ZEBs forms a Zero Energy Community (ZEC). This paper addresses\nthe problem of energy sharing in such a community. This is different from\npreviously addressed energy sharing between buildings as our focus is on the\nimprovement of community energy status, while traditionally research focused on\nreducing losses due to transmission and storage, or achieving economic gains.\nWe model this problem in a multi-agent environment and propose a Deep\nReinforcement Learning (DRL) based solution. Each building is represented by an\nintelligent agent that learns over time the appropriate behaviour to share\nenergy. We have evaluated the proposed solution in a multi-agent simulation\nbuilt using osBrain. Results indicate that with time agents learn to\ncollaborate and learn a policy comparable to the optimal policy, which in turn\nimproves the ZEC's energy status. Buildings with no renewables preferred to\nrequest energy from their neighbours rather than from the supply grid.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 19:58:46 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 15:10:27 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Prasad", "Amit", ""], ["Dusparic", "Ivana", ""]]}, {"id": "1810.03711", "submitter": "Luigi Freda", "authors": "Luigi Freda and Mario Gianni and Fiora Pirri", "title": "A Hybrid Approach for Trajectory Control Design", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents a methodology to design trajectory tracking feedback\ncontrol laws, which embed non-parametric statistical models, such as Gaussian\nProcesses (GPs). The aim is to minimize unmodeled dynamics such as undesired\nslippages. The proposed approach has the benefit of avoiding complex\nterramechanics analysis to directly estimate from data the robot dynamics on a\nwide class of trajectories. Experiments in both real and simulated environments\nprove that the proposed methodology is promising.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 21:40:07 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2019 10:15:13 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Freda", "Luigi", ""], ["Gianni", "Mario", ""], ["Pirri", "Fiora", ""]]}, {"id": "1810.03714", "submitter": "David Brookes", "authors": "David H. Brookes and Jennifer Listgarten", "title": "Design by adaptive sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic modeling framework and adaptive sampling algorithm\nwherein unsupervised generative models are combined with black box predictive\nmodels to tackle the problem of input design. In input design, one is given one\nor more stochastic \"oracle\" predictive functions, each of which maps from the\ninput design space (e.g. DNA sequences or images) to a distribution over a\nproperty of interest (e.g. protein fluorescence or image content). Given such\nstochastic oracles, the problem is to find an input that is expected to\nmaximize one or more properties, or to achieve a specified value of one or more\nproperties, or any combination thereof. We demonstrate experimentally that our\napproach substantially outperforms other recently presented methods for\ntackling a specific version of this problem, namely, maximization when the\noracle is assumed to be deterministic and unbiased. We also demonstrate that\nour method can tackle more general versions of the problem.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 21:47:11 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 00:30:22 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 23:01:28 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 19:42:55 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Brookes", "David H.", ""], ["Listgarten", "Jennifer", ""]]}, {"id": "1810.03728", "submitter": "Emilien Dupont", "authors": "Emilien Dupont, Suhas Suresha", "title": "Probabilistic Semantic Inpainting with Pixel Constrained CNNs", "comments": "AISTATS camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic inpainting is the task of inferring missing pixels in an image given\nsurrounding pixels and high level image semantics. Most semantic inpainting\nalgorithms are deterministic: given an image with missing regions, a single\ninpainted image is generated. However, there are often several plausible\ninpaintings for a given missing region. In this paper, we propose a method to\nperform probabilistic semantic inpainting by building a model, based on\nPixelCNNs, that learns a distribution of images conditioned on a subset of\nvisible pixels. Experiments on the MNIST and CelebA datasets show that our\nmethod produces diverse and realistic inpaintings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 22:19:08 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 22:38:27 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Dupont", "Emilien", ""], ["Suresha", "Suhas", ""]]}, {"id": "1810.03730", "submitter": "Rui Zhang", "authors": "Rui Zhang, Christian Walder, Marian-Andrei Rizoiu, Lexing Xie", "title": "Efficient Non-parametric Bayesian Hawkes Processes", "comments": "IJCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an efficient nonparametric Bayesian estimation of\nthe kernel function of Hawkes processes. The non-parametric Bayesian approach\nis important because it provides flexible Hawkes kernels and quantifies their\nuncertainty. Our method is based on the cluster representation of Hawkes\nprocesses. Utilizing the stationarity of the Hawkes process, we efficiently\nsample random branching structures and thus, we split the Hawkes process into\nclusters of Poisson processes. We derive two algorithms -- a block Gibbs\nsampler and a maximum a posteriori estimator based on expectation maximization\n-- and we show that our methods have a linear time complexity, both\ntheoretically and empirically. On synthetic data, we show our methods to be\nable to infer flexible Hawkes triggering kernels. On two large-scale Twitter\ndiffusion datasets, we show that our methods outperform the current\nstate-of-the-art in goodness-of-fit and that the time complexity is linear in\nthe size of the dataset. We also observe that on diffusions related to online\nvideos, the learned kernels reflect the perceived longevity for different\ncontent types such as music or pets videos.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 22:21:49 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2018 00:38:46 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 05:22:56 GMT"}, {"version": "v4", "created": "Thu, 24 Jun 2021 08:05:34 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Zhang", "Rui", ""], ["Walder", "Christian", ""], ["Rizoiu", "Marian-Andrei", ""], ["Xie", "Lexing", ""]]}, {"id": "1810.03739", "submitter": "Ting-Jui Chang", "authors": "Ting-Jui Chang, Yukun He, Peng Li", "title": "Efficient Two-Step Adversarial Defense for Deep Neural Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks have demonstrated outstanding\nperformance in many machine learning tasks. However, researchers have\ndiscovered that these state-of-the-art models are vulnerable to adversarial\nexamples: legitimate examples added by small perturbations which are\nunnoticeable to human eyes. Adversarial training, which augments the training\ndata with adversarial examples during the training process, is a well known\ndefense to improve the robustness of the model against adversarial attacks.\nHowever, this robustness is only effective to the same attack method used for\nadversarial training. Madry et al.(2017) suggest that effectiveness of\niterative multi-step adversarial attacks and particularly that projected\ngradient descent (PGD) may be considered the universal first order adversary\nand applying the adversarial training with PGD implies resistance against many\nother first order attacks. However, the computational cost of the adversarial\ntraining with PGD and other multi-step adversarial examples is much higher than\nthat of the adversarial training with other simpler attack techniques. In this\npaper, we show how strong adversarial examples can be generated only at a cost\nsimilar to that of two runs of the fast gradient sign method (FGSM), allowing\ndefense against adversarial attacks with a robustness level comparable to that\nof the adversarial training with multi-step adversarial examples. We\nempirically demonstrate the effectiveness of the proposed two-step defense\napproach against different attack methods and its improvements over existing\ndefense strategies.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:00:06 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Chang", "Ting-Jui", ""], ["He", "Yukun", ""], ["Li", "Peng", ""]]}, {"id": "1810.03743", "submitter": "LuoLuo Liu", "authors": "Luoluo Liu, Sang Peter Chin, Trac D. Tran", "title": "JOBS: Joint-Sparse Optimization from Bootstrap Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical signal recovery based on $\\ell_1$ minimization solves the least\nsquares problem with all available measurements via sparsity-promoting\nregularization. In practice, it is often the case that not all measurements are\navailable or required for recovery. Measurements might be corrupted/missing or\nthey arrive sequentially in streaming fashion. In this paper, we propose a\nglobal sparse recovery strategy based on subsets of measurements, named JOBS,\nin which multiple measurements vectors are generated from the original pool of\nmeasurements via bootstrapping, and then a joint-sparse constraint is enforced\nto ensure support consistency among multiple predictors. The final estimate is\nobtained by averaging over the $K$ predictors. The performance limits\nassociated with different choices of number of bootstrap samples $L$ and number\nof estimates $K$ is analyzed theoretically. Simulation results validate some of\nthe theoretical analysis, and show that the proposed method yields\nstate-of-the-art recovery performance, outperforming $\\ell_1$ minimization and\na few other existing bootstrap-based techniques in the challenging case of low\nlevels of measurements and is preferable over other bagging-based methods in\nthe streaming setting since it performs better with small $K$ and $L$ for\ndata-sets with large sizes.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:24:22 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 02:34:29 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Liu", "Luoluo", ""], ["Chin", "Sang Peter", ""], ["Tran", "Trac D.", ""]]}, {"id": "1810.03744", "submitter": "Marcelo Prates", "authors": "Felipe Zilio, Marcelo Prates, Luis Lamb", "title": "Neural Networks Models for Analyzing Magic: the Gathering Cards", "comments": "10 pages, 1 figure, 9 tables. Accepted at ICONIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, games of all kinds have often been the subject of study in\nscientific works of Computer Science, including the field of machine learning.\nBy using machine learning techniques and applying them to a game with defined\nrules or a structured dataset, it's possible to learn and improve on the\nalready existing techniques and methods to tackle new challenges and solve\nproblems that are out of the ordinary. The already existing work on card games\ntends to focus on gameplay and card mechanics. This work aims to apply neural\nnetworks models, including Convolutional Neural Networks and Recurrent Neural\nNetworks, in order to analyze Magic: the Gathering cards, both in terms of card\ntext and illustrations; the card images and texts are used to train the\nnetworks in order to be able to classify them into multiple categories. The\nultimate goal was to develop a methodology that could generate card text\nmatching it to an input image, which was attained by relating the prediction\nvalues of the images and generated text across the different categories.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:25:18 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zilio", "Felipe", ""], ["Prates", "Marcelo", ""], ["Lamb", "Luis", ""]]}, {"id": "1810.03745", "submitter": "Alexander Neergaard Olesen", "authors": "Alexander Neergaard Olesen, Poul Jennum, Paul Peppard, Emmanuel\n  Mignot, Helge Bjarup Dissing Sorensen", "title": "Deep residual networks for automatic sleep stage classification of raw\n  polysomnographic waveforms", "comments": null, "journal-ref": "2018 40th Annual International Conference of the IEEE Engineering\n  in Medicine and Biology Society (EMBC), Honolulu, HI, 2018, pp. 1-4", "doi": "10.1109/EMBC.2018.8513080", "report-no": null, "categories": "cs.CV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed an automatic sleep stage classification algorithm based on\ndeep residual neural networks and raw polysomnogram signals. Briefly, the raw\ndata is passed through 50 convolutional layers before subsequent classification\ninto one of five sleep stages. Three model configurations were trained on 1850\npolysomnogram recordings and subsequently tested on 230 independent recordings.\nOur best performing model yielded an accuracy of 84.1% and a Cohen's kappa of\n0.746, improving on previous reported results by other groups also using only\nraw polysomnogram data. Most errors were made on non-REM stage 1 and 3\ndecisions, errors likely resulting from the definition of these stages. Further\ntesting on independent cohorts is needed to verify performance for clinical\nuse.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:28:33 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Olesen", "Alexander Neergaard", ""], ["Jennum", "Poul", ""], ["Peppard", "Paul", ""], ["Mignot", "Emmanuel", ""], ["Sorensen", "Helge Bjarup Dissing", ""]]}, {"id": "1810.03763", "submitter": "Zhe Wang", "authors": "Zhe Wang, Yi Zhou, Yingbin Liang, Guanghui Lan", "title": "Cubic Regularization with Momentum for Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum is a popular technique to accelerate the convergence in practical\ntraining, and its impact on convergence guarantee has been well-studied for\nfirst-order algorithms. However, such a successful acceleration technique has\nnot yet been proposed for second-order algorithms in nonconvex optimization.In\nthis paper, we apply the momentum scheme to cubic regularized (CR) Newton's\nmethod and explore the potential for acceleration. Our numerical experiments on\nvarious nonconvex optimization problems demonstrate that the momentum scheme\ncan substantially facilitate the convergence of cubic regularization, and\nperform even better than the Nesterov's acceleration scheme for CR.\nTheoretically, we prove that CR under momentum achieves the best possible\nconvergence rate to a second-order stationary point for nonconvex optimization.\nMoreover, we study the proposed algorithm for solving problems satisfying an\nerror bound condition and establish a local quadratic convergence rate. Then,\nparticularly for finite-sum problems, we show that the proposed algorithm can\nallow computational inexactness that reduces the overall sample complexity\nwithout degrading the convergence rate.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 00:43:56 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 14:35:46 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Wang", "Zhe", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""], ["Lan", "Guanghui", ""]]}, {"id": "1810.03764", "submitter": "Nicholas Egan", "authors": "Nicholas Egan, Jeffrey Zhang, Kevin Shen", "title": "Generalized Latent Variable Recovery for Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generator of a Generative Adversarial Network (GAN) is trained to\ntransform latent vectors drawn from a prior distribution into realistic looking\nphotos. These latent vectors have been shown to encode information about the\ncontent of their corresponding images. Projecting input images onto the latent\nspace of a GAN is non-trivial, but previous work has successfully performed\nthis task for latent spaces with a uniform prior. We extend these techniques to\nlatent spaces with a Gaussian prior, and demonstrate our technique's\neffectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 00:46:00 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Egan", "Nicholas", ""], ["Zhang", "Jeffrey", ""], ["Shen", "Kevin", ""]]}, {"id": "1810.03770", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Naonori Ueda", "title": "Unsupervised Object Matching for Relational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised object matching method for relational data, which\nfinds matchings between objects in different relational datasets without\ncorrespondence information. For example, the proposed method matches documents\nin different languages in multi-lingual document-word networks without\ndictionaries nor alignment information. The proposed method assumes that each\nobject has latent vectors, and the probability of neighbor objects is modeled\nby the inner-product of the latent vectors, where the neighbors are generated\nby short random walks over the relations. The latent vectors are estimated by\nmaximizing the likelihood of the neighbors for each dataset. The estimated\nlatent vectors contain hidden structural information of each object in the\ngiven relational dataset. Then, the proposed method linearly projects the\nlatent vectors for all the datasets onto a common latent space shared across\nall datasets by matching the distributions while preserving the structural\ninformation. The projection matrix is estimated by minimizing the distance\nbetween the latent vector distributions with an orthogonality regularizer. To\nrepresent the distributions effectively, we use the kernel embedding of\ndistributions that hold high-order moment information about a distribution as\nan element in a reproducing kernel Hilbert space, which enables us to calculate\nthe distance between the distributions without density estimation. The\nstructural information encoded in the latent vectors are preserved by using the\northogonality regularizer. We demonstrate the effectiveness of the proposed\nmethod with experiments using real-world multi-lingual document-word relational\ndatasets and multiple user-item relational datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 01:51:58 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 05:18:09 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 02:44:50 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Ueda", "Naonori", ""]]}, {"id": "1810.03773", "submitter": "Matt Olfat", "authors": "Matt Olfat, Anil Aswani", "title": "Average Margin Regularization for Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness has become an important research topic given empirical\ndemonstrations on the lack of robustness of deep neural networks.\nUnfortunately, recent theoretical results suggest that adversarial training\ninduces a strict tradeoff between classification accuracy and adversarial\nrobustness. In this paper, we propose and then study a new regularization for\nany margin classifier or deep neural network. We motivate this regularization\nby a novel generalization bound that shows a tradeoff in classifier accuracy\nbetween maximizing its margin and average margin. We thus call our approach an\naverage margin (AM) regularization, and it consists of a linear term added to\nthe objective. We theoretically show that for certain distributions AM\nregularization can both improve classifier accuracy and robustness to\nadversarial attacks. We conclude by using both synthetic and real data to\nempirically show that AM regularization can strictly improve both accuracy and\nrobustness for support vector machine's (SVM's), relative to unregularized\nclassifiers and adversarially trained classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 02:10:30 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 19:12:07 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 02:35:26 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Olfat", "Matt", ""], ["Aswani", "Anil", ""]]}, {"id": "1810.03779", "submitter": "David Ha", "authors": "David Ha", "title": "Reinforcement Learning for Improving Agent Design", "comments": "Earlier version appeared at NeurIPS 2018 Deep Reinforcement Learning\n  Workshop. Published in Artificial Life journal", "journal-ref": "Artificial Life 25 (4), 352-365, 2019", "doi": "10.1162/artl_a_00301", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many reinforcement learning tasks, the goal is to learn a policy to\nmanipulate an agent, whose design is fixed, to maximize some notion of\ncumulative reward. The design of the agent's physical structure is rarely\noptimized for the task at hand. In this work, we explore the possibility of\nlearning a version of the agent's design that is better suited for its task,\njointly with the policy. We propose an alteration to the popular OpenAI Gym\nframework, where we parameterize parts of an environment, and allow an agent to\njointly learn to modify these environment parameters along with its policy. We\ndemonstrate that an agent can learn a better structure of its body that is not\nonly better suited for the task, but also facilitates policy learning. Joint\nlearning of policy and structure may even uncover design principles that are\nuseful for assisted-design applications. Videos of results at\nhttps://designrl.github.io/\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 02:32:37 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 11:01:21 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 10:49:36 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ha", "David", ""]]}, {"id": "1810.03785", "submitter": "Piotr A. Sok\\'o{\\l}", "authors": "Piotr A. Sokol, Il Memming Park", "title": "Information Geometry of Orthogonal Initializations and Training", "comments": "10 pages and 5 figures; 5 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently mean field theory has been successfully used to analyze properties\nof wide, random neural networks. It gave rise to a prescriptive theory for\ninitializing feed-forward neural networks with orthogonal weights, which\nensures that both the forward propagated activations and the backpropagated\ngradients are near $\\ell_2$ isometries and as a consequence training is orders\nof magnitude faster. Despite strong empirical performance, the mechanisms by\nwhich critical initializations confer an advantage in the optimization of deep\nneural networks are poorly understood. Here we show a novel connection between\nthe maximum curvature of the optimization landscape (gradient smoothness) as\nmeasured by the Fisher information matrix (FIM) and the spectral radius of the\ninput-output Jacobian, which partially explains why more isometric networks can\ntrain much faster. Furthermore, given that orthogonal weights are necessary to\nensure that gradient norms are approximately preserved at initialization, we\nexperimentally investigate the benefits of maintaining orthogonality throughout\ntraining, from which we conclude that manifold optimization of weights performs\nwell regardless of the smoothness of the gradients. Moreover, motivated by\nexperimental results we show that a low condition number of the FIM is not\npredictive of faster learning.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 03:00:41 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 17:58:13 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Sokol", "Piotr A.", ""], ["Park", "Il Memming", ""]]}, {"id": "1810.03798", "submitter": "Craig Bakker", "authors": "Craig Bakker, Michael J. Henry, and Nathan O. Hodas", "title": "The Outer Product Structure of Neural Network Derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that feedforward and recurrent neural networks exhibit\nan outer product derivative structure but that convolutional neural networks do\nnot. This structure makes it possible to use higher-order information without\nneeding approximations or infeasibly large amounts of memory, and it may also\nprovide insights into the geometry of neural network optima. The ability to\neasily access these derivatives also suggests a new, geometric approach to\nregularization. We then discuss how this structure could be used to improve\ntraining methods, increase network robustness and generalizability, and inform\nnetwork compression methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 03:37:08 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Bakker", "Craig", ""], ["Henry", "Michael J.", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "1810.03805", "submitter": "Jonas Mueller", "authors": "Brandon Carter, Jonas Mueller, Siddhartha Jain, David Gifford", "title": "What made you do this? Understanding black-box decisions with sufficient\n  input subsets", "comments": "Published in AISTATS 2019; Equal contribution by first two authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local explanation frameworks aim to rationalize particular decisions made by\na black-box prediction model. Existing techniques are often restricted to a\nspecific type of predictor or based on input saliency, which may be undesirably\nsensitive to factors unrelated to the model's decision making process. We\ninstead propose sufficient input subsets that identify minimal subsets of\nfeatures whose observed values alone suffice for the same decision to be\nreached, even if all other input feature values are missing. General principles\nthat globally govern a model's decision-making can also be revealed by\nsearching for clusters of such input patterns across many data points. Our\napproach is conceptually straightforward, entirely model-agnostic, simply\nimplemented using instance-wise backward selection, and able to produce more\nconcise rationales than existing techniques. We demonstrate the utility of our\ninterpretation method on various neural network models trained on text, image,\nand genomic data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 04:22:44 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 19:06:28 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Carter", "Brandon", ""], ["Mueller", "Jonas", ""], ["Jain", "Siddhartha", ""], ["Gifford", "David", ""]]}, {"id": "1810.03806", "submitter": "Chenxiao Zhao", "authors": "Chenxiao Zhao, P. Thomas Fletcher, Mixue Yu, Yaxin Peng, Guixu Zhang\n  and Chaomin Shen", "title": "The Adversarial Attack and Detection under the Fisher Information Metric", "comments": "Accepted as an AAAI-2019 oral paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep learning models are vulnerable to the adversarial attack, i.e.,\nimperceptible but intentionally-designed perturbations to the input can cause\nincorrect output of the networks. In this paper, using information geometry, we\nprovide a reasonable explanation for the vulnerability of deep learning models.\nBy considering the data space as a non-linear space with the Fisher information\nmetric induced from a neural network, we first propose an adversarial attack\nalgorithm termed one-step spectral attack (OSSA). The method is described by a\nconstrained quadratic form of the Fisher information matrix, where the optimal\nadversarial perturbation is given by the first eigenvector, and the model\nvulnerability is reflected by the eigenvalues. The larger an eigenvalue is, the\nmore vulnerable the model is to be attacked by the corresponding eigenvector.\nTaking advantage of the property, we also propose an adversarial detection\nmethod with the eigenvalues serving as characteristics. Both our attack and\ndetection algorithms are numerically optimized to work efficiently on large\ndatasets. Our evaluations show superior performance compared with other\nmethods, implying that the Fisher information is a promising approach to\ninvestigate the adversarial attacks and defenses.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 04:25:05 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 03:40:49 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Zhao", "Chenxiao", ""], ["Fletcher", "P. Thomas", ""], ["Yu", "Mixue", ""], ["Peng", "Yaxin", ""], ["Zhang", "Guixu", ""], ["Shen", "Chaomin", ""]]}, {"id": "1810.03814", "submitter": "Yueyong Shi", "authors": "Jian Huang, Yuling Jiao, Xiliang Lu, Yueyong Shi, Qinglong Yang", "title": "SNAP: A semismooth Newton algorithm for pathwise optimization with\n  optimal local convergence rate and oracle properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.AP stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semismooth Newton algorithm for pathwise optimization (SNAP) for\nthe LASSO and Enet in sparse, high-dimensional linear regression. SNAP is\nderived from a suitable formulation of the KKT conditions based on Newton\nderivatives. It solves the semismooth KKT equations efficiently by actively and\ncontinuously seeking the support of the regression coefficients along the\nsolution path with warm start. At each knot in the path, SNAP converges locally\nsuperlinearly for the Enet criterion and achieves an optimal local convergence\nrate for the LASSO criterion, i.e., SNAP converges in one step at the cost of\ntwo matrix-vector multiplication per iteration. Under certain regularity\nconditions on the design matrix and the minimum magnitude of the nonzero\nelements of the target regression coefficients, we show that SNAP hits a\nsolution with the same signs as the regression coefficients and achieves a\nsharp estimation error bound in finite steps with high probability. The\ncomputational complexity of SNAP is shown to be the same as that of LARS and\ncoordinate descent algorithms per iteration. Simulation studies and real data\nanalysis support our theoretical results and demonstrate that SNAP is faster\nand accurate than LARS and coordinate descent algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 04:44:42 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Lu", "Xiliang", ""], ["Shi", "Yueyong", ""], ["Yang", "Qinglong", ""]]}, {"id": "1810.03817", "submitter": "Shahin Shahrampour", "authors": "Shahin Shahrampour, Vahid Tarokh", "title": "Learning Bounds for Greedy Approximation with Explicit Feature Maps from\n  Multiple Kernels", "comments": "Proc. of 2018 Advances in Neural Information Processing Systems (NIPS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear kernels can be approximated using finite-dimensional feature maps\nfor efficient risk minimization. Due to the inherent trade-off between the\ndimension of the (mapped) feature space and the approximation accuracy, the key\nproblem is to identify promising (explicit) features leading to a satisfactory\nout-of-sample performance. In this work, we tackle this problem by efficiently\nchoosing such features from multiple kernels in a greedy fashion. Our method\nsequentially selects these explicit features from a set of candidate features\nusing a correlation metric. We establish an out-of-sample error bound capturing\nthe trade-off between the error in terms of explicit features (approximation\nerror) and the error due to spectral properties of the best model in the\nHilbert space associated to the combined kernel (spectral error). The result\nverifies that when the (best) underlying data model is sparse enough, i.e., the\nspectral error is negligible, one can control the test error with a small\nnumber of explicit features, that can scale poly-logarithmically with data. Our\nempirical results show that given a fixed number of explicit features, the\nmethod can achieve a lower test error with a smaller time cost, compared to the\nstate-of-the-art in data-dependent random features.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 05:20:41 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Shahrampour", "Shahin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1810.03825", "submitter": "Kohei Miyaguchi", "authors": "Kohei Miyaguchi and Kenji Yamanishi", "title": "Adaptive Minimax Regret against Smooth Logarithmic Losses over\n  High-Dimensional $\\ell_1$-Balls via Envelope Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new theoretical framework, the \\emph{envelope complexity}, to\nanalyze the minimax regret with logarithmic loss functions and derive a\nBayesian predictor that adaptively achieves the minimax regret over\nhigh-dimensional $\\ell_1$-balls within a factor of two. The prior is newly\nderived for achieving the minimax regret and called the\n\\emph{spike-and-tails~(ST) prior} as it looks like. The resulting regret bound\nis so simple that it is completely determined with the smoothness of the loss\nfunction and the radius of the balls except with logarithmic factors, and it\nhas a generalized form of existing regret/risk bounds. In the preliminary\nexperiment, we confirm that the ST prior outperforms the conventional\nminimax-regret prior under non-high-dimensional asymptotics.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 06:08:27 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 02:16:20 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Miyaguchi", "Kohei", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "1810.03880", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "Continual State Representation Learning for Reinforcement Learning using\n  Generative Replay", "comments": "Accepted contribution to the Workshop on Continual Learning, NeurIPS\n  2018 (Neural Information Processing Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of building a state representation model in a\ncontinual fashion. As the environment changes, the aim is to efficiently\ncompress the sensory state's information without losing past knowledge. The\nlearned features are then fed to a Reinforcement Learning algorithm to learn a\npolicy. We propose to use Variational Auto-Encoders for state representation,\nand Generative Replay, i.e. the use of generated samples, to maintain past\nknowledge. We also provide a general and statistically sound method for\nautomatic environment change detection. Our method provides efficient state\nrepresentation as well as forward transfer, and avoids catastrophic forgetting.\nThe resulting model is capable of incrementally learning information without\nusing past data and with a bounded system size.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:42:53 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 09:49:24 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 13:03:34 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "1810.03913", "submitter": "Shixia Liu", "authors": "Mengchen Liu, Shixia Liu, Hang Su, Kelei Cao, Jun Zhu", "title": "Analyzing the Noise Robustness of Deep Neural Networks", "comments": "IEEE VAST 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to maliciously generated\nadversarial examples. These examples are intentionally designed by making\nimperceptible perturbations and often mislead a DNN into making an incorrect\nprediction. This phenomenon means that there is significant risk in applying\nDNNs to safety-critical applications, such as driverless cars. To address this\nissue, we present a visual analytics approach to explain the primary cause of\nthe wrong predictions introduced by adversarial examples. The key is to analyze\nthe datapaths of the adversarial examples and compare them with those of the\nnormal examples. A datapath is a group of critical neurons and their\nconnections. To this end, we formulate the datapath extraction as a subset\nselection problem and approximately solve it based on back-propagation. A\nmulti-level visualization consisting of a segmented DAG (layer level), an Euler\ndiagram (feature map level), and a heat map (neuron level), has been designed\nto help experts investigate datapaths from the high-level layers to the\ndetailed neuron activations. Two case studies are conducted that demonstrate\nthe promise of our approach in support of explaining the working mechanism of\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 11:13:44 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Liu", "Mengchen", ""], ["Liu", "Shixia", ""], ["Su", "Hang", ""], ["Cao", "Kelei", ""], ["Zhu", "Jun", ""]]}, {"id": "1810.03944", "submitter": "Yong Luo", "authors": "Yong Luo, Yonggang Wen, Ling-Yu Duan, and Dacheng Tao", "title": "Transfer Metric Learning: Algorithms, Applications and Outlooks", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning (DML) aims to find an appropriate way to reveal the\nunderlying data relationship. It is critical in many machine learning, pattern\nrecognition and data mining algorithms, and usually require large amount of\nlabel information (such as class labels or pair/triplet constraints) to achieve\nsatisfactory performance. However, the label information may be insufficient in\nreal-world applications due to the high-labeling cost, and DML may fail in this\ncase. Transfer metric learning (TML) is able to mitigate this issue for DML in\nthe domain of interest (target domain) by leveraging knowledge/information from\nother related domains (source domains). Although achieved a certain level of\ndevelopment, TML has limited success in various aspects such as selective\ntransfer, theoretical understanding, handling complex data, big data and\nextreme cases. In this survey, we present a systematic review of the TML\nliterature. In particular, we group TML into different categories according to\ndifferent settings and metric transfer strategies, such as direct metric\napproximation, subspace approximation, distance approximation, and distribution\napproximation. A summarization and insightful discussion of the various TML\napproaches and their applications will be presented. Finally, we indicate some\nchallenges and provide possible future directions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 12:46:20 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 02:18:49 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 06:53:11 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Luo", "Yong", ""], ["Wen", "Yonggang", ""], ["Duan", "Ling-Yu", ""], ["Tao", "Dacheng", ""]]}, {"id": "1810.03958", "submitter": "Alexander Gaunt", "authors": "Anqi Wu, Sebastian Nowozin, Edward Meeds, Richard E. Turner, Jos\\'e\n  Miguel Hern\\'andez-Lobato, Alexander L. Gaunt", "title": "Deterministic Variational Inference for Robust Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) hold great promise as a flexible and\nprincipled solution to deal with uncertainty when learning from finite data.\nAmong approaches to realize probabilistic inference in deep neural networks,\nvariational Bayes (VB) is theoretically grounded, generally applicable, and\ncomputationally efficient. With wide recognition of potential advantages, why\nis it that variational Bayes has seen very limited practical use for BNNs in\nreal applications? We argue that variational inference in neural networks is\nfragile: successful implementations require careful initialization and tuning\nof prior variances, as well as controlling the variance of Monte Carlo gradient\nestimates. We provide two innovations that aim to turn VB into a robust\ninference tool for Bayesian neural networks: first, we introduce a novel\ndeterministic method to approximate moments in neural networks, eliminating\ngradient variance; second, we introduce a hierarchical prior for parameters and\na novel Empirical Bayes procedure for automatically selecting prior variances.\nCombining these two innovations, the resulting method is highly efficient and\nrobust. On the application of heteroscedastic regression we demonstrate good\npredictive performance over alternative approaches.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:30:58 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 17:05:48 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Wu", "Anqi", ""], ["Nowozin", "Sebastian", ""], ["Meeds", "Edward", ""], ["Turner", "Richard E.", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Gaunt", "Alexander L.", ""]]}, {"id": "1810.03964", "submitter": "Alhabib Abbas", "authors": "Mohammad Jubran, Alhabib Abbas, Aaron Chadha and Yiannis Andreopoulos", "title": "Rate-Accuracy Trade-Off In Video Classification With Deep Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced video classification systems decode video frames to derive the\nnecessary texture and motion representations for ingestion and analysis by\nspatio-temporal deep convolutional neural networks (CNNs). However, when\nconsidering visual Internet-of-Things applications, surveillance systems and\nsemantic crawlers of large video repositories, the video capture and the\nCNN-based semantic analysis parts do not tend to be co-located. This\nnecessitates the transport of compressed video over networks and incurs\nsignificant overhead in bandwidth and energy consumption, thereby significantly\nundermining the deployment potential of such systems. In this paper, we\ninvestigate the trade-off between the encoding bitrate and the achievable\naccuracy of CNN-based video classification models that directly ingest\nAVC/H.264 and HEVC encoded videos. Instead of retaining entire compressed video\nbitstreams and applying complex optical flow calculations prior to CNN\nprocessing, we only retain motion vector and select texture information at\nsignificantly-reduced bitrates and apply no additional processing prior to CNN\ningestion. Based on three CNN architectures and two action recognition\ndatasets, we achieve 11%-94% saving in bitrate with marginal effect on\nclassification accuracy. A model-based selection between multiple CNNs\nincreases these savings further, to the point where, if up to 7% loss of\naccuracy can be tolerated, video classification can take place with as little\nas 3 kbps for the transport of the required compressed video information to the\nsystem implementing the CNN models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 14:33:43 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 13:08:19 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Jubran", "Mohammad", ""], ["Abbas", "Alhabib", ""], ["Chadha", "Aaron", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1810.03969", "submitter": "Nicolo' Savioli", "authors": "Nicol\\'o Savioli, Miguel Silva Vieira, Pablo Lamata, Giovanni Montana", "title": "A Generative Adversarial Model for Right Ventricle Segmentation", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The clinical management of several cardiovascular conditions, such as\npulmonary hypertension, require the assessment of the right ventricular (RV)\nfunction. This work addresses the fully automatic and robust access to one of\nthe key RV biomarkers, its ejection fraction, from the gold standard imaging\nmodality, MRI. The problem becomes the accurate segmentation of the RV blood\npool from cine MRI sequences. This work proposes a solution based on Fully\nConvolutional Neural Networks (FCNN), where our first contribution is the\noptimal combination of three concepts (the convolution Gated Recurrent Units\n(GRU), the Generative Adversarial Networks (GAN), and the L1 loss function)\nthat achieves an improvement of 0.05 and 3.49 mm in Dice Index and Hausdorff\nDistance respectively with respect to the baseline FCNN. This improvement is\nthen doubled by our second contribution, the ROI-GAN, that sets two GANs to\ncooperate working at two fields of view of the image, its full resolution and\nthe region of interest (ROI). Our rationale here is to better guide the FCNN\nlearning by combining global (full resolution) and local Region Of Interest\n(ROI) features. The study is conducted in a large in-house dataset of $\\sim$\n23.000 segmented MRI slices, and its generality is verified in a publicly\navailable dataset.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 09:52:10 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Savioli", "Nicol\u00f3", ""], ["Vieira", "Miguel Silva", ""], ["Lamata", "Pablo", ""], ["Montana", "Giovanni", ""]]}, {"id": "1810.03982", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Paul Hand", "title": "Deep Decoder: Concise Image Representations from Untrained\n  Non-convolutional Networks", "comments": "International Conference on Learning Representations 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, in particular convolutional neural networks, have\nbecome highly effective tools for compressing images and solving inverse\nproblems including denoising, inpainting, and reconstruction from few and noisy\nmeasurements. This success can be attributed in part to their ability to\nrepresent and generate natural images well. Contrary to classical tools such as\nwavelets, image-generating deep neural networks have a large number of\nparameters---typically a multiple of their output dimension---and need to be\ntrained on large datasets. In this paper, we propose an untrained simple image\nmodel, called the deep decoder, which is a deep neural network that can\ngenerate natural images from very few weight parameters. The deep decoder has a\nsimple architecture with no convolutions and fewer weight parameters than the\noutput dimensionality. This underparameterization enables the deep decoder to\ncompress images into a concise set of network weights, which we show is on par\nwith wavelet-based thresholding. Further, underparameterization provides a\nbarrier to overfitting, allowing the deep decoder to have state-of-the-art\nperformance for denoising. The deep decoder is simple in the sense that each\nlayer has an identical structure that consists of only one upsampling unit,\npixel-wise linear combination of channels, ReLU activation, and channelwise\nnormalization. This simplicity makes the network amenable to theoretical\nanalysis, and it sheds light on the aspects of neural networks that enable them\nto form effective signal representations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:07:07 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 22:13:19 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Heckel", "Reinhard", ""], ["Hand", "Paul", ""]]}, {"id": "1810.03999", "submitter": "Dufan Wu", "authors": "Dufan Wu, Kyungsang Kim, and Quanzheng Li", "title": "Computationally Efficient Deep Neural Network for Computed Tomography\n  Image Reconstruction", "comments": "33 pages, 14 figures, accepted by Medical Physics", "journal-ref": null, "doi": "10.1002/mp.13627", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-neural-network-based image reconstruction has demonstrated promising\nperformance in medical imaging for under-sampled and low-dose scenarios.\nHowever, it requires large amount of memory and extensive time for the\ntraining. It is especially challenging to train the reconstruction networks for\nthree-dimensional computed tomography (CT) because of the high resolution of CT\nimages. The purpose of this work is to reduce the memory and time consumption\nof the training of the reconstruction networks for CT to make it practical for\ncurrent hardware, while maintaining the quality of the reconstructed images.\n  We unrolled the proximal gradient descent algorithm for iterative image\nreconstruction to finite iterations and replaced the terms related to the\npenalty function with trainable convolutional neural networks (CNN). The\nnetwork was trained greedily iteration by iteration in the image-domain on\npatches, which requires reasonable amount of memory and time on mainstream\ngraphics processing unit (GPU). To overcome the local-minimum problem caused by\ngreedy learning, we used deep UNet as the CNN and incorporated separable\nquadratic surrogate with ordered subsets for data fidelity, so that the\nsolution could escape from easy local minimums and achieve better image\nquality.\n  The proposed method achieved comparable image quality with state-of-the-art\nneural network for CT image reconstruction on 2D sparse-view and limited-angle\nproblems on the low-dose CT challenge dataset.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:26:39 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 15:50:20 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 03:25:59 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Wu", "Dufan", ""], ["Kim", "Kyungsang", ""], ["Li", "Quanzheng", ""]]}, {"id": "1810.04020", "submitter": "Md Zakir Hossain", "authors": "Md. Zakir Hossain, Ferdous Sohel, Mohd Fairuz Shiratuddin, Hamid Laga", "title": "A Comprehensive Survey of Deep Learning for Image Captioning", "comments": "36 Pages, Accepted as a Journal Paper in ACM Computing Surveys\n  (October 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating a description of an image is called image captioning. Image\ncaptioning requires to recognize the important objects, their attributes and\ntheir relationships in an image. It also needs to generate syntactically and\nsemantically correct sentences. Deep learning-based techniques are capable of\nhandling the complexities and challenges of image captioning. In this survey\npaper, we aim to present a comprehensive review of existing deep learning-based\nimage captioning techniques. We discuss the foundation of the techniques to\nanalyze their performances, strengths and limitations. We also discuss the\ndatasets and the evaluation metrics popularly used in deep learning based\nautomatic image captioning.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 16:31:52 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 04:55:06 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hossain", "Md. Zakir", ""], ["Sohel", "Ferdous", ""], ["Shiratuddin", "Mohd Fairuz", ""], ["Laga", "Hamid", ""]]}, {"id": "1810.04021", "submitter": "Neslisah Torosdagli", "authors": "Neslisah Torosdagli, Denise K. Liberton, Payal Verma, Murat Sincan,\n  Janice S. Lee, and Ulas Bagci", "title": "Deep Geodesic Learning for Segmentation and Anatomical Landmarking", "comments": "14 pages, 12 Figures, IEEE Transactions on Medical Imaging 2018,\n  TMI-2018-0898.R1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel deep learning framework for anatomy\nsegmentation and automatic landmark- ing. Specifically, we focus on the\nchallenging problem of mandible segmentation from cone-beam computed tomography\n(CBCT) scans and identification of 9 anatomical landmarks of the mandible on\nthe geodesic space. The overall approach employs three inter-related steps. In\nstep 1, we propose a deep neu- ral network architecture with carefully designed\nregularization, and network hyper-parameters to perform image segmentation\nwithout the need for data augmentation and complex post- processing refinement.\nIn step 2, we formulate the landmark localization problem directly on the\ngeodesic space for sparsely- spaced anatomical landmarks. In step 3, we propose\nto use a long short-term memory (LSTM) network to identify closely- spaced\nlandmarks, which is rather difficult to obtain using other standard detection\nnetworks. The proposed fully automated method showed superior efficacy compared\nto the state-of-the- art mandible segmentation and landmarking approaches in\ncraniofacial anomalies and diseased states. We used a very challenging CBCT\ndataset of 50 patients with a high-degree of craniomaxillofacial (CMF)\nvariability that is realistic in clinical practice. Complementary to the\nquantitative analysis, the qualitative visual inspection was conducted for\ndistinct CBCT scans from 250 patients with high anatomical variability. We have\nalso shown feasibility of the proposed work in an independent dataset from\nMICCAI Head-Neck Challenge (2015) achieving the state-of-the-art performance.\nLastly, we present an in-depth analysis of the proposed deep networks with\nrespect to the choice of hyper-parameters such as pooling and activation\nfunctions.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:37:39 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Torosdagli", "Neslisah", ""], ["Liberton", "Denise K.", ""], ["Verma", "Payal", ""], ["Sincan", "Murat", ""], ["Lee", "Janice S.", ""], ["Bagci", "Ulas", ""]]}, {"id": "1810.04028", "submitter": "Hao Zhang", "authors": "Hao Zhang, Jianwei Ma", "title": "Hartley Spectral Pooling for Deep Learning", "comments": "5 pages, 6 figures, letter", "journal-ref": "CSIAM Transactions on Applied Mathematics, 2020, 1(3):518-529", "doi": "10.4208/csiam-am.2020", "report-no": null, "categories": "cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most convolution neural networks (CNNs), downsampling hidden layers is\nadopted for increasing computation efficiency and the receptive field size.\nSuch operation is commonly so-called pooling. Maximation and averaging over\nsliding windows (max/average pooling), and plain downsampling in the form of\nstrided convolution are popular pooling methods. Since the pooling is a lossy\nprocedure, a motivation of our work is to design a new pooling approach for\nless lossy in the dimensionality reduction. Inspired by the Fourier spectral\npooling(FSP) proposed by Rippel et. al. [1], we present the Hartley transform\nbased spectral pooling method in CNNs. Compared with FSP, the proposed spectral\npooling avoids the use of complex arithmetic for frequency representation and\nreduces the computation. Spectral pooling preserves more structure features for\nnetwork's discriminability than max and average pooling. We empirically show\nthat Hartley spectral pooling gives rise to the convergence of training CNNs on\nMNIST and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 06:57:01 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 20:05:06 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhang", "Hao", ""], ["Ma", "Jianwei", ""]]}, {"id": "1810.04038", "submitter": "Ming Zeng", "authors": "Ming Zeng, Haoxiang Gao, Tong Yu, Ole J. Mengshoel, Helge Langseth,\n  Ian Lane, Xiaobing Liu", "title": "Understanding and Improving Recurrent Networks for Human Activity\n  Recognition by Continuous Attention", "comments": "8 pages. published in The International Symposium on Wearable\n  Computers (ISWC) 2018", "journal-ref": "The International Symposium on Wearable Computers (ISWC) 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, including recurrent networks, have been successfully\napplied to human activity recognition. Unfortunately, the final representation\nlearned by recurrent networks might encode some noise (irrelevant signal\ncomponents, unimportant sensor modalities, etc.). Besides, it is difficult to\ninterpret the recurrent networks to gain insight into the models' behavior. To\naddress these issues, we propose two attention models for human activity\nrecognition: temporal attention and sensor attention. These two mechanisms\nadaptively focus on important signals and sensor modalities. To further improve\nthe understandability and mean F1 score, we add continuity constraints,\nconsidering that continuous sensor signals are more robust than discrete ones.\nWe evaluate the approaches on three datasets and obtain state-of-the-art\nresults. Furthermore, qualitative analysis shows that the attention learned by\nthe models agree well with human intuition.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 21:24:19 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zeng", "Ming", ""], ["Gao", "Haoxiang", ""], ["Yu", "Tong", ""], ["Mengshoel", "Ole J.", ""], ["Langseth", "Helge", ""], ["Lane", "Ian", ""], ["Liu", "Xiaobing", ""]]}, {"id": "1810.04045", "submitter": "Eric Nalisnick", "authors": "Eric Nalisnick, Jos\\'e Miguel Hern\\'andez-Lobato, Padhraic Smyth", "title": "Dropout as a Structured Shrinkage Prior", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout regularization of deep neural networks has been a mysterious yet\neffective tool to prevent overfitting. Explanations for its success range from\nthe prevention of \"co-adapted\" weights to it being a form of cheap Bayesian\ninference. We propose a novel framework for understanding multiplicative noise\nin neural networks, considering continuous distributions as well as Bernoulli\nnoise (i.e. dropout). We show that multiplicative noise induces structured\nshrinkage priors on a network's weights. We derive the equivalence through\nreparametrization properties of scale mixtures and without invoking any\napproximations. Given the equivalence, we then show that dropout's Monte Carlo\ntraining objective approximates marginal MAP estimation. We leverage these\ninsights to propose a novel shrinkage framework for resnets, terming the prior\n'automatic depth determination' as it is the natural analog of automatic\nrelevance determination for network depth. Lastly, we investigate two inference\nstrategies that improve upon the aforementioned MAP approximation in regression\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 14:44:08 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 14:35:37 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 14:01:20 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Nalisnick", "Eric", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Smyth", "Padhraic", ""]]}, {"id": "1810.04064", "submitter": "Miao Cheng", "authors": "Miao Cheng, Zunren Liu, Hongwei Zou, Ah Chung Tsoi", "title": "A Family of Maximum Margin Criterion for Adaptive Learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, pattern analysis plays an important role in data mining and\nrecognition, and many variants have been proposed to handle complicated\nscenarios. In the literature, it has been quite familiar with high\ndimensionality of data samples, but either such characteristics or large data\nhave become usual sense in real-world applications. In this work, an improved\nmaximum margin criterion (MMC) method is introduced firstly. With the new\ndefinition of MMC, several variants of MMC, including random MMC, layered MMC,\n2D^2 MMC, are designed to make adaptive learning applicable. Particularly, the\nMMC network is developed to learn deep features of images in light of simple\ndeep networks. Experimental results on a diversity of data sets demonstrate the\ndiscriminant ability of proposed MMC methods are compenent to be adopted in\ncomplicated application scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:45:53 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 02:47:47 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Cheng", "Miao", ""], ["Liu", "Zunren", ""], ["Zou", "Hongwei", ""], ["Tsoi", "Ah Chung", ""]]}, {"id": "1810.04065", "submitter": "Elvis Dohmatob", "authors": "Elvis Dohmatob", "title": "Generalized No Free Lunch Theorem for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This manuscript presents some new impossibility results on adversarial\nrobustness in machine learning, a very important yet largely open problem. We\nshow that if conditioned on a class label the data distribution satisfies the\n$W_2$ Talagrand transportation-cost inequality (for example, this condition is\nsatisfied if the conditional distribution has density which is log-concave; is\nthe uniform measure on a compact Riemannian manifold with positive Ricci\ncurvature, any classifier can be adversarially fooled with high probability\nonce the perturbations are slightly greater than the natural noise level in the\nproblem. We call this result The Strong \"No Free Lunch\" Theorem as some recent\nresults (Tsipras et al. 2018, Fawzi et al. 2018, etc.) on the subject can be\nimmediately recovered as very particular cases. Our theoretical bounds are\ndemonstrated on both simulated and real data (MNIST). We conclude the\nmanuscript with some speculation on possible future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 10:13:48 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 18:11:23 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 17:13:27 GMT"}, {"version": "v4", "created": "Tue, 13 Nov 2018 09:51:02 GMT"}, {"version": "v5", "created": "Tue, 11 Dec 2018 19:11:52 GMT"}, {"version": "v6", "created": "Fri, 1 Feb 2019 05:57:34 GMT"}, {"version": "v7", "created": "Mon, 22 Apr 2019 12:43:00 GMT"}, {"version": "v8", "created": "Tue, 4 Jun 2019 04:39:09 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Dohmatob", "Elvis", ""]]}, {"id": "1810.04066", "submitter": "Pashupati Hegde", "authors": "Pashupati Hegde, Markus Heinonen, Harri L\\\"ahdesm\\\"aki, Samuel Kaski", "title": "Deep learning with differential Gaussian process flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel deep learning paradigm of differential flows that learn a\nstochastic differential equation transformations of inputs prior to a standard\nclassification or regression function. The key property of differential\nGaussian processes is the warping of inputs through infinitely deep, but\ninfinitesimal, differential fields, that generalise discrete layers into a\ndynamical system. We demonstrate state-of-the-art results that exceed the\nperformance of deep Gaussian processes and neural networks\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 15:15:23 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 11:46:33 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hegde", "Pashupati", ""], ["Heinonen", "Markus", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""], ["Kaski", "Samuel", ""]]}, {"id": "1810.04088", "submitter": "Thomas Nedelec", "authors": "R\\'emy Degenne, Thomas Nedelec, Cl\\'ement Calauz\\`enes and Vianney\n  Perchet", "title": "Bridging the gap between regret minimization and best arm\n  identification, with application to A/B tests", "comments": null, "journal-ref": "AISTATS 2019 proceedings", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art online learning procedures focus either on selecting the\nbest alternative (\"best arm identification\") or on minimizing the cost (the\n\"regret\"). We merge these two objectives by providing the theoretical analysis\nof cost minimizing algorithms that are also delta-PAC (with a proven guaranteed\nbound on the decision time), hence fulfilling at the same time regret\nminimization and best arm identification. This analysis sheds light on the\ncommon observation that ill-callibrated UCB-algorithms minimize regret while\nstill identifying quickly the best arm.\n  We also extend these results to the non-iid case faced by many practitioners.\nThis provides a technique to make cost versus decision time compromise when\ndoing adaptive tests with applications ranging from website A/B testing to\nclinical trials.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 15:45:10 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 08:14:09 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Degenne", "R\u00e9my", ""], ["Nedelec", "Thomas", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""], ["Perchet", "Vianney", ""]]}, {"id": "1810.04106", "submitter": "Fei Wang", "authors": "Fei Wang, Jinsong Han, Feng Lin, Kui Ren", "title": "WiPIN: Operation-free Passive Person Identification Using Wi-Fi Signals", "comments": "accepted by GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wi-Fi signals-based person identification attracts increasing attention in\nthe booming Internet-of-Things era mainly due to its pervasiveness and\npassiveness. Most previous work applies gaits extracted from WiFi distortions\ncaused by the person walking to achieve the identification. However, to extract\nuseful gait, a person must walk along a pre-defined path for several meters,\nwhich requires user high collaboration and increases identification time\noverhead, thus limiting use scenarios. Moreover, gait based work has severe\nshortcoming in identification performance, especially when the user volume is\nlarge. In order to eliminate the above limitations, in this paper, we present\nan operation-free person identification system, namely WiPIN, that requires\nleast user collaboration and achieves good performance. WiPIN is based on an\nentirely new insight that Wi-Fi signals would carry person body information\nwhen propagating through the body, which is potentially discriminated for\nperson identification. Then we demonstrate the feasibility on commodity\noff-the-shelf Wi-Fi devices by well-designed signal pre-processing, feature\nextraction, and identity matching algorithms. Results show that WiPIN achieves\n92% identification accuracy over 30 users, high robustness to various\nexperimental settings, and low identifying time overhead, i.e., less than\n300ms.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 02:17:07 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 19:22:42 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Wang", "Fei", ""], ["Han", "Jinsong", ""], ["Lin", "Feng", ""], ["Ren", "Kui", ""]]}, {"id": "1810.04114", "submitter": "Ksenia Konyushkova", "authors": "Ksenia Konyushkova and Raphael Sznitman and Pascal Fua", "title": "Discovering General-Purpose Active Learning Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general-purpose approach to discovering active learning (AL)\nstrategies from data. These strategies are transferable from one domain to\nanother and can be used in conjunction with many machine learning models. To\nthis end, we formalize the annotation process as a Markov decision process,\ndesign universal state and action spaces and introduce a new reward function\nthat precisely model the AL objective of minimizing the annotation cost. We\nseek to find an optimal (non-myopic) AL strategy using reinforcement learning.\nWe evaluate the learned strategies on multiple unrelated domains and show that\nthey consistently outperform state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:40:02 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 10:53:33 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Konyushkova", "Ksenia", ""], ["Sznitman", "Raphael", ""], ["Fua", "Pascal", ""]]}, {"id": "1810.04115", "submitter": "Nick Whiteley Prof.", "authors": "Nick Whiteley, Matt W. Jones and Aleks P.F. Domanski", "title": "The Viterbi process, decay-convexity and parallelized maximum\n  a-posteriori estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Viterbi process is the limiting maximum a-posteriori estimate of the\nunobserved path in a hidden Markov model as the length of the time horizon\ngrows. The existence of such a process suggests that approximate estimation\nusing optimization algorithms which process data segments in parallel may be\naccurate. For models on state-space $\\mathbb{R}^{d}$ satisfying a new\n\"decay-convexity\" condition, we develop an approach to existence of the Viterbi\nprocess via fixed points of ordinary differential equations in a certain\ninfinite dimensional Hilbert space. Bounds on the distance to the Viterbi\nprocess show that approximate estimation via parallelization can indeed be\naccurate and scaleable to high-dimensional problems because the rate of\nconvergence to the Viterbi process does not necessarily depend on $d$. The\nresults are applied to a factor model with stochastic volatility and a model of\nneural population activity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:17:21 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 12:34:27 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 09:35:41 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2019 18:24:59 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Whiteley", "Nick", ""], ["Jones", "Matt W.", ""], ["Domanski", "Aleks P. F.", ""]]}, {"id": "1810.04122", "submitter": "Jennifer John", "authors": "Jennifer N. John, Conner Galloway, Alexander Valys", "title": "Deep Convolutional Neural Networks for Noise Detection in ECGs", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile electrocardiogram (ECG) recording technologies represent a promising\ntool to fight the ongoing epidemic of cardiovascular diseases, which are\nresponsible for more deaths globally than any other cause. While the ability to\nmonitor one's heart activity at any time in any place is a crucial advantage of\nsuch technologies, it is also the cause of a drawback: signal noise due to\nenvironmental factors can render the ECGs illegible. In this work, we develop\nconvolutional neural networks (CNNs) to automatically label ECGs for noise,\ntraining them on a novel noise-annotated dataset. By reducing distraction from\nnoisy intervals of signals, such networks have the potential to increase the\naccuracy of models for the detection of atrial fibrillation, long QT syndrome,\nand other cardiovascular conditions. Comparing several architectures, we find\nthat a 16-layer CNN adapted from the VGG16 network which generates one\nprediction per second on a 10-second input performs exceptionally well on this\ntask, with an AUC of 0.977.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 02:59:04 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["John", "Jennifer N.", ""], ["Galloway", "Conner", ""], ["Valys", "Alexander", ""]]}, {"id": "1810.04133", "submitter": "Weihao Gao", "authors": "Weihao Gao, Ashok Vardhan Makkuva, Sewoong Oh, Pramod Viswanath", "title": "Learning One-hidden-layer Neural Networks under General Input\n  Distributions", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made recently on training neural networks,\nwhere the main challenge is in solving an optimization problem with abundant\ncritical points. However, existing approaches to address this issue crucially\nrely on a restrictive assumption: the training data is drawn from a Gaussian\ndistribution. In this paper, we provide a novel unified framework to design\nloss functions with desirable landscape properties for a wide range of general\ninput distributions. On these loss functions, remarkably, stochastic gradient\ndescent theoretically recovers the true parameters with global initializations\nand empirically outperforms the existing approaches. Our loss function design\nbridges the notion of score functions with the topic of neural network\noptimization. Central to our approach is the task of estimating the score\nfunction from samples, which is of basic and independent interest to\ntheoretical statistics. Traditional estimation methods (example: kernel based)\nfail right at the outset; we bring statistical methods of local likelihood to\ndesign a novel estimator of score functions, that provably adapts to the local\ngeometry of the unknown density.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 16:58:33 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 21:52:06 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Gao", "Weihao", ""], ["Makkuva", "Ashok Vardhan", ""], ["Oh", "Sewoong", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1810.04147", "submitter": "Yogesh Balaji", "authors": "Yogesh Balaji, Hamed Hassani, Rama Chellappa and Soheil Feizi", "title": "Entropic GANs meet VAEs: A Statistical Approach to Compute Sample\n  Likelihoods in GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the success of deep learning, two modern approaches to learn a\nprobability model from the data are Generative Adversarial Networks (GANs) and\nVariational AutoEncoders (VAEs). VAEs consider an explicit probability model\nfor the data and compute a generative distribution by maximizing a variational\nlower-bound on the log-likelihood function. GANs, however, compute a generative\nmodel by minimizing a distance between observed and generated probability\ndistributions without considering an explicit model for the observed data. The\nlack of having explicit probability models in GANs prohibits computation of\nsample likelihoods in their frameworks and limits their use in statistical\ninference problems. In this work, we resolve this issue by constructing an\nexplicit probability model that can be used to compute sample likelihood\nstatistics in GANs. In particular, we prove that under this probability model,\na family of Wasserstein GANs with an entropy regularization can be viewed as a\ngenerative model that maximizes a variational lower-bound on average sample log\nlikelihoods, an approach that VAEs are based on. This result makes a principled\nconnection between two modern generative models, namely GANs and VAEs. In\naddition to the aforementioned theoretical results, we compute likelihood\nstatistics for GANs trained on Gaussian, MNIST, SVHN, CIFAR-10 and LSUN\ndatasets. Our numerical results validate the proposed theory.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 17:27:20 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 05:22:08 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Balaji", "Yogesh", ""], ["Hassani", "Hamed", ""], ["Chellappa", "Rama", ""], ["Feizi", "Soheil", ""]]}, {"id": "1810.04152", "submitter": "George Tucker", "authors": "George Tucker, Dieterich Lawson, Shixiang Gu, Chris J. Maddison", "title": "Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models have become a popular model choice due to the\nscalable learning algorithms introduced by (Kingma & Welling, 2013; Rezende et\nal., 2014). These approaches maximize a variational lower bound on the\nintractable log likelihood of the observed data. Burda et al. (2015) introduced\na multi-sample variational bound, IWAE, that is at least as tight as the\nstandard variational lower bound and becomes increasingly tight as the number\nof samples increases. Counterintuitively, the typical inference network\ngradient estimator for the IWAE bound performs poorly as the number of samples\nincreases (Rainforth et al., 2018; Le et al., 2018). Roeder et al. (2017)\npropose an improved gradient estimator, however, are unable to show it is\nunbiased. We show that it is in fact biased and that the bias can be estimated\nefficiently with a second application of the reparameterization trick. The\ndoubly reparameterized gradient (DReG) estimator does not suffer as the number\nof samples increases, resolving the previously raised issues. The same idea can\nbe used to improve many recently introduced training techniques for latent\nvariable models. In particular, we show that this estimator reduces the\nvariance of the IWAE gradient, the reweighted wake-sleep update (RWS)\n(Bornschein & Bengio, 2014), and the jackknife variational inference (JVI)\ngradient (Nowozin, 2018). Finally, we show that this computationally efficient,\nunbiased drop-in gradient estimator translates to improved performance for all\nthree objectives on several modeling tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 17:46:55 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 18:40:45 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Tucker", "George", ""], ["Lawson", "Dieterich", ""], ["Gu", "Shixiang", ""], ["Maddison", "Chris J.", ""]]}, {"id": "1810.04160", "submitter": "Myung Seok Shim", "authors": "Myung Seok Shim, Peng Li", "title": "Optimized Gated Deep Learning Architectures for Sensor Fusion", "comments": "10 pages, 5 figures. Submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor fusion is a key technology that integrates various sensory inputs to\nallow for robust decision making in many applications such as autonomous\ndriving and robot control. Deep neural networks have been adopted for sensor\nfusion in a body of recent studies. Among these, the so-called netgated\narchitecture was proposed, which has demonstrated improved performances over\nthe conventional convolutional neural networks (CNN). In this paper, we address\nseveral limitations of the baseline negated architecture by proposing two\nfurther optimized architectures: a coarser-grained gated architecture employing\n(feature) group-level fusion weights and a two-stage gated architectures\nleveraging both the group-level and feature level fusion weights. Using driving\nmode prediction and human activity recognition datasets, we demonstrate the\nsignificant performance improvements brought by the proposed gated\narchitectures and also their robustness in the presence of sensor noise and\nfailures.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:24:12 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Shim", "Myung Seok", ""], ["Li", "Peng", ""]]}, {"id": "1810.04227", "submitter": "Chris Cantwell", "authors": "Chris D. Cantwell, Yumnah Mohamied, Konstantinos N. Tzortzis, Stef\n  Garasto, Charles Houston, Rasheda A. Chowdhury, Fu Siong Ng, Anil A. Bharath,\n  Nicholas S. Peters", "title": "Rethinking multiscale cardiac electrophysiology with machine learning\n  and predictive modelling", "comments": null, "journal-ref": null, "doi": "10.1016/j.compbiomed.2018.10.015", "report-no": null, "categories": "cs.LG math.DS q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some of the latest approaches to analysing cardiac\nelectrophysiology data using machine learning and predictive modelling. Cardiac\narrhythmias, particularly atrial fibrillation, are a major global healthcare\nchallenge. Treatment is often through catheter ablation, which involves the\ntargeted localized destruction of regions of the myocardium responsible for\ninitiating or perpetuating the arrhythmia. Ablation targets are either\nanatomically defined, or identified based on their functional properties as\ndetermined through the analysis of contact intracardiac electrograms acquired\nwith increasing spatial density by modern electroanatomic mapping systems.\nWhile numerous quantitative approaches have been investigated over the past\ndecades for identifying these critical curative sites, few have provided a\nreliable and reproducible advance in success rates. Machine learning\ntechniques, including recent deep-learning approaches, offer a potential route\nto gaining new insight from this wealth of highly complex spatio-temporal\ninformation that existing methods struggle to analyse. Coupled with predictive\nmodelling, these techniques offer exciting opportunities to advance the field\nand produce more accurate diagnoses and robust personalised treatment. We\noutline some of these methods and illustrate their use in making predictions\nfrom the contact electrogram and augmenting predictive modelling tools, both by\nmore rapidly predicting future states of the system and by inferring the\nparameters of these models from experimental observations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 20:09:45 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Cantwell", "Chris D.", ""], ["Mohamied", "Yumnah", ""], ["Tzortzis", "Konstantinos N.", ""], ["Garasto", "Stef", ""], ["Houston", "Charles", ""], ["Chowdhury", "Rasheda A.", ""], ["Ng", "Fu Siong", ""], ["Bharath", "Anil A.", ""], ["Peters", "Nicholas S.", ""]]}, {"id": "1810.04240", "submitter": "Kyle Julian", "authors": "Kyle D. Julian and Mykel J. Kochenderfer and Michael P. Owen", "title": "Deep Neural Network Compression for Aircraft Collision Avoidance Systems", "comments": null, "journal-ref": null, "doi": "10.2514/1.G003724", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One approach to designing decision making logic for an aircraft collision\navoidance system frames the problem as a Markov decision process and optimizes\nthe system using dynamic programming. The resulting collision avoidance\nstrategy can be represented as a numeric table. This methodology has been used\nin the development of the Airborne Collision Avoidance System X (ACAS X) family\nof collision avoidance systems for manned and unmanned aircraft, but the high\ndimensionality of the state space leads to very large tables. To improve\nstorage efficiency, a deep neural network is used to approximate the table.\nWith the use of an asymmetric loss function and a gradient descent algorithm,\nthe parameters for this network can be trained to provide accurate estimates of\ntable values while preserving the relative preferences of the possible\nadvisories for each state. By training multiple networks to represent\nsubtables, the network also decreases the required runtime for computing the\ncollision avoidance advisory. Simulation studies show that the network improves\nthe safety and efficiency of the collision avoidance system. Because only the\nnetwork parameters need to be stored, the required storage space is reduced by\na factor of 1000, enabling the collision avoidance system to operate using\ncurrent avionics systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:02:48 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Julian", "Kyle D.", ""], ["Kochenderfer", "Mykel J.", ""], ["Owen", "Michael P.", ""]]}, {"id": "1810.04246", "submitter": "Mohammed Jabi", "authors": "Mohammed Jabi, Marco Pedersoli, Amar Mitiche and Ismail Ben Ayed", "title": "Deep clustering: On the link between discriminative models and K-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of recent deep clustering studies, discriminative models\ndominate the literature and report the most competitive performances. These\nmodels learn a deep discriminative neural network classifier in which the\nlabels are latent. Typically, they use multinomial logistic regression\nposteriors and parameter regularization, as is very common in supervised\nlearning. It is generally acknowledged that discriminative objective functions\n(e.g., those based on the mutual information or the KL divergence) are more\nflexible than generative approaches (e.g., K-means) in the sense that they make\nfewer assumptions about the data distributions and, typically, yield much\nbetter unsupervised deep learning results. On the surface, several recent\ndiscriminative models may seem unrelated to K-means. This study shows that\nthese models are, in fact, equivalent to K-means under mild conditions and\ncommon posterior models and parameter regularization. We prove that, for the\ncommonly used logistic regression posteriors, maximizing the $L_2$ regularized\nmutual information via an approximate alternating direction method (ADM) is\nequivalent to a soft and regularized K-means loss. Our theoretical analysis not\nonly connects directly several recent state-of-the-art discriminative models to\nK-means, but also leads to a new soft and regularized deep K-means algorithm,\nwhich yields competitive performance on several image clustering benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:17:09 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 23:28:05 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Jabi", "Mohammed", ""], ["Pedersoli", "Marco", ""], ["Mitiche", "Amar", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "1810.04247", "submitter": "Ofir Lindenbaum", "authors": "Yutaro Yamada and Ofir Lindenbaum and Sahand Negahban and Yuval Kluger", "title": "Feature Selection using Stochastic Gates", "comments": "Published in ICML 2020", "journal-ref": "Proceedings of Machine Learning and Systems 2020, pages 8952--8963", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Feature selection problems have been extensively studied for linear\nestimation, for instance, Lasso, but less emphasis has been placed on feature\nselection for non-linear functions. In this study, we propose a method for\nfeature selection in high-dimensional non-linear function estimation problems.\nThe new procedure is based on minimizing the $\\ell_0$ norm of the vector of\nindicator variables that represent if a feature is selected or not. Our\napproach relies on the continuous relaxation of Bernoulli distributions, which\nallows our model to learn the parameters of the approximate Bernoulli\ndistributions via gradient descent. This general framework simultaneously\nminimizes a loss function while selecting relevant features. Furthermore, we\nprovide an information-theoretic justification of incorporating Bernoulli\ndistribution into our approach and demonstrate the potential of the approach on\nsynthetic and real-life applications.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:17:37 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 01:24:37 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 21:53:19 GMT"}, {"version": "v4", "created": "Sun, 13 Oct 2019 15:25:53 GMT"}, {"version": "v5", "created": "Thu, 5 Dec 2019 20:17:40 GMT"}, {"version": "v6", "created": "Thu, 12 Mar 2020 22:10:57 GMT"}, {"version": "v7", "created": "Sun, 26 Jul 2020 15:45:08 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yamada", "Yutaro", ""], ["Lindenbaum", "Ofir", ""], ["Negahban", "Sahand", ""], ["Kluger", "Yuval", ""]]}, {"id": "1810.04249", "submitter": "Raj Agrawal", "authors": "Raj Agrawal, Trevor Campbell, Jonathan H. Huggins, Tamara Broderick", "title": "Data-dependent compression of random features for large-scale kernel\n  approximation", "comments": "24 pages, 8 figures, to appear in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods offer the flexibility to learn complex relationships in\nmodern, large data sets while enjoying strong theoretical guarantees on\nquality. Unfortunately, these methods typically require cubic running time in\nthe data set size, a prohibitive cost in the large-data setting. Random feature\nmaps (RFMs) and the Nystrom method both consider low-rank approximations to the\nkernel matrix as a potential solution. But, in order to achieve desirable\ntheoretical guarantees, the former may require a prohibitively large number of\nfeatures J+, and the latter may be prohibitively expensive for high-dimensional\nproblems. We propose to combine the simplicity and generality of RFMs with a\ndata-dependent feature selection scheme to achieve desirable theoretical\napproximation properties of Nystrom with just O(log J+) features. Our key\ninsight is to begin with a large set of random features, then reduce them to a\nsmall number of weighted features in a data-dependent, computationally\nefficient way, while preserving the statistical guarantees of using the\noriginal large set of features. We demonstrate the efficacy of our method with\ntheory and experiments--including on a data set with over 50 million\nobservations. In particular, we show that our method achieves small kernel\nmatrix approximation error and better test set accuracy with provably fewer\nrandom features than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:20:41 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 02:17:38 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Agrawal", "Raj", ""], ["Campbell", "Trevor", ""], ["Huggins", "Jonathan H.", ""], ["Broderick", "Tamara", ""]]}, {"id": "1810.04261", "submitter": "Ruiqi Gao", "authors": "Ying Nian Wu, Ruiqi Gao, Tian Han, Song-Chun Zhu", "title": "A Tale of Three Probabilistic Families: Discriminative, Descriptive and\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pattern theory of Grenander is a mathematical framework where patterns\nare represented by probability models on random variables of algebraic\nstructures. In this paper, we review three families of probability models,\nnamely, the discriminative models, the descriptive models, and the generative\nmodels. A discriminative model is in the form of a classifier. It specifies the\nconditional probability of the class label given the input signal. A\ndescriptive model specifies the probability distribution of the signal, based\non an energy function defined on the signal. A generative model assumes that\nthe signal is generated by some latent variables via a transformation. We shall\nreview these models within a common framework and explore their connections. We\nshall also review the recent developments that take advantage of the high\napproximation capacities of deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 21:54:54 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 00:33:15 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Wu", "Ying Nian", ""], ["Gao", "Ruiqi", ""], ["Han", "Tian", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1810.04303", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Dorsa Sadigh", "title": "Batch Active Preference-Based Learning of Reward Functions", "comments": "Proceedings of the 2nd Conference on Robot Learning (CoRL), October\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data generation and labeling are usually an expensive part of learning for\nrobotics. While active learning methods are commonly used to tackle the former\nproblem, preference-based learning is a concept that attempts to solve the\nlatter by querying users with preference questions. In this paper, we will\ndevelop a new algorithm, batch active preference-based learning, that enables\nefficient learning of reward functions using as few data samples as possible\nwhile still having short query generation times. We introduce several\napproximations to the batch active learning problem, and provide theoretical\nguarantees for the convergence of our algorithms. Finally, we present our\nexperimental results for a variety of robotics tasks in simulation. Our results\nsuggest that our batch active learning algorithm requires only a few queries\nthat are computed in a short amount of time. We then showcase our algorithm in\na study to learn human users' preferences.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:02:55 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1810.04304", "submitter": "G Reina", "authors": "Micah J Sheller, G Anthony Reina, Brandon Edwards, Jason Martin, and\n  Spyridon Bakas", "title": "Multi-Institutional Deep Learning Modeling Without Sharing Patient Data:\n  A Feasibility Study on Brain Tumor Segmentation", "comments": "MICCAI, Brain Lesion (BrainLes) workshop, September 16, 2018,\n  Granada, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models for semantic segmentation of images require large\namounts of data. In the medical imaging domain, acquiring sufficient data is a\nsignificant challenge. Labeling medical image data requires expert knowledge.\nCollaboration between institutions could address this challenge, but sharing\nmedical data to a centralized location faces various legal, privacy, technical,\nand data-ownership challenges, especially among international institutions. In\nthis study, we introduce the first use of federated learning for\nmulti-institutional collaboration, enabling deep learning modeling without\nsharing patient data. Our quantitative results demonstrate that the performance\nof federated semantic segmentation models (Dice=0.852) on multimodal brain\nscans is similar to that of models trained by sharing data (Dice=0.862). We\ncompare federated learning with two alternative collaborative learning methods\nand find that they fail to match the performance of federated learning.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:05:44 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 18:51:38 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sheller", "Micah J", ""], ["Reina", "G Anthony", ""], ["Edwards", "Brandon", ""], ["Martin", "Jason", ""], ["Bakas", "Spyridon", ""]]}, {"id": "1810.04327", "submitter": "Takashi Ishida", "authors": "Takashi Ishida, Gang Niu, Aditya Krishna Menon, Masashi Sugiyama", "title": "Complementary-Label Learning for Arbitrary Losses and Models", "comments": "accepted to ICML 2019 (Added errata on Nov. 19, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to the standard classification paradigm where the true class is\ngiven to each training pattern, complementary-label learning only uses training\npatterns each equipped with a complementary label, which only specifies one of\nthe classes that the pattern does not belong to. The goal of this paper is to\nderive a novel framework of complementary-label learning with an unbiased\nestimator of the classification risk, for arbitrary losses and models---all\nexisting methods have failed to achieve this goal. Not only is this beneficial\nfor the learning stage, it also makes model/hyper-parameter selection (through\ncross-validation) possible without the need of any ordinarily labeled\nvalidation data, while using any linear/non-linear models or convex/non-convex\nloss functions. We further improve the risk estimator by a non-negative\ncorrection and gradient ascent trick, and demonstrate its superiority through\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 01:52:43 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 12:21:06 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 05:55:54 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2019 00:11:04 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Ishida", "Takashi", ""], ["Niu", "Gang", ""], ["Menon", "Aditya Krishna", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1810.04336", "submitter": "Sharan Vaswani", "authors": "Mohamed Osama Ahmed, Sharan Vaswani, Mark Schmidt", "title": "Combining Bayesian Optimization and Lipschitz Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization and Lipschitz optimization have developed alternative\ntechniques for optimizing black-box functions. They each exploit a different\nform of prior about the function. In this work, we explore strategies to\ncombine these techniques for better global optimization. In particular, we\npropose ways to use the Lipschitz continuity assumption within traditional BO\nalgorithms, which we call Lipschitz Bayesian optimization (LBO). This approach\ndoes not increase the asymptotic runtime and in some cases drastically improves\nthe performance (while in the worst-case the performance is similar). Indeed,\nin a particular setting, we prove that using the Lipschitz information yields\nthe same or a better bound on the regret compared to using Bayesian\noptimization on its own. Moreover, we propose a simple heuristics to estimate\nthe Lipschitz constant, and prove that a growing estimate of the Lipschitz\nconstant is in some sense ``harmless''. Our experiments on 15 datasets with 4\nacquisition functions show that in the worst case LBO performs similar to the\nunderlying BO method while in some cases it performs substantially better.\nThompson sampling in particular typically saw drastic improvements (as the\nLipschitz information corrected for its well-known ``over-exploration''\nphenomenon) and its LBO variant often outperformed other acquisition functions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 02:26:02 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 16:34:33 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Ahmed", "Mohamed Osama", ""], ["Vaswani", "Sharan", ""], ["Schmidt", "Mark", ""]]}, {"id": "1810.04361", "submitter": "Shrinu Kushagra", "authors": "Shrinu Kushagra, Shai Ben-David, Ihab Ilyas", "title": "Semi-supervised clustering for de-duplication", "comments": null, "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019", "doi": null, "report-no": "PMLR 89:1659-1667, 2019", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data de-duplication is the task of detecting multiple records that correspond\nto the same real-world entity in a database. In this work, we view\nde-duplication as a clustering problem where the goal is to put records\ncorresponding to the same physical entity in the same cluster and putting\nrecords corresponding to different physical entities into different clusters.\n  We introduce a framework which we call promise correlation clustering. Given\na complete graph $G$ with the edges labelled $0$ and $1$, the goal is to find a\nclustering that minimizes the number of $0$ edges within a cluster plus the\nnumber of $1$ edges across different clusters (or correlation loss). The\noptimal clustering can also be viewed as a complete graph $G^*$ with edges\ncorresponding to points in the same cluster being labelled $0$ and other edges\nbeing labelled $1$. Under the promise that the edge difference between $G$ and\n$G^*$ is \"small\", we prove that finding the optimal clustering (or $G^*$) is\nstill NP-Hard. [Ashtiani et. al, 2016] introduced the framework of\nsemi-supervised clustering, where the learning algorithm has access to an\noracle, which answers whether two points belong to the same or different\nclusters. We further prove that even with access to a same-cluster oracle, the\npromise version is NP-Hard as long as the number queries to the oracle is not\ntoo large ($o(n)$ where $n$ is the number of vertices).\n  Given these negative results, we consider a restricted version of correlation\nclustering. As before, the goal is to find a clustering that minimizes the\ncorrelation loss. However, we restrict ourselves to a given class $\\mathcal F$\nof clusterings. We offer a semi-supervised algorithmic approach to solve the\nrestricted variant with success guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 04:12:50 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Kushagra", "Shrinu", ""], ["Ben-David", "Shai", ""], ["Ilyas", "Ihab", ""]]}, {"id": "1810.04374", "submitter": "Yitong Sun", "authors": "Yitong Sun, Anna Gilbert, Ambuj Tewari", "title": "On the Approximation Properties of Random ReLU Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation properties of random ReLU features through their\nreproducing kernel Hilbert space (RKHS). We first prove a universality theorem\nfor the RKHS induced by random features whose feature maps are of the form of\nnodes in neural networks. The universality result implies that the random ReLU\nfeatures method is a universally consistent learning algorithm. We prove that\ndespite the universality of the RKHS induced by the random ReLU features,\ncomposition of functions in it generates substantially more complicated\nfunctions that are harder to approximate than those functions simply in the\nRKHS. We also prove that such composite functions can be efficiently\napproximated by multi-layer ReLU networks with bounded weights. This depth\nseparation result shows that the random ReLU features models suffer from the\nsame weakness as that of shallow models. We show in experiments that the\nperformance of random ReLU features is comparable to that of random Fourier\nfeatures and, in general, has a lower computational cost. We also demonstrate\nthat when the target function is the composite function as described in the\ndepth separation theorem, 3-layer neural networks indeed outperform both random\nReLU features and 2-layer neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 04:58:45 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 17:31:38 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 05:16:46 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sun", "Yitong", ""], ["Gilbert", "Anna", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1810.04416", "submitter": "Zheyang Shen", "authors": "Zheyang Shen, Markus Heinonen, Samuel Kaski", "title": "Harmonizable mixture kernels with variational Fourier features", "comments": "18 pages, 5 figures", "journal-ref": "Proceedings of Machine Learning Research (PMLR) 2019, vol. 89:\n  3273-3282", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressive power of Gaussian processes depends heavily on the choice of\nkernel. In this work we propose the novel harmonizable mixture kernel (HMK), a\nfamily of expressive, interpretable, non-stationary kernels derived from\nmixture models on the generalized spectral representation. As a theoretically\nsound treatment of non-stationary kernels, HMK supports harmonizable\ncovariances, a wide subset of kernels including all stationary and many\nnon-stationary covariances. We also propose variational Fourier features, an\ninter-domain sparse GP inference framework that offers a representative set of\n'inducing frequencies'. We show that harmonizable mixture kernels interpolate\nbetween local patterns, and that variational Fourier features offers a robust\nkernel learning framework for the new kernel family.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 08:41:51 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 12:43:28 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2019 09:08:09 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Shen", "Zheyang", ""], ["Heinonen", "Markus", ""], ["Kaski", "Samuel", ""]]}, {"id": "1810.04433", "submitter": "Yichi Zhou", "authors": "Yichi Zhou, Tongzheng Ren, Jialian Li, Dong Yan, Jun Zhu", "title": "Lazy-CFR: fast and near optimal regret minimization for extensive games\n  with imperfect information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual regret minimization (CFR) is the most popular algorithm on\nsolving two-player zero-sum extensive games with imperfect information and\nachieves state-of-the-art performance in practice. However, the performance of\nCFR is not fully understood, since empirical results on the regret are much\nbetter than the upper bound proved in \\cite{zinkevich2008regret}. Another issue\nis that CFR has to traverse the whole game tree in each round, which is\ntime-consuming in large scale games. In this paper, we present a novel\ntechnique, lazy update, which can avoid traversing the whole game tree in CFR,\nas well as a novel analysis on the regret of CFR with lazy update. Our analysis\ncan also be applied to the vanilla CFR, resulting in a much tighter regret\nbound than that in \\cite{zinkevich2008regret}. Inspired by lazy update, we\nfurther present a novel CFR variant, named Lazy-CFR. Compared to traversing\n$O(|\\mathcal{I}|)$ information sets in vanilla CFR, Lazy-CFR needs only to\ntraverse $O(\\sqrt{|\\mathcal{I}|})$ information sets per round while keeping the\nregret bound almost the same, where $\\mathcal{I}$ is the class of all\ninformation sets. As a result, Lazy-CFR shows better convergence result\ncompared with vanilla CFR. Experimental results consistently show that Lazy-CFR\noutperforms the vanilla CFR significantly.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:24:39 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 05:17:34 GMT"}, {"version": "v3", "created": "Tue, 25 Dec 2018 04:54:33 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zhou", "Yichi", ""], ["Ren", "Tongzheng", ""], ["Li", "Jialian", ""], ["Yan", "Dong", ""], ["Zhu", "Jun", ""]]}, {"id": "1810.04437", "submitter": "Giancarlo Salton", "authors": "Giancarlo D. Salton and John D. Kelleher", "title": "Persistence pays off: Paying Attention to What the LSTM Gating Mechanism\n  Persists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language Models (LMs) are important components in several Natural Language\nProcessing systems. Recurrent Neural Network LMs composed of LSTM units,\nespecially those augmented with an external memory, have achieved\nstate-of-the-art results. However, these models still struggle to process long\nsequences which are more likely to contain long-distance dependencies because\nof information fading and a bias towards more recent information. In this paper\nwe demonstrate an effective mechanism for retrieving information in a memory\naugmented LSTM LM based on attending to information in memory in proportion to\nthe number of timesteps the LSTM gating mechanism persisted the information.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:48:20 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Salton", "Giancarlo D.", ""], ["Kelleher", "John D.", ""]]}, {"id": "1810.04468", "submitter": "David Mart\\'inez-Rubio", "authors": "David Mart\\'inez-Rubio, Varun Kanade and Patrick Rebeschini", "title": "Decentralized Cooperative Stochastic Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a decentralized cooperative stochastic multi-armed bandit problem\nwith $K$ arms on a network of $N$ agents. In our model, the reward distribution\nof each arm is the same for each agent and rewards are drawn independently\nacross agents and time steps. In each round, each agent chooses an arm to play\nand subsequently sends a message to her neighbors. The goal is to minimize the\noverall regret of the entire network. We design a fully decentralized algorithm\nthat uses an accelerated consensus procedure to compute (delayed) estimates of\nthe average of rewards obtained by all the agents for each arm, and then uses\nan upper confidence bound (UCB) algorithm that accounts for the delay and error\nof the estimates. We analyze the regret of our algorithm and also provide a\nlower bound. The regret is bounded by the optimal centralized regret plus a\nnatural and simple term depending on the spectral gap of the communication\nmatrix. Our algorithm is simpler to analyze than those proposed in prior work\nand it achieves better regret bounds, while requiring less information about\nthe underlying network. It also performs better empirically.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 11:46:20 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 13:19:01 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Mart\u00ednez-Rubio", "David", ""], ["Kanade", "Varun", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "1810.04472", "submitter": "Jiawei Wang", "authors": "Jiawei Wang, Zhaoshui He, Chengjian Feng, Zhouping Zhu, Qinzhuang Lin,\n  Jun Lv, Shengli Xie", "title": "Domain Confusion with Self Ensembling for Unsupervised Adaptation", "comments": "The expression is ambiguous, which is not convenient for readers to\n  understand, and in today's view, the conclusion of the paper is of little\n  significance, so it is no longer open", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection and annotation are time-consuming in machine learning,\nexpecially for large scale problem. A common approach for this problem is to\ntransfer knowledge from a related labeled domain to a target one. There are two\npopular ways to achieve this goal: adversarial learning and self training. In\nthis article, we first analyze the training unstablity problem and the mistaken\nconfusion issue in adversarial learning process. Then, inspired by domain\nconfusion and self-ensembling methods, we propose a combined model to learn\nfeature and class jointly invariant representation, namely Domain Confusion\nwith Self Ensembling (DCSE). The experiments verified that our proposed\napproach can offer better performance than empirical art in a variety of\nunsupervised domain adaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 12:09:36 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:53:19 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 08:48:09 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wang", "Jiawei", ""], ["He", "Zhaoshui", ""], ["Feng", "Chengjian", ""], ["Zhu", "Zhouping", ""], ["Lin", "Qinzhuang", ""], ["Lv", "Jun", ""], ["Xie", "Shengli", ""]]}, {"id": "1810.04491", "submitter": "Prayag Tiwari Mr.", "authors": "Prayag Tiwari, Massimo Melucci", "title": "Multi-class Classification Model Inspired by Quantum Detection Theory", "comments": "Future Directions in Information Access (FDIA) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has become very famous currently which assist in identifying\nthe patterns from the raw data. Technological advancement has led to\nsubstantial improvement in Machine Learning which, thus helping to improve\nprediction. Current Machine Learning models are based on Classical Theory,\nwhich can be replaced by Quantum Theory to improve the effectiveness of the\nmodel. In the previous work, we developed binary classifier inspired by Quantum\nDetection Theory. In this extended abstract, our main goal is to develop\nmulti-class classifier. We generally use the terminology multinomial\nclassification or multi-class classification when we have a classification\nproblem for classifying observations or instances into one of three or more\nclasses.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 12:56:06 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Tiwari", "Prayag", ""], ["Melucci", "Massimo", ""]]}, {"id": "1810.04511", "submitter": "Lili Meng", "authors": "Lili Meng, Bo Zhao, Bo Chang, Gao Huang, Wei Sun, Frederich Tung,\n  Leonid Sigal", "title": "Interpretable Spatio-temporal Attention for Video Action Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the observation that humans are able to process videos\nefficiently by only paying attention where and when it is needed, we propose an\ninterpretable and easy plug-in spatial-temporal attention mechanism for video\naction recognition. For spatial attention, we learn a saliency mask to allow\nthe model to focus on the most salient parts of the feature maps. For temporal\nattention, we employ a convolutional LSTM based attention mechanism to identify\nthe most relevant frames from an input video. Further, we propose a set of\nregularizers to ensure that our attention mechanism attends to coherent regions\nin space and time. Our model not only improves video action recognition\naccuracy, but also localizes discriminative regions both spatially and\ntemporally, despite being trained in a weakly-supervised manner with only\nclassification labels (no bounding box labels or time frame temporal labels).\nWe evaluate our approach on several public video action recognition datasets\nwith ablation studies. Furthermore, we quantitatively and qualitatively\nevaluate our model's ability to localize discriminative regions spatially and\ncritical frames temporally. Experimental results demonstrate the efficacy of\nour approach, showing superior or comparable accuracy with the state-of-the-art\nmethods while increasing model interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 04:23:35 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 03:09:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Meng", "Lili", ""], ["Zhao", "Bo", ""], ["Chang", "Bo", ""], ["Huang", "Gao", ""], ["Sun", "Wei", ""], ["Tung", "Frederich", ""], ["Sigal", "Leonid", ""]]}, {"id": "1810.04513", "submitter": "Jiawei Wen", "authors": "Songshan Yang, Jiawei Wen, Xiang Zhan and Daniel Kifer", "title": "ET-Lasso: A New Efficient Tuning of Lasso-type Regularization for\n  High-Dimensional Data", "comments": "Figure 1 in the real data example is changed to plot the difference\n  of true values and predicted values; added references for section 1; more\n  explanation for section 2.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The L1 regularization (Lasso) has proven to be a versatile tool to select\nrelevant features and estimate the model coefficients simultaneously and has\nbeen widely used in many research areas such as genomes studies, finance, and\nbiomedical imaging. Despite its popularity, it is very challenging to guarantee\nthe feature selection consistency of Lasso especially when the dimension of the\ndata is huge. One way to improve the feature selection consistency is to select\nan ideal tuning parameter. Traditional tuning criteria mainly focus on\nminimizing the estimated prediction error or maximizing the posterior model\nprobability, such as cross-validation and BIC, which may either be\ntime-consuming or fail to control the false discovery rate (FDR) when the\nnumber of features is extremely large. The other way is to introduce\npseudo-features to learn the importance of the original ones. Recently, the\nKnockoff filter is proposed to control the FDR when performing feature\nselection. However, its performance is sensitive to the choice of the expected\nFDR threshold. Motivated by these ideas, we propose a new method using\npseudo-features to obtain an ideal tuning parameter. In particular, we present\nthe Efficient Tuning of Lasso (ET-Lasso) to separate active and inactive\nfeatures by adding permuted features as pseudo-features in linear models. The\npseudo-features are constructed to be inactive by nature, which can be used to\nobtain a cutoff to select the tuning parameter that separates active and\ninactive features. Experimental studies on both simulations and real-world data\napplications are provided to show that ET-Lasso can effectively and efficiently\nselect active features under a wide range of scenarios\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 13:25:03 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 04:40:08 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Yang", "Songshan", ""], ["Wen", "Jiawei", ""], ["Zhan", "Xiang", ""], ["Kifer", "Daniel", ""]]}, {"id": "1810.04535", "submitter": "Rafik Hadfi Dr", "authors": "Rafik Hadfi", "title": "Investigating Enactive Learning for Autonomous Intelligent Agents", "comments": "6 pages, 5 figures, 1 table, accepted as conference paper but\n  withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enactive approach to cognition is typically proposed as a viable\nalternative to traditional cognitive science. Enactive cognition displaces the\nexplanatory focus from the internal representations of the agent to the direct\nsensorimotor interaction with its environment. In this paper, we investigate\nenactive learning through means of artificial agent simulations. We compare the\nperformances of the enactive agent to an agent operating on classical\nreinforcement learning in foraging tasks within maze environments. The\ncharacteristics of the agents are analysed in terms of the accessibility of the\nenvironmental states, goals, and exploration/exploitation tradeoffs. We confirm\nthat the enactive agent can successfully interact with its environment and\nlearn to avoid unfavourable interactions using intrinsically defined goals. The\nperformance of the enactive agent is shown to be limited by the number of\naffordable actions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 03:43:04 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Hadfi", "Rafik", ""]]}, {"id": "1810.04570", "submitter": "Florian Hartl", "authors": "Peter Sugimura, Florian Hartl", "title": "Building a Reproducible Machine Learning Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducibility of modeling is a problem that exists for any machine learning\npractitioner, whether in industry or academia. The consequences of an\nirreproducible model can include significant financial costs, lost time, and\neven loss of personal reputation (if results prove unable to be replicated).\nThis paper will first discuss the problems we have encountered while building a\nvariety of machine learning models, and subsequently describe the framework we\nbuilt to tackle the problem of model reproducibility. The framework is\ncomprised of four main components (data, feature, scoring, and evaluation\nlayers), which are themselves comprised of well defined transformations. This\nenables us to not only exactly replicate a model, but also to reuse the\ntransformations across different models. As a result, the platform has\ndramatically increased the speed of both offline and online experimentation\nwhile also ensuring model reproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 17:32:36 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Sugimura", "Peter", ""], ["Hartl", "Florian", ""]]}, {"id": "1810.04586", "submitter": "Yifan Wu", "authors": "Yifan Wu, George Tucker, Ofir Nachum", "title": "The Laplacian in RL: Learning Representations with Efficient\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smallest eigenvectors of the graph Laplacian are well-known to provide a\nsuccinct representation of the geometry of a weighted graph. In reinforcement\nlearning (RL), where the weighted graph may be interpreted as the state\ntransition process induced by a behavior policy acting on the environment,\napproximating the eigenvectors of the Laplacian provides a promising approach\nto state representation learning. However, existing methods for performing this\napproximation are ill-suited in general RL settings for two main reasons:\nFirst, they are computationally expensive, often requiring operations on large\nmatrices. Second, these methods lack adequate justification beyond simple,\ntabular, finite-state settings. In this paper, we present a fully general and\nscalable method for approximating the eigenvectors of the Laplacian in a\nmodel-free RL context. We systematically evaluate our approach and empirically\nshow that it generalizes beyond the tabular, finite-state setting. Even in\ntabular, finite-state settings, its ability to approximate the eigenvectors\noutperforms previous proposals. Finally, we show the potential benefits of\nusing a Laplacian representation learned using our method in goal-achieving RL\ntasks, providing evidence that our technique can be used to significantly\nimprove the performance of an RL agent.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 15:25:49 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Wu", "Yifan", ""], ["Tucker", "George", ""], ["Nachum", "Ofir", ""]]}, {"id": "1810.04622", "submitter": "Elliot J. Crowley", "authors": "Elliot J. Crowley, Jack Turner, Amos Storkey, Michael O'Boyle", "title": "A Closer Look at Structured Pruning for Neural Network Compression", "comments": "Preprint. First two authors contributed equally. Paper title has\n  changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Structured pruning is a popular method for compressing a neural network:\ngiven a large trained network, one alternates between removing channel\nconnections and fine-tuning; reducing the overall width of the network.\nHowever, the efficacy of structured pruning has largely evaded scrutiny. In\nthis paper, we examine ResNets and DenseNets obtained through structured\npruning-and-tuning and make two interesting observations: (i) reduced\nnetworks---smaller versions of the original network trained from\nscratch---consistently outperform pruned networks; (ii) if one takes the\narchitecture of a pruned network and then trains it from scratch it is\nsignificantly more competitive. Furthermore, these architectures are easy to\napproximate: we can prune once and obtain a family of new, scalable network\narchitectures that can simply be trained from scratch. Finally, we compare the\ninference speed of reduced and pruned networks on hardware, and show that\nreduced networks are significantly faster. Code is available at\nhttps://github.com/BayesWatch/pytorch-prunes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:30:02 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 14:40:12 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 14:23:14 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Crowley", "Elliot J.", ""], ["Turner", "Jack", ""], ["Storkey", "Amos", ""], ["O'Boyle", "Michael", ""]]}, {"id": "1810.04632", "submitter": "Wil Ward", "authors": "Mauricio A. \\'Alvarez, Wil O. C. Ward, Cristian Guarnizo", "title": "Non-linear process convolutions for multi-output Gaussian processes", "comments": "16 pages plus 2 page supplementary. Accepted to AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a non-linear version of the process convolution\nformalism for building covariance functions for multi-output Gaussian\nprocesses. The non-linearity is introduced via Volterra series, one series per\neach output. We provide closed-form expressions for the mean function and the\ncovariance function of the approximated Gaussian process at the output of the\nVolterra series. The mean function and covariance function for the joint\nGaussian process are derived using formulae for the product moments of Gaussian\nvariables. We compare the performance of the non-linear model against the\nclassical process convolution approach in one synthetic dataset and two real\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:47:35 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 19:23:26 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["\u00c1lvarez", "Mauricio A.", ""], ["Ward", "Wil O. C.", ""], ["Guarnizo", "Cristian", ""]]}, {"id": "1810.04642", "submitter": "Indrasis Chakraborty", "authors": "Indrasis Chakraborty, Sai Pushpak Nandanoori, Soumya Kundu", "title": "Virtual Battery Parameter Identification using Transfer Learning based\n  Stacked Autoencoder", "comments": "8 pages, 6 figures, accepted to IEEE ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that the aggregated dynamic flexibility of an\nensemble of thermostatic loads can be modeled in the form of a virtual battery.\nThe existing methods for computing the virtual battery parameters require the\nknowledge of the first-principle models and parameter values of the loads in\nthe ensemble. In real-world applications, however, it is likely that the only\navailable information are end-use measurements such as power consumption, room\ntemperature, device on/off status, etc., while very little about the individual\nload models and parameters are known. We propose a transfer learning based deep\nnetwork framework for calculating virtual battery state of a given ensemble of\nflexible thermostatic loads, from the available end-use measurements. This\nproposed framework extracts first order virtual battery model parameters for\nthe given ensemble. We illustrate the effectiveness of this novel framework on\ndifferent ensembles of ACs and WHs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:07:53 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Chakraborty", "Indrasis", ""], ["Nandanoori", "Sai Pushpak", ""], ["Kundu", "Soumya", ""]]}, {"id": "1810.04650", "submitter": "Ozan Sener", "authors": "Ozan Sener, Vladlen Koltun", "title": "Multi-Task Learning as Multi-Objective Optimization", "comments": "In Neural Information Processing Systems (NeurIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task learning, multiple tasks are solved jointly, sharing inductive\nbias between them. Multi-task learning is inherently a multi-objective problem\nbecause different tasks may conflict, necessitating a trade-off. A common\ncompromise is to optimize a proxy objective that minimizes a weighted linear\ncombination of per-task losses. However, this workaround is only valid when the\ntasks do not compete, which is rarely the case. In this paper, we explicitly\ncast multi-task learning as multi-objective optimization, with the overall\nobjective of finding a Pareto optimal solution. To this end, we use algorithms\ndeveloped in the gradient-based multi-objective optimization literature. These\nalgorithms are not directly applicable to large-scale learning problems since\nthey scale poorly with the dimensionality of the gradients and the number of\ntasks. We therefore propose an upper bound for the multi-objective loss and\nshow that it can be optimized efficiently. We further prove that optimizing\nthis upper bound yields a Pareto optimal solution under realistic assumptions.\nWe apply our method to a variety of multi-task deep learning problems including\ndigit classification, scene understanding (joint semantic segmentation,\ninstance segmentation, and depth estimation), and multi-label classification.\nOur method produces higher-performing models than recent multi-task learning\nformulations or per-task training.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:18:09 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 12:57:32 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Sener", "Ozan", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.04651", "submitter": "Jingyi Kenneth Tay", "authors": "J. Kenneth Tay, Jerome Friedman and Robert Tibshirani", "title": "Principal component-guided sparse regression", "comments": "Update to acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for supervised learning, especially suited to wide\ndata where the number of features is much greater than the number of\nobservations. The method combines the lasso ($\\ell_1$) sparsity penalty with a\nquadratic penalty that shrinks the coefficient vector toward the leading\nprincipal components of the feature matrix. We call the proposed method the\n\"principal components lasso\" (\"pcLasso\"). The method can be especially powerful\nif the features are pre-assigned to groups (such as cell-pathways, assays or\nprotein interaction networks). In that case, pcLasso shrinks each group-wise\ncomponent of the solution toward the leading principal components of that\ngroup. In the process, it also carries out selection of the feature groups. We\nprovide some theory for this method and illustrate it on a number of simulated\nand real data examples.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:18:46 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 02:46:45 GMT"}, {"version": "v3", "created": "Wed, 24 Oct 2018 06:38:27 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Tay", "J. Kenneth", ""], ["Friedman", "Jerome", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1810.04714", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong and Yi-Hsuan Yang", "title": "Training Generative Adversarial Networks with Binary Neurons by\n  End-to-end Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the BinaryGAN, a novel generative adversarial network (GAN) that\nuses binary neurons at the output layer of the generator. We employ the\nsigmoid-adjusted straight-through estimators to estimate the gradients for the\nbinary neurons and train the whole network by end-to-end backpropogation. The\nproposed model is able to directly generate binary-valued predictions at test\ntime. We implement such a model to generate binarized MNIST digits and\nexperimentally compare the performance for different types of binary neurons,\nGAN objectives and network architectures. Although the results are still\npreliminary, we show that it is possible to train a GAN that has binary neurons\nand that the use of gradient estimators can be a promising direction for\nmodeling discrete distributions with GANs. For reproducibility, the source code\nis available at https://github.com/salu133445/binarygan .\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 19:13:59 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1810.04719", "submitter": "Quan Wang", "authors": "Aonan Zhang, Quan Wang, Zhenyao Zhu, John Paisley, Chong Wang", "title": "Fully Supervised Speaker Diarization", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fully supervised speaker diarization approach,\nnamed unbounded interleaved-state recurrent neural networks (UIS-RNN). Given\nextracted speaker-discriminative embeddings (a.k.a. d-vectors) from input\nutterances, each individual speaker is modeled by a parameter-sharing RNN,\nwhile the RNN states for different speakers interleave in the time domain. This\nRNN is naturally integrated with a distance-dependent Chinese restaurant\nprocess (ddCRP) to accommodate an unknown number of speakers. Our system is\nfully supervised and is able to learn from examples where time-stamped speaker\nlabels are annotated. We achieved a 7.6% diarization error rate on NIST SRE\n2000 CALLHOME, which is better than the state-of-the-art method using spectral\nclustering. Moreover, our method decodes in an online fashion while most\nstate-of-the-art systems rely on offline clustering.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 19:21:44 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 13:12:36 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 05:44:52 GMT"}, {"version": "v4", "created": "Mon, 17 Dec 2018 23:30:02 GMT"}, {"version": "v5", "created": "Fri, 8 Feb 2019 21:52:19 GMT"}, {"version": "v6", "created": "Sun, 17 Feb 2019 20:02:52 GMT"}, {"version": "v7", "created": "Tue, 19 Feb 2019 16:30:55 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Zhang", "Aonan", ""], ["Wang", "Quan", ""], ["Zhu", "Zhenyao", ""], ["Paisley", "John", ""], ["Wang", "Chong", ""]]}, {"id": "1810.04738", "submitter": "David Qiu", "authors": "David Qiu and Anuran Makur and Lizhong Zheng", "title": "Probabilistic Clustering Using Maximal Matrix Norm Couplings", "comments": "Presented at 56th Annual Allerton Conference on Communication,\n  Control, and Computing, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a local information theoretic approach to\nexplicitly learn probabilistic clustering of a discrete random variable. Our\nformulation yields a convex maximization problem for which it is NP-hard to\nfind the global optimum. In order to algorithmically solve this optimization\nproblem, we propose two relaxations that are solved via gradient ascent and\nalternating maximization. Experiments on the MSR Sentence Completion Challenge,\nMovieLens 100K, and Reuters21578 datasets demonstrate that our approach is\ncompetitive with existing techniques and worthy of further investigation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 20:26:44 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Qiu", "David", ""], ["Makur", "Anuran", ""], ["Zheng", "Lizhong", ""]]}, {"id": "1810.04754", "submitter": "Rose Yu", "authors": "Sung-En Chang, Xun Zheng, Ian E.H. Yen, Pradeep Ravikumar, Rose Yu", "title": "Efficient Tensor Decomposition with Boolean Factors", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition has been extensively used as a tool for exploratory\nanalysis. Motivated by neuroscience applications, we study tensor decomposition\nwith Boolean factors. The resulting optimization problem is challenging due to\nthe non-convex objective and the combinatorial constraints. We propose Binary\nMatching Pursuit (BMP), a novel generalization of the matching pursuit strategy\nto decompose the tensor efficiently. BMP iteratively searches for atoms in a\ngreedy fashion. The greedy atom search step is solved efficiently via a\nMAXCUT-like boolean quadratic program. We prove that BMP is guaranteed to\nconverge sublinearly to the optimal solution and recover the factors under mild\nidentifiability conditions. Experiments demonstrate the superior performance of\nour method over baselines on synthetic and real datasets. We also showcase the\napplication of BMP in quantifying neural interactions underlying\nhigh-resolution spatiotemporal ECoG recordings.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 21:41:52 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 22:35:27 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Chang", "Sung-En", ""], ["Zheng", "Xun", ""], ["Yen", "Ian E. H.", ""], ["Ravikumar", "Pradeep", ""], ["Yu", "Rose", ""]]}, {"id": "1810.04777", "submitter": "Runjing Liu", "authors": "Runjing Liu, Jeffrey Regier, Nilesh Tripuraneni, Michael I. Jordan,\n  and Jon McAuliffe", "title": "Rao-Blackwellized Stochastic Gradients for Discrete Distributions", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We wish to compute the gradient of an expectation over a finite or countably\ninfinite sample space having $K \\leq \\infty$ categories. When $K$ is indeed\ninfinite, or finite but very large, the relevant summation is intractable.\nAccordingly, various stochastic gradient estimators have been proposed. In this\npaper, we describe a technique that can be applied to reduce the variance of\nany such estimator, without changing its bias---in particular, unbiasedness is\nretained. We show that our technique is an instance of Rao-Blackwellization,\nand we demonstrate the improvement it yields on a semi-supervised\nclassification problem and a pixel attention task.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:17:11 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 07:00:13 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 17:36:37 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Liu", "Runjing", ""], ["Regier", "Jeffrey", ""], ["Tripuraneni", "Nilesh", ""], ["Jordan", "Michael I.", ""], ["McAuliffe", "Jon", ""]]}, {"id": "1810.04778", "submitter": "Susan Athey", "authors": "Zhengyuan Zhou, Susan Athey, Stefan Wager", "title": "Offline Multi-Action Policy Learning: Generalization and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings, a decision-maker wishes to learn a rule, or policy, that\nmaps from observable characteristics of an individual to an action. Examples\ninclude selecting offers, prices, advertisements, or emails to send to\nconsumers, as well as the problem of determining which medication to prescribe\nto a patient. While there is a growing body of literature devoted to this\nproblem, most existing results are focused on the case where data comes from a\nrandomized experiment, and further, there are only two possible actions, such\nas giving a drug to a patient or not. In this paper, we study the offline\nmulti-action policy learning problem with observational data and where the\npolicy may need to respect budget constraints or belong to a restricted policy\nclass such as decision trees. We build on the theory of efficient\nsemi-parametric inference in order to propose and implement a policy learning\nalgorithm that achieves asymptotically minimax-optimal regret. To the best of\nour knowledge, this is the first result of this type in the multi-action setup,\nand it provides a substantial performance improvement over the existing\nlearning algorithms. We then consider additional computational challenges that\narise in implementing our method for the case where the policy is restricted to\ntake the form of a decision tree. We propose two different approaches, one\nusing a mixed integer program formulation and the other using a tree-search\nbased algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:34:37 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 16:29:24 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zhou", "Zhengyuan", ""], ["Athey", "Susan", ""], ["Wager", "Stefan", ""]]}, {"id": "1810.04793", "submitter": "Kamran Kowsari", "authors": "Jinghe Zhang, Kamran Kowsari, James H. Harrison, Jennifer M. Lobo,\n  Laura E. Barnes", "title": "Patient2Vec: A Personalized Interpretable Deep Representation of the\n  Longitudinal Electronic Health Record", "comments": "Accepted by IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2875677", "report-no": null, "categories": "q-bio.QM cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide implementation of electronic health record (EHR) systems facilitates\nthe collection of large-scale health data from real clinical settings. Despite\nthe significant increase in adoption of EHR systems, this data remains largely\nunexplored, but presents a rich data source for knowledge discovery from\npatient health histories in tasks such as understanding disease correlations\nand predicting health outcomes. However, the heterogeneity, sparsity, noise,\nand bias in this data present many complex challenges. This complexity makes it\ndifficult to translate potentially relevant information into machine learning\nalgorithms. In this paper, we propose a computational framework, Patient2Vec,\nto learn an interpretable deep representation of longitudinal EHR data which is\npersonalized for each patient. To evaluate this approach, we apply it to the\nprediction of future hospitalizations using real EHR data and compare its\npredictive performance with baseline methods. Patient2Vec produces a vector\nspace with meaningful structure and it achieves an AUC around 0.799\noutperforming baseline methods. In the end, the learned feature importance can\nbe visualized and interpreted at both the individual and population levels to\nbring clinical insights.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:41:05 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 15:13:16 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 13:38:34 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zhang", "Jinghe", ""], ["Kowsari", "Kamran", ""], ["Harrison", "James H.", ""], ["Lobo", "Jennifer M.", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1810.04824", "submitter": "Fei Tan", "authors": "Fei Tan, Zhi Wei, Jun He, Xiang Wu, Bo Peng, Haoran Liu, and Zhenyu\n  Yan", "title": "A Blended Deep Learning Approach for Predicting User Intended Actions", "comments": "10 pages, International Conference on Data Mining 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User intended actions are widely seen in many areas. Forecasting these\nactions and taking proactive measures to optimize business outcome is a crucial\nstep towards sustaining the steady business growth. In this work, we focus on\npre- dicting attrition, which is one of typical user intended actions.\nConventional attrition predictive modeling strategies suffer a few inherent\ndrawbacks. To overcome these limitations, we propose a novel end-to-end\nlearning scheme to keep track of the evolution of attrition patterns for the\npredictive modeling. It integrates user activity logs, dynamic and static user\nprofiles based on multi-path learning. It exploits historical user records by\nestablishing a decaying multi-snapshot technique. And finally it employs the\nprecedent user intentions via guiding them to the subsequent learning\nprocedure. As a result, it addresses all disadvantages of conventional methods.\nWe evaluate our methodology on two public data repositories and one private\nuser usage dataset provided by Adobe Creative Cloud. The extensive experiments\ndemonstrate that it can offer the appealing performance in comparison with\nseveral existing approaches as rated by different popular metrics. Furthermore,\nwe introduce an advanced interpretation and visualization strategy to\neffectively characterize the periodicity of user activity logs. It can help to\npinpoint important factors that are critical to user attrition and retention\nand thus suggests actionable improvement targets for business practice. Our\nwork will provide useful insights into the prediction and elucidation of other\nuser intended actions as well.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 02:48:20 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Tan", "Fei", ""], ["Wei", "Zhi", ""], ["He", "Jun", ""], ["Wu", "Xiang", ""], ["Peng", "Bo", ""], ["Liu", "Haoran", ""], ["Yan", "Zhenyu", ""]]}, {"id": "1810.04826", "submitter": "Quan Wang", "authors": "Quan Wang, Hannah Muckenhirn, Kevin Wilson, Prashant Sridhar, Zelin\n  Wu, John Hershey, Rif A. Saurous, Ron J. Weiss, Ye Jia, Ignacio Lopez Moreno", "title": "VoiceFilter: Targeted Voice Separation by Speaker-Conditioned\n  Spectrogram Masking", "comments": "To appear in Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel system that separates the voice of a target\nspeaker from multi-speaker signals, by making use of a reference signal from\nthe target speaker. We achieve this by training two separate neural networks:\n(1) A speaker recognition network that produces speaker-discriminative\nembeddings; (2) A spectrogram masking network that takes both noisy spectrogram\nand speaker embedding as input, and produces a mask. Our system significantly\nreduces the speech recognition WER on multi-speaker signals, with minimal WER\ndegradation on single-speaker signals.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 02:57:14 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 13:08:42 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 05:36:13 GMT"}, {"version": "v4", "created": "Thu, 21 Feb 2019 15:36:55 GMT"}, {"version": "v5", "created": "Wed, 29 May 2019 14:23:02 GMT"}, {"version": "v6", "created": "Wed, 19 Jun 2019 17:10:51 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Wang", "Quan", ""], ["Muckenhirn", "Hannah", ""], ["Wilson", "Kevin", ""], ["Sridhar", "Prashant", ""], ["Wu", "Zelin", ""], ["Hershey", "John", ""], ["Saurous", "Rif A.", ""], ["Weiss", "Ron J.", ""], ["Jia", "Ye", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1810.04851", "submitter": "Fang Liu", "authors": "Yinan Li, Xiao Liu, Fang Liu", "title": "PANDA: AdaPtive Noisy Data Augmentation for Regularization of Undirected\n  Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an AdaPtive Noise Augmentation (PANDA) technique to regularize the\nestimation and construction of undirected graphical models. PANDA iteratively\noptimizes the objective function given the noise augmented data until\nconvergence to achieve regularization on model parameters. The augmented noises\ncan be designed to achieve various regularization effects on graph estimation,\nsuch as the bridge (including lasso and ridge), elastic net, adaptive lasso,\nand SCAD penalization; it also realizes the group lasso and fused ridge. We\nexamine the tail bound of the noise-augmented loss function and establish that\nthe noise-augmented loss function and its minimizer converge almost surely to\nthe expected penalized loss function and its minimizer, respectively. We derive\nthe asymptotic distributions for the regularized parameters through PANDA in\ngeneralized linear models, based on which, inferences for the parameters can be\nobtained simultaneously with variable selection. We show the non-inferior\nperformance of PANDA in constructing graphs of different types in simulation\nstudies and apply PANDA to an autism spectrum disorder data to construct a\nmixed-node graph. We also show that the inferences based on the asymptotic\ndistribution of regularized parameter estimates via PANDA achieve nominal or\nnear-nominal coverage and are far more efficient, compared to some existing\npost-selection procedures. Computationally, PANDA can be easily programmed in\nsoftware that implements (GLMs) without resorting to complicated optimization\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 05:54:44 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 22:52:51 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Li", "Yinan", ""], ["Liu", "Xiao", ""], ["Liu", "Fang", ""]]}, {"id": "1810.04863", "submitter": "Matthew J. Holland", "authors": "Matthew J. Holland", "title": "Classification using margin pursuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study a new approach to optimizing the margin distribution\nrealized by binary classifiers. The classical approach to this problem is\nsimply maximization of the expected margin, while more recent proposals\nconsider simultaneous variance control and proxy objectives based on robust\nlocation estimates, in the vein of keeping the margin distribution sharply\nconcentrated in a desirable region. While conceptually appealing, these new\napproaches are often computationally unwieldy, and theoretical guarantees are\nlimited. Given this context, we propose an algorithm which searches the\nhypothesis space in such a way that a pre-set \"margin level\" ends up being a\ndistribution-robust estimator of the margin location. This procedure is easily\nimplemented using gradient descent, and admits finite-sample bounds on the\nexcess risk under unbounded inputs. Empirical tests on real-world benchmark\ndata reinforce the basic principles highlighted by the theory, and are\nsuggestive of a promising new technique for classification.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 06:35:48 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Holland", "Matthew J.", ""]]}, {"id": "1810.04903", "submitter": "Fatma BenSaid", "authors": "Fatma BenSaid and Adel M. Alimi", "title": "MOANOFS: Multi-Objective Automated Negotiation based Online Feature\n  Selection System for Big Data Classification", "comments": "15 pages, 8 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Selection (FS) plays an important role in learning and classification\ntasks. The object of FS is to select the relevant and non-redundant features.\nConsidering the huge amount number of features in real-world applications, FS\nmethods using batch learning technique can't resolve big data problem\nespecially when data arrive sequentially. In this paper, we propose an online\nfeature selection system which resolves this problem. More specifically, we\ntreat the problem of online supervised feature selection for binary\nclassification as a decision-making problem. A philosophical vision to this\nproblem leads to a hybridization between two important domains: feature\nselection using online learning technique (OFS) and automated negotiation (AN).\nThe proposed OFS system called MOANOFS (Multi-Objective Automated Negotiation\nbased Online Feature Selection) uses two levels of decision. In the first\nlevel, from n learners (or OFS methods), we decide which are the k trustful\nones (with high confidence or trust value). These elected k learners will\nparticipate in the second level. In this level, we integrate our proposed\nMultilateral Automated Negotiation based OFS (MANOFS) method to decide finally\nwhich is the best solution or which are relevant features. We show that MOANOFS\nsystem is applicable to different domains successfully and achieves high\naccuracy with several real-world applications.\n  Index Terms: Feature selection, online learning, multi-objective automated\nnegotiation, trust, classification, big data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:41:30 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 15:19:17 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["BenSaid", "Fatma", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1810.04920", "submitter": "Aibek Alanov", "authors": "Aibek Alanov, Max Kochurov, Daniil Yashkov, Dmitry Vetrov", "title": "Pairwise Augmented GANs with Adversarial Reconstruction Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel autoencoding model called Pairwise Augmented GANs. We\ntrain a generator and an encoder jointly and in an adversarial manner. The\ngenerator network learns to sample realistic objects. In turn, the encoder\nnetwork at the same time is trained to map the true data distribution to the\nprior in latent space. To ensure good reconstructions, we introduce an\naugmented adversarial reconstruction loss. Here we train a discriminator to\ndistinguish two types of pairs: an object with its augmentation and the one\nwith its reconstruction. We show that such adversarial loss compares objects\nbased on the content rather than on the exact match. We experimentally\ndemonstrate that our model generates samples and reconstructions of quality\ncompetitive with state-of-the-art on datasets MNIST, CIFAR10, CelebA and\nachieves good quantitative results on CIFAR10.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 09:22:36 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Alanov", "Aibek", ""], ["Kochurov", "Max", ""], ["Yashkov", "Daniil", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.04963", "submitter": "Peter Bubenik", "authors": "Peter Bubenik", "title": "The persistence landscape and some of its properties", "comments": "18 pages, to appear in the Proceedings of the 2018 Abel Symposium", "journal-ref": "In: Topological Data Analysis. Abel Symposia, vol 15. Springer.\n  (2020)", "doi": "10.1007/978-3-030-43408-3_4", "report-no": null, "categories": "math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence landscapes map persistence diagrams into a function space, which\nmay often be taken to be a Banach space or even a Hilbert space. In the latter\ncase, it is a feature map and there is an associated kernel. The main advantage\nof this summary is that it allows one to apply tools from statistics and\nmachine learning. Furthermore, the mapping from persistence diagrams to\npersistence landscapes is stable and invertible. We introduce a weighted\nversion of the persistence landscape and define a one-parameter family of\nPoisson-weighted persistence landscape kernels that may be useful for learning.\nWe also demonstrate some additional properties of the persistence landscape.\nFirst, the persistence landscape may be viewed as a tropical rational function.\nSecond, in many cases it is possible to exactly reconstruct all of the\ncomponent persistence diagrams from an average persistence landscape. It\nfollows that the persistence landscape kernel is characteristic for certain\ngeneric empirical measures. Finally, the persistence landscape distance may be\narbitrarily small compared to the interleaving distance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 11:47:48 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 22:01:34 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Bubenik", "Peter", ""]]}, {"id": "1810.04996", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama and Takanori Maehara", "title": "A Simple Way to Deal with Cherry-picking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical hypothesis testing serves as statistical evidence for scientific\ninnovation. However, if the reported results are intentionally biased,\nhypothesis testing no longer controls the rate of false discovery. In\nparticular, we study such selection bias in machine learning models where the\nreporter is motivated to promote an algorithmic innovation. When the number of\npossible configurations (e.g., datasets) is large, we show that the reporter\ncan falsely report an innovation even if there is no improvement at all. We\npropose a `post-reporting' solution to this issue where the bias of the\nreported results is verified by another set of results. The theoretical\nfindings are supported by experimental results with synthetic and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 13:06:48 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Komiyama", "Junpei", ""], ["Maehara", "Takanori", ""]]}, {"id": "1810.05041", "submitter": "Jack Fitzsimons", "authors": "Jack Fitzsimons, AbdulRahman Al Ali, Michael Osborne and Stephen\n  Roberts", "title": "A General Framework for Fair Regression", "comments": "8 pages, 4 figures, 2 pages references", "journal-ref": null, "doi": "10.3390/e21080741", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness, through its many forms and definitions, has become an important\nissue facing the machine learning community. In this work, we consider how to\nincorporate group fairness constraints in kernel regression methods, applicable\nto Gaussian processes, support vector machines, neural network regression and\ndecision tree regression. Further, we focus on examining the effect of\nincorporating these constraints in decision tree regression, with direct\napplications to random forests and boosted trees amongst other widespread\npopular inference techniques. We show that the order of complexity of memory\nand computation is preserved for such models and tightly bound the expected\nperturbations to the model in terms of the number of leaves of the trees.\nImportantly, the approach works on trained models and hence can be easily\napplied to models in current use and group labels are only required on training\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:16:03 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 08:09:20 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Fitzsimons", "Jack", ""], ["Ali", "AbdulRahman Al", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1810.05057", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Nicolas Le Hir, Olivier Sigaud, Alban Laflaqui\\`ere", "title": "Identification of Invariant Sensorimotor Structures as a Prerequisite\n  for the Discovery of Objects", "comments": "24 pages, 10 figures, published in Frontiers Robotics and AI", "journal-ref": "Front. Robot. AI, 25 June 2018", "doi": "10.3389/frobt.2018.00070", "report-no": null, "categories": "cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceiving the surrounding environment in terms of objects is useful for any\ngeneral purpose intelligent agent. In this paper, we investigate a fundamental\nmechanism making object perception possible, namely the identification of\nspatio-temporally invariant structures in the sensorimotor experience of an\nagent. We take inspiration from the Sensorimotor Contingencies Theory to define\na computational model of this mechanism through a sensorimotor, unsupervised\nand predictive approach. Our model is based on processing the unsupervised\ninteraction of an artificial agent with its environment. We show how\nspatio-temporally invariant structures in the environment induce regularities\nin the sensorimotor experience of an agent, and how this agent, while building\na predictive model of its sensorimotor experience, can capture them as densely\nconnected subgraphs in a graph of sensory states connected by motor commands.\nOur approach is focused on elementary mechanisms, and is illustrated with a set\nof simple experiments in which an agent interacts with an environment. We show\nhow the agent can build an internal model of moving but spatio-temporally\ninvariant structures by performing a Spectral Clustering of the graph modeling\nits overall sensorimotor experiences. We systematically examine properties of\nthe model, shedding light more globally on the specificities of the paradigm\nwith respect to methods based on the supervised processing of collections of\nstatic images.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 14:47:38 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Hir", "Nicolas Le", ""], ["Sigaud", "Olivier", ""], ["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1810.05064", "submitter": "Dennis Rohde", "authors": "Hendrik Fichtenberger, Dennis Rohde", "title": "A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the $k$-nearest neighborhood model ($k$-NN), we are given a set of points\n$P$, and we shall answer queries $q$ by returning the $k$ nearest neighbors of\n$q$ in $P$ according to some metric. This concept is crucial in many areas of\ndata analysis and data processing, e.g., computer vision, document retrieval\nand machine learning. Many $k$-NN algorithms have been published and\nimplemented, but often the relation between parameters and accuracy of the\ncomputed $k$-NN is not explicit. We study property testing of $k$-NN graphs in\ntheory and evaluate it empirically: given a point set $P \\subset\n\\mathbb{R}^\\delta$ and a directed graph $G=(P,E)$, is $G$ a $k$-NN graph, i.e.,\nevery point $p \\in P$ has outgoing edges to its $k$ nearest neighbors, or is it\n$\\epsilon$-far from being a $k$-NN graph? Here, $\\epsilon$-far means that one\nhas to change more than an $\\epsilon$-fraction of the edges in order to make\n$G$ a $k$-NN graph. We develop a randomized algorithm with one-sided error that\ndecides this question, i.e., a property tester for the $k$-NN property, with\ncomplexity $O(\\sqrt{n} k^2 / \\epsilon^2)$ measured in terms of the number of\nvertices and edges it inspects, and we prove a lower bound of $\\Omega(\\sqrt{n /\n\\epsilon k})$. We evaluate our tester empirically on the $k$-NN models computed\nby various algorithms and show that it can be used to detect $k$-NN models with\nbad accuracy in significantly less time than the building time of the $k$-NN\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 14:56:03 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 14:28:12 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 18:33:18 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Fichtenberger", "Hendrik", ""], ["Rohde", "Dennis", ""]]}, {"id": "1810.05065", "submitter": "Xavier Fontaine", "authors": "Xavier Fontaine, Quentin Berthet, Vianney Perchet", "title": "Regularized Contextual Bandits", "comments": "AISTATS 2019, 23 pages, 2 figures", "journal-ref": "Proceedings of Machine Learning Research, PMLR 89:2144-2153, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic contextual bandit problem with additional\nregularization. The motivation comes from problems where the policy of the\nagent must be close to some baseline policy which is known to perform well on\nthe task. To tackle this problem we use a nonparametric model and propose an\nalgorithm splitting the context space into bins, and solving simultaneously -\nand independently - regularized multi-armed bandit instances on each bin. We\nderive slow and fast rates of convergence, depending on the unknown complexity\nof the problem. We also consider a new relevant margin condition to get\nproblem-independent convergence rates, ending up in intermediate convergence\nrates interpolating between the aforementioned slow and fast rates.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 15:00:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 15:25:32 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Fontaine", "Xavier", ""], ["Berthet", "Quentin", ""], ["Perchet", "Vianney", ""]]}, {"id": "1810.05075", "submitter": "Manuel Isaac Martinez Torres", "authors": "Manuel Martinez and Rainer Stiefelhagen", "title": "Taming the Cross Entropy Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Tamed Cross Entropy (TCE) loss function, a robust derivative\nof the standard Cross Entropy (CE) loss used in deep learning for\nclassification tasks. However, unlike other robust losses, the TCE loss is\ndesigned to exhibit the same training properties than the CE loss in noiseless\nscenarios. Therefore, the TCE loss requires no modification on the training\nregime compared to the CE loss and, in consequence, can be applied in all\napplications where the CE loss is currently used. We evaluate the TCE loss\nusing the ResNet architecture on four image datasets that we artificially\ncontaminated with various levels of label noise. The TCE loss outperforms the\nCE loss in every tested scenario.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 15:18:19 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Martinez", "Manuel", ""], ["Stiefelhagen", "Rainer", ""]]}, {"id": "1810.05148", "submitter": "Roman Novak", "authors": "Roman Novak, Lechao Xiao, Jaehoon Lee, Yasaman Bahri, Greg Yang, Jiri\n  Hron, Daniel A. Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein", "title": "Bayesian Deep Convolutional Networks with Many Channels are Gaussian\n  Processes", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a previously identified equivalence between wide fully connected\nneural networks (FCNs) and Gaussian processes (GPs). This equivalence enables,\nfor instance, test set predictions that would have resulted from a fully\nBayesian, infinitely wide trained FCN to be computed without ever instantiating\nthe FCN, but by instead evaluating the corresponding GP. In this work, we\nderive an analogous equivalence for multi-layer convolutional neural networks\n(CNNs) both with and without pooling layers, and achieve state of the art\nresults on CIFAR10 for GPs without trainable kernels. We also introduce a Monte\nCarlo method to estimate the GP corresponding to a given neural network\narchitecture, even in cases where the analytic form has too many terms to be\ncomputationally feasible.\n  Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs\nwith and without weight sharing are identical. As a consequence, translation\nequivariance, beneficial in finite channel CNNs trained with stochastic\ngradient descent (SGD), is guaranteed to play no role in the Bayesian treatment\nof the infinite channel limit - a qualitative difference between the two\nregimes that is not present in the FCN case. We confirm experimentally, that\nwhile in some scenarios the performance of SGD-trained finite CNNs approaches\nthat of the corresponding GPs as the channel count increases, with careful\ntuning SGD-trained CNNs can significantly outperform their corresponding GPs,\nsuggesting advantages from SGD training compared to fully Bayesian parameter\nestimation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:49:41 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 00:38:34 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 04:42:51 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 15:28:27 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Novak", "Roman", ""], ["Xiao", "Lechao", ""], ["Lee", "Jaehoon", ""], ["Bahri", "Yasaman", ""], ["Yang", "Greg", ""], ["Hron", "Jiri", ""], ["Abolafia", "Daniel A.", ""], ["Pennington", "Jeffrey", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1810.05157", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Andrea Bajcsy, Jaime F. Fisac, Anca D. Dragan", "title": "Learning under Misspecified Objective Spaces", "comments": "Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot objective functions from human input has become increasingly\nimportant, but state-of-the-art techniques assume that the human's desired\nobjective lies within the robot's hypothesis space. When this is not true, even\nmethods that keep track of uncertainty over the objective fail because they\nreason about which hypothesis might be correct, and not whether any of the\nhypotheses are correct. We focus specifically on learning from physical human\ncorrections during the robot's task execution, where not having a rich enough\nhypothesis space leads to the robot updating its objective in ways that the\nperson did not actually intend. We observe that such corrections appear\nirrelevant to the robot, because they are not the best way of achieving any of\nthe candidate objectives. Instead of naively trusting and learning from every\nhuman interaction, we propose robots learn conservatively by reasoning in real\ntime about how relevant the human's correction is for the robot's hypothesis\nspace. We test our inference method in an experiment with human interaction\ndata, and demonstrate that this alleviates unintended learning in an in-person\nuser study with a 7DoF robot manipulator.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:58:27 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 00:47:32 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 07:09:31 GMT"}, {"version": "v4", "created": "Fri, 26 Oct 2018 05:21:19 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Bobu", "Andreea", ""], ["Bajcsy", "Andrea", ""], ["Fisac", "Jaime F.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1810.05165", "submitter": "Patrick Komiske", "authors": "Patrick T. Komiske, Eric M. Metodiev, Jesse Thaler", "title": "Energy Flow Networks: Deep Sets for Particle Jets", "comments": "31+16 pages, 21 figures, 5 tables; v2: updated to match JHEP version;\n  code available at https://energyflow.network", "journal-ref": "JHEP 01 (2019) 121", "doi": "10.1007/JHEP01(2019)121", "report-no": "MIT-CTP 5064", "categories": "hep-ph hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question for machine learning approaches in particle physics is how to\nbest represent and learn from collider events. As an event is intrinsically a\nvariable-length unordered set of particles, we build upon recent machine\nlearning efforts to learn directly from sets of features or \"point clouds\".\nAdapting and specializing the \"Deep Sets\" framework to particle physics, we\nintroduce Energy Flow Networks, which respect infrared and collinear safety by\nconstruction. We also develop Particle Flow Networks, which allow for general\nenergy dependence and the inclusion of additional particle-level information\nsuch as charge and flavor. These networks feature a per-particle internal\n(latent) representation, and summing over all particles yields an overall\nevent-level latent representation. We show how this latent space decomposition\nunifies existing event representations based on detector images and radiation\nmoments. To demonstrate the power and simplicity of this set-based approach, we\napply these networks to the collider task of discriminating quark jets from\ngluon jets, finding similar or improved performance compared to existing\nmethods. We also show how the learned event representation can be directly\nvisualized, providing insight into the inner workings of the model. These\narchitectures lend themselves to efficiently processing and analyzing events\nfor a wide variety of tasks at the Large Hadron Collider. Implementations and\nexamples of our architectures are available online in our EnergyFlow package.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 18:35:51 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Komiske", "Patrick T.", ""], ["Metodiev", "Eric M.", ""], ["Thaler", "Jesse", ""]]}, {"id": "1810.05186", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, James Cheng, Yuanyuan Liu, Zhi-Quan Luo, Zhouchen Lin", "title": "Bilinear Factor Matrix Norm Minimization for Robust PCA: Algorithms and\n  Applications", "comments": "29 pages, 19 figures", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  40(9): 2066-2080, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heavy-tailed distributions of corrupted outliers and singular values of\nall channels in low-level vision have proven effective priors for many\napplications such as background modeling, photometric stereo and image\nalignment. And they can be well modeled by a hyper-Laplacian. However, the use\nof such distributions generally leads to challenging non-convex, non-smooth and\nnon-Lipschitz problems, and makes existing algorithms very slow for large-scale\napplications. Together with the analytic solutions to lp-norm minimization with\ntwo specific values of p, i.e., p=1/2 and p=2/3, we propose two novel bilinear\nfactor matrix norm minimization models for robust principal component analysis.\nWe first define the double nuclear norm and Frobenius/nuclear hybrid norm\npenalties, and then prove that they are in essence the Schatten-1/2 and 2/3\nquasi-norms, respectively, which lead to much more tractable and scalable\nLipschitz optimization problems. Our experimental analysis shows that both our\nmethods yield more accurate solutions than original Schatten quasi-norm\nminimization, even when the number of observations is very limited. Finally, we\napply our penalties to various low-level vision problems, e.g., text removal,\nmoving object detection, image alignment and inpainting, and show that our\nmethods usually outperform the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:06:27 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Shang", "Fanhua", ""], ["Cheng", "James", ""], ["Liu", "Yuanyuan", ""], ["Luo", "Zhi-Quan", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1810.05187", "submitter": "Faiz Ali Shah", "authors": "Faiz Ali Shah, Kairit Sirts, Dietmar Pfahl", "title": "The Impact of Annotation Guidelines and Annotated Data on Extracting App\n  Features from App Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotation guidelines used to guide the annotation of training and evaluation\ndatasets can have a considerable impact on the quality of machine learning\nmodels. In this study, we explore the effects of annotation guidelines on the\nquality of app feature extraction models. As a main result, we propose several\nchanges to the existing annotation guidelines with a goal of making the\nextracted app features more useful and informative to the app developers. We\ntest the proposed changes via simulating the application of the new annotation\nguidelines and then evaluating the performance of the supervised machine\nlearning models trained on datasets annotated with initial and simulated\nguidelines. While the overall performance of automatic app feature extraction\nremains the same as compared to the model trained on the dataset with initial\nannotations, the features extracted by the model trained on the dataset with\nsimulated new annotations are less noisy and more informative to the app\ndevelopers. Secondly, we are interested in what kind of annotated training data\nis necessary for training an automatic app feature extraction model. In\nparticular, we explore whether the training set should contain annotated app\nreviews from those apps/app categories on which the model is subsequently\nplanned to be applied, or is it sufficient to have annotated app reviews from\nany app available for training, even when these apps are from very different\ncategories compared to the test app. Our experiments show that having annotated\ntraining reviews from the test app is not necessary although including them\ninto training set helps to improve recall. Furthermore, we test whether\naugmenting the training set with annotated product reviews helps to improve the\nperformance of app feature extraction. We find that the models trained on\naugmented training set lead to improved recall but at the cost of the drop in\nprecision.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:07:14 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Shah", "Faiz Ali", ""], ["Sirts", "Kairit", ""], ["Pfahl", "Dietmar", ""]]}, {"id": "1810.05188", "submitter": "Young Hun Jung", "authors": "Young Hun Jung, Ambuj Tewari", "title": "Fighting Contextual Bandits with Stochastic Smoothing", "comments": "merged to a manuscript \"Online Learning via the Differential Privacy\n  Lens,\" which can be found here: arXiv:1711.10019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new stochastic smoothing perspective to study adversarial\ncontextual bandit problems. We propose a general algorithm template that\nrepresents random perturbation based algorithms and identify several\nperturbation distributions that lead to strong regret bounds. Using the idea of\nsmoothness, we provide an $O(\\sqrt{T})$ zero-order bound for the vanilla\nalgorithm and an $O(L^{*2/3}_{T})$ first-order bound for the clipped version.\nThese bounds hold when the algorithms use with a variety of distributions that\nhave a bounded hazard rate. Our algorithm template includes EXP4 as a special\ncase corresponding to the Gumbel perturbation. Our regret bounds match existing\nresults for EXP4 without relying on the specific properties of the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:07:43 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 00:52:25 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Jung", "Young Hun", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1810.05193", "submitter": "Mariia Vladimirova", "authors": "Mariia Vladimirova, Jakob Verbeek, Pablo Mesejo and Julyan Arbel", "title": "Understanding Priors in Bayesian Neural Networks at the Unit Level", "comments": "10 pages, 5 figures, ICML'19 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate deep Bayesian neural networks with Gaussian weight priors and\na class of ReLU-like nonlinearities. Bayesian neural networks with Gaussian\npriors are well known to induce an L2, \"weight decay\", regularization. Our\nresults characterize a more intricate regularization effect at the level of the\nunit activations. Our main result establishes that the induced prior\ndistribution on the units before and after activation becomes increasingly\nheavy-tailed with the depth of the layer. We show that first layer units are\nGaussian, second layer units are sub-exponential, and units in deeper layers\nare characterized by sub-Weibull distributions. Our results provide new\ntheoretical insight on deep Bayesian neural networks, which we corroborate with\nsimulation experiments.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:26:50 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 15:23:50 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Vladimirova", "Mariia", ""], ["Verbeek", "Jakob", ""], ["Mesejo", "Pablo", ""], ["Arbel", "Julyan", ""]]}, {"id": "1810.05206", "submitter": "Dawei Yang", "authors": "Chaowei Xiao, Dawei Yang, Bo Li, Jia Deng, Mingyan Liu", "title": "MeshAdv: Adversarial Meshes for Visual Recognition", "comments": "Published in IEEE CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly expressive models such as deep neural networks (DNNs) have been widely\napplied to various applications. However, recent studies show that DNNs are\nvulnerable to adversarial examples, which are carefully crafted inputs aiming\nto mislead the predictions. Currently, the majority of these studies have\nfocused on perturbation added to image pixels, while such manipulation is not\nphysically realistic. Some works have tried to overcome this limitation by\nattaching printable 2D patches or painting patterns onto surfaces, but can be\npotentially defended because 3D shape features are intact. In this paper, we\npropose meshAdv to generate \"adversarial 3D meshes\" from objects that have rich\nshape features but minimal textural variation. To manipulate the shape or\ntexture of the objects, we make use of a differentiable renderer to compute\naccurate shading on the shape and propagate the gradient. Extensive experiments\nshow that the generated 3D meshes are effective in attacking both classifiers\nand object detectors. We evaluate the attack under different viewpoints. In\naddition, we design a pipeline to perform black-box attack on a photorealistic\nrenderer with unknown rendering parameters.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:01:10 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 19:43:54 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Xiao", "Chaowei", ""], ["Yang", "Dawei", ""], ["Li", "Bo", ""], ["Deng", "Jia", ""], ["Liu", "Mingyan", ""]]}, {"id": "1810.05207", "submitter": "Zoltan Szabo", "authors": "Zoltan Szabo and Bharath K. Sriperumbudur", "title": "On Kernel Derivative Approximation with Random Fourier Features", "comments": "AISTATS-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Fourier features (RFF) represent one of the most popular and\nwide-spread techniques in machine learning to scale up kernel algorithms.\nDespite the numerous successful applications of RFFs, unfortunately, quite\nlittle is understood theoretically on their optimality and limitations of their\nperformance. Only recently, precise statistical-computational trade-offs have\nbeen established for RFFs in the approximation of kernel values, kernel ridge\nregression, kernel PCA and SVM classification. Our goal is to spark the\ninvestigation of optimality of RFF-based approximations in tasks involving not\nonly function values but derivatives, which naturally lead to optimization\nproblems with kernel derivatives. Particularly, in this paper, we focus on the\napproximation quality of RFFs for kernel derivatives and prove that the\nexisting finite-sample guarantees can be improved exponentially in terms of the\ndomain where they hold, using recent tools from unbounded empirical process\ntheory. Our result implies that the same approximation guarantee is attainable\nfor kernel derivatives using RFF as achieved for kernel values.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:03:11 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2018 13:55:57 GMT"}, {"version": "v3", "created": "Sat, 9 Feb 2019 20:37:55 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Szabo", "Zoltan", ""], ["Sriperumbudur", "Bharath K.", ""]]}, {"id": "1810.05221", "submitter": "Gilad Katz", "authors": "Yotam Intrator, Gilad Katz, Asaf Shabtai", "title": "MDGAN: Boosting Anomaly Detection Using \\\\Multi-Discriminator Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is often considered a challenging field of machine learning\ndue to the difficulty of obtaining anomalous samples for training and the need\nto obtain a sufficient amount of training data. In recent years, autoencoders\nhave been shown to be effective anomaly detectors that train only on \"normal\"\ndata. Generative adversarial networks (GANs) have been used to generate\nadditional training samples for classifiers, thus making them more accurate and\nrobust. However, in anomaly detection GANs are only used to reconstruct\nexisting samples rather than to generate additional ones. This stems both from\nthe small amount and lack of diversity of anomalous data in most domains. In\nthis study we propose MDGAN, a novel GAN architecture for improving anomaly\ndetection through the generation of additional samples. Our approach uses two\ndiscriminators: a dense network for determining whether the generated samples\nare of sufficient quality (i.e., valid) and an autoencoder that serves as an\nanomaly detector. MDGAN enables us to reconcile two conflicting goals: 1)\ngenerate high-quality samples that can fool the first discriminator, and 2)\ngenerate samples that can eventually be effectively reconstructed by the second\ndiscriminator, thus improving its performance. Empirical evaluation on a\ndiverse set of datasets demonstrates the merits of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:45:30 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Intrator", "Yotam", ""], ["Katz", "Gilad", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1810.05222", "submitter": "Michael Kuchnik", "authors": "Michael Kuchnik, Virginia Smith", "title": "Efficient Augmentation via Data Subsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is commonly used to encode invariances in learning methods.\nHowever, this process is often performed in an inefficient manner, as\nartificial examples are created by applying a number of transformations to all\npoints in the training set. The resulting explosion of the dataset size can be\nan issue in terms of storage and training costs, as well as in selecting and\ntuning the optimal set of transformations to apply. In this work, we\ndemonstrate that it is possible to significantly reduce the number of data\npoints included in data augmentation while realizing the same accuracy and\ninvariance benefits of augmenting the entire dataset. We propose a novel set of\nsubsampling policies, based on model influence and loss, that can achieve a 90%\nreduction in augmentation set size while maintaining the accuracy gains of\nstandard data augmentation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:50:08 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 13:23:42 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kuchnik", "Michael", ""], ["Smith", "Virginia", ""]]}, {"id": "1810.05236", "submitter": "Luigi Nardi", "authors": "Luigi Nardi and David Koeplinger and Kunle Olukotun", "title": "Practical Design Space Exploration", "comments": "12 pages, MASCOTS 2019 conference\n  (https://sites.google.com/view/mascots-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective optimization is a crucial matter in computer systems design\nspace exploration because real-world applications often rely on a trade-off\nbetween several objectives. Derivatives are usually not available or\nimpractical to compute and the feasibility of an experiment can not always be\ndetermined in advance. These problems are particularly difficult when the\nfeasible region is relatively small, and it may be prohibitive to even find a\nfeasible experiment, let alone an optimal one.\n  We introduce a new methodology and corresponding software framework,\nHyperMapper 2.0, which handles multi-objective optimization, unknown\nfeasibility constraints, and categorical/ordinal variables. This new\nmethodology also supports injection of the user prior knowledge in the search\nwhen available. All of these features are common requirements in computer\nsystems but rarely exposed in existing design space exploration systems. The\nproposed methodology follows a white-box model which is simple to understand\nand interpret (unlike, for example, neural networks) and can be used by the\nuser to better understand the results of the automatic search.\n  We apply and evaluate the new methodology to the automatic static tuning of\nhardware accelerators within the recently introduced Spatial programming\nlanguage, with minimization of design run-time and compute logic under the\nconstraint of the design fitting in a target field-programmable gate array\nchip. Our results show that HyperMapper 2.0 provides better Pareto fronts\ncompared to state-of-the-art baselines, with better or competitive hypervolume\nindicator and with 8x improvement in sampling budget for most of the benchmarks\nexplored.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 20:23:57 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 21:17:47 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 22:33:56 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Nardi", "Luigi", ""], ["Koeplinger", "David", ""], ["Olukotun", "Kunle", ""]]}, {"id": "1810.05246", "submitter": "Chris Donahue", "authors": "Chris Donahue, Ian Simon, Sander Dieleman", "title": "Piano Genie", "comments": "Published as a conference paper at ACM IUI 2019", "journal-ref": null, "doi": "10.1145/3301275.3302288", "report-no": null, "categories": "cs.LG cs.HC cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Piano Genie, an intelligent controller which allows non-musicians\nto improvise on the piano. With Piano Genie, a user performs on a simple\ninterface with eight buttons, and their performance is decoded into the space\nof plausible piano music in real time. To learn a suitable mapping procedure\nfor this problem, we train recurrent neural network autoencoders with discrete\nbottlenecks: an encoder learns an appropriate sequence of buttons corresponding\nto a piano piece, and a decoder learns to map this sequence back to the\noriginal piece. During performance, we substitute a user's input for the\nencoder output, and play the decoder's prediction each time the user presses a\nbutton. To improve the intuitiveness of Piano Genie's performance behavior, we\nimpose musically meaningful constraints over the encoder's outputs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 21:00:44 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 08:53:31 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Donahue", "Chris", ""], ["Simon", "Ian", ""], ["Dieleman", "Sander", ""]]}, {"id": "1810.05247", "submitter": "Deepjyoti Deka", "authors": "Wenting Li, Deepjyoti Deka, Michael Chertkov, Meng Wang", "title": "Real-time Faulted Line Localization and PMU Placement in Power Systems\n  through Convolutional Neural Networks", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse fault types, fast re-closures, and complicated transient states after\na fault event make real-time fault location in power grids challenging.\nExisting localization techniques in this area rely on simplistic assumptions,\nsuch as static loads, or require much higher sampling rates or total\nmeasurement availability. This paper proposes a faulted line localization\nmethod based on a Convolutional Neural Network (CNN) classifier using bus\nvoltages. Unlike prior data-driven methods, the proposed classifier is based on\nfeatures with physical interpretations that improve the robustness of the\nlocation performance. The accuracy of our CNN based localization tool is\ndemonstrably superior to other machine learning classifiers in the literature.\nTo further improve the location performance, a joint phasor measurement units\n(PMU) placement strategy is proposed and validated against other methods. A\nsignificant aspect of our methodology is that under very low observability (7%\nof buses), the algorithm is still able to localize the faulted line to a small\nneighborhood with high probability. The performance of our scheme is validated\nthrough simulations of faults of various types in the IEEE 39-bus and 68-bus\npower systems under varying uncertain conditions, system observability, and\nmeasurement quality.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 21:06:33 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 01:55:50 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Li", "Wenting", ""], ["Deka", "Deepjyoti", ""], ["Chertkov", "Michael", ""], ["Wang", "Meng", ""]]}, {"id": "1810.05270", "submitter": "Zhuang Liu", "authors": "Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, Trevor Darrell", "title": "Rethinking the Value of Network Pruning", "comments": "ICLR 2019. Significant revisions from the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning is widely used for reducing the heavy inference cost of deep\nmodels in low-resource settings. A typical pruning algorithm is a three-stage\npipeline, i.e., training (a large model), pruning and fine-tuning. During\npruning, according to a certain criterion, redundant weights are pruned and\nimportant weights are kept to best preserve the accuracy. In this work, we make\nseveral surprising observations which contradict common beliefs. For all\nstate-of-the-art structured pruning algorithms we examined, fine-tuning a\npruned model only gives comparable or worse performance than training that\nmodel with randomly initialized weights. For pruning algorithms which assume a\npredefined target network architecture, one can get rid of the full pipeline\nand directly train the target network from scratch. Our observations are\nconsistent for multiple network architectures, datasets, and tasks, which imply\nthat: 1) training a large, over-parameterized model is often not necessary to\nobtain an efficient final model, 2) learned \"important\" weights of the large\nmodel are typically not useful for the small pruned model, 3) the pruned\narchitecture itself, rather than a set of inherited \"important\" weights, is\nmore crucial to the efficiency in the final model, which suggests that in some\ncases pruning can be useful as an architecture search paradigm. Our results\nsuggest the need for more careful baseline evaluations in future research on\nstructured pruning methods. We also compare with the \"Lottery Ticket\nHypothesis\" (Frankle & Carbin 2019), and find that with optimal learning rate,\nthe \"winning ticket\" initialization as used in Frankle & Carbin (2019) does not\nbring improvement over random initialization.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 22:15:28 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 05:58:11 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Liu", "Zhuang", ""], ["Sun", "Mingjie", ""], ["Zhou", "Tinghui", ""], ["Huang", "Gao", ""], ["Darrell", "Trevor", ""]]}, {"id": "1810.05290", "submitter": "Young Hun Jung", "authors": "Daniel T. Zhang, Young Hun Jung, Ambuj Tewari", "title": "Online Multiclass Boosting with Bandit Feedback", "comments": "Accepted in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present online boosting algorithms for multiclass classification with\nbandit feedback, where the learner only receives feedback about the correctness\nof its prediction. We propose an unbiased estimate of the loss using a\nrandomized prediction, allowing the model to update its weak learners with\nlimited information. Using the unbiased estimate, we extend two full\ninformation boosting algorithms (Jung et al., 2017) to the bandit setting. We\nprove that the asymptotic error bounds of the bandit algorithms exactly match\ntheir full information counterparts. The cost of restricted feedback is\nreflected in the larger sample complexity. Experimental results also support\nour theoretical findings, and performance of the proposed models is comparable\nto that of an existing bandit boosting algorithm, which is limited to use\nbinary weak learners.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 23:47:21 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 05:28:45 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Daniel T.", ""], ["Jung", "Young Hun", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1810.05305", "submitter": "Hunter Lang", "authors": "Hunter Lang, David Sontag, Aravindan Vijayaraghavan", "title": "Block Stability for MAP Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the empirical success of approximate MAP inference, recent work\n(Lang et al., 2018) has shown that some popular approximation algorithms\nperform very well when the input instance is stable. The simplest stability\ncondition assumes that the MAP solution does not change at all when some of the\npairwise potentials are (adversarially) perturbed. Unfortunately, this strong\ncondition does not seem to be satisfied in practice. In this paper, we\nintroduce a significantly more relaxed condition that only requires blocks\n(portions) of an input instance to be stable. Under this block stability\ncondition, we prove that the pairwise LP relaxation is persistent on the stable\nblocks. We complement our theoretical results with an empirical evaluation of\nreal-world MAP inference instances from computer vision. We design an algorithm\nto find stable blocks, and find that these real instances have large stable\nregions. Our work gives a theoretical explanation for the widespread empirical\nphenomenon of persistency for this LP relaxation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 01:17:38 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 00:52:41 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Lang", "Hunter", ""], ["Sontag", "David", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1810.05347", "submitter": "Xiao Li", "authors": "Xiao Li, Hanchen Xu, Jinming Zhang, Hua-hua Chang", "title": "Optimal Hierarchical Learning Path Design with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-learning systems are capable of providing more adaptive and efficient\nlearning experiences for students than the traditional classroom setting. A key\ncomponent of such systems is the learning strategy, the algorithm that designs\nthe learning paths for students based on information such as the students'\ncurrent progresses, their skills, learning materials, and etc. In this paper,\nwe address the problem of finding the optimal learning strategy for an\nE-learning system. To this end, we first develop a model for students'\nhierarchical skills in the E-learning system. Based on the hierarchical skill\nmodel and the classical cognitive diagnosis model, we further develop a\nframework to model various proficiency levels of hierarchical skills. The\noptimal learning strategy on top of the hierarchical structure is found by\napplying a model-free reinforcement learning method, which does not require\ninformation on students' learning transition process. The effectiveness of the\nproposed framework is demonstrated via numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 04:03:20 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Li", "Xiao", ""], ["Xu", "Hanchen", ""], ["Zhang", "Jinming", ""], ["Chang", "Hua-hua", ""]]}, {"id": "1810.05369", "submitter": "Colin Wei", "authors": "Colin Wei, Jason D. Lee, Qiang Liu, Tengyu Ma", "title": "Regularization Matters: Generalization and Optimization of Neural Nets\n  v.s. their Induced Kernel", "comments": "version 2: title changed from originally \"On the Margin Theory of\n  Feedforward Neural Networks\". Substantial changes from old version of paper,\n  including a new lower bound on NTK sample complexity version 3: reorganized\n  NTK lower bound proof version 4: reorganized proof of optimization result", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that on sufficiently over-parametrized neural nets,\ngradient descent with relatively large initialization optimizes a prediction\nfunction in the RKHS of the Neural Tangent Kernel (NTK). This analysis leads to\nglobal convergence results but does not work when there is a standard $\\ell_2$\nregularizer, which is useful to have in practice. We show that sample\nefficiency can indeed depend on the presence of the regularizer: we construct a\nsimple distribution in d dimensions which the optimal regularized neural net\nlearns with $O(d)$ samples but the NTK requires $\\Omega(d^2)$ samples to learn.\nTo prove this, we establish two analysis tools: i) for multi-layer feedforward\nReLU nets, we show that the global minimizer of a weakly-regularized\ncross-entropy loss is the max normalized margin solution among all neural nets,\nwhich generalizes well; ii) we develop a new technique for proving lower bounds\nfor kernel methods, which relies on showing that the kernel cannot focus on\ninformative features. Motivated by our generalization results, we study whether\nthe regularized global optimum is attainable. We prove that for infinite-width\ntwo-layer nets, noisy gradient descent optimizes the regularized neural net\nloss to a global minimum in polynomial iterations.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 06:21:22 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 09:04:32 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 06:33:39 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 06:17:48 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wei", "Colin", ""], ["Lee", "Jason D.", ""], ["Liu", "Qiang", ""], ["Ma", "Tengyu", ""]]}, {"id": "1810.05394", "submitter": "Meenakshi Sarkar", "authors": "Meenakshi Sarkar, Debasish Ghose", "title": "Sequential Learning of Movement Prediction in Dynamic Environments using\n  LSTM Autoencoder", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting movement of objects while the action of learning agent interacts\nwith the dynamics of the scene still remains a key challenge in robotics. We\npropose a multi-layer Long Short Term Memory (LSTM) autoendocer network that\npredicts future frames for a robot navigating in a dynamic environment with\nmoving obstacles. The autoencoder network is composed of a state and action\nconditioned decoder network that reconstructs the future frames of video,\nconditioned on the action taken by the agent. The input image frames are first\ntransformed into low dimensional feature vectors with a pre-trained encoder\nnetwork and then reconstructed with the LSTM autoencoder network to generate\nthe future frames. A virtual environment, based on the OpenAi-Gym framework for\nrobotics, is used to gather training data and test the proposed network. The\ninitial experiments show promising results indicating that these predicted\nframes can be used by an appropriate reinforcement learning framework in future\nto navigate around dynamic obstacles.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 08:11:13 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Sarkar", "Meenakshi", ""], ["Ghose", "Debasish", ""]]}, {"id": "1810.05440", "submitter": "Manolis Tsakiris", "authors": "Manolis C. Tsakiris, Liangzu Peng, Aldo Conca, Laurent Kneip, Yuanming\n  Shi, Hayoung Choi", "title": "An algebraic-geometric approach for linear regression without\n  correspondences", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression without correspondences is the problem of performing a\nlinear regression fit to a dataset for which the correspondences between the\nindependent samples and the observations are unknown. Such a problem naturally\narises in diverse domains such as computer vision, data mining, communications\nand biology. In its simplest form, it is tantamount to solving a linear system\nof equations, for which the entries of the right hand side vector have been\npermuted. This type of data corruption renders the linear regression task\nconsiderably harder, even in the absence of other corruptions, such as noise,\noutliers or missing entries. Existing methods are either applicable only to\nnoiseless data or they are very sensitive to initialization or they work only\nfor partially shuffled data. In this paper we address these issues via an\nalgebraic geometric approach, which uses symmetric polynomials to extract\npermutation-invariant constraints that the parameters $\\xi^* \\in \\Re^n$ of the\nlinear regression model must satisfy. This naturally leads to a polynomial\nsystem of $n$ equations in $n$ unknowns, which contains $\\xi^*$ in its root\nlocus. Using the machinery of algebraic geometry we prove that as long as the\nindependent samples are generic, this polynomial system is always consistent\nwith at most $n!$ complex roots, regardless of any type of corruption inflicted\non the observations. The algorithmic implication of this fact is that one can\nalways solve this polynomial system and use its most suitable root as\ninitialization to the Expectation Maximization algorithm. To the best of our\nknowledge, the resulting method is the first working solution for small values\nof $n$ able to handle thousands of fully shuffled noisy observations in\nmilliseconds.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 10:22:05 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 12:16:11 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Tsakiris", "Manolis C.", ""], ["Peng", "Liangzu", ""], ["Conca", "Aldo", ""], ["Kneip", "Laurent", ""], ["Shi", "Yuanming", ""], ["Choi", "Hayoung", ""]]}, {"id": "1810.05466", "submitter": "Lucas Deecke", "authors": "Lucas Deecke, Iain Murray, Hakan Bilen", "title": "Mode Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization methods are a central building block in the deep learning\ntoolbox. They accelerate and stabilize training, while decreasing the\ndependence on manually tuned learning rate schedules. When learning from\nmulti-modal distributions, the effectiveness of batch normalization (BN),\narguably the most prominent normalization method, is reduced. As a remedy, we\npropose a more flexible approach: by extending the normalization to more than a\nsingle mean and variance, we detect modes of data on-the-fly, jointly\nnormalizing samples that share common features. We demonstrate that our method\noutperforms BN and other widely used normalization techniques in several\nexperiments, including single and multi-task datasets.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:10:10 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Deecke", "Lucas", ""], ["Murray", "Iain", ""], ["Bilen", "Hakan", ""]]}, {"id": "1810.05471", "submitter": "Eugene Ndiaye", "authors": "Eugene Ndiaye and Tam Le and Olivier Fercoq and Joseph Salmon and\n  Ichiro Takeuchi", "title": "Safe Grid Search with Optimal Complexity", "comments": null, "journal-ref": "International Conference on Machine Learning, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular machine learning estimators involve regularization parameters that\ncan be challenging to tune, and standard strategies rely on grid search for\nthis task. In this paper, we revisit the techniques of approximating the\nregularization path up to predefined tolerance $\\epsilon$ in a unified\nframework and show that its complexity is $O(1/\\sqrt[d]{\\epsilon})$ for\nuniformly convex loss of order $d \\geq 2$ and $O(1/\\sqrt{\\epsilon})$ for\nGeneralized Self-Concordant functions. This framework encompasses least-squares\nbut also logistic regression, a case that as far as we know was not handled as\nprecisely in previous works. We leverage our technique to provide refined\nbounds on the validation error as well as a practical algorithm for\nhyperparameter tuning. The latter has global convergence guarantee when\ntargeting a prescribed accuracy on the validation set. Last but not least, our\napproach helps relieving the practitioner from the (often neglected) task of\nselecting a stopping criterion when optimizing over the training set: our\nmethod automatically calibrates this criterion based on the targeted accuracy\non the validation set.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:16:52 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 11:17:35 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 04:49:13 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Le", "Tam", ""], ["Fercoq", "Olivier", ""], ["Salmon", "Joseph", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1810.05497", "submitter": "Rebecca Steorts", "authors": "Rebecca C. Steorts and Anshumali Shrivastava", "title": "Probabilistic Blocking with An Application to the Syrian Conflict", "comments": "16 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:1510.07714, arXiv:1710.02690", "journal-ref": "Steorts R.C., Shrivastava A. (2018) Probabilistic Blocking with an\n  Application to the Syrian Conflict. PSD (2018)", "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution seeks to merge databases as to remove duplicate entries\nwhere unique identifiers are typically unknown. We review modern blocking\napproaches for entity resolution, focusing on those based upon locality\nsensitive hashing (LSH). First, we introduce $k$-means locality sensitive\nhashing (KLSH), which is based upon the information retrieval literature and\nclusters similar records into blocks using a vector-space representation and\nprojections. Second, we introduce a subquadratic variant of LSH to the\nliterature, known as Densified One Permutation Hashing (DOPH). Third, we\npropose a weighted variant of DOPH. We illustrate each method on an application\nto a subset of the ongoing Syrian conflict, giving a discussion of each method.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 01:16:31 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Steorts", "Rebecca C.", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1810.05500", "submitter": "Bastiaan Veeling", "authors": "Bastiaan S. Veeling, Rianne van den Berg, Max Welling", "title": "Predictive Uncertainty through Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-risk domains require reliable confidence estimates from predictive\nmodels. Deep latent variable models provide these, but suffer from the rigid\nvariational distributions used for tractable inference, which err on the side\nof overconfidence. We propose Stochastic Quantized Activation Distributions\n(SQUAD), which imposes a flexible yet tractable distribution over discretized\nlatent variables. The proposed method is scalable, self-normalizing and sample\nefficient. We demonstrate that the model fully utilizes the flexible\ndistribution, learns interesting non-linearities, and provides predictive\nuncertainty of competitive quality.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 13:37:43 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Veeling", "Bastiaan S.", ""], ["Berg", "Rianne van den", ""], ["Welling", "Max", ""]]}, {"id": "1810.05504", "submitter": "Parviz Asghari", "authors": "Parviz Asghari and Ehsan Nazerfard", "title": "Activity Recognition using Hierarchical Hidden Markov Models on\n  Streaming Sensor Data", "comments": null, "journal-ref": null, "doi": "10.1109/ISTEL.2018.8661053", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity recognition from sensor data deals with various challenges, such as\noverlapping activities, activity labeling, and activity detection. Although\neach challenge in the field of recognition has great importance, the most\nimportant one refers to online activity recognition. The present study tries to\nuse online hierarchical hidden Markov model to detect an activity on the stream\nof sensor data which can predict the activity in the environment with any\nsensor event. The activity recognition samples were labeled by the statistical\nfeatures such as the duration of activity. The results of our proposed method\ntest on two different datasets of smart homes in the real world showed that one\ndataset has improved 4% and reached (59%) while the results reached 64.6% for\nthe other data by using the best methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 20:13:46 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Asghari", "Parviz", ""], ["Nazerfard", "Ehsan", ""]]}, {"id": "1810.05507", "submitter": "Zixing Zhang", "authors": "Zixing Zhang, Jing Han, Eduardo Coutinho, Bj\\\"orn Schuller", "title": "Dynamic Difficulty Awareness Training for Continuous Emotion Prediction", "comments": "accepted by IEEE T-MM", "journal-ref": null, "doi": "10.1109/TMM.2018.2871949", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-continuous emotion prediction has become an increasingly compelling task\nin machine learning. Considerable efforts have been made to advance the\nperformance of these systems. Nonetheless, the main focus has been the\ndevelopment of more sophisticated models and the incorporation of different\nexpressive modalities (e. g., speech, face, and physiology). In this paper,\nmotivated by the benefit of difficulty awareness in a human learning procedure,\nwe propose a novel machine learning framework, namely, Dynamic Difficulty\nAwareness Training (DDAT), which sheds fresh light on the research -- directly\nexploiting the difficulties in learning to boost the machine learning process.\nThe DDAT framework consists of two stages: information retrieval and\ninformation exploitation. In the first stage, we make use of the reconstruction\nerror of input features or the annotation uncertainty to estimate the\ndifficulty of learning specific information. The obtained difficulty level is\nthen used in tandem with original features to update the model input in a\nsecond learning stage with the expectation that the model can learn to focus on\nhigh difficulty regions of the learning process. We perform extensive\nexperiments on a benchmark database (RECOLA) to evaluate the effectiveness of\nthe proposed framework. The experimental results show that our approach\noutperforms related baselines as well as other well-established time-continuous\nemotion prediction systems, which suggests that dynamically integrating the\ndifficulty information for neural networks can help enhance the learning\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 07:30:52 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Zhang", "Zixing", ""], ["Han", "Jing", ""], ["Coutinho", "Eduardo", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1810.05512", "submitter": "David Leroy", "authors": "David Leroy, Alice Coucke, Thibaut Lavril, Thibault Gisselbrecht and\n  Joseph Dureau", "title": "Federated Learning for Keyword Spotting", "comments": "Accepted for publication to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical approach based on federated learning to solve\nout-of-domain issues with continuously running embedded speech-based models\nsuch as wake word detectors. We conduct an extensive empirical study of the\nfederated averaging algorithm for the \"Hey Snips\" wake word based on a\ncrowdsourced dataset that mimics a federation of wake word users. We\nempirically demonstrate that using an adaptive averaging strategy inspired from\nAdam in place of standard weighted model averaging highly reduces the number of\ncommunication rounds required to reach our target performance. The associated\nupstream communication costs per user are estimated at 8 MB, which is a\nreasonable in the context of smart home voice assistants. Additionally, the\ndataset used for these experiments is being open sourced with the aim of\nfostering further transparent research in the application of federated learning\nto speech data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:41:15 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 10:07:18 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 09:31:52 GMT"}, {"version": "v4", "created": "Mon, 18 Feb 2019 18:41:00 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Leroy", "David", ""], ["Coucke", "Alice", ""], ["Lavril", "Thibaut", ""], ["Gisselbrecht", "Thibault", ""], ["Dureau", "Joseph", ""]]}, {"id": "1810.05524", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh Kassani, Seyed Esmaeel\n  Najafi", "title": "Introducing a hybrid model of DEA and data mining in evaluating\n  efficiency. Case study: Bank Branches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The banking industry is very important for an economic cycle of each country\nand provides some quality of services for us. With the advancement in\ntechnology and rapidly increasing of the complexity of the business\nenvironment, it has become more competitive than the past so that efficiency\nanalysis in the banking industry attracts much attention in recent years. From\nmany aspects, such analyses at the branch level are more desirable. Evaluating\nthe branch performance with the purpose of eliminating deficiency can be a\ncrucial issue for branch managers to measure branch efficiency. This work not\nonly can lead to a better understanding of bank branch performance but also\ngive further information to enhance managerial decisions to recognize\nproblematic areas. To achieve this purpose, this study presents an integrated\napproach based on Data Envelopment Analysis (DEA), Clustering algorithms and\nPolynomial Pattern Classifier for constructing a classifier to identify a class\nof bank branches. First, the efficiency estimates of individual branches are\nevaluated by using the DEA approach. Next, when the range and number of classes\nwere identified by experts, the number of clusters is identified by an\nagglomerative hierarchical clustering algorithm based on some statistical\nmethods. Next, we divide our raw data into k clusters By means of\nself-organizing map (SOM) neural networks. Finally, all clusters are fed into\nthe reduced multivariate polynomial model to predict the classes of data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 18:59:29 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Kassani", "Peyman Hosseinzadeh", ""], ["Najafi", "Seyed Esmaeel", ""]]}, {"id": "1810.05526", "submitter": "Bas van Stein", "authors": "Bas van Stein, Hao Wang, Thomas B\\\"ack", "title": "Automatic Configuration of Deep Neural Networks with EGO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing the architecture for an artificial neural network is a cumbersome\ntask because of the numerous parameters to configure, including activation\nfunctions, layer types, and hyper-parameters. With the large number of\nparameters for most networks nowadays, it is intractable to find a good\nconfiguration for a given task by hand. In this paper an Efficient Global\nOptimization (EGO) algorithm is adapted to automatically optimize and configure\nconvolutional neural network architectures. A configurable neural network\narchitecture based solely on convolutional layers is proposed for the\noptimization. Without using any knowledge on the target problem and not using\nany data augmentation techniques, it is shown that on several image\nclassification tasks this approach is able to find competitive network\narchitectures in terms of prediction accuracy, compared to the best\nhand-crafted ones in literature. In addition, a very small training budget (200\nevaluations and 10 epochs in training) is spent on each optimized architectures\nin contrast to the usual long training time of hand-crafted networks. Moreover,\ninstead of the standard sequential evaluation in EGO, several candidate\narchitectures are proposed and evaluated in parallel, which saves the execution\noverheads significantly and leads to an efficient automation for deep neural\nnetwork design.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:06:15 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["van Stein", "Bas", ""], ["Wang", "Hao", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "1810.05533", "submitter": "Navneet Kumar", "authors": "Navneet Madhu Kumar", "title": "Empowerment-driven Exploration using Mutual Information Estimation", "comments": "Preprint. Under Development. arXiv admin note: text overlap with\n  arXiv:1807.02078 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a difficult challenge in reinforcement learning and is of\nprime importance in sparse reward environments. However, many of the state of\nthe art deep reinforcement learning algorithms, that rely on epsilon-greedy,\nfail on these environments. In such cases, empowerment can serve as an\nintrinsic reward signal to enable the agent to maximize the influence it has\nover the near future. We formulate empowerment as the channel capacity between\nstates and actions and is calculated by estimating the mutual information\nbetween the actions and the following states. The mutual information is\nestimated using Mutual Information Neural Estimator and a forward dynamics\nmodel. We demonstrate that an empowerment driven agent is able to improve\nsignificantly the score of a baseline DQN agent on the game of Montezuma's\nRevenge.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 06:34:18 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kumar", "Navneet Madhu", ""]]}, {"id": "1810.05546", "submitter": "Tim Pearce", "authors": "Tim Pearce, Felix Leibfried, Alexandra Brintrup, Mohamed Zaki, Andy\n  Neely", "title": "Uncertainty in Neural Networks: Approximately Bayesian Ensembling", "comments": "Please cite as published in AISTATS 2020", "journal-ref": "The 23rd International Conference on Artificial Intelligence and\n  Statistics, AISTATS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the uncertainty of a neural network's (NN) predictions is\nessential for many purposes. The Bayesian framework provides a principled\napproach to this, however applying it to NNs is challenging due to large\nnumbers of parameters and data. Ensembling NNs provides an easily\nimplementable, scalable method for uncertainty quantification, however, it has\nbeen criticised for not being Bayesian. This work proposes one modification to\nthe usual process that we argue does result in approximate Bayesian inference;\nregularising parameters about values drawn from a distribution which can be set\nequal to the prior. A theoretical analysis of the procedure in a simplified\nsetting suggests the recovered posterior is centred correctly but tends to have\nan underestimated marginal variance, and overestimated correlation. However,\ntwo conditions can lead to exact recovery. We argue that these conditions are\npartially present in NNs. Empirical evaluations demonstrate it has an advantage\nover standard ensembling, and is competitive with variational methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 14:26:34 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 11:07:20 GMT"}, {"version": "v3", "created": "Sun, 27 Jan 2019 13:22:11 GMT"}, {"version": "v4", "created": "Mon, 14 Oct 2019 16:14:46 GMT"}, {"version": "v5", "created": "Wed, 26 Feb 2020 12:21:59 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Pearce", "Tim", ""], ["Leibfried", "Felix", ""], ["Brintrup", "Alexandra", ""], ["Zaki", "Mohamed", ""], ["Neely", "Andy", ""]]}, {"id": "1810.05547", "submitter": "Mohammad Amin Nabian", "authors": "Mohammad Amin Nabian, Hadi Meidani", "title": "Physics-Driven Regularization of Deep Neural Networks for Enhanced\n  Engineering Design and Analysis", "comments": null, "journal-ref": "Journal of Computing and Information Science in Engineering, 20(1)\n  (2020)", "doi": "10.1115/1.4044507", "report-no": null, "categories": "cs.LG cs.CE cs.NA math.AP math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a physics-driven regularization method for\ntraining of deep neural networks (DNNs) for use in engineering design and\nanalysis problems. In particular, we focus on prediction of a physical system,\nfor which in addition to training data, partial or complete information on a\nset of governing laws is also available. These laws often appear in the form of\ndifferential equations, derived from first principles, empirically-validated\nlaws, or domain expertise, and are usually neglected in data-driven prediction\nof engineering systems. We propose a training approach that utilizes the known\ngoverning laws and regularizes data-driven DNN models by penalizing divergence\nfrom those laws. The first two numerical examples are synthetic examples, where\nwe show that in constructing a DNN model that best fits the measurements from a\nphysical system, the use of our proposed regularization results in DNNs that\nare more interpretable with smaller generalization errors, compared to other\ncommon regularization methods. The last two examples concern metamodeling for a\nrandom Burgers' system and for aerodynamic analysis of passenger vehicles,\nwhere we demonstrate that the proposed regularization provides superior\ngeneralization accuracy compared to other common alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:12:34 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 22:27:24 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Nabian", "Mohammad Amin", ""], ["Meidani", "Hadi", ""]]}, {"id": "1810.05558", "submitter": "Luigi Acerbi", "authors": "Luigi Acerbi", "title": "Variational Bayesian Monte Carlo", "comments": "In Advances in Neural Information Processing Systems 31 (NeurIPS\n  2018), pp. 8222-8232. (25 pages, 9 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many probabilistic models of interest in scientific computing and machine\nlearning have expensive, black-box likelihoods that prevent the application of\nstandard techniques for Bayesian inference, such as MCMC, which would require\naccess to the gradient or a large number of likelihood evaluations. We\nintroduce here a novel sample-efficient inference framework, Variational\nBayesian Monte Carlo (VBMC). VBMC combines variational inference with\nGaussian-process based, active-sampling Bayesian quadrature, using the latter\nto efficiently approximate the intractable integral in the variational\nobjective. Our method produces both a nonparametric approximation of the\nposterior distribution and an approximate lower bound of the model evidence,\nuseful for model selection. We demonstrate VBMC both on several synthetic\nlikelihoods and on a neuronal model with data from real neurons. Across all\ntested problems and dimensions (up to $D = 10$), VBMC performs consistently\nwell in reconstructing the posterior and the model evidence with a limited\nbudget of likelihood evaluations, unlike other methods that work only in very\nlow dimensions. Our framework shows great promise as a novel tool for posterior\nand model inference with expensive, black-box likelihoods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 14:50:13 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 12:47:30 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Acerbi", "Luigi", ""]]}, {"id": "1810.05567", "submitter": "Andr\\'e Martin", "authors": "Oleh Bodunov, Florian Schmidt, Andr\\'e Martin, Andrey Brito, Christof\n  Fetzer", "title": "Grand Challenge: Real-time Destination and ETA Prediction for Maritime\n  Traffic", "comments": null, "journal-ref": null, "doi": "10.1145/3210284.3220502", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our approach for solving the DEBS Grand Challenge\n2018. The challenge asks to provide a prediction for (i) a destination and the\n(ii) arrival time of ships in a streaming-fashion using Geo-spatial data in the\nmaritime context. Novel aspects of our approach include the use of ensemble\nlearning based on Random Forest, Gradient Boosting Decision Trees (GBDT),\nXGBoost Trees and Extremely Randomized Trees (ERT) in order to provide a\nprediction for a destination while for the arrival time, we propose the use of\nFeed-forward Neural Networks. In our evaluation, we were able to achieve an\naccuracy of 97% for the port destination classification problem and 90% (in\nmins) for the ETA prediction.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 15:14:00 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Bodunov", "Oleh", ""], ["Schmidt", "Florian", ""], ["Martin", "Andr\u00e9", ""], ["Brito", "Andrey", ""], ["Fetzer", "Christof", ""]]}, {"id": "1810.05571", "submitter": "Karsten Maurer", "authors": "Karsten Maurer and Walter Bennette", "title": "Facility Locations Utility for Uncovering Classifier Overconfidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessing the predictive accuracy of black box classifiers is challenging in\nthe absence of labeled test datasets. In these scenarios we may need to rely on\na human oracle to evaluate individual predictions; presenting the challenge to\ncreate query algorithms to guide the search for points that provide the most\ninformation about the classifier's predictive characteristics. Previous works\nhave focused on developing utility models and query algorithms for discovering\nunknown unknowns --- misclassifications with a predictive confidence above some\narbitrary threshold. However, if misclassifications occur at the rate reflected\nby the confidence values, then these search methods reveal nothing more than a\nproper assessment of predictive certainty. We are unable to properly mitigate\nthe risks associated with model deficiency when the model's confidence in\nprediction exceeds the actual model accuracy. We propose a facility locations\nutility model and corresponding greedy query algorithm that instead searches\nfor overconfident unknown unknowns. Through robust empirical experiments we\ndemonstrate that the greedy query algorithm with the facility locations utility\nmodel consistently results in oracle queries with superior performance in\ndiscovering overconfident unknown unknowns than previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 15:19:19 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Maurer", "Karsten", ""], ["Bennette", "Walter", ""]]}, {"id": "1810.05596", "submitter": "Vincenzo Lomonaco", "authors": "Claudia Carpineti, Vincenzo Lomonaco, Luca Bedogni, Marco Di Felice,\n  Luciano Bononi", "title": "Custom Dual Transportation Mode Detection by Smartphone Devices\n  Exploiting Sensor Diversity", "comments": "Pre-print of the accepted version for the 14th Workshop on Context\n  and Activity Modeling and Recognition (IEEE COMOREA 2018), Athens, Greece,\n  March 19-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making applications aware of the mobility experienced by the user can open\nthe door to a wide range of novel services in different use-cases, from smart\nparking to vehicular traffic monitoring. In the literature, there are many\ndifferent studies demonstrating the theoretical possibility of performing\nTransportation Mode Detection (TMD) by mining smart-phones embedded sensors\ndata. However, very few of them provide details on the benchmarking process and\non how to implement the detection process in practice. In this study, we\nprovide guidelines and fundamental results that can be useful for both\nresearcher and practitioners aiming at implementing a working TMD system. These\nguidelines consist of three main contributions. First, we detail the\nconstruction of a training dataset, gathered by heterogeneous users and\nincluding five different transportation modes; the dataset is made available to\nthe research community as reference benchmark. Second, we provide an in-depth\nanalysis of the sensor-relevance for the case of Dual TDM, which is required by\nmost of mobility-aware applications. Third, we investigate the possibility to\nperform TMD of unknown users/instances not present in the training set and we\ncompare with state-of-the-art Android APIs for activity recognition.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:31:43 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Carpineti", "Claudia", ""], ["Lomonaco", "Vincenzo", ""], ["Bedogni", "Luca", ""], ["Di Felice", "Marco", ""], ["Bononi", "Luciano", ""]]}, {"id": "1810.05597", "submitter": "Ruiqi Gao", "authors": "Ruiqi Gao, Jianwen Xie, Song-Chun Zhu, Ying Nian Wu", "title": "Learning Grid Cells as Vector Representation of Self-Position Coupled\n  with Matrix Representation of Self-Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a representational model for grid cells. In this model,\nthe 2D self-position of the agent is represented by a high-dimensional vector,\nand the 2D self-motion or displacement of the agent is represented by a matrix\nthat transforms the vector. Each component of the vector is a unit or a cell.\nThe model consists of the following three sub-models. (1) Vector-matrix\nmultiplication. The movement from the current position to the next position is\nmodeled by matrix-vector multiplication, i.e., the vector of the next position\nis obtained by multiplying the matrix of the motion to the vector of the\ncurrent position. (2) Magnified local isometry. The angle between two nearby\nvectors equals the Euclidean distance between the two corresponding positions\nmultiplied by a magnifying factor. (3) Global adjacency kernel. The inner\nproduct between two vectors measures the adjacency between the two\ncorresponding positions, which is defined by a kernel function of the Euclidean\ndistance between the two positions. Our representational model has explicit\nalgebra and geometry. It can learn hexagon patterns of grid cells, and it is\ncapable of error correction, path integral and path planning.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:34:07 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 06:17:11 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 00:22:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gao", "Ruiqi", ""], ["Xie", "Jianwen", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1810.05598", "submitter": "Thomas Kehrenberg", "authors": "Thomas Kehrenberg, Zexun Chen, Novi Quadrianto", "title": "Tuning Fairness by Balancing Target Labels", "comments": "Published in Frontiers in Artificial Intelligence, Volume 3 (2020)", "journal-ref": null, "doi": "10.3389/frai.2020.00033", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of fairness in machine learning models has recently attracted a lot\nof attention as ensuring it will ensure continued confidence of the general\npublic in the deployment of machine learning systems. We focus on mitigating\nthe harm incurred by a biased machine learning system that offers better\noutputs (e.g. loans, job interviews) for certain groups than for others. We\nshow that bias in the output can naturally be controlled in probabilistic\nmodels by introducing a latent target output. This formulation has several\nadvantages: first, it is a unified framework for several notions of group\nfairness such as Demographic Parity and Equality of Opportunity; second, it is\nexpressed as a marginalisation instead of a constrained problem; and third, it\nallows the encoding of our knowledge of what unbiased outputs should be.\nPractically, the second allows us to avoid unstable constrained optimisation\nprocedures and to reuse off-the-shelf toolboxes. The latter translates to the\nability to control the level of fairness by directly varying fairness target\nrates. In contrast, existing approaches rely on intermediate, arguably\nunintuitive, control parameters such as covariance thresholds.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:36:23 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 16:30:03 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 11:20:20 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 16:21:43 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 11:08:21 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Kehrenberg", "Thomas", ""], ["Chen", "Zexun", ""], ["Quadrianto", "Novi", ""]]}, {"id": "1810.05633", "submitter": "John Duchi", "authors": "Hilal Asi, John C. Duchi", "title": "Stochastic (Approximate) Proximal Point Methods: Convergence,\n  Optimality, and Adaptivity", "comments": "To appear in SIAM Journal on Optimization", "journal-ref": "SIAM Journal on Optimization 29(3), pp. 2257--2290, 2019", "doi": "10.1137/18M1230323", "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop model-based methods for solving stochastic convex optimization\nproblems, introducing the approximate-proximal point, or aProx, family, which\nincludes stochastic subgradient, proximal point, and bundle methods. When the\nmodeling approaches we propose are appropriately accurate, the methods enjoy\nstronger convergence and robustness guarantees than classical approaches, even\nthough the model-based methods typically add little to no computational\noverhead over stochastic subgradient methods. For example, we show that\nimproved models converge with probability 1 and enjoy optimal asymptotic\nnormality results under weak assumptions; these methods are also adaptive to a\nnatural class of what we term easy optimization problems, achieving linear\nconvergence under appropriate strong growth conditions on the objective. Our\nsubstantial experimental investigation shows the advantages of more accurate\nmodeling over standard subgradient methods across many smooth and non-smooth\noptimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 17:56:08 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 20:57:41 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Asi", "Hilal", ""], ["Duchi", "John C.", ""]]}, {"id": "1810.05640", "submitter": "Xinshang Wang", "authors": "Wang Chi Cheung and Will Ma and David Simchi-Levi and Xinshang Wang", "title": "Inventory Balancing with Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a general problem of allocating limited resources to heterogeneous\ncustomers over time under model uncertainty. Each type of customer can be\nserviced using different actions, each of which stochastically consumes some\ncombination of resources, and returns different rewards for the resources\nconsumed. We consider a general model where the resource consumption\ndistribution associated with each (customer type, action)-combination is not\nknown, but is consistent and can be learned over time. In addition, the\nsequence of customer types to arrive over time is arbitrary and completely\nunknown.\n  We overcome both the challenges of model uncertainty and customer\nheterogeneity by judiciously synthesizing two algorithmic frameworks from the\nliterature: inventory balancing, which \"reserves\" a portion of each resource\nfor high-reward customer types which could later arrive, and online learning,\nwhich shows how to \"explore\" the resource consumption distributions of each\ncustomer type under different actions. We define an auxiliary problem, which\nallows for existing competitive ratio and regret bounds to be seamlessly\nintegrated. Furthermore, we show that the performance guarantee generated by\nour framework is tight, that is, we provide an information-theoretic lower\nbound which shows that both the loss from competitive ratio and the loss for\nregret are relevant in the combined problem.\n  Finally, we demonstrate the efficacy of our algorithms on a publicly\navailable hotel data set. Our framework is highly practical in that it requires\nno historical data (no fitted customer choice models, nor forecasting of\ncustomer arrival patterns) and can be used to initialize allocation strategies\nin fast-changing environments.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:34:13 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Cheung", "Wang Chi", ""], ["Ma", "Will", ""], ["Simchi-Levi", "David", ""], ["Wang", "Xinshang", ""]]}, {"id": "1810.05642", "submitter": "Robert Krajewski", "authors": "Robert Krajewski, Julian Bock, Laurent Kloeker and Lutz Eckstein", "title": "The highD Dataset: A Drone Dataset of Naturalistic Vehicle Trajectories\n  on German Highways for Validation of Highly Automated Driving Systems", "comments": "IEEE International Conference on Intelligent Transportation Systems\n  (ITSC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario-based testing for the safety validation of highly automated vehicles\nis a promising approach that is being examined in research and industry. This\napproach heavily relies on data from real-world scenarios to derive the\nnecessary scenario information for testing. Measurement data should be\ncollected at a reasonable effort, contain naturalistic behavior of road users\nand include all data relevant for a description of the identified scenarios in\nsufficient quality. However, the current measurement methods fail to meet at\nleast one of the requirements. Thus, we propose a novel method to measure data\nfrom an aerial perspective for scenario-based validation fulfilling the\nmentioned requirements. Furthermore, we provide a large-scale naturalistic\nvehicle trajectory dataset from German highways called highD. We evaluate the\ndata in terms of quantity, variety and contained scenarios. Our dataset\nconsists of 16.5 hours of measurements from six locations with 110 000\nvehicles, a total driven distance of 45 000 km and 5600 recorded complete lane\nchanges. The highD dataset is available online at: http://www.highD-dataset.com\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 22:47:33 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Krajewski", "Robert", ""], ["Bock", "Julian", ""], ["Kloeker", "Laurent", ""], ["Eckstein", "Lutz", ""]]}, {"id": "1810.05644", "submitter": "Lahiru Jayasinghe", "authors": "Lahiru Jayasinghe, Tharaka Samarasinghe, Chau Yuen, Jenny Chen Ni Low,\n  and Shuzhi Sam Ge", "title": "Temporal Convolutional Memory Networks for Remaining Useful Life\n  Estimation of Industrial Machinery", "comments": "accepted to IEEE International Conference on Industrial Technology\n  (ICIT2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately estimating the remaining useful life (RUL) of industrial machinery\nis beneficial in many real-world applications. Estimation techniques have\nmainly utilized linear models or neural network based approaches with a focus\non short term time dependencies. This paper, introduces a system model that\nincorporates temporal convolutions with both long term and short term time\ndependencies. The proposed network learns salient features and complex temporal\nvariations in sensor values, and predicts the RUL. A data augmentation method\nis used for increased accuracy. The proposed method is compared with several\nstate-of-the-art algorithms on publicly available datasets. It demonstrates\npromising results, with superior results for datasets obtained from complex\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 08:00:33 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 10:11:11 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Jayasinghe", "Lahiru", ""], ["Samarasinghe", "Tharaka", ""], ["Yuen", "Chau", ""], ["Low", "Jenny Chen Ni", ""], ["Ge", "Shuzhi Sam", ""]]}, {"id": "1810.05665", "submitter": "Tianhang Zheng", "authors": "Tianhang Zheng, Changyou Chen, Kui Ren", "title": "Is PGD-Adversarial Training Necessary? Alternative Training via a\n  Soft-Quantization Network with Noisy-Natural Samples Only", "comments": "Further improvement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on adversarial attack and defense suggests that PGD is a\nuniversal $l_\\infty$ first-order attack, and PGD adversarial training can\nsignificantly improve network robustness against a wide range of first-order\n$l_\\infty$-bounded attacks, represented as the state-of-the-art defense method.\nHowever, an obvious weakness of PGD adversarial training is its\nhighly-computational cost in generating adversarial samples, making it\ncomputationally infeasible for large and high-resolution real datasets such as\nthe ImageNet dataset. In addition, recent work also has suggested a simple\n\"close-form\" solution to a robust model on MNIST. Therefore, a natural question\nraised is that is PGD adversarial training really necessary for robust defense?\nIn this paper, we give a negative answer by proposing a training paradigm that\nis comparable to PGD adversarial training on several standard datasets, while\nonly using noisy-natural samples. Specifically, we reformulate the min-max\nobjective in PGD adversarial training by a problem to minimize the original\nnetwork loss plus $l_1$ norms of its gradients w.r.t. the inputs. For the\n$l_1$-norm loss, we propose a computationally-feasible solution by embedding a\ndifferentiable soft-quantization layer after the network input layer. We show\nformally that the soft-quantization layer trained with noisy-natural samples is\nan alternative approach to minimizing the $l_1$-gradient norms as in PGD\nadversarial training. Extensive empirical evaluations on standard datasets show\nthat our proposed models are comparable to PGD-adversarially-trained models\nunder PGD and BPDA attacks. Remarkably, our method achieves a 24X speed-up on\nMNIST while maintaining a comparable defensive ability, and for the first time\nfine-tunes a robust Imagenet model within only two days. Code is provided on\n\\url{https://github.com/tianzheng4/Noisy-Training-Soft-Quantization}\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 01:06:05 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 17:31:50 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Zheng", "Tianhang", ""], ["Chen", "Changyou", ""], ["Ren", "Kui", ""]]}, {"id": "1810.05691", "submitter": "Erich Schubert", "authors": "Erich Schubert and Peter J. Rousseeuw", "title": "Faster k-Medoids Clustering: Improving the PAM, CLARA, and CLARANS\n  Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32047-8_16", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering non-Euclidean data is difficult, and one of the most used\nalgorithms besides hierarchical clustering is the popular algorithm\nPartitioning Around Medoids (PAM), also simply referred to as k-medoids. In\nEuclidean geometry the mean-as used in k-means-is a good estimator for the\ncluster center, but this does not hold for arbitrary dissimilarities. PAM uses\nthe medoid instead, the object with the smallest dissimilarity to all others in\nthe cluster. This notion of centrality can be used with any (dis-)similarity,\nand thus is of high relevance to many domains such as biology that require the\nuse of Jaccard, Gower, or more complex distances.\n  A key issue with PAM is its high run time cost. We propose modifications to\nthe PAM algorithm to achieve an O(k)-fold speedup in the second SWAP phase of\nthe algorithm, but will still find the same results as the original PAM\nalgorithm. If we slightly relax the choice of swaps performed (at comparable\nquality), we can further accelerate the algorithm by performing up to k swaps\nin each iteration. With the substantially faster SWAP, we can now also explore\nalternative strategies for choosing the initial medoids. We also show how the\nCLARA and CLARANS algorithms benefit from these modifications. It can easily be\ncombined with earlier approaches to use PAM and CLARA on big data (some of\nwhich use PAM as a subroutine, hence can immediately benefit from these\nimprovements), where the performance with high k becomes increasingly\nimportant.\n  In experiments on real data with k=100, we observed a 200-fold speedup\ncompared to the original PAM SWAP algorithm, making PAM applicable to larger\ndata sets as long as we can afford to compute a distance matrix, and in\nparticular to higher k (at k=2, the new SWAP was only 1.5 times faster, as the\nspeedup is expected to increase with k).\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 19:26:28 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 14:09:31 GMT"}, {"version": "v3", "created": "Sat, 4 May 2019 22:01:11 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 19:05:32 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Schubert", "Erich", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "1810.05713", "submitter": "Sandesh Ghimire", "authors": "Sandesh Ghimire, Prashnna Kumar Gyawali, John L Sapp, Milan Horacek,\n  Linwei Wang", "title": "Improving Generalization of Sequence Encoder-Decoder Networks for\n  Inverse Imaging of Cardiac Transmembrane Potential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning models have shown state-of-the-art performance in many inverse\nreconstruction problems. However, it is not well understood what properties of\nthe latent representation may improve the generalization ability of the\nnetwork. Furthermore, limited models have been presented for inverse\nreconstructions over time sequences. In this paper, we study the generalization\nability of a sequence encoder decoder model for solving inverse reconstructions\non time sequences. Our central hypothesis is that the generalization ability of\nthe network can be improved by 1) constrained stochasticity and 2) global\naggregation of temporal information in the latent space. First, drawing from\nanalytical learning theory, we theoretically show that a stochastic latent\nspace will lead to an improved generalization ability. Second, we consider an\nLSTM encoder-decoder architecture that compresses a global latent vector from\nall last-layer units in the LSTM encoder. This model is compared with\nalternative LSTM encoder-decoder architectures, each in deterministic and\nstochastic versions. The results demonstrate that the generalization ability of\nan inverse reconstruction network can be improved by constrained stochasticity\ncombined with global aggregation of temporal information in the latent space.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 20:42:23 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Ghimire", "Sandesh", ""], ["Gyawali", "Prashnna Kumar", ""], ["Sapp", "John L", ""], ["Horacek", "Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "1810.05724", "submitter": "Andrej Junginger", "authors": "Andrej Junginger, Markus Hanselmann, Thilo Strauss, Sebastian Boblest,\n  Jens Buchner, Holger Ulmer", "title": "Unpaired High-Resolution and Scalable Style Transfer Using Generative\n  Adversarial Networks", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have proven their capabilities by outperforming many other\napproaches on regression or classification tasks on various kinds of data.\nOther astonishing results have been achieved using neural nets as data\ngenerators, especially in settings of generative adversarial networks (GANs).\nOne special application is the field of image domain translations. Here, the\ngoal is to take an image with a certain style (e.g. a photography) and\ntransform it into another one (e.g. a painting). If such a task is performed\nfor unpaired training examples, the corresponding GAN setting is complex, the\nneural networks are large, and this leads to a high peak memory consumption\nduring, both, training and evaluation phase. This sets a limit to the highest\nprocessable image size. We address this issue by the idea of not processing the\nwhole image at once, but to train and evaluate the domain translation on the\nlevel of overlapping image subsamples. This new approach not only enables us to\ntranslate high-resolution images that otherwise cannot be processed by the\nneural network at once, but also allows us to work with comparably small neural\nnetworks and with limited hardware resources. Additionally, the number of\nimages required for the training process is significantly reduced. We present\nhigh-quality results on images with a total resolution of up to over 50\nmegapixels and emonstrate that our method helps to preserve local image details\nwhile it also keeps global consistency.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 07:02:47 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Junginger", "Andrej", ""], ["Hanselmann", "Markus", ""], ["Strauss", "Thilo", ""], ["Boblest", "Sebastian", ""], ["Buchner", "Jens", ""], ["Ulmer", "Holger", ""]]}, {"id": "1810.05726", "submitter": "Alex Olsen", "authors": "Alex Olsen, Dmitry A. Konovalov, Bronson Philippa, Peter Ridd, Jake C.\n  Wood, Jamie Johns, Wesley Banks, Benjamin Girgenti, Owen Kenny, James\n  Whinney, Brendan Calvert, Mostafa Rahimi Azghadi and Ronald D. White", "title": "DeepWeeds: A Multiclass Weed Species Image Dataset for Deep Learning", "comments": "14 pages, 8 figures, 4 tables", "journal-ref": "Sci.Rep. 9, 2058 (2019)", "doi": "10.1038/s41598-018-38343-3", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robotic weed control has seen increased research of late with its potential\nfor boosting productivity in agriculture. Majority of works focus on developing\nrobotics for croplands, ignoring the weed management problems facing rangeland\nstock farmers. Perhaps the greatest obstacle to widespread uptake of robotic\nweed control is the robust classification of weed species in their natural\nenvironment. The unparalleled successes of deep learning make it an ideal\ncandidate for recognising various weed species in the complex rangeland\nenvironment. This work contributes the first large, public, multiclass image\ndataset of weed species from the Australian rangelands; allowing for the\ndevelopment of robust classification methods to make robotic weed control\nviable. The DeepWeeds dataset consists of 17,509 labelled images of eight\nnationally significant weed species native to eight locations across northern\nAustralia. This paper presents a baseline for classification performance on the\ndataset using the benchmark deep learning models, Inception-v3 and ResNet-50.\nThese models achieved an average classification accuracy of 95.1% and 95.7%,\nrespectively. We also demonstrate real time performance of the ResNet-50\narchitecture, with an average inference time of 53.4 ms per image. These strong\nresults bode well for future field implementation of robotic weed control\nmethods in the Australian rangelands.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 05:53:26 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 21:49:49 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 11:20:57 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Olsen", "Alex", ""], ["Konovalov", "Dmitry A.", ""], ["Philippa", "Bronson", ""], ["Ridd", "Peter", ""], ["Wood", "Jake C.", ""], ["Johns", "Jamie", ""], ["Banks", "Wesley", ""], ["Girgenti", "Benjamin", ""], ["Kenny", "Owen", ""], ["Whinney", "James", ""], ["Calvert", "Brendan", ""], ["Azghadi", "Mostafa Rahimi", ""], ["White", "Ronald D.", ""]]}, {"id": "1810.05728", "submitter": "Kristjan Greenewald", "authors": "Ziv Goldfeld, Ewout van den Berg, Kristjan Greenewald, Igor Melnyk,\n  Nam Nguyen, Brian Kingsbury, Yury Polyanskiy", "title": "Estimating Information Flow in Deep Neural Networks", "comments": "Main text accepted to ICML 2019. This preprint contains the full\n  version of that paper (including omitted appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the flow of information and the evolution of internal\nrepresentations during deep neural network (DNN) training, aiming to demystify\nthe compression aspect of the information bottleneck theory. The theory\nsuggests that DNN training comprises a rapid fitting phase followed by a slower\ncompression phase, in which the mutual information $I(X;T)$ between the input\n$X$ and internal representations $T$ decreases. Several papers observe\ncompression of estimated mutual information on different DNN models, but the\ntrue $I(X;T)$ over these networks is provably either constant (discrete $X$) or\ninfinite (continuous $X$). This work explains the discrepancy between theory\nand experiments, and clarifies what was actually measured by these past works.\nTo this end, we introduce an auxiliary (noisy) DNN framework for which $I(X;T)$\nis a meaningful quantity that depends on the network's parameters. This noisy\nframework is shown to be a good proxy for the original (deterministic) DNN both\nin terms of performance and the learned representations. We then develop a\nrigorous estimator for $I(X;T)$ in noisy DNNs and observe compression in\nvarious models. By relating $I(X;T)$ in the noisy DNN to an\ninformation-theoretic communication problem, we show that compression is driven\nby the progressive clustering of hidden representations of inputs from the same\nclass. Several methods to directly monitor clustering of hidden\nrepresentations, both in noisy and deterministic DNNs, are used to show that\nmeaningful clusters form in the $T$ space. Finally, we return to the estimator\nof $I(X;T)$ employed in past works, and demonstrate that while it fails to\ncapture the true (vacuous) mutual information, it does serve as a measure for\nclustering. This clarifies the past observations of compression and isolates\nthe geometric clustering of hidden representations as the true phenomenon of\ninterest.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 21:11:30 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 02:52:45 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 16:38:23 GMT"}, {"version": "v4", "created": "Thu, 30 May 2019 15:42:19 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Goldfeld", "Ziv", ""], ["Berg", "Ewout van den", ""], ["Greenewald", "Kristjan", ""], ["Melnyk", "Igor", ""], ["Nguyen", "Nam", ""], ["Kingsbury", "Brian", ""], ["Polyanskiy", "Yury", ""]]}, {"id": "1810.05729", "submitter": "Teresa Finisterra Ara\\'ujo", "authors": "Teresa Ara\\'ujo, Guilherme Aresta, Adrian Galdran, Pedro Costa, Ana\n  Maria Mendon\\c{c}a, and Aur\\'elio Campilho", "title": "UOLO - automatic object detection and segmentation in biomedical images", "comments": "Publised on DLMIA 2018. Licensed under the Creative Commons\n  CC-BY-NC-ND 4.0 license: http://creativecommons.org/licenses/by-nc-nd/4.0/", "journal-ref": "4th International Workshop, DLMIA 2018, and 8th International\n  Workshop, ML-CDS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain,\n  September 20, 2018, Proceedings. 165-173", "doi": "10.1007/978-3-030-00889-5_19", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose UOLO, a novel framework for the simultaneous detection and\nsegmentation of structures of interest in medical images. UOLO consists of an\nobject segmentation module which intermediate abstract representations are\nprocessed and used as input for object detection. The resulting system is\noptimized simultaneously for detecting a class of objects and segmenting an\noptionally different class of structures. UOLO is trained on a set of bounding\nboxes enclosing the objects to detect, as well as pixel-wise segmentation\ninformation, when available. A new loss function is devised, taking into\naccount whether a reference segmentation is accessible for each training image,\nin order to suitably backpropagate the error. We validate UOLO on the task of\nsimultaneous optic disc (OD) detection, fovea detection, and OD segmentation\nfrom retinal images, achieving state-of-the-art performance on public datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:53:13 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ara\u00fajo", "Teresa", ""], ["Aresta", "Guilherme", ""], ["Galdran", "Adrian", ""], ["Costa", "Pedro", ""], ["Mendon\u00e7a", "Ana Maria", ""], ["Campilho", "Aur\u00e9lio", ""]]}, {"id": "1810.05731", "submitter": "Saifuddin Hitawala", "authors": "Saifuddin Hitawala, Yao Li, Xian Wang, Dongyang Yang", "title": "Image Super-Resolution Using VDSR-ResNeXt and SRCGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, many Super Resolution techniques have been developed\nusing deep learning. Among those, generative adversarial networks (GAN) and\nvery deep convolutional networks (VDSR) have shown promising results in terms\nof HR image quality and computational speed. In this paper, we propose two\napproaches based on these two algorithms: VDSR-ResNeXt, which is a deep\nmulti-branch convolutional network inspired by VDSR and ResNeXt; and SRCGAN,\nwhich is a conditional GAN that explicitly passes class labels as input to the\nGAN. The two methods were implemented on common SR benchmark datasets for both\nquantitative and qualitative assessment.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 19:20:15 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hitawala", "Saifuddin", ""], ["Li", "Yao", ""], ["Wang", "Xian", ""], ["Yang", "Dongyang", ""]]}, {"id": "1810.05732", "submitter": "Amir Gholami", "authors": "Amir Gholami and Shashank Subramanian and Varun Shenoy and Naveen\n  Himthani and Xiangyu Yue and Sicheng Zhao and Peter Jin and George Biros and\n  Kurt Keutzer", "title": "A Novel Domain Adaptation Framework for Medical Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a segmentation framework that uses deep neural networks and\nintroduce two innovations. First, we describe a biophysics-based domain\nadaptation method. Second, we propose an automatic method to segment white and\ngray matter, and cerebrospinal fluid, in addition to tumorous tissue. Regarding\nour first innovation, we use a domain adaptation framework that combines a\nnovel multispecies biophysical tumor growth model with a generative adversarial\nmodel to create realistic looking synthetic multimodal MR images with known\nsegmentation. Regarding our second innovation, we propose an automatic approach\nto enrich available segmentation data by computing the segmentation for healthy\ntissues. This segmentation, which is done using diffeomorphic image\nregistration between the BraTS training data and a set of prelabeled atlases,\nprovides more information for training and reduces the class imbalance problem.\nOur overall approach is not specific to any particular neural network and can\nbe used in conjunction with existing solutions. We demonstrate the performance\nimprovement using a 2D U-Net for the BraTS'18 segmentation challenge. Our\nbiophysics based domain adaptation achieves better results, as compared to the\nexisting state-of-the-art GAN model used to create synthetic data for training.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 04:03:30 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Gholami", "Amir", ""], ["Subramanian", "Shashank", ""], ["Shenoy", "Varun", ""], ["Himthani", "Naveen", ""], ["Yue", "Xiangyu", ""], ["Zhao", "Sicheng", ""], ["Jin", "Peter", ""], ["Biros", "George", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1810.05741", "submitter": "R\\'emi Eyraud", "authors": "Stephane Ayache and Remi Eyraud and Noe Goudian", "title": "Explaining Black Boxes on Sequential Data using Weighted Automata", "comments": "Published in the Proceedings of the International Conference in\n  Grammatical Inference, September 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding how a learned black box works is of crucial interest for the\nfuture of Machine Learning. In this paper, we pioneer the question of the\nglobal interpretability of learned black box models that assign numerical\nvalues to symbolic sequential data. To tackle that task, we propose a spectral\nalgorithm for the extraction of weighted automata (WA) from such black boxes.\nThis algorithm does not require the access to a dataset or to the inner\nrepresentation of the black box: the inferred model can be obtained solely by\nquerying the black box, feeding it with inputs and analyzing its outputs.\nExperiments using Recurrent Neural Networks (RNN) trained on a wide collection\nof 48 synthetic datasets and 2 real datasets show that the obtained\napproximation is of great quality.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 21:35:23 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Ayache", "Stephane", ""], ["Eyraud", "Remi", ""], ["Goudian", "Noe", ""]]}, {"id": "1810.05749", "submitter": "Chris Zhang", "authors": "Chris Zhang, Mengye Ren, Raquel Urtasun", "title": "Graph HyperNetworks for Neural Architecture Search", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) automatically finds the best task-specific\nneural network topology, outperforming many manual architecture designs.\nHowever, it can be prohibitively expensive as the search requires training\nthousands of different networks, while each can last for hours. In this work,\nwe propose the Graph HyperNetwork (GHN) to amortize the search cost: given an\narchitecture, it directly generates the weights by running inference on a graph\nneural network. GHNs model the topology of an architecture and therefore can\npredict network performance more accurately than regular hypernetworks and\npremature early stopping. To perform NAS, we randomly sample architectures and\nuse the validation accuracy of networks with GHN generated weights as the\nsurrogate search signal. GHNs are fast -- they can search nearly 10 times\nfaster than other random search methods on CIFAR-10 and ImageNet. GHNs can be\nfurther extended to the anytime prediction setting, where they have found\nnetworks with better speed-accuracy tradeoff than the state-of-the-art manual\ndesigns.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 22:21:05 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 04:03:03 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 18:01:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Zhang", "Chris", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1810.05751", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, C. Karen Liu and Greg Turk", "title": "Policy Transfer with Strategy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer simulation provides an automatic and safe way for training robotic\ncontrol policies to achieve complex tasks such as locomotion. However, a policy\ntrained in simulation usually does not transfer directly to the real hardware\ndue to the differences between the two environments. Transfer learning using\ndomain randomization is a promising approach, but it usually assumes that the\ntarget environment is close to the distribution of the training environments,\nthus relying heavily on accurate system identification. In this paper, we\npresent a different approach that leverages domain randomization for\ntransferring control policies to unknown environments. The key idea that,\ninstead of learning a single policy in the simulation, we simultaneously learn\na family of policies that exhibit different behaviors. When tested in the\ntarget environment, we directly search for the best policy in the family based\non the task performance, without the need to identify the dynamic parameters.\nWe evaluate our method on five simulated robotic control problems with\ndifferent discrepancies in the training and testing environment and demonstrate\nthat our method can overcome larger modeling errors compared to training a\nrobust policy or an adaptive policy.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 22:53:30 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 16:36:47 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Yu", "Wenhao", ""], ["Liu", "C. Karen", ""], ["Turk", "Greg", ""]]}, {"id": "1810.05752", "submitter": "Jeongyeol Kwon", "authors": "Jeongyeol Kwon, Wei Qian, Constantine Caramanis, Yudong Chen, Damek\n  Davis", "title": "Global Convergence of EM Algorithm for Mixtures of Two Component Linear\n  Regression", "comments": "To appear in the proceedings of the Conference on Learning Theory\n  (COLT), 2019. This paper results from a merger of work from two groups who\n  work on the problem at the same time", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization algorithm is perhaps the most broadly used\nalgorithm for inference of latent variable problems. A theoretical\nunderstanding of its performance, however, largely remains lacking. Recent\nresults established that EM enjoys global convergence for Gaussian Mixture\nModels. For Mixed Linear Regression, however, only local convergence results\nhave been established, and those only for the high SNR regime. We show here\nthat EM converges for mixed linear regression with two components (it is known\nthat it may fail to converge for three or more), and moreover that this\nconvergence holds for random initialization. Our analysis reveals that EM\nexhibits very different behavior in Mixed Linear Regression from its behavior\nin Gaussian Mixture Models, and hence our proofs require the development of\nseveral new ideas.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 22:59:30 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 22:40:37 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 22:29:36 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 21:29:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kwon", "Jeongyeol", ""], ["Qian", "Wei", ""], ["Caramanis", "Constantine", ""], ["Chen", "Yudong", ""], ["Davis", "Damek", ""]]}, {"id": "1810.05795", "submitter": "Chun-Liang Li", "authors": "Chun-Liang Li, Manzil Zaheer, Yang Zhang, Barnabas Poczos, Ruslan\n  Salakhutdinov", "title": "Point Cloud GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) can achieve promising performance on\nlearning complex data distributions on different types of data. In this paper,\nwe first show a straightforward extension of existing GAN algorithm is not\napplicable to point clouds, because the constraint required for discriminators\nis undefined for set data. We propose a two fold modification to GAN algorithm\nfor learning to generate point clouds (PC-GAN). First, we combine ideas from\nhierarchical Bayesian modeling and implicit generative models by learning a\nhierarchical and interpretable sampling process. A key component of our method\nis that we train a posterior inference network for the hidden variables.\nSecond, instead of using only state-of-the-art Wasserstein GAN objective, we\npropose a sandwiching objective, which results in a tighter Wasserstein\ndistance estimate than the commonly used dual form. Thereby, PC-GAN defines a\ngeneric framework that can incorporate many existing GAN algorithms. We\nvalidate our claims on ModelNet40 benchmark dataset. Using the distance between\ngenerated point clouds and true meshes as metric, we find that PC-GAN trained\nby the sandwiching objective achieves better results on test data than the\nexisting methods. Moreover, as a byproduct, PC- GAN learns versatile latent\nrepresentations of point clouds, which can achieve competitive performance with\nother unsupervised learning algorithms on object recognition task. Lastly, we\nalso provide studies on generating unseen classes of objects and transforming\nimage to point cloud, which demonstrates the compelling generalization\ncapability and potentials of PC-GAN.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 04:14:14 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Chun-Liang", ""], ["Zaheer", "Manzil", ""], ["Zhang", "Yang", ""], ["Poczos", "Barnabas", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1810.05868", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim", "title": "Hybrid Building/Floor Classification and Location Coordinates Regression\n  Using A Single-Input and Multi-Output Deep Neural Network for Large-Scale\n  Indoor Localization Based on Wi-Fi Fingerprinting", "comments": "6 pages, 4 figures, 3rd International Workshop on GPU Computing and\n  AI (GCA'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose hybrid building/floor classification and\nfloor-level two-dimensional location coordinates regression using a\nsingle-input and multi-output (SIMO) deep neural network (DNN) for large-scale\nindoor localization based on Wi-Fi fingerprinting. The proposed scheme exploits\nthe different nature of the estimation of building/floor and floor-level\nlocation coordinates and uses a different estimation framework for each task\nwith a dedicated output and hidden layers enabled by SIMO DNN architecture. We\ncarry out preliminary evaluation of the performance of the hybrid floor\nclassification and floor-level two-dimensional location coordinates regression\nusing new Wi-Fi crowdsourced fingerprinting datasets provided by Tampere\nUniversity of Technology (TUT), Finland, covering a single building with five\nfloors. Experimental results demonstrate that the proposed SIMO-DNN-based\nhybrid classification/regression scheme outperforms existing schemes in terms\nof both floor detection rate and mean positioning errors.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 14:39:20 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Kim", "Kyeong Soo", ""]]}, {"id": "1810.05893", "submitter": "Mehran Soltani", "authors": "Mehran Soltani, Vahid Pourahmadi, Ali Mirzaei, Hamid Sheikhzadeh", "title": "Deep Learning-Based Channel Estimation", "comments": "4 pages , 5 figures , Accepted for publication in the IEEE\n  Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep learning (DL) algorithm for channel\nestimation in communication systems. We consider the time-frequency response of\na fast fading communication channel as a two-dimensional image. The aim is to\nfind the unknown values of the channel response using some known values at the\npilot locations. To this end, a general pipeline using deep image processing\ntechniques, image super-resolution (SR) and image restoration (IR) is proposed.\nThis scheme considers the pilot values, altogether, as a low-resolution image\nand uses an SR network cascaded with a denoising IR network to estimate the\nchannel. Moreover, an implementation of the proposed pipeline is presented. The\nestimation error shows that the presented algorithm is comparable to the\nminimum mean square error (MMSE) with full knowledge of the channel statistics\nand it is better than ALMMSE (an approximation to linear MMSE). The results\nconfirm that this pipeline can be used efficiently in channel estimation.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 17:08:52 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 20:25:48 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 14:41:24 GMT"}, {"version": "v4", "created": "Tue, 19 Feb 2019 09:42:45 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Soltani", "Mehran", ""], ["Pourahmadi", "Vahid", ""], ["Mirzaei", "Ali", ""], ["Sheikhzadeh", "Hamid", ""]]}, {"id": "1810.05934", "submitter": "Liam Li", "authors": "Liam Li, Kevin Jamieson, Afshin Rostamizadeh, Ekaterina Gonina, Moritz\n  Hardt, Benjamin Recht, Ameet Talwalkar", "title": "A System for Massively Parallel Hyperparameter Tuning", "comments": "v2: Corrected typo in Algorithm 1 v3: Added comparison to BOHB and\n  parallel version of synchronous SHA. Add PBT to experiment in Section 4.3.1\n  v4: Added acknowledgements and slight edit to related work", "journal-ref": "Conference on Machine Learning and Systems 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern learning models are characterized by large hyperparameter spaces and\nlong training times. These properties, coupled with the rise of parallel\ncomputing and the growing demand to productionize machine learning workloads,\nmotivate the need to develop mature hyperparameter optimization functionality\nin distributed computing settings. We address this challenge by first\nintroducing a simple and robust hyperparameter optimization algorithm called\nASHA, which exploits parallelism and aggressive early-stopping to tackle\nlarge-scale hyperparameter optimization problems. Our extensive empirical\nresults show that ASHA outperforms existing state-of-the-art hyperparameter\noptimization methods; scales linearly with the number of workers in distributed\nsettings; and is suitable for massive parallelism, as demonstrated on a task\nwith 500 workers. We then describe several design decisions we encountered,\nalong with our associated solutions, when integrating ASHA in Determined AI's\nend-to-end production-quality machine learning system that offers\nhyperparameter tuning as a service.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 22:02:52 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 00:23:57 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 04:41:42 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 02:15:22 GMT"}, {"version": "v5", "created": "Mon, 16 Mar 2020 01:28:21 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Li", "Liam", ""], ["Jamieson", "Kevin", ""], ["Rostamizadeh", "Afshin", ""], ["Gonina", "Ekaterina", ""], ["Hardt", "Moritz", ""], ["Recht", "Benjamin", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1810.05986", "submitter": "Zirui Wang", "authors": "Zirui Wang", "title": "Theoretical Guarantees of Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has been proven effective when within-target labeled data\nis scarce. A lot of works have developed successful algorithms and empirically\nobserved positive transfer effect that improves target generalization error\nusing source knowledge. However, theoretical analysis of transfer learning is\nmore challenging due to the nature of the problem and thus is less studied. In\nthis report, we do a survey of theoretical works in transfer learning and\nsummarize key theoretical guarantees that prove the effectiveness of transfer\nlearning. The theoretical bounds are derived using model complexity and\nlearning algorithm stability. As we should see, these works exhibit a trade-off\nbetween tight bounds and restrictive assumptions. Moreover, we also prove a new\ngeneralization bound for the multi-source transfer learning problem using the\nVC-theory, which is more informative than the one proved in previous work.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 07:19:27 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 02:15:28 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Wang", "Zirui", ""]]}, {"id": "1810.05992", "submitter": "Satoshi Hara", "authors": "Satoshi Hara, Takanori Maehara", "title": "Convex Hull Approximation of Nearly Optimal Lasso Solutions", "comments": "14pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an ordinary feature selection procedure, a set of important features is\nobtained by solving an optimization problem such as the Lasso regression\nproblem, and we expect that the obtained features explain the data well. In\nthis study, instead of the single optimal solution, we consider finding a set\nof diverse yet nearly optimal solutions. To this end, we formulate the problem\nas finding a small number of solutions such that the convex hull of these\nsolutions approximates the set of nearly optimal solutions. The proposed\nalgorithm consists of two steps: First, we randomly sample the extreme points\nof the set of nearly optimal solutions. Then, we select a small number of\npoints using a greedy algorithm. The experimental results indicate that the\nproposed algorithm can approximate the solution set well. The results also\nindicate that we can obtain Lasso solutions with a large diversity.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 08:10:54 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hara", "Satoshi", ""], ["Maehara", "Takanori", ""]]}, {"id": "1810.05997", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Aleksandar Bojchevski, Stephan G\\\"unnemann", "title": "Predict then Propagate: Graph Neural Networks meet Personalized PageRank", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": "International Conference on Learning Representations (ICLR), New\n  Orleans, LA, USA, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural message passing algorithms for semi-supervised classification on\ngraphs have recently achieved great success. However, for classifying a node\nthese methods only consider nodes that are a few propagation steps away and the\nsize of this utilized neighborhood is hard to extend. In this paper, we use the\nrelationship between graph convolutional networks (GCN) and PageRank to derive\nan improved propagation scheme based on personalized PageRank. We utilize this\npropagation procedure to construct a simple model, personalized propagation of\nneural predictions (PPNP), and its fast approximation, APPNP. Our model's\ntraining time is on par or faster and its number of parameters on par or lower\nthan previous models. It leverages a large, adjustable neighborhood for\nclassification and can be easily combined with any neural network. We show that\nthis model outperforms several recently proposed methods for semi-supervised\nclassification in the most thorough study done so far for GCN-like models. Our\nimplementation is available online.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 08:36:54 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 13:50:58 GMT"}, {"version": "v3", "created": "Sat, 24 Nov 2018 11:38:20 GMT"}, {"version": "v4", "created": "Fri, 22 Feb 2019 21:09:06 GMT"}, {"version": "v5", "created": "Wed, 27 Feb 2019 10:26:24 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Klicpera", "Johannes", ""], ["Bojchevski", "Aleksandar", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1810.06021", "submitter": "Alejandro Alcalde-Barros", "authors": "Alejandro Alcalde-Barros, Diego Garc\\'ia-Gil, Salvador Garc\\'ia,\n  Francisco Herrera", "title": "DPASF: A Flink Library for Streaming Data preprocessing", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data preprocessing techniques are devoted to correct or alleviate errors in\ndata. Discretization and feature selection are two of the most extended data\npreprocessing techniques. Although we can find many proposals for static Big\nData preprocessing, there is little research devoted to the continuous Big Data\nproblem. Apache Flink is a recent and novel Big Data framework, following the\nMapReduce paradigm, focused on distributed stream and batch data processing. In\nthis paper we propose a data stream library for Big Data preprocessing, named\nDPASF, under Apache Flink. We have implemented six of the most popular data\npreprocessing algorithms, three for discretization and the rest for feature\nselection. The algorithms have been tested using two Big Data datasets.\nExperimental results show that preprocessing can not only reduce the size of\nthe data, but to maintain or even improve the original accuracy in a short\ntime. DPASF contains useful algorithms when dealing with Big Data data streams.\nThe preprocessing algorithms included in the library are able to tackle Big\nDatasets efficiently and to correct imperfections in the data.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 11:59:18 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Alcalde-Barros", "Alejandro", ""], ["Garc\u00eda-Gil", "Diego", ""], ["Garc\u00eda", "Salvador", ""], ["Herrera", "Francisco", ""]]}, {"id": "1810.06032", "submitter": "Yaqi Duan", "authors": "Yaqi Duan, Mengdi Wang, Zaiwen Wen, Yaxiang Yuan", "title": "Adaptive Low-Nonnegative-Rank Approximation for State Aggregation of\n  Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a low-nonnegative-rank approximation method to identify\nthe state aggregation structure of a finite-state Markov chain under an\nassumption that the state space can be mapped into a handful of meta-states.\nThe number of meta-states is characterized by the nonnegative rank of the\nMarkov transition matrix. Motivated by the success of the nuclear norm\nrelaxation in low rank minimization problems, we propose an atomic regularizer\nas a convex surrogate for the nonnegative rank and formulate a convex\noptimization problem. Because the atomic regularizer itself is not\ncomputationally tractable, we instead solve a sequence of problems involving a\nnonnegative factorization of the Markov transition matrices by using the\nproximal alternating linearized minimization method. Two methods for adjusting\nthe rank of factorization are developed so that local minima are escaped. One\nis to append an additional column to the factorized matrices, which can be\ninterpreted as an approximation of a negative subgradient step. The other is to\nreduce redundant dimensions by means of linear combinations. Overall, the\nproposed algorithm very likely converges to the global solution. The efficiency\nand statistical properties of our approach are illustrated on synthetic data.\nWe also apply our state aggregation algorithm on a Manhattan transportation\ndata set and make extensive comparisons with an existing method.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 13:24:48 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Duan", "Yaqi", ""], ["Wang", "Mengdi", ""], ["Wen", "Zaiwen", ""], ["Yuan", "Yaxiang", ""]]}, {"id": "1810.06049", "submitter": "Dor Bank", "authors": "Dor Bank and Raja Giryes", "title": "An ETF view of Dropout regularization", "comments": "Accepted to BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a popular regularization technique in deep learning. Yet, the\nreason for its success is still not fully understood. This paper provides a new\ninterpretation of Dropout from a frame theory perspective. By drawing a\nconnection to recent developments in analog channel coding, we suggest that for\na certain family of autoencoders with a linear encoder, optimizing the encoder\nwith dropout regularization leads to an equiangular tight frame (ETF). Since\nthis optimization is non-convex, we add another regularization that promotes\nsuch structures by minimizing the cross-correlation between filters in the\nnetwork. We demonstrate its applicability in convolutional and fully connected\nlayers in both feed-forward and recurrent networks. All these results suggest\nthat there is indeed a relationship between dropout and ETF structure of the\nregularized linear operations.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 15:50:21 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:20:17 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 12:40:11 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 09:12:27 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Bank", "Dor", ""], ["Giryes", "Raja", ""]]}, {"id": "1810.06060", "submitter": "Otkrist Gupta", "authors": "Otkrist Gupta and Ramesh Raskar", "title": "Distributed learning of deep neural network over multiple agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domains such as health care and finance, shortage of labeled data and\ncomputational resources is a critical issue while developing machine learning\nalgorithms. To address the issue of labeled data scarcity in training and\ndeployment of neural network-based systems, we propose a new technique to train\ndeep neural networks over several data sources. Our method allows for deep\nneural networks to be trained using data from multiple entities in a\ndistributed fashion. We evaluate our algorithm on existing datasets and show\nthat it obtains performance which is similar to a regular neural network\ntrained on a single machine. We further extend it to incorporate\nsemi-supervised learning when training with few labeled samples, and analyze\nany security concerns that may arise. Our algorithm paves the way for\ndistributed training of deep neural networks in data sensitive applications\nwhen raw data may not be shared directly.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 16:57:10 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Gupta", "Otkrist", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1810.06089", "submitter": "Edgar Dobriban", "authors": "Edgar Dobriban, Sifan Liu", "title": "Asymptotics for Sketching in Least Squares Regression", "comments": null, "journal-ref": "Updated manuscript to be consistent with version at NeurIPS 2019", "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.NA math.NA stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a least squares regression problem where the data has been\ngenerated from a linear model, and we are interested to learn the unknown\nregression parameters. We consider \"sketch-and-solve\" methods that randomly\nproject the data first, and do regression after. Previous works have analyzed\nthe statistical and computational performance of such methods. However, the\nexisting analysis is not fine-grained enough to show the fundamental\ndifferences between various methods, such as the Subsampled Randomized Hadamard\nTransform (SRHT) and Gaussian projections. In this paper, we make progress on\nthis problem, working in an asymptotic framework where the number of datapoints\nand dimension of features goes to infinity. We find the limits of the accuracy\nloss (for estimation and test error) incurred by popular sketching methods. We\nshow separation between different methods, so that SRHT is better than Gaussian\nprojections. Our theoretical results are verified on both real and synthetic\ndata. The analysis of SRHT relies on novel methods from random matrix theory\nthat may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 19:48:05 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 19:25:12 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Dobriban", "Edgar", ""], ["Liu", "Sifan", ""]]}, {"id": "1810.06115", "submitter": "Yunseong Lee", "authors": "Yunseong Lee, Alberto Scolari, Byung-Gon Chun, Marco Domenico\n  Santambrogio, Markus Weimer, Matteo Interlandi", "title": "PRETZEL: Opening the Black Box of Machine Learning Prediction Serving\n  Systems", "comments": "16 pages, 14 figures, 13th USENIX Symposium on Operating Systems\n  Design and Implementation (OSDI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning models are often composed of pipelines of transformations.\nWhile this design allows to efficiently execute single model components at\ntraining time, prediction serving has different requirements such as low\nlatency, high throughput and graceful performance degradation under heavy load.\nCurrent prediction serving systems consider models as black boxes, whereby\nprediction-time-specific optimizations are ignored in favor of ease of\ndeployment. In this paper, we present PRETZEL, a prediction serving system\nintroducing a novel white box architecture enabling both end-to-end and\nmulti-model optimizations. Using production-like model pipelines, our\nexperiments show that PRETZEL is able to introduce performance improvements\nover different dimensions; compared to state-of-the-art approaches PRETZEL is\non average able to reduce 99th percentile latency by 5.5x while reducing memory\nfootprint by 25x, and increasing throughput by 4.7x.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 22:21:30 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Lee", "Yunseong", ""], ["Scolari", "Alberto", ""], ["Chun", "Byung-Gon", ""], ["Santambrogio", "Marco Domenico", ""], ["Weimer", "Markus", ""], ["Interlandi", "Matteo", ""]]}, {"id": "1810.06118", "submitter": "Allon G. Percus", "authors": "Max Schwarzer, Bryce Rogan, Yadong Ruan, Zhengming Song, Diana Y. Lee,\n  Allon G. Percus, Viet T. Chau, Bryan A. Moore, Esteban Rougier, Hari S.\n  Viswanathan, Gowri Srinivasan", "title": "Learning to fail: Predicting fracture evolution in brittle material\n  models using recurrent graph convolutional neural networks", "comments": null, "journal-ref": "Computational Materials Science 162, 322-332 (2019)", "doi": "10.1016/j.commatsci.2019.02.046", "report-no": "LA-UR-18-29693", "categories": "cond-mat.mtrl-sci cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a machine learning approach to address a key challenge in\nmaterials science: predicting how fractures propagate in brittle materials\nunder stress, and how these materials ultimately fail. Our methods use deep\nlearning and train on simulation data from high-fidelity models, emulating the\nresults of these models while avoiding the overwhelming computational demands\nassociated with running a statistically significant sample of simulations. We\nemploy a graph convolutional network that recognizes features of the fracturing\nmaterial and a recurrent neural network that models the evolution of these\nfeatures, along with a novel form of data augmentation that compensates for the\nmodest size of our training data. We simultaneously generate predictions for\nqualitatively distinct material properties. Results on fracture damage and\nlength are within 3% of their simulated values, and results on time to material\nfailure, which is notoriously difficult to predict even with high-fidelity\nmodels, are within approximately 15% of simulated values. Once trained, our\nneural networks generate predictions within seconds, rather than the hours\nneeded to run a single simulation.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 22:38:18 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 05:21:55 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 05:28:02 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Schwarzer", "Max", ""], ["Rogan", "Bryce", ""], ["Ruan", "Yadong", ""], ["Song", "Zhengming", ""], ["Lee", "Diana Y.", ""], ["Percus", "Allon G.", ""], ["Chau", "Viet T.", ""], ["Moore", "Bryan A.", ""], ["Rougier", "Esteban", ""], ["Viswanathan", "Hari S.", ""], ["Srinivasan", "Gowri", ""]]}, {"id": "1810.06120", "submitter": "Enzhi Li", "authors": "Yiwei Li, Enzhi Li", "title": "Variational Neural Networks: Every Layer and Neuron Can Be Unique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of activation function can significantly influence the performance\nof neural networks. The lack of guiding principles for the selection of\nactivation function is lamentable. We try to address this issue by introducing\nour variational neural networks, where the activation function is represented\nas a linear combination of possible candidate functions, and an optimal\nactivation is obtained via minimization of a loss function using gradient\ndescent method. The gradient formulae for the loss function with respect to\nthese expansion coefficients are central for the implementation of gradient\ndescent algorithm, and here we derive these gradient formulae.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 22:41:11 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Yiwei", ""], ["Li", "Enzhi", ""]]}, {"id": "1810.06167", "submitter": "Wenyu Zhang", "authors": "Wenyu Zhang, Daniel Gilbert, David Matteson", "title": "ABACUS: Unsupervised Multivariate Change Detection via Bayesian Source\n  Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change detection involves segmenting sequential data such that observations\nin the same segment share some desired properties. Multivariate change\ndetection continues to be a challenging problem due to the variety of ways\nchange points can be correlated across channels and the potentially poor\nsignal-to-noise ratio on individual channels. In this paper, we are interested\nin locating additive outliers (AO) and level shifts (LS) in the unsupervised\nsetting. We propose ABACUS, Automatic BAyesian Changepoints Under Sparsity, a\nBayesian source separation technique to recover latent signals while also\ndetecting changes in model parameters. Multi-level sparsity achieves both\ndimension reduction and modeling of signal changes. We show ABACUS has\ncompetitive or superior performance in simulation studies against\nstate-of-the-art change detection methods and established latent variable\nmodels. We also illustrate ABACUS on two real application, modeling genomic\nprofiles and analyzing household electricity consumption.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 03:12:01 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Zhang", "Wenyu", ""], ["Gilbert", "Daniel", ""], ["Matteson", "David", ""]]}, {"id": "1810.06175", "submitter": "Xuezhou Zhang", "authors": "Laurent Lessard, Xuezhou Zhang, Xiaojin Zhu", "title": "An Optimal Control Approach to Sequential Machine Teaching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sequential learning algorithm and a target model, sequential machine\nteaching aims to find the shortest training sequence to drive the learning\nalgorithm to the target model. We present the first principled way to find such\nshortest training sequences. Our key insight is to formulate sequential machine\nteaching as a time-optimal control problem. This allows us to solve sequential\nteaching by leveraging key theoretical and computational tools developed over\nthe past 60 years in the optimal control community. Specifically, we study the\nPontryagin Maximum Principle, which yields a necessary condition for optimality\nof a training sequence. We present analytic, structural, and numerical\nimplications of this approach on a case study with a least-squares loss\nfunction and gradient descent learner. We compute optimal training sequences\nfor this problem, and although the sequences seem circuitous, we find that they\ncan vastly outperform the best available heuristics for generating training\nsequences.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 04:18:39 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 04:13:27 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Lessard", "Laurent", ""], ["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1810.06207", "submitter": "Matthew J. Holland", "authors": "Matthew J. Holland", "title": "Robust descent using smoothed multiplicative noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the off-sample generalization of classical procedures minimizing\nthe empirical risk under potentially heavy-tailed data, new robust learning\nalgorithms have been proposed in recent years, with generalized median-of-means\nstrategies being particularly salient. These procedures enjoy performance\nguarantees in the form of sharp risk bounds under weak moment assumptions on\nthe underlying loss, but typically suffer from a large computational overhead\nand substantial bias when the data happens to be sub-Gaussian, limiting their\nutility. In this work, we propose a novel robust gradient descent procedure\nwhich makes use of a smoothed multiplicative noise applied directly to\nobservations before constructing a sum of soft-truncated gradient coordinates.\nWe show that the procedure has competitive theoretical guarantees, with the\nmajor advantage of a simple implementation that does not require an iterative\nsub-routine for robustification. Empirical tests reinforce the theory, showing\nmore efficient generalization over a much wider class of data distributions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 07:38:12 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Holland", "Matthew J.", ""]]}, {"id": "1810.06240", "submitter": "Malte Renken", "authors": "Vincent Froese, Brijnesh Jain, Rolf Niedermeier, Malte Renken", "title": "Comparing Temporal Graphs Using Dynamic Time Warping", "comments": null, "journal-ref": null, "doi": "10.1007/s13278-020-00664-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within many real-world networks the links between pairs of nodes change over\ntime. Thus, there has been a recent boom in studying temporal graphs.\nRecognizing patterns in temporal graphs requires a proximity measure to compare\ndifferent temporal graphs. To this end, we propose to study dynamic time\nwarping on temporal graphs. We define the dynamic temporal graph warping\ndistance (dtgw) to determine the dissimilarity of two temporal graphs. Our\nnovel measure is flexible and can be applied in various application domains. We\nshow that computing the dtgw-distance is a challenging (in general) NP-hard\noptimization problem and identify some polynomial-time solvable special cases.\nMoreover, we develop a quadratic programming formulation and an efficient\nheuristic. In experiments on real-word data we show that the heuristic performs\nvery well and that our dtgw-distance performs favorably in de-anonymizing\nnetworks compared to other approaches.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 09:21:36 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 13:39:14 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 08:57:12 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 12:41:12 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Froese", "Vincent", ""], ["Jain", "Brijnesh", ""], ["Niedermeier", "Rolf", ""], ["Renken", "Malte", ""]]}, {"id": "1810.06291", "submitter": "Mastane Achab", "authors": "Mastane Achab, Anna Korba, Stephan Cl\\'emen\\c{c}on", "title": "Dimensionality Reduction and (Bucket) Ranking: a Mass Transportation\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas most dimensionality reduction techniques (e.g. PCA, ICA, NMF) for\nmultivariate data essentially rely on linear algebra to a certain extent,\nsummarizing ranking data, viewed as realizations of a random permutation\n$\\Sigma$ on a set of items indexed by $i\\in \\{1,\\ldots,\\; n\\}$, is a great\nstatistical challenge, due to the absence of vector space structure for the set\nof permutations $\\mathfrak{S}_n$. It is the goal of this article to develop an\noriginal framework for possibly reducing the number of parameters required to\ndescribe the distribution of a statistical population composed of\nrankings/permutations, on the premise that the collection of items under study\ncan be partitioned into subsets/buckets, such that, with high probability,\nitems in a certain bucket are either all ranked higher or else all ranked lower\nthan items in another bucket. In this context, $\\Sigma$'s distribution can be\nhopefully represented in a sparse manner by a bucket distribution, i.e. a\nbucket ordering plus the ranking distributions within each bucket. More\nprecisely, we introduce a dedicated distortion measure, based on a mass\ntransportation metric, in order to quantify the accuracy of such\nrepresentations. The performance of buckets minimizing an empirical version of\nthe distortion is investigated through a rate bound analysis. Complexity\npenalization techniques are also considered to select the shape of a bucket\norder with minimum expected distortion. Beyond theoretical concepts and\nresults, numerical experiments on real ranking data are displayed in order to\nprovide empirical evidence of the relevance of the approach promoted.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 11:55:07 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 11:29:59 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Achab", "Mastane", ""], ["Korba", "Anna", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]]}, {"id": "1810.06305", "submitter": "Ho Chung Leon Law", "authors": "Ho Chung Leon Law, Peilin Zhao, Lucian Chan, Junzhou Huang and Dino\n  Sejdinovic", "title": "Hyperparameter Learning via Distributional Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a popular technique for hyperparameter learning but\ntypically requires initial exploration even in cases where similar prior tasks\nhave been solved. We propose to transfer information across tasks using learnt\nrepresentations of training datasets used in those tasks. This results in a\njoint Gaussian process model on hyperparameters and data representations.\nRepresentations make use of the framework of distribution embeddings into\nreproducing kernel Hilbert spaces. The developed method has a faster\nconvergence compared to existing baselines, in some cases requiring only a few\nevaluations of the target objective.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 12:31:20 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 10:04:26 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 13:48:03 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Law", "Ho Chung Leon", ""], ["Zhao", "Peilin", ""], ["Chan", "Lucian", ""], ["Huang", "Junzhou", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1810.06313", "submitter": "Linqi Song", "authors": "Linqi Song, Christina Fragouli, Devavrat Shah", "title": "Regret vs. Bandwidth Trade-off for Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider recommendation systems that need to operate under wireless\nbandwidth constraints, measured as number of broadcast transmissions, and\ndemonstrate a (tight for some instances) tradeoff between regret and bandwidth\nfor two scenarios: the case of multi-armed bandit with context, and the case\nwhere there is a latent structure in the message space that we can exploit to\nreduce the learning phase.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 12:41:25 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Song", "Linqi", ""], ["Fragouli", "Christina", ""], ["Shah", "Devavrat", ""]]}, {"id": "1810.06323", "submitter": "Mehmet Yamac", "authors": "Aysen Degerli, Sinem Aslan, Mehmet Yamac, Bulent Sankur, Moncef\n  Gabbouj", "title": "Compressively Sensed Image Recognition", "comments": "6 pages, submitted/accepted, EUVIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive Sensing (CS) theory asserts that sparse signal reconstruction is\npossible from a small number of linear measurements. Although CS enables\nlow-cost linear sampling, it requires non-linear and costly reconstruction.\nRecent literature works show that compressive image classification is possible\nin CS domain without reconstruction of the signal. In this work, we introduce a\nDCT base method that extracts binary discriminative features directly from CS\nmeasurements. These CS measurements can be obtained by using (i) a random or a\npseudo-random measurement matrix, or (ii) a measurement matrix whose elements\nare learned from the training data to optimize the given classification task.\nWe further introduce feature fusion by concatenating Bag of Words (BoW)\nrepresentation of our binary features with one of the two state-of-the-art\nCNN-based feature vectors. We show that our fused feature outperforms the\nstate-of-the-art in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 12:55:10 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Degerli", "Aysen", ""], ["Aslan", "Sinem", ""], ["Yamac", "Mehmet", ""], ["Sankur", "Bulent", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1810.06339", "submitter": "Yuxi Li", "authors": "Yuxi Li", "title": "Deep Reinforcement Learning", "comments": "Under review for Morgan & Claypool: Synthesis Lectures in Artificial\n  Intelligence and Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss deep reinforcement learning in an overview style. We draw a big\npicture, filled with details. We discuss six core elements, six important\nmechanisms, and twelve applications, focusing on contemporary work, and in\nhistorical contexts. We start with background of artificial intelligence,\nmachine learning, deep learning, and reinforcement learning (RL), with\nresources. Next we discuss RL core elements, including value function, policy,\nreward, model, exploration vs. exploitation, and representation. Then we\ndiscuss important mechanisms for RL, including attention and memory,\nunsupervised learning, hierarchical RL, multi-agent RL, relational RL, and\nlearning to learn. After that, we discuss RL applications, including games,\nrobotics, natural language processing (NLP), computer vision, finance, business\nmanagement, healthcare, education, energy, transportation, computer systems,\nand, science, engineering, and art. Finally we summarize briefly, discuss\nchallenges and opportunities, and close with an epilogue.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 13:20:56 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Yuxi", ""]]}, {"id": "1810.06376", "submitter": "Luwan Zhang", "authors": "Luwan Zhang and Tianrun Cai", "title": "Unsupervised Ensemble Learning via Ising Model Approximation with\n  Application to Phenotyping Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised ensemble learning has long been an interesting yet challenging\nproblem that comes to prominence in recent years with the increasing demand of\ncrowdsourcing in various applications. In this paper, we propose a novel\nmethod-- unsupervised ensemble learning via Ising model approximation (unElisa)\nthat combines a pruning step with a predicting step. We focus on the binary\ncase and use an Ising model to characterize interactions between the ensemble\nand the underlying true classifier. The presence of an edge between an observed\nclassifier and the true classifier indicates a direct dependence whereas the\nabsence indicates the corresponding one provides no additional information and\nshall be eliminated. This observation leads to the pruning step where the key\nis to recover the neighborhood of the true classifier. We show that it can be\nrecovered successfully with exponentially decaying error in the\nhigh-dimensional setting by performing nodewise $\\ell_1$-regularized logistic\nregression. The pruned ensemble allows us to get a consistent estimate of the\nBayes classifier for predicting. We also propose an augmented version of\nmajority voting by reversing all labels given by a subgroup of the pruned\nensemble. We demonstrate the efficacy of our method through extensive numerical\nexperiments and through the application to EHR-based phenotyping prediction on\nRheumatoid Arthritis (RA) using data from Partners Healthcare System.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 14:27:38 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Zhang", "Luwan", ""], ["Cai", "Tianrun", ""]]}, {"id": "1810.06394", "submitter": "Jiechao Xiong", "authors": "Jiechao Xiong, Qing Wang, Zhuoran Yang, Peng Sun, Lei Han, Yang Zheng,\n  Haobo Fu, Tong Zhang, Ji Liu, and Han Liu", "title": "Parametrized Deep Q-Networks Learning: Reinforcement Learning with\n  Discrete-Continuous Hybrid Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing deep reinforcement learning (DRL) frameworks consider either\ndiscrete action space or continuous action space solely. Motivated by\napplications in computer games, we consider the scenario with\ndiscrete-continuous hybrid action space. To handle hybrid action space,\nprevious works either approximate the hybrid space by discretization, or relax\nit into a continuous set. In this paper, we propose a parametrized deep\nQ-network (P- DQN) framework for the hybrid action space without approximation\nor relaxation. Our algorithm combines the spirits of both DQN (dealing with\ndiscrete action space) and DDPG (dealing with continuous action space) by\nseamlessly integrating them. Empirical results on a simulation example, scoring\na goal in simulated RoboCup soccer and the solo mode in game King of Glory\n(KOG) validate the efficiency and effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 07:38:44 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Xiong", "Jiechao", ""], ["Wang", "Qing", ""], ["Yang", "Zhuoran", ""], ["Sun", "Peng", ""], ["Han", "Lei", ""], ["Zheng", "Yang", ""], ["Fu", "Haobo", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""], ["Liu", "Han", ""]]}, {"id": "1810.06397", "submitter": "Lei Wu", "authors": "Weinan E, Chao Ma, Lei Wu", "title": "A Priori Estimates of the Population Risk for Two-layer Neural Networks", "comments": "Published version", "journal-ref": "Communications in Mathematical Sciences, Volume 17(2019)", "doi": "10.4310/CMS.2019.v17.n5.a11", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New estimates for the population risk are established for two-layer neural\nnetworks. These estimates are nearly optimal in the sense that the error rates\nscale in the same way as the Monte Carlo error rates. They are equally\neffective in the over-parametrized regime when the network size is much larger\nthan the size of the dataset. These new estimates are a priori in nature in the\nsense that the bounds depend only on some norms of the underlying functions to\nbe fitted, not the parameters in the model, in contrast with most existing\nresults which are a posteriori in nature. Using these a priori estimates, we\nprovide a perspective for understanding why two-layer neural networks perform\nbetter than the related kernel methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 14:38:56 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 22:15:01 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 23:33:56 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wu", "Lei", ""]]}, {"id": "1810.06401", "submitter": "Weihao Gao", "authors": "Weihao Gao, Yu-Han Liu, Chong Wang, Sewoong Oh", "title": "Rate Distortion For Model Compression: From Theory To Practice", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enormous size of modern deep neural networks makes it challenging to\ndeploy those models in memory and communication limited scenarios. Thus,\ncompressing a trained model without a significant loss in performance has\nbecome an increasingly important task. Tremendous advances has been made\nrecently, where the main technical building blocks are parameter pruning,\nparameter sharing (quantization), and low-rank factorization. In this paper, we\npropose principled approaches to improve upon the common heuristics used in\nthose building blocks, namely pruning and quantization.\n  We first study the fundamental limit for model compression via the rate\ndistortion theory. We bring the rate distortion function from data compression\nto model compression to quantify this fundamental limit. We prove a lower bound\nfor the rate distortion function and prove its achievability for linear models.\nAlthough this achievable compression scheme is intractable in practice, this\nanalysis motivates a novel model compression framework. This framework provides\na new objective function in model compression, which can be applied together\nwith other classes of model compressor such as pruning or quantization.\nTheoretically, we prove that the proposed scheme is optimal for compressing\none-hidden-layer ReLU neural networks. Empirically, we show that the proposed\nscheme improves upon the baseline in the compression-accuracy tradeoff.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 18:44:22 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 23:59:28 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Gao", "Weihao", ""], ["Liu", "Yu-Han", ""], ["Wang", "Chong", ""], ["Oh", "Sewoong", ""]]}, {"id": "1810.06443", "submitter": "Damien Pellier", "authors": "Bruno Bouzy and Marc M\\'etivier and Damien Pellier", "title": "Hedging Algorithms and Repeated Matrix Games", "comments": "12 pages, Workshop of the European Conference on Machine Learning on\n  Machine Learning and Data Mining in and around Games, 2011", "journal-ref": "Workshop of the European Conference on Machine Learning on Machine\n  Learning and Data Mining in and around Games, 2011", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Playing repeated matrix games (RMG) while maximizing the cumulative returns\nis a basic method to evaluate multi-agent learning (MAL) algorithms. Previous\nwork has shown that $UCB$, $M3$, $S$ or $Exp3$ algorithms have good behaviours\non average in RMG. Besides, hedging algorithms have been shown to be effective\non prediction problems. An hedging algorithm is made up with a top-level\nalgorithm and a set of basic algorithms. To make its decision, an hedging\nalgorithm uses its top-level algorithm to choose a basic algorithm, and the\nchosen algorithm makes the decision. This paper experimentally shows that\nwell-selected hedging algorithms are better on average than all previous MAL\nalgorithms on the task of playing RMG against various players. $S$ is a very\ngood top-level algorithm, and $UCB$ and $M3$ are very good basic algorithms.\nFurthermore, two-level hedging algorithms are more effective than one-level\nhedging algorithms, and three levels are not better than two levels.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 15:05:21 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Bouzy", "Bruno", ""], ["M\u00e9tivier", "Marc", ""], ["Pellier", "Damien", ""]]}, {"id": "1810.06509", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Xinyan Yan, Nathan Ratliff, Byron Boots", "title": "Predictor-Corrector Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a predictor-corrector framework, called PicCoLO, that can\ntransform a first-order model-free reinforcement or imitation learning\nalgorithm into a new hybrid method that leverages predictive models to\naccelerate policy learning. The new \"PicCoLOed\" algorithm optimizes a policy by\nrecursively repeating two steps: In the Prediction Step, the learner uses a\nmodel to predict the unseen future gradient and then applies the predicted\nestimate to update the policy; in the Correction Step, the learner runs the\nupdated policy in the environment, receives the true gradient, and then\ncorrects the policy using the gradient error. Unlike previous algorithms,\nPicCoLO corrects for the mistakes of using imperfect predicted gradients and\nhence does not suffer from model bias. The development of PicCoLO is made\npossible by a novel reduction from predictable online learning to adversarial\nonline learning, which provides a systematic way to modify existing first-order\nalgorithms to achieve the optimal regret with respect to predictable\ninformation. We show, in both theory and simulation, that the convergence rate\nof several first-order model-free algorithms can be improved by PicCoLO.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 16:44:48 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 18:45:57 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cheng", "Ching-An", ""], ["Yan", "Xinyan", ""], ["Ratliff", "Nathan", ""], ["Boots", "Byron", ""]]}, {"id": "1810.06526", "submitter": "Youzhi Tian", "authors": "Youzhi Tian, Zhiting Hu, Zhou Yu", "title": "Structured Content Preservation for Unsupervised Text Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer aims to modify the style of a sentence while keeping its\ncontent unchanged. Recent style transfer systems often fail to faithfully\npreserve the content after changing the style. This paper proposes a structured\ncontent preserving model that leverages linguistic information in the\nstructured fine-grained supervisions to better preserve the style-independent\ncontent during style transfer. In particular, we achieve the goal by devising\nrich model objectives based on both the sentence's lexical information and a\nlanguage model that conditions on content. The resulting model therefore is\nencouraged to retain the semantic meaning of the target sentences. We perform\nextensive experiments that compare our model to other existing approaches in\nthe tasks of sentiment and political slant transfer. Our model achieves\nsignificant improvement in terms of both content preservation and style\ntransfer in automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:19:18 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 21:55:10 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Tian", "Youzhi", ""], ["Hu", "Zhiting", ""], ["Yu", "Zhou", ""]]}, {"id": "1810.06530", "submitter": "David Janz", "authors": "David Janz, Jiri Hron, Przemys{\\l}aw Mazur, Katja Hofmann, Jos\\'e\n  Miguel Hern\\'andez-Lobato, Sebastian Tschiatschek", "title": "Successor Uncertainties: Exploration and Uncertainty in Temporal\n  Difference Learning", "comments": "Camera ready version, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior sampling for reinforcement learning (PSRL) is an effective method\nfor balancing exploration and exploitation in reinforcement learning.\nRandomised value functions (RVF) can be viewed as a promising approach to\nscaling PSRL. However, we show that most contemporary algorithms combining RVF\nwith neural network function approximation do not possess the properties which\nmake PSRL effective, and provably fail in sparse reward problems. Moreover, we\nfind that propagation of uncertainty, a property of PSRL previously thought\nimportant for exploration, does not preclude this failure. We use these\ninsights to design Successor Uncertainties (SU), a cheap and easy to implement\nRVF algorithm that retains key properties of PSRL. SU is highly effective on\nhard tabular exploration benchmarks. Furthermore, on the Atari 2600 domain, it\nsurpasses human performance on 38 of 49 games tested (achieving a median human\nnormalised score of 2.09), and outperforms its closest RVF competitor,\nBootstrapped DQN, on 36 of those.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:30:53 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 13:38:43 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 22:57:44 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 16:50:39 GMT"}, {"version": "v5", "created": "Tue, 3 Dec 2019 16:30:17 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Janz", "David", ""], ["Hron", "Jiri", ""], ["Mazur", "Przemys\u0142aw", ""], ["Hofmann", "Katja", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Tschiatschek", "Sebastian", ""]]}, {"id": "1810.06544", "submitter": "Nicholas Rhinehart", "authors": "Nicholas Rhinehart, Rowan McAllister, Sergey Levine", "title": "Deep Imitative Models for Flexible Inference, Planning, and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning (IL) is an appealing approach to learn desirable\nautonomous behavior. However, directing IL to achieve arbitrary goals is\ndifficult. In contrast, planning-based algorithms use dynamics models and\nreward functions to achieve goals. Yet, reward functions that evoke desirable\nbehavior are often difficult to specify. In this paper, we propose Imitative\nModels to combine the benefits of IL and goal-directed planning. Imitative\nModels are probabilistic predictive models of desirable behavior able to plan\ninterpretable expert-like trajectories to achieve specified goals. We derive\nfamilies of flexible goal objectives, including constrained goal regions,\nunconstrained goal sets, and energy-based goals. We show that our method can\nuse these objectives to successfully direct behavior. Our method substantially\noutperforms six IL approaches and a planning-based approach in a dynamic\nsimulated autonomous driving task, and is efficiently learned from expert\ndemonstrations without online data collection. We also show our approach is\nrobust to poorly specified goals, such as goals on the wrong side of the road.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:51:03 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 20:07:49 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 19:48:56 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2019 00:13:58 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Rhinehart", "Nicholas", ""], ["McAllister", "Rowan", ""], ["Levine", "Sergey", ""]]}, {"id": "1810.06583", "submitter": "Prasad Chalasani", "authors": "Prasad Chalasani, Jiefeng Chen, Amrita Roy Chowdhury, Somesh Jha, Xi\n  Wu", "title": "Concise Explanations of Neural Networks using Adversarial Training", "comments": "30 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show new connections between adversarial learning and explainability for\ndeep neural networks (DNNs). One form of explanation of the output of a neural\nnetwork model in terms of its input features, is a vector of\nfeature-attributions. Two desirable characteristics of an attribution-based\nexplanation are: (1) $\\textit{sparseness}$: the attributions of irrelevant or\nweakly relevant features should be negligible, thus resulting in\n$\\textit{concise}$ explanations in terms of the significant features, and (2)\n$\\textit{stability}$: it should not vary significantly within a small local\nneighborhood of the input. Our first contribution is a theoretical exploration\nof how these two properties (when using attributions based on Integrated\nGradients, or IG) are related to adversarial training, for a class of 1-layer\nnetworks (which includes logistic regression models for binary and multi-class\nclassification); for these networks we show that (a) adversarial training using\nan $\\ell_\\infty$-bounded adversary produces models with sparse attribution\nvectors, and (b) natural model-training while encouraging stable explanations\n(via an extra term in the loss function), is equivalent to adversarial\ntraining. Our second contribution is an empirical verification of phenomenon\n(a), which we show, somewhat surprisingly, occurs $\\textit{not only}$\n$\\textit{in 1-layer networks}$, $\\textit{but also DNNs}$ $\\textit{trained on }$\n$\\textit{standard image datasets}$, and extends beyond IG-based attributions,\nto those based on DeepSHAP: adversarial training with $\\ell_\\infty$-bounded\nperturbations yields significantly sparser attribution vectors, with little\ndegradation in performance on natural test data, compared to natural training.\nMoreover, the sparseness of the attribution vectors is significantly better\nthan that achievable via $\\ell_1$-regularized natural training.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 18:01:06 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 17:59:08 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 18:18:48 GMT"}, {"version": "v4", "created": "Mon, 12 Nov 2018 18:59:43 GMT"}, {"version": "v5", "created": "Fri, 24 May 2019 13:28:30 GMT"}, {"version": "v6", "created": "Fri, 11 Oct 2019 14:37:10 GMT"}, {"version": "v7", "created": "Mon, 14 Oct 2019 00:54:12 GMT"}, {"version": "v8", "created": "Mon, 17 Feb 2020 00:18:51 GMT"}, {"version": "v9", "created": "Sun, 5 Jul 2020 01:06:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Chalasani", "Prasad", ""], ["Chen", "Jiefeng", ""], ["Chowdhury", "Amrita Roy", ""], ["Jha", "Somesh", ""], ["Wu", "Xi", ""]]}, {"id": "1810.06640", "submitter": "David Donahue", "authors": "David Donahue, Anna Rumshisky", "title": "Adversarial Text Generation Without Reinforcement Learning", "comments": "Four pages without references. ACL latex style. Four figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have experienced a recent surge in\npopularity, performing competitively in a variety of tasks, especially in\ncomputer vision. However, GAN training has shown limited success in natural\nlanguage processing. This is largely because sequences of text are discrete,\nand thus gradients cannot propagate from the discriminator to the generator.\nRecent solutions use reinforcement learning to propagate approximate gradients\nto the generator, but this is inefficient to train. We propose to utilize an\nautoencoder to learn a low-dimensional representation of sentences. A GAN is\nthen trained to generate its own vectors in this space, which decode to\nrealistic utterances. We report both random and interpolated samples from the\ngenerator. Visualization of sentence vectors indicate our model correctly\nlearns the latent space of the autoencoder. Both human ratings and BLEU scores\nshow that our model generates realistic text against competitive baselines.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 22:50:38 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 23:38:54 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Donahue", "David", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1810.06665", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Bernhard Waltl, Ingo Glaser, J\\\"org Landthaler, Elena\n  Scepankova and Florian Matthes", "title": "Stop Illegal Comments: A Multi-Task Deep Learning Approach", "comments": "10 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are often difficult to apply in the legal domain due to\nthe large amount of labeled data required by deep learning methods. A recent\nnew trend in the deep learning community is the application of multi-task\nmodels that enable single deep neural networks to perform more than one task at\nthe same time, for example classification and translation tasks. These powerful\nnovel models are capable of transferring knowledge among different tasks or\ntraining sets and therefore could open up the legal domain for many deep\nlearning applications. In this paper, we investigate the transfer learning\ncapabilities of such a multi-task model on a classification task on the\npublicly available Kaggle toxic comment dataset for classifying illegal\ncomments and we can report promising results.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:22:44 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Waltl", "Bernhard", ""], ["Glaser", "Ingo", ""], ["Landthaler", "J\u00f6rg", ""], ["Scepankova", "Elena", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.06667", "submitter": "Yaser Keneshloo", "authors": "Yaser Keneshloo, Naren Ramakrishnan, Chandan K. Reddy", "title": "Deep Transfer Reinforcement Learning for Text Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are data hungry models and thus face difficulties when\nattempting to train on small text datasets. Transfer learning is a potential\nsolution but their effectiveness in the text domain is not as explored as in\nareas such as image analysis. In this paper, we study the problem of transfer\nlearning for text summarization and discuss why existing state-of-the-art\nmodels fail to generalize well on other (unseen) datasets. We propose a\nreinforcement learning framework based on a self-critic policy gradient\napproach which achieves good generalization and state-of-the-art results on a\nvariety of datasets. Through an extensive set of experiments, we also show the\nability of our proposed framework to fine-tune the text summarization model\nusing only a few training samples. To the best of our knowledge, this is the\nfirst work that studies transfer learning in text summarization and provides a\ngeneric solution that works well on unseen data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:26:44 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 20:14:33 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Keneshloo", "Yaser", ""], ["Ramakrishnan", "Naren", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1810.06673", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Robin Otto and Florian Matthes", "title": "Named-Entity Linking Using Deep Learning For Legal Documents: A Transfer\n  Learning Approach", "comments": "10 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the legal domain it is important to differentiate between words in\ngeneral, and afterwards to link the occurrences of the same entities. The topic\nto solve these challenges is called Named-Entity Linking (NEL). Current\nsupervised neural networks designed for NEL use publicly available datasets for\ntraining and testing. However, this paper focuses especially on the aspect of\napplying transfer learning approach using networks trained for NEL to legal\ndocuments. Experiments show consistent improvement in the legal datasets that\nwere created from the European Union law in the scope of this research. Using\ntransfer learning approach, we reached F1-score of 98.90\\% and 98.01\\% on the\nlegal small and large test dataset.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:38:00 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Otto", "Robin", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.06682", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "Trellis Networks for Sequence Modeling", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present trellis networks, a new architecture for sequence modeling. On the\none hand, a trellis network is a temporal convolutional network with special\nstructure, characterized by weight tying across depth and direct injection of\nthe input into deep layers. On the other hand, we show that truncated recurrent\nnetworks are equivalent to trellis networks with special sparsity structure in\ntheir weight matrices. Thus trellis networks with general weight matrices\ngeneralize truncated recurrent networks. We leverage these connections to\ndesign high-performing trellis networks that absorb structural and algorithmic\nelements from both recurrent and convolutional models. Experiments demonstrate\nthat trellis networks outperform the current state of the art methods on a\nvariety of challenging benchmarks, including word-level language modeling and\ncharacter-level language modeling tasks, and stress tests designed to evaluate\nlong-term memory retention. The code is available at\nhttps://github.com/locuslab/trellisnet .\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:50:05 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 21:37:42 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.06684", "submitter": "Murat Firat", "authors": "Murat Firat, Guillaume Crognier, Adriana F. Gabor, C.A.J. Hurkens, and\n  Yingqian Zhang", "title": "Column generation based math-heuristic for classification trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of Column Generation (CG) techniques in\nconstructing univariate binary decision trees for classification tasks. We\npropose a novel Integer Linear Programming (ILP) formulation, based on\nroot-to-leaf paths in decision trees. The model is solved via a Column\nGeneration based heuristic. To speed up the heuristic, we use a restricted\ninstance data by considering a subset of decision splits, sampled from the\nsolutions of the well-known CART algorithm. Extensive numerical experiments\nshow that our approach is competitive with the state-of-the-art ILP-based\nalgorithms. In particular, the proposed approach is capable of handling big\ndata sets with tens of thousands of data rows. Moreover, for large data sets,\nit finds solutions competitive to CART.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:50:39 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 07:04:18 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Firat", "Murat", ""], ["Crognier", "Guillaume", ""], ["Gabor", "Adriana F.", ""], ["Hurkens", "C. A. J.", ""], ["Zhang", "Yingqian", ""]]}, {"id": "1810.06695", "submitter": "Giancarlo Salton", "authors": "Giancarlo D. Salton and Robert J. Ross and John D. Kelleher", "title": "Exploring the Use of Attention within an Neural Machine Translation\n  Decoder States to Translate Idioms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Idioms pose problems to almost all Machine Translation systems. This type of\nlanguage is very frequent in day-to-day language use and cannot be simply\nignored. The recent interest in memory augmented models in the field of\nLanguage Modelling has aided the systems to achieve good results by bridging\nlong-distance dependencies. In this paper we explore the use of such techniques\ninto a Neural Machine Translation system to help in translation of idiomatic\nlanguage.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:57:32 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Salton", "Giancarlo D.", ""], ["Ross", "Robert J.", ""], ["Kelleher", "John D.", ""]]}, {"id": "1810.06702", "submitter": "James Murphy", "authors": "Mauro Maggioni and James M. Murphy", "title": "Learning by Unsupervised Nonlinear Diffusion", "comments": "40 Pages, 17 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes and analyzes a novel clustering algorithm that combines\ngraph-based diffusion geometry with techniques based on density and mode\nestimation. The proposed method is suitable for data generated from mixtures of\ndistributions with densities that are both multimodal and have nonlinear\nshapes. A crucial aspect of this algorithm is the use of time of a data-adapted\ndiffusion process as a scale parameter that is different from the local spatial\nscale parameter used in many clustering algorithms. We prove estimates for the\nbehavior of diffusion distances with respect to this time parameter under a\nflexible nonparametric data model, identifying a range of times in which the\nmesoscopic equilibria of the underlying process are revealed, corresponding to\na gap between within-cluster and between-cluster diffusion distances. These\nstructures can be missed by the top eigenvectors of the graph Laplacian,\ncommonly used in spectral clustering. This analysis is leveraged to prove\nsufficient conditions guaranteeing the accuracy of the proposed \\emph{learning\nby unsupervised nonlinear diffusion (LUND)} procedure. We implement LUND and\nconfirm its theoretical properties on illustrative datasets, demonstrating the\ntheoretical and empirical advantages over both spectral clustering and\ndensity-based clustering techniques.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 21:23:03 GMT"}, {"version": "v2", "created": "Sat, 29 Dec 2018 16:28:58 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Maggioni", "Mauro", ""], ["Murphy", "James M.", ""]]}, {"id": "1810.06710", "submitter": "Ardavan Salehi Nobandegani", "authors": "Ardavan S. Nobandegani, William Campoli, Thomas R. Shultz", "title": "Bringing Order to the Cognitive Fallacy Zoo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the eyes of a rationalist like Descartes or Spinoza, human reasoning is\nflawless, marching toward uncovering ultimate truth. A few centuries later,\nhowever, culminating in the work of Kahneman and Tversky, human reasoning was\nportrayed as anything but flawless, filled with numerous misjudgments, biases,\nand cognitive fallacies. With further investigations, new cognitive fallacies\ncontinually emerged, leading to a state of affairs which can fairly be\ncharacterized as the cognitive fallacy zoo! In this largely methodological\nwork, we formally present a principled way to bring order to this zoo. We\nintroduce the idea of establishing implication relationships (IRs) between\ncognitive fallacies, formally characterizing how one fallacy implies another.\nIR is analogous to, and partly inspired by, the fundamental concept of\nreduction in computational complexity theory. We present several examples of\nIRs involving experimentally well-documented cognitive fallacies: base-rate\nneglect, availability bias, conjunction fallacy, decoy effect, framing effect,\nand Allais paradox. We conclude by discussing how our work: (i) allows for\nidentifying those pivotal cognitive fallacies whose investigation would be the\nmost rewarding research agenda, and importantly (ii) permits a systematized,\nguided research program on cognitive fallacies, motivating influential\ntheoretical as well as experimental avenues of future research.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 21:37:38 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Nobandegani", "Ardavan S.", ""], ["Campoli", "William", ""], ["Shultz", "Thomas R.", ""]]}, {"id": "1810.06746", "submitter": "Winfried L\\\"otzsch", "authors": "Winfried L\\\"otzsch", "title": "Using Deep Reinforcement Learning for the Continuous Control of Robotic\n  Arms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning enables algorithms to learn complex behavior,\ndeal with continuous action spaces and find good strategies in environments\nwith high dimensional state spaces. With deep reinforcement learning being an\nactive area of research and many concurrent inventions, we decided to focus on\na relatively simple robotic task to evaluate a set of ideas that might help to\nsolve recent reinforcement learning problems. We test a newly created\ncombination of two commonly used reinforcement learning methods, whether it is\nable to learn more effectively than a baseline. We also compare different ideas\nto preprocess information before it is fed to the reinforcement learning\nalgorithm. The goal of this strategy is to reduce training time and eventually\nhelp the algorithm to converge. The concluding evaluation proves the general\napplicability of the described concepts by testing them using a simulated\nenvironment. These concepts might be reused for future experiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:10:46 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["L\u00f6tzsch", "Winfried", ""]]}, {"id": "1810.06749", "submitter": "Bastian Bohn", "authors": "Bastian Bohn and Michael Griebel and Jens Oettershagen", "title": "Optimally rotated coordinate systems for adaptive least-squares\n  regression on sparse grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For low-dimensional data sets with a large amount of data points, standard\nkernel methods are usually not feasible for regression anymore. Besides simple\nlinear models or involved heuristic deep learning models, grid-based\ndiscretizations of larger (kernel) model classes lead to algorithms, which\nnaturally scale linearly in the amount of data points. For moderate-dimensional\nor high-dimensional regression tasks, these grid-based discretizations suffer\nfrom the curse of dimensionality. Here, sparse grid methods have proven to\ncircumvent this problem to a large extent. In this context, space- and\ndimension-adaptive sparse grids, which can detect and exploit a given low\neffective dimensionality of nominally high-dimensional data, are particularly\nsuccessful. They nevertheless rely on an axis-aligned structure of the solution\nand exhibit issues for data with predominantly skewed and rotated coordinates.\n  In this paper we propose a preprocessing approach for these adaptive sparse\ngrid algorithms that determines an optimized, problem-dependent coordinate\nsystem and, thus, reduces the effective dimensionality of a given data set in\nthe ANOVA sense. We provide numerical examples on synthetic data as well as\nreal-world data to show how an adaptive sparse grid least squares algorithm\nbenefits from our preprocessing method.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:24:21 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 11:28:02 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Bohn", "Bastian", ""], ["Griebel", "Michael", ""], ["Oettershagen", "Jens", ""]]}, {"id": "1810.06755", "submitter": "Oliver Thomas", "authors": "Novi Quadrianto, Viktoriia Sharmanska, Oliver Thomas", "title": "Discovering Fair Representations in the Data Domain", "comments": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability and fairness are critical in computer vision and machine\nlearning applications, in particular when dealing with human outcomes, e.g.\ninviting or not inviting for a job interview based on application materials\nthat may include photographs. One promising direction to achieve fairness is by\nlearning data representations that remove the semantics of protected\ncharacteristics, and are therefore able to mitigate unfair outcomes. All\navailable models however learn latent embeddings which comes at the cost of\nbeing uninterpretable. We propose to cast this problem as data-to-data\ntranslation, i.e. learning a mapping from an input domain to a fair target\ndomain, where a fairness definition is being enforced. Here the data domain can\nbe images, or any tabular data representation. This task would be\nstraightforward if we had fair target data available, but this is not the case.\nTo overcome this, we learn a highly unconstrained mapping by exploiting\nstatistics of residuals - the difference between input data and its translated\nversion - and the protected characteristics. When applied to the CelebA dataset\nof face images with gender attribute as the protected characteristic, our model\nenforces equality of opportunity by adjusting the eyes and lips regions.\nIntriguingly, on the same dataset we arrive at similar conclusions when using\nsemantic attribute representations of images for translation. On face images of\nthe recent DiF dataset, with the same gender attribute, our method adjusts nose\nregions. In the Adult income dataset, also with protected gender attribute, our\nmodel achieves equality of opportunity by, among others, obfuscating the wife\nand husband relationship. Analyzing those systematic changes will allow us to\nscrutinize the interplay of fairness criterion, chosen protected\ncharacteristics, and prediction performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:58:36 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 10:51:18 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Quadrianto", "Novi", ""], ["Sharmanska", "Viktoriia", ""], ["Thomas", "Oliver", ""]]}, {"id": "1810.06758", "submitter": "Samaneh Azadi", "authors": "Samaneh Azadi, Catherine Olsson, Trevor Darrell, Ian Goodfellow,\n  Augustus Odena", "title": "Discriminator Rejection Sampling", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a rejection sampling scheme using the discriminator of a GAN to\napproximately correct errors in the GAN generator distribution. We show that\nunder quite strict assumptions, this will allow us to recover the data\ndistribution exactly. We then examine where those strict assumptions break down\nand design a practical algorithm - called Discriminator Rejection Sampling\n(DRS) - that can be used on real data-sets. Finally, we demonstrate the\nefficacy of DRS on a mixture of Gaussians and on the SAGAN model,\nstate-of-the-art in the image generation task at the time of developing this\nwork. On ImageNet, we train an improved baseline that increases the Inception\nScore from 52.52 to 62.36 and reduces the Frechet Inception Distance from 18.65\nto 14.79. We then use DRS to further improve on this baseline, improving the\nInception Score to 76.08 and the FID to 13.75.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:06:54 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 01:04:37 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 09:06:47 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Azadi", "Samaneh", ""], ["Olsson", "Catherine", ""], ["Darrell", "Trevor", ""], ["Goodfellow", "Ian", ""], ["Odena", "Augustus", ""]]}, {"id": "1810.06759", "submitter": "Harish S. Bhat", "authors": "Ramin Raziperchikolaei and Harish S. Bhat", "title": "A Block Coordinate Descent Proximal Method for Simultaneous Filtering\n  and Parameter Estimation", "comments": "18 pages, ICML 2019", "journal-ref": "PMLR 97:5380-5388, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a block coordinate descent proximal algorithm\n(BCD-prox) for simultaneous filtering and parameter estimation of ODE models.\nAs we show on ODE systems with up to d=40 dimensions, as compared to\nstate-of-the-art methods, BCD-prox exhibits increased robustness (to noise,\nparameter initialization, and hyperparameters), decreased training times, and\nimproved accuracy of both filtered states and estimated parameters. We show how\nBCD-prox can be used with multistep numerical discretizations, and we establish\nconvergence of BCD-prox under hypotheses that include real systems of interest.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:11:03 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 20:05:04 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Raziperchikolaei", "Ramin", ""], ["Bhat", "Harish S.", ""]]}, {"id": "1810.06773", "submitter": "Xiaodong Cui", "authors": "Xiaodong Cui, Wei Zhang, Zolt\\'an T\\\"uske and Michael Picheny", "title": "Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a population-based Evolutionary Stochastic Gradient Descent (ESGD)\nframework for optimizing deep neural networks. ESGD combines SGD and\ngradient-free evolutionary algorithms as complementary algorithms in one\nframework in which the optimization alternates between the SGD step and\nevolution step to improve the average fitness of the population. With a\nback-off strategy in the SGD step and an elitist strategy in the evolution\nstep, it guarantees that the best fitness in the population will never degrade.\nIn addition, individuals in the population optimized with various SGD-based\noptimizers using distinct hyper-parameters in the SGD step are considered as\ncompeting species in a coevolution setting such that the complementarity of the\noptimizers is also taken into account. The effectiveness of ESGD is\ndemonstrated across multiple applications including speech recognition, image\nrecognition and language modeling, using networks with a variety of deep\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 01:12:06 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Cui", "Xiaodong", ""], ["Zhang", "Wei", ""], ["T\u00fcske", "Zolt\u00e1n", ""], ["Picheny", "Michael", ""]]}, {"id": "1810.06784", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss, Dennis Lee, Ignasi Clavera, Tamim Asfour, Pieter\n  Abbeel", "title": "ProMP: Proximal Meta-Policy Search", "comments": "The first three authors contributed equally. Accepted for ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Credit assignment in Meta-reinforcement learning (Meta-RL) is still poorly\nunderstood. Existing methods either neglect credit assignment to pre-adaptation\nbehavior or implement it naively. This leads to poor sample-efficiency during\nmeta-training as well as ineffective task identification strategies. This paper\nprovides a theoretical analysis of credit assignment in gradient-based Meta-RL.\nBuilding on the gained insights we develop a novel meta-learning algorithm that\novercomes both the issue of poor credit assignment and previous difficulties in\nestimating meta-policy gradients. By controlling the statistical distance of\nboth pre-adaptation and adapted policies during meta-policy search, the\nproposed algorithm endows efficient and stable meta-learning. Our approach\nleads to superior pre-adaptation policy behavior and consistently outperforms\nprevious Meta-RL algorithms in sample-efficiency, wall-clock time, and\nasymptotic performance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 01:43:51 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 18:09:00 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 13:10:34 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Lee", "Dennis", ""], ["Clavera", "Ignasi", ""], ["Asfour", "Tamim", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1810.06793", "submitter": "Xiang Wang", "authors": "Rong Ge, Rohith Kuditipudi, Zhize Li, Xiang Wang", "title": "Learning Two-layer Neural Networks with Symmetric Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm for learning a two-layer neural network under a\ngeneral class of input distributions. Assuming there is a ground-truth\ntwo-layer network $$ y = A \\sigma(Wx) + \\xi, $$ where $A,W$ are weight\nmatrices, $\\xi$ represents noise, and the number of neurons in the hidden layer\nis no larger than the input or output, our algorithm is guaranteed to recover\nthe parameters $A,W$ of the ground-truth network. The only requirement on the\ninput $x$ is that it is symmetric, which still allows highly complicated and\nstructured input.\n  Our algorithm is based on the method-of-moments framework and extends several\nresults in tensor decompositions. We use spectral algorithms to avoid the\ncomplicated non-convex optimization in learning neural networks. Experiments\nshow that our algorithm can robustly learn the ground-truth neural network with\na small number of samples for many symmetric input distributions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 02:26:55 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 19:46:44 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Ge", "Rong", ""], ["Kuditipudi", "Rohith", ""], ["Li", "Zhize", ""], ["Wang", "Xiang", ""]]}, {"id": "1810.06801", "submitter": "Jerry Ma", "authors": "Jerry Ma and Denis Yarats", "title": "Quasi-hyperbolic momentum and Adam for deep learning", "comments": "Published as a conference paper at ICLR 2019. This version corrects\n  one typological error in the published text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Momentum-based acceleration of stochastic gradient descent (SGD) is widely\nused in deep learning. We propose the quasi-hyperbolic momentum algorithm (QHM)\nas an extremely simple alteration of momentum SGD, averaging a plain SGD step\nwith a momentum step. We describe numerous connections to and identities with\nother algorithms, and we characterize the set of two-state optimization\nalgorithms that QHM can recover. Finally, we propose a QH variant of Adam\ncalled QHAdam, and we empirically demonstrate that our algorithms lead to\nsignificantly improved training in a variety of settings, including a new\nstate-of-the-art result on WMT16 EN-DE. We hope that these empirical results,\ncombined with the conceptual and practical simplicity of QHM and QHAdam, will\nspur interest from both practitioners and researchers. Code is immediately\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 03:58:14 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 20:40:01 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 00:50:15 GMT"}, {"version": "v4", "created": "Thu, 2 May 2019 04:57:39 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Ma", "Jerry", ""], ["Yarats", "Denis", ""]]}, {"id": "1810.06803", "submitter": "Gal Mishne", "authors": "Gal Mishne, Eric C. Chi, Ronald R. Coifman", "title": "Co-manifold learning with missing data", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is typically applied to only one mode of a data\nmatrix, either its rows or columns. Yet in many applications, there is an\nunderlying geometry to both the rows and the columns. We propose utilizing this\ncoupled structure to perform co-manifold learning: uncovering the underlying\ngeometry of both the rows and the columns of a given matrix, where we focus on\na missing data setting. Our unsupervised approach consists of three components.\nWe first solve a family of optimization problems to estimate a complete matrix\nat multiple scales of smoothness. We then use this collection of smooth matrix\nestimates to compute pairwise distances on the rows and columns based on a new\nmulti-scale metric that implicitly introduces a coupling between the rows and\nthe columns. Finally, we construct row and column representations from these\nmulti-scale metrics. We demonstrate that our approach outperforms competing\nmethods in both data visualization and clustering.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 04:01:45 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Mishne", "Gal", ""], ["Chi", "Eric C.", ""], ["Coifman", "Ronald R.", ""]]}, {"id": "1810.06807", "submitter": "Kartik Hegde", "authors": "Kartik Hegde, Rohit Agrawal, Yulun Yao, Christopher W. Fletcher", "title": "Morph: Flexible Acceleration for 3D CNN-based Video Understanding", "comments": "Appears in the proceedings of the 51st Annual IEEE/ACM International\n  Symposium on Microarchitecture (MICRO), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past several years have seen both an explosion in the use of\nConvolutional Neural Networks (CNNs) and the design of accelerators to make CNN\ninference practical. In the architecture community, the lion share of effort\nhas targeted CNN inference for image recognition. The closely related problem\nof video recognition has received far less attention as an accelerator target.\nThis is surprising, as video recognition is more computationally intensive than\nimage recognition, and video traffic is predicted to be the majority of\ninternet traffic in the coming years.\n  This paper fills the gap between algorithmic and hardware advances for video\nrecognition by providing a design space exploration and flexible architecture\nfor accelerating 3D Convolutional Neural Networks (3D CNNs) - the core kernel\nin modern video understanding. When compared to (2D) CNNs used for image\nrecognition, efficiently accelerating 3D CNNs poses a significant engineering\nchallenge due to their large (and variable over time) memory footprint and\nhigher dimensionality.\n  To address these challenges, we design a novel accelerator, called Morph,\nthat can adaptively support different spatial and temporal tiling strategies\ndepending on the needs of each layer of each target 3D CNN. We codesign a\nsoftware infrastructure alongside the Morph hardware to find good-fit\nparameters to control the hardware. Evaluated on state-of-the-art 3D CNNs,\nMorph achieves up to 3.4x (2.5x average) reduction in energy consumption and\nimproves performance/watt by up to 5.1x (4x average) compared to a baseline 3D\nCNN accelerator, with an area overhead of 5%. Morph further achieves a 15.9x\naverage energy reduction on 3D CNNs when compared to Eyeriss.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 04:49:15 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Hegde", "Kartik", ""], ["Agrawal", "Rohit", ""], ["Yao", "Yulun", ""], ["Fletcher", "Christopher W.", ""]]}, {"id": "1810.06825", "submitter": "Xu Feng", "authors": "Xu Feng, Yuyang Xie, Mingye Song, Wenjian Yu, Jie Tang", "title": "Fast Randomized PCA for Sparse Data", "comments": "16 pages, ACML2018 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is widely used for dimension reduction and\nembedding of real data in social network analysis, information retrieval, and\nnatural language processing, etc. In this work we propose a fast randomized PCA\nalgorithm for processing large sparse data. The algorithm has similar accuracy\nto the basic randomized SVD (rPCA) algorithm (Halko et al., 2011), but is\nlargely optimized for sparse data. It also has good flexibility to trade off\nruntime against accuracy for practical usage. Experiments on real data show\nthat the proposed algorithm is up to 9.1X faster than the basic rPCA algorithm\nwithout accuracy loss, and is up to 20X faster than the svds in Matlab with\nlittle error. The algorithm computes the first 100 principal components of a\nlarge information retrieval data with 12,869,521 persons and 323,899 keywords\nin less than 400 seconds on a 24-core machine, while all conventional methods\nfail due to the out-of-memory issue.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:00:28 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Feng", "Xu", ""], ["Xie", "Yuyang", ""], ["Song", "Mingye", ""], ["Yu", "Wenjian", ""], ["Tang", "Jie", ""]]}, {"id": "1810.06833", "submitter": "Chao Qian", "authors": "Yibo Zhang, Chao Qian, Ke Tang", "title": "Maximizing Monotone DR-submodular Continuous Functions by\n  Derivative-free Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of monotone (weakly) DR-submodular\ncontinuous maximization. While previous methods require the gradient\ninformation of the objective function, we propose a derivative-free algorithm\nLDGM for the first time. We define $\\beta$ and $\\alpha$ to characterize how\nclose a function is to continuous DR-submodulr and submodular, respectively.\nUnder a convex polytope constraint, we prove that LDGM can achieve a\n$(1-e^{-\\beta}-\\epsilon)$-approximation guarantee after $O(1/\\epsilon)$\niterations, which is the same as the best previous gradient-based algorithm.\nMoreover, in some special cases, a variant of LDGM can achieve a\n$((\\alpha/2)(1-e^{-\\alpha})-\\epsilon)$-approximation guarantee for (weakly)\nsubmodular functions. We also compare LDGM with the gradient-based algorithm\nFrank-Wolfe under noise, and show that LDGM can be more robust. Empirical\nresults on budget allocation verify the effectiveness of LDGM.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:32:34 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 08:23:23 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhang", "Yibo", ""], ["Qian", "Chao", ""], ["Tang", "Ke", ""]]}, {"id": "1810.06838", "submitter": "Dmitrii Ostrovskii", "authors": "Dmitrii Ostrovskii (USC), Francis Bach (DI-ENS, SIERRA)", "title": "Finite-sample analysis of M-estimators using self-concordance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical asymptotic theory for parametric $M$-estimators guarantees\nthat, in the limit of infinite sample size, the excess risk has a chi-square\ntype distribution, even in the misspecified case. We demonstrate how\nself-concordance of the loss allows to characterize the critical sample size\nsufficient to guarantee a chi-square type in-probability bound for the excess\nrisk. Specifically, we consider two classes of losses: (i) self-concordant\nlosses in the classical sense of Nesterov and Nemirovski, i.e., whose third\nderivative is uniformly bounded with the $3/2$ power of the second derivative;\n(ii) pseudo self-concordant losses, for which the power is removed. These\nclasses contain losses corresponding to several generalized linear models,\nincluding the logistic loss and pseudo-Huber losses. Our basic result under\nminimal assumptions bounds the critical sample size by $O(d \\cdot\nd_{\\text{eff}}),$ where $d$ the parameter dimension and $d_{\\text{eff}}$ the\neffective dimension that accounts for model misspecification. In contrast to\nthe existing results, we only impose local assumptions that concern the\npopulation risk minimizer $\\theta_*$. Namely, we assume that the calibrated\ndesign, i.e., design scaled by the square root of the second derivative of the\nloss, is subgaussian at $\\theta_*$. Besides, for type-ii losses we require\nboundedness of a certain measure of curvature of the population risk at\n$\\theta_*$.Our improved result bounds the critical sample size from above as\n$O(\\max\\{d_{\\text{eff}}, d \\log d\\})$ under slightly stronger assumptions.\nNamely, the local assumptions must hold in the neighborhood of $\\theta_*$ given\nby the Dikin ellipsoid of the population risk. Interestingly, we find that, for\nlogistic regression with Gaussian design, there is no actual restriction of\nconditions: the subgaussian parameter and curvature measure remain\nnear-constant over the Dikin ellipsoid. Finally, we extend some of these\nresults to $\\ell_1$-penalized estimators in high dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:39:10 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 14:21:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ostrovskii", "Dmitrii", "", "USC"], ["Bach", "Francis", "", "DI-ENS, SIERRA"]]}, {"id": "1810.06839", "submitter": "Alex Nowak-Vila", "authors": "Alex Nowak-Vila (SIERRA, PSL), Francis Bach (SIERRA, PSL), Alessandro\n  Rudi (SIERRA, PSL)", "title": "Sharp Analysis of Learning with Discrete Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of devising learning strategies for discrete losses (e.g.,\nmultilabeling, ranking) is currently addressed with methods and theoretical\nanalyses ad-hoc for each loss. In this paper we study a least-squares framework\nto systematically design learning algorithms for discrete losses, with\nquantitative characterizations in terms of statistical and computational\ncomplexity. In particular we improve existing results by providing explicit\ndependence on the number of labels for a wide class of losses and faster\nlearning rates in conditions of low-noise. Theoretical results are complemented\nwith experiments on real datasets, showing the effectiveness of the proposed\ngeneral approach.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:44:42 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Nowak-Vila", "Alex", "", "SIERRA, PSL"], ["Bach", "Francis", "", "SIERRA, PSL"], ["Rudi", "Alessandro", "", "SIERRA, PSL"]]}, {"id": "1810.06860", "submitter": "Xu Feng", "authors": "Xu Feng, Wenjian Yu, Yaohang Li", "title": "Faster Matrix Completion Using Randomized SVD", "comments": "8 pages, 5 figures, ICTAI 2018 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a widely used technique for image inpainting and\npersonalized recommender system, etc. In this work, we focus on accelerating\nthe matrix completion using faster randomized singular value decomposition\n(rSVD). Firstly, two fast randomized algorithms (rSVD-PI and rSVD- BKI) are\nproposed for handling sparse matrix. They make use of an eigSVD procedure and\nseveral accelerating skills. Then, with the rSVD-BKI algorithm and a new\nsubspace recycling technique, we accelerate the singular value thresholding\n(SVT) method in [1] to realize faster matrix completion. Experiments show that\nthe proposed rSVD algorithms can be 6X faster than the basic rSVD algorithm [2]\nwhile keeping same accuracy. For image inpainting and movie-rating estimation\nproblems, the proposed accelerated SVT algorithm consumes 15X and 8X less CPU\ntime than the methods using svds and lansvd respectively, without loss of\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 07:57:07 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Feng", "Xu", ""], ["Yu", "Wenjian", ""], ["Li", "Yaohang", ""]]}, {"id": "1810.06877", "submitter": "Kele Xu", "authors": "Kele Xu, Haibo Mi, Dawei Feng, Huaimin Wang, Chuan Chen, Zibin Zheng,\n  Xu Lan", "title": "Collaborative Deep Learning Across Multiple Data Centers", "comments": "Submitted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valuable training data is often owned by independent organizations and\nlocated in multiple data centers. Most deep learning approaches require to\ncentralize the multi-datacenter data for performance purpose. In practice,\nhowever, it is often infeasible to transfer all data to a centralized data\ncenter due to not only bandwidth limitation but also the constraints of privacy\nregulations. Model averaging is a conventional choice for data parallelized\ntraining, but its ineffectiveness is claimed by previous studies as deep neural\nnetworks are often non-convex. In this paper, we argue that model averaging can\nbe effective in the decentralized environment by using two strategies, namely,\nthe cyclical learning rate and the increased number of epochs for local model\ntraining. With the two strategies, we show that model averaging can provide\ncompetitive performance in the decentralized mode compared to the\ndata-centralized one. In a practical environment with multiple data centers, we\nconduct extensive experiments using state-of-the-art deep network architectures\non different types of data. Results demonstrate the effectiveness and\nrobustness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 08:33:33 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Xu", "Kele", ""], ["Mi", "Haibo", ""], ["Feng", "Dawei", ""], ["Wang", "Huaimin", ""], ["Chen", "Chuan", ""], ["Zheng", "Zibin", ""], ["Lan", "Xu", ""]]}, {"id": "1810.06891", "submitter": "Sharad Vikram", "authors": "Sharad Vikram, Matthew D. Hoffman, Matthew J. Johnson", "title": "The LORACs prior for VAEs: Letting the Trees Speak for the Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In variational autoencoders, the prior on the latent codes $z$ is often\ntreated as an afterthought, but the prior shapes the kind of latent\nrepresentation that the model learns. If the goal is to learn a representation\nthat is interpretable and useful, then the prior should reflect the ways in\nwhich the high-level factors that describe the data vary. The \"default\" prior\nis an isotropic normal, but if the natural factors of variation in the dataset\nexhibit discrete structure or are not independent, then the isotropic-normal\nprior will actually encourage learning representations that mask this\nstructure. To alleviate this problem, we propose using a flexible Bayesian\nnonparametric hierarchical clustering prior based on the time-marginalized\ncoalescent (TMC). To scale learning to large datasets, we develop a new\ninducing-point approximation and inference algorithm. We then apply the method\nwithout supervision to several datasets and examine the interpretability and\npractical performance of the inferred hierarchies and learned latent space.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:24:00 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Vikram", "Sharad", ""], ["Hoffman", "Matthew D.", ""], ["Johnson", "Matthew J.", ""]]}, {"id": "1810.06917", "submitter": "Fragkiskos  Malliaros", "authors": "Abdulkadir \\c{C}elikkanat, Fragkiskos D. Malliaros", "title": "TNE: A Latent Model for Representation Learning on Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning (NRL) methods aim to map each vertex into a\nlow dimensional space by preserving the local and global structure of a given\nnetwork, and in recent years they have received a significant attention thanks\nto their success in several challenging problems. Although various approaches\nhave been proposed to compute node embeddings, many successful methods benefit\nfrom random walks in order to transform a given network into a collection of\nsequences of nodes and then they target to learn the representation of nodes by\npredicting the context of each vertex within the sequence. In this paper, we\nintroduce a general framework to enhance the embeddings of nodes acquired by\nmeans of the random walk-based approaches. Similar to the notion of topical\nword embeddings in NLP, the proposed method assigns each vertex to a topic with\nthe favor of various statistical models and community detection methods, and\nthen generates the enhanced community representations. We evaluate our method\non two downstream tasks: node classification and link prediction. The\nexperimental results demonstrate that the incorporation of vertex and topic\nembeddings outperform widely-known baseline NRL methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 10:26:47 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["\u00c7elikkanat", "Abdulkadir", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "1810.06943", "submitter": "Arsenii Ashukha", "authors": "Andrei Atanov, Arsenii Ashukha, Kirill Struminsky, Dmitry Vetrov, Max\n  Welling", "title": "The Deep Weight Prior", "comments": "TL;DR: The deep weight prior learns a generative model for kernels of\n  convolutional neural networks, that acts as a prior distribution while\n  training on new datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bayesian inference is known to provide a general framework for incorporating\nprior knowledge or specific properties into machine learning models via\ncarefully choosing a prior distribution. In this work, we propose a new type of\nprior distributions for convolutional neural networks, deep weight prior (DWP),\nthat exploit generative models to encourage a specific structure of trained\nconvolutional filters e.g., spatial correlations of weights. We define DWP in\nthe form of an implicit distribution and propose a method for variational\ninference with such type of implicit priors. In experiments, we show that DWP\nimproves the performance of Bayesian neural networks when training data are\nlimited, and initialization of weights with samples from DWP accelerates\ntraining of conventional convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 11:59:10 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 17:39:40 GMT"}, {"version": "v3", "created": "Fri, 9 Nov 2018 06:47:43 GMT"}, {"version": "v4", "created": "Wed, 14 Nov 2018 15:06:04 GMT"}, {"version": "v5", "created": "Tue, 27 Nov 2018 15:41:39 GMT"}, {"version": "v6", "created": "Mon, 18 Feb 2019 21:51:28 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Atanov", "Andrei", ""], ["Ashukha", "Arsenii", ""], ["Struminsky", "Kirill", ""], ["Vetrov", "Dmitry", ""], ["Welling", "Max", ""]]}, {"id": "1810.06983", "submitter": "Kaspar M\\\"artens", "authors": "Kaspar M\\\"artens, Kieran R. Campbell, Christopher Yau", "title": "Decomposing feature-level variation with Covariate Gaussian Process\n  Latent Variable Models", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interpretation of complex high-dimensional data typically requires the\nuse of dimensionality reduction techniques to extract explanatory\nlow-dimensional representations. However, in many real-world problems these\nrepresentations may not be sufficient to aid interpretation on their own, and\nit would be desirable to interpret the model in terms of the original features\nthemselves. Our goal is to characterise how feature-level variation depends on\nlatent low-dimensional representations, external covariates, and non-linear\ninteractions between the two. In this paper, we propose to achieve this through\na structured kernel decomposition in a hybrid Gaussian Process model which we\ncall the Covariate Gaussian Process Latent Variable Model (c-GPLVM). We\ndemonstrate the utility of our model on simulated examples and applications in\ndisease progression modelling from high-dimensional gene expression data in the\npresence of additional phenotypes. In each setting we show how the c-GPLVM can\nextract low-dimensional structures from high-dimensional data sets whilst\nallowing a breakdown of feature-level variability that is not present in other\ncommonly used dimensionality reduction approaches.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 13:29:56 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 14:03:32 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["M\u00e4rtens", "Kaspar", ""], ["Campbell", "Kieran R.", ""], ["Yau", "Christopher", ""]]}, {"id": "1810.06992", "submitter": "Bruce MacLennan", "authors": "Bruce MacLennan", "title": "Topographic Representation for Quantum Machine Learning", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a brain-inspired approach to quantum machine learning\nwith the goal of circumventing many of the complications of other approaches.\nThe fact that quantum processes are unitary presents both opportunities and\nchallenges. A principal opportunity is that a large number of computations can\nbe carried out in parallel in linear superposition, that is, quantum\nparallelism. The challenge is that the process is linear, and most approaches\nto machine learning depend significantly on nonlinear processes. Fortunately,\nthe situation is not hopeless, for we know that nonlinear processes can be\nembedded in unitary processes, as is familiar from the circuit model of quantum\ncomputation. This paper explores an approach to the quantum implementation of\nmachine learning involving nonlinear functions operating on information\nrepresented topographically (by computational maps), as common in neural\ncortex.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 01:54:08 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 17:38:12 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 01:13:20 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["MacLennan", "Bruce", ""]]}, {"id": "1810.06999", "submitter": "Sai Praneeth Karimireddy", "authors": "Sai Praneeth Karimireddy, Anastasia Koloskova, Sebastian U. Stich,\n  Martin Jaggi", "title": "Efficient Greedy Coordinate Descent for Composite Problems", "comments": "44 pages, 17 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinate descent with random coordinate selection is the current state of\nthe art for many large scale optimization problems. However, greedy selection\nof the steepest coordinate on smooth problems can yield convergence rates\nindependent of the dimension $n$, and requiring upto $n$ times fewer\niterations.\n  In this paper, we consider greedy updates that are based on subgradients for\na class of non-smooth composite problems, which includes $L1$-regularized\nproblems, SVMs and related applications. For these problems we provide (i) the\nfirst linear rates of convergence independent of $n$, and show that our greedy\nupdate rule provides speedups similar to those obtained in the smooth case.\nThis was previously conjectured to be true for a stronger greedy coordinate\nselection strategy.\n  Furthermore, we show that (ii) our new selection rule can be mapped to\ninstances of maximum inner product search, allowing to leverage standard\nnearest neighbor algorithms to speed up the implementation. We demonstrate the\nvalidity of the approach through extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 13:54:59 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Karimireddy", "Sai Praneeth", ""], ["Koloskova", "Anastasia", ""], ["Stich", "Sebastian U.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1810.07052", "submitter": "Yigitcan Kaya", "authors": "Yigitcan Kaya, Sanghyun Hong, Tudor Dumitras", "title": "Shallow-Deep Networks: Understanding and Mitigating Network Overthinking", "comments": "Accepted to ICML2019. Source code here: www.shallowdeep.network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize a prevalent weakness of deep neural networks\n(DNNs)---overthinking---which occurs when a DNN can reach correct predictions\nbefore its final layer. Overthinking is computationally wasteful, and it can\nalso be destructive when, by the final layer, a correct prediction changes into\na misclassification. Understanding overthinking requires studying how each\nprediction evolves during a DNN's forward pass, which conventionally is opaque.\nFor prediction transparency, we propose the Shallow-Deep Network (SDN), a\ngeneric modification to off-the-shelf DNNs that introduces internal\nclassifiers. We apply SDN to four modern architectures, trained on three image\nclassification tasks, to characterize the overthinking problem. We show that\nSDNs can mitigate the wasteful effect of overthinking with confidence-based\nearly exits, which reduce the average inference cost by more than 50% and\npreserve the accuracy. We also find that the destructive effect occurs for 50%\nof misclassifications on natural inputs and that it can be induced,\nadversarially, with a recent backdooring attack. To mitigate this effect, we\npropose a new confusion metric to quantify the internal disagreements that will\nlikely lead to misclassifications.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 14:51:13 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 23:34:31 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 00:49:52 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Kaya", "Yigitcan", ""], ["Hong", "Sanghyun", ""], ["Dumitras", "Tudor", ""]]}, {"id": "1810.07076", "submitter": "Sashank J. Reddi", "authors": "Sashank J. Reddi, Satyen Kale, Felix Yu, Dan Holtmann-Rice, Jiecao\n  Chen, Sanjiv Kumar", "title": "Stochastic Negative Mining for Learning with Large Output Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of retrieving the most relevant labels for a given\ninput when the size of the output space is very large. Retrieval methods are\nmodeled as set-valued classifiers which output a small set of classes for each\ninput, and a mistake is made if the label is not in the output set. Despite its\npractical importance, a statistically principled, yet practical solution to\nthis problem is largely missing. To this end, we first define a family of\nsurrogate losses and show that they are calibrated and convex under certain\nconditions on the loss parameters and data distribution, thereby establishing a\nstatistical and analytical basis for using these losses. Furthermore, we\nidentify a particularly intuitive class of loss functions in the aforementioned\nfamily and show that they are amenable to practical implementation in the large\noutput space setting (i.e. computation is possible without evaluating scores of\nall labels) by developing a technique called Stochastic Negative Mining. We\nalso provide generalization error bounds for the losses in the family. Finally,\nwe conduct experiments which demonstrate that Stochastic Negative Mining yields\nbenefits over commonly used negative sampling approaches.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 15:27:31 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Reddi", "Sashank J.", ""], ["Kale", "Satyen", ""], ["Yu", "Felix", ""], ["Holtmann-Rice", "Dan", ""], ["Chen", "Jiecao", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1810.07128", "submitter": "Sen Na", "authors": "Sen Na, Zhuoran Yang, Zhaoran Wang, Mladen Kolar", "title": "High-dimensional Varying Index Coefficient Models via Stein's Identity", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameter estimation problem for a varying index coefficient\nmodel in high dimensions. Unlike the most existing works that iteratively\nestimate the parameters and link functions, based on the generalized Stein's\nidentity, we propose computationally efficient estimators for the\nhigh-dimensional parameters without estimating the link functions. We consider\ntwo different setups where we either estimate each sparse parameter vector\nindividually or estimate the parameters simultaneously as a sparse or low-rank\nmatrix. For all these cases, our estimators are shown to achieve optimal\nstatistical rates of convergence (up to logarithmic terms in the low-rank\nsetting). Moreover, throughout our analysis, we only require the covariate to\nsatisfy certain moment conditions, which is significantly weaker than the\nGaussian or elliptically symmetric assumptions that are commonly made in the\nexisting literature. Finally, we conduct extensive numerical experiments to\ncorroborate the theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 16:51:28 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 03:00:26 GMT"}, {"version": "v3", "created": "Sun, 21 Oct 2018 21:56:15 GMT"}, {"version": "v4", "created": "Fri, 25 Oct 2019 18:33:53 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Na", "Sen", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Kolar", "Mladen", ""]]}, {"id": "1810.07147", "submitter": "Sinong Geng", "authors": "Sinong Geng, Mladen Kolar and Oluwasanmi Koyejo", "title": "Joint Nonparametric Precision Matrix Estimation with Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of precision matrix estimation where, due to\nextraneous confounding of the underlying precision matrix, the data are\nindependent but not identically distributed. While such confounding occurs in\nmany scientific problems, our approach is inspired by recent neuroscientific\nresearch suggesting that brain function, as measured using functional magnetic\nresonance imagine (fMRI), is susceptible to confounding by physiological noise\nsuch as breathing and subject motion. Following the scientific motivation, we\npropose a graphical model, which in turn motivates a joint nonparametric\nestimator. We provide theoretical guarantees for the consistency and the\nconvergence rate of the proposed estimator. In addition, we demonstrate that\nthe optimization of the proposed estimator can be transformed into a series of\nlinear programming problems, and thus be efficiently solved in parallel.\nEmpirical results are presented using simulated and real brain imaging data,\nwhich suggest that our approach improves precision matrix estimation, as\ncompared to baselines, when confounding is present.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:20:15 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 18:35:29 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Geng", "Sinong", ""], ["Kolar", "Mladen", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1810.07151", "submitter": "Kirill Neklyudov", "authors": "Kirill Neklyudov, Evgenii Egorov, Pavel Shvechikov, Dmitry Vetrov", "title": "Metropolis-Hastings view on variational inference and adversarial\n  training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant part of MCMC methods can be considered as the\nMetropolis-Hastings (MH) algorithm with different proposal distributions. From\nthis point of view, the problem of constructing a sampler can be reduced to the\nquestion - how to choose a proposal for the MH algorithm? To address this\nquestion, we propose to learn an independent sampler that maximizes the\nacceptance rate of the MH algorithm, which, as we demonstrate, is highly\nrelated to the conventional variational inference. For Bayesian inference, the\nproposed method compares favorably against alternatives to sample from the\nposterior distribution. Under the same approach, we step beyond the scope of\nclassical MCMC methods and deduce the Generative Adversarial Networks (GANs)\nframework from scratch, treating the generator as the proposal and the\ndiscriminator as the acceptance test. On real-world datasets, we improve\nFrechet Inception Distance and Inception Score, using different GANs as a\nproposal distribution for the MH algorithm. In particular, we demonstrate\nimprovements of recently proposed BigGAN model on ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:26:24 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 14:23:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Neklyudov", "Kirill", ""], ["Egorov", "Evgenii", ""], ["Shvechikov", "Pavel", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.07155", "submitter": "Samuel Yeom", "authors": "Samuel Yeom, Anupam Datta, Matt Fredrikson", "title": "Hunting for Discriminatory Proxies in Linear Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning model may exhibit discrimination when used to make\ndecisions involving people. One potential cause for such outcomes is that the\nmodel uses a statistical proxy for a protected demographic attribute. In this\npaper we formulate a definition of proxy use for the setting of linear\nregression and present algorithms for detecting proxies. Our definition follows\nrecent work on proxies in classification models, and characterizes a model's\nconstituent behavior that: 1) correlates closely with a protected random\nvariable, and 2) is causally influential in the overall behavior of the model.\nWe show that proxies in linear regression models can be efficiently identified\nby solving a second-order cone program, and further extend this result to\naccount for situations where the use of a certain input variable is justified\nas a `business necessity'. Finally, we present empirical results on two law\nenforcement datasets that exhibit varying degrees of racial disparity in\nprediction outcomes, demonstrating that proxies shed useful light on the causes\nof discriminatory behavior in models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:32:27 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 18:12:11 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 21:43:47 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Yeom", "Samuel", ""], ["Datta", "Anupam", ""], ["Fredrikson", "Matt", ""]]}, {"id": "1810.07158", "submitter": "Markus Kaiser", "authors": "Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Henrik Ek", "title": "Data Association with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data association problem is concerned with separating data coming from\ndifferent generating processes, for example when data come from different data\nsources, contain significant noise, or exhibit multimodality. We present a\nfully Bayesian approach to this problem. Our model is capable of simultaneously\nsolving the data association problem and the induced supervised learning\nproblems. Underpinning our approach is the use of Gaussian process priors to\nencode the structure of both the data and the data associations. We present an\nefficient learning scheme based on doubly stochastic variational inference and\ndiscuss how it can be applied to deep Gaussian process priors.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:39:12 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 13:39:21 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 12:46:26 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kaiser", "Markus", ""], ["Otte", "Clemens", ""], ["Runkler", "Thomas", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1810.07168", "submitter": "Jacques Wainer", "authors": "Jacques Wainer and Rodrigo A. Franceschinell", "title": "An empirical evaluation of imbalanced data strategies from a\n  practitioner's point of view", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research tested the following well known strategies to deal with binary\nimbalanced data on 82 different real life data sets (sampled to imbalance rates\nof 5%, 3%, 1%, and 0.1%): class weight, SMOTE, Underbagging, and a baseline\n(just the base classifier). As base classifiers we used SVM with RBF kernel,\nrandom forests, and gradient boosting machines and we measured the quality of\nthe resulting classifier using 6 different metrics (Area under the curve,\nAccuracy, F-measure, G-mean, Matthew's correlation coefficient and Balanced\naccuracy). The best strategy strongly depends on the metric used to measure the\nquality of the classifier. For AUC and accuracy class weight and the baseline\nperform better; for F-measure and MCC, SMOTE performs better; and for G-mean\nand balanced accuracy, underbagging.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:50:31 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Wainer", "Jacques", ""], ["Franceschinell", "Rodrigo A.", ""]]}, {"id": "1810.07180", "submitter": "Yanjie Wang", "authors": "Yanjie Wang, Daniel Ruffinelli, Rainer Gemulla, Samuel Broscheit,\n  Christian Meilicke", "title": "On Evaluating Embedding Models for Knowledge Base Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases contribute to many web search and mining tasks, yet they are\noften incomplete. To add missing facts to a given knowledge base, various\nembedding models have been proposed in the recent literature. Perhaps\nsurprisingly, relatively simple models with limited expressiveness often\nperformed remarkably well under today's most commonly used evaluation\nprotocols. In this paper, we explore whether recent models work well for\nknowledge base completion and argue that the current evaluation protocols are\nmore suited for question answering rather than knowledge base completion. We\nshow that when focusing on a different prediction task for evaluating knowledge\nbase completion, the performance of current embedding models is unsatisfactory\neven on datasets previously thought to be too easy. This is especially true\nwhen embedding models are compared against a simple rule-based baseline. This\nwork indicates the need for more research into the embedding models and\nevaluation protocols for knowledge base completion.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 14:09:10 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 13:30:39 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 11:28:19 GMT"}, {"version": "v4", "created": "Thu, 31 Jan 2019 19:22:59 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Wang", "Yanjie", ""], ["Ruffinelli", "Daniel", ""], ["Gemulla", "Rainer", ""], ["Broscheit", "Samuel", ""], ["Meilicke", "Christian", ""]]}, {"id": "1810.07216", "submitter": "Hannah Druckenmiller", "authors": "Hannah Druckenmiller and Solomon Hsiang", "title": "Accounting for Unobservable Heterogeneity in Cross Section Using Spatial\n  First Differences", "comments": "42 pages, 11 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a cross-sectional research design to identify causal effects in\nthe presence of unobservable heterogeneity without instruments. When units are\ndense in physical space, it may be sufficient to regress the \"spatial first\ndifferences\" (SFD) of the outcome on the treatment and omit all covariates. The\nidentifying assumptions of SFD are similar in mathematical structure and\nplausibility to other quasi-experimental designs. We use SFD to obtain new\nestimates for the effects of time-invariant geographic factors, soil and\nclimate, on long-run agricultural productivities --- relationships crucial for\neconomic decisions, such as land management and climate policy, but notoriously\nconfounded by unobservables.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:19:38 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 13:16:59 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Druckenmiller", "Hannah", ""], ["Hsiang", "Solomon", ""]]}, {"id": "1810.07218", "submitter": "Mengye Ren", "authors": "Mengye Ren, Renjie Liao, Ethan Fetaya, Richard S. Zemel", "title": "Incremental Few-Shot Learning with Attention Attractor Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning classifiers are often trained to recognize a set of\npre-defined classes. However, in many applications, it is often desirable to\nhave the flexibility of learning additional concepts, with limited data and\nwithout re-training on the full training set. This paper addresses this\nproblem, incremental few-shot learning, where a regular classification network\nhas already been trained to recognize a set of base classes, and several extra\nnovel classes are being considered, each with only a few labeled examples.\nAfter learning the novel classes, the model is then evaluated on the overall\nclassification performance on both base and novel classes. To this end, we\npropose a meta-learning model, the Attention Attractor Network, which\nregularizes the learning of novel classes. In each episode, we train a set of\nnew weights to recognize novel classes until they converge, and we show that\nthe technique of recurrent back-propagation can back-propagate through the\noptimization process and facilitate the learning of these parameters. We\ndemonstrate that the learned attractor network can help recognize novel classes\nwhile remembering old classes without the need to review the original training\nset, outperforming various baselines.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:25:17 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 15:35:29 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 21:08:47 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ren", "Mengye", ""], ["Liao", "Renjie", ""], ["Fetaya", "Ethan", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1810.07248", "submitter": "Ali Emami", "authors": "Mahdi Ahmadi, Alireza Norouzi, S.M.Reza Soroushmehr, Nader Karimi,\n  Kayvan Najarian, Shadrokh Samavi and Ali Emami", "title": "ReDMark: Framework for Residual Diffusion Watermarking on Deep Networks", "comments": "33 pages (Single column), 10 figures, 5 tables, one appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rapid growth of machine learning tools and specifically deep\nnetworks in various computer vision and image processing areas, application of\nConvolutional Neural Networks for watermarking have recently emerged. In this\npaper, we propose a deep end-to-end diffusion watermarking framework (ReDMark)\nwhich can be adapted for any desired transform space. The framework is composed\nof two Fully Convolutional Neural Networks with the residual structure for\nembedding and extraction. The whole deep network is trained end-to-end to\nconduct a blind secure watermarking. The framework is customizable for the\nlevel of robustness vs. imperceptibility. It is also adjustable for the\ntrade-off between capacity and robustness. The proposed framework simulates\nvarious attacks as a differentiable network layer to facilitate end-to-end\ntraining. For JPEG attack, a differentiable approximation is utilized, which\ndrastically improves the watermarking robustness to this attack. Another\nimportant characteristic of the proposed framework, which leads to improved\nsecurity and robustness, is its capability to diffuse watermark information\namong a relatively wide area of the image. Comparative results versus recent\nstate-of-the-art researches highlight the superiority of the proposed framework\nin terms of imperceptibility and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:07:15 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 09:53:39 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 09:32:01 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ahmadi", "Mahdi", ""], ["Norouzi", "Alireza", ""], ["Soroushmehr", "S. M. Reza", ""], ["Karimi", "Nader", ""], ["Najarian", "Kayvan", ""], ["Samavi", "Shadrokh", ""], ["Emami", "Ali", ""]]}, {"id": "1810.07251", "submitter": "Nelly Elsayed", "authors": "Nelly Elsayed, Anthony S. Maida, Magdy Bayoumi", "title": "Reduced-Gate Convolutional LSTM Using Predictive Coding for\n  Spatiotemporal Prediction", "comments": "A novel rgcLSTM model for spatiotemporal prediction. This version\n  contains the full description and detailed empirical study of the rgcLSTM\n  architecture. 28 pages, 12 figures, 20 tables", "journal-ref": null, "doi": "10.1111/coin.12277", "report-no": "COIN12277", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal sequence prediction is an important problem in deep learning.\nWe study next-frame(s) video prediction using a deep-learning-based predictive\ncoding framework that uses convolutional, long short-term memory (convLSTM)\nmodules. We introduce a novel reduced-gate convolutional LSTM(rgcLSTM)\narchitecture that requires a significantly lower parameter budget than a\ncomparable convLSTM. By using a single multi-function gate, our reduced-gate\nmodel achieves equal or better next-frame(s) prediction accuracy than the\noriginal convolutional LSTM while using a smaller parameter budget, thereby\nreducing training time and memory requirements. We tested our reduced gate\nmodules within a predictive coding architecture on the moving MNIST and KITTI\ndatasets. We found that our reduced-gate model has a significant reduction of\napproximately 40 percent of the total number of training parameters and a 25\npercent reduction in elapsed training time in comparison with the standard\nconvolutional LSTM model. The performance accuracy of the new model was also\nimproved. This makes our model more attractive for hardware implementation,\nespecially on small devices. We also explored a space of twenty different gated\narchitectures to get insight into how our rgcLSTM fit into that space.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 19:55:51 GMT"}, {"version": "v10", "created": "Wed, 23 Oct 2019 03:30:11 GMT"}, {"version": "v11", "created": "Sun, 22 Dec 2019 21:44:41 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 20:36:59 GMT"}, {"version": "v3", "created": "Sun, 18 Nov 2018 06:08:08 GMT"}, {"version": "v4", "created": "Wed, 5 Dec 2018 01:52:15 GMT"}, {"version": "v5", "created": "Sun, 9 Dec 2018 03:11:44 GMT"}, {"version": "v6", "created": "Tue, 11 Dec 2018 01:57:45 GMT"}, {"version": "v7", "created": "Fri, 28 Dec 2018 01:26:57 GMT"}, {"version": "v8", "created": "Thu, 10 Jan 2019 19:05:49 GMT"}, {"version": "v9", "created": "Fri, 15 Mar 2019 19:21:00 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Elsayed", "Nelly", ""], ["Maida", "Anthony S.", ""], ["Bayoumi", "Magdy", ""]]}, {"id": "1810.07254", "submitter": "Amos Azaria", "authors": "Yitzhak Spielberg, Amos Azaria", "title": "The Concept of Criticality in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods carry a well known bias-variance trade-off in\nn-step algorithms for optimal control. Unfortunately, this has rarely been\naddressed in current research. This trade-off principle holds independent of\nthe choice of the algorithm, such as n-step SARSA, n-step Expected SARSA or\nn-step Tree backup. A small n results in a large bias, while a large n leads to\nlarge variance. The literature offers no straightforward recipe for the best\nchoice of this value. While currently all n-step algorithms use a fixed value\nof n over the state space we extend the framework of n-step updates by allowing\neach state to have its specific n.\n  We propose a solution to this problem within the context of human aided\nreinforcement learning. Our approach is based on the observation that a human\ncan learn more efficiently if she receives input regarding the criticality of a\ngiven state and thus the amount of attention she needs to invest into the\nlearning in that state. This observation is related to the idea that each state\nof the MDP has a certain measure of criticality which indicates how much the\nchoice of the action in that state influences the return. In our algorithm the\nRL agent utilizes the criticality measure, a function provided by a human\ntrainer, in order to locally choose the best stepnumber n for the update of the\nQ function.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 20:07:06 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Spielberg", "Yitzhak", ""], ["Azaria", "Amos", ""]]}, {"id": "1810.07260", "submitter": "Shouhuai Xu", "authors": "Pang Du and Zheyuan Sun and Huashan Chen and Jin-Hee Cho and Shouhuai\n  Xu", "title": "Statistical Estimation of Malware Detection Metrics in the Absence of\n  Ground Truth", "comments": null, "journal-ref": "IEEE T-IFS (2018)", "doi": null, "report-no": null, "categories": "stat.AP cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate measurement of security metrics is a critical research problem\nbecause an improper or inaccurate measurement process can ruin the usefulness\nof the metrics, no matter how well they are defined. This is a highly\nchallenging problem particularly when the ground truth is unknown or noisy. In\ncontrast to the well perceived importance of defining security metrics, the\nmeasurement of security metrics has been little understood in the literature.\nIn this paper, we measure five malware detection metrics in the {\\em absence}\nof ground truth, which is a realistic setting that imposes many technical\nchallenges. The ultimate goal is to develop principled, automated methods for\nmeasuring these metrics at the maximum accuracy possible. The problem naturally\ncalls for investigations into statistical estimators by casting the measurement\nproblem as a {\\em statistical estimation} problem. We propose statistical\nestimators for these five malware detection metrics. By investigating the\nstatistical properties of these estimators, we are able to characterize when\nthe estimators are accurate, and what adjustments can be made to improve them\nunder what circumstances. We use synthetic data with known ground truth to\nvalidate these statistical estimators. Then, we employ these estimators to\nmeasure five metrics with respect to a large dataset collected from VirusTotal.\nWe believe our study touches upon a vital problem that has not been paid due\nattention and will inspire many future investigations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 02:40:31 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Du", "Pang", ""], ["Sun", "Zheyuan", ""], ["Chen", "Huashan", ""], ["Cho", "Jin-Hee", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1810.07287", "submitter": "Karl Kumbier", "authors": "Karl Kumbier and Sumanta Basu and James B. Brown and Susan Celniker\n  and Bin Yu", "title": "Refining interaction search through signed iterative Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in supervised learning have enabled accurate prediction in\nbiological systems governed by complex interactions among biomolecules.\nHowever, state-of-the-art predictive algorithms are typically black-boxes,\nlearning statistical interactions that are difficult to translate into testable\nhypotheses. The iterative Random Forest algorithm took a step towards bridging\nthis gap by providing a computationally tractable procedure to identify the\nstable, high-order feature interactions that drive the predictive accuracy of\nRandom Forests (RF). Here we refine the interactions identified by iRF to\nexplicitly map responses as a function of interacting features. Our method,\nsigned iRF, describes subsets of rules that frequently occur on RF decision\npaths. We refer to these rule subsets as signed interactions. Signed\ninteractions share not only the same set of interacting features but also\nexhibit similar thresholding behavior, and thus describe a consistent\nfunctional relationship between interacting features and responses. We describe\nstable and predictive importance metrics to rank signed interactions. For each\nSPIM, we define null importance metrics that characterize its expected behavior\nunder known structure. We evaluate our proposed approach in biologically\ninspired simulations and two case studies: predicting enhancer activity and\nspatial gene expression patterns. In the case of enhancer activity, s-iRF\nrecovers one of the few experimentally validated high-order interactions and\nsuggests novel enhancer elements where this interaction may be active. In the\ncase of spatial gene expression patterns, s-iRF recovers all 11 reported links\nin the gap gene network. By refining the process of interaction recovery, our\napproach has the potential to guide mechanistic inquiry into systems whose\nscale and complexity is beyond human comprehension.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:39:41 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Kumbier", "Karl", ""], ["Basu", "Sumanta", ""], ["Brown", "James B.", ""], ["Celniker", "Susan", ""], ["Yu", "Bin", ""]]}, {"id": "1810.07288", "submitter": "Sharan Vaswani", "authors": "Sharan Vaswani, Francis Bach, Mark Schmidt", "title": "Fast and Faster Convergence of SGD for Over-Parameterized Models and an\n  Accelerated Perceptron", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning focuses on highly expressive models that are able to\nfit or interpolate the data completely, resulting in zero training loss. For\nsuch models, we show that the stochastic gradients of common loss functions\nsatisfy a strong growth condition. Under this condition, we prove that constant\nstep-size stochastic gradient descent (SGD) with Nesterov acceleration matches\nthe convergence rate of the deterministic accelerated method for both convex\nand strongly-convex functions. We also show that this condition implies that\nSGD can find a first-order stationary point as efficiently as full gradient\ndescent in non-convex settings. Under interpolation, we further show that all\nsmooth loss functions with a finite-sum structure satisfy a weaker growth\ncondition. Given this weaker condition, we prove that SGD with a constant\nstep-size attains the deterministic convergence rate in both the\nstrongly-convex and convex settings. Under additional assumptions, the above\nresults enable us to prove an O(1/k^2) mistake bound for k iterations of a\nstochastic perceptron algorithm using the squared-hinge loss. Finally, we\nvalidate our theoretical findings with experiments on synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:48:11 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:27:06 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 18:58:38 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Vaswani", "Sharan", ""], ["Bach", "Francis", ""], ["Schmidt", "Mark", ""]]}, {"id": "1810.07291", "submitter": "Mehran Pesteie", "authors": "Mehran Pesteie, Purang Abolmaesumi, Robert Rohling", "title": "Deep Neural Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new unsupervised representation learning and visualization\nusing deep convolutional networks and self organizing maps called Deep Neural\nMaps (DNM). DNM jointly learns an embedding of the input data and a mapping\nfrom the embedding space to a two-dimensional lattice. We compare\nvisualizations of DNM with those of t-SNE and LLE on the MNIST and COIL-20 data\nsets. Our experiments show that the DNM can learn efficient representations of\nthe input data, which reflects characteristics of each class. This is shown via\nback-projecting the neurons of the map on the data space.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:59:47 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Pesteie", "Mehran", ""], ["Abolmaesumi", "Purang", ""], ["Rohling", "Robert", ""]]}, {"id": "1810.07301", "submitter": "Tamar Pichkhadze", "authors": "Vikas K. Garg and Tamar Pichkhadze", "title": "Online Markov Decoding: Lower Bounds and Near-Optimal Approximation\n  Algorithms", "comments": "Added experiments, fixed typos, and polished presentation. Currently\n  under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We resolve the fundamental problem of online decoding with general $n^{th}$\norder ergodic Markov chain models. Specifically, we provide deterministic and\nrandomized algorithms whose performance is close to that of the optimal offline\nalgorithm even when latency is small. Our algorithms admit efficient\nimplementation via dynamic programs, and readily extend to (adversarial)\nnon-stationary or time-varying settings. We also establish lower bounds for\nonline methods under latency constraints in both deterministic and randomized\nsettings, and show that no online algorithm can perform significantly better\nthan our algorithms. Empirically, just with latency one, our algorithm\noutperforms the online step algorithm by over 30\\% in terms of decoding\nagreement with the optimal algorithm on genome sequence data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 22:49:48 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:07:52 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Garg", "Vikas K.", ""], ["Pichkhadze", "Tamar", ""]]}, {"id": "1810.07309", "submitter": "Jinxi Guo", "authors": "Jinxi Guo, Ning Xu, Kailun Qian, Yang Shi, Kaiyuan Xu, Yingnian Wu,\n  Abeer Alwan", "title": "Deep neural network based i-vector mapping for speaker verification\n  using short utterances", "comments": "Submitted to Speech Communication; under final review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-independent speaker recognition using short utterances is a highly\nchallenging task due to the large variation and content mismatch between short\nutterances. I-vector based systems have become the standard in speaker\nverification applications, but they are less effective with short utterances.\nIn this paper, we first compare two state-of-the-art universal background model\ntraining methods for i-vector modeling using full-length and short utterance\nevaluation tasks. The two methods are Gaussian mixture model (GMM) based and\ndeep neural network (DNN) based methods. The results indicate that the\nI-vector_DNN system outperforms the I-vector_GMM system under various\ndurations. However, the performances of both systems degrade significantly as\nthe duration of the utterances decreases. To address this issue, we propose two\nnovel nonlinear mapping methods which train DNN models to map the i-vectors\nextracted from short utterances to their corresponding long-utterance\ni-vectors. The mapped i-vector can restore missing information and reduce the\nvariance of the original short-utterance i-vectors. The proposed methods both\nmodel the joint representation of short and long utterance i-vectors by using\nautoencoder. Experimental results using the NIST SRE 2010 dataset show that\nboth methods provide significant improvement and result in a max of 28.43%\nrelative improvement in Equal Error Rates from a baseline system, when using\ndeep encoder with residual blocks and adding an additional phoneme vector. When\nfurther testing the best-validated models of SRE10 on the Speaker In The Wild\ndataset, the methods result in a 23.12% improvement on arbitrary-duration (1-5\ns) short-utterance conditions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:16:38 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Guo", "Jinxi", ""], ["Xu", "Ning", ""], ["Qian", "Kailun", ""], ["Shi", "Yang", ""], ["Xu", "Kaiyuan", ""], ["Wu", "Yingnian", ""], ["Alwan", "Abeer", ""]]}, {"id": "1810.07310", "submitter": "Yu-Hang Tang", "authors": "Yu-Hang Tang, Wibe A. de Jong", "title": "Prediction of Atomization Energy Using Graph Kernel and Active Learning", "comments": null, "journal-ref": "J. Chem. Phys. 150(4): 044107, 2019", "doi": "10.1063/1.5078640", "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci cs.CE physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven prediction of molecular properties presents unique challenges to\nthe design of machine learning methods concerning data\nstructure/dimensionality, symmetry adaption, and confidence management. In this\npaper, we present a kernel-based pipeline that can learn and predict the\natomization energy of molecules with high accuracy. The framework employs\nGaussian process regression to perform predictions based on the similarity\nbetween molecules, which is computed using the marginalized graph kernel. To\napply the marginalized graph kernel, a spatial adjacency rule is first employed\nto convert molecules into graphs whose vertices and edges are labeled by\nelements and interatomic distances, respectively. We then derive formulas for\nthe efficient evaluation of the kernel. Specific functional components for the\nmarginalized graph kernel are proposed, while the effect of the associated\nhyperparameters on accuracy and predictive confidence are examined. We show\nthat the graph kernel is particularly suitable for predicting extensive\nproperties because its convolutional structure coincides with that of the\ncovariance formula between sums of random variables. Using an active learning\nprocedure, we demonstrate that the proposed method can achieve a mean absolute\nerror of 0.62 +- 0.01 kcal/mol using as few as 2000 training samples on the QM7\ndata set.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:21:03 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 06:39:50 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 06:00:28 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Tang", "Yu-Hang", ""], ["de Jong", "Wibe A.", ""]]}, {"id": "1810.07320", "submitter": "Adly Templeton", "authors": "Adly Templeton, Jugal Kalita", "title": "Exploring Sentence Vector Spaces through Automatic Summarization", "comments": "Accepted for publication in ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given vector representations for individual words, it is necessary to compute\nvector representations of sentences for many applications in a compositional\nmanner, often using artificial neural networks.\n  Relatively little work has explored the internal structure and properties of\nsuch sentence vectors. In this paper, we explore the properties of sentence\nvectors in the context of automatic summarization. In particular, we show that\ncosine similarity between sentence vectors and document vectors is strongly\ncorrelated with sentence importance and that vector semantics can identify and\ncorrect gaps between the sentences chosen so far and the document. In addition,\nwe identify specific dimensions which are linked to effective summaries. To our\nknowledge, this is the first time specific dimensions of sentence embeddings\nhave been connected to sentence properties. We also compare the features of\ndifferent methods of sentence embeddings. Many of these insights have\napplications in uses of sentence embeddings far beyond summarization.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:57:37 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Templeton", "Adly", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.07322", "submitter": "Zhuwei Qin", "authors": "Zhuwei Qin, Fuxun Yu, Chenchen Liu, Xiang Chen", "title": "Functionality-Oriented Convolutional Filter Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As\nsignificant redundancies inevitably present in such a structure, many works\nhave been proposed to prune the convolutional filters for computation cost\nreduction. Although extremely effective, most works are based only on\nquantitative characteristics of the convolutional filters, and highly overlook\nthe qualitative interpretation of individual filter's specific functionality.\nIn this work, we interpreted the functionality and redundancy of the\nconvolutional filters from different perspectives, and proposed a\nfunctionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters' qualitative significance\nregardless of magnitude, demonstrated significant neural network redundancy due\nto repetitive filter functions, and analyzed the filter functionality defection\nunder inappropriate retraining process. Such an interpretable pruning approach\nnot only offers outstanding computation cost optimization over previous filter\npruning methods, but also interprets filter pruning process.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 20:39:47 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 03:24:06 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Qin", "Zhuwei", ""], ["Yu", "Fuxun", ""], ["Liu", "Chenchen", ""], ["Chen", "Xiang", ""]]}, {"id": "1810.07339", "submitter": "Guofu Li", "authors": "Guofu Li, Pengjia Zhu, Jin Li, Zhemin Yang, Ning Cao, and Zhiyi Chen", "title": "Security Matters: A Survey on Adversarial Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial machine learning is a fast growing research area, which considers\nthe scenarios when machine learning systems may face potential adversarial\nattackers, who intentionally synthesize input data to make a well-trained model\nto make mistake. It always involves a defending side, usually a classifier, and\nan attacking side that aims to cause incorrect output. The earliest studies on\nthe adversarial examples for machine learning algorithms start from the\ninformation security area, which considers a much wider varieties of attacking\nmethods. But recent research focus that popularized by the deep learning\ncommunity places strong emphasis on how the \"imperceivable\" perturbations on\nthe normal inputs may cause dramatic mistakes by the deep learning with\nsupposed super-human accuracy. This paper serves to give a comprehensive\nintroduction to a range of aspects of the adversarial deep learning topic,\nincluding its foundations, typical attacking and defending strategies, and some\nextended studies.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:06:26 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 03:13:05 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Li", "Guofu", ""], ["Zhu", "Pengjia", ""], ["Li", "Jin", ""], ["Yang", "Zhemin", ""], ["Cao", "Ning", ""], ["Chen", "Zhiyi", ""]]}, {"id": "1810.07348", "submitter": "Andri Ashfahani", "authors": "Andri Ashfahani and Mahardhika Pratama", "title": "Autonomous Deep Learning: Continual Learning Approach for Dynamic\n  Environments", "comments": null, "journal-ref": "This paper has been published in Proceedings of the 2019 SIAM\n  International Conference on Data Mining", "doi": "10.1137/1.9781611975673.75", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The feasibility of deep neural networks (DNNs) to address data stream\nproblems still requires intensive study because of the static and offline\nnature of conventional deep learning approaches. A deep continual learning\nalgorithm, namely autonomous deep learning (ADL), is proposed in this paper.\nUnlike traditional deep learning methods, ADL features a flexible structure\nwhere its network structure can be constructed from scratch with the absence of\nan initial network structure via the self-constructing network structure. ADL\nspecifically addresses catastrophic forgetting by having a different-depth\nstructure which is capable of achieving a trade-off between plasticity and\nstability. Network significance (NS) formula is proposed to drive the hidden\nnodes growing and pruning mechanism. Drift detection scenario (DDS) is put\nforward to signal distributional changes in data streams which induce the\ncreation of a new hidden layer. The maximum information compression index\n(MICI) method plays an important role as a complexity reduction module\neliminating redundant layers. The efficacy of ADL is numerically validated\nunder the prequential test-then-train procedure in lifelong environments using\nnine popular data stream problems. The numerical results demonstrate that ADL\nconsistently outperforms recent continual learning methods while characterizing\nthe automatic construction of network structures.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 01:40:45 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 18:48:02 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 15:02:06 GMT"}, {"version": "v4", "created": "Thu, 9 Jan 2020 12:19:19 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ashfahani", "Andri", ""], ["Pratama", "Mahardhika", ""]]}, {"id": "1810.07354", "submitter": "Aurick Qiao", "authors": "Aurick Qiao, Bryon Aragam, Bingjing Zhang, Eric P. Xing", "title": "Fault Tolerance in Iterative-Convergent Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) training algorithms often possess an inherent\nself-correcting behavior due to their iterative-convergent nature. Recent\nsystems exploit this property to achieve adaptability and efficiency in\nunreliable computing environments by relaxing the consistency of execution and\nallowing calculation errors to be self-corrected during training. However, the\nbehavior of such systems are only well understood for specific types of\ncalculation errors, such as those caused by staleness, reduced precision, or\nasynchronicity, and for specific types of training algorithms, such as\nstochastic gradient descent. In this paper, we develop a general framework to\nquantify the effects of calculation errors on iterative-convergent algorithms\nand use this framework to design new strategies for checkpoint-based fault\ntolerance. Our framework yields a worst-case upper bound on the iteration cost\nof arbitrary perturbations to model parameters during training. Our system,\nSCAR, employs strategies which reduce the iteration cost upper bound due to\nperturbations incurred when recovering from checkpoints. We show that SCAR can\nreduce the iteration cost of partial failures by 78% - 95% when compared with\ntraditional checkpoint-based fault tolerance across a variety of ML models and\ntraining algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 02:19:35 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Qiao", "Aurick", ""], ["Aragam", "Bryon", ""], ["Zhang", "Bingjing", ""], ["Xing", "Eric P.", ""]]}, {"id": "1810.07362", "submitter": "Alon Gonen", "authors": "Naman Agarwal, Alon Gonen, Elad Hazan", "title": "Learning in Non-convex Games with an Optimization Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning in an adversarial, non-convex setting under the\nassumption that the learner has an access to an offline optimization oracle. In\nthe general setting of prediction with expert advice, Hazan et al. (2016)\nestablished that in the optimization-oracle model, online learning requires\nexponentially more computation than statistical learning. In this paper we show\nthat by slightly strengthening the oracle model, the online and the statistical\nlearning models become computationally equivalent. Our result holds for any\nLipschitz and bounded (but not necessarily convex) function. As an application\nwe demonstrate how the offline oracle enables efficient computation of an\nequilibrium in non-convex games, that include GAN (generative adversarial\nnetworks) as a special case.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 02:46:30 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 23:09:47 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 21:16:55 GMT"}, {"version": "v4", "created": "Fri, 21 Dec 2018 23:31:49 GMT"}, {"version": "v5", "created": "Fri, 1 Feb 2019 15:10:29 GMT"}, {"version": "v6", "created": "Wed, 13 Mar 2019 12:53:17 GMT"}, {"version": "v7", "created": "Wed, 29 May 2019 01:50:48 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Agarwal", "Naman", ""], ["Gonen", "Alon", ""], ["Hazan", "Elad", ""]]}, {"id": "1810.07368", "submitter": "Hanze Dong", "authors": "Hanze Dong, Yanwei Fu, Leonid Sigal, Sung Ju Hwang, Yu-Gang Jiang,\n  Xiangyang Xue", "title": "Learning to Separate Domains in Generalized Zero-Shot and Open Set\n  Learning: a probabilistic perspective", "comments": "10 pages, 5 figures, submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of domain division which aims to segment\ninstances drawn from different probabilistic distributions. Such a problem\nexists in many previous recognition tasks, such as Open Set Learning (OSL) and\nGeneralized Zero-Shot Learning (G-ZSL), where the testing instances come from\neither seen or novel/unseen classes of different probabilistic distributions.\nPrevious works focused on either only calibrating the confident prediction of\nclassifiers of seen classes (W-SVM), or taking unseen classes as outliers. In\ncontrast, this paper proposes a probabilistic way of directly estimating and\nfine-tuning the decision boundary between seen and novel/unseen classes. In\nparticular, we propose a domain division algorithm of learning to split the\ntesting instances into known, unknown and uncertain domains, and then conduct\nrecognize tasks in each domain. Two statistical tools, namely, bootstrapping\nand Kolmogorov-Smirnov (K-S) Test, for the first time, are introduced to\ndiscover and fine-tune the decision boundary of each domain. Critically, the\nuncertain domain is newly introduced in our framework to adopt those instances\nwhose domain cannot be predicted confidently. Extensive experiments demonstrate\nthat our approach achieved the state-of-the-art performance on OSL and G-ZSL\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:11:20 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 05:50:07 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Dong", "Hanze", ""], ["Fu", "Yanwei", ""], ["Sigal", "Leonid", ""], ["Hwang", "Sung Ju", ""], ["Jiang", "Yu-Gang", ""], ["Xue", "Xiangyang", ""]]}, {"id": "1810.07371", "submitter": "Aniket Anand Deshmukh", "authors": "Aniket Anand Deshmukh, Srinagesh Sharma, James W. Cutler, Mark Moldwin\n  and Clayton Scott", "title": "Simple Regret Minimization for Contextual Bandits", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two variants of the classical multi-armed bandit (MAB) problem that\nhave received considerable attention from machine learning researchers in\nrecent years: contextual bandits and simple regret minimization. Contextual\nbandits are a sub-class of MABs where, at every time step, the learner has\naccess to side information that is predictive of the best arm. Simple regret\nminimization assumes that the learner only incurs regret after a pure\nexploration phase. In this work, we study simple regret minimization for\ncontextual bandits. Motivated by applications where the learner has separate\ntraining and autonomous modes, we assume that the learner experiences a pure\nexploration phase, where feedback is received after every action but no regret\nis incurred, followed by a pure exploitation phase in which regret is incurred\nbut there is no feedback. We present the Contextual-Gap algorithm and establish\nperformance guarantees on the simple regret, i.e., the regret during the pure\nexploitation phase. Our experiments examine a novel application to adaptive\nsensor selection for magnetic field estimation in interplanetary spacecraft,\nand demonstrate considerable improvement over algorithms designed to minimize\nthe cumulative regret.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:17:26 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 20:13:42 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Deshmukh", "Aniket Anand", ""], ["Sharma", "Srinagesh", ""], ["Cutler", "James W.", ""], ["Moldwin", "Mark", ""], ["Scott", "Clayton", ""]]}, {"id": "1810.07377", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Zhenghang Zhong, Zhe Tang, Xiangxing Li, Tiancheng Yuan, Yang Yang,\n  Meng Wei, Yuanyuan Zhang, Renzhi Sheng, Naomi Grant, Chongfeng Ling, Xintao\n  Huan, Kyeong Soo Kim and Sanghyuk Lee", "title": "XJTLUIndoorLoc: A New Fingerprinting Database for Indoor Localization\n  and Trajectory Estimation Based on Wi-Fi RSS and Geomagnetic Field", "comments": "7 pages, 16 figures, 3rd International Workshop on GPU Computing and\n  AI (GCA'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new location fingerprinting database comprised of\nWi-Fi received signal strength (RSS) and geomagnetic field intensity measured\nwith multiple devices at a multi-floor building in Xi'an Jiatong-Liverpool\nUniversity, Suzhou, China. We also provide preliminary results of localization\nand trajectory estimation based on convolutional neural network (CNN) and long\nshort-term memory (LSTM) network with this database. For localization, we map\nRSS data for a reference point to an image-like, two-dimensional array and then\napply CNN which is popular in image and video analysis and recognition. For\ntrajectory estimation, we use a modified random way point model to efficiently\ngenerate continuous step traces imitating human walking and train a stacked\ntwo-layer LSTM network with the generated data to remember the changing pattern\nof geomagnetic field intensity against (x,y) coordinates. Experimental results\ndemonstrate the usefulness of our new database and the feasibility of the CNN\nand LSTM-based localization and trajectory estimation with the database.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:47:29 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Zhong", "Zhenghang", ""], ["Tang", "Zhe", ""], ["Li", "Xiangxing", ""], ["Yuan", "Tiancheng", ""], ["Yang", "Yang", ""], ["Wei", "Meng", ""], ["Zhang", "Yuanyuan", ""], ["Sheng", "Renzhi", ""], ["Grant", "Naomi", ""], ["Ling", "Chongfeng", ""], ["Huan", "Xintao", ""], ["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""]]}, {"id": "1810.07378", "submitter": "Tianyun Zhang", "authors": "Shaokai Ye, Tianyun Zhang, Kaiqi Zhang, Jiayu Li, Kaidi Xu, Yunfei\n  Yang, Fuxun Yu, Jian Tang, Makan Fardad, Sijia Liu, Xiang Chen, Xue Lin,\n  Yanzhi Wang", "title": "Progressive Weight Pruning of Deep Neural Networks using ADMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) although achieving human-level performance in\nmany domains, have very large model size that hinders their broader\napplications on edge computing devices. Extensive research work have been\nconducted on DNN model compression or pruning. However, most of the previous\nwork took heuristic approaches. This work proposes a progressive weight pruning\napproach based on ADMM (Alternating Direction Method of Multipliers), a\npowerful technique to deal with non-convex optimization problems with\npotentially combinatorial constraints. Motivated by dynamic programming, the\nproposed method reaches extremely high pruning rate by using partial prunings\nwith moderate pruning rates. Therefore, it resolves the accuracy degradation\nand long convergence time problems when pursuing extremely high pruning ratios.\nIt achieves up to 34 times pruning rate for ImageNet dataset and 167 times\npruning rate for MNIST dataset, significantly higher than those reached by the\nliterature work. Under the same number of epochs, the proposed method also\nachieves faster convergence and higher compression rates. The codes and pruned\nDNN models are released in the link bit.ly/2zxdlss\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:51:38 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 16:41:06 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Ye", "Shaokai", ""], ["Zhang", "Tianyun", ""], ["Zhang", "Kaiqi", ""], ["Li", "Jiayu", ""], ["Xu", "Kaidi", ""], ["Yang", "Yunfei", ""], ["Yu", "Fuxun", ""], ["Tang", "Jian", ""], ["Fardad", "Makan", ""], ["Liu", "Sijia", ""], ["Chen", "Xiang", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1810.07382", "submitter": "Kamran Kowsari", "authors": "Mojtaba Heidarysafa, Kamran Kowsari, Laura E. Barnes and Donald E.\n  Brown", "title": "Analysis of Railway Accidents' Narratives Using Deep Learning", "comments": "accepted in IEEE International Conference on Machine Learning and\n  Applications (IEEE ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00235", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic understanding of domain specific texts in order to extract useful\nrelationships for later use is a non-trivial task. One such relationship would\nbe between railroad accidents' causes and their correspondent descriptions in\nreports. From 2001 to 2016 rail accidents in the U.S. cost more than $4.6B.\nRailroads involved in accidents are required to submit an accident report to\nthe Federal Railroad Administration (FRA). These reports contain a variety of\nfixed field entries including primary cause of the accidents (a coded variable\nwith 389 values) as well as a narrative field which is a short text description\nof the accident. Although these narratives provide more information than a\nfixed field entry, the terminologies used in these reports are not easy to\nunderstand by a non-expert reader. Therefore, providing an assisting method to\nfill in the primary cause from such domain specific texts(narratives) would\nhelp to label the accidents with more accuracy. Another important question for\ntransportation safety is whether the reported accident cause is consistent with\nnarrative description. To address these questions, we applied deep learning\nmethods together with powerful word embeddings such as Word2Vec and GloVe to\nclassify accident cause values for the primary cause field using the text in\nthe narratives. The results show that such approaches can both accurately\nclassify accident causes based on report narratives and find important\ninconsistencies in accident reporting.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 04:30:02 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 22:08:21 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 16:16:48 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Heidarysafa", "Mojtaba", ""], ["Kowsari", "Kamran", ""], ["Barnes", "Laura E.", ""], ["Brown", "Donald E.", ""]]}, {"id": "1810.07406", "submitter": "Michal Ozery-Flato", "authors": "Michal Ozery-Flato, Pierre Thodoroff, Matan Ninio, Michal Rosen-Zvi,\n  Tal El-Hay", "title": "Adversarial Balancing for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biases in observational data of treatments pose a major challenge to\nestimating expected treatment outcomes in different populations. An important\ntechnique that accounts for these biases is reweighting samples to minimize the\ndiscrepancy between treatment groups. We present a novel reweighting approach\nthat uses bi-level optimization to alternately train a discriminator to\nminimize classification error, and a balancing weights generator that uses\nexponentiated gradient descent to maximize this error. This approach borrows\nprinciples from generative adversarial networks (GANs) to exploit the power of\nclassifiers for measuring two-sample divergence. We provide theoretical results\nfor conditions in which the estimation error is bounded by two factors: (i) the\ndiscrepancy measure induced by the discriminator; and (ii) the weights\nvariability. Experimental results on several benchmarks comparing to previous\nstate-of-the-art reweighting methods demonstrate the effectiveness of this\napproach in estimating causal effects.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 07:16:20 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 13:33:27 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 15:51:32 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Ozery-Flato", "Michal", ""], ["Thodoroff", "Pierre", ""], ["Ninio", "Matan", ""], ["Rosen-Zvi", "Michal", ""], ["El-Hay", "Tal", ""]]}, {"id": "1810.07430", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw, Marco Loog, Wilbert Bartels, Adri\\\"enne M. Mendrik", "title": "Learning an MR acquisition-invariant representation using Siamese neural\n  networks", "comments": "3 figures, submitted to International Symposium on Biomedical Imaging\n  2019", "journal-ref": "16th IEEE International Symposium on Biomedical Imaging (ISBI),\n  Venice, 2019, pp. 364-367", "doi": "10.1109/ISBI.2019.8759281", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization of voxelwise classifiers is hampered by differences between\nMRI-scanners, e.g. different acquisition protocols and field strengths. To\naddress this limitation, we propose a Siamese neural network (MRAI-NET) that\nextracts acquisition-invariant feature vectors. These can consequently be used\nby task-specific methods, such as voxelwise classifiers for tissue\nsegmentation. MRAI-NET is tested on both simulated and real patient data.\nExperiments show that MRAI-NET outperforms voxelwise classifiers trained on the\nsource or target scanner data when a small number of labeled samples is\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 08:37:09 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kouw", "Wouter M.", ""], ["Loog", "Marco", ""], ["Bartels", "Wilbert", ""], ["Mendrik", "Adri\u00ebnne M.", ""]]}, {"id": "1810.07435", "submitter": "Antoni Chan", "authors": "Antoni B. Chan and Janet H. Hsiao", "title": "EMHMM Simulation Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye Movement analysis with Hidden Markov Models (EMHMM) is a method for\nmodeling eye fixation sequences using hidden Markov models (HMMs). In this\nreport, we run a simulation study to investigate the estimation error for\nlearning HMMs with variational Bayesian inference, with respect to the number\nof sequences and the sequence lengths. We also relate the estimation error\nmeasured by KL divergence and L1-norm to a corresponding distortion in the\nground-truth HMM parameters.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 08:53:40 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 02:33:50 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Chan", "Antoni B.", ""], ["Hsiao", "Janet H.", ""]]}, {"id": "1810.07450", "submitter": "Arnaud Mignan", "authors": "Arnaud Mignan", "title": "Generalized Earthquake Frequency-Magnitude Distribution Described by\n  Asymmetric Laplace Mixture Modelling", "comments": "30 pages, 9 figures, 1 table", "journal-ref": "Geophysical Journal International, 2019", "doi": "10.1093/gji/ggz373", "report-no": null, "categories": "physics.geo-ph stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complete part of the earthquake frequency-magnitude distribution (FMD),\nabove completeness magnitude mc, is well described by the Gutenberg-Richter\nlaw. The parameter mc however varies in space due to the seismic network\nconfiguration, yielding a convoluted FMD shape below max(mc). This paper\ninvestigates the shape of the generalized FMD (GFMD), which may be described as\na mixture of elemental FMDs (eFMDs) defined as asymmetric Laplace distributions\nof mode mc [Mignan, 2012, https://doi.org/10.1029/2012JB009347]. An asymmetric\nLaplace mixture model (GFMD- ALMM) is thus proposed with its parameters\n(detection parameter kappa, Gutenberg-Richter beta-value, mc distribution, as\nwell as number K and weight w of eFMD components) estimated using a\nsemi-supervised hard expectation maximization approach including BIC penalties\nfor model complexity. The performance of the proposed method is analysed, with\nencouraging results obtained: kappa, beta, and the mc distribution range are\nretrieved for different GFMD shapes in simulations, as well as in regional\ncatalogues (southern and northern California, Nevada, Taiwan, France), in a\nglobal catalogue, and in an aftershock sequence (Christchurch, New Zealand). We\nfind max(mc) to be conservative compared to other methods, kappa = k/log(10) =\n3 in most catalogues (compared to beta = b/log(10) = 1), but also that biases\nin kappa and beta may occur when rounding errors are present below\ncompleteness. The GFMD-ALMM, by modelling different FMD shapes in an autonomous\nmanner, opens the door to new statistical analyses in the realm of incomplete\nseismicity data, which could in theory improve earthquake forecasting by\nconsidering c. ten times more events.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 09:31:59 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Mignan", "Arnaud", ""]]}, {"id": "1810.07451", "submitter": "Georg Muntingh PhD", "authors": "Andrea Raffo, Oliver J.D. Barrowclough, Georg Muntingh", "title": "Reverse engineering of CAD models via clustering and approximate\n  implicitization", "comments": null, "journal-ref": null, "doi": "10.1016/j.cagd.2020.101876", "report-no": null, "categories": "math.NA cs.GR cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications like computer aided design, geometric models are often\nrepresented numerically as polynomial splines or NURBS, even when they\noriginate from primitive geometry. For purposes such as redesign and\nisogeometric analysis, it is of interest to extract information about the\nunderlying geometry through reverse engineering. In this work we develop a\nnovel method to determine these primitive shapes by combining clustering\nanalysis with approximate implicitization. The proposed method is automatic and\ncan recover algebraic hypersurfaces of any degree in any dimension. In exact\narithmetic, the algorithm returns exact results. All the required parameters,\nsuch as the implicit degree of the patches and the number of clusters of the\nmodel, are inferred using numerical approaches in order to obtain an algorithm\nthat requires as little manual input as possible. The effectiveness, efficiency\nand robustness of the method are shown both in a theoretical analysis and in\nnumerical examples implemented in Python.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 09:32:50 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 10:06:41 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 17:56:05 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Raffo", "Andrea", ""], ["Barrowclough", "Oliver J. D.", ""], ["Muntingh", "Georg", ""]]}, {"id": "1810.07468", "submitter": "Matteo Ruffini MR", "authors": "Matteo Ruffini, Guillaume Rabusseau, Borja Balle", "title": "Hierarchical Methods of Moments", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods of moments provide a powerful tool for learning the\nparameters of latent variable models. Despite their theoretical appeal, the\napplicability of these methods to real data is still limited due to a lack of\nrobustness to model misspecification. In this paper we present a hierarchical\napproach to methods of moments to circumvent such limitations. Our method is\nbased on replacing the tensor decomposition step used in previous algorithms\nwith approximate joint diagonalization. Experiments on topic modeling show that\nour method outperforms previous tensor decomposition methods in terms of speed\nand model quality.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 10:44:23 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Ruffini", "Matteo", ""], ["Rabusseau", "Guillaume", ""], ["Balle", "Borja", ""]]}, {"id": "1810.07481", "submitter": "Francesco Croce", "authors": "Francesco Croce (University of T\\\"ubingen), Maksym Andriushchenko\n  (Saarland University), Matthias Hein (University of T\\\"ubingen)", "title": "Provable Robustness of ReLU networks via Maximization of Linear Regions", "comments": "In AISTATS 2019. Conference version with the following modifications:\n  improved readability, comparison to Xiao et al (2018) added, section on\n  visualizations extended", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that neural network classifiers are not robust. This raises\nconcerns about their usage in safety-critical systems. We propose in this paper\na regularization scheme for ReLU networks which provably improves the\nrobustness of the classifier by maximizing the linear regions of the classifier\nas well as the distance to the decision boundary. Our techniques allow even to\nfind the minimal adversarial perturbation for a fraction of test points for\nlarge networks. In the experiments we show that our approach improves upon\nadversarial training both in terms of lower and upper bounds on the robustness\nand is comparable or better than the state-of-the-art in terms of test error\nand robustness.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 11:25:08 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 18:18:24 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Croce", "Francesco", "", "University of T\u00fcbingen"], ["Andriushchenko", "Maksym", "", "Saarland University"], ["Hein", "Matthias", "", "University of T\u00fcbingen"]]}, {"id": "1810.07513", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Christoph Gebendorfer, Ingo Glaser and Florian Matthes", "title": "Multi-Task Deep Learning for Legal Document Translation, Summarization\n  and Multi-Label Classification", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitalization of the legal domain has been ongoing for a couple of\nyears. In that process, the application of different machine learning (ML)\ntechniques is crucial. Tasks such as the classification of legal documents or\ncontract clauses as well as the translation of those are highly relevant. On\nthe other side, digitized documents are barely accessible in this field,\nparticularly in Germany. Today, deep learning (DL) is one of the hot topics\nwith many publications and various applications. Sometimes it provides results\noutperforming the human level. Hence this technique may be feasible for the\nlegal domain as well. However, DL requires thousands of samples to provide\ndecent results. A potential solution to this problem is multi-task DL to enable\ntransfer learning. This approach may be able to overcome the data scarcity\nproblem in the legal domain, specifically for the German language. We applied\nthe state of the art multi-task model on three tasks: translation,\nsummarization, and multi-label classification. The experiments were conducted\non legal document corpora utilizing several task combinations as well as\nvarious model parameters. The goal was to find the optimal configuration for\nthe tasks at hand within the legal domain. The multi-task DL approach\noutperformed the state of the art results in all three tasks. This opens a new\ndirection to integrate DL technology more efficiently in the legal domain.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 08:54:50 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Gebendorfer", "Christoph", ""], ["Glaser", "Ingo", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.07548", "submitter": "Chuang Ye", "authors": "Chuang Ye, M. Cenk Gursoy, and Senem Velipasalar", "title": "Deep Learning Based Power Control for Quality-Driven Wireless Video\n  Transmissions", "comments": "arXiv admin note: text overlap with arXiv:1707.08232", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.IV math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, wireless video transmission to multiple users under total\ntransmission power and minimum required video quality constraints is studied.\nIn order to provide the desired performance levels to the end-users in\nreal-time video transmissions while using the energy resources efficiently, we\nassume that power control is employed. Due to the presence of interference,\ndetermining the optimal power control is a non-convex problem but can be solved\nvia monotonic optimization framework. However, monotonic optimization is an\niterative algorithm and can often entail considerable computational complexity,\nmaking it not suitable for real-time applications. To address this, we propose\na learning-based approach that treats the input and output of a resource\nallocation algorithm as an unknown nonlinear mapping and a deep neural network\n(DNN) is employed to learn this mapping. This learned mapping via DNN can\nprovide the optimal power level quickly for given channel conditions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 05:14:05 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Ye", "Chuang", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1810.07559", "submitter": "Rodrigo de Lamare", "authors": "Y. Yu, H. Zhao and R. C. de Lamare", "title": "Study of Sparsity-Aware Subband Adaptive Filtering Algorithms with\n  Adjustable Penalties", "comments": "32 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two sparsity-aware normalized subband adaptive filter (NSAF)\nalgorithms by using the gradient descent method to minimize a combination of\nthe original NSAF cost function and the l1-norm penalty function on the filter\ncoefficients. This l1-norm penalty exploits the sparsity of a system in the\ncoefficients update formulation, thus improving the performance when\nidentifying sparse systems. Compared with prior work, the proposed algorithms\nhave lower computational complexity with comparable performance. We study and\ndevise statistical models for these sparsity-aware NSAF algorithms in the mean\nsquare sense involving their transient and steady -state behaviors. This study\nrelies on the vectorization argument and the paraunitary assumption imposed on\nthe analysis filter banks, and thus does not restrict the input signal to being\nGaussian or having another distribution. In addition, we propose to adjust\nadaptively the intensity parameter of the sparsity attraction term. Finally,\nsimulation results in sparse system identification demonstrate the\neffectiveness of our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 15:27:11 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Yu", "Y.", ""], ["Zhao", "H.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1810.07570", "submitter": "Christian Grussler", "authors": "Christian Grussler and Pontus Giselsson", "title": "Efficient Proximal Mapping Computation for Unitarily Invariant Low-Rank\n  Inducing Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank inducing unitarily invariant norms have been introduced to convexify\nproblems with low-rank/sparsity constraint. They are the convex envelope of a\nunitary invariant norm and the indicator function of an upper bounding rank\nconstraint. The most well-known member of this family is the so-called nuclear\nnorm. To solve optimization problems involving such norms with proximal\nsplitting methods, efficient ways of evaluating the proximal mapping of the\nlow-rank inducing norms are needed. This is known for the nuclear norm, but not\nfor most other members of the low-rank inducing family. This work supplies a\nframework that reduces the proximal mapping evaluation into a nested binary\nsearch, in which each iteration requires the solution of a much simpler\nproblem. This simpler problem can often be solved analytically as it is\ndemonstrated for the so-called low-rank inducing Frobenius and spectral norms.\nMoreover, the framework allows to compute the proximal mapping of compositions\nof these norms with increasing convex functions and the projections onto their\nepigraphs. This has the additional advantage that we can also deal with\ncompositions of increasing convex functions and low-rank inducing norms in\nproximal splitting methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 14:21:44 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Grussler", "Christian", ""], ["Giselsson", "Pontus", ""]]}, {"id": "1810.07652", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi, Roberto Dess\\`i, Roldano Cattoni, Matteo\n  Negri, Marco Turchi", "title": "Fine-tuning on Clean Data for End-to-End Speech Translation: FBK @ IWSLT\n  2018", "comments": "6 pages, 2 figures, system description at the 15th International\n  Workshop on Spoken Language Translation (IWSLT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes FBK's submission to the end-to-end English-German speech\ntranslation task at IWSLT 2018. Our system relies on a state-of-the-art model\nbased on LSTMs and CNNs, where the CNNs are used to reduce the temporal\ndimension of the audio input, which is in general much higher than machine\ntranslation input. Our model was trained only on the audio-to-text parallel\ndata released for the task, and fine-tuned on cleaned subsets of the original\ntraining corpus. The addition of weight normalization and label smoothing\nimproved the baseline system by 1.0 BLEU point on our validation set. The final\nsubmission also featured checkpoint averaging within a training run and\nensemble decoding of models trained during multiple runs. On test data, our\nbest single model obtained a BLEU score of 9.7, while the ensemble obtained a\nBLEU score of 10.24.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:54:37 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Dess\u00ec", "Roberto", ""], ["Cattoni", "Roldano", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "1810.07716", "submitter": "Dhagash Mehta", "authors": "Dhagash Mehta, Tianran Chen, Tingting Tang, Jonathan D. Hauenstein", "title": "The loss surface of deep linear networks viewed through the algebraic\n  geometry lens", "comments": "16 pages (2-columns), 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using the viewpoint of modern computational algebraic geometry, we explore\nproperties of the optimization landscapes of the deep linear neural network\nmodels. After clarifying on the various definitions of \"flat\" minima, we show\nthat the geometrically flat minima, which are merely artifacts of residual\ncontinuous symmetries of the deep linear networks, can be straightforwardly\nremoved by a generalized $L_2$ regularization. Then, we establish upper bounds\non the number of isolated stationary points of these networks with the help of\nalgebraic geometry. Using these upper bounds and utilizing a numerical\nalgebraic geometry method, we find all stationary points of modest depth and\nmatrix size. We show that in the presence of the non-zero regularization, deep\nlinear networks indeed possess local minima which are not the global minima.\nOur computational results clarify certain aspects of the loss surfaces of deep\nlinear networks and provide novel insights.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 18:07:44 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Mehta", "Dhagash", ""], ["Chen", "Tianran", ""], ["Tang", "Tingting", ""], ["Hauenstein", "Jonathan D.", ""]]}, {"id": "1810.07725", "submitter": "Rosana Veroneze", "authors": "Rosana Veroneze and Fernando J. Von Zuben", "title": "RIn-Close_CVC2: an even more efficient enumerative algorithm for\n  biclustering of numerical datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RIn-Close_CVC is an efficient (take polynomial time per bicluster), complete\n(find all maximal biclusters), correct (all biclusters attend the user-defined\nlevel of consistency) and non-redundant (all the obtained biclusters are\nmaximal and the same bicluster is not enumerated more than once) enumerative\nalgorithm for mining maximal biclusters with constant values on columns in\nnumerical datasets. Despite RIn-Close_CVC has all these outstanding properties,\nit has a high computational cost in terms of memory usage because it must keep\na symbol table in memory to prevent a maximal bicluster to be found more than\nonce. In this paper, we propose a new version of RIn-Close_CVC, named\nRIn-Close_CVC2, that does not use a symbol table to prevent redundant\nbiclusters, and keeps all these four properties. We also prove that these\nalgorithms actually possess these properties. Experiments are carried out with\nsynthetic and real-world datasets to compare RIn-Close_CVC and RIn-Close_CVC2\nin terms of memory usage and runtime. The experimental results show that\nRIn-Close_CVC2 brings a large reduction in memory usage and, in average,\nsignificant runtime gain when compared to its predecessor.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 18:19:39 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Veroneze", "Rosana", ""], ["Von Zuben", "Fernando J.", ""]]}, {"id": "1810.07742", "submitter": "Jianguo Chen", "authors": "Jianguo Chen, Kenli Li, Kashif Bilal, Xu Zhou, Keqin Li, and Philip S.\n  Yu", "title": "A Bi-layered Parallel Training Architecture for Large-scale\n  Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Transactions on Parallel and Distributed Systems,2019, 30(5):\n  965-976", "doi": "10.1109/TPDS.2018.2877359", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefitting from large-scale training datasets and the complex training\nnetwork, Convolutional Neural Networks (CNNs) are widely applied in various\nfields with high accuracy. However, the training process of CNNs is very\ntime-consuming, where large amounts of training samples and iterative\noperations are required to obtain high-quality weight parameters. In this\npaper, we focus on the time-consuming training process of large-scale CNNs and\npropose a Bi-layered Parallel Training (BPT-CNN) architecture in distributed\ncomputing environments. BPT-CNN consists of two main components: (a) an\nouter-layer parallel training for multiple CNN subnetworks on separate data\nsubsets, and (b) an inner-layer parallel training for each subnetwork. In the\nouter-layer parallelism, we address critical issues of distributed and parallel\ncomputing, including data communication, synchronization, and workload balance.\nA heterogeneous-aware Incremental Data Partitioning and Allocation (IDPA)\nstrategy is proposed, where large-scale training datasets are partitioned and\nallocated to the computing nodes in batches according to their computing power.\nTo minimize the synchronization waiting during the global weight update\nprocess, an Asynchronous Global Weight Update (AGWU) strategy is proposed. In\nthe inner-layer parallelism, we further accelerate the training process for\neach CNN subnetwork on each computer, where computation steps of convolutional\nlayer and the local weight training are parallelized based on task-parallelism.\nWe introduce task decomposition and scheduling strategies with the objectives\nof thread-level load balancing and minimum waiting time for critical paths.\nExtensive experimental results indicate that the proposed BPT-CNN effectively\nimproves the training performance of CNNs while maintaining the accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 19:18:10 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Bilal", "Kashif", ""], ["Zhou", "Xu", ""], ["Li", "Keqin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1810.07743", "submitter": "Kahini Wadhawan", "authors": "Payel Das, Kahini Wadhawan, Oscar Chang, Tom Sercu, Cicero Dos Santos,\n  Matthew Riemer, Vijil Chenthamarakshan, Inkit Padhi, Aleksandra Mojsilovic", "title": "PepCVAE: Semi-Supervised Targeted Design of Antimicrobial Peptide\n  Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the emerging global threat of antimicrobial resistance, new methods for\nnext-generation antimicrobial design are urgently needed. We report a peptide\ngeneration framework PepCVAE, based on a semi-supervised variational\nautoencoder (VAE) model, for designing novel antimicrobial peptide (AMP)\nsequences. Our model learns a rich latent space of the biological peptide\ncontext by taking advantage of abundant, unlabeled peptide sequences. The model\nfurther learns a disentangled antimicrobial attribute space by using the\nfeedback from a jointly trained AMP classifier that uses limited labeled\ninstances. The disentangled representation allows for controllable generation\nof AMPs. Extensive analysis of the PepCVAE-generated sequences reveals superior\nperformance of our model in comparison to a plain VAE, as PepCVAE generates\nnovel AMP sequences with higher long-range diversity, while being closer to the\ntraining distribution of biological peptides. These features are highly desired\nin next-generation antimicrobial design.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 19:19:36 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 18:50:04 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 16:24:09 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Das", "Payel", ""], ["Wadhawan", "Kahini", ""], ["Chang", "Oscar", ""], ["Sercu", "Tom", ""], ["Santos", "Cicero Dos", ""], ["Riemer", "Matthew", ""], ["Chenthamarakshan", "Vijil", ""], ["Padhi", "Inkit", ""], ["Mojsilovic", "Aleksandra", ""]]}, {"id": "1810.07758", "submitter": "Hoang Anh Dau", "authors": "Hoang Anh Dau, Anthony Bagnall, Kaveh Kamgar, Chin-Chia Michael Yeh,\n  Yan Zhu, Shaghayegh Gharghabi, Chotirat Ann Ratanamahatana, Eamonn Keogh", "title": "The UCR Time Series Archive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The UCR Time Series Archive - introduced in 2002, has become an important\nresource in the time series data mining community, with at least one thousand\npublished papers making use of at least one data set from the archive. The\noriginal incarnation of the archive had sixteen data sets but since that time,\nit has gone through periodic expansions. The last expansion took place in the\nsummer of 2015 when the archive grew from 45 to 85 data sets. This paper\nintroduces and will focus on the new data expansion from 85 to 128 data sets.\nBeyond expanding this valuable resource, this paper offers pragmatic advice to\nanyone who may wish to evaluate a new algorithm on the archive. Finally, this\npaper makes a novel and yet actionable claim: of the hundreds of papers that\nshow an improvement over the standard baseline (1-nearest neighbor\nclassification), a large fraction may be mis-attributing the reasons for their\nimprovement. Moreover, they may have been able to achieve the same improvement\nwith a much simpler modification, requiring just a single line of code.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:00:40 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 01:48:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Dau", "Hoang Anh", ""], ["Bagnall", "Anthony", ""], ["Kamgar", "Kaveh", ""], ["Yeh", "Chin-Chia Michael", ""], ["Zhu", "Yan", ""], ["Gharghabi", "Shaghayegh", ""], ["Ratanamahatana", "Chotirat Ann", ""], ["Keogh", "Eamonn", ""]]}, {"id": "1810.07762", "submitter": "Jianguo Chen", "authors": "Jianguo Chen, Kenli Li, Huigui Rong, Kashif Bilal, Nan Yang, Keqin Li", "title": "A Disease Diagnosis and Treatment Recommendation System Based on Big\n  Data Mining and Cloud Computing", "comments": null, "journal-ref": "Information Sciences, 2018, 435:124-149", "doi": "10.1016/j.ins.2018.01.001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is crucial to provide compatible treatment schemes for a disease according\nto various symptoms at different stages. However, most classification methods\nmight be ineffective in accurately classifying a disease that holds the\ncharacteristics of multiple treatment stages, various symptoms, and\nmulti-pathogenesis. Moreover, there are limited exchanges and cooperative\nactions in disease diagnoses and treatments between different departments and\nhospitals. Thus, when new diseases occur with atypical symptoms, inexperienced\ndoctors might have difficulty in identifying them promptly and accurately.\nTherefore, to maximize the utilization of the advanced medical technology of\ndeveloped hospitals and the rich medical knowledge of experienced doctors, a\nDisease Diagnosis and Treatment Recommendation System (DDTRS) is proposed in\nthis paper. First, to effectively identify disease symptoms more accurately, a\nDensity-Peaked Clustering Analysis (DPCA) algorithm is introduced for\ndisease-symptom clustering. In addition, association analyses on\nDisease-Diagnosis (D-D) rules and Disease-Treatment (D-T) rules are conducted\nby the Apriori algorithm separately. The appropriate diagnosis and treatment\nschemes are recommended for patients and inexperienced doctors, even if they\nare in a limited therapeutic environment. Moreover, to reach the goals of high\nperformance and low latency response, we implement a parallel solution for\nDDTRS using the Apache Spark cloud platform. Extensive experimental results\ndemonstrate that the proposed DDTRS realizes disease-symptom clustering\neffectively and derives disease treatment recommendations intelligently and\naccurately.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:07:08 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Rong", "Huigui", ""], ["Bilal", "Kashif", ""], ["Yang", "Nan", ""], ["Li", "Keqin", ""]]}, {"id": "1810.07770", "submitter": "Chulhee Yun", "authors": "Chulhee Yun, Suvrit Sra, Ali Jadbabaie", "title": "Small ReLU networks are powerful memorizers: a tight analysis of\n  memorization capacity", "comments": "28 pages, 2 figures. NeurIPS 2019 Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study finite sample expressivity, i.e., memorization power of ReLU\nnetworks. Recent results require $N$ hidden nodes to memorize/interpolate\narbitrary $N$ data points. In contrast, by exploiting depth, we show that\n3-layer ReLU networks with $\\Omega(\\sqrt{N})$ hidden nodes can perfectly\nmemorize most datasets with $N$ points. We also prove that width\n$\\Theta(\\sqrt{N})$ is necessary and sufficient for memorizing $N$ data points,\nproving tight bounds on memorization capacity. The sufficiency result can be\nextended to deeper networks; we show that an $L$-layer network with $W$\nparameters in the hidden layers can memorize $N$ data points if $W =\n\\Omega(N)$. Combined with a recent upper bound $O(WL\\log W)$ on VC dimension,\nour construction is nearly tight for any fixed $L$. Subsequently, we analyze\nmemorization capacity of residual networks under a general position assumption;\nwe prove results that substantially reduce the known requirement of $N$ hidden\nnodes. Finally, we study the dynamics of stochastic gradient descent (SGD), and\nshow that when initialized near a memorizing global minimum of the empirical\nrisk, SGD quickly finds a nearby point with much smaller empirical risk.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:21:43 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 00:35:32 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 05:22:58 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Yun", "Chulhee", ""], ["Sra", "Suvrit", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1810.07776", "submitter": "Jianguo Chen", "authors": "Jianguo Chen, Kenli Li, Huigui Rong, Kashif Bilal, Keqin Li, Philip S.\n  Yu", "title": "A Periodicity-based Parallel Time Series Prediction Algorithm in Cloud\n  Computing Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, practical applications in various domains continually\ngenerate large-scale time-series data. Among them, some data show significant\nor potential periodicity characteristics, such as meteorological and financial\ndata. It is critical to efficiently identify the potential periodic patterns\nfrom massive time-series data and provide accurate predictions. In this paper,\na Periodicity-based Parallel Time Series Prediction (PPTSP) algorithm for\nlarge-scale time-series data is proposed and implemented in the Apache Spark\ncloud computing environment. To effectively handle the massive historical\ndatasets, a Time Series Data Compression and Abstraction (TSDCA) algorithm is\npresented, which can reduce the data scale as well as accurately extracting the\ncharacteristics. Based on this, we propose a Multi-layer Time Series Periodic\nPattern Recognition (MTSPPR) algorithm using the Fourier Spectrum Analysis\n(FSA) method. In addition, a Periodicity-based Time Series Prediction (PTSP)\nalgorithm is proposed. Data in the subsequent period are predicted based on all\nprevious period models, in which a time attenuation factor is introduced to\ncontrol the impact of different periods on the prediction results. Moreover, to\nimprove the performance of the proposed algorithms, we propose a parallel\nsolution on the Apache Spark platform, using the Streaming real-time computing\nmodule. To efficiently process the large-scale time-series datasets in\ndistributed computing environments, Distributed Streams (DStreams) and\nResilient Distributed Datasets (RDDs) are used to store and calculate these\ndatasets. Extensive experimental results show that our PPTSP algorithm has\nsignificant advantages compared with other algorithms in terms of prediction\naccuracy and performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:26:49 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Chen", "Jianguo", ""], ["Li", "Kenli", ""], ["Rong", "Huigui", ""], ["Bilal", "Kashif", ""], ["Li", "Keqin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1810.07778", "submitter": "Kunkun Pang", "authors": "Kunkun Pang, Mingzhi Dong, Yang Wu, Timothy M. Hospedales", "title": "Dynamic Ensemble Active Learning: A Non-Stationary Bandit with Expert\n  Advice", "comments": "This work has been accepted at ICPR2018 and won Piero Zamperoni Best\n  Student Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to reduce annotation cost by predicting which samples\nare useful for a human teacher to label. However it has become clear there is\nno best active learning algorithm. Inspired by various philosophies about what\nconstitutes a good criteria, different algorithms perform well on different\ndatasets. This has motivated research into ensembles of active learners that\nlearn what constitutes a good criteria in a given scenario, typically via\nmulti-armed bandit algorithms. Though algorithm ensembles can lead to better\nresults, they overlook the fact that not only does algorithm efficacy vary\nacross datasets, but also during a single active learning session. That is, the\nbest criteria is non-stationary. This breaks existing algorithms' guarantees\nand hampers their performance in practice. In this paper, we propose dynamic\nensemble active learning as a more general and promising research direction. We\ndevelop a dynamic ensemble active learner based on a non-stationary multi-armed\nbandit with expert advice algorithm. Our dynamic ensemble selects the right\ncriteria at each step of active learning. It has theoretical guarantees, and\nshows encouraging results on $13$ popular datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 14:29:02 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Pang", "Kunkun", ""], ["Dong", "Mingzhi", ""], ["Wu", "Yang", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1810.07785", "submitter": "Michael Chertkov", "authors": "Ryan King (NREL), Oliver Hennigh, Arvind Mohan and Michael Chertkov\n  (LANL)", "title": "From Deep to Physics-Informed Learning of Turbulence: Diagnostics", "comments": "8 pages, 3 figures", "journal-ref": "Workshop on Modeling and Decision-Making in the Spatiotemporal\n  Domain, NIPS 2018", "doi": null, "report-no": "LA-UR-18-29576", "categories": "physics.flu-dyn cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe tests validating progress made toward acceleration and automation\nof hydrodynamic codes in the regime of developed turbulence by three Deep\nLearning (DL) Neural Network (NN) schemes trained on Direct Numerical\nSimulations of turbulence. Even the bare DL solutions, which do not take into\naccount any physics of turbulence explicitly, are impressively good overall\nwhen it comes to qualitative description of important features of turbulence.\nHowever, the early tests have also uncovered some caveats of the DL approaches.\nWe observe that the static DL scheme, implementing Convolutional GAN and\ntrained on spatial snapshots of turbulence, fails to reproduce intermittency of\nturbulent fluctuations at small scales and details of the turbulence geometry\nat large scales. We show that the dynamic NN schemes, namely LAT-NET and\nCompressed Convolutional LSTM, trained on a temporal sequence of turbulence\nsnapshots are capable to correct for the caveats of the static NN. We suggest a\npath forward towards improving reproducibility of the large-scale geometry of\nturbulence with NN.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:20:27 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 18:10:19 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["King", "Ryan", "", "NREL"], ["Hennigh", "Oliver", "", "LANL"], ["Mohan", "Arvind", "", "LANL"], ["Chertkov", "Michael", "", "LANL"]]}, {"id": "1810.07791", "submitter": "Dominika Woszczyk", "authors": "Dominika Woszczyk, Gerasimos Spanakis", "title": "MaaSim: A Liveability Simulation for Improving the Quality of Life in\n  Cities", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Urbanism is no longer planned on paper thanks to powerful models and 3D\nsimulation platforms. However, current work is not open to the public and lacks\nan optimisation agent that could help in decision making. This paper describes\nthe creation of an open-source simulation based on an existing Dutch\nliveability score with a built-in AI module. Features are selected using\nfeature engineering and Random Forests. Then, a modified scoring function is\nbuilt based on the former liveability classes. The score is predicted using\nRandom Forest for regression and achieved a recall of 0.83 with 10-fold\ncross-validation. Afterwards, Exploratory Factor Analysis is applied to select\nthe actions present in the model. The resulting indicators are divided into 5\ngroups, and 12 actions are generated. The performance of four optimisation\nalgorithms is compared, namely NSGA-II, PAES, SPEA2 and eps-MOEA, on three\nestablished criteria of quality: cardinality, the spread of the solutions,\nspacing, and the resulting score and number of turns. Although all four\nalgorithms show different strengths, eps-MOEA is selected to be the most\nsuitable for this problem. Ultimately, the simulation incorporates the model\nand the selected AI module in a GUI written in the Kivy framework for Python.\nTests performed on users show positive responses and encourage further\ninitiatives towards joining technology and public applications.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 15:19:41 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Woszczyk", "Dominika", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1810.07792", "submitter": "Lucas Cassano", "authors": "Lucas Cassano, Kun Yuan, Ali H. Sayed", "title": "Multi-Agent Fully Decentralized Value Function Learning with Linear\n  Convergence Rates", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops a fully decentralized multi-agent algorithm for policy\nevaluation. The proposed scheme can be applied to two distinct scenarios. In\nthe first scenario, a collection of agents have distinct datasets gathered\nfollowing different behavior policies (none of which is required to explore the\nfull state space) in different instances of the same environment and they all\ncollaborate to evaluate a common target policy. The network approach allows for\nefficient exploration of the state space and allows all agents to converge to\nthe optimal solution even in situations where neither agent can converge on its\nown without cooperation. The second scenario is that of multi-agent games, in\nwhich the state is global and rewards are local. In this scenario, agents\ncollaborate to estimate the value function of a target team policy. The\nproposed algorithm combines off-policy learning, eligibility traces and linear\nfunction approximation. The proposed algorithm is of the variance-reduced kind\nand achieves linear convergence with $O(1)$ memory requirements. The linear\nconvergence of the algorithm is established analytically, and simulations are\nused to illustrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:54:47 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 16:41:28 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 15:15:39 GMT"}, {"version": "v4", "created": "Wed, 31 Jul 2019 13:15:34 GMT"}, {"version": "v5", "created": "Mon, 12 Aug 2019 09:44:11 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Cassano", "Lucas", ""], ["Yuan", "Kun", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1810.07793", "submitter": "Facundo Memoli", "authors": "Facundo M\\'emoli, Zane Smith, and Zhengchao Wan", "title": "The Wasserstein transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Wasserstein transform, a method for enhancing and denoising\ndatasets defined on general metric spaces. The construction draws inspiration\nfrom Optimal Transportation ideas. We establish precise connections with the\nmean shift family of algorithms and establish the stability of both our method\nand mean shift under data perturbation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 20:58:32 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["M\u00e9moli", "Facundo", ""], ["Smith", "Zane", ""], ["Wan", "Zhengchao", ""]]}, {"id": "1810.07795", "submitter": "Markus Ring", "authors": "Markus Ring and Daniel Schl\\\"or and Dieter Landes and Andreas Hotho", "title": "Flow-based Network Traffic Generation using Generative Adversarial\n  Networks", "comments": "37 pages, submitted to Computer & Security", "journal-ref": null, "doi": "10.1016/j.cose.2018.12.012", "report-no": null, "categories": "cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based data sets are necessary for evaluating network-based intrusion\ndetection systems (NIDS). In this work, we propose a novel methodology for\ngenerating realistic flow-based network traffic. Our approach is based on\nGenerative Adversarial Networks (GANs) which achieve good results for image\ngeneration. A major challenge lies in the fact that GANs can only process\ncontinuous attributes. However, flow-based data inevitably contain categorical\nattributes such as IP addresses or port numbers. Therefore, we propose three\ndifferent preprocessing approaches for flow-based data in order to transform\nthem into continuous values. Further, we present a new method for evaluating\nthe generated flow-based network traffic which uses domain knowledge to define\nquality tests. We use the three approaches for generating flow-based network\ntraffic based on the CIDDS-001 data set. Experiments indicate that two of the\nthree approaches are able to generate high quality data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 11:31:43 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Ring", "Markus", ""], ["Schl\u00f6r", "Daniel", ""], ["Landes", "Dieter", ""], ["Hotho", "Andreas", ""]]}, {"id": "1810.07845", "submitter": "Amir Najafi", "authors": "Amir Najafi, Saeed Ilchi, Amir H. Saberi, Seyed Abolfazl Motahari,\n  Babak H. Khalaj, Hamid R. Rabiee", "title": "On Statistical Learning of Simplices: Unmixing Problem Revisited", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning a high-dimensional simplex from a\nset of points uniformly sampled from its interior. Learning of simplices is a\nlong studied problem in computer science and has applications in computational\nbiology and remote sensing, mostly under the name of `spectral unmixing'. We\ntheoretically show that a sufficient sample complexity for reliable learning of\na $K$-dimensional simplex up to a total-variation error of $\\epsilon$ is\n$O\\left(\\frac{K^2}{\\epsilon}\\log\\frac{K}{\\epsilon}\\right)$, which yields a\nsubstantial improvement over existing bounds. Based on our new theoretical\nframework, we also propose a heuristic approach for the inference of simplices.\nExperimental results on synthetic and real-world datasets demonstrate a\ncomparable performance for our method on noiseless samples, while we outperform\nthe state-of-the-art in noisy cases.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 00:20:25 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 19:54:20 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 16:35:40 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 23:08:46 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Najafi", "Amir", ""], ["Ilchi", "Saeed", ""], ["Saberi", "Amir H.", ""], ["Motahari", "Seyed Abolfazl", ""], ["Khalaj", "Babak H.", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1810.07874", "submitter": "Lifang He", "authors": "Lifang He, Chun-ta Lu, Yong Chen, Jiawei Zhang, Linlin Shen, Philip S.\n  Yu, Fei Wang", "title": "A Self-Organizing Tensor Architecture for Multi-View Clustering", "comments": "2018 IEEE International Conference on Data Mining (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, data are often unlabeled and comprised of\ndifferent representations/views which often provide information complementary\nto each other. Although several multi-view clustering methods have been\nproposed, most of them routinely assume one weight for one view of features,\nand thus inter-view correlations are only considered at the view-level. These\napproaches, however, fail to explore the explicit correlations between features\nacross multiple views. In this paper, we introduce a tensor-based approach to\nincorporate the higher-order interactions among multiple views as a tensor\nstructure. Specifically, we propose a multi-linear multi-view clustering (MMC)\nmethod that can efficiently explore the full-order structural information among\nall views and reveal the underlying subspace structure embedded within the\ntensor. Extensive experiments on real-world datasets demonstrate that our\nproposed MMC algorithm clearly outperforms other related state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 02:26:28 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["He", "Lifang", ""], ["Lu", "Chun-ta", ""], ["Chen", "Yong", ""], ["Zhang", "Jiawei", ""], ["Shen", "Linlin", ""], ["Yu", "Philip S.", ""], ["Wang", "Fei", ""]]}, {"id": "1810.07900", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli, Yisong Yue, Animashree Anandkumar", "title": "Policy Gradient in Partially Observable Environments: Approximation and\n  Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient is a generic and flexible reinforcement learning approach\nthat generally enjoys simplicity in analysis, implementation, and deployment.\nIn the last few decades, this approach has been extensively advanced for fully\nobservable environments. In this paper, we generalize a variety of these\nadvances to partially observable settings, and similar to the fully observable\ncase, we keep our focus on the class of Markovian policies. We propose a series\nof technical tools, including a novel notion of advantage function, to develop\npolicy gradient algorithms and study their convergence properties in such\nenvironments. Deploying these tools, we generalize a variety of existing\ntheoretical guarantees, such as policy gradient and convergence theorems, to\npartially observable domains, those which also could be carried to more\nsettings of interest. This study also sheds light on the understanding of\npolicy gradient approaches in real-world applications which tend to be\npartially observable.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 05:25:11 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 23:34:04 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 21:30:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Yue", "Yisong", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1810.07913", "submitter": "Kean Ming Tan", "authors": "Kean Ming Tan and Qiang Sun and Daniela Witten", "title": "Robust Sparse Reduced Rank Regression in High Dimensions", "comments": "This is a replacement of a previous article titled \"Distributionally\n  Robust Reduced Rank Regression and Principal Component Analysis in High\n  Dimensions\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose robust sparse reduced rank regression for analyzing large and\ncomplex high-dimensional data with heavy-tailed random noise. The proposed\nmethod is based on a convex relaxation of a rank- and sparsity-constrained\nnon-convex optimization problem, which is then solved using the alternating\ndirection method of multipliers algorithm. We establish non-asymptotic\nestimation error bounds under both Frobenius and nuclear norms in the\nhigh-dimensional setting. This is a major contribution over existing results in\nreduced rank regression, which mainly focus on rank selection and prediction\nconsistency. Our theoretical results quantify the tradeoff between\nheavy-tailedness of the random noise and statistical bias. For random noise\nwith bounded $(1+\\delta)$th moment with $\\delta \\in (0,1)$, the rate of\nconvergence is a function of $\\delta$, and is slower than the sub-Gaussian-type\ndeviation bounds; for random noise with bounded second moment, we obtain a rate\nof convergence as if sub-Gaussian noise were assumed. Furthermore, the\ntransition between the two regimes is smooth. We illustrate the performance of\nthe proposed method via extensive numerical studies and a data application.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 06:21:52 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 19:37:42 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Tan", "Kean Ming", ""], ["Sun", "Qiang", ""], ["Witten", "Daniela", ""]]}, {"id": "1810.07924", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc (IMT), Fabrice Gamboa (IMT), Max Halford (IMT,\n  IRIT), Jean-Michel Loubes (IMT), Laurent Risser (IMT)", "title": "Explaining Machine Learning Models using Entropic Variable Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new explainability formalism designed to explain\nhow each input variable of a test set impacts the predictions of machine\nlearning models. Hence, we propose a group explainability formalism for trained\nmachine learning decision rules, based on their response to the variability of\nthe input variables distribution. In order to emphasize the impact of each\ninput variable, this formalism uses an information theory framework that\nquantifies the influence of all input-output observations based on entropic\nprojections. This is thus the first unified and model agnostic formalism\nenabling data scientists to interpret the dependence between the input\nvariables, their impact on the prediction errors, and their influence on the\noutput predictions. Convergence rates of the entropic projections are provided\nin the large sample case. Most importantly, we prove that computing an\nexplanation in our framework has a low algorithmic complexity, making it\nscalable to real-life large datasets. We illustrate our strategy by explaining\ncomplex decision rules learned by using XGBoost, Random Forest or Deep Neural\nNetwork classifiers on various datasets such as Adult income, MNIST and CelebA.\nWe finally make clear its differences with the explainability strategies\n\\textit{LIME} and \\textit{SHAP}, that are based on single observations. Results\ncan be reproduced by using the freely distributed Python toolbox\nhttps://gems-ai.com}.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 07:04:39 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 17:47:22 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 12:44:12 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 11:41:16 GMT"}, {"version": "v5", "created": "Wed, 2 Dec 2020 14:29:31 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Bachoc", "Fran\u00e7ois", "", "IMT"], ["Gamboa", "Fabrice", "", "IMT"], ["Halford", "Max", "", "IMT,\n  IRIT"], ["Loubes", "Jean-Michel", "", "IMT"], ["Risser", "Laurent", "", "IMT"]]}, {"id": "1810.07954", "submitter": "Yuting Ye", "authors": "Christine Ho, Yuting Ye, Ci-Ren Jiang, Wayne Tai Lee and Haiyan Huang", "title": "HierLPR: Decision making in hierarchical multi-label classification with\n  local precision rates", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a novel ranking algorithm, referred to as HierLPR,\nfor the multi-label classification problem when the candidate labels follow a\nknown hierarchical structure. HierLPR is motivated by a new metric called eAUC\nthat we design to assess the ranking of classification decisions. This metric,\nassociated with the hit curve and local precision rate, emphasizes the accuracy\nof the first calls. We show that HierLPR optimizes eAUC under the tree\nconstraint and some light assumptions on the dependency between the nodes in\nthe hierarchy. We also provide a strategy to make calls for each node based on\nthe ordering produced by HierLPR, with the intent of controlling FDR or\nmaximizing F-score. The performance of our proposed methods is demonstrated on\nsynthetic datasets as well as a real example of disease diagnosis using NCBI\nGEO datasets. In these cases, HierLPR shows a favorable result over competing\nmethods in the early part of the precision-recall curve.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 08:59:04 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Ho", "Christine", ""], ["Ye", "Yuting", ""], ["Jiang", "Ci-Ren", ""], ["Lee", "Wayne Tai", ""], ["Huang", "Haiyan", ""]]}, {"id": "1810.07973", "submitter": "Tineke Blom", "authors": "Tineke Blom, Anna Klimovskaia, Sara Magliacane, Joris M. Mooij", "title": "An Upper Bound for Random Measurement Error in Causal Discovery", "comments": "Published in Proceedings of the 34th Annual Conference on Uncertainty\n  in Artificial Intelligence (UAI-18)", "journal-ref": "Proceedings of the 34th Annual Conference on Uncertainty in\n  Artificial Intelligence, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery algorithms infer causal relations from data based on several\nassumptions, including notably the absence of measurement error. However, this\nassumption is most likely violated in practical applications, which may result\nin erroneous, irreproducible results. In this work we show how to obtain an\nupper bound for the variance of random measurement error from the covariance\nmatrix of measured variables and how to use this upper bound as a correction\nfor constraint-based causal discovery. We demonstrate a practical application\nof our approach on both simulated data and real-world protein signaling data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 09:47:35 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Blom", "Tineke", ""], ["Klimovskaia", "Anna", ""], ["Magliacane", "Sara", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1810.08010", "submitter": "Benjamin Rhodes", "authors": "Benjamin Rhodes, Michael Gutmann", "title": "Variational Noise-Contrastive Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unnormalised latent variable models are a broad and flexible class of\nstatistical models. However, learning their parameters from data is\nintractable, and few estimation techniques are currently available for such\nmodels. To increase the number of techniques in our arsenal, we propose\nvariational noise-contrastive estimation (VNCE), building on NCE which is a\nmethod that only applies to unnormalised models. The core idea is to use a\nvariational lower bound to the NCE objective function, which can be optimised\nin the same fashion as the evidence lower bound (ELBO) in standard variational\ninference (VI). We prove that VNCE can be used for both parameter estimation of\nunnormalised models and posterior inference of latent variables. The developed\ntheory shows that VNCE has the same level of generality as standard VI, meaning\nthat advances made there can be directly imported to the unnormalised setting.\nWe validate VNCE on toy models and apply it to a realistic problem of\nestimating an undirected graphical model from incomplete data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 12:32:11 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 08:14:56 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 14:07:40 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Rhodes", "Benjamin", ""], ["Gutmann", "Michael", ""]]}, {"id": "1810.08033", "submitter": "Taiji Suzuki", "authors": "Taiji Suzuki", "title": "Adaptivity of deep ReLU network for learning in Besov and mixed smooth\n  Besov spaces: optimal rate and curse of dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown high performances in various types of tasks from\nvisual recognition to natural language processing, which indicates superior\nflexibility and adaptivity of deep learning. To understand this phenomenon\ntheoretically, we develop a new approximation and estimation error analysis of\ndeep learning with the ReLU activation for functions in a Besov space and its\nvariant with mixed smoothness. The Besov space is a considerably general\nfunction space including the Holder space and Sobolev space, and especially can\ncapture spatial inhomogeneity of smoothness. Through the analysis in the Besov\nspace, it is shown that deep learning can achieve the minimax optimal rate and\noutperform any non-adaptive (linear) estimator such as kernel ridge regression,\nwhich shows that deep learning has higher adaptivity to the spatial\ninhomogeneity of the target function than other estimators such as linear ones.\nIn addition to this, it is shown that deep learning can avoid the curse of\ndimensionality if the target function is in a mixed smooth Besov space. We also\nshow that the dependency of the convergence rate on the dimensionality is tight\ndue to its minimax optimality. These results support high adaptivity of deep\nlearning and its superior ability as a feature extractor.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 13:17:20 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Suzuki", "Taiji", ""]]}, {"id": "1810.08061", "submitter": "Andrew Johnson", "authors": "Dan Moldovan and James M Decker and Fei Wang and Andrew A Johnson and\n  Brian K Lee and Zachary Nado and D Sculley and Tiark Rompf and Alexander B\n  Wiltschko", "title": "AutoGraph: Imperative-style Coding with Graph-based Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a perceived trade-off between machine learning code that is easy to\nwrite, and machine learning code that is scalable or fast to execute. In\nmachine learning, imperative style libraries like Autograd and PyTorch are easy\nto write, but suffer from high interpretive overhead and are not easily\ndeployable in production or mobile settings. Graph-based libraries like\nTensorFlow and Theano benefit from whole-program optimization and can be\ndeployed broadly, but make expressing complex models more cumbersome. We\ndescribe how the use of staged programming in Python, via source code\ntransformation, offers a midpoint between these two library design patterns,\ncapturing the benefits of both. A key insight is to delay all type-dependent\ndecisions until runtime, via dynamic dispatch. We instantiate these principles\nin AutoGraph, a software system that improves the programming experience of the\nTensorFlow library, and demonstrate usability improvements with no loss in\nperformance compared to native TensorFlow graphs. We also show that our system\nis backend agnostic, and demonstrate targeting an alternate IR with\ncharacteristics not found in TensorFlow graphs.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 19:14:09 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 19:19:51 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Moldovan", "Dan", ""], ["Decker", "James M", ""], ["Wang", "Fei", ""], ["Johnson", "Andrew A", ""], ["Lee", "Brian K", ""], ["Nado", "Zachary", ""], ["Sculley", "D", ""], ["Rompf", "Tiark", ""], ["Wiltschko", "Alexander B", ""]]}, {"id": "1810.08083", "submitter": "Simone Rossi", "authors": "Simone Rossi and Pietro Michiardi and Maurizio Filippone", "title": "Good Initializations of Variational Bayes for Deep Models", "comments": "8 pages of main paper (+3 for references and +6 of supplement\n  material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference is an established way to carry out\napproximate Bayesian inference for deep models. While there have been effective\nproposals for good initializations for loss minimization in deep learning, far\nless attention has been devoted to the issue of initialization of stochastic\nvariational inference. We address this by proposing a novel layer-wise\ninitialization strategy based on Bayesian linear models. The proposed method is\nextensively validated on regression and classification tasks, including\nBayesian DeepNets and ConvNets, showing faster and better convergence compared\nto alternatives inspired by the literature on initializations for loss\nminimization.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 14:35:23 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 09:41:07 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Rossi", "Simone", ""], ["Michiardi", "Pietro", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1810.08102", "submitter": "Nicolas Perrin-Gilbert", "authors": "Thomas Pierrot and Nicolas Perrin and Olivier Sigaud", "title": "First-order and second-order variants of the gradient descent in a\n  unified framework", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide an overview of first-order and second-order\nvariants of the gradient descent method that are commonly used in machine\nlearning. We propose a general framework in which 6 of these variants can be\ninterpreted as different instances of the same approach. They are the vanilla\ngradient descent, the classical and generalized Gauss-Newton methods, the\nnatural gradient descent method, the gradient covariance matrix approach, and\nNewton's method. Besides interpreting these methods within a single framework,\nwe explain their specificities and show under which conditions some of them\ncoincide.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 15:18:09 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 15:34:39 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 11:56:10 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Pierrot", "Thomas", ""], ["Perrin", "Nicolas", ""], ["Sigaud", "Olivier", ""]]}, {"id": "1810.08126", "submitter": "Peiye Liu", "authors": "Peiye Liu, Wu Liu, Huadong Ma, Tao Mei, Mingoo Seok", "title": "KTAN: Knowledge Transfer Adversarial Network", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the large computation and storage cost of a deep convolutional\nneural network, the knowledge distillation based methods have pioneered to\ntransfer the generalization ability of a large (teacher) deep network to a\nlight-weight (student) network. However, these methods mostly focus on\ntransferring the probability distribution of the softmax layer in a teacher\nnetwork and thus neglect the intermediate representations. In this paper, we\npropose a knowledge transfer adversarial network to better train a student\nnetwork. Our technique holistically considers both intermediate representations\nand probability distributions of a teacher network. To transfer the knowledge\nof intermediate representations, we set high-level teacher feature maps as a\ntarget, toward which the student feature maps are trained. Specifically, we\narrange a Teacher-to-Student layer for enabling our framework suitable for\nvarious student structures. The intermediate representation helps the student\nnetwork better understand the transferred generalization as compared to the\nprobability distribution only. Furthermore, we infuse an adversarial learning\nprocess by employing a discriminator network, which can fully exploit the\nspatial correlation of feature maps in training a student network. The\nexperimental results demonstrate that the proposed method can significantly\nimprove the performance of a student network on both image classification and\nobject detection tasks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 15:57:02 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Liu", "Peiye", ""], ["Liu", "Wu", ""], ["Ma", "Huadong", ""], ["Mei", "Tao", ""], ["Seok", "Mingoo", ""]]}, {"id": "1810.08164", "submitter": "Samarth Gupta", "authors": "Samarth Gupta, Shreyas Chaudhari, Subhojyoti Mukherjee, Gauri Joshi,\n  Osman Ya\\u{g}an", "title": "A Unified Approach to Translate Classical Bandit Algorithms to the\n  Structured Bandit Setting", "comments": null, "journal-ref": "IEEE Journal on Selected Areas of Information Theory 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a finite-armed structured bandit problem in which mean rewards of\ndifferent arms are known functions of a common hidden parameter $\\theta^*$.\nSince we do not place any restrictions of these functions, the problem setting\nsubsumes several previously studied frameworks that assume linear or invertible\nreward functions. We propose a novel approach to gradually estimate the hidden\n$\\theta^*$ and use the estimate together with the mean reward functions to\nsubstantially reduce exploration of sub-optimal arms. This approach enables us\nto fundamentally generalize any classic bandit algorithm including UCB and\nThompson Sampling to the structured bandit setting. We prove via regret\nanalysis that our proposed UCB-C algorithm (structured bandit versions of UCB)\npulls only a subset of the sub-optimal arms $O(\\log T)$ times while the other\nsub-optimal arms (referred to as non-competitive arms) are pulled $O(1)$ times.\nAs a result, in cases where all sub-optimal arms are non-competitive, which can\nhappen in many practical scenarios, the proposed algorithms achieve bounded\nregret. We also conduct simulations on the Movielens recommendations dataset to\ndemonstrate the improvement of the proposed algorithms over existing structured\nbandit algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:01:00 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 22:31:18 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 14:50:05 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 16:18:31 GMT"}, {"version": "v5", "created": "Tue, 3 Dec 2019 23:22:38 GMT"}, {"version": "v6", "created": "Mon, 25 May 2020 18:53:55 GMT"}, {"version": "v7", "created": "Wed, 3 Feb 2021 17:46:16 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Gupta", "Samarth", ""], ["Chaudhari", "Shreyas", ""], ["Mukherjee", "Subhojyoti", ""], ["Joshi", "Gauri", ""], ["Ya\u011fan", "Osman", ""]]}, {"id": "1810.08171", "submitter": "Hongyang Zhang", "authors": "Maria-Florina Balcan and Yi Li and David P. Woodruff and Hongyang\n  Zhang", "title": "Testing Matrix Rank, Optimally", "comments": "51 pages. To appear in SODA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for the problem of testing if a matrix $A \\in F^{n \\times n}$\nhas rank at most $d$, or requires changing an $\\epsilon$-fraction of entries to\nhave rank at most $d$, there is a non-adaptive query algorithm making\n$\\widetilde{O}(d^2/\\epsilon)$ queries. Our algorithm works for any field $F$.\nThis improves upon the previous $O(d^2/\\epsilon^2)$ bound (SODA'03), and\nbypasses an $\\Omega(d^2/\\epsilon^2)$ lower bound of (KDD'14) which holds if the\nalgorithm is required to read a submatrix. Our algorithm is the first such\nalgorithm which does not read a submatrix, and instead reads a carefully\nselected non-adaptive pattern of entries in rows and columns of $A$. We\ncomplement our algorithm with a matching query complexity lower bound for\nnon-adaptive testers over any field. We also give tight bounds of\n$\\widetilde{\\Theta}(d^2)$ queries in the sensing model for which query access\ncomes in the form of $\\langle X_i, A\\rangle:=tr(X_i^\\top A)$; perhaps\nsurprisingly these bounds do not depend on $\\epsilon$.\n  We next develop a novel property testing framework for testing numerical\nproperties of a real-valued matrix $A$ more generally, which includes the\nstable rank, Schatten-$p$ norms, and SVD entropy. Specifically, we propose a\nbounded entry model, where $A$ is required to have entries bounded by $1$ in\nabsolute value. We give upper and lower bounds for a wide range of problems in\nthis model, and discuss connections to the sensing model above.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:24:52 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Li", "Yi", ""], ["Woodruff", "David P.", ""], ["Zhang", "Hongyang", ""]]}, {"id": "1810.08178", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, David Eigen, Massoud Pedram", "title": "Gradient Agreement as an Optimization Objective for Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel optimization method for maximizing generalization\nover tasks in meta-learning. The goal of meta-learning is to learn a model for\nan agent adapting rapidly when presented with previously unseen tasks. Tasks\nare sampled from a specific distribution which is assumed to be similar for\nboth seen and unseen tasks. We focus on a family of meta-learning methods\nlearning initial parameters of a base model which can be fine-tuned quickly on\na new task, by few gradient steps (MAML). Our approach is based on pushing the\nparameters of the model to a direction in which tasks have more agreement upon.\nIf the gradients of a task agree with the parameters update vector, then their\ninner product will be a large positive value. As a result, given a batch of\ntasks to be optimized for, we associate a positive (negative) weight to the\nloss function of a task, if the inner product between its gradients and the\naverage of the gradients of all tasks in the batch is a positive (negative)\nvalue. Therefore, the degree of the contribution of a task to the parameter\nupdates is controlled by introducing a set of weights on the loss function of\nthe tasks. Our method can be easily integrated with the current meta-learning\nalgorithms for neural networks. Our experiments demonstrate that it yields\nmodels with better generalization compared to MAML and Reptile.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:38:57 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Eigen", "David", ""], ["Pedram", "Massoud", ""]]}, {"id": "1810.08217", "submitter": "Nils Thuerey", "authors": "Nils Thuerey, Konstantin Weissenow, Lukas Prantl, Xiangyu Hu", "title": "Deep Learning Methods for Reynolds-Averaged Navier-Stokes Simulations of\n  Airfoil Flows", "comments": "Code and data available at:\n  https://github.com/thunil/Deep-Flow-Prediction", "journal-ref": null, "doi": "10.2514/1.j058291", "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With this study we investigate the accuracy of deep learning models for the\ninference of Reynolds-Averaged Navier-Stokes solutions. We focus on a\nmodernized U-net architecture, and evaluate a large number of trained neural\nnetworks with respect to their accuracy for the calculation of pressure and\nvelocity distributions. In particular, we illustrate how training data size and\nthe number of weights influence the accuracy of the solutions. With our best\nmodels we arrive at a mean relative pressure and velocity error of less than 3%\nacross a range of previously unseen airfoil shapes. In addition all source code\nis publicly available in order to ensure reproducibility and to provide a\nstarting point for researchers interested in deep learning methods for physics\nproblems. While this work focuses on RANS solutions, the neural network\narchitecture and learning setup are very generic, and applicable to a wide\nrange of PDE boundary value problems on Cartesian grids.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:01:01 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 16:52:30 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 10:38:43 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Thuerey", "Nils", ""], ["Weissenow", "Konstantin", ""], ["Prantl", "Lukas", ""], ["Hu", "Xiangyu", ""]]}, {"id": "1810.08223", "submitter": "Muhammad Asiful Islam", "authors": "Muhammad Asiful Islam, Ramakrishnan Srikant, Sugato Basu", "title": "Micro-Browsing Models for Search Snippets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) is a key signal of relevance for search engine\nresults, both organic and sponsored. CTR of a result has two core components:\n(a) the probability of examination of a result by a user, and (b) the perceived\nrelevance of the result given that it has been examined by the user. There has\nbeen considerable work on user browsing models, to model and analyze both the\nexamination and the relevance components of CTR. In this paper, we propose a\nnovel formulation: a micro-browsing model for how users read result snippets.\nThe snippet text of a result often plays a critical role in the perceived\nrelevance of the result. We study how particular words within a line of snippet\ncan influence user behavior. We validate this new micro-browsing user model by\nconsidering the problem of predicting which snippet will yield higher CTR, and\nshow that classification accuracy is dramatically higher with our\nmicro-browsing user model. The key insight in this paper is that varying\nrelatively few words within a snippet, and even their location within a\nsnippet, can have a significant influence on the clickthrough of a snippet.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:13:28 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Islam", "Muhammad Asiful", ""], ["Srikant", "Ramakrishnan", ""], ["Basu", "Sugato", ""]]}, {"id": "1810.08264", "submitter": "Yichen Zhang", "authors": "Xi Chen, Weidong Liu, Yichen Zhang", "title": "Quantile Regression Under Memory Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the inference problem in quantile regression (QR) for a\nlarge sample size $n$ but under a limited memory constraint, where the memory\ncan only store a small batch of data of size $m$. A natural method is the\nna\\\"ive divide-and-conquer approach, which splits data into batches of size\n$m$, computes the local QR estimator for each batch, and then aggregates the\nestimators via averaging. However, this method only works when $n=o(m^2)$ and\nis computationally expensive. This paper proposes a computationally efficient\nmethod, which only requires an initial QR estimator on a small batch of data\nand then successively refines the estimator via multiple rounds of\naggregations. Theoretically, as long as $n$ grows polynomially in $m$, we\nestablish the asymptotic normality for the obtained estimator and show that our\nestimator with only a few rounds of aggregations achieves the same efficiency\nas the QR estimator computed on all the data. Moreover, our result allows the\ncase that the dimensionality $p$ goes to infinity. The proposed method can also\nbe applied to address the QR problem under distributed computing environment\n(e.g., in a large-scale sensor network) or for real-time streaming data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 20:03:51 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Chen", "Xi", ""], ["Liu", "Weidong", ""], ["Zhang", "Yichen", ""]]}, {"id": "1810.08280", "submitter": "Octavian Suciu", "authors": "Octavian Suciu, Scott E. Coull, Jeffrey Johns", "title": "Exploring Adversarial Examples in Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convolutional neural network (CNN) architecture is increasingly being\napplied to new domains, such as malware detection, where it is able to learn\nmalicious behavior from raw bytes extracted from executables. These\narchitectures reach impressive performance with no feature engineering effort\ninvolved, but their robustness against active attackers is yet to be\nunderstood. Such malware detectors could face a new attack vector in the form\nof adversarial interference with the classification model. Existing evasion\nattacks intended to cause misclassification on test-time instances, which have\nbeen extensively studied for image classifiers, are not applicable because of\nthe input semantics that prevents arbitrary changes to the binaries. This paper\nexplores the area of adversarial examples for malware detection. By training an\nexisting model on a production-scale dataset, we show that some previous\nattacks are less effective than initially reported, while simultaneously\nhighlighting architectural weaknesses that facilitate new attack strategies for\nmalware classification. Finally, we explore how generalizable different attack\nstrategies are, the trade-offs when aiming to increase their effectiveness, and\nthe transferability of single-step attacks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 21:26:27 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 14:23:22 GMT"}, {"version": "v3", "created": "Sat, 13 Apr 2019 23:21:45 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Suciu", "Octavian", ""], ["Coull", "Scott E.", ""], ["Johns", "Jeffrey", ""]]}, {"id": "1810.08305", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic, Badal Singh, Anima Anandkumar", "title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "comments": "Published in the International Conference on Machine Learning (ICML\n  2019), 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models that take computer program source code as input\ntypically use Natural Language Processing (NLP) techniques. However, a major\nchallenge is that code is written using an open, rapidly changing vocabulary\ndue to, e.g., the coinage of new variable and method names. Reasoning over such\na vocabulary is not something for which most NLP methods are designed. We\nintroduce a Graph-Structured Cache to address this problem; this cache contains\na node for each new word the model encounters with edges connecting each word\nto its occurrences in the code. We find that combining this graph-structured\ncache strategy with recent Graph-Neural-Network-based models for supervised\nlearning on code improves the models' performance on a code completion task and\na variable naming task --- with over $100\\%$ relative improvement on the latter\n--- at the cost of a moderate increase in computation time.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:33:11 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 22:44:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cvitkovic", "Milan", ""], ["Singh", "Badal", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1810.08309", "submitter": "Ian Davis", "authors": "Ian J Davis", "title": "Unsupervised Anomalous Data Space Specification", "comments": "18 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer algorithms are written with the intent that when run they perform a\nuseful function. Typically any information obtained is unknown until the\nalgorithm is run. However, if the behavior of an algorithm can be fully\ndescribed by precomputing just once how this algorithm will respond when\nexecuted on any input, this precomputed result provides a complete\nspecification for all solutions in the problem domain. We apply this idea to a\nprevious anomaly detection algorithm, and in doing so transform it from one\nthat merely detects individual anomalies when asked to discover potentially\nanomalous values, into an algorithm also capable of generating a complete\nspecification for those values it would deem to be anomalous. This\nspecification is derived by examining no more than a small training data, can\nbe obtained in very small constant time, and is inherently far more useful than\nresults obtained by repeated execution of this tool. For example, armed with\nsuch a specification one can ask how close an anomaly is to being deemed\nnormal, and can validate this answer not by exhaustively testing the algorithm\nbut by examining if the specification so generated is indeed correct. This\npowerful idea can be applied to any algorithm whose runtime behavior can be\nrecovered from its construction and so has wide applicability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:43:21 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Davis", "Ian J", ""]]}, {"id": "1810.08313", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Gauri Joshi", "title": "Adaptive Communication Strategies to Achieve the Best Error-Runtime\n  Trade-off in Local-Update SGD", "comments": "Accepted to SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale machine learning training, in particular distributed stochastic\ngradient descent, needs to be robust to inherent system variability such as\nnode straggling and random communication delays. This work considers a\ndistributed training framework where each worker node is allowed to perform\nlocal model updates and the resulting models are averaged periodically. We\nanalyze the true speed of error convergence with respect to wall-clock time\n(instead of the number of iterations), and analyze how it is affected by the\nfrequency of averaging. The main contribution is the design of AdaComm, an\nadaptive communication strategy that starts with infrequent averaging to save\ncommunication delay and improve convergence speed, and then increases the\ncommunication frequency in order to achieve a low error floor. Rigorous\nexperiments on training deep neural networks show that AdaComm can take $3\n\\times$ less time than fully synchronous SGD, and still reach the same final\ntraining loss.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 00:04:05 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:45:02 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Wang", "Jianyu", ""], ["Joshi", "Gauri", ""]]}, {"id": "1810.08316", "submitter": "Anru R. Zhang", "authors": "Anru R. Zhang and T. Tony Cai and Yihong Wu", "title": "Heteroskedastic PCA: Algorithm, Optimality, and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A general framework for principal component analysis (PCA) in the presence of\nheteroskedastic noise is introduced. We propose an algorithm called HeteroPCA,\nwhich involves iteratively imputing the diagonal entries of the sample\ncovariance matrix to remove estimation bias due to heteroskedasticity. This\nprocedure is computationally efficient and provably optimal under the\ngeneralized spiked covariance model. A key technical step is a deterministic\nrobust perturbation analysis on singular subspaces, which can be of independent\ninterest. The effectiveness of the proposed algorithm is demonstrated in a\nsuite of problems in high-dimensional statistics, including singular value\ndecomposition (SVD) under heteroskedastic noise, Poisson PCA, and SVD for\nheteroskedastic and incomplete data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 00:22:25 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 01:29:04 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 14:00:56 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhang", "Anru R.", ""], ["Cai", "T. Tony", ""], ["Wu", "Yihong", ""]]}, {"id": "1810.08322", "submitter": "Dae Hoon Park", "authors": "Chiu Man Ho, Dae Hoon Park, Wei Yang, Yi Chang", "title": "Sequenced-Replacement Sampling for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose sequenced-replacement sampling (SRS) for training deep neural\nnetworks. The basic idea is to assign a fixed sequence index to each sample in\nthe dataset. Once a mini-batch is randomly drawn in each training iteration, we\nrefill the original dataset by successively adding samples according to their\nsequence index. Thus we carry out replacement sampling but in a batched and\nsequenced way. In a sense, SRS could be viewed as a way of performing\n\"mini-batch augmentation\". It is particularly useful for a task where we have a\nrelatively small images-per-class such as CIFAR-100. Together with a longer\nperiod of initial large learning rate, it significantly improves the\nclassification accuracy in CIFAR-100 over the current state-of-the-art results.\nOur experiments indicate that training deeper networks with SRS is less prone\nto over-fitting. In the best case, we achieve an error rate as low as 10.10%.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 00:55:47 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Ho", "Chiu Man", ""], ["Park", "Dae Hoon", ""], ["Yang", "Wei", ""], ["Chang", "Yi", ""]]}, {"id": "1810.08323", "submitter": "Saiprasad Ravishankar", "authors": "Saiprasad Ravishankar and Brendt Wohlberg", "title": "Learning Multi-Layer Transform Models", "comments": "In Proceedings of the Annual Allerton Conference on Communication,\n  Control, and Computing, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned data models based on sparsity are widely used in signal processing\nand imaging applications. A variety of methods for learning synthesis\ndictionaries, sparsifying transforms, etc., have been proposed in recent years,\noften imposing useful structures or properties on the models. In this work, we\nfocus on sparsifying transform learning, which enjoys a number of advantages.\nWe consider multi-layer or nested extensions of the transform model, and\npropose efficient learning algorithms. Numerical experiments with image data\nillustrate the behavior of the multi-layer transform learning algorithm and its\nusefulness for image denoising. Multi-layer models provide better denoising\nquality than single layer schemes.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 00:56:42 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Wohlberg", "Brendt", ""]]}, {"id": "1810.08351", "submitter": "Russell Tsuchida B.E.", "authors": "Russell Tsuchida, Fred Roosta, Marcus Gallagher", "title": "Exchangeability and Kernel Invariance in Trained MLPs", "comments": "26 pages, 16 Figures; Changed Fred (Farbod) Roosta to Fred Roosta in\n  Metadata", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the analysis of machine learning models, it is often convenient to assume\nthat the parameters are IID. This assumption is not satisfied when the\nparameters are updated through training processes such as SGD. A relaxation of\nthe IID condition is a probabilistic symmetry known as exchangeability. We show\nthe sense in which the weights in MLPs are exchangeable. This yields the result\nthat in certain instances, the layer-wise kernel of fully-connected layers\nremains approximately constant during training. We identify a sharp change in\nthe macroscopic behavior of networks as the covariance between weights changes\nfrom zero.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 04:09:09 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 11:18:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tsuchida", "Russell", ""], ["Roosta", "Fred", ""], ["Gallagher", "Marcus", ""]]}, {"id": "1810.08359", "submitter": "Zhongyi Hu", "authors": "Zhongyi Hu, Raymond Chiong, Ilung Pranata, Yukun Bao, Yuqing Lin", "title": "Malicious Web Domain Identification using Online Credibility and\n  Performance Data by Considering the Class Imbalance Issue", "comments": "20 pages", "journal-ref": "Industrial Management & Data Systems, 2018", "doi": "10.1108/IMDS-02-2018-0072", "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Malicious web domain identification is of significant importance to\nthe security protection of Internet users. With online credibility and\nperformance data, this paper aims to investigate the use of machine learning\ntech-niques for malicious web domain identification by considering the class\nimbalance issue (i.e., there are more benign web domains than malicious ones).\nDesign/methodology/approach: We propose an integrated resampling approach to\nhandle class imbalance by combining the Synthetic Minority Over-sampling\nTEchnique (SMOTE) and Particle Swarm Optimisation (PSO), a population-based\nmeta-heuristic algorithm. We use the SMOTE for over-sampling and PSO for\nunder-sampling. Findings: By applying eight well-known machine learning\nclassifiers, the proposed integrated resampling approach is comprehensively\nexamined using several imbalanced web domain datasets with different imbalance\nratios. Com-pared to five other well-known resampling approaches, experimental\nresults confirm that the proposed approach is highly effective. Practical\nimplications: This study not only inspires the practical use of online\ncredibility and performance data for identifying malicious web domains, but\nalso provides an effective resampling approach for handling the class\nimbal-ance issue in the area of malicious web domain identification.\nOriginality/value: Online credibility and performance data is applied to build\nmalicious web domain identification models using machine learning techniques.\nAn integrated resampling approach is proposed to address the class im-balance\nissue. The performance of the proposed approach is confirmed based on\nreal-world datasets with different imbalance ratios.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 05:54:40 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Hu", "Zhongyi", ""], ["Chiong", "Raymond", ""], ["Pranata", "Ilung", ""], ["Bao", "Yukun", ""], ["Lin", "Yuqing", ""]]}, {"id": "1810.08363", "submitter": "Adi Hayat", "authors": "Adi Hayat, Mark Kliger, Shachar Fleishman, Daniel Cohen-Or", "title": "Generative Low-Shot Network Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional deep learning classifiers are static in the sense that they are\ntrained on a predefined set of classes and learning to classify a novel class\ntypically requires re-training. In this work, we address the problem of\nLow-Shot network expansion learning. We introduce a learning framework which\nenables expanding a pre-trained (base) deep network to classify novel classes\nwhen the number of examples for the novel classes is particularly small. We\npresent a simple yet powerful hard distillation method where the base network\nis augmented with additional weights to classify the novel classes, while\nkeeping the weights of the base network unchanged. We show that since only a\nsmall number of weights needs to be trained, the hard distillation excels in\nlow-shot training scenarios. Furthermore, hard distillation avoids detriment to\nclassification performance on the base classes. Finally, we show that low-shot\nnetwork expansion can be done with a very small memory footprint by using a\ncompact generative model of the base classes training data with only a\nnegligible degradation relative to learning with the full training set.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 06:25:00 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Hayat", "Adi", ""], ["Kliger", "Mark", ""], ["Fleishman", "Shachar", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1810.08379", "submitter": "Haiyue Song", "authors": "Haiyue Song, Chengwen Xu, Qiang Xu, Zhuoran Song, Naifeng Jing,\n  Xiaoyao Liang, Li Jiang", "title": "Invocation-driven Neural Approximate Computing with a\n  Multiclass-Classifier and Multiple Approximators", "comments": "Accepted by ICCAD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural approximate computing gains enormous energy-efficiency at the cost of\ntolerable quality-loss. A neural approximator can map the input data to output\nwhile a classifier determines whether the input data are safe to approximate\nwith quality guarantee. However, existing works cannot maximize the invocation\nof the approximator, resulting in limited speedup and energy saving. By\nexploring the mapping space of those target functions, in this paper, we\nobserve a nonuniform distribution of the approximation error incurred by the\nsame approximator. We thus propose a novel approximate computing architecture\nwith a Multiclass-Classifier and Multiple Approximators (MCMA). These\napproximators have identical network topologies and thus can share the same\nhardware resource in a neural processing unit(NPU) clip. In the runtime, MCMA\ncan swap in the invoked approximator by merely shipping the synapse weights\nfrom the on-chip memory to the buffers near MAC within a cycle. We also propose\nefficient co-training methods for such MCMA architecture. Experimental results\nshow a more substantial invocation of MCMA as well as the gain of\nenergy-efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 07:37:31 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Song", "Haiyue", ""], ["Xu", "Chengwen", ""], ["Xu", "Qiang", ""], ["Song", "Zhuoran", ""], ["Jing", "Naifeng", ""], ["Liang", "Xiaoyao", ""], ["Jiang", "Li", ""]]}, {"id": "1810.08480", "submitter": "Edouard Pauwels", "authors": "Edouard Pauwels, Mihai Putinar (UCSB), Jean-Bernard Lasserre\n  (LAAS-MAC)", "title": "Data analysis from empirical moments and the Christoffel function", "comments": null, "journal-ref": null, "doi": null, "report-no": "Rapport LAAS n{\\textdegree} 18219", "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral features of the empirical moment matrix constitute a resourceful\ntool for unveiling properties of a cloud of points, among which, density,\nsupport and latent structures. It is already well known that the empirical\nmoment matrix encodes a great deal of subtle attributes of the underlying\nmeasure. Starting from this object as base of observations we combine ideas\nfrom statistics, real algebraic geometry, orthogonal polynomials and\napproximation theory for opening new insights relevant for Machine Learning\n(ML) problems with data supported on singular sets. Refined concepts and\nresults from real algebraic geometry and approximation theory are empowering a\nsimple tool (the empirical moment matrix) for the task of solving non-trivial\nquestions in data analysis. We provide (1) theoretical support, (2) numerical\nexperiments and, (3) connections to real world data as a validation of the\nstamina of the empirical moment matrix approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 13:12:09 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:53:07 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Pauwels", "Edouard", "", "UCSB"], ["Putinar", "Mihai", "", "UCSB"], ["Lasserre", "Jean-Bernard", "", "LAAS-MAC"]]}, {"id": "1810.08515", "submitter": "Mark Schutera", "authors": "Mark Schutera, Niklas Goby, Dirk Neumann, Markus Reischl", "title": "Transfer Learning versus Multi-agent Learning regarding Distributed\n  Decision-Making in Highway Traffic", "comments": "Proc. of the 10th International Workshop on Agents in Traffic and\n  Transportation (ATT 2018), co-located with ECAI/IJCAI, AAMAS and ICML 2018\n  conferences (FAIM 2018)", "journal-ref": "CEUR Workshop Proceedings 2018", "doi": null, "report-no": "CEUR-WS.org/Vol-2129", "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation and traffic are currently undergoing a rapid increase in terms\nof both scale and complexity. At the same time, an increasing share of traffic\nparticipants are being transformed into agents driven or supported by\nartificial intelligence resulting in mixed-intelligence traffic. This work\nexplores the implications of distributed decision-making in mixed-intelligence\ntraffic. The investigations are carried out on the basis of an online-simulated\nhighway scenario, namely the MIT \\emph{DeepTraffic} simulation. In the first\nstep traffic agents are trained by means of a deep reinforcement learning\napproach, being deployed inside an elitist evolutionary algorithm for\nhyperparameter search. The resulting architectures and training parameters are\nthen utilized in order to either train a single autonomous traffic agent and\ntransfer the learned weights onto a multi-agent scenario or else to conduct\nmulti-agent learning directly. Both learning strategies are evaluated on\ndifferent ratios of mixed-intelligence traffic. The strategies are assessed\naccording to the average speed of all agents driven by artificial intelligence.\nTraffic patterns that provoke a reduction in traffic flow are analyzed with\nrespect to the different strategies.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 14:16:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Schutera", "Mark", ""], ["Goby", "Niklas", ""], ["Neumann", "Dirk", ""], ["Reischl", "Markus", ""]]}, {"id": "1810.08537", "submitter": "Leo Duan", "authors": "Leo L Duan, David B Dunson", "title": "Bayesian Distance Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based clustering is widely-used in a variety of application areas.\nHowever, fundamental concerns remain about robustness. In particular, results\ncan be sensitive to the choice of kernel representing the within-cluster data\ndensity. Leveraging on properties of pairwise differences between data points,\nwe propose a class of Bayesian distance clustering methods, which rely on\nmodeling the likelihood of the pairwise distances in place of the original\ndata. Although some information in the data is discarded, we gain substantial\nrobustness to modeling assumptions. The proposed approach represents an\nappealing middle ground between distance- and model-based clustering, drawing\nadvantages from each of these canonical approaches. We illustrate dramatic\ngains in the ability to infer clusters that are not well represented by the\nusual choices of kernel. A simulation study is included to assess performance\nrelative to competitors, and we apply the approach to clustering of brain\ngenome expression data.\n  Keywords: Distance-based clustering; Mixture model; Model-based clustering;\nModel misspecification; Pairwise distance matrix; Partial likelihood;\nRobustness.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:09:08 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:48:35 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Duan", "Leo L", ""], ["Dunson", "David B", ""]]}, {"id": "1810.08552", "submitter": "Ravi Patel", "authors": "Ravi G. Patel and Olivier Desjardins", "title": "Nonlinear integro-differential operator regression with neural networks", "comments": "5 pages, 3 figures, preprint submitted to the Journal of\n  Computational Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note introduces a regression technique for finding a class of nonlinear\nintegro-differential operators from data. The method parametrizes the spatial\noperator with neural networks and Fourier transforms such that it can fit a\nclass of nonlinear operators without needing a library of a priori selected\noperators. We verify that this method can recover the spatial operators in the\nfractional heat equation and the Kuramoto-Sivashinsky equation from numerical\nsolutions of the equations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:33:59 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Patel", "Ravi G.", ""], ["Desjardins", "Olivier", ""]]}, {"id": "1810.08553", "submitter": "Santiago Silva", "authors": "Santiago Silva, Boris Gutman, Eduardo Romero, Paul M Thompson, Andre\n  Altmann, Marco Lorenzi", "title": "Federated Learning in Distributed Medical Databases: Meta-Analysis of\n  Large-Scale Subcortical Brain Data", "comments": "Federated learning, distributed databases, PCA, SVD, meta-analysis,\n  brain disease", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At this moment, databanks worldwide contain brain images of previously\nunimaginable numbers. Combined with developments in data science, these massive\ndata provide the potential to better understand the genetic underpinnings of\nbrain diseases. However, different datasets, which are stored at different\ninstitutions, cannot always be shared directly due to privacy and legal\nconcerns, thus limiting the full exploitation of big data in the study of brain\ndisorders. Here we propose a federated learning framework for securely\naccessing and meta-analyzing any biomedical data without sharing individual\ninformation. We illustrate our framework by investigating brain structural\nrelationships across diseases and clinical cohorts. The framework is first\ntested on synthetic data and then applied to multi-centric, multi-database\nstudies including ADNI, PPMI, MIRIAD and UK Biobank, showing the potential of\nthe approach for further applications in distributed analysis of multi-centric\ncohorts\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:36:35 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 08:40:43 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 16:13:30 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Silva", "Santiago", ""], ["Gutman", "Boris", ""], ["Romero", "Eduardo", ""], ["Thompson", "Paul M", ""], ["Altmann", "Andre", ""], ["Lorenzi", "Marco", ""]]}, {"id": "1810.08559", "submitter": "Alexander Wong", "authors": "Zhong Qiu Lin, Audrey G. Chung, and Alexander Wong", "title": "EdgeSpeechNets: Highly Efficient Deep Neural Networks for Speech\n  Recognition on the Edge", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite showing state-of-the-art performance, deep learning for speech\nrecognition remains challenging to deploy in on-device edge scenarios such as\nmobile and other consumer devices. Recently, there have been greater efforts in\nthe design of small, low-footprint deep neural networks (DNNs) that are more\nappropriate for edge devices, with much of the focus on design principles for\nhand-crafting efficient network architectures. In this study, we explore a\nhuman-machine collaborative design strategy for building low-footprint DNN\narchitectures for speech recognition through a marriage of human-driven\nprincipled network design prototyping and machine-driven design exploration.\nThe efficacy of this design strategy is demonstrated through the design of a\nfamily of highly-efficient DNNs (nicknamed EdgeSpeechNets) for\nlimited-vocabulary speech recognition. Experimental results using the Google\nSpeech Commands dataset for limited-vocabulary speech recognition showed that\nEdgeSpeechNets have higher accuracies than state-of-the-art DNNs (with the best\nEdgeSpeechNet achieving ~97% accuracy), while achieving significantly smaller\nnetwork sizes (as much as 7.8x smaller) and lower computational cost (as much\nas 36x fewer multiply-add operations, 10x lower prediction latency, and 16x\nsmaller memory footprint on a Motorola Moto E phone), making them very\nwell-suited for on-device edge voice interface applications.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 00:47:20 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 19:25:08 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Lin", "Zhong Qiu", ""], ["Chung", "Audrey G.", ""], ["Wong", "Alexander", ""]]}, {"id": "1810.08564", "submitter": "Mingyuan Zhou", "authors": "Quan Zhang and Mingyuan Zhou", "title": "Nonparametric Bayesian Lomax delegate racing for survival analysis with\n  competing risks", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Lomax delegate racing (LDR) to explicitly model the mechanism of\nsurvival under competing risks and to interpret how the covariates accelerate\nor decelerate the time to event. LDR explains non-monotonic covariate effects\nby racing a potentially infinite number of sub-risks, and consequently relaxes\nthe ubiquitous proportional-hazards assumption which may be too restrictive.\nMoreover, LDR is naturally able to model not only censoring, but also missing\nevent times or event types. For inference, we develop a Gibbs sampler under\ndata augmentation for moderately sized data, along with a stochastic gradient\ndescent maximum a posteriori inference algorithm for big data applications.\nIllustrative experiments are provided on both synthetic and real datasets, and\ncomparison with various benchmark algorithms for survival analysis with\ncompeting risks demonstrates distinguished performance of LDR.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:57:22 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 00:48:10 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Zhang", "Quan", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1810.08575", "submitter": "Paul Christiano", "authors": "Paul Christiano, Buck Shlegeris, Dario Amodei", "title": "Supervising strong learners by amplifying weak experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world learning tasks involve complex or hard-to-specify objectives,\nand using an easier-to-specify proxy can lead to poor performance or misaligned\nbehavior. One solution is to have humans provide a training signal by\ndemonstrating or judging performance, but this approach fails if the task is\ntoo complicated for a human to directly evaluate. We propose Iterated\nAmplification, an alternative training strategy which progressively builds up a\ntraining signal for difficult problems by combining solutions to easier\nsubproblems. Iterated Amplification is closely related to Expert Iteration\n(Anthony et al., 2017; Silver et al., 2017), except that it uses no external\nreward function. We present results in algorithmic environments, showing that\nIterated Amplification can efficiently learn complex behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 16:30:48 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Christiano", "Paul", ""], ["Shlegeris", "Buck", ""], ["Amodei", "Dario", ""]]}, {"id": "1810.08591", "submitter": "Brady Neal", "authors": "Brady Neal, Sarthak Mittal, Aristide Baratin, Vinayak Tantia, Matthew\n  Scicluna, Simon Lacoste-Julien, Ioannis Mitliagkas", "title": "A Modern Take on the Bias-Variance Tradeoff in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bias-variance tradeoff tells us that as model complexity increases, bias\nfalls and variances increases, leading to a U-shaped test error curve. However,\nrecent empirical results with over-parameterized neural networks are marked by\na striking absence of the classic U-shaped test error curve: test error keeps\ndecreasing in wider networks. This suggests that there might not be a\nbias-variance tradeoff in neural networks with respect to network width, unlike\nwas originally claimed by, e.g., Geman et al. (1992). Motivated by the shaky\nevidence used to support this claim in neural networks, we measure bias and\nvariance in the modern setting. We find that both bias and variance can\ndecrease as the number of parameters grows. To better understand this, we\nintroduce a new decomposition of the variance to disentangle the effects of\noptimization and data sampling. We also provide theoretical analysis in a\nsimplified setting that is consistent with our empirical findings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 17:19:38 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 14:55:04 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 15:05:50 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2019 20:35:59 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Neal", "Brady", ""], ["Mittal", "Sarthak", ""], ["Baratin", "Aristide", ""], ["Tantia", "Vinayak", ""], ["Scicluna", "Matthew", ""], ["Lacoste-Julien", "Simon", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1810.08609", "submitter": "Mohendra Roy (PhD)", "authors": "Mohendra Roy, Sumon Kumar Bose, Bapi Kar, Pradeep Kumar\n  Gopalakrishnan, Arindam Basu", "title": "A Stacked Autoencoder Neural Network based Automated Feature Extraction\n  Method for Anomaly detection in On-line Condition Monitoring", "comments": "This article has been submitted to IEEE-SSCI 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Condition monitoring is one of the routine tasks in all major process\nindustries. The mechanical parts such as a motor, gear, bearings are the major\ncomponents of a process industry and any fault in them may cause a total\nshutdown of the whole process, which may result in serious losses. Therefore,\nit is very crucial to predict any approaching defects before its occurrence.\nSeveral methods exist for this purpose and many research are being carried out\nfor better and efficient models. However, most of them are based on the\nprocessing of raw sensor signals, which is tedious and expensive. Recently,\nthere has been an increase in the feature based condition monitoring, where\nonly the useful features are extracted from the raw signals and interpreted for\nthe prediction of the fault. Most of these are handcrafted features, where\nthese are manually obtained based on the nature of the raw data. This of course\nrequires the prior knowledge of the nature of data and related processes. This\nlimits the feature extraction process. However, recent development in the\nautoencoder based feature extraction method provides an alternative to the\ntraditional handcrafted approaches; however, they have mostly been confined in\nthe area of image and audio processing. In this work, we have developed an\nautomated feature extraction method for on-line condition monitoring based on\nthe stack of the traditional autoencoder and an on-line sequential extreme\nlearning machine(OSELM) network. The performance of this method is comparable\nto that of the traditional feature extraction approaches. The method can\nachieve 100% detection accuracy for determining the bearing health states of\nNASA bearing dataset. The simple design of this method is promising for the\neasy hardware implementation of Internet of Things(IoT) based prognostics\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 03:53:47 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Roy", "Mohendra", ""], ["Bose", "Sumon Kumar", ""], ["Kar", "Bapi", ""], ["Gopalakrishnan", "Pradeep Kumar", ""], ["Basu", "Arindam", ""]]}, {"id": "1810.08612", "submitter": "Denis Parkhomenko", "authors": "D.Babin, I.Mazurenko, D.Parkhomenko, A.Voloshko", "title": "CNN inference acceleration using dictionary of centroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  It is well known that multiplication operations in convolutional layers of\ncommon CNNs consume a lot of time during inference stage. In this article we\npresent a flexible method to decrease both computational complexity of\nconvolutional layers in inference as well as amount of space to store them. The\nmethod is based on centroid filter quantization and outperforms approaches\nbased on tensor decomposition by a large margin. We performed comparative\nanalysis of the proposed method and series of CP tensor decomposition on\nImageNet benchmark and found that our method provide almost 2.9 times better\ncomputational gain. Despite the simplicity of our method it cannot be applied\ndirectly in inference stage in modern frameworks, but could be useful for cases\ncalculation flow could be changed, e.g. for CNN-chip designers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 13:12:13 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Babin", "D.", ""], ["Mazurenko", "I.", ""], ["Parkhomenko", "D.", ""], ["Voloshko", "A.", ""]]}, {"id": "1810.08635", "submitter": "Jacqueline Hughes-Oliver", "authors": "Jacqueline M. Hughes-Oliver", "title": "Population and Empirical PR Curves for Assessment of Ranking Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ROC curve is widely used to assess the quality of\nprediction/classification/ranking algorithms, and its properties have been\nextensively studied. The precision-recall (PR) curve has become the de facto\nreplacement for the ROC curve in the presence of imbalance, namely where one\nclass is far more likely than the other class. While the PR and ROC curves tend\nto be used interchangeably, they have some very different properties.\nProperties of the PR curve are the focus of this paper. We consider: (1)\npopulation PR curves, where complete distributional assumptions are specified\nfor scores from both classes; and (2) empirical estimators of the PR curve,\nwhere we observe scores and no distributional assumptions are made. The\nproperties have direct consequence on how the PR curve should, and should not,\nbe used. For example, the empirical PR curve is not consistent when scores in\nthe class of primary interest come from discrete distributions. On the other\nhand, a normal approximation can fit quite well for points on the empirical PR\ncurve from continuously-defined scores, but convergence can be heavily\ninfluenced by the distributional setting, the amount of imbalance, and the\npoint of interest on the PR curve.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 18:29:27 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hughes-Oliver", "Jacqueline M.", ""]]}, {"id": "1810.08640", "submitter": "Tsui-Wei Weng", "authors": "Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Aurelie Lozano, Cho-Jui Hsieh,\n  Luca Daniel", "title": "On Extensions of CLEVER: A Neural Network Robustness Evaluation\n  Algorithm", "comments": "Accepted by GlobalSIP 2018. Tsui-Wei Weng and Huan Zhang contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CLEVER (Cross-Lipschitz Extreme Value for nEtwork Robustness) is an Extreme\nValue Theory (EVT) based robustness score for large-scale deep neural networks\n(DNNs). In this paper, we propose two extensions on this robustness score.\nFirst, we provide a new formal robustness guarantee for classifier functions\nthat are twice differentiable. We apply extreme value theory on the new formal\nrobustness guarantee and the estimated robustness is called second-order CLEVER\nscore. Second, we discuss how to handle gradient masking, a common defensive\ntechnique, using CLEVER with Backward Pass Differentiable Approximation (BPDA).\nWith BPDA applied, CLEVER can evaluate the intrinsic robustness of neural\nnetworks of a broader class -- networks with non-differentiable input\ntransformations. We demonstrate the effectiveness of CLEVER with BPDA in\nexperiments on a 121-layer Densenet model trained on the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 18:44:58 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Weng", "Tsui-Wei", ""], ["Zhang", "Huan", ""], ["Chen", "Pin-Yu", ""], ["Lozano", "Aurelie", ""], ["Hsieh", "Cho-Jui", ""], ["Daniel", "Luca", ""]]}, {"id": "1810.08646", "submitter": "Sumit Bam Shrestha", "authors": "Sumit Bam Shrestha and Garrick Orchard", "title": "SLAYER: Spike Layer Error Reassignment in Time", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configuring deep Spiking Neural Networks (SNNs) is an exciting research\navenue for low power spike event based computation. However, the spike\ngeneration function is non-differentiable and therefore not directly compatible\nwith the standard error backpropagation algorithm. In this paper, we introduce\na new general backpropagation mechanism for learning synaptic weights and\naxonal delays which overcomes the problem of non-differentiability of the spike\nfunction and uses a temporal credit assignment policy for backpropagating error\nto preceding layers. We describe and release a GPU accelerated software\nimplementation of our method which allows training both fully connected and\nconvolutional neural network (CNN) architectures. Using our software, we\ncompare our method against existing SNN based learning approaches and standard\nANN to SNN conversion techniques and show that our method achieves state of the\nart performance for an SNN on the MNIST, NMNIST, DVS Gesture, and TIDIGITS\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 10:10:03 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Shrestha", "Sumit Bam", ""], ["Orchard", "Garrick", ""]]}, {"id": "1810.08647", "submitter": "Natasha Jaques", "authors": "Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre,\n  Pedro A. Ortega, DJ Strouse, Joel Z. Leibo, Nando de Freitas", "title": "Social Influence as Intrinsic Motivation for Multi-Agent Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified mechanism for achieving coordination and communication\nin Multi-Agent Reinforcement Learning (MARL), through rewarding agents for\nhaving causal influence over other agents' actions. Causal influence is\nassessed using counterfactual reasoning. At each timestep, an agent simulates\nalternate actions that it could have taken, and computes their effect on the\nbehavior of other agents. Actions that lead to bigger changes in other agents'\nbehavior are considered influential and are rewarded. We show that this is\nequivalent to rewarding agents for having high mutual information between their\nactions. Empirical results demonstrate that influence leads to enhanced\ncoordination and communication in challenging social dilemma environments,\ndramatically increasing the learning curves of the deep RL agents, and leading\nto more meaningful learned communication protocols. The influence rewards for\nall agents can be computed in a decentralized way by enabling agents to learn a\nmodel of other agents using deep neural networks. In contrast, key previous\nworks on emergent communication in the MARL setting were unable to learn\ndiverse policies in a decentralized manner and had to resort to centralized\ntraining. Consequently, the influence reward opens up a window of new\nopportunities for research in this area.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 19:01:15 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 22:44:48 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 23:52:07 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 21:39:08 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Jaques", "Natasha", ""], ["Lazaridou", "Angeliki", ""], ["Hughes", "Edward", ""], ["Gulcehre", "Caglar", ""], ["Ortega", "Pedro A.", ""], ["Strouse", "DJ", ""], ["Leibo", "Joel Z.", ""], ["de Freitas", "Nando", ""]]}, {"id": "1810.08651", "submitter": "Jessica Thompson", "authors": "Jessica A. F. Thompson, Yoshua Bengio, Elia Formisano, and Marc\n  Sch\\\"onwiesner", "title": "How can deep learning advance computational modeling of sensory\n  information processing?", "comments": "Presented at MLINI-2016 workshop, 2016 (arXiv:1701.01437)", "journal-ref": null, "doi": null, "report-no": "MLINI/2016/04", "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, computational neuroscience, and cognitive science have\noverlapping goals related to understanding intelligence such that perception\nand behaviour can be simulated in computational systems. In neuroimaging,\nmachine learning methods have been used to test computational models of sensory\ninformation processing. Recently, these model comparison techniques have been\nused to evaluate deep neural networks (DNNs) as models of sensory information\nprocessing. However, the interpretation of such model evaluations is muddied by\nimprecise statistical conclusions. Here, we make explicit the types of\nconclusions that can be drawn from these existing model comparison techniques\nand how these conclusions change when the model in question is a DNN. We\ndiscuss how DNNs are amenable to new model comparison techniques that allow for\nstronger conclusions to be made about the computational mechanisms underlying\nsensory information processing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 23:39:34 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Thompson", "Jessica A. F.", ""], ["Bengio", "Yoshua", ""], ["Formisano", "Elia", ""], ["Sch\u00f6nwiesner", "Marc", ""]]}, {"id": "1810.08676", "submitter": "Kommy Weldemariam Dr", "authors": "Skyler Speakman, Srihari Sridharan, Sekou Remy, Komminist Weldemariam,\n  Edward McFowland", "title": "Subset Scanning Over Neural Network Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work views neural networks as data generating systems and applies\nanomalous pattern detection techniques on that data in order to detect when a\nnetwork is processing an anomalous input. Detecting anomalies is a critical\ncomponent for multiple machine learning problems including detecting\nadversarial noise. More broadly, this work is a step towards giving neural\nnetworks the ability to recognize an out-of-distribution sample. This is the\nfirst work to introduce \"Subset Scanning\" methods from the anomalous pattern\ndetection domain to the task of detecting anomalous input of neural networks.\nSubset scanning treats the detection problem as a search for the most anomalous\nsubset of node activations (i.e., highest scoring subset according to\nnon-parametric scan statistics). Mathematical properties of these scoring\nfunctions allow the search to be completed in log-linear rather than\nexponential time while still guaranteeing the most anomalous subset of nodes in\nthe network is identified for a given input. Quantitative results for detecting\nand characterizing adversarial noise are provided for CIFAR-10 images on a\nsimple convolutional neural network. We observe an \"interference\" pattern where\nanomalous activations in shallow layers suppress the activation structure of\nthe original image in deeper layers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:22:53 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Speakman", "Skyler", ""], ["Sridharan", "Srihari", ""], ["Remy", "Sekou", ""], ["Weldemariam", "Komminist", ""], ["McFowland", "Edward", ""]]}, {"id": "1810.08677", "submitter": "Matthew Turner", "authors": "Matthew A. Turner", "title": "A neural network to classify metaphorical violence on cable news", "comments": "6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I present here an experimental system for identifying and annotating metaphor\nin corpora. It is designed to plug in to Metacorps, an experimental web app for\nannotating metaphor. As Metacorps users annotate metaphors, the system will use\nuser annotations as training data. When the system is confident, it will\nsuggest an identification and an annotation. Once approved by the user, this\nbecomes more training data. This naturally allows for transfer learning, where\nthe system can, with some known degree of reliability, classify one class of\nmetaphor after only being trained on another class of metaphor. For example, in\nour metaphorical violence project, metaphors may be classified by the network\nthey were observed on, the grammatical subject or object of the violence\nmetaphor, or the violent word used (hit, attack, beat, etc.).\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:22:53 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Turner", "Matthew A.", ""]]}, {"id": "1810.08678", "submitter": "Zhenpeng Zhou", "authors": "Zhenpeng Zhou, Steven Kearnes, Li Li, Richard N. Zare, and Patrick\n  Riley", "title": "Optimization of Molecules via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-019-47148-x", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework, which we call Molecule Deep $Q$-Networks (MolDQN),\nfor molecule optimization by combining domain knowledge of chemistry and\nstate-of-the-art reinforcement learning techniques (double $Q$-learning and\nrandomized value functions). We directly define modifications on molecules,\nthereby ensuring 100\\% chemical validity. Further, we operate without\npre-training on any dataset to avoid possible bias from the choice of that set.\nInspired by problems faced during medicinal chemistry lead optimization, we\nextend our model with multi-objective reinforcement learning, which maximizes\ndrug-likeness while maintaining similarity to the original molecule. We further\nshow the path through chemical space to achieve optimization for a molecule to\nunderstand how the model works.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:23:44 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 05:28:46 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 01:46:11 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Zhou", "Zhenpeng", ""], ["Kearnes", "Steven", ""], ["Li", "Li", ""], ["Zare", "Richard N.", ""], ["Riley", "Patrick", ""]]}, {"id": "1810.08683", "submitter": "Michele Donini", "authors": "Luca Oneto, Michele Donini, Amon Elders, Massimiliano Pontil", "title": "Taking Advantage of Multitask Learning for Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A central goal of algorithmic fairness is to reduce bias in automated\ndecision making. An unavoidable tension exists between accuracy gains obtained\nby using sensitive information (e.g., gender or ethnic group) as part of a\nstatistical model, and any commitment to protect these characteristics. Often,\ndue to biases present in the data, using the sensitive information in the\nfunctional form of a classifier improves classification accuracy. In this paper\nwe show how it is possible to get the best of both worlds: optimize model\naccuracy and fairness without explicitly using the sensitive feature in the\nfunctional form of the model, thereby treating different individuals equally.\nOur method is based on two key ideas. On the one hand, we propose to use\nMultitask Learning (MTL), enhanced with fairness constraints, to jointly learn\ngroup specific classifiers that leverage information between sensitive groups.\nOn the other hand, since learning group specific models might not be permitted,\nwe propose to first predict the sensitive features by any learning method and\nthen to use the predicted sensitive feature to train MTL with fairness\nconstraints. This enables us to tackle fairness with a three-pronged approach,\nthat is, by increasing accuracy on each group, enforcing measures of fairness\nduring training, and protecting sensitive information during testing.\nExperimental results on two real datasets support our proposal, showing\nsubstantial improvements in both accuracy and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:34:46 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 08:03:05 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Oneto", "Luca", ""], ["Donini", "Michele", ""], ["Elders", "Amon", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1810.08726", "submitter": "Yong Liu Stephen", "authors": "Yong Liu, Min Wu, Chenghao Liu, Xiao-Li Li, Jie Zheng", "title": "SL$^2$MF: Predicting Synthetic Lethality in Human Cancers via Logistic\n  Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic lethality (SL) is a promising concept for novel discovery of\nanti-cancer drug targets. However, wet-lab experiments for detecting SLs are\nfaced with various challenges, such as high cost, low consistency across\nplatforms or cell lines. Therefore, computational prediction methods are needed\nto address these issues. This paper proposes a novel SL prediction method,\nnamed SL2MF, which employs logistic matrix factorization to learn latent\nrepresentations of genes from the observed SL data. The probability that two\ngenes are likely to form SL is modeled by the linear combination of gene latent\nvectors. As known SL pairs are more trustworthy than unknown pairs, we design\nimportance weighting schemes to assign higher importance weights for known SL\npairs and lower importance weights for unknown pairs in SL2MF. Moreover, we\nalso incorporate biological knowledge about genes from protein-protein\ninteraction (PPI) data and Gene Ontology (GO). In particular, we calculate the\nsimilarity between genes based on their GO annotations and topological\nproperties in the PPI network. Extensive experiments on the SL interaction data\nfrom SynLethDB database have been conducted to demonstrate the effectiveness of\nSL2MF.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 01:33:07 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Liu", "Yong", ""], ["Wu", "Min", ""], ["Liu", "Chenghao", ""], ["Li", "Xiao-Li", ""], ["Zheng", "Jie", ""]]}, {"id": "1810.08727", "submitter": "Paul Grigas", "authors": "Robert M. Freund, Paul Grigas, Rahul Mazumder", "title": "Condition Number Analysis of Logistic Regression, and its Implications\n  for Standard First-Order Solution Methods", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression is one of the most popular methods in binary\nclassification, wherein estimation of model parameters is carried out by\nsolving the maximum likelihood (ML) optimization problem, and the ML estimator\nis defined to be the optimal solution of this problem. It is well known that\nthe ML estimator exists when the data is non-separable, but fails to exist when\nthe data is separable. First-order methods are the algorithms of choice for\nsolving large-scale instances of the logistic regression problem. In this\npaper, we introduce a pair of condition numbers that measure the degree of\nnon-separability or separability of a given dataset in the setting of binary\nclassification, and we study how these condition numbers relate to and inform\nthe properties and the convergence guarantees of first-order methods. When the\ntraining data is non-separable, we show that the degree of non-separability\nnaturally enters the analysis and informs the properties and convergence\nguarantees of two standard first-order methods: steepest descent (for any given\nnorm) and stochastic gradient descent. Expanding on the work of Bach, we also\nshow how the degree of non-separability enters into the analysis of linear\nconvergence of steepest descent (without needing strong convexity), as well as\nthe adaptive convergence of stochastic gradient descent. When the training data\nis separable, first-order methods rather curiously have good empirical success,\nwhich is not well understood in theory. In the case of separable data, we\ndemonstrate how the degree of separability enters into the analysis of $\\ell_2$\nsteepest descent and stochastic gradient descent for delivering\napproximate-maximum-margin solutions with associated computational guarantees\nas well. This suggests that first-order methods can lead to statistically\nmeaningful solutions in the separable case, even though the ML solution does\nnot exist.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 01:37:20 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Freund", "Robert M.", ""], ["Grigas", "Paul", ""], ["Mazumder", "Rahul", ""]]}, {"id": "1810.08732", "submitter": "Eda Okur", "authors": "Eda Okur and Hakan Demir and Arzucan \\\"Ozg\\\"ur", "title": "Named Entity Recognition on Twitter for Turkish using Semi-supervised\n  Learning with Word Embeddings", "comments": "Proceedings of the Tenth International Conference on Language\n  Resources and Evaluation (LREC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to the increasing popularity of social media, the necessity for\nextracting information from informal text types, such as microblog texts, has\ngained significant attention. In this study, we focused on the Named Entity\nRecognition (NER) problem on informal text types for Turkish. We utilized a\nsemi-supervised learning approach based on neural networks. We applied a fast\nunsupervised method for learning continuous representations of words in vector\nspace. We made use of these obtained word embeddings, together with language\nindependent features that are engineered to work better on informal text types,\nfor generating a Turkish NER system on microblog texts. We evaluated our\nTurkish NER system on Twitter messages and achieved better F-score performances\nthan the published results of previously proposed NER systems on Turkish\ntweets. Since we did not employ any language dependent features, we believe\nthat our method can be easily adapted to microblog texts in other\nmorphologically rich languages.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 02:00:35 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Okur", "Eda", ""], ["Demir", "Hakan", ""], ["\u00d6zg\u00fcr", "Arzucan", ""]]}, {"id": "1810.08743", "submitter": "Christopher Jung", "authors": "Christopher Jung, Sampath Kannan, Neil Lutz", "title": "Quantifying the Burden of Exploration and the Unfairness of Free Riding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-armed bandit setting with a twist. Rather than having\njust one decision maker deciding which arm to pull in each round, we have $n$\ndifferent decision makers (agents). In the simple stochastic setting, we show\nthat a \"free-riding\" agent observing another \"self-reliant\" agent can achieve\njust $O(1)$ regret, as opposed to the regret lower bound of $\\Omega (\\log t)$\nwhen one decision maker is playing in isolation. This result holds whenever the\nself-reliant agent's strategy satisfies either one of two assumptions: (1) each\narm is pulled at least $\\gamma \\ln t$ times in expectation for a constant\n$\\gamma$ that we compute, or (2) the self-reliant agent achieves $o(t)$\nrealized regret with high probability. Both of these assumptions are satisfied\nby standard zero-regret algorithms. Under the second assumption, we further\nshow that the free rider only needs to observe the number of times each arm is\npulled by the self-reliant agent, and not the rewards realized.\n  In the linear contextual setting, each arm has a distribution over parameter\nvectors, each agent has a context vector, and the reward realized when an agent\npulls an arm is the inner product of that agent's context vector with a\nparameter vector sampled from the pulled arm's distribution. We show that the\nfree rider can achieve $O(1)$ regret in this setting whenever the free rider's\ncontext is a small (in $L_2$-norm) linear combination of other agents' contexts\nand all other agents pull each arm $\\Omega (\\log t)$ times with high\nprobability. Again, this condition on the self-reliant players is satisfied by\nstandard zero-regret algorithms like UCB. We also prove a number of lower\nbounds.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:08:52 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 22:22:35 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 01:16:56 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 17:29:49 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Jung", "Christopher", ""], ["Kannan", "Sampath", ""], ["Lutz", "Neil", ""]]}, {"id": "1810.08744", "submitter": "Mark Hamilton", "authors": "Mark Hamilton, Sudarshan Raghunathan, Ilya Matiach, Andrew\n  Schonhoffer, Anand Raman, Eli Barzilay, Karthik Rajendran, Dalitso Banda,\n  Casey Jisoo Hong, Manon Knoertzer, Ben Brodsky, Minsoo Thigpen, Janhavi\n  Suresh Mahajan, Courtney Cochrane, Abhiram Eswaran, Ari Green", "title": "MMLSpark: Unifying Machine Learning Ecosystems at Massive Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Microsoft Machine Learning for Apache Spark (MMLSpark), an\necosystem of enhancements that expand the Apache Spark distributed computing\nlibrary to tackle problems in Deep Learning, Micro-Service Orchestration,\nGradient Boosting, Model Interpretability, and other areas of modern\ncomputation. Furthermore, we present a novel system called Spark Serving that\nallows users to run any Apache Spark program as a distributed, sub-millisecond\nlatency web service backed by their existing Spark Cluster. All MMLSpark\ncontributions have the same API to enable simple composition across frameworks\nand usage across batch, streaming, and RESTful web serving scenarios on static,\nelastic, or serverless clusters. We showcase MMLSpark by creating a method for\ndeep object detection capable of learning without human labeled data and\ndemonstrate its effectiveness for Snow Leopard conservation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:12:59 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 15:39:52 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hamilton", "Mark", ""], ["Raghunathan", "Sudarshan", ""], ["Matiach", "Ilya", ""], ["Schonhoffer", "Andrew", ""], ["Raman", "Anand", ""], ["Barzilay", "Eli", ""], ["Rajendran", "Karthik", ""], ["Banda", "Dalitso", ""], ["Hong", "Casey Jisoo", ""], ["Knoertzer", "Manon", ""], ["Brodsky", "Ben", ""], ["Thigpen", "Minsoo", ""], ["Mahajan", "Janhavi Suresh", ""], ["Cochrane", "Courtney", ""], ["Eswaran", "Abhiram", ""], ["Green", "Ari", ""]]}, {"id": "1810.08749", "submitter": "Borzou Alipourfard", "authors": "Borzou Alipourfard and Jean X. Gao", "title": "Renormalized Normalized Maximum Likelihood and Three-Part Code Criteria\n  For Learning Gaussian Networks", "comments": "This work has been submitted to a journal for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score based learning (SBL) is a promising approach for learning Bayesian\nnetworks in the discrete domain. However, when employing SBL in the continuous\ndomain, one is either forced to move the problem to the discrete domain or use\nmetrics such as BIC/AIC, and these approaches are often lacking. Discretization\ncan have an undesired impact on the accuracy of the results, and BIC/AIC can\nfall short of achieving the desired accuracy. In this paper, we introduce two\nnew scoring metrics for scoring Bayesian networks in the continuous domain: the\nthree-part minimum description length and the renormalized normalized maximum\nlikelihood metric. We rely on the minimum description length principle in\nformulating these metrics. The metrics proposed are free of hyperparameters,\ndecomposable, and are asymptotically consistent. We evaluate our solution by\nstudying the convergence rate of the learned graph to the generating network\nand, also, the structural hamming distance of the learned graph to the\ngenerating network. Our evaluations show that the proposed metrics outperform\ntheir competitors, the BIC/AIC metrics. Furthermore, using the proposed RNML\nmetric, SBL will have the fastest rate of convergence with the smallest\nstructural hamming distance to the generating network.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:46:41 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 13:13:15 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Alipourfard", "Borzou", ""], ["Gao", "Jean X.", ""]]}, {"id": "1810.08750", "submitter": "Hongseok Namkoong", "authors": "John Duchi, Hongseok Namkoong", "title": "Learning Models with Uniform Performance via Distributionally Robust\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common goal in statistics and machine learning is to learn models that can\nperform well against distributional shifts, such as latent heterogeneous\nsubpopulations, unknown covariate shifts, or unmodeled temporal effects. We\ndevelop and analyze a distributionally robust stochastic optimization (DRO)\nframework that learns a model providing good performance against perturbations\nto the data-generating distribution. We give a convex formulation for the\nproblem, providing several convergence guarantees. We prove finite-sample\nminimax upper and lower bounds, showing that distributional robustness\nsometimes comes at a cost in convergence rates. We give limit theorems for the\nlearned parameters, where we fully specify the limiting distribution so that\nconfidence intervals can be computed. On real tasks including generalizing to\nunknown subpopulations, fine-grained recognition, and providing good tail\nperformance, the distributionally robust approach often exhibits improved\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:50:29 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 20:59:12 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 02:39:04 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 05:24:31 GMT"}, {"version": "v5", "created": "Mon, 6 Jul 2020 16:58:54 GMT"}, {"version": "v6", "created": "Sat, 18 Jul 2020 01:20:20 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Duchi", "John", ""], ["Namkoong", "Hongseok", ""]]}, {"id": "1810.08765", "submitter": "Wen-Hao Chen", "authors": "Wen-Hao Chen, Chin-Chi Hsu, Yi-An Lai, Vincent Liu, Mi-Yen Yeh,\n  Shou-De Lin", "title": "Attribute-aware Collaborative Filtering: Survey and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-aware CF models aims at rating prediction given not only the\nhistorical rating from users to items, but also the information associated with\nusers (e.g. age), items (e.g. price), or even ratings (e.g. rating time). This\npaper surveys works in the past decade developing attribute-aware CF systems,\nand discovered that mathematically they can be classified into four different\ncategories. We provide the readers not only the high level mathematical\ninterpretation of the existing works in this area but also the mathematical\ninsight for each category of models. Finally we provide in-depth experiment\nresults comparing the effectiveness of the major works in each category.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 07:29:52 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chen", "Wen-Hao", ""], ["Hsu", "Chin-Chi", ""], ["Lai", "Yi-An", ""], ["Liu", "Vincent", ""], ["Yeh", "Mi-Yen", ""], ["Lin", "Shou-De", ""]]}, {"id": "1810.08802", "submitter": "Mehdi Drissi", "authors": "Mehdi Drissi, Olivia Watkins, Jugal Kalita", "title": "Hierarchical Text Generation using an Outline", "comments": "8 pages, Accepted to International Conference on Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many challenges in natural language processing require generating text,\nincluding language translation, dialogue generation, and speech recognition.\nFor all of these problems, text generation becomes more difficult as the text\nbecomes longer. Current language models often struggle to keep track of\ncoherence for long pieces of text. Here, we attempt to have the model construct\nand use an outline of the text it generates to keep it focused. We find that\nthe usage of an outline improves perplexity. We do not find that using the\noutline improves human evaluation over a simpler baseline, revealing a\ndiscrepancy in perplexity and human perception. Similarly, hierarchical\ngeneration is not found to improve human evaluation scores.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 13:27:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Drissi", "Mehdi", ""], ["Watkins", "Olivia", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.08810", "submitter": "Aaron Roth", "authors": "Alexandra Chouldechova, Aaron Roth", "title": "The Frontiers of Fairness in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last few years have seen an explosion of academic and popular interest in\nalgorithmic fairness. Despite this interest and the volume and velocity of work\nthat has been produced recently, the fundamental science of fairness in machine\nlearning is still in a nascent state. In March 2018, we convened a group of\nexperts as part of a CCC visioning workshop to assess the state of the field,\nand distill the most promising research directions going forward. This report\nsummarizes the findings of that workshop. Along the way, it surveys recent\ntheoretical work in the field and points towards promising directions for\nresearch.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 14:24:05 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chouldechova", "Alexandra", ""], ["Roth", "Aaron", ""]]}, {"id": "1810.08851", "submitter": "Jing Li", "authors": "Jing Li, Rafal K. Mantiuk, Junle Wang, Suiyi Ling, Patrick Le Callet", "title": "Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference\n  Aggregation", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a hybrid active sampling strategy for pairwise\npreference aggregation, which aims at recovering the underlying rating of the\ntest candidates from sparse and noisy pairwise labelling. Our method employs\nBayesian optimization framework and Bradley-Terry model to construct the\nutility function, then to obtain the Expected Information Gain (EIG) of each\npair. For computational efficiency, Gaussian-Hermite quadrature is used for\nestimation of EIG. In this work, a hybrid active sampling strategy is proposed,\neither using Global Maximum (GM) EIG sampling or Minimum Spanning Tree (MST)\nsampling in each trial, which is determined by the test budget. The proposed\nmethod has been validated on both simulated and real-world datasets, where it\nshows higher preference aggregation ability than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 21:31:12 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Li", "Jing", ""], ["Mantiuk", "Rafal K.", ""], ["Wang", "Junle", ""], ["Ling", "Suiyi", ""], ["Callet", "Patrick Le", ""]]}, {"id": "1810.08867", "submitter": "Alireza Rezaei", "authors": "Shayan Oveis Gharan, Alireza Rezaei", "title": "A Polynomial Time MCMC Method for Sampling from Continuous DPPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Gibbs sampling algorithm for continuous determinantal point\nprocesses. We show that, given a warm start, the Gibbs sampler generates a\nrandom sample from a continuous $k$-DPP defined on a $d$-dimensional domain by\nonly taking $\\text{poly}(k)$ number of steps. As an application, we design an\nalgorithm to generate random samples from $k$-DPPs defined by a spherical\nGaussian kernel on a unit sphere in $d$-dimensions, $\\mathbb{S}^{d-1}$ in time\npolynomial in $k,d$.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 23:29:40 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Gharan", "Shayan Oveis", ""], ["Rezaei", "Alireza", ""]]}, {"id": "1810.08869", "submitter": "Ryan Kim", "authors": "Biresh Kumar Joardar, Ryan Gary Kim, Janardhan Rao Doppa, Partha\n  Pratim Pande, Diana Marculescu, and Radu Marculescu", "title": "Learning-based Application-Agnostic 3D NoC Design for Heterogeneous\n  Manycore Systems", "comments": "Published in IEEE Transactions on Computers", "journal-ref": "IEEE Transactions on Computers, vol. 68, no. 6, June 2019", "doi": "10.1109/TC.2018.2889053", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising use of deep learning and other big-data algorithms has led to an\nincreasing demand for hardware platforms that are computationally powerful, yet\nenergy-efficient. Due to the amount of data parallelism in these algorithms,\nhigh-performance 3D manycore platforms that incorporate both CPUs and GPUs\npresent a promising direction. However, as systems use heterogeneity (e.g., a\ncombination of CPUs, GPUs, and accelerators) to improve performance and\nefficiency, it becomes more pertinent to address the distinct and likely\nconflicting communication requirements (e.g., CPU memory access latency or GPU\nnetwork throughput) that arise from such heterogeneity. Unfortunately, it is\ndifficult to quickly explore the hardware design space and choose appropriate\ntradeoffs between these heterogeneous requirements. To address these\nchallenges, we propose the design of a 3D Network-on-Chip (NoC) for\nheterogeneous manycore platforms that considers the appropriate design\nobjectives for a 3D heterogeneous system and explores various tradeoffs using\nan efficient ML-based multi-objective optimization technique. The proposed\ndesign space exploration considers the various requirements of its\nheterogeneous components and generates a set of 3D NoC architectures that\nefficiently trades off these design objectives. Our findings show that by\njointly considering these requirements (latency, throughput, temperature, and\nenergy), we can achieve 9.6% better Energy-Delay Product on average at nearly\niso-temperature conditions when compared to a thermally-optimized design for 3D\nheterogeneous NoCs. More importantly, our results suggest that our 3D NoCs\noptimized for a few applications can be generalized for unknown applications as\nwell. Our results show that these generalized 3D NoCs only incur a 1.8%\n(36-tile system) and 1.1% (64-tile system) average performance loss compared to\napplication-specific NoCs.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 23:46:14 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 15:06:54 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Joardar", "Biresh Kumar", ""], ["Kim", "Ryan Gary", ""], ["Doppa", "Janardhan Rao", ""], ["Pande", "Partha Pratim", ""], ["Marculescu", "Diana", ""], ["Marculescu", "Radu", ""]]}, {"id": "1810.08875", "submitter": "Masun Nabhan Homsi", "authors": "Philip Warrick and Masun Nabhan Homsi", "title": "Sleep Arousal Detection from Polysomnography using the Scattering\n  Transform and Recurrent Neural Networks", "comments": "Computing in Cardiology 2018, 4 pages and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sleep disorders are implicated in a growing number of health problems. In\nthis paper, we present a signal-processing/machine learning approach to\ndetecting arousals in the multi-channel polysomnographic recordings of the\nPhysionet/CinC Challenge2018 dataset.\n  Methods: Our network architecture consists of two components. Inputs were\npresented to a Scattering Transform (ST) representation layer which fed a\nrecurrent neural network for sequence learning using three layers of Long\nShort-Term Memory (LSTM). The STs were calculated for each signal with\ndownsampling parameters chosen to give approximately 1 s time resolution,\nresulting in an eighteen-fold data reduction. The LSTM layers then operated at\nthis downsampled rate.\n  Results: The proposed approach detected arousal regions on the 10% random\nsample of the hidden test set with an AUROC of 88.0% and an AUPRC of 42.1%.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 00:42:58 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Warrick", "Philip", ""], ["Homsi", "Masun Nabhan", ""]]}, {"id": "1810.08899", "submitter": "Jie Ren", "authors": "Qing Qin, Jie Ren, Jialong Yu, Ling Gao, Hai Wang, Jie Zheng, Yansong\n  Feng, Jianbin Fang, Zheng Wang", "title": "To Compress, or Not to Compress: Characterizing Deep Learning Model\n  Compression for Embedded Inference", "comments": "8 pages, To appear in ISPA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep neural networks (DNNs) make them attractive for\nembedded systems. However, it can take a long time for DNNs to make an\ninference on resource-constrained computing devices. Model compression\ntechniques can address the computation issue of deep inference on embedded\ndevices. This technique is highly attractive, as it does not rely on\nspecialized hardware, or computation-offloading that is often infeasible due to\nprivacy concerns or high latency. However, it remains unclear how model\ncompression techniques perform across a wide range of DNNs. To design efficient\nembedded deep learning solutions, we need to understand their behaviors. This\nwork develops a quantitative approach to characterize model compression\ntechniques on a representative embedded deep learning architecture, the NVIDIA\nJetson Tx2. We perform extensive experiments by considering 11 influential\nneural network architectures from the image classification and the natural\nlanguage processing domains. We experimentally show that how two mainstream\ncompression techniques, data quantization and pruning, perform on these network\narchitectures and the implications of compression techniques to the model\nstorage size, inference time, energy consumption and performance metrics. We\ndemonstrate that there are opportunities to achieve fast deep inference on\nembedded systems, but one must carefully choose the compression settings. Our\nresults provide insights on when and how to apply model compression techniques\nand guidelines for designing efficient embedded deep learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 05:09:45 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Qin", "Qing", ""], ["Ren", "Jie", ""], ["Yu", "Jialong", ""], ["Gao", "Ling", ""], ["Wang", "Hai", ""], ["Zheng", "Jie", ""], ["Feng", "Yansong", ""], ["Fang", "Jianbin", ""], ["Wang", "Zheng", ""]]}, {"id": "1810.08907", "submitter": "Bin Shi", "authors": "Bin Shi, Simon S. Du, Michael I. Jordan, Weijie J. Su", "title": "Understanding the Acceleration Phenomenon via High-Resolution\n  Differential Equations", "comments": "82 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.CA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based optimization algorithms can be studied from the perspective of\nlimiting ordinary differential equations (ODEs). Motivated by the fact that\nexisting ODEs do not distinguish between two fundamentally different\nalgorithms---Nesterov's accelerated gradient method for strongly convex\nfunctions (NAG-SC) and Polyak's heavy-ball method---we study an alternative\nlimiting process that yields high-resolution ODEs. We show that these ODEs\npermit a general Lyapunov function framework for the analysis of convergence in\nboth continuous and discrete time. We also show that these ODEs are more\naccurate surrogates for the underlying algorithms; in particular, they not only\ndistinguish between NAG-SC and Polyak's heavy-ball method, but they allow the\nidentification of a term that we refer to as \"gradient correction\" that is\npresent in NAG-SC but not in the heavy-ball method and is responsible for the\nqualitative difference in convergence of the two methods. We also use the\nhigh-resolution ODE framework to study Nesterov's accelerated gradient method\nfor (non-strongly) convex functions, uncovering a hitherto unknown\nresult---that NAG-C minimizes the squared gradient norm at an inverse cubic\nrate. Finally, by modifying the high-resolution ODE of NAG-C, we obtain a\nfamily of new optimization methods that are shown to maintain the accelerated\nconvergence rates of NAG-C for smooth convex functions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 07:34:09 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 05:26:04 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 19:10:45 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Shi", "Bin", ""], ["Du", "Simon S.", ""], ["Jordan", "Michael I.", ""], ["Su", "Weijie J.", ""]]}, {"id": "1810.08923", "submitter": "Ehsan Hoseinzade", "authors": "Ehsan Hoseinzade, Saman Haratizadeh", "title": "CNNPred: CNN-based stock market prediction using several data sources", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.NE q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction from financial data is one of the most important problems\nin market prediction domain for which many approaches have been suggested.\nAmong other modern tools, convolutional neural networks (CNN) have recently\nbeen applied for automatic feature selection and market prediction. However, in\nexperiments reported so far, less attention has been paid to the correlation\namong different markets as a possible source of information for extracting\nfeatures. In this paper, we suggest a CNN-based framework with specially\ndesigned CNNs, that can be applied on a collection of data from a variety of\nsources, including different markets, in order to extract features for\npredicting the future of those markets. The suggested framework has been\napplied for predicting the next day's direction of movement for the indices of\nS&P 500, NASDAQ, DJI, NYSE, and RUSSELL markets based on various sets of\ninitial features. The evaluations show a significant improvement in\nprediction's performance compared to the state of the art baseline algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 10:34:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hoseinzade", "Ehsan", ""], ["Haratizadeh", "Saman", ""]]}, {"id": "1810.08926", "submitter": "Adish Singla", "authors": "Luis Haug, Sebastian Tschiatschek, Adish Singla", "title": "Teaching Inverse Reinforcement Learners via Features and Demonstrations", "comments": "NeurIPS'2018 (extended version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning near-optimal behaviour from an expert's demonstrations typically\nrelies on the assumption that the learner knows the features that the true\nreward function depends on. In this paper, we study the problem of learning\nfrom demonstrations in the setting where this is not the case, i.e., where\nthere is a mismatch between the worldviews of the learner and the expert. We\nintroduce a natural quantity, the teaching risk, which measures the potential\nsuboptimality of policies that look optimal to the learner in this setting. We\nshow that bounds on the teaching risk guarantee that the learner is able to\nfind a near-optimal policy using standard algorithms based on inverse\nreinforcement learning. Based on these findings, we suggest a teaching scheme\nin which the expert can decrease the teaching risk by updating the learner's\nworldview, and thus ultimately enable her to find a near-optimal policy.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 10:44:22 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 21:37:28 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 17:17:31 GMT"}, {"version": "v4", "created": "Wed, 27 Mar 2019 11:14:44 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Haug", "Luis", ""], ["Tschiatschek", "Sebastian", ""], ["Singla", "Adish", ""]]}, {"id": "1810.08940", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang and Osvaldo Simeone", "title": "Training Dynamic Exponential Family Models with Causal and Lateral\n  Dependencies for Generalized Neuromorphic Computing", "comments": "Published in IEEE ICASSP 2019. Author's Accepted Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic hardware platforms, such as Intel's Loihi chip, support the\nimplementation of Spiking Neural Networks (SNNs) as an energy-efficient\nalternative to Artificial Neural Networks (ANNs). SNNs are networks of neurons\nwith internal analogue dynamics that communicate by means of binary time\nseries. In this work, a probabilistic model is introduced for a generalized\nset-up in which the synaptic time series can take values in an arbitrary\nalphabet and are characterized by both causal and instantaneous statistical\ndependencies. The model, which can be considered as an extension of exponential\nfamily harmoniums to time series, is introduced by means of a hybrid\ndirected-undirected graphical representation. Furthermore, distributed learning\nrules are derived for Maximum Likelihood and Bayesian criteria under the\nassumption of fully observed time series in the training set.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 13:27:55 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 11:06:37 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 14:43:42 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1810.08955", "submitter": "Jiawen Liu", "authors": "Jiawen Liu, Dong Li, Gokcen Kestor, Jeffrey Vetter", "title": "Runtime Concurrency Control and Operation Scheduling for High\n  Performance Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural network often uses a machine learning framework such as\nTensorFlow and Caffe2. These frameworks employ a dataflow model where the NN\ntraining is modeled as a directed graph composed of a set of nodes. Operations\nin neural network training are typically implemented by the frameworks as\nprimitives and represented as nodes in the dataflow graph. Training NN models\nin a dataflow-based machine learning framework involves a large number of\nfine-grained operations. Those operations have diverse memory access patterns\nand computation intensity. How to manage and schedule those operations is\nchallenging, because we have to decide the number of threads to run each\noperation (concurrency control) and schedule those operations for good hardware\nutilization and system throughput.\n  In this paper, we extend an existing runtime system (the TensorFlow runtime)\nto enable automatic concurrency control and scheduling of operations. We\nexplore performance modeling to predict the performance of operations with\nvarious thread-level parallelism. Our performance model is highly accurate and\nlightweight. Leveraging the performance model, our runtime system employs a set\nof scheduling strategies that co-run operations to improve hardware utilization\nand system throughput. Our runtime system demonstrates a big performance\nbenefit. Comparing with using the recommended configurations for concurrency\ncontrol and operation scheduling in TensorFlow, our approach achieves 33%\nperformance (execution time) improvement on average (up to 49%) for three\nneural network models, and achieves high performance closing to the optimal one\nmanually obtained by the user.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 14:18:03 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 01:15:36 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Liu", "Jiawen", ""], ["Li", "Dong", ""], ["Kestor", "Gokcen", ""], ["Vetter", "Jeffrey", ""]]}, {"id": "1810.08985", "submitter": "Abhishek Dubey", "authors": "Sanchita Basak, Saptarshi Sengupta, Abhishek Dubey", "title": "Mechanisms for Integrated Feature Normalization and Remaining Useful\n  Life Estimation Using LSTMs Applied to Hard-Disks", "comments": "9 pages, 13 figures, 2 tables", "journal-ref": "Proceedings of IEEE Smartcomp 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With emerging smart communities, improving overall system availability is\nbecoming a major concern. In order to improve the reliability of the components\nin a system we propose an inference model to predict Remaining Useful Life\n(RUL) of those components. In this paper we work with components of backend\ndata servers such as hard disks, that are subject to degradation. A Deep\nLong-Short Term Memory (LSTM) Network is used as the backbone of this fast,\ndata-driven decision framework and dynamically captures the pattern of the\nincoming data. In the article, we discuss the architecture of the neural\nnetwork and describe the mechanisms to choose the various hyper-parameters.\nFurther, we describe the challenges faced in extracting effective training sets\nfrom highly unorganized and class-imbalanced big data and establish methods for\nonline predictions with extensive data pre-processing, feature extraction and\nvalidation through online simulation sets with unknown remaining useful lives\nof the hard disks. Our algorithm performs especially well in predicting RUL\nnear the critical zone of a device approaching failure. With the proposed\napproach we are able to predict whether a disk is going to fail in next ten\ndays with an average precision of 0.8435. We also show that the architecture\ntrained on a particular model can be used to predict RUL for devices in\ndifferent models from same manufacturer through transfer learning.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 16:24:46 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 08:57:58 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 00:41:38 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Basak", "Sanchita", ""], ["Sengupta", "Saptarshi", ""], ["Dubey", "Abhishek", ""]]}, {"id": "1810.09026", "submitter": "Marc Lanctot", "authors": "Sriram Srinivasan, Marc Lanctot, Vinicius Zambaldi, Julien Perolat,\n  Karl Tuyls, Remi Munos, Michael Bowling", "title": "Actor-Critic Policy Optimization in Partially Observable Multiagent\n  Environments", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of parameterized policies for reinforcement learning (RL) is an\nimportant and challenging problem in artificial intelligence. Among the most\ncommon approaches are algorithms based on gradient ascent of a score function\nrepresenting discounted return. In this paper, we examine the role of these\npolicy gradient and actor-critic algorithms in partially-observable multiagent\nenvironments. We show several candidate policy update rules and relate them to\na foundation of regret minimization and multiagent learning techniques for the\none-shot and tabular cases, leading to previously unknown convergence\nguarantees. We apply our method to model-free multiagent reinforcement learning\nin adversarial sequential decision problems (zero-sum imperfect information\ngames), using RL-style function approximation. We evaluate on commonly used\nbenchmark Poker domains, showing performance against fixed policies and\nempirical convergence to approximate Nash equilibria in self-play with rates\nsimilar to or better than a baseline model-free algorithm for zero sum games,\nwithout any domain-specific state space reductions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 21:01:49 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 04:41:14 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 23:16:33 GMT"}, {"version": "v4", "created": "Sat, 19 Oct 2019 15:23:13 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 04:32:01 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Srinivasan", "Sriram", ""], ["Lanctot", "Marc", ""], ["Zambaldi", "Vinicius", ""], ["Perolat", "Julien", ""], ["Tuyls", "Karl", ""], ["Munos", "Remi", ""], ["Bowling", "Michael", ""]]}, {"id": "1810.09028", "submitter": "Michael Schaarschmidt", "authors": "Michael Schaarschmidt, Sven Mika, Kai Fricke, Eiko Yoneki", "title": "RLgraph: Modular Computation Graphs for Deep Reinforcement Learning", "comments": "SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) tasks are challenging to implement, execute and\ntest due to algorithmic instability, hyper-parameter sensitivity, and\nheterogeneous distributed communication patterns. We argue for the separation\nof logical component composition, backend graph definition, and distributed\nexecution. To this end, we introduce RLgraph, a library for designing and\nexecuting reinforcement learning tasks in both static graph and define-by-run\nparadigms. The resulting implementations are robust, incrementally testable,\nand yield high performance across different deep learning frameworks and\ndistributed backends.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 21:12:06 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 19:32:08 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Schaarschmidt", "Michael", ""], ["Mika", "Sven", ""], ["Fricke", "Kai", ""], ["Yoneki", "Eiko", ""]]}, {"id": "1810.09038", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Yoshua Bengio", "title": "Depth with Nonlinearity Creates No Bad Local Minima in ResNets", "comments": null, "journal-ref": "Neural Networks, volume 118, pages 167-174 (2019)", "doi": "10.1016/j.neunet.2019.06.009", "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that depth with nonlinearity creates no bad local\nminima in a type of arbitrarily deep ResNets with arbitrary nonlinear\nactivation functions, in the sense that the values of all local minima are no\nworse than the global minimum value of corresponding classical machine-learning\nmodels, and are guaranteed to further improve via residual representations. As\na result, this paper provides an affirmative answer to an open question stated\nin a paper in the conference on Neural Information Processing Systems 2018.\nThis paper advances the optimization theory of deep learning only for ResNets\nand not for other network architectures.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 22:38:32 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 16:50:26 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 14:59:54 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1810.09043", "submitter": "Nikhil Galagali", "authors": "Nikhil Galagali and Minnan Xu-Wilson", "title": "Patient Subtyping with Disease Progression and Irregular Observation\n  Trajectories", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient subtyping based on temporal observations can lead to significantly\nnuanced subtyping that acknowledges the dynamic characteristics of diseases.\nExisting methods for subtyping trajectories treat the evolution of clinical\nobservations as a homogeneous process or employ data available at regular\nintervals. In reality, diseases may have transient underlying states and a\nstate-dependent observation pattern. In our paper, we present an approach to\nsubtype irregular patient data while acknowledging the underlying progression\nof disease states. Our approach consists of two components: a probabilistic\nmodel to determine the likelihood of a patient's observation trajectory and a\nmixture model to measure similarity between asynchronous patient trajectories.\nWe demonstrate our model by discovering subtypes of progression to hemodynamic\ninstability (requiring cardiovascular intervention) in a patient cohort from a\nmulti-institution ICU dataset. We find three primary patterns: two of which\nshow classic signs of decompensation (rising heart rate with dropping blood\npressure), with one of these showing a faster course of decompensation than the\nother. The third pattern has transient period of low heart rate and blood\npressure. We also show that our model results in a 13% reduction in average\ncross-entropy error compared to a model with no state progression when\nforecasting vital signs.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 23:46:38 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 15:59:49 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 18:45:08 GMT"}, {"version": "v4", "created": "Wed, 28 Nov 2018 22:06:14 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Galagali", "Nikhil", ""], ["Xu-Wilson", "Minnan", ""]]}, {"id": "1810.09071", "submitter": "Kar-Ann Toh", "authors": "Kar-Ann Toh", "title": "Learning from the Kernel and the Range Space", "comments": "Camera-ready finalized on 22 April 2018, paper presented on 07 June\n  2018 in the 17th IEEE/ACIS International Conference on Computer and\n  Information Science (ICIS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, a novel approach to learning a complex function which can be\nwritten as the system of linear equations is introduced. This learning is\ngrounded upon the observation that solving the system of linear equations by a\nmanipulation in the kernel and the range space boils down to an estimation\nbased on the least squares error approximation. The learning approach is\napplied to learn a deep feedforward network with full weight connections. The\nnumerical experiments on network learning of synthetic and benchmark data not\nonly show feasibility of the proposed learning approach but also provide\ninsights into the mechanism of data representation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 03:35:32 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Toh", "Kar-Ann", ""]]}, {"id": "1810.09078", "submitter": "Siddhardha Balemarthy", "authors": "Siddhardha Balemarthy, Atul Sajjanhar, James Xi Zheng", "title": "Our Practice Of Using Machine Learning To Recognize Species By Voice", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the technology is advancing, audio recognition in machine learning is\nimproved as well. Research in audio recognition has traditionally focused on\nspeech. Living creatures (especially the small ones) are part of the whole\necosystem, monitoring as well as maintaining them are important tasks. Species\nsuch as animals and birds are tending to change their activities as well as\ntheir habitats due to the adverse effects on the environment or due to other\nnatural or man-made calamities. For those in far deserted areas, we will not\nhave any idea about their existence until we can continuously monitor them.\nContinuous monitoring will take a lot of hard work and labor. If there is no\ncontinuous monitoring, then there might be instances where endangered species\nmay encounter dangerous situations. The best way to monitor those species are\nthrough audio recognition. Classifying sound can be a difficult task even for\nhumans. Powerful audio signals and their processing techniques make it possible\nto detect audio of various species. There might be many ways wherein audio\nrecognition can be done. We can train machines either by pre-recorded audio\nfiles or by recording them live and detecting them. The audio of species can be\ndetected by removing all the background noise and echoes. Smallest sound is\nconsidered as a syllable. Extracting various syllables is the process we are\nfocusing on which is known as audio recognition in terms of Machine Learning\n(ML).\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 04:23:17 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Balemarthy", "Siddhardha", ""], ["Sajjanhar", "Atul", ""], ["Zheng", "James Xi", ""]]}, {"id": "1810.09079", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Zhiyue Hu and Xin Guo", "title": "Sparsemax and Relaxed Wasserstein for Topic Sparsity", "comments": "10 Pages. To appear in WSDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic sparsity refers to the observation that individual documents usually\nfocus on several salient topics instead of covering a wide variety of topics,\nand a real topic adopts a narrow range of terms instead of a wide coverage of\nthe vocabulary. Understanding this topic sparsity is especially important for\nanalyzing user-generated web content and social media, which are featured in\nthe form of extremely short posts and discussions. As topic sparsity of\nindividual documents in online social media increases, so does the difficulty\nof analyzing the online text sources using traditional methods.\n  In this paper, we propose two novel neural models by providing sparse\nposterior distributions over topics based on the Gaussian sparsemax\nconstruction, enabling efficient training by stochastic backpropagation. We\nconstruct an inference network conditioned on the input data and infer the\nvariational distribution with the relaxed Wasserstein (RW) divergence. Unlike\nexisting works based on Gaussian softmax construction and Kullback-Leibler (KL)\ndivergence, our approaches can identify latent topic sparsity with training\nstability, predictive performance, and topic coherence. Experiments on\ndifferent genres of large text corpora have demonstrated the effectiveness of\nour models as they outperform both probabilistic and neural methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 04:23:44 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 10:22:18 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Lin", "Tianyi", ""], ["Hu", "Zhiyue", ""], ["Guo", "Xin", ""]]}, {"id": "1810.09092", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Sarah Tan, Paul Koch, Yin Lou, Urszula Chajewska, Rich\n  Caruana", "title": "Axiomatic Interpretability for Multiclass Additive Models", "comments": "KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized additive models (GAMs) are favored in many regression and binary\nclassification problems because they are able to fit complex, nonlinear\nfunctions while still remaining interpretable. In the first part of this paper,\nwe generalize a state-of-the-art GAM learning algorithm based on boosted trees\nto the multiclass setting, and show that this multiclass algorithm outperforms\nexisting GAM learning algorithms and sometimes matches the performance of full\ncomplexity models such as gradient boosted trees.\n  In the second part, we turn our attention to the interpretability of GAMs in\nthe multiclass setting. Surprisingly, the natural interpretability of GAMs\nbreaks down when there are more than two classes. Naive interpretation of\nmulticlass GAMs can lead to false conclusions. Inspired by binary GAMs, we\nidentify two axioms that any additive model must satisfy in order to not be\nvisually misleading. We then develop a technique called Additive\nPost-Processing for Interpretability (API), that provably transforms a\npre-trained additive model to satisfy the interpretability axioms without\nsacrificing accuracy. The technique works not just on models trained with our\nlearning algorithm, but on any multiclass additive model, including multiclass\nlinear and logistic regression. We demonstrate the effectiveness of API on a\n12-class infant mortality dataset.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 05:40:05 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 23:11:55 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Tan", "Sarah", ""], ["Koch", "Paul", ""], ["Lou", "Yin", ""], ["Chajewska", "Urszula", ""], ["Caruana", "Rich", ""]]}, {"id": "1810.09098", "submitter": "Christopher Aicher", "authors": "Christopher Aicher, Yi-An Ma, Nicholas J. Foti, and Emily B. Fox", "title": "Stochastic Gradient MCMC for State Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State space models (SSMs) are a flexible approach to modeling complex time\nseries. However, inference in SSMs is often computationally prohibitive for\nlong time series. Stochastic gradient MCMC (SGMCMC) is a popular method for\nscalable Bayesian inference for large independent data. Unfortunately when\napplied to dependent data, such as in SSMs, SGMCMC's stochastic gradient\nestimates are biased as they break crucial temporal dependencies. To alleviate\nthis, we propose stochastic gradient estimators that control this bias by\nperforming additional computation in a `buffer' to reduce breaking\ndependencies. Furthermore, we derive error bounds for this bias and show a\ngeometric decay under mild conditions. Using these estimators, we develop novel\nSGMCMC samplers for discrete, continuous and mixed-type SSMs with analytic\nmessage passing. Our experiments on real and synthetic data demonstrate the\neffectiveness of our SGMCMC algorithms compared to batch MCMC, allowing us to\nscale inference to long time series with millions of time points.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 05:53:22 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 18:09:39 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Aicher", "Christopher", ""], ["Ma", "Yi-An", ""], ["Foti", "Nicholas J.", ""], ["Fox", "Emily B.", ""]]}, {"id": "1810.09102", "submitter": "Xiaohan Chen", "authors": "Nitin Bansal, Xiaohan Chen, Zhangyang Wang", "title": "Can We Gain More from Orthogonality Regularizations in Training Deep\n  CNNs?", "comments": "11 pages, 1 figure, 2 tables. Accepted in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper seeks to answer the question: as the (near-) orthogonality of\nweights is found to be a favorable property for training deep convolutional\nneural networks, how can we enforce it in more effective and easy-to-use ways?\nWe develop novel orthogonality regularizations on training deep CNNs, utilizing\nvarious advanced analytical tools such as mutual coherence and restricted\nisometry property. These plug-and-play regularizations can be conveniently\nincorporated into training almost any CNN without extra hassle. We then\nbenchmark their effects on state-of-the-art models: ResNet, WideResNet, and\nResNeXt, on several most popular computer vision datasets: CIFAR-10, CIFAR-100,\nSVHN and ImageNet. We observe consistent performance gains after applying those\nproposed regularizations, in terms of both the final accuracies achieved, and\nfaster and more stable convergences. We have made our codes and pre-trained\nmodels publicly available:\nhttps://github.com/nbansal90/Can-we-Gain-More-from-Orthogonality.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 06:22:54 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Bansal", "Nitin", ""], ["Chen", "Xiaohan", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1810.09103", "submitter": "Sungsu Lim", "authors": "Sungsu Lim, Ajin Joseph, Lei Le, Yangchen Pan, Martha White", "title": "Actor-Expert: A Framework for using Q-learning in Continuous Action\n  Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning can be difficult to use in continuous action spaces, because an\noptimization has to be solved to find the maximal action for the action-values.\nA common strategy has been to restrict the functional form of the action-values\nto be concave in the actions, to simplify the optimization. Such restrictions,\nhowever, can prevent learning accurate action-values. In this work, we propose\na new policy search objective that facilitates using Q-learning and a framework\nto optimize this objective, called Actor-Expert. The Expert uses Q-learning to\nupdate the action-values towards optimal action-values. The Actor learns the\nmaximal actions over time for these changing action-values. We develop a Cross\nEntropy Method (CEM) for the Actor, where such a global optimization approach\nfacilitates use of generically parameterized action-values. This method - which\nwe call Conditional CEM - iteratively concentrates density around maximal\nactions, conditioned on state. We prove that this algorithm tracks the expected\nCEM update, over states with changing action-values. We demonstrate in a toy\nenvironment that previous methods that restrict the action-value\nparameterization fail whereas Actor-Expert with a more general action-value\nparameterization succeeds. Finally, we demonstrate that Actor-Expert performs\nas well as or better than competitors on four benchmark continuous-action\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 06:35:03 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 17:34:35 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Lim", "Sungsu", ""], ["Joseph", "Ajin", ""], ["Le", "Lei", ""], ["Pan", "Yangchen", ""], ["White", "Martha", ""]]}, {"id": "1810.09104", "submitter": "Xiao Yan", "authors": "Xiao Yan, Xinyan Dai, Jie Liu, Kaiwen Zhou, James Cheng", "title": "Norm-Range Partition: A Universal Catalyst for LSH based Maximum Inner\n  Product Search (MIPS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, locality sensitive hashing (LSH) was shown to be effective for MIPS\nand several algorithms including $L_2$-ALSH, Sign-ALSH and Simple-LSH have been\nproposed. In this paper, we introduce the norm-range partition technique, which\npartitions the original dataset into sub-datasets containing items with similar\n2-norms and builds hash index independently for each sub-dataset. We prove that\nnorm-range partition reduces the query processing complexity for all existing\nLSH based MIPS algorithms under mild conditions. The key to performance\nimprovement is that norm-range partition allows to use smaller normalization\nfactor most sub-datasets. For efficient query processing, we also formulate a\nunified framework to rank the buckets from the hash indexes of different\nsub-datasets. Experiments on real datasets show that norm-range partition\nsignificantly reduces the number of probed for LSH based MIPS algorithms when\nachieving the same recall.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 06:36:23 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 12:49:32 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Yan", "Xiao", ""], ["Dai", "Xinyan", ""], ["Liu", "Jie", ""], ["Zhou", "Kaiwen", ""], ["Cheng", "James", ""]]}, {"id": "1810.09113", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Richard Nock", "title": "The Bregman chord divergence", "comments": "10 pages", "journal-ref": "GSI 2019: Geometric Science of Information pp 299-308", "doi": "10.1007/978-3-030-26980-7_31", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distances are fundamental primitives whose choice significantly impacts the\nperformances of algorithms in machine learning and signal processing. However\nselecting the most appropriate distance for a given task is an endeavor.\nInstead of testing one by one the entries of an ever-expanding dictionary of\n{\\em ad hoc} distances, one rather prefers to consider parametric classes of\ndistances that are exhaustively characterized by axioms derived from first\nprinciples. Bregman divergences are such a class. However fine-tuning a Bregman\ndivergence is delicate since it requires to smoothly adjust a functional\ngenerator. In this work, we propose an extension of Bregman divergences called\nthe Bregman chord divergences. This new class of distances does not require\ngradient calculations, uses two scalar parameters that can be easily tailored\nin applications, and generalizes asymptotically Bregman divergences.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 07:11:11 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Nielsen", "Frank", ""], ["Nock", "Richard", ""]]}, {"id": "1810.09126", "submitter": "L.A. Prashanth", "authors": "Prashanth L.A., Michael Fu", "title": "Risk-Sensitive Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic objective in a reinforcement learning (RL) problem is to find a\npolicy that minimizes, in expectation, a long-run objective such as the\ninfinite-horizon cumulative discounted or long-run average cost. In many\npractical applications, optimizing the expected value alone is not sufficient,\nand it may be necessary to include a risk measure in the optimization process,\neither in the objective or as a constraint. Various risk measures have been\nproposed in the literature, e.g., variance, exponential utility, percentile\nperformance, chance constraints, value at risk (quantile), conditional\nvalue-at-risk, coherent risk measure, prospect theory and its later\nenhancement, cumulative prospect theory. In this article, we focus on the\ncombination of risk criteria and reinforcement learning in a constrained\noptimization framework, i.e., a setting where the goal to find a policy that\noptimizes the usual objective of infinite-horizon discounted/average cost,\nwhile ensuring that an explicit risk constraint is satisfied. We introduce the\nrisk-constrained RL framework, cover popular risk measures based on variance,\nconditional value-at-risk, and chance constraints, and present a template for a\nrisk-sensitive RL algorithm. Next, we study risk-sensitive RL with the\nobjective of minimizing risk in an unconstrained framework, and cover\ncumulative prospect theory and coherent risk measures as special cases. We\nsurvey some of the recent work on this topic, covering problems encompassing\ndiscounted cost, average cost, and stochastic shortest path settings, together\nwith the aforementioned risk measures, in constrained as well as unconstrained\nframeworks. This non-exhaustive survey is aimed at giving a flavor of the\nchallenges involved in solving risk-sensitive RL problems, and outlining some\npotential future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:01:18 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 19:56:37 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["A.", "Prashanth L.", ""], ["Fu", "Michael", ""]]}, {"id": "1810.09133", "submitter": "Yuma Koizumi Dr.", "authors": "Yuma Koizumi, Shoichiro Saito, Hisashi Uematsum Yuta Kawachi, Noboru\n  Harada", "title": "Unsupervised Detection of Anomalous Sound based on Deep Learning and the\n  Neyman-Pearson Lemma", "comments": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2018", "journal-ref": null, "doi": "10.1109/TASLP.2018.2877258", "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel optimization principle and its implementation for\nunsupervised anomaly detection in sound (ADS) using an autoencoder (AE). The\ngoal of unsupervised-ADS is to detect unknown anomalous sound without training\ndata of anomalous sound. Use of an AE as a normal model is a state-of-the-art\ntechnique for unsupervised-ADS. To decrease the false positive rate (FPR), the\nAE is trained to minimize the reconstruction error of normal sounds and the\nanomaly score is calculated as the reconstruction error of the observed sound.\nUnfortunately, since this training procedure does not take into account the\nanomaly score for anomalous sounds, the true positive rate (TPR) does not\nnecessarily increase. In this study, we define an objective function based on\nthe Neyman-Pearson lemma by considering ADS as a statistical hypothesis test.\nThe proposed objective function trains the AE to maximize the TPR under an\narbitrary low FPR condition. To calculate the TPR in the objective function, we\nconsider that the set of anomalous sounds is the complementary set of normal\nsounds and simulate anomalous sounds by using a rejection sampling algorithm.\nThrough experiments using synthetic data, we found that the proposed method\nimproved the performance measures of ADS under low FPR conditions. In addition,\nwe confirmed that the proposed method could detect anomalous sounds in real\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:20:59 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koizumi", "Yuma", ""], ["Saito", "Shoichiro", ""], ["Kawachi", "Hisashi Uematsum Yuta", ""], ["Harada", "Noboru", ""]]}, {"id": "1810.09136", "submitter": "Eric Nalisnick", "authors": "Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Gorur, Balaji\n  Lakshminarayanan", "title": "Do Deep Generative Models Know What They Don't Know?", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural network deployed in the wild may be asked to make predictions for\ninputs that were drawn from a different distribution than that of the training\ndata. A plethora of work has demonstrated that it is easy to find or synthesize\ninputs for which a neural network is highly confident yet wrong. Generative\nmodels are widely viewed to be robust to such mistaken confidence as modeling\nthe density of the input features can be used to detect novel,\nout-of-distribution inputs. In this paper we challenge this assumption. We find\nthat the density learned by flow-based models, VAEs, and PixelCNNs cannot\ndistinguish images of common objects such as dogs, trucks, and horses (i.e.\nCIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher\nlikelihood to the latter when the model is trained on the former. Moreover, we\nfind evidence of this phenomenon when pairing several popular image data sets:\nFashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN.\nTo investigate this curious behavior, we focus analysis on flow-based\ngenerative models in particular since they are trained and evaluated via the\nexact marginal likelihood. We find such behavior persists even when we restrict\nthe flows to constant-volume transformations. These transformations admit some\ntheoretical analysis, and we show that the difference in likelihoods can be\nexplained by the location and variances of the data and the model curvature.\nOur results caution against using the density estimates from deep generative\nmodels to identify inputs similar to the training distribution until their\nbehavior for out-of-distribution inputs is better understood.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:32:02 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 19:52:27 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 11:57:32 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Nalisnick", "Eric", ""], ["Matsukawa", "Akihiro", ""], ["Teh", "Yee Whye", ""], ["Gorur", "Dilan", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1810.09137", "submitter": "Yuma Koizumi Dr.", "authors": "Yuma Koizumi, Kenta Niwa, Yusuke Hioka, Kazunori Kobayashi, Yoichi\n  Haneda", "title": "DNN-based Source Enhancement to Increase Objective Sound Quality\n  Assessment Score", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,\n  Vol.26, Issue.10, 2018", "doi": "10.1109/TASLP.2018.2842156", "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a training method for deep neural network (DNN)-based source\nenhancement to increase objective sound quality assessment (OSQA) scores such\nas the perceptual evaluation of speech quality (PESQ). In many conventional\nstudies, DNNs have been used as a mapping function to estimate time-frequency\nmasks and trained to minimize an analytically tractable objective function such\nas the mean squared error (MSE). Since OSQA scores have been used widely for\nsound-quality evaluation, constructing DNNs to increase OSQA scores would be\nbetter than using the minimum-MSE to create high-quality output signals.\nHowever, since most OSQA scores are not analytically tractable, \\textit{i.e.},\nthey are black boxes, the gradient of the objective function cannot be\ncalculated by simply applying back-propagation. To calculate the gradient of\nthe OSQA-based objective function, we formulated a DNN optimization scheme on\nthe basis of \\textit{black-box optimization}, which is used for training a\ncomputer that plays a game. For a black-box-optimization scheme, we adopt the\npolicy gradient method for calculating the gradient on the basis of a sampling\nalgorithm. To simulate output signals using the sampling algorithm, DNNs are\nused to estimate the probability density function of the output signals that\nmaximize OSQA scores. The OSQA scores are calculated from the simulated output\nsignals, and the DNNs are trained to increase the probability of generating the\nsimulated output signals that achieve high OSQA scores. Through several\nexperiments, we found that OSQA scores significantly increased by applying the\nproposed method, even though the MSE was not minimized.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 08:34:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koizumi", "Yuma", ""], ["Niwa", "Kenta", ""], ["Hioka", "Yusuke", ""], ["Kobayashi", "Kazunori", ""], ["Haneda", "Yoichi", ""]]}, {"id": "1810.09155", "submitter": "Edouard Pineau", "authors": "Nathan de Lara and Edouard Pineau", "title": "A Simple Baseline Algorithm for Graph Classification", "comments": "Relational Representation Learning, NIPS 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification has recently received a lot of attention from various\nfields of machine learning e.g. kernel methods, sequential modeling or graph\nembedding. All these approaches offer promising results with different\nrespective strengths and weaknesses. However, most of them rely on complex\nmathematics and require heavy computational power to achieve their best\nperformance. We propose a simple and fast algorithm based on the spectral\ndecomposition of graph Laplacian to perform graph classification and get a\nfirst reference score for a dataset. We show that this method obtains\ncompetitive results compared to state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 09:47:38 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 15:47:10 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["de Lara", "Nathan", ""], ["Pineau", "Edouard", ""]]}, {"id": "1810.09166", "submitter": "Evgeniy Ozhegov M.", "authors": "Evgeniy M. Ozhegov, Daria Teterina", "title": "Ensemble Method for Censored Demand Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many economic applications including optimal pricing and inventory management\nrequires prediction of demand based on sales data and estimation of sales\nreaction to a price change. There is a wide range of econometric approaches\nwhich are used to correct a bias in estimates of demand parameters on censored\nsales data. These approaches can also be applied to various classes of machine\nlearning models to reduce the prediction error of sales volume. In this study\nwe construct two ensemble models for demand prediction with and without\naccounting for demand censorship. Accounting for sales censorship is based on\nthe idea of censored quantile regression method where the model estimation is\nsplitted on two separate parts: a) prediction of zero sales by classification\nmodel; and b) prediction of non-zero sales by regression model. Models with and\nwithout accounting for censorship are based on the predictions aggregations of\nLeast squares, Ridge and Lasso regressions and Random Forest model. Having\nestimated the predictive properties of both models, we empirically test the\nbest predictive power of the model that takes into account the censored nature\nof demand. We also show that machine learning method with censorship accounting\nprovide bias corrected estimates of demand sensitivity for price change similar\nto econometric models.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 10:20:55 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Ozhegov", "Evgeniy M.", ""], ["Teterina", "Daria", ""]]}, {"id": "1810.09167", "submitter": "Victor Blanco", "authors": "V\\'ictor Blanco, Alberto Jap\\'on and Justo Puerto", "title": "Optimal arrangements of hyperplanes for multiclass classification", "comments": "8 Figures, 2 Tables", "journal-ref": "Advances in Data Analysis and Classification 14 (2020) 175-199", "doi": "10.1007/s11634-019-00367-6", "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach to construct multiclass\nclassifiers by means of arrangements of hyperplanes. We propose different mixed\ninteger (linear and non linear) programming formulations for the problem using\nextensions of widely used measures for misclassifying observations where the\n\\textit{kernel trick} can be adapted to be applicable. Some dimensionality\nreductions and variable fixing strategies are also developed for these models.\nAn extensive battery of experiments has been run which reveal the powerfulness\nof our proposal as compared with other previously proposed methodologies.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 10:22:33 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 15:29:48 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Blanco", "V\u00edctor", ""], ["Jap\u00f3n", "Alberto", ""], ["Puerto", "Justo", ""]]}, {"id": "1810.09176", "submitter": "Megha Khosla", "authors": "Megha Khosla, Jurek Leonhardt, Wolfgang Nejdl, Avishek Anand", "title": "Node Representation Learning for Directed Graphs", "comments": "Accepted in ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for learning node representations in directed\ngraphs, which maintains separate views or embedding spaces for the two distinct\nnode roles induced by the directionality of the edges. We argue that the\nprevious approaches either fail to encode the edge directionality or their\nencodings cannot be generalized across tasks. With our simple \\emph{alternating\nrandom walk} strategy, we generate role specific vertex neighborhoods and train\nnode embeddings in their corresponding source/target roles while fully\nexploiting the semantics of directed graphs. We also unearth the limitations of\nevaluations on directed graphs in previous works and propose a clear strategy\nfor evaluating link prediction and graph reconstruction in directed graphs. We\nconduct extensive experiments to showcase our effectiveness on several\nreal-world datasets on link prediction, node classification and graph\nreconstruction tasks. We show that the embeddings from our approach are indeed\nrobust, generalizable and well performing across multiple kinds of tasks and\ngraphs. We show that we consistently outperform all baselines for node\nclassification task. In addition to providing a theoretical interpretation of\nour method we also show that we are considerably more robust than the other\ndirected graph approaches.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 11:04:00 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 11:50:24 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 10:53:18 GMT"}, {"version": "v4", "created": "Fri, 28 Jun 2019 11:32:13 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Khosla", "Megha", ""], ["Leonhardt", "Jurek", ""], ["Nejdl", "Wolfgang", ""], ["Anand", "Avishek", ""]]}, {"id": "1810.09177", "submitter": "Hao Ren", "authors": "Hao Ren, Hong Lu", "title": "Compositional coding capsule network with k-means routing for text\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is a challenging problem which aims to identify the\ncategory of texts. Recently, Capsule Networks (CapsNets) are proposed for image\nclassification. It has been shown that CapsNets have several advantages over\nConvolutional Neural Networks (CNNs), while, their validity in the domain of\ntext has less been explored. An effective method named deep compositional code\nlearning has been proposed lately. This method can save many parameters about\nword embeddings without any significant sacrifices in performance. In this\npaper, we introduce the Compositional Coding (CC) mechanism between capsules,\nand we propose a new routing algorithm, which is based on k-means clustering\ntheory. Experiments conducted on eight challenging text classification datasets\nshow the proposed method achieves competitive accuracy compared to the\nstate-of-the-art approach with significantly fewer parameters.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 11:04:27 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 07:34:04 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 14:29:24 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Ren", "Hao", ""], ["Lu", "Hong", ""]]}, {"id": "1810.09184", "submitter": "Peter Bloem", "authors": "Peter Bloem", "title": "Learning sparse transformations through backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many transformations in deep learning architectures are sparsely connected.\nWhen such transformations cannot be designed by hand, they can be learned, even\nthrough plain backpropagation, for instance in attention mechanisms. However,\nduring learning, such sparse structures are often represented in a dense form,\nas we do not know beforehand which elements will eventually become non-zero. We\nintroduce the adaptive, sparse hyperlayer, a method for learning a sparse\ntransformation, paramatrized sparsely: as index-tuples with associated values.\nTo overcome the lack of gradients from such a discrete structure, we introduce\na method of randomly sampling connections, and backpropagating over the\nrandomly wired computation graph. To show that this approach allows us to train\na model to competitive performance on real data, we use it to build two\narchitectures. First, an attention mechanism for visual classification. Second,\nwe implement a method for differentiable sorting: specifically, learning to\nsort unlabeled MNIST digits, given only the correct order.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 11:34:32 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Bloem", "Peter", ""]]}, {"id": "1810.09202", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang, Chen Dun, Tiejun Huang, and Zongqing Lu", "title": "Graph Convolutional Reinforcement Learning", "comments": "ICLR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to cooperate is crucially important in multi-agent environments. The\nkey is to understand the mutual interplay between agents. However, multi-agent\nenvironments are highly dynamic, where agents keep moving and their neighbors\nchange quickly. This makes it hard to learn abstract representations of mutual\ninterplay between agents. To tackle these difficulties, we propose graph\nconvolutional reinforcement learning, where graph convolution adapts to the\ndynamics of the underlying graph of the multi-agent environment, and relation\nkernels capture the interplay between agents by their relation representations.\nLatent features produced by convolutional layers from gradually increased\nreceptive fields are exploited to learn cooperation, and cooperation is further\nimproved by temporal relation regularization for consistency. Empirically, we\nshow that our method substantially outperforms existing methods in a variety of\ncooperative scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:17:40 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 12:42:24 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 05:21:13 GMT"}, {"version": "v4", "created": "Tue, 4 Feb 2020 03:22:09 GMT"}, {"version": "v5", "created": "Tue, 11 Feb 2020 13:46:23 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Dun", "Chen", ""], ["Huang", "Tiejun", ""], ["Lu", "Zongqing", ""]]}, {"id": "1810.09225", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, David Evans", "title": "Cost-Sensitive Robustness against Adversarial Examples", "comments": "ICLR final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have developed methods for training classifiers that are\ncertifiably robust against norm-bounded adversarial perturbations. These\nmethods assume that all the adversarial transformations are equally important,\nwhich is seldom the case in real-world applications. We advocate for\ncost-sensitive robustness as the criteria for measuring the classifier's\nperformance for tasks where some adversarial transformation are more important\nthan others. We encode the potential harm of each adversarial transformation in\na cost matrix, and propose a general objective function to adapt the robust\ntraining method of Wong & Kolter (2018) to optimize for cost-sensitive\nrobustness. Our experiments on simple MNIST and CIFAR10 models with a variety\nof cost matrices show that the proposed approach can produce models with\nsubstantially reduced cost-sensitive robust error, while maintaining\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:55:48 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 15:43:25 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Zhang", "Xiao", ""], ["Evans", "David", ""]]}, {"id": "1810.09227", "submitter": "Brandon Malone", "authors": "Brandon Malone and Alberto Garc\\'ia-Dur\\'an and Mathias Niepert", "title": "Knowledge Graph Completion to Predict Polypharmacy Side Effects", "comments": "13th International Conference on Data Integration in the Life\n  Sciences (DILS2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polypharmacy side effect prediction problem considers cases in which two\ndrugs taken individually do not result in a particular side effect; however,\nwhen the two drugs are taken in combination, the side effect manifests. In this\nwork, we demonstrate that multi-relational knowledge graph completion achieves\nstate-of-the-art results on the polypharmacy side effect prediction problem.\nEmpirical results show that our approach is particularly effective when the\nprotein targets of the drugs are well-characterized. In contrast to prior work,\nour approach provides more interpretable predictions and hypotheses for wet lab\nvalidation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:59:51 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Malone", "Brandon", ""], ["Garc\u00eda-Dur\u00e1n", "Alberto", ""], ["Niepert", "Mathias", ""]]}, {"id": "1810.09230", "submitter": "Abdullah Al-Dujaili", "authors": "Gili Rusak, Abdullah Al-Dujaili, Una-May O'Reilly", "title": "AST-Based Deep Learning for Detecting Malicious PowerShell", "comments": "To appear at ACM CCS 2018 Poster Session", "journal-ref": null, "doi": "10.1145/3243734.3278496", "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the celebrated success of deep learning, some attempts to develop\neffective methods for detecting malicious PowerShell programs employ neural\nnets in a traditional natural language processing setup while others employ\nconvolutional neural nets to detect obfuscated malicious commands at a\ncharacter level. While these representations may express salient PowerShell\nproperties, our hypothesis is that tools from static program analysis will be\nmore effective. We propose a hybrid approach combining traditional program\nanalysis (in the form of abstract syntax trees) and deep learning. This poster\npresents preliminary results of a fundamental step in our approach: learning\nembeddings for nodes of PowerShell ASTs. We classify malicious scripts by\nfamily type and explore embedded program vector representations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:03:53 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Rusak", "Gili", ""], ["Al-Dujaili", "Abdullah", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1810.09233", "submitter": "Haowen Fang", "authors": "Haowem Fang, Amar Shrestha, De Ma, Qinru Qiu", "title": "Scalable NoC-based Neuromorphic Hardware Learning and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired neuromorphic hardware is a research direction to approach\nbrain's computational power and energy efficiency. Spiking neural networks\n(SNN) encode information as sparsely distributed spike trains and employ\nspike-timing-dependent plasticity (STDP) mechanism for learning. Existing\nhardware implementations of SNN are limited in scale or do not have in-hardware\nlearning capability. In this work, we propose a low-cost scalable\nNetwork-on-Chip (NoC) based SNN hardware architecture with fully distributed\nin-hardware STDP learning capability. All hardware neurons work in parallel and\ncommunicate through the NoC. This enables chip-level interconnection,\nscalability and reconfigurability necessary for deploying different\napplications. The hardware is applied to learn MNIST digits as an evaluation of\nits learning capability. We explore the design space to study the trade-offs\nbetween speed, area and energy. How to use this procedure to find optimal\narchitecture configuration is also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 16:41:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fang", "Haowem", ""], ["Shrestha", "Amar", ""], ["Ma", "De", ""], ["Qiu", "Qinru", ""]]}, {"id": "1810.09250", "submitter": "Jelani Nelson", "authors": "Shyam Narayanan, Jelani Nelson", "title": "Optimal terminal dimensionality reduction in Euclidean space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\varepsilon\\in(0,1)$ and $X\\subset\\mathbb R^d$ be arbitrary with $|X|$\nhaving size $n>1$. The Johnson-Lindenstrauss lemma states there exists\n$f:X\\rightarrow\\mathbb R^m$ with $m = O(\\varepsilon^{-2}\\log n)$ such that $$\n\\forall x\\in X\\ \\forall y\\in X, \\|x-y\\|_2 \\le \\|f(x)-f(y)\\|_2 \\le\n(1+\\varepsilon)\\|x-y\\|_2 . $$ We show that a strictly stronger version of this\nstatement holds, answering one of the main open questions of [MMMR18]:\n\"$\\forall y\\in X$\" in the above statement may be replaced with \"$\\forall\ny\\in\\mathbb R^d$\", so that $f$ not only preserves distances within $X$, but\nalso distances to $X$ from the rest of space. Previously this stronger version\nwas only known with the worse bound $m = O(\\varepsilon^{-4}\\log n)$. Our proof\nis via a tighter analysis of (a specific instantiation of) the embedding recipe\nof [MMMR18].\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 13:22:38 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Narayanan", "Shyam", ""], ["Nelson", "Jelani", ""]]}, {"id": "1810.09253", "submitter": "Mingjun Zhong", "authors": "Hong Tang, Huaming Chen, Ting Li, Mingjun Zhong", "title": "Classification of normal/abnormal heart sound recordings based on\n  multi-domain features and back propagation neural network", "comments": "4 pages", "journal-ref": "2016 Computing in Cardiology Conference (CinC), IEEE, Vancouver,\n  BC, 2016, pp. 593-596", "doi": "10.23919/CIC.2016.7868812", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to classify a single PCG recording as normal or abnormal for\ncomputer-aided diagnosis. The proposed framework for this challenge has four\nsteps: preprocessing, feature extraction, training and validation. In the\npreprocessing step, a recording is segmented into four states, i.e., the first\nheart sound, systolic interval, the second heart sound, and diastolic interval\nby the Springer Segmentation algorithm. In the feature extraction step, the\nauthors extract 324 features from multi-domains to perform classification. A\nback propagation neural network is used as predication model. The optimal\nthreshold for distinguishing normal and abnormal is determined by the\nstatistics of model output for both normal and abnormal. The performance of the\nproposed predictor tested by the six training sets is sensitivity 0.812 and\nspecificity 0.860 (overall accuracy is 0.836). However, the performance reduces\nto sensitivity 0.807 and specificity 0.829 (overall accuracy is 0.818) for the\nhidden test set.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 21:17:48 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Tang", "Hong", ""], ["Chen", "Huaming", ""], ["Li", "Ting", ""], ["Zhong", "Mingjun", ""]]}, {"id": "1810.09261", "submitter": "Francisco Ruiz", "authors": "Francisco J. R. Ruiz, Isabel Valera, Lennart Svensson, Fernando\n  Perez-Cruz", "title": "Infinite Factorial Finite State Machine for Blind Multiuser Channel\n  Estimation", "comments": "15 pages, 15 figures", "journal-ref": "IEEE Transactions on Cognitive Communications and Networking, June\n  2018, Vol 2, Issue 2, pages 177-191", "doi": "10.1109/TCCN.2018.2790976", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New communication standards need to deal with machine-to-machine\ncommunications, in which users may start or stop transmitting at any time in an\nasynchronous manner. Thus, the number of users is an unknown and time-varying\nparameter that needs to be accurately estimated in order to properly recover\nthe symbols transmitted by all users in the system. In this paper, we address\nthe problem of joint channel parameter and data estimation in a multiuser\ncommunication channel in which the number of transmitters is not known. For\nthat purpose, we develop the infinite factorial finite state machine model, a\nBayesian nonparametric model based on the Markov Indian buffet that allows for\nan unbounded number of transmitters with arbitrary channel length. We propose\nan inference algorithm that makes use of slice sampling and particle Gibbs with\nancestor sampling. Our approach is fully blind as it does not require a prior\nchannel estimation step, prior knowledge of the number of transmitters, or any\nsignaling information. Our experimental results, loosely based on the LTE\nrandom access channel, show that the proposed approach can effectively recover\nthe data-generating process for a wide range of scenarios, with varying number\nof transmitters, number of receivers, constellation order, channel length, and\nsignal-to-noise ratio.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 20:26:17 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Ruiz", "Francisco J. R.", ""], ["Valera", "Isabel", ""], ["Svensson", "Lennart", ""], ["Perez-Cruz", "Fernando", ""]]}, {"id": "1810.09270", "submitter": "Rui Zhu", "authors": "Rui Zhu and Di Niu", "title": "A Model Parallel Proximal Stochastic Gradient Algorithm for Partially\n  Asynchronous Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.08880", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large models are prevalent in modern machine learning scenarios, including\ndeep learning, recommender systems, etc., which can have millions or even\nbillions of parameters. Parallel algorithms have become an essential solution\ntechnique to many large-scale machine learning jobs. In this paper, we propose\na model parallel proximal stochastic gradient algorithm, AsyB-ProxSGD, to deal\nwith large models using model parallel blockwise updates while in the meantime\nhandling a large amount of training data using proximal stochastic gradient\ndescent (ProxSGD). In our algorithm, worker nodes communicate with the\nparameter servers asynchronously, and each worker performs proximal stochastic\ngradient for only one block of model parameters during each iteration. Our\nproposed algorithm generalizes ProxSGD to the asynchronous and model parallel\nsetting. We prove that AsyB-ProxSGD achieves a convergence rate of\n$O(1/\\sqrt{K})$ to stationary points for nonconvex problems under\n\\emph{constant} minibatch sizes, where $K$ is the total number of block\nupdates. This rate matches the best-known rates of convergence for a wide range\nof gradient-like algorithms. Furthermore, we show that when the number of\nworkers is bounded by $O(K^{1/4})$, we can expect AsyB-ProxSGD to achieve\nlinear speedup as the number of workers increases. We implement the proposed\nalgorithm on MXNet and demonstrate its convergence behavior and near-linear\nspeedup on a real-world dataset involving both a large model size and large\namounts of data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 17:22:30 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Zhu", "Rui", ""], ["Niu", "Di", ""]]}, {"id": "1810.09274", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Richard G. Baraniuk", "title": "From Hard to Soft: Understanding Deep Network Nonlinearities via Vector\n  Quantization and Statistical Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinearity is crucial to the performance of a deep (neural) network (DN).\nTo date there has been little progress understanding the menagerie of available\nnonlinearities, but recently progress has been made on understanding the r\\^ole\nplayed by piecewise affine and convex nonlinearities like the ReLU and absolute\nvalue activation functions and max-pooling. In particular, DN layers\nconstructed from these operations can be interpreted as {\\em max-affine spline\noperators} (MASOs) that have an elegant link to vector quantization (VQ) and\n$K$-means. While this is good theoretical progress, the entire MASO approach is\npredicated on the requirement that the nonlinearities be piecewise affine and\nconvex, which precludes important activation functions like the sigmoid,\nhyperbolic tangent, and softmax. {\\em This paper extends the MASO framework to\nthese and an infinitely large class of new nonlinearities by linking\ndeterministic MASOs with probabilistic Gaussian Mixture Models (GMMs).} We show\nthat, under a GMM, piecewise affine, convex nonlinearities like ReLU, absolute\nvalue, and max-pooling can be interpreted as solutions to certain natural\n\"hard\" VQ inference problems, while sigmoid, hyperbolic tangent, and softmax\ncan be interpreted as solutions to corresponding \"soft\" VQ inference problems.\nWe further extend the framework by hybridizing the hard and soft VQ\noptimizations to create a $\\beta$-VQ inference that interpolates between hard,\nsoft, and linear VQ inference. A prime example of a $\\beta$-VQ DN nonlinearity\nis the {\\em swish} nonlinearity, which offers state-of-the-art performance in a\nrange of computer vision tasks but was developed ad hoc by experimentation.\nFinally, we validate with experiments an important assertion of our theory,\nnamely that DN performance can be significantly improved by enforcing\northogonality in its linear filters.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 13:39:44 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Balestriero", "Randall", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1810.09311", "submitter": "Alejandro Moreo Fern\\'andez", "authors": "Alejandro Moreo, Andrea Esuli, Fabrizio Sebastiani", "title": "Revisiting Distributional Correspondence Indexing: A Python\n  Reimplementation and New Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces PyDCI, a new implementation of Distributional\nCorrespondence Indexing (DCI) written in Python. DCI is a transfer learning\nmethod for cross-domain and cross-lingual text classification for which we had\nprovided an implementation (here called JaDCI) built on top of JaTeCS, a Java\nframework for text classification. PyDCI is a stand-alone version of DCI that\nexploits scikit-learn and the SciPy stack. We here report on new experiments\nthat we have carried out in order to test PyDCI, and in which we use as\nbaselines new high-performing methods that have appeared after DCI was\noriginally proposed. These experiments show that, thanks to a few subtle ways\nin which we have improved DCI, PyDCI outperforms both JaDCI and the\nabove-mentioned high-performing methods, and delivers the best known results on\nthe two popular benchmarks on which we had tested DCI, i.e.,\nMultiDomainSentiment (a.k.a. MDS -- for cross-domain adaptation) and\nWebis-CLS-10 (for cross-lingual adaptation). PyDCI, together with the code\nallowing to replicate our experiments, is available at\nhttps://github.com/AlexMoreo/pydci .\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 07:27:24 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Moreo", "Alejandro", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1810.09312", "submitter": "Mahnaz Koupaee", "authors": "Mahnaz Koupaee, William Yang Wang", "title": "Analyzing and Interpreting Convolutional Neural Networks in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been successfully applied to various NLP\ntasks. However, it is not obvious whether they model different linguistic\npatterns such as negation, intensification, and clause compositionality to help\nthe decision-making process. In this paper, we apply visualization techniques\nto observe how the model can capture different linguistic features and how\nthese features can affect the performance of the model. Later on, we try to\nidentify the model errors and their sources. We believe that interpreting CNNs\nis the first step to understand the underlying semantic features which can\nraise awareness to further improve the performance and explainability of CNN\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 05:18:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koupaee", "Mahnaz", ""], ["Wang", "William Yang", ""]]}, {"id": "1810.09346", "submitter": "Alon Resler", "authors": "Alon Resler, Yishay Mansour", "title": "Adversarial Online Learning with noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and study models of adversarial online learning where the feedback\nobserved by the learner is noisy, and the feedback is either full information\nfeedback or bandit feedback. Specifically, we consider binary losses xored with\nthe noise, which is a Bernoulli random variable. We consider both a constant\nnoise rate and a variable noise rate. Our main results are tight regret bounds\nfor learning with noise in the adversarial online learning model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:10:41 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 11:59:42 GMT"}, {"version": "v3", "created": "Sun, 4 Nov 2018 10:49:09 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Resler", "Alon", ""], ["Mansour", "Yishay", ""]]}, {"id": "1810.09352", "submitter": "Riccardo Guidotti", "authors": "Riccardo Guidotti, Salvatore Ruggieri", "title": "On The Stability of Interpretable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable classification models are built with the purpose of providing a\ncomprehensible description of the decision logic to an external oversight\nagent. When considered in isolation, a decision tree, a set of classification\nrules, or a linear model, are widely recognized as human-interpretable.\nHowever, such models are generated as part of a larger analytical process. Bias\nin data collection and preparation, or in model's construction may severely\naffect the accountability of the design process. We conduct an experimental\nstudy of the stability of interpretable models with respect to feature\nselection, instance selection, and model selection. Our conclusions should\nraise awareness and attention of the scientific community on the need of a\nstability impact assessment of interpretable models.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:16:53 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 08:45:23 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Guidotti", "Riccardo", ""], ["Ruggieri", "Salvatore", ""]]}, {"id": "1810.09365", "submitter": "Guillaume Devineau", "authors": "Guillaume Devineau, Philip Polack, Florent Altch\\'e, Fabien Moutarde", "title": "Coupled Longitudinal and Lateral Control of a Vehicle using Deep\n  Learning", "comments": "Published in the IEEE 2018 International Conference on Intelligent\n  Transportation Systems (ITSC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the capability of deep neural networks to capture key\ncharacteristics of vehicle dynamics, and their ability to perform coupled\nlongitudinal and lateral control of a vehicle. To this extent, two different\nartificial neural networks are trained to compute vehicle controls\ncorresponding to a reference trajectory, using a dataset based on high-fidelity\nsimulations of vehicle dynamics. In this study, control inputs are chosen as\nthe steering angle of the front wheels, and the applied torque on each wheel.\nThe performance of both models, namely a Multi-Layer Perceptron (MLP) and a\nConvolutional Neural Network (CNN), is evaluated based on their ability to\ndrive the vehicle on a challenging test track, shifting between long straight\nlines and tight curves. A comparison to conventional decoupled controllers on\nthe same track is also provided.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:35:12 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Devineau", "Guillaume", ""], ["Polack", "Philip", ""], ["Altch\u00e9", "Florent", ""], ["Moutarde", "Fabien", ""]]}, {"id": "1810.09390", "submitter": "Joseph C. Lam", "authors": "Juliette Achdou, Joseph C. Lam, Alexandra Carpentier and Gilles\n  Blanchard", "title": "A minimax near-optimal algorithm for adaptive rejection sampling", "comments": "32 pages, 4 figures. Submitted to ALT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rejection Sampling is a fundamental Monte-Carlo method. It is used to sample\nfrom distributions admitting a probability density function which can be\nevaluated exactly at any given point, albeit at a high computational cost.\nHowever, without proper tuning, this technique implies a high rejection rate.\nSeveral methods have been explored to cope with this problem, based on the\nprinciple of adaptively estimating the density by a simpler function, using the\ninformation of the previous samples. Most of them either rely on strong\nassumptions on the form of the density, or do not offer any theoretical\nperformance guarantee. We give the first theoretical lower bound for the\nproblem of adaptive rejection sampling and introduce a new algorithm which\nguarantees a near-optimal rejection rate in a minimax sense.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:22:43 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Achdou", "Juliette", ""], ["Lam", "Joseph C.", ""], ["Carpentier", "Alexandra", ""], ["Blanchard", "Gilles", ""]]}, {"id": "1810.09391", "submitter": "Constantine Dovrolis", "authors": "Constantine Dovrolis", "title": "A neuro-inspired architecture for unsupervised continual learning based\n  on online clustering and hierarchical predictive coding", "comments": "Under peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose that the Continual Learning desiderata can be achieved through a\nneuro-inspired architecture, grounded on Mountcastle's cortical column\nhypothesis. The proposed architecture involves a single module, called\nSelf-Taught Associative Memory (STAM), which models the function of a cortical\ncolumn. STAMs are repeated in multi-level hierarchies involving feedforward,\nlateral and feedback connections. STAM networks learn in an unsupervised\nmanner, based on a combination of online clustering and hierarchical predictive\ncoding. This short paper only presents the architecture and its connections\nwith neuroscience. A mathematical formulation and experimental results will be\npresented in an extended version of this paper.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:27:21 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dovrolis", "Constantine", ""]]}, {"id": "1810.09401", "submitter": "Hamid Dadkhahi", "authors": "Hamid Dadkhahi and Sahand Negahban", "title": "Alternating Linear Bandits for Online Matrix-Factorization\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online collaborative filtering in the online\nsetting, where items are recommended to the users over time. At each time step,\nthe user (selected by the environment) consumes an item (selected by the agent)\nand provides a rating of the selected item. In this paper, we propose a novel\nalgorithm for online matrix factorization recommendation that combines linear\nbandits and alternating least squares. In this formulation, the bandit feedback\nis equal to the difference between the ratings of the best and selected items.\nWe evaluate the performance of the proposed algorithm over time using both\ncumulative regret and average cumulative NDCG. Simulation results over three\nsynthetic datasets as well as three real-world datasets for online\ncollaborative filtering indicate the superior performance of the proposed\nalgorithm over two state-of-the-art online algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:52:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dadkhahi", "Hamid", ""], ["Negahban", "Sahand", ""]]}, {"id": "1810.09409", "submitter": "Matthias Meyer", "authors": "Matthias Meyer, Timo Farei-Campagna, Akos Pasztor, Reto Da Forno,\n  Tonio Gsell, J\\'erome Faillettaz, Andreas Vieli, Samuel Weber, Jan Beutel,\n  Lothar Thiele", "title": "Event-triggered Natural Hazard Monitoring with Convolutional Neural\n  Networks on the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural hazard warning systems fast decision making is vital to avoid\ncatastrophes. Decision making at the edge of a wireless sensor network promises\nfast response times but is limited by the availability of energy, data transfer\nspeed, processing and memory constraints. In this work we present a realization\nof a wireless sensor network for hazard monitoring based on an array of\nevent-triggered single-channel micro-seismic sensors with advanced signal\nprocessing and characterization capabilities based on a novel co-detection\ntechnique. On the one hand we leverage an ultra-low power, threshold-triggering\ncircuit paired with on-demand digital signal acquisition capable of extracting\nrelevant information exactly and efficiently at times when it matters most and\nconsequentially not wasting precious resources when nothing can be observed. On\nthe other hand we utilize machine-learning-based classification implemented on\nlow-power, off-the-shelf microcontrollers to avoid false positive warnings and\nto actively identify humans in hazard zones. The sensors' response time and\nmemory requirement is substantially improved by quantizing and pipelining the\ninference of a convolutional neural network. In this way, convolutional neural\nnetworks that would not run unmodified on a memory constrained device can be\nexecuted in real-time and at scale on low-power embedded devices. A field study\nwith our system is running on the rockfall scarp of the Matterhorn H\\\"ornligrat\nat 3500 m a.s.l. since 08/2018.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:24:31 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 10:11:47 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Meyer", "Matthias", ""], ["Farei-Campagna", "Timo", ""], ["Pasztor", "Akos", ""], ["Da Forno", "Reto", ""], ["Gsell", "Tonio", ""], ["Faillettaz", "J\u00e9rome", ""], ["Vieli", "Andreas", ""], ["Weber", "Samuel", ""], ["Beutel", "Jan", ""], ["Thiele", "Lothar", ""]]}, {"id": "1810.09414", "submitter": "Rodrigo Collazo", "authors": "Rodrigo A. Collazo, Jim Q. Smith", "title": "Properties of an N Time-Slice Dynamic Chain Event Graph", "comments": "38 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dynamic Chain Event Graph (DCEG) provides a rich tree-based framework for\nmodelling a dynamic process with highly asymmetric developments. An N\nTime-Slice DCEG (NT-DCEG) is a useful subclass of the DCEG class that exhibits\na specific type of periodicity in its supporting tree graph and embodies a\ntime-homogeneity assumption. Here some desired properties of an NT-DCEG is\nexplored. In particular, we prove that the class of NT-DCEGs contains all\ndiscrete N time-slice Dynamic Bayesian Networks as special cases. We also\ndevelop a method to distributively construct an NT-DCEG model. By exploiting\nthe topology of an NT-DCEG graph, we show how to construct intrinsic random\nvariables which exhibit context-specific independences that can then be checked\nby domain experts. We also show how an NT-DCEG can be used to depict various\nstructural and Granger causal hypotheses about a given process. Our methods are\nillustrated throughout using examples of dynamic multivariate processes\ndescribing inmate radicalisation in a prison.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:35:33 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Collazo", "Rodrigo A.", ""], ["Smith", "Jim Q.", ""]]}, {"id": "1810.09418", "submitter": "Andrea Schioppa", "authors": "Andrea Schioppa", "title": "Optimality of the final model found via Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study convergence properties of Stochastic Gradient Descent (SGD) for\nconvex objectives without assumptions on smoothness or strict convexity. We\nconsider the question of establishing that with high probability the objective\nevaluated at the candidate minimizer returned by SGD is close to the minimal\nvalue of the objective. We compare this result concerning the final candidate\nminimzer (i.e. the final model parameters learned after all gradient steps) to\nthe online learning techniques of [Zin03] that take a rolling average of the\nmodel parameters at the different steps of SGD.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:36:20 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Schioppa", "Andrea", ""]]}, {"id": "1810.09425", "submitter": "Jakub Mare\\v{c}ek", "authors": "Philipp Haehnel, Jakub Marecek, Julien Monteil, and Fearghal O'Donncha", "title": "Using Deep Learning to Extend the Range of Air-Pollution Monitoring and\n  Forecasting", "comments": "14 pages, 10 figures", "journal-ref": "Journal of Computational Physics, 2020", "doi": "10.1016/j.jcp.2020.109278", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across numerous applications, forecasting relies on numerical solvers for\npartial differential equations (PDEs). Although the use of deep-learning\ntechniques has been proposed, actual applications have been restricted by the\nfact the training data are obtained using traditional PDE solvers. Thereby, the\nuses of deep-learning techniques were limited to domains, where the PDE solver\nwas applicable.\n  We demonstrate a deep-learning framework for air-pollution monitoring and\nforecasting that provides the ability to train across different model domains,\nas well as a reduction in the run-time by two orders of magnitude. It presents\na first-of-a-kind implementation that combines deep-learning and\ndomain-decomposition techniques to allow model deployments extend beyond the\ndomain(s) on which the it has been trained.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:46:23 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 12:47:19 GMT"}, {"version": "v3", "created": "Sun, 26 Jan 2020 23:55:43 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Haehnel", "Philipp", ""], ["Marecek", "Jakub", ""], ["Monteil", "Julien", ""], ["O'Donncha", "Fearghal", ""]]}, {"id": "1810.09433", "submitter": "Ehsan Hajiramezanali", "authors": "Ehsan Hajiramezanali, Siamak Zamani Dadaneh, Alireza Karbalayghareh,\n  Mingyuan Zhou, and Xiaoning Qian", "title": "Bayesian multi-domain learning for cancer subtype discovery from\n  next-generation sequencing count data", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision medicine aims for personalized prognosis and therapeutics by\nutilizing recent genome-scale high-throughput profiling techniques, including\nnext-generation sequencing (NGS). However, translating NGS data faces several\nchallenges. First, NGS count data are often overdispersed, requiring\nappropriate modeling. Second, compared to the number of involved molecules and\nsystem complexity, the number of available samples for studying complex\ndisease, such as cancer, is often limited, especially considering disease\nheterogeneity. The key question is whether we may integrate available data from\nall different sources or domains to achieve reproducible disease prognosis\nbased on NGS count data. In this paper, we develop a Bayesian Multi-Domain\nLearning (BMDL) model that derives domain-dependent latent representations of\noverdispersed count data based on hierarchical negative binomial factorization\nfor accurate cancer subtyping even if the number of samples for a specific\ncancer type is small. Experimental results from both our simulated and NGS\ndatasets from The Cancer Genome Atlas (TCGA) demonstrate the promising\npotential of BMDL for effective multi-domain learning without \"negative\ntransfer\" effects often seen in existing multi-task learning and transfer\nlearning methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:58:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hajiramezanali", "Ehsan", ""], ["Dadaneh", "Siamak Zamani", ""], ["Karbalayghareh", "Alireza", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1810.09440", "submitter": "Karim Pichara Baksai", "authors": "Carlos Aguirre and Karim Pichara and Ignacio Becker", "title": "Deep multi-survey classification of variable stars", "comments": "Accepted for publication in Monthly Notices of the Royal Astronomical\n  Society", "journal-ref": null, "doi": "10.1093/mnras/sty2836", "report-no": null, "categories": "astro-ph.IM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, a considerable amount of effort has been made to\nclassify variable stars using different machine learning techniques. Typically,\nlight curves are represented as vectors of statistical descriptors or features\nthat are used to train various algorithms. These features demand big\ncomputational powers that can last from hours to days, making impossible to\ncreate scalable and efficient ways of automatically classifying variable stars.\nAlso, light curves from different surveys cannot be integrated and analyzed\ntogether when using features, because of observational differences. For\nexample, having variations in cadence and filters, feature distributions become\nbiased and require expensive data-calibration models. The vast amount of data\nthat will be generated soon make necessary to develop scalable machine learning\narchitectures without expensive integration techniques. Convolutional Neural\nNetworks have shown impressing results in raw image classification and\nrepresentation within the machine learning literature. In this work, we present\na novel Deep Learning model for light curve classification, mainly based on\nconvolutional units. Our architecture receives as input the differences between\ntime and magnitude of light curves. It captures the essential classification\npatterns regardless of cadence and filter. In addition, we introduce a novel\ndata augmentation schema for unevenly sampled time series. We test our method\nusing three different surveys: OGLE-III; Corot; and VVV, which differ in\nfilters, cadence, and area of the sky. We show that besides the benefit of\nscalability, our model obtains state of the art levels accuracy in light curve\nclassification benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 14:22:31 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Aguirre", "Carlos", ""], ["Pichara", "Karim", ""], ["Becker", "Ignacio", ""]]}, {"id": "1810.09447", "submitter": "Babak Barazandeh", "authors": "Babak Barazandeh, Mohammadhussein Rafieisakhaei, Sunwook Kim, Zhenyu\n  (James) Kong, Maury A. Nussbaum", "title": "A Method for Robust Online Classification using Dictionary Learning:\n  Development and Assessment for Monitoring Manual Material Handling Activities\n  Using Wearable Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification methods based on sparse estimation have drawn much attention\nrecently, due to their effectiveness in processing high-dimensional data such\nas images. In this paper, a method to improve the performance of a sparse\nrepresentation classification (SRC) approach is proposed; it is then applied to\nthe problem of online process monitoring of human workers, specifically manual\nmaterial handling (MMH) operations monitored using wearable sensors (involving\n111 sensor channels). Our proposed method optimizes the design matrix (aka\ndictionary) in the linear model used for SRC, minimizing its ill-posedness to\nachieve a sparse solution. This procedure is based on the idea of dictionary\nlearning (DL): we optimize the design matrix formed by training datasets to\nminimize both redundancy and coherency as well as reducing the size of these\ndatasets. Use of such optimized training data can subsequently improve\nclassification accuracy and help decrease the computational time needed for the\nSRC; it is thus more applicable for online process monitoring. Performance of\nthe proposed methodology is demonstrated using wearable sensor data obtained\nfrom manual material handling experiments, and is found to be superior to those\nof benchmark methods in terms of accuracy, while also requiring computational\ntime appropriate for MMH online monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 03:13:48 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Barazandeh", "Babak", "", "James"], ["Rafieisakhaei", "Mohammadhussein", "", "James"], ["Kim", "Sunwook", "", "James"], ["Zhenyu", "", "", "James"], ["Kong", "", ""], ["Nussbaum", "Maury A.", ""]]}, {"id": "1810.09502", "submitter": "Antreas Antoniou Mr", "authors": "Antreas Antoniou, Harrison Edwards and Amos Storkey", "title": "How to train your MAML", "comments": "Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of few-shot learning has recently seen substantial advancements.\nMost of these advancements came from casting few-shot learning as a\nmeta-learning problem. Model Agnostic Meta Learning or MAML is currently one of\nthe best approaches for few-shot learning via meta-learning. MAML is simple,\nelegant and very powerful, however, it has a variety of issues, such as being\nvery sensitive to neural network architectures, often leading to instability\nduring training, requiring arduous hyperparameter searches to stabilize\ntraining and achieve high generalization and being very computationally\nexpensive at both training and inference times. In this paper, we propose\nvarious modifications to MAML that not only stabilize the system, but also\nsubstantially improve the generalization performance, convergence speed and\ncomputational overhead of MAML, which we call MAML++.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 18:48:16 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 06:13:09 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 23:11:02 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Antoniou", "Antreas", ""], ["Edwards", "Harrison", ""], ["Storkey", "Amos", ""]]}, {"id": "1810.09519", "submitter": "Justin Khim", "authors": "Justin Khim and Po-Ling Loh", "title": "Adversarial Risk Bounds via Function Transformation", "comments": "43 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive bounds for a notion of adversarial risk, designed to characterize\nthe robustness of linear and neural network classifiers to adversarial\nperturbations. Specifically, we introduce a new class of function\ntransformations with the property that the risk of the transformed functions\nupper-bounds the adversarial risk of the original functions. This reduces the\nproblem of deriving bounds on the adversarial risk to the problem of deriving\nrisk bounds using standard learning-theoretic techniques. We then derive bounds\non the Rademacher complexities of the transformed function classes, obtaining\nerror rates on the same order as the generalization error of the original\nfunction classes. We also discuss extensions of our theory to multiclass\nclassification and regression. Finally, we provide two algorithms for\noptimizing the adversarial risk bounds in the linear case, and discuss\nconnections to regularization and distributional robustness.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 19:51:20 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 22:29:27 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Khim", "Justin", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1810.09538", "submitter": "Eli Bingham", "authors": "Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer,\n  Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul\n  Horsfall, Noah D. Goodman", "title": "Pyro: Deep Universal Probabilistic Programming", "comments": "Submitted to JMLR MLOSS track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pyro is a probabilistic programming language built on Python as a platform\nfor developing advanced probabilistic models in AI research. To scale to large\ndatasets and high-dimensional models, Pyro uses stochastic variational\ninference algorithms and probability distributions built on top of PyTorch, a\nmodern GPU-accelerated deep learning framework. To accommodate complex or\nmodel-specific algorithmic behavior, Pyro leverages Poutine, a library of\ncomposable building blocks for modifying the behavior of probabilistic\nprograms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 19:28:32 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Bingham", "Eli", ""], ["Chen", "Jonathan P.", ""], ["Jankowiak", "Martin", ""], ["Obermeyer", "Fritz", ""], ["Pradhan", "Neeraj", ""], ["Karaletsos", "Theofanis", ""], ["Singh", "Rohit", ""], ["Szerlip", "Paul", ""], ["Horsfall", "Paul", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1810.09549", "submitter": "Benjamin Day", "authors": "Conor Sheehan, Ben Day, Pietro Li\\`o", "title": "Introducing Curvature to the Label Space", "comments": "Under review as a workshop paper at MetaLearn, NIPS 2018, 4 pages, 2\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-hot encoding is a labelling system that embeds classes as standard basis\nvectors in a label space. Despite seeing near-universal use in supervised\ncategorical classification tasks, the scheme is problematic in its geometric\nimplication that, as all classes are equally distant, all classes are equally\ndifferent. This is inconsistent with most, if not all, real-world tasks due to\nthe prevalence of ancestral and convergent relationships generating a varying\ndegree of morphological similarity across classes. We address this issue by\nintroducing curvature to the label-space using a metric tensor as a\nself-regulating method that better represents these relationships as a bolt-on,\nlearning-algorithm agnostic solution. We propose both general constraints and\nspecific statistical parameterizations of the metric and identify a direction\nfor future research using autoencoder-based parameterizations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 20:57:42 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sheehan", "Conor", ""], ["Day", "Ben", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1810.09558", "submitter": "Houssam Nassif", "authors": "Daniel N Hill, Houssam Nassif, Yi Liu, Anand Iyer, S V N Vishwanathan", "title": "An Efficient Bandit Algorithm for Realtime Multivariate Optimization", "comments": "KDD'17 Audience Appreciation Award", "journal-ref": "Daniel N. Hill, Houssam Nassif, Yi Liu, Anand Iyer, and S. V. N.\n  Vishwanathan. 2017. An Efficient Bandit Algorithm for Realtime Multivariate\n  Optimization. In Proceedings of KDD'17, Halifax, NS, Canada, pp. 1813-1821,\n  2017", "doi": "10.1145/3097983.3098184", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is commonly employed to determine the content of web pages, such\nas to maximize conversions on landing pages or click-through rates on search\nengine result pages. Often the layout of these pages can be decoupled into\nseveral separate decisions. For example, the composition of a landing page may\ninvolve deciding which image to show, which wording to use, what color\nbackground to display, etc. Such optimization is a combinatorial problem over\nan exponentially large decision space. Randomized experiments do not scale well\nto this setting, and therefore, in practice, one is typically limited to\noptimizing a single aspect of a web page at a time. This represents a missed\nopportunity in both the speed of experimentation and the exploitation of\npossible interactions between layout decisions.\n  Here we focus on multivariate optimization of interactive web pages. We\nformulate an approach where the possible interactions between different\ncomponents of the page are modeled explicitly. We apply bandit methodology to\nexplore the layout space efficiently and use hill-climbing to select optimal\ncontent in realtime. Our algorithm also extends to contextualization and\npersonalization of layout selection. Simulation results show the suitability of\nour approach to large decision spaces with strong interactions between content.\nWe further apply our algorithm to optimize a message that promotes adoption of\nan Amazon service. After only a single week of online optimization, we saw a\n21% conversion increase compared to the median layout. Our technique is\ncurrently being deployed to optimize content across several locations at\nAmazon.com.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 21:09:38 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Hill", "Daniel N", ""], ["Nassif", "Houssam", ""], ["Liu", "Yi", ""], ["Iyer", "Anand", ""], ["Vishwanathan", "S V N", ""]]}, {"id": "1810.09568", "submitter": "Shane Barratt", "authors": "Shane Barratt, Mykel Kochenderfer, and Stephen Boyd", "title": "Learning Probabilistic Trajectory Models of Aircraft in Terminal\n  Airspace from Position Data", "comments": "IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2018.2877572", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models for predicting aircraft motion are an important component of modern\naeronautical systems. These models help aircraft plan collision avoidance\nmaneuvers and help conduct offline performance and safety analyses. In this\narticle, we develop a method for learning a probabilistic generative model of\naircraft motion in terminal airspace, the controlled airspace surrounding a\ngiven airport. The method fits the model based on a historical dataset of\nradar-based position measurements of aircraft landings and takeoffs at that\nairport. We find that the model generates realistic trajectories, provides\naccurate predictions, and captures the statistical properties of aircraft\ntrajectories. Furthermore, the model trains quickly, is compact, and allows for\nefficient real-time inference.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 21:41:11 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Barratt", "Shane", ""], ["Kochenderfer", "Mykel", ""], ["Boyd", "Stephen", ""]]}, {"id": "1810.09569", "submitter": "Adel Javanmard", "authors": "Ery Arias-Castro, Adel Javanmard, Bruno Pelletier", "title": "Perturbation Bounds for Procrustes, Classical Scaling, and\n  Trilateration, with Applications to Manifold Learning", "comments": "33 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the common tasks in unsupervised learning is dimensionality reduction,\nwhere the goal is to find meaningful low-dimensional structures hidden in\nhigh-dimensional data. Sometimes referred to as manifold learning, this problem\nis closely related to the problem of localization, which aims at embedding a\nweighted graph into a low-dimensional Euclidean space. Several methods have\nbeen proposed for localization, and also manifold learning. Nonetheless, the\nrobustness property of most of them is little understood. In this paper, we\nobtain perturbation bounds for classical scaling and trilateration, which are\nthen applied to derive performance bounds for Isomap, Landmark Isomap, and\nMaximum Variance Unfolding. A new perturbation bound for procrustes analysis\nplays a key role.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 21:43:33 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 20:41:02 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Javanmard", "Adel", ""], ["Pelletier", "Bruno", ""]]}, {"id": "1810.09583", "submitter": "Jie Ding", "authors": "Jie Ding, Vahid Tarokh, and Yuhong Yang", "title": "Model Selection Techniques -- An Overview", "comments": "accepted by IEEE SIGNAL PROCESSING MAGAZINE", "journal-ref": null, "doi": "10.1109/MSP.2018.2867638", "report-no": null, "categories": "stat.ML cs.IT cs.LG econ.EM math.IT physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, analysts usually explore various statistical models\nor machine learning methods for observed data in order to facilitate scientific\ndiscoveries or gain predictive power. Whatever data and fitting procedures are\nemployed, a crucial step is to select the most appropriate model or method from\na set of candidates. Model selection is a key ingredient in data analysis for\nreliable and reproducible statistical inference or prediction, and thus central\nto scientific studies in fields such as ecology, economics, engineering,\nfinance, political science, biology, and epidemiology. There has been a long\nhistory of model selection techniques that arise from researches in statistics,\ninformation theory, and signal processing. A considerable number of methods\nhave been proposed, following different philosophies and exhibiting varying\nperformances. The purpose of this article is to bring a comprehensive overview\nof them, in terms of their motivation, large sample performance, and\napplicability. We provide integrated and practically relevant discussions on\ntheoretical properties of state-of- the-art model selection approaches. We also\nshare our thoughts on some controversial views on the practice of model\nselection.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 22:33:44 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Ding", "Jie", ""], ["Tarokh", "Vahid", ""], ["Yang", "Yuhong", ""]]}, {"id": "1810.09591", "submitter": "Malay Haldar", "authors": "Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin\n  Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull,\n  Brendan M. Collins and Thomas Legrand", "title": "Applying Deep Learning To Airbnb Search", "comments": "8 pages", "journal-ref": null, "doi": "10.1145/3292500.3330658", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application to search ranking is one of the biggest machine learning\nsuccess stories at Airbnb. Much of the initial gains were driven by a gradient\nboosted decision tree model. The gains, however, plateaued over time. This\npaper discusses the work done in applying neural networks in an attempt to\nbreak out of that plateau. We present our perspective not with the intention of\npushing the frontier of new modeling techniques. Instead, ours is a story of\nthe elements we found useful in applying neural networks to a real life\nproduct. Deep learning was steep learning for us. To other teams embarking on\nsimilar journeys, we hope an account of our struggles and triumphs will provide\nsome useful pointers. Bon voyage!\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:11:01 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 18:28:03 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Haldar", "Malay", ""], ["Abdool", "Mustafa", ""], ["Ramanathan", "Prashant", ""], ["Xu", "Tao", ""], ["Yang", "Shulin", ""], ["Duan", "Huizhong", ""], ["Zhang", "Qing", ""], ["Barrow-Williams", "Nick", ""], ["Turnbull", "Bradley C.", ""], ["Collins", "Brendan M.", ""], ["Legrand", "Thomas", ""]]}, {"id": "1810.09593", "submitter": "Edward Choi", "authors": "Edward Choi, Cao Xiao, Walter F. Stewart, Jimeng Sun", "title": "MiME: Multilevel Medical Embedding of Electronic Health Records for\n  Predictive Healthcare", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models exhibit state-of-the-art performance for many predictive\nhealthcare tasks using electronic health records (EHR) data, but these models\ntypically require training data volume that exceeds the capacity of most\nhealthcare systems. External resources such as medical ontologies are used to\nbridge the data volume constraint, but this approach is often not directly\napplicable or useful because of inconsistencies with terminology. To solve the\ndata insufficiency challenge, we leverage the inherent multilevel structure of\nEHR data and, in particular, the encoded relationships among medical codes. We\npropose Multilevel Medical Embedding (MiME) which learns the multilevel\nembedding of EHR data while jointly performing auxiliary prediction tasks that\nrely on this inherent EHR structure without the need for external labels. We\nconducted two prediction tasks, heart failure prediction and sequential disease\nprediction, where MiME outperformed baseline methods in diverse evaluation\nsettings. In particular, MiME consistently outperformed all baselines when\npredicting heart failure on datasets of different volumes, especially\ndemonstrating the greatest performance improvement (15% relative gain in PR-AUC\nover the best baseline) on the smallest dataset, demonstrating its ability to\neffectively model the multilevel structure of EHR data.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:19:43 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Choi", "Edward", ""], ["Xiao", "Cao", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1810.09619", "submitter": "Yiwen Guo", "authors": "Yiwen Guo, Chao Zhang, Changshui Zhang and Yurong Chen", "title": "Sparse DNNs with Improved Adversarial Robustness", "comments": "l1 regularization on weights --> l1 regularization on activations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are computationally/memory-intensive and\nvulnerable to adversarial attacks, making them prohibitive in some real-world\napplications. By converting dense models into sparse ones, pruning appears to\nbe a promising solution to reducing the computation/memory cost. This paper\nstudies classification models, especially DNN-based ones, to demonstrate that\nthere exists intrinsic relationships between their sparsity and adversarial\nrobustness. Our analyses reveal, both theoretically and empirically, that\nnonlinear DNN-based classifiers behave differently under $l_2$ attacks from\nsome linear ones. We further demonstrate that an appropriately higher model\nsparsity implies better robustness of nonlinear DNNs, whereas over-sparsified\nmodels can be more difficult to resist adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 01:05:41 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:32:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Guo", "Yiwen", ""], ["Zhang", "Chao", ""], ["Zhang", "Changshui", ""], ["Chen", "Yurong", ""]]}, {"id": "1810.09650", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Ruoxi Jia, Gerald Friedland, Bo Li, Costas Spanos", "title": "One Bit Matters: Understanding Adversarial Examples as the Abuse of\n  Redundancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great success achieved in machine learning (ML), adversarial\nexamples have caused concerns with regards to its trustworthiness: A small\nperturbation of an input results in an arbitrary failure of an otherwise\nseemingly well-trained ML model. While studies are being conducted to discover\nthe intrinsic properties of adversarial examples, such as their transferability\nand universality, there is insufficient theoretic analysis to help understand\nthe phenomenon in a way that can influence the design process of ML\nexperiments. In this paper, we deduce an information-theoretic model which\nexplains adversarial attacks as the abuse of feature redundancies in ML\nalgorithms. We prove that feature redundancy is a necessary condition for the\nexistence of adversarial examples. Our model helps to explain some major\nquestions raised in many anecdotal studies on adversarial examples. Our theory\nis backed up by empirical measurements of the information content of benign and\nadversarial examples on both image and text datasets. Our measurements show\nthat typical adversarial examples introduce just enough redundancy to overflow\nthe decision making of an ML model trained on corresponding benign examples. We\nconclude with actionable recommendations to improve the robustness of machine\nlearners against adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:23:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Wang", "Jingkang", ""], ["Jia", "Ruoxi", ""], ["Friedland", "Gerald", ""], ["Li", "Bo", ""], ["Spanos", "Costas", ""]]}, {"id": "1810.09656", "submitter": "Ermo Wei", "authors": "Ermo Wei and Drew Wicke and Sean Luke", "title": "Hierarchical Approaches for Reinforcement Learning in Parameterized\n  Action Space", "comments": "Accepted in AAAI 18 Spring Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore Deep Reinforcement Learning in a parameterized action space.\nSpecifically, we investigate how to achieve sample-efficient end-to-end\ntraining in these tasks. We propose a new compact architecture for the tasks\nwhere the parameter policy is conditioned on the output of the discrete action\npolicy. We also propose two new methods based on the state-of-the-art\nalgorithms Trust Region Policy Optimization (TRPO) and Stochastic Value\nGradient (SVG) to train such an architecture. We demonstrate that these methods\noutperform the state of the art method, Parameterized Action DDPG, on test\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:52:53 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Wei", "Ermo", ""], ["Wicke", "Drew", ""], ["Luke", "Sean", ""]]}, {"id": "1810.09665", "submitter": "Stefano Spigler", "authors": "Stefano Spigler, Mario Geiger, St\\'ephane d'Ascoli, Levent Sagun,\n  Giulio Biroli and Matthieu Wyart", "title": "A jamming transition from under- to over-parametrization affects loss\n  landscape and generalization", "comments": "arXiv admin note: text overlap with arXiv:1809.09349", "journal-ref": null, "doi": "10.1088/1751-8121/ab4c8b", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that in fully-connected networks a phase transition delimits the\nover- and under-parametrized regimes where fitting can or cannot be achieved.\nUnder some general conditions, we show that this transition is sharp for the\nhinge loss. In the whole over-parametrized regime, poor minima of the loss are\nnot encountered during training since the number of constraints to satisfy is\ntoo small to hamper minimization. Our findings support a link between this\ntransition and the generalization properties of the network: as we increase the\nnumber of parameters of a given model, starting from an under-parametrized\nnetwork, we observe that the generalization error displays three phases: (i)\ninitial decay, (ii) increase until the transition point --- where it displays a\ncusp --- and (iii) slow decay toward a constant for the rest of the\nover-parametrized regime. Thereby we identify the region where the classical\nphenomenon of over-fitting takes place, and the region where the model keeps\nimproving, in line with previous empirical observations for modern neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 09:49:32 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 09:22:15 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 13:29:18 GMT"}, {"version": "v4", "created": "Mon, 18 Feb 2019 09:19:24 GMT"}, {"version": "v5", "created": "Tue, 18 Jun 2019 09:51:38 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Spigler", "Stefano", ""], ["Geiger", "Mario", ""], ["d'Ascoli", "St\u00e9phane", ""], ["Sagun", "Levent", ""], ["Biroli", "Giulio", ""], ["Wyart", "Matthieu", ""]]}, {"id": "1810.09666", "submitter": "Anshuka Rangi", "authors": "Anshuka Rangi and Massimo Franceschetti", "title": "Online learning with feedback graphs and switching costs", "comments": "Published in Proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019. PMLR: Volume 89", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online learning when partial feedback information is provided\nfollowing every action of the learning process, and the learner incurs\nswitching costs for changing his actions. In this setting, the feedback\ninformation system can be represented by a graph, and previous works studied\nthe expected regret of the learner in the case of a clique (Expert setup), or\ndisconnected single loops (Multi-Armed Bandits (MAB)). This work provides a\nlower bound on the expected regret in the Partial Information (PI) setting,\nnamely for general feedback graphs --excluding the clique. Additionally, it\nshows that all algorithms that are optimal without switching costs are\nnecessarily sub-optimal in the presence of switching costs, which motivates the\nneed to design new algorithms. We propose two new algorithms: Threshold Based\nEXP3 and EXP3. SC. For the two special cases of symmetric PI setting and MAB,\nthe expected regret of both of these algorithms is order optimal in the\nduration of the learning process. Additionally, Threshold Based EXP3 is order\noptimal in the switching cost, whereas EXP3. SC is not. Finally, empirical\nevaluations show that Threshold Based EXP3 outperforms the previously proposed\norder-optimal algorithms EXP3 SET in the presence of switching costs, and Batch\nEXP3 in the MAB setting with switching costs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 05:34:19 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 15:16:46 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Rangi", "Anshuka", ""], ["Franceschetti", "Massimo", ""]]}, {"id": "1810.09712", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Takuma Otsuka, Hitoshi Shimizu, Hiroshi Sawada,\n  Futoshi Naya, Naonori Ueda", "title": "Finding Appropriate Traffic Regulations via Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appropriate traffic regulations, e.g. planned road closure, are important in\ncongested events. Crowd simulators have been used to find appropriate\nregulations by simulating multiple scenarios with different regulations.\nHowever, this approach requires multiple simulation runs, which are\ntime-consuming. In this paper, we propose a method to learn a function that\noutputs regulation effects given the current traffic situation as inputs. If\nthe function is learned using the training data of many simulation runs in\nadvance, we can obtain an appropriate regulation efficiently by bypassing\nsimulations for the current situation. We use the graph convolutional networks\nfor modeling the function, which enable us to find regulations even for unseen\nareas. With the proposed method, we construct a graph for each area, where a\nnode represents a road, and an edge represents the road connection. By running\ncrowd simulations with various regulations on various areas, we generate\ntraffic situations and regulation effects. The graph convolutional networks are\ntrained to output the regulation effects given the graph with the traffic\nsituation information as inputs. With experiments using real-world road\nnetworks and a crowd simulator, we demonstrate that the proposed method can\nfind a road to close that reduces the average time needed to reach the\ndestination.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 08:19:33 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Otsuka", "Takuma", ""], ["Shimizu", "Hitoshi", ""], ["Sawada", "Hiroshi", ""], ["Naya", "Futoshi", ""], ["Ueda", "Naonori", ""]]}, {"id": "1810.09717", "submitter": "Jakub Bednarek", "authors": "Jakub Bednarek, Karol Piaskowski, Krzysztof Krawiec", "title": "Ain't Nobody Got Time For Coding: Structure-Aware Program Synthesis From\n  Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis from natural language (NL) is practical for humans and,\nonce technically feasible, would significantly facilitate software development\nand revolutionize end-user programming. We present SAPS, an end-to-end neural\nnetwork capable of mapping relatively complex, multi-sentence NL specifications\nto snippets of executable code. The proposed architecture relies exclusively on\nneural components, and is trained on abstract syntax trees, combined with a\npretrained word embedding and a bi-directional multi-layer LSTM for processing\nof word sequences. The decoder features a doubly-recurrent LSTM, for which we\npropose novel signal propagation schemes and soft attention mechanism. When\napplied to a large dataset of problems proposed in a previous study, SAPS\nperforms on par with or better than the method proposed there, producing\ncorrect programs in over 92% of cases. In contrast to other methods, it does\nnot require post-processing of the resulting programs, and uses a\nfixed-dimensional latent representation as the only interface between the NL\nanalyzer and the source code generator.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 08:29:11 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 07:17:09 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Bednarek", "Jakub", ""], ["Piaskowski", "Karol", ""], ["Krawiec", "Krzysztof", ""]]}, {"id": "1810.09733", "submitter": "Maria Cristina Heredia G\\'omez", "authors": "M. Cristina Heredia-G\\'omez, Salvador Garc\\'ia, Pedro Antonio\n  Guti\\'errez, Francisco Herrera", "title": "OCAPIS: R package for Ordinal Classification And Preprocessing In Scala", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal Data are those where a natural order exist between the labels. The\nclassification and pre-processing of this type of data is attracting more and\nmore interest in the area of machine learning, due to its presence in many\ncommon problems. Traditionally, ordinal classification problems have been\napproached as nominal problems. However, that implies not taking into account\ntheir natural order constraints. In this paper, an innovative R package named\nocapis (Ordinal Classification and Preprocessing In Scala) is introduced.\nImplemented mainly in Scala and available through Github, this library includes\nfour learners and two pre-processing algorithms for ordinal and monotonic data.\nMain features of the package and examples of installation and use are explained\nthroughout this manuscript.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 09:12:34 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 16:12:02 GMT"}, {"version": "v3", "created": "Sun, 17 Mar 2019 10:27:33 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Heredia-G\u00f3mez", "M. Cristina", ""], ["Garc\u00eda", "Salvador", ""], ["Guti\u00e9rrez", "Pedro Antonio", ""], ["Herrera", "Francisco", ""]]}, {"id": "1810.09746", "submitter": "Stephan Sloth Lorenzen", "authors": "Stephan Sloth Lorenzen and Christian Igel and Yevgeny Seldin", "title": "On PAC-Bayesian Bounds for Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing guarantees in terms of rigorous upper bounds on the generalization\nerror for the original random forest algorithm, one of the most frequently used\nmachine learning methods, are unsatisfying. We discuss and evaluate various\nPAC-Bayesian approaches to derive such bounds. The bounds do not require\nadditional hold-out data, because the out-of-bag samples from the bagging in\nthe training process can be exploited. A random forest predicts by taking a\nmajority vote of an ensemble of decision trees. The first approach is to bound\nthe error of the vote by twice the error of the corresponding Gibbs classifier\n(classifying with a single member of the ensemble selected at random). However,\nthis approach does not take into account the effect of averaging out of errors\nof individual classifiers when taking the majority vote. This effect provides a\nsignificant boost in performance when the errors are independent or negatively\ncorrelated, but when the correlations are strong the advantage from taking the\nmajority vote is small. The second approach based on PAC-Bayesian C-bounds\ntakes dependencies between ensemble members into account, but it requires\nestimating correlations between the errors of the individual classifiers. When\nthe correlations are high or the estimation is poor, the bounds degrade. In our\nexperiments, we compute generalization bounds for random forests on various\nbenchmark data sets. Because the individual decision trees already perform\nwell, their predictions are highly correlated and the C-bounds do not lead to\nsatisfactory results. For the same reason, the bounds based on the analysis of\nGibbs classifiers are typically superior and often reasonably tight. Bounds\nbased on a validation set coming at the cost of a smaller training set gave\nbetter performance guarantees, but worse performance in most experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 09:44:40 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 10:38:24 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Lorenzen", "Stephan Sloth", ""], ["Igel", "Christian", ""], ["Seldin", "Yevgeny", ""]]}, {"id": "1810.09751", "submitter": "Kim Andrea Nicoli", "authors": "Kim A. Nicoli and Pan Kessel and Michael Gastegger and Kristof T.\n  Sch\\\"utt", "title": "Analysis of Atomistic Representations Using Weighted Skip-Connections", "comments": "NIPS 2018 Workshop: Machine Learning for Molecules and Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we extend the SchNet architecture by using weighted skip\nconnections to assemble the final representation. This enables us to study the\nrelative importance of each interaction block for property prediction. We\ndemonstrate on both the QM9 and MD17 dataset that their relative weighting\ndepends strongly on the chemical composition and configurational degrees of\nfreedom of the molecules which opens the path towards a more detailed\nunderstanding of machine learning models for molecules.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 10:00:34 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 11:52:07 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Nicoli", "Kim A.", ""], ["Kessel", "Pan", ""], ["Gastegger", "Michael", ""], ["Sch\u00fctt", "Kristof T.", ""]]}, {"id": "1810.09785", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez (FAIR, PSL, SIERRA), Neil Zeghidour (PSL, FAIR,\n  LSCP), Nicolas Usunier (FAIR), L\\'eon Bottou (FAIR), Francis Bach (DI-ENS,\n  PSL, SIERRA)", "title": "SING: Symbol-to-Instrument Neural Generator", "comments": null, "journal-ref": "Conference on Neural Information Processing Systems (NIPS), Dec\n  2018, Montr{\\'e}al, Canada", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in deep learning for audio synthesis opens the way to models\nthat directly produce the waveform, shifting away from the traditional paradigm\nof relying on vocoders or MIDI synthesizers for speech or music generation.\nDespite their successes, current state-of-the-art neural audio synthesizers\nsuch as WaveNet and SampleRNN suffer from prohibitive training and inference\ntimes because they are based on autoregressive models that generate audio\nsamples one at a time at a rate of 16kHz. In this work, we study the more\ncomputationally efficient alternative of generating the waveform frame-by-frame\nwith large strides. We present SING, a lightweight neural audio synthesizer for\nthe original task of generating musical notes given desired instrument, pitch\nand velocity. Our model is trained end-to-end to generate notes from nearly\n1000 instruments with a single decoder, thanks to a new loss function that\nminimizes the distances between the log spectrograms of the generated and\ntarget waveforms. On the generalization task of synthesizing notes for pairs of\npitch and instrument not seen during training, SING produces audio with\nsignificantly improved perceptual quality compared to a state-of-the-art\nautoencoder based on WaveNet as measured by a Mean Opinion Score (MOS), and is\nabout 32 times faster for training and 2, 500 times faster for inference.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 11:27:06 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["D\u00e9fossez", "Alexandre", "", "FAIR, PSL, SIERRA"], ["Zeghidour", "Neil", "", "PSL, FAIR,\n  LSCP"], ["Usunier", "Nicolas", "", "FAIR"], ["Bottou", "L\u00e9on", "", "FAIR"], ["Bach", "Francis", "", "DI-ENS,\n  PSL, SIERRA"]]}, {"id": "1810.09828", "submitter": "Emil Iacob", "authors": "Duleep Rathgamage Don and Ionut E. Iacob", "title": "DCSVM: Fast Multi-class Classification using Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DCSVM, an efficient algorithm for multi-class classification using\nSupport Vector Machines. DCSVM is a divide and conquer algorithm which relies\non data sparsity in high dimensional space and performs a smart partitioning of\nthe whole training data set into disjoint subsets that are easily separable. A\nsingle prediction performed between two partitions eliminates at once one or\nmore classes in one partition, leaving only a reduced number of candidate\nclasses for subsequent steps. The algorithm continues recursively, reducing the\nnumber of classes at each step, until a final binary decision is made between\nthe last two classes left in the competition. In the best case scenario, our\nalgorithm makes a final decision between $k$ classes in $O(\\log k)$ decision\nsteps and in the worst case scenario DCSVM makes a final decision in $k-1$\nsteps, which is not worse than the existent techniques.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 13:07:48 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Don", "Duleep Rathgamage", ""], ["Iacob", "Ionut E.", ""]]}, {"id": "1810.09854", "submitter": "Lukas Mauch", "authors": "Lukas Mauch and Bin Yang", "title": "Deep Neural Network inference with reduced word length", "comments": "submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are powerful models for many pattern recognition\ntasks, yet their high computational complexity and memory requirement limit\nthem to applications on high-performance computing platforms. In this paper, we\npropose a new method to evaluate DNNs trained with 32bit floating point\n(float32) accuracy using only low precision integer arithmetics in combination\nwith binary shift and clipping operations. Because hardware implementation of\nthese operations is much simpler than high precision floating point\ncalculation, our method can be used for an efficient DNN inference on dedicated\nhardware. In experiments on MNIST, we demonstrate that DNNs trained with\nfloat32 can be evaluated using a combination of 2bit integer arithmetics and a\nfew float32 calculations in each layer or only 3bit integer arithmetics in\ncombination with binary shift and clipping without significant performance\ndegradation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 13:48:53 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Mauch", "Lukas", ""], ["Yang", "Bin", ""]]}, {"id": "1810.09868", "submitter": "Keno Fischer", "authors": "Keno Fischer, Elliot Saba", "title": "Automatic Full Compilation of Julia Programs and ML Models to Cloud TPUs", "comments": "Submitted to SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Google's Cloud TPUs are a promising new hardware architecture for machine\nlearning workloads. They have powered many of Google's milestone machine\nlearning achievements in recent years. Google has now made TPUs available for\ngeneral use on their cloud platform and as of very recently has opened them up\nfurther to allow use by non-TensorFlow frontends. We describe a method and\nimplementation for offloading suitable sections of Julia programs to TPUs via\nthis new API and the Google XLA compiler. Our method is able to completely fuse\nthe forward pass of a VGG19 model expressed as a Julia program into a single\nTPU executable to be offloaded to the device. Our method composes well with\nexisting compiler-based automatic differentiation techniques on Julia code, and\nwe are thus able to also automatically obtain the VGG19 backwards pass and\nsimilarly offload it to the TPU. Targeting TPUs using our compiler, we are able\nto evaluate the VGG19 forward pass on a batch of 100 images in 0.23s which\ncompares favorably to the 52.4s required for the original model on the CPU. Our\nimplementation is less than 1000 lines of Julia, with no TPU specific changes\nmade to the core Julia compiler or any other Julia packages.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:02:11 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Fischer", "Keno", ""], ["Saba", "Elliot", ""]]}, {"id": "1810.09878", "submitter": "Tara Salman", "authors": "Deval Bhamare, Tara Salman, Mohammed Samaka, Aiman Erbad, Raj Jain", "title": "Feasibility of Supervised Machine Learning for Cloud Security", "comments": null, "journal-ref": "2016 International Conference on Information Science and Security\n  (ICISS)", "doi": "10.1109/ICISSEC.2016.7885853", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is gaining significant attention, however, security is the\nbiggest hurdle in its wide acceptance. Users of cloud services are under\nconstant fear of data loss, security threats and availability issues. Recently,\nlearning-based methods for security applications are gaining popularity in the\nliterature with the advents in machine learning techniques. However, the major\nchallenge in these methods is obtaining real-time and unbiased datasets. Many\ndatasets are internal and cannot be shared due to privacy issues or may lack\ncertain statistical characteristics. As a result of this, researchers prefer to\ngenerate datasets for training and testing purpose in the simulated or closed\nexperimental environments which may lack comprehensiveness. Machine learning\nmodels trained with such a single dataset generally result in a semantic gap\nbetween results and their application. There is a dearth of research work which\ndemonstrates the effectiveness of these models across multiple datasets\nobtained in different environments. We argue that it is necessary to test the\nrobustness of the machine learning models, especially in diversified operating\nconditions, which are prevalent in cloud scenarios. In this work, we use the\nUNSW dataset to train the supervised machine learning models. We then test\nthese models with ISOT dataset. We present our results and argue that more\nresearch in the field of machine learning is still required for its\napplicability to the cloud security.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:23:43 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Bhamare", "Deval", ""], ["Salman", "Tara", ""], ["Samaka", "Mohammed", ""], ["Erbad", "Aiman", ""], ["Jain", "Raj", ""]]}, {"id": "1810.09899", "submitter": "Traiko Dinev", "authors": "Traiko Dinev and Michael U. Gutmann", "title": "Dynamic Likelihood-free Inference via Ratio Estimation (DIRE)", "comments": "For a demo, see https://traiko.com/pages/research/lfire/", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric statistical models that are implicitly defined in terms of a\nstochastic data generating process are used in a wide range of scientific\ndisciplines because they enable accurate modeling. However, learning the\nparameters from observed data is generally very difficult because their\nlikelihood function is typically intractable. Likelihood-free Bayesian\ninference methods have been proposed which include the frameworks of\napproximate Bayesian computation (ABC), synthetic likelihood, and its recent\ngeneralization that performs likelihood-free inference by ratio estimation\n(LFIRE). A major difficulty in all these methods is choosing summary statistics\nthat reduce the dimensionality of the data to facilitate inference. While\nseveral methods for choosing summary statistics have been proposed for ABC, the\nliterature for synthetic likelihood and LFIRE is very thin to date. We here\naddress this gap in the literature, focusing on the important special case of\ntime-series models. We show that convolutional neural networks trained to\npredict the input parameters from the data provide suitable summary statistics\nfor LFIRE. On a wide range of time-series models, a single neural network\narchitecture produced equally or more accurate posteriors than alternative\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:02:47 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Dinev", "Traiko", ""], ["Gutmann", "Michael U.", ""]]}, {"id": "1810.09912", "submitter": "Steven Kleinegesse", "authors": "Steven Kleinegesse and Michael Gutmann", "title": "Efficient Bayesian Experimental Design for Implicit Models", "comments": "Added references and fixed typos. Results and figures remain\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian experimental design involves the optimal allocation of resources in\nan experiment, with the aim of optimising cost and performance. For implicit\nmodels, where the likelihood is intractable but sampling from the model is\npossible, this task is particularly difficult and therefore largely unexplored.\nThis is mainly due to technical difficulties associated with approximating\nposterior distributions and utility functions. We devise a novel experimental\ndesign framework for implicit models that improves upon previous work in two\nways. First, we use the mutual information between parameters and data as the\nutility function, which has previously not been feasible. We achieve this by\nutilising Likelihood-Free Inference by Ratio Estimation (LFIRE) to approximate\nposterior distributions, instead of the traditional approximate Bayesian\ncomputation or synthetic likelihood methods. Secondly, we use Bayesian\noptimisation in order to solve the optimal design problem, as opposed to the\ntypically used grid search or sampling-based methods. We find that this\nincreases efficiency and allows us to consider higher design dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:24:29 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 13:48:19 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Kleinegesse", "Steven", ""], ["Gutmann", "Michael", ""]]}, {"id": "1810.09920", "submitter": "Alexander Lin", "authors": "Alexander Lin, Yingzhuo Zhang, Jeremy Heng, Stephen A. Allsop, Kay M.\n  Tye, Pierre E. Jacob, and Demba Ba", "title": "Clustering Time Series with Nonlinear Dynamics: A Bayesian\n  Non-Parametric and Particle-Based Approach", "comments": null, "journal-ref": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a general statistical framework for clustering multiple time\nseries that exhibit nonlinear dynamics into an a-priori-unknown number of\nsub-groups. Our motivation comes from neuroscience, where an important problem\nis to identify, within a large assembly of neurons, subsets that respond\nsimilarly to a stimulus or contingency. Upon modeling the multiple time series\nas the output of a Dirichlet process mixture of nonlinear state-space models,\nwe derive a Metropolis-within-Gibbs algorithm for full Bayesian inference that\nalternates between sampling cluster assignments and sampling parameter values\nthat form the basis of the clustering. The Metropolis step employs recent\ninnovations in particle-based methods. We apply the framework to clustering\ntime series acquired from the prefrontal cortex of mice in an experiment\ndesigned to characterize the neural underpinnings of fear.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:40:25 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 18:44:19 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 21:28:11 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 18:40:29 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Lin", "Alexander", ""], ["Zhang", "Yingzhuo", ""], ["Heng", "Jeremy", ""], ["Allsop", "Stephen A.", ""], ["Tye", "Kay M.", ""], ["Jacob", "Pierre E.", ""], ["Ba", "Demba", ""]]}, {"id": "1810.09930", "submitter": "Umberto Simola Mr.", "authors": "U. Simola, B. Pelssers, D. Barge, J. Conrad, J. Corander", "title": "Machine Learning Accelerated Likelihood-Free Event Reconstruction in\n  Dark Matter Direct Detection", "comments": null, "journal-ref": null, "doi": "10.1088/1748-0221/14/03/P03004", "report-no": null, "categories": "astro-ph.IM hep-ex hep-ph physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reconstructing the position of an interaction for any dual-phase time\nprojection chamber (TPC) with the best precision is key to directly detecting\nDark Matter. Using the likelihood-free framework, a new algorithm to\nreconstruct the 2-D (x; y) position and the size of the charge signal (e) of an\ninteraction is presented. The algorithm uses the charge signal (S2) light\ndistribution obtained by simulating events using a waveform generator. To deal\nwith the computational effort required by the likelihood-free approach, we\nemploy the Bayesian Optimization for Likelihood-Free Inference (BOLFI)\nalgorithm. Together with BOLFI, prior distributions for the parameters of\ninterest (x; y; e) and highly informative discrepancy measures to perform the\nanalyses are introduced. We evaluate the quality of the proposed algorithm by a\ncomparison against the currently existing alternative methods using a\nlarge-scale simulation study. BOLFI provides a natural probabilistic\nuncertainty measure for the reconstruction and it improved the accuracy of the\nreconstruction over the next best algorithm by up to 15% when focusing on\nevents over a large radii (R > 30 cm, the outer 37% of the detector). In\naddition, BOLFI provides the smallest uncertainties among all the tested\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 15:54:28 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 12:15:43 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 08:15:28 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Simola", "U.", ""], ["Pelssers", "B.", ""], ["Barge", "D.", ""], ["Conrad", "J.", ""], ["Corander", "J.", ""]]}, {"id": "1810.09942", "submitter": "Brandon Schoenfeld", "authors": "Brandon Schoenfeld, Christophe Giraud-Carrier, Mason Poggemann, Jarom\n  Christensen, Kevin Seppi", "title": "Preprocessor Selection for Machine Learning Pipelines", "comments": "Accepted at the ICML 2018 AutoML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the work in metalearning has focused on classifier selection,\ncombined more recently with hyperparameter optimization, with little concern\nfor data preprocessing. Yet, it is generally well accepted that machine\nlearning applications require not only model building, but also data\npreprocessing. In other words, practical solutions consist of pipelines of\nmachine learning operators rather than single algorithms. Interestingly, our\nexperiments suggest that, on average, data preprocessing hinders accuracy,\nwhile the best performing pipelines do actually make use of preprocessors.\nHere, we conduct an extensive empirical study over a wide range of learning\nalgorithms and preprocessors, and use metalearning to determine when one should\nmake use of preprocessors in ML pipeline design.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:14:11 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Schoenfeld", "Brandon", ""], ["Giraud-Carrier", "Christophe", ""], ["Poggemann", "Mason", ""], ["Christensen", "Jarom", ""], ["Seppi", "Kevin", ""]]}, {"id": "1810.09944", "submitter": "Monika Sharma", "authors": "Monika Sharma, Tristan Glatard, Eric Gelinas, Mariam Tagmouti,\n  Brigitte Jaumard", "title": "Data models for service failure prediction in supply-chain networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to predict and explain service failures in supply-chain networks, more\nprecisely among last-mile pickup and delivery services to customers. We analyze\na dataset of 500,000 services using (1) supervised classification with Random\nForests, and (2) Association Rules. Our classifier reaches an average\nsensitivity of 0.7 and an average specificity of 0.7 for the 5 studied types of\nfailure. Association Rules reassert the importance of confirmation calls to\nprevent failures due to customers not at home, show the importance of the time\nwindow size, slack time, and geographical location of the customer for the\nother failure types, and highlight the effect of the retailer company on\nseveral failure types. To reduce the occurrence of service failures, our data\nmodels could be coupled to optimizers, or used to define counter-measures to be\ntaken by human dispatchers.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 22:50:01 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sharma", "Monika", ""], ["Glatard", "Tristan", ""], ["Gelinas", "Eric", ""], ["Tagmouti", "Mariam", ""], ["Jaumard", "Brigitte", ""]]}, {"id": "1810.09945", "submitter": "Wojciech Samek", "authors": "Armin W. Thomas, Hauke R. Heekeren, Klaus-Robert M\\\"uller, Wojciech\n  Samek", "title": "Analyzing Neuroimaging Data Through Recurrent Deep Learning Models", "comments": "36 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning (DL) models to neuroimaging data poses\nseveral challenges, due to the high dimensionality, low sample size and complex\ntemporo-spatial dependency structure of these datasets. Even further, DL models\nact as as black-box models, impeding insight into the association of cognitive\nstate and brain activity. To approach these challenges, we introduce the\nDeepLight framework, which utilizes long short-term memory (LSTM) based DL\nmodels to analyze whole-brain functional Magnetic Resonance Imaging (fMRI)\ndata. To decode a cognitive state (e.g., seeing the image of a house),\nDeepLight separates the fMRI volume into a sequence of axial brain slices,\nwhich is then sequentially processed by an LSTM. To maintain interpretability,\nDeepLight adapts the layer-wise relevance propagation (LRP) technique. Thereby,\ndecomposing its decoding decision into the contributions of the single input\nvoxels to this decision. Importantly, the decomposition is performed on the\nlevel of single fMRI volumes, enabling DeepLight to study the associations\nbetween cognitive state and brain activity on several levels of data\ngranularity, from the level of the group down to the level of single time\npoints. To demonstrate the versatility of DeepLight, we apply it to a large\nfMRI dataset of the Human Connectome Project. We show that DeepLight\noutperforms conventional approaches of uni- and multivariate fMRI analysis in\ndecoding the cognitive states and in identifying the physiologically\nappropriate brain regions associated with these states. We further demonstrate\nDeepLight's ability to study the fine-grained temporo-spatial variability of\nbrain activity over sequences of single fMRI samples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:23:27 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 07:31:32 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Thomas", "Armin W.", ""], ["Heekeren", "Hauke R.", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1810.09957", "submitter": "Hanjoo Kim", "authors": "Hanjoo Kim, Minkyu Kim, Dongjoo Seo, Jinwoong Kim, Heungseok Park,\n  Soeun Park, Hyunwoo Jo, KyungHyun Kim, Youngil Yang, Youngkwan Kim, Nako\n  Sung, Jung-Woo Ha", "title": "NSML: Meet the MLaaS platform with a real-world case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The boom of deep learning induced many industries and academies to introduce\nmachine learning based approaches into their concern, competitively. However,\nexisting machine learning frameworks are limited to sufficiently fulfill the\ncollaboration and management for both data and models. We proposed NSML, a\nmachine learning as a service (MLaaS) platform, to meet these demands. NSML\nhelps machine learning work be easily launched on a NSML cluster and provides a\ncollaborative environment which can afford development at enterprise scale.\nFinally, NSML users can deploy their own commercial services with NSML cluster.\nIn addition, NSML furnishes convenient visualization tools which assist the\nusers in analyzing their work. To verify the usefulness and accessibility of\nNSML, we performed some experiments with common examples. Furthermore, we\nexamined the collaborative advantages of NSML through three competitions with\nreal-world use cases.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 04:30:44 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Kim", "Hanjoo", ""], ["Kim", "Minkyu", ""], ["Seo", "Dongjoo", ""], ["Kim", "Jinwoong", ""], ["Park", "Heungseok", ""], ["Park", "Soeun", ""], ["Jo", "Hyunwoo", ""], ["Kim", "KyungHyun", ""], ["Yang", "Youngil", ""], ["Kim", "Youngkwan", ""], ["Sung", "Nako", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "1810.09965", "submitter": "Avraam Tsantekidis", "authors": "Avraam Tsantekidis, Nikolaos Passalis, Anastasios Tefas, Juho\n  Kanniainen, Moncef Gabbouj, Alexandros Iosifidis", "title": "Using Deep Learning for price prediction by exploiting stationary limit\n  order book features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent surge in Deep Learning (DL) research of the past decade has\nsuccessfully provided solutions to many difficult problems. The field of\nquantitative analysis has been slowly adapting the new methods to its problems,\nbut due to problems such as the non-stationary nature of financial data,\nsignificant challenges must be overcome before DL is fully utilized. In this\nwork a new method to construct stationary features, that allows DL models to be\napplied effectively, is proposed. These features are thoroughly tested on the\ntask of predicting mid price movements of the Limit Order Book. Several DL\nmodels are evaluated, such as recurrent Long Short Term Memory (LSTM) networks\nand Convolutional Neural Networks (CNN). Finally a novel model that combines\nthe ability of CNNs to extract useful features and the ability of LSTMs' to\nanalyze time series, is proposed and evaluated. The combined model is able to\noutperform the individual LSTM and CNN models in the prediction horizons that\nare tested.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:53:03 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Tsantekidis", "Avraam", ""], ["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1810.09967", "submitter": "Brett Daley", "authors": "Brett Daley and Christopher Amato", "title": "Reconciling $\\lambda$-Returns with Experience Replay", "comments": "NeurIPS 2019 (Camera-Ready) Code available:\n  https://github.com/brett-daley/dqn-lambda", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep reinforcement learning methods have departed from the incremental\nlearning required for eligibility traces, rendering the implementation of the\n$\\lambda$-return difficult in this context. In particular, off-policy methods\nthat utilize experience replay remain problematic because their random sampling\nof minibatches is not conducive to the efficient calculation of\n$\\lambda$-returns. Yet replay-based methods are often the most sample\nefficient, and incorporating $\\lambda$-returns into them is a viable way to\nachieve new state-of-the-art performance. Towards this, we propose the first\nmethod to enable practical use of $\\lambda$-returns in arbitrary replay-based\nmethods without relying on other forms of decorrelation such as asynchronous\ngradient updates. By promoting short sequences of past transitions into a small\ncache within the replay memory, adjacent $\\lambda$-returns can be efficiently\nprecomputed by sharing Q-values. Computation is not wasted on experiences that\nare never sampled, and stored $\\lambda$-returns behave as stable\ntemporal-difference (TD) targets that replace the target network. Additionally,\nour method grants the unique ability to observe TD errors prior to sampling;\nfor the first time, transitions can be prioritized by their true significance\nrather than by a proxy to it. Furthermore, we propose the novel use of the TD\nerror to dynamically select $\\lambda$-values that facilitate faster learning.\nWe show that these innovations can enhance the performance of DQN when playing\nAtari 2600 games, even under partial observability. While our work specifically\nfocuses on $\\lambda$-returns, these ideas are applicable to any multi-step\nreturn estimator.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:55:28 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 02:38:07 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 19:05:20 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Daley", "Brett", ""], ["Amato", "Christopher", ""]]}, {"id": "1810.09977", "submitter": "Bleema Rosenfeld", "authors": "Bleema Rosenfeld, Osvaldo Simeone and Bipin Rajendran", "title": "Learning First-to-Spike Policies for Neuromorphic Control Using Policy\n  Gradients", "comments": "Submitted for conference publication", "journal-ref": null, "doi": "10.1109/SPAWC.2019.8815546", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) are currently being used as function\napproximators in many state-of-the-art Reinforcement Learning (RL) algorithms.\nSpiking Neural Networks (SNNs) have been shown to drastically reduce the energy\nconsumption of ANNs by encoding information in sparse temporal binary spike\nstreams, hence emulating the communication mechanism of biological neurons. Due\nto their low energy consumption, SNNs are considered to be important candidates\nas co-processors to be implemented in mobile devices. In this work, the use of\nSNNs as stochastic policies is explored under an energy-efficient\nfirst-to-spike action rule, whereby the action taken by the RL agent is\ndetermined by the occurrence of the first spike among the output neurons. A\npolicy gradient-based algorithm is derived considering a Generalized Linear\nModel (GLM) for spiking neurons. Experimental results demonstrate the\ncapability of online trained SNNs as stochastic policies to gracefully trade\nenergy consumption, as measured by the number of spikes, and control\nperformance. Significant gains are shown as compared to the standard approach\nof converting an offline trained ANN into an SNN.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 17:13:21 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 18:29:37 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 17:00:29 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Rosenfeld", "Bleema", ""], ["Simeone", "Osvaldo", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1810.10002", "submitter": "Kristen Masada", "authors": "Kristen Masada, Razvan Bunescu", "title": "Chord Recognition in Symbolic Music: A Segmental CRF Model,\n  Segment-Level Features, and Comparative Evaluations on Classical and Popular\n  Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new approach to harmonic analysis that is trained to segment\nmusic into a sequence of chord spans tagged with chord labels. Formulated as a\nsemi-Markov Conditional Random Field (semi-CRF), this joint segmentation and\nlabeling approach enables the use of a rich set of segment-level features, such\nas segment purity and chord coverage, that capture the extent to which the\nevents in an entire segment of music are compatible with a candidate chord\nlabel. The new chord recognition model is evaluated extensively on three\ncorpora of classical music and a newly created corpus of rock music.\nExperimental results show that the semi-CRF model performs substantially better\nthan previous approaches when trained on a sufficient number of labeled\nexamples and remains competitive when the amount of training data is limited.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 22:55:17 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:05:13 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Masada", "Kristen", ""], ["Bunescu", "Razvan", ""]]}, {"id": "1810.10004", "submitter": "Pavlos Fafalios", "authors": "Nilamadhaba Mohapatra, Vasileios Iosifidis, Asif Ekbal, Stefan Dietze,\n  Pavlos Fafalios", "title": "Time-Aware and Corpus-Specific Entity Relatedness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity relatedness has emerged as an important feature in a plethora of\napplications such as information retrieval, entity recommendation and entity\nlinking. Given an entity, for instance a person or an organization, entity\nrelatedness measures can be exploited for generating a list of highly-related\nentities. However, the relation of an entity to some other entity depends on\nseveral factors, with time and context being two of the most important ones\n(where, in our case, context is determined by a particular corpus). For\nexample, the entities related to the International Monetary Fund are different\nnow compared to some years ago, while these entities also may highly differ in\nthe context of a USA news portal compared to a Greek news portal. In this\npaper, we propose a simple but flexible model for entity relatedness which\nconsiders time and entity aware word embeddings by exploiting the underlying\ncorpus. The proposed model does not require external knowledge and is language\nindependent, which makes it widely useful in a variety of applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 11:17:45 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Mohapatra", "Nilamadhaba", ""], ["Iosifidis", "Vasileios", ""], ["Ekbal", "Asif", ""], ["Dietze", "Stefan", ""], ["Fafalios", "Pavlos", ""]]}, {"id": "1810.10031", "submitter": "Mohammad Hashemi", "authors": "Mohammad Hashemi, Greg Cusack, Eric Keller", "title": "Stochastic Substitute Training: A Gray-box Approach to Craft Adversarial\n  Examples Against Gradient Obfuscation Defenses", "comments": "Accepted by AISec '18: 11th ACM Workshop on Artificial Intelligence\n  and Security. Source code at https://github.com/S-Mohammad-Hashemi/SST", "journal-ref": null, "doi": "10.1145/3270101.3270111", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that adversaries can craft example inputs to neural\nnetworks which are similar to legitimate inputs but have been created to\npurposely cause the neural network to misclassify the input. These adversarial\nexamples are crafted, for example, by calculating gradients of a carefully\ndefined loss function with respect to the input. As a countermeasure, some\nresearchers have tried to design robust models by blocking or obfuscating\ngradients, even in white-box settings. Another line of research proposes\nintroducing a separate detector to attempt to detect adversarial examples. This\napproach also makes use of gradient obfuscation techniques, for example, to\nprevent the adversary from trying to fool the detector. In this paper, we\nintroduce stochastic substitute training, a gray-box approach that can craft\nadversarial examples for defenses which obfuscate gradients. For those defenses\nthat have tried to make models more robust, with our technique, an adversary\ncan craft adversarial examples with no knowledge of the defense. For defenses\nthat attempt to detect the adversarial examples, with our technique, an\nadversary only needs very limited information about the defense to craft\nadversarial examples. We demonstrate our technique by applying it against two\ndefenses which make models more robust and two defenses which detect\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 18:14:47 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Hashemi", "Mohammad", ""], ["Cusack", "Greg", ""], ["Keller", "Eric", ""]]}, {"id": "1810.10032", "submitter": "Jose Maria Almira", "authors": "J. M. Almira, P.E. Lopez-de-Teruel, D.J. Romero-Lopez, F. Voigtlaender", "title": "Negative results for approximation using single layer and multilayer\n  feedforward neural networks", "comments": "12 pages, submitted to a Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a negative result for the approximation of functions defined on\ncompact subsets of $\\mathbb{R}^d$ (where $d \\geq 2$) using feedforward neural\nnetworks with one hidden layer and arbitrary continuous activation function. In\na nutshell, this result claims the existence of target functions that are as\ndifficult to approximate using these neural networks as one may want. We also\ndemonstrate an analogous result (for general $d \\in \\mathbb{N}$) for neural\nnetworks with an \\emph{arbitrary} number of hidden layers, for activation\nfunctions that are either rational functions or continuous splines with\nfinitely many pieces.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 18:15:50 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 08:56:16 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 19:37:20 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 07:45:04 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Almira", "J. M.", ""], ["Lopez-de-Teruel", "P. E.", ""], ["Romero-Lopez", "D. J.", ""], ["Voigtlaender", "F.", ""]]}, {"id": "1810.10053", "submitter": "Hermina Petric Maretic", "authors": "Hermina Petric Maretic and Pascal Frossard", "title": "Graph Laplacian mixture model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph learning methods have recently been receiving increasing interest as\nmeans to infer structure in datasets. Most of the recent approaches focus on\ndifferent relationships between a graph and data sample distributions, mostly\nin settings where all available data relate to the same graph. This is,\nhowever, not always the case, as data is often available in mixed form,\nyielding the need for methods that are able to cope with mixture data and learn\nmultiple graphs. We propose a novel generative model that represents a\ncollection of distinct data which naturally live on different graphs. We assume\nthe mapping of data to graphs is not known and investigate the problem of\njointly clustering a set of data and learning a graph for each of the clusters.\nExperiments demonstrate promising performance in data clustering and multiple\ngraph inference, and show desirable properties in terms of interpretability and\ncoping with high dimensionality on weather and traffic data, as well as digit\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:03:06 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 17:36:19 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Maretic", "Hermina Petric", ""], ["Frossard", "Pascal", ""]]}, {"id": "1810.10065", "submitter": "Jonathan Kadmon", "authors": "Jonathan Kadmon and Surya Ganguli", "title": "Statistical mechanics of low-rank tensor decomposition", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": "10.1088/1742-5468/ab3216", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, large, high dimensional datasets collected across multiple modalities\ncan be organized as a higher order tensor. Low-rank tensor decomposition then\narises as a powerful and widely used tool to discover simple low dimensional\nstructures underlying such data. However, we currently lack a theoretical\nunderstanding of the algorithmic behavior of low-rank tensor decompositions. We\nderive Bayesian approximate message passing (AMP) algorithms for recovering\narbitrarily shaped low-rank tensors buried within noise, and we employ dynamic\nmean field theory to precisely characterize their performance. Our theory\nreveals the existence of phase transitions between easy, hard and impossible\ninference regimes, and displays an excellent match with simulations. Moreover,\nit reveals several qualitative surprises compared to the behavior of symmetric,\ncubic tensor decomposition. Finally, we compare our AMP algorithm to the most\ncommonly used algorithm, alternating least squares (ALS), and demonstrate that\nAMP significantly outperforms ALS in the presence of noise.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:36:28 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kadmon", "Jonathan", ""], ["Ganguli", "Surya", ""]]}, {"id": "1810.10076", "submitter": "Navoneel Chakrabarty", "authors": "Navoneel Chakrabarty and Sanket Biswas", "title": "A Statistical Approach to Adult Census Income Level Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The prominent inequality of wealth and income is a huge concern especially in\nthe United States. The likelihood of diminishing poverty is one valid reason to\nreduce the world's surging level of economic inequality. The principle of\nuniversal moral equality ensures sustainable development and improve the\neconomic stability of a nation. Governments in different countries have been\ntrying their best to address this problem and provide an optimal solution. This\nstudy aims to show the usage of machine learning and data mining techniques in\nproviding a solution to the income equality problem. The UCI Adult Dataset has\nbeen used for the purpose. Classification has been done to predict whether a\nperson's yearly income in US falls in the income category of either greater\nthan 50K Dollars or less equal to 50K Dollars category based on a certain set\nof attributes. The Gradient Boosting Classifier Model was deployed which\nclocked the highest accuracy of 88.16%, eventually breaking the benchmark\naccuracy of existing works.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 20:21:31 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Chakrabarty", "Navoneel", ""], ["Biswas", "Sanket", ""]]}, {"id": "1810.10078", "submitter": "Zhaoqiang Liu", "authors": "Zhaoqiang Liu", "title": "Model Selection for Nonnegative Matrix Factorization by Support Union\n  Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has been widely used in machine\nlearning and signal processing because of its non-subtractive, part-based\nproperty which enhances interpretability. It is often assumed that the latent\ndimensionality (or the number of components) is given. Despite the large amount\nof algorithms designed for NMF, there is little literature about automatic\nmodel selection for NMF with theoretical guarantees. In this paper, we propose\nan algorithm that first calculates an empirical second-order moment from the\nempirical fourth-order cumulant tensor, and then estimates the latent\ndimensionality by recovering the support union (the index set of non-zero rows)\nof a matrix related to the empirical second-order moment. By assuming a\ngenerative model of the data with additional mild conditions, our algorithm\nprovably detects the true latent dimensionality. We show on synthetic examples\nthat our proposed algorithm is able to find an approximately correct number of\ncomponents.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 20:31:14 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Liu", "Zhaoqiang", ""]]}, {"id": "1810.10082", "submitter": "Alnur Ali", "authors": "Alnur Ali, J. Zico Kolter, Ryan J. Tibshirani", "title": "A Continuous-Time View of Early Stopping for Least Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical properties of the iterates generated by gradient\ndescent, applied to the fundamental problem of least squares regression. We\ntake a continuous-time view, i.e., consider infinitesimal step sizes in\ngradient descent, in which case the iterates form a trajectory called gradient\nflow. Our primary focus is to compare the risk of gradient flow to that of\nridge regression. Under the calibration $t=1/\\lambda$---where $t$ is the time\nparameter in gradient flow, and $\\lambda$ the tuning parameter in ridge\nregression---we prove that the risk of gradient flow is no less than 1.69 times\nthat of ridge, along the entire path (for all $t \\geq 0$). This holds in finite\nsamples with very weak assumptions on the data model (in particular, with no\nassumptions on the features $X$). We prove that the same relative risk bound\nholds for prediction risk, in an average sense over the underlying signal\n$\\beta_0$. Finally, we examine limiting risk expressions (under standard\nMarchenko-Pastur asymptotics), and give supporting numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 20:44:16 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 20:32:30 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 15:44:57 GMT"}, {"version": "v4", "created": "Sat, 23 Feb 2019 20:08:39 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ali", "Alnur", ""], ["Kolter", "J. Zico", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "1810.10085", "submitter": "Ehsan Kazemi Dr", "authors": "Ehsan Kazemi, Liqiang Wang", "title": "A Proximal Zeroth-Order Algorithm for Nonconvex Nonsmooth Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on solving an important class of nonconvex\noptimization problems which includes many problems for example signal\nprocessing over a networked multi-agent system and distributed learning over\nnetworks. Motivated by many applications in which the local objective function\nis the sum of smooth but possibly nonconvex part, and non-smooth but convex\npart subject to a linear equality constraint, this paper proposes a proximal\nzeroth-order primal dual algorithm (PZO-PDA) that accounts for the information\nstructure of the problem. This algorithm only utilize the zeroth-order\ninformation (i.e., the functional values) of smooth functions, yet the\nflexibility is achieved for applications that only noisy information of the\nobjective function is accessible, where classical methods cannot be applied. We\nprove convergence and rate of convergence for PZO-PDA. Numerical experiments\nare provided to validate the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 18:28:51 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Wang", "Liqiang", ""]]}, {"id": "1810.10098", "submitter": "David Reiman", "authors": "David M. Reiman, Brett E. G\\\"ohre", "title": "Deblending galaxy superpositions with branched generative adversarial\n  networks", "comments": "14 pages, 6 figures, accepted for publication in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/stz575", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-future large galaxy surveys will encounter blended galaxy images at a\nfraction of up to 50% in the densest regions of the universe. Current\ndeblending techniques may segment the foreground galaxy while leaving missing\npixel intensities in the background galaxy flux. The problem is compounded by\nthe diffuse nature of galaxies in their outer regions, making segmentation\nsignificantly more difficult than in traditional object segmentation\napplications. We propose a novel branched generative adversarial network (GAN)\nto deblend overlapping galaxies, where the two branches produce images of the\ntwo deblended galaxies. We show that generative models are a powerful engine\nfor deblending given their innate ability to infill missing pixel values\noccluded by the superposition. We maintain high peak signal-to-noise ratio and\nstructural similarity scores with respect to ground truth images upon\ndeblending. Our model also predicts near-instantaneously, making it a natural\nchoice for the immense quantities of data soon to be created by large surveys\nsuch as LSST, Euclid and WFIRST.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 21:28:53 GMT"}, {"version": "v2", "created": "Sat, 29 Dec 2018 17:41:25 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 03:58:38 GMT"}, {"version": "v4", "created": "Fri, 8 Mar 2019 20:29:44 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Reiman", "David M.", ""], ["G\u00f6hre", "Brett E.", ""]]}, {"id": "1810.10107", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, James Zou", "title": "Autowarp: Learning a Warping Distance from Unlabeled Time Series Using\n  Sequence Autoencoders", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarities between unlabeled time series trajectories is an\nimportant problem in domains as diverse as medicine, astronomy, finance, and\ncomputer vision. It is often unclear what is the appropriate metric to use\nbecause of the complex nature of noise in the trajectories (e.g. different\nsampling rates or outliers). Domain experts typically hand-craft or manually\nselect a specific metric, such as dynamic time warping (DTW), to apply on their\ndata. In this paper, we propose Autowarp, an end-to-end algorithm that\noptimizes and learns a good metric given unlabeled trajectories. We define a\nflexible and differentiable family of warping metrics, which encompasses common\nmetrics such as DTW, Euclidean, and edit distance. Autowarp then leverages the\nrepresentation power of sequence autoencoders to optimize for a member of this\nwarping distance family. The output is a metric which is easy to interpret and\ncan be robustly learned from relatively few trajectories. In systematic\nexperiments across different domains, we show that Autowarp often outperforms\nhand-crafted trajectory similarity metrics.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:04:16 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1810.10118", "submitter": "Rajiv Khanna", "authors": "Rajiv Khanna, Been Kim, Joydeep Ghosh, Oluwasanmi Koyejo", "title": "Interpreting Black Box Predictions using Fisher Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in both machine learning and psychology suggests that salient\nexamples can help humans to interpret learning models. To this end, we take a\nnovel look at black box interpretation of test predictions in terms of training\nexamples. Our goal is to ask `which training examples are most responsible for\na given set of predictions'? To answer this question, we make use of Fisher\nkernels as the defining feature embedding of each data point, combined with\nSequential Bayesian Quadrature (SBQ) for efficient selection of examples. In\ncontrast to prior work, our method is able to seamlessly handle any sized\nsubset of test predictions in a principled way. We theoretically analyze our\napproach, providing novel convergence bounds for SBQ over discrete candidate\natoms. Our approach recovers the application of influence functions for\ninterpretability as a special case yielding novel insights from this\nconnection. We also present applications of the proposed approach to three use\ncases: cleaning training data, fixing mislabeled examples and data\nsummarization.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:41:41 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Khanna", "Rajiv", ""], ["Kim", "Been", ""], ["Ghosh", "Joydeep", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1810.10122", "submitter": "Hongteng Xu", "authors": "Hongteng Xu", "title": "PoPPy: A Point Process Toolbox Based on PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PoPPy is a Point Process toolbox based on PyTorch, which achieves flexible\ndesigning and efficient learning of point process models. It can be used for\ninterpretable sequential data modeling and analysis, e.g., Granger causality\nanalysis of multi-variate point processes, point process-based simulation and\nprediction of event sequences. In practice, the key points of point\nprocess-based sequential data modeling include: 1) How to design intensity\nfunctions to describe the mechanism behind observed data? 2) How to learn the\nproposed intensity functions from observed data? The goal of PoPPy is providing\na user-friendly solution to the key points above and achieving large-scale\npoint process-based sequential data analysis, simulation and prediction.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:04:13 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 05:41:20 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 16:54:25 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Xu", "Hongteng", ""]]}, {"id": "1810.10126", "submitter": "Yang Li", "authors": "Yang Li, Lukasz Kaiser, Samy Bengio, Si Si", "title": "Area Attention", "comments": "@InProceedings{pmlr-v97-li19e, title = {Area Attention}, author =\n  {Li, Yang and Kaiser, Lukasz and Bengio, Samy and Si, Si}, booktitle =\n  {Proceedings of the 36th International Conference on Machine Learning}, pages\n  = {3846--3855}, year = {2019}, volume = {97}, series = {Proceedings of\n  Machine Learning Research}, publisher = {PMLR} }", "journal-ref": "ICML 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing attention mechanisms are trained to attend to individual items in a\ncollection (the memory) with a predefined, fixed granularity, e.g., a word\ntoken or an image grid. We propose area attention: a way to attend to areas in\nthe memory, where each area contains a group of items that are structurally\nadjacent, e.g., spatially for a 2D memory such as images, or temporally for a\n1D memory such as natural language sentences. Importantly, the shape and the\nsize of an area are dynamically determined via learning, which enables a model\nto attend to information with varying granularity. Area attention can easily\nwork with existing model architectures such as multi-head attention for\nsimultaneously attending to multiple areas in the memory. We evaluate area\nattention on two tasks: neural machine translation (both character and\ntoken-level) and image captioning, and improve upon strong (state-of-the-art)\nbaselines in all the cases. These improvements are obtainable with a basic form\nof area attention that is parameter free.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:14:27 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:01:08 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 01:31:26 GMT"}, {"version": "v4", "created": "Tue, 5 Feb 2019 19:58:57 GMT"}, {"version": "v5", "created": "Thu, 23 May 2019 23:34:46 GMT"}, {"version": "v6", "created": "Wed, 5 Jun 2019 22:07:12 GMT"}, {"version": "v7", "created": "Thu, 7 May 2020 21:55:04 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Li", "Yang", ""], ["Kaiser", "Lukasz", ""], ["Bengio", "Samy", ""], ["Si", "Si", ""]]}, {"id": "1810.10132", "submitter": "Gautam Goel", "authors": "Gautam Goel, Adam Wierman", "title": "Smoothed Online Optimization for Regression and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Online Convex Optimization (OCO) in the setting where the costs\nare $m$-strongly convex and the online learner pays a switching cost for\nchanging decisions between rounds. We show that the recently proposed Online\nBalanced Descent (OBD) algorithm is constant competitive in this setting, with\ncompetitive ratio $3 + O(1/m)$, irrespective of the ambient dimension.\nAdditionally, we show that when the sequence of cost functions is\n$\\epsilon$-smooth, OBD has near-optimal dynamic regret and maintains strong\nper-round accuracy. We demonstrate the generality of our approach by showing\nthat the OBD framework can be used to construct competitive algorithms for a\nvariety of online problems across learning and control, including online\nvariants of ridge regression, logistic regression, maximum likelihood\nestimation, and LQR control.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:57:40 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 05:30:46 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Goel", "Gautam", ""], ["Wierman", "Adam", ""]]}, {"id": "1810.10147", "submitter": "Hao Zhu", "authors": "Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu,\n  Maosong Sun", "title": "FewRel: A Large-Scale Supervised Few-Shot Relation Classification\n  Dataset with State-of-the-Art Evaluation", "comments": "EMNLP 2018. The first four authors contribute equally. The order is\n  determined by dice rolling. Visit our website http://zhuhao.me/fewrel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a Few-Shot Relation Classification Dataset (FewRel), consisting of\n70, 000 sentences on 100 relations derived from Wikipedia and annotated by\ncrowdworkers. The relation of each sentence is first recognized by distant\nsupervision methods, and then filtered by crowdworkers. We adapt the most\nrecent state-of-the-art few-shot learning methods for relation classification\nand conduct a thorough evaluation of these methods. Empirical results show that\neven the most competitive few-shot learning models struggle on this task,\nespecially as compared with humans. We also show that a range of different\nreasoning skills are needed to solve our task. These results indicate that\nfew-shot relation classification remains an open problem and still requires\nfurther research. Our detailed analysis points multiple directions for future\nresearch. All details and resources about the dataset and baselines are\nreleased on http://zhuhao.me/fewrel.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 01:18:08 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 21:41:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Han", "Xu", ""], ["Zhu", "Hao", ""], ["Yu", "Pengfei", ""], ["Wang", "Ziyun", ""], ["Yao", "Yuan", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1810.10158", "submitter": "Haihao Lu", "authors": "Haihao Lu and Rahul Mazumder", "title": "Randomized Gradient Boosting Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Boosting Machine (GBM) introduced by Friedman is a powerful\nsupervised learning algorithm that is very widely used in practice---it\nroutinely features as a leading algorithm in machine learning competitions such\nas Kaggle and the KDDCup. In spite of the usefulness of GBM in practice, our\ncurrent theoretical understanding of this method is rather limited. In this\nwork, we propose Randomized Gradient Boosting Machine (RGBM) which leads to\nsubstantial computational gains compared to GBM, by using a randomization\nscheme to reduce search in the space of weak-learners. We derive novel\ncomputational guarantees for RGBM. We also provide a principled guideline\ntowards better step-size selection in RGBM that does not require a line search.\nOur proposed framework is inspired by a special variant of coordinate descent\nthat combines the benefits of randomized coordinate descent and greedy\ncoordinate descent; and may be of independent interest as an optimization\nalgorithm. As a special case, our results for RGBM lead to superior\ncomputational guarantees for GBM. Our computational guarantees depend upon a\ncurious geometric quantity that we call Minimal Cosine Angle, which relates to\nthe density of weak-learners in the prediction space. On a series of numerical\nexperiments on real datasets, we demonstrate the effectiveness of RGBM over GBM\nin terms of obtaining a model with good training and/or testing data fidelity\nwith a fraction of the computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 02:50:45 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 18:12:47 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 02:09:40 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 01:00:08 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Lu", "Haihao", ""], ["Mazumder", "Rahul", ""]]}, {"id": "1810.10172", "submitter": "Qiang Sun", "authors": "Xiucai Ding and Qiang Sun", "title": "Modified Multidimensional Scaling and High Dimensional Clustering", "comments": "There are critical errors in the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional scaling is an important dimension reduction tool in\nstatistics and machine learning. Yet few theoretical results characterizing its\nstatistical performance exist, not to mention any in high dimensions. By\nconsidering a unified framework that includes low, moderate and high\ndimensions, we study multidimensional scaling in the setting of clustering\nnoisy data. Our results suggest that, the classical multidimensional scaling\ncan be modified to further improve the quality of embedded samples, especially\nwhen the noise level increases. To this end, we propose {\\it modified\nmultidimensional scaling} which applies a nonlinear transformation to the\nsample eigenvalues. The nonlinear transformation depends on the dimensionality,\nsample size and moment of noise. We show that modified multidimensional scaling\nfollowed by various clustering algorithms can achieve exact recovery, i.e., all\nthe cluster labels can be recovered correctly with probability tending to one.\nNumerical simulations and two real data applications lend strong support to our\nproposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 03:51:26 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 23:53:54 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 03:20:14 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 01:03:53 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ding", "Xiucai", ""], ["Sun", "Qiang", ""]]}, {"id": "1810.10176", "submitter": "Tolgahan Cakaloglu Ph.D.c", "authors": "Tolgahan Cakaloglu, Christian Szegedy, Xiaowei Xu", "title": "Text Embeddings for Retrieval From a Large Knowledge Base", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text embedding representing natural language documents in a semantic vector\nspace can be used for document retrieval using nearest neighbor lookup. In\norder to study the feasibility of neural models specialized for retrieval in a\nsemantically meaningful way, we suggest the use of the Stanford Question\nAnswering Dataset (SQuAD) in an open-domain question answering context, where\nthe first task is to find paragraphs useful for answering a given question.\nFirst, we compare the quality of various text-embedding methods on the\nperformance of retrieval and give an extensive empirical comparison on the\nperformance of various non-augmented base embedding with, and without IDF\nweighting. Our main results are that by training deep residual neural models,\nspecifically for retrieval purposes, can yield significant gains when it is\nused to augment existing embeddings. We also establish that deeper models are\nsuperior to this task. The best base baseline embeddings augmented by our\nlearned neural approach improves the top-1 paragraph recall of the system by\n14%.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 03:57:11 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 17:19:08 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Cakaloglu", "Tolgahan", ""], ["Szegedy", "Christian", ""], ["Xu", "Xiaowei", ""]]}, {"id": "1810.10180", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, Jeremy Nixon, C. Daniel Freeman,\n  Jascha Sohl-Dickstein", "title": "Understanding and correcting pathologies in the training of learned\n  optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown that learned functions can dramatically outperform\nhand-designed functions on perceptual tasks. Analogously, this suggests that\nlearned optimizers may similarly outperform current hand-designed optimizers,\nespecially for specific problems. However, learned optimizers are notoriously\ndifficult to train and have yet to demonstrate wall-clock speedups over\nhand-designed optimizers, and thus are rarely used in practice. Typically,\nlearned optimizers are trained by truncated backpropagation through an unrolled\noptimization process resulting in gradients that are either strongly biased\n(for short truncations) or have exploding norm (for long truncations). In this\nwork we propose a training scheme which overcomes both of these difficulties,\nby dynamically weighting two unbiased gradient estimators for a variational\nloss on optimizer performance, allowing us to train neural networks to perform\noptimization of a specific task faster than tuned first-order methods. We\ndemonstrate these results on problems where our learned optimizer trains\nconvolutional networks faster in wall-clock time compared to tuned first-order\nmethods and with an improvement in test loss.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 04:04:25 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 17:41:54 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 00:12:30 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 23:14:02 GMT"}, {"version": "v5", "created": "Sat, 8 Jun 2019 00:33:09 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Nixon", "Jeremy", ""], ["Freeman", "C. Daniel", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1810.10207", "submitter": "Tianbao Yang", "authors": "Mingrui Liu, Hassan Rafique, Qihang Lin, Tianbao Yang", "title": "First-order Convergence Theory for Weakly-Convex-Weakly-Concave Min-max\n  Problems", "comments": "Accepted by Journal of Machine Learning Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider first-order convergence theory and algorithms for\nsolving a class of non-convex non-concave min-max saddle-point problems, whose\nobjective function is weakly convex in the variables of minimization and weakly\nconcave in the variables of maximization. It has many important applications in\nmachine learning including training Generative Adversarial Nets (GANs). We\npropose an algorithmic framework motivated by the inexact proximal point\nmethod, where the weakly monotone variational inequality (VI) corresponding to\nthe original min-max problem is solved through approximately solving a sequence\nof strongly monotone VIs constructed by adding a strongly monotone mapping to\nthe original gradient mapping. We prove first-order convergence to a nearly\nstationary solution of the original min-max problem of the generic algorithmic\nframework and establish different rates by employing different algorithms for\nsolving each strongly monotone VI. Experiments verify the convergence theory\nand also demonstrate the effectiveness of the proposed methods on training\nGANs.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 06:25:01 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 03:29:01 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 03:51:29 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 05:42:21 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Liu", "Mingrui", ""], ["Rafique", "Hassan", ""], ["Lin", "Qihang", ""], ["Yang", "Tianbao", ""]]}, {"id": "1810.10222", "submitter": "Marcin Kardas", "authors": "Piotr Czapla, Jeremy Howard, Marcin Kardas", "title": "Universal Language Model Fine-Tuning with Subword Tokenization for\n  Polish", "comments": "PolEval 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal Language Model for Fine-tuning [arXiv:1801.06146] (ULMFiT) is one\nof the first NLP methods for efficient inductive transfer learning.\nUnsupervised pretraining results in improvements on many NLP tasks for English.\nIn this paper, we describe a new method that uses subword tokenization to adapt\nULMFiT to languages with high inflection. Our approach results in a new\nstate-of-the-art for the Polish language, taking first place in Task 3 of\nPolEval'18. After further training, our final model outperformed the second\nbest model by 35%. We have open-sourced our pretrained models and code.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 07:34:45 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Czapla", "Piotr", ""], ["Howard", "Jeremy", ""], ["Kardas", "Marcin", ""]]}, {"id": "1810.10237", "submitter": "Zhengchao Zhang", "authors": "Zhengchao Zhang, Meng Li, Xi Lin, Yinhai Wang, Fang He", "title": "Multistep Speed Prediction on Traffic Networks: A Graph Convolutional\n  Sequence-to-Sequence Learning Approach with Attention Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multistep traffic forecasting on road networks is a crucial task in\nsuccessful intelligent transportation system applications. To capture the\ncomplex non-stationary temporal dynamics and spatial dependency in multistep\ntraffic-condition prediction, we propose a novel deep learning framework named\nattention graph convolutional sequence-to-sequence model (AGC-Seq2Seq). In the\nproposed deep learning framework, spatial and temporal dependencies are modeled\nthrough the Seq2Seq model and graph convolution network separately, and the\nattention mechanism along with a newly designed training method based on the\nSeq2Seq architecture is proposed to overcome the difficulty in multistep\nprediction and further capture the temporal heterogeneity of traffic pattern.\nWe conduct numerical tests to compare AGC-Seq2Seq with other benchmark models\nusing a real-world dataset. The results indicate that our model yields the best\nprediction performance in terms of various prediction error measures.\nFurthermore, the variation of spatiotemporal correlation of traffic conditions\nunder different perdition steps and road segments is revealed through\nsensitivity analyses.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 08:22:01 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhang", "Zhengchao", ""], ["Li", "Meng", ""], ["Lin", "Xi", ""], ["Wang", "Yinhai", ""], ["He", "Fang", ""]]}, {"id": "1810.10307", "submitter": "Jinjin Chi", "authors": "Jinjin Chi, Jihong Ouyang, Changchun Li, Xueyang Dong, Ximing Li,\n  Xinhua Wang", "title": "Topic representation: finding more representative words in topic models", "comments": "The paper has been submitted to Pattern Recognition Letters and is\n  being reviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The top word list, i.e., the top-M words with highest marginal probability in\na given topic, is the standard topic representation in topic models. Most of\nrecent automatical topic labeling algorithms and popular topic quality metrics\nare based on it. However, we find, empirically, words in this type of top word\nlist are not always representative. The objective of this paper is to find more\nrepresentative top word lists for topics. To achieve this, we rerank the words\nin a given topic by further considering marginal probability on words over\nevery other topic. The reranking list of top-M words is used to be a novel\ntopic representation for topic models. We investigate three reranking\nmethodologies, using (1) standard deviation weight, (2) standard deviation\nweight with topic size and (3) Chi Square \\c{hi}2statistic selection.\nExperimental results on real world collections indicate that our\nrepresentations can extract more representative words for topics, agreeing with\nhuman judgements.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:33:49 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Chi", "Jinjin", ""], ["Ouyang", "Jihong", ""], ["Li", "Changchun", ""], ["Dong", "Xueyang", ""], ["Li", "Ximing", ""], ["Wang", "Xinhua", ""]]}, {"id": "1810.10321", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Active Ranking with Subset-wise Preferences", "comments": "In 22nd International Conference on Artificial Intelligence and\n  Statistics (AISTATS), 2019. (44 pages, 8 figures). arXiv admin note: text\n  overlap with arXiv:1808.04008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of probably approximately correct (PAC) ranking $n$\nitems by adaptively eliciting subset-wise preference feedback. At each round,\nthe learner chooses a subset of $k$ items and observes stochastic feedback\nindicating preference information of the winner (most preferred) item of the\nchosen subset drawn according to a Plackett-Luce (PL) subset choice model\nunknown a priori. The objective is to identify an $\\epsilon$-optimal ranking of\nthe $n$ items with probability at least $1 - \\delta$. When the feedback in each\nsubset round is a single Plackett-Luce-sampled item, we show $(\\epsilon,\n\\delta)$-PAC algorithms with a sample complexity of\n$O\\left(\\frac{n}{\\epsilon^2} \\ln \\frac{n}{\\delta} \\right)$ rounds, which we\nestablish as being order-optimal by exhibiting a matching sample complexity\nlower bound of $\\Omega\\left(\\frac{n}{\\epsilon^2} \\ln \\frac{n}{\\delta}\n\\right)$---this shows that there is essentially no improvement possible from\nthe pairwise comparisons setting ($k = 2$). When, however, it is possible to\nelicit top-$m$ ($\\leq k$) ranking feedback according to the PL model from each\nadaptively chosen subset of size $k$, we show that an $(\\epsilon, \\delta)$-PAC\nranking sample complexity of $O\\left(\\frac{n}{m \\epsilon^2} \\ln\n\\frac{n}{\\delta} \\right)$ is achievable with explicit algorithms, which\nrepresents an $m$-wise reduction in sample complexity compared to the pairwise\ncase. This again turns out to be order-wise unimprovable across the class of\nsymmetric ranking algorithms. Our algorithms rely on a novel {pivot trick} to\nmaintain only $n$ itemwise score estimates, unlike $O(n^2)$ pairwise score\nestimates that has been used in prior work. We report results of numerical\nexperiments that corroborate our findings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 17:31:52 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 21:45:38 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1810.10323", "submitter": "Dong Kyun Shin", "authors": "Dong Kyun Shin, Minhaz Uddin Ahmed and Phill Kyu Rhee", "title": "Incremental Deep Learning for Robust Object Detection in Unknown\n  Cluttered Environments", "comments": "14 pages, 17 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2875720", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection in streaming images is a major step in different\ndetection-based applications, such as object tracking, action recognition,\nrobot navigation, and visual surveillance applications. In mostcases, image\nquality is noisy and biased, and as a result, the data distributions are\ndisturbed and imbalanced. Most object detection approaches, such as the faster\nregion-based convolutional neural network (Faster RCNN), Single Shot Multibox\nDetector with 300x300 inputs (SSD300), and You Only Look Once version 2\n(YOLOv2), rely on simple sampling without considering distortions and noise\nunder real-world changing environments, despite poor object labeling. In this\npaper, we propose an Incremental active semi-supervised learning (IASSL)\ntechnology for unseen object detection. It combines batch-based active learning\n(AL) and bin-based semi-supervised learning (SSL) to leverage the strong points\nof AL's exploration and SSL's exploitation capabilities. A collaborative\nsampling method is also adopted to measure the uncertainty and diversity of AL\nand the confidence in SSL. Batch-based AL allows us to select more informative,\nconfident, and representative samples with low cost. Bin-based SSL divides\nstreaming image samples into several bins, and each bin repeatedly transfers\nthe discriminative knowledge of convolutional neural network (CNN) deep\nlearning to the next bin until the performance criterion is reached. IASSL can\novercome noisy and biased labels in unknown, cluttered data distributions. We\nobtain superior performance, compared to state-of-the-art technologies such as\nFaster RCNN, SSD300, and YOLOv2.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 17:10:41 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Shin", "Dong Kyun", ""], ["Ahmed", "Minhaz Uddin", ""], ["Rhee", "Phill Kyu", ""]]}, {"id": "1810.10325", "submitter": "Sebastian Niehaus", "authors": "Jonas Koenig, Simon Malberg, Martin Martens, Sebastian Niehaus, Artus\n  Krohn-Grimberghe, Arunselvan Ramaswamy", "title": "Multi-Stage Reinforcement Learning For Object Detection", "comments": "Accepted for the Computer Vision Conference (CVC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning approach for detecting objects within an\nimage. Our approach performs a step-wise deformation of a bounding box with the\ngoal of tightly framing the object. It uses a hierarchical tree-like\nrepresentation of predefined region candidates, which the agent can zoom in on.\nThis reduces the number of region candidates that must be evaluated so that the\nagent can afford to compute new feature maps before each step to enhance\ndetection quality. We compare an approach that is based purely on zoom actions\nwith one that is extended by a second refinement stage to fine-tune the\nbounding box after each zoom step. We also improve the fitting ability by\nallowing for different aspect ratios of the bounding box. Finally, we propose\ndifferent reward functions to lead to a better guidance of the agent while\nfollowing its search trajectories. Experiments indicate that each of these\nextensions leads to more correct detections. The best performing approach\ncomprises a zoom stage and a refinement stage, uses aspect-ratio modifying\nactions and is trained using a combination of three different reward metrics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 21:41:57 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 11:11:02 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Koenig", "Jonas", ""], ["Malberg", "Simon", ""], ["Martens", "Martin", ""], ["Niehaus", "Sebastian", ""], ["Krohn-Grimberghe", "Artus", ""], ["Ramaswamy", "Arunselvan", ""]]}, {"id": "1810.10326", "submitter": "Lisa Graziani", "authors": "Lisa Graziani, Stefano Melacci, Marco Gori", "title": "Coherence Constraints in Facial Expression Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing facial expressions from static images or video sequences is a\nwidely studied but still challenging problem. The recent progresses obtained by\ndeep neural architectures, or by ensembles of heterogeneous models, have shown\nthat integrating multiple input representations leads to state-of-the-art\nresults. In particular, the appearance and the shape of the input face, or the\nrepresentations of some face parts, are commonly used to boost the quality of\nthe recognizer. This paper investigates the application of Convolutional Neural\nNetworks (CNNs) with the aim of building a versatile recognizer of expressions\nin static images that can be further applied to video sequences. We first study\nthe importance of different face parts in the recognition task, focussing on\nappearance and shape-related features. Then we cast the learning problem in the\nSemi-Supervised setting, exploiting video data, where only a few frames are\nsupervised. The unsupervised portion of the training data is used to enforce\nthree types of coherence, namely temporal coherence, coherence among the\npredictions on the face parts and coherence between appearance and shape-based\nrepresentation. Our experimental analysis shows that coherence constraints can\nimprove the quality of the expression recognizer, thus offering a suitable\nbasis to profitably exploit unsupervised video sequences. Finally we present\nsome examples with occlusions where the shape-based predictor performs better\nthan the appearance one.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 07:51:46 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Graziani", "Lisa", ""], ["Melacci", "Stefano", ""], ["Gori", "Marco", ""]]}, {"id": "1810.10327", "submitter": "Ha Young Kim", "authors": "Ba Rom Kang and Ha Young Kim", "title": "BshapeNet: Object Detection and Instance Segmentation with Bounding\n  Shape Masks", "comments": "10 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent object detectors use four-coordinate bounding box (bbox) regression to\npredict object locations. Providing additional information indicating the\nobject positions and coordinates will improve detection performance. Thus, we\npropose two types of masks: a bbox mask and a bounding shape (bshape) mask, to\nrepresent the object's bbox and boundary shape, respectively. For each of these\ntypes, we consider two variants: the Thick model and the Scored model, both of\nwhich have the same morphology but differ in ways to make their boundaries\nthicker. To evaluate the proposed masks, we design extended frameworks by\nadding a bshape mask (or a bbox mask) branch to a Faster R-CNN framework, and\ncall this BshapeNet (or BboxNet). Further, we propose BshapeNet+, a network\nthat combines a bshape mask branch with a Mask R-CNN to improve instance\nsegmentation as well as detection. Among our proposed models, BshapeNet+\ndemonstrates the best performance in both tasks and achieves highly competitive\nresults with state of the art (SOTA) models. Particularly, it improves the\ndetection results over Faster R-CNN+RoIAlign (37.3% and 28.9%) with a detection\nAP of 42.4% and 32.3% on MS COCO test-dev and Cityscapes val, respectively.\nFurthermore, for small objects, it achieves 24.9% AP on COCO test-dev, a\nsignificant improvement over previous SOTA models. For instance segmentation,\nit is substantially superior to Mask R-CNN on both test datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 10:12:45 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 19:04:05 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 11:19:23 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kang", "Ba Rom", ""], ["Kim", "Ha Young", ""]]}, {"id": "1810.10328", "submitter": "Niall Twomey", "authors": "Rafael Poyiadzi and Raul Santos-Rodriguez and Niall Twomey", "title": "Label Propagation for Learning with Label Proportions", "comments": "Accepted to MLSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning with Label Proportions (LLP) is the problem of recovering the\nunderlying true labels given a dataset when the data is presented in the form\nof bags. This paradigm is particularly suitable in contexts where providing\nindividual labels is expensive and label aggregates are more easily obtained.\nIn the healthcare domain, it is a burden for a patient to keep a detailed diary\nof their daily routines, but often they will be amenable to provide higher\nlevel summaries of daily behavior. We present a novel and efficient graph-based\nalgorithm that encourages local smoothness and exploits the global structure of\nthe data, while preserving the `mass' of each bag.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:24:59 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Santos-Rodriguez", "Raul", ""], ["Twomey", "Niall", ""]]}, {"id": "1810.10329", "submitter": "Nick Pears", "authors": "Rohan Watkins, Nick Pears and Suresh Manandhar", "title": "Vehicle classification using ResNets, localisation and\n  spatially-weighted pooling", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether ResNet architectures can outperform more traditional\nConvolutional Neural Networks on the task of fine-grained vehicle\nclassification. We train and test ResNet-18, ResNet-34 and ResNet-50 on the\nComprehensive Cars dataset without pre-training on other datasets. We then\nmodify the networks to use Spatially Weighted Pooling. Finally, we add a\nlocalisation step before the classification process, using a network based on\nResNet-50. We find that using Spatially Weighted Pooling and localisation both\nimprove classification accuracy of ResNet50. Spatially Weighted Pooling\nincreases accuracy by 1.5 percent points and localisation increases accuracy by\n3.4 percent points. Using both increases accuracy by 3.7 percent points giving\na top-1 accuracy of 96.351\\% on the Comprehensive Cars dataset. Our method\nachieves higher accuracy than a range of methods including those that use\ntraditional CNNs. However, our method does not perform quite as well as\npre-trained networks that use Spatially Weighted Pooling.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 13:28:19 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Watkins", "Rohan", ""], ["Pears", "Nick", ""], ["Manandhar", "Suresh", ""]]}, {"id": "1810.10330", "submitter": "Joao Reis", "authors": "Joao Reis and Gil Gon\\c{c}alves", "title": "Hyper-Process Model: A Zero-Shot Learning algorithm for Regression\n  Problems based on Shape Analysis", "comments": "36 pages, 4 figures, 2 tables, submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) can be defined by correctly solving a task where no\ntraining data is available, based on previous acquired knowledge from\ndifferent, but related tasks. So far, this area has mostly drawn the attention\nfrom computer vision community where a new unseen image needs to be correctly\nclassified, assuming the target class was not used in the training procedure.\nApart from image classification, only a couple of generic methods were proposed\nthat are applicable to both classification and regression. These learn the\nrelation among model coefficients so new ones can be predicted according to\nprovided conditions. So far, up to our knowledge, no methods exist that are\napplicable only to regression, and take advantage from such setting. Therefore,\nthe present work proposes a novel algorithm for regression problems that uses\ndata drawn from trained models, instead of model coefficients. In this case, a\nshape analyses on the data is performed to create a statistical shape model and\ngenerate new shapes to train new models. The proposed algorithm is tested in a\ntheoretical setting using the beta distribution where main problem to solve is\nto estimate a function that predicts curves, based on already learned\ndifferent, but related ones.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 11:35:16 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Reis", "Joao", ""], ["Gon\u00e7alves", "Gil", ""]]}, {"id": "1810.10333", "submitter": "Adityanarayanan Radhakrishnan", "authors": "Adityanarayanan Radhakrishnan, Karren Yang, Mikhail Belkin, Caroline\n  Uhler", "title": "Memorization in Overparameterized Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of deep neural networks to generalize well in the\noverparameterized regime has become a subject of significant research interest.\nWe show that overparameterized autoencoders exhibit memorization, a form of\ninductive bias that constrains the functions learned through the optimization\nprocess to concentrate around the training examples, although the network could\nin principle represent a much larger function class. In particular, we prove\nthat single-layer fully-connected autoencoders project data onto the\n(nonlinear) span of the training examples. In addition, we show that deep\nfully-connected autoencoders learn a map that is locally contractive at the\ntraining examples, and hence iterating the autoencoder results in convergence\nto the training examples. Finally, we prove that depth is necessary and provide\nempirical evidence that it is also sufficient for memorization in convolutional\nautoencoders. Understanding this inductive bias may shed light on the\ngeneralization properties of overparametrized deep neural networks that are\ncurrently unexplained by classical statistical theory.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:02:54 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 17:56:43 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 22:37:13 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Radhakrishnan", "Adityanarayanan", ""], ["Yang", "Karren", ""], ["Belkin", "Mikhail", ""], ["Uhler", "Caroline", ""]]}, {"id": "1810.10337", "submitter": "Robert Jasper", "authors": "Nicole Nichols and Robert Jasper", "title": "Projecting Trouble: Light Based Adversarial Attacks on Deep Learning\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work demonstrates a physical attack on a deep learning image\nclassification system using projected light onto a physical scene. Prior work\nis dominated by techniques for creating adversarial examples which directly\nmanipulate the digital input of the classifier. Such an attack is limited to\nscenarios where the adversary can directly update the inputs to the classifier.\nThis could happen by intercepting and modifying the inputs to an online API\nsuch as Clarifai or Cloud Vision. Such limitations have led to a vein of\nresearch around physical attacks where objects are constructed to be inherently\nadversarial or adversarial modifications are added to cause misclassification.\nOur work differs from other physical attacks in that we can cause\nmisclassification dynamically without altering physical objects in a permanent\nway.\n  We construct an experimental setup which includes a light projection source,\nan object for classification, and a camera to capture the scene. Experiments\nare conducted against 2D and 3D objects from CIFAR-10. Initial tests show\nprojected light patterns selected via differential evolution could degrade\nclassification from 98% to 22% and 89% to 43% probability for 2D and 3D targets\nrespectively. Subsequent experiments explore sensitivity to physical setup and\ncompare two additional baseline conditions for all 10 CIFAR classes. Some\nphysical targets are more susceptible to perturbation. Simple attacks show near\nequivalent success, and 6 of the 10 classes were disrupted by light.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:47:07 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Nichols", "Nicole", ""], ["Jasper", "Robert", ""]]}, {"id": "1810.10338", "submitter": "Thomas Lampert", "authors": "Thomas Lampert, Odyss\\'ee Merveille, Jessica Schmitz, Germain\n  Forestier, Friedrich Feuerhake, C\\'edric Wemmert", "title": "Strategies for Training Stain Invariant CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important part of Digital Pathology is the analysis of multiple digitised\nwhole slide images from differently stained tissue sections. It is common\npractice to mount consecutive sections containing corresponding microscopic\nstructures on glass slides, and to stain them differently to highlight specific\ntissue components. These multiple staining modalities result in very different\nimages but include a significant amount of consistent image information. Deep\nlearning approaches have recently been proposed to analyse these images in\norder to automatically identify objects of interest for pathologists. These\nsupervised approaches require a vast amount of annotations, which are difficult\nand expensive to acquire---a problem that is multiplied with multiple\nstainings. This article presents several training strategies that make progress\ntowards stain invariant networks. By training the network on one commonly used\nstaining modality and applying it to images that include corresponding but\ndifferently stained tissue structures, the presented unsupervised strategies\ndemonstrate significant improvements over standard training strategies.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 09:41:23 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 23:13:02 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Lampert", "Thomas", ""], ["Merveille", "Odyss\u00e9e", ""], ["Schmitz", "Jessica", ""], ["Forestier", "Germain", ""], ["Feuerhake", "Friedrich", ""], ["Wemmert", "C\u00e9dric", ""]]}, {"id": "1810.10342", "submitter": "Lily Peng", "authors": "Avinash Varadarajan, Pinal Bavishi, Paisan Raumviboonsuk, Peranut\n  Chotcomwongse, Subhashini Venugopalan, Arunachalam Narayanaswamy, Jorge\n  Cuadros, Kuniyoshi Kanai, George Bresnick, Mongkol Tadarati, Sukhum\n  Silpa-archa, Jirawut Limwattanayingyong, Variya Nganthavee, Joe Ledsam,\n  Pearse A Keane, Greg S Corrado, Lily Peng, Dale R Webster", "title": "Predicting optical coherence tomography-derived diabetic macular edema\n  grades from fundus photographs using deep learning", "comments": null, "journal-ref": "Nature Communications (2020)", "doi": "10.1038/s41467-019-13922-8", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic eye disease is one of the fastest growing causes of preventable\nblindness. With the advent of anti-VEGF (vascular endothelial growth factor)\ntherapies, it has become increasingly important to detect center-involved\ndiabetic macular edema (ci-DME). However, center-involved diabetic macular\nedema is diagnosed using optical coherence tomography (OCT), which is not\ngenerally available at screening sites because of cost and workflow\nconstraints. Instead, screening programs rely on the detection of hard exudates\nin color fundus photographs as a proxy for DME, often resulting in high false\npositive or false negative calls. To improve the accuracy of DME screening, we\ntrained a deep learning model to use color fundus photographs to predict\nci-DME. Our model had an ROC-AUC of 0.89 (95% CI: 0.87-0.91), which corresponds\nto a sensitivity of 85% at a specificity of 80%. In comparison, three retinal\nspecialists had similar sensitivities (82-85%), but only half the specificity\n(45-50%, p<0.001 for each comparison with model). The positive predictive value\n(PPV) of the model was 61% (95% CI: 56-66%), approximately double the 36-38% by\nthe retinal specialists. In addition to predicting ci-DME, our model was able\nto detect the presence of intraretinal fluid with an AUC of 0.81 (95% CI:\n0.81-0.86) and subretinal fluid with an AUC of 0.88 (95% CI: 0.85-0.91). The\nability of deep learning algorithms to make clinically relevant predictions\nthat generally require sophisticated 3D-imaging equipment from simple 2D images\nhas broad relevance to many other applications in medical imaging.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:22:33 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 01:46:59 GMT"}, {"version": "v3", "created": "Sat, 9 Feb 2019 17:50:50 GMT"}, {"version": "v4", "created": "Wed, 31 Jul 2019 23:39:59 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Varadarajan", "Avinash", ""], ["Bavishi", "Pinal", ""], ["Raumviboonsuk", "Paisan", ""], ["Chotcomwongse", "Peranut", ""], ["Venugopalan", "Subhashini", ""], ["Narayanaswamy", "Arunachalam", ""], ["Cuadros", "Jorge", ""], ["Kanai", "Kuniyoshi", ""], ["Bresnick", "George", ""], ["Tadarati", "Mongkol", ""], ["Silpa-archa", "Sukhum", ""], ["Limwattanayingyong", "Jirawut", ""], ["Nganthavee", "Variya", ""], ["Ledsam", "Joe", ""], ["Keane", "Pearse A", ""], ["Corrado", "Greg S", ""], ["Peng", "Lily", ""], ["Webster", "Dale R", ""]]}, {"id": "1810.10348", "submitter": "Amirreza Rezvantalab", "authors": "Amirreza Rezvantalab, Habib Safigholi, Somayeh Karimijeshni", "title": "Dermatologist Level Dermoscopy Skin Cancer Classification Using\n  Different Deep Learning Convolutional Neural Networks Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the effectiveness and capability of convolutional neural\nnetworks have been studied in the classification of 8 skin diseases. Different\npre-trained state-of-the-art architectures (DenseNet 201, ResNet 152, Inception\nv3, InceptionResNet v2) were used and applied on 10135 dermoscopy skin images\nin total (HAM10000: 10015, PH2: 120). The utilized dataset includes 8\ndiagnostic categories - melanoma, melanocytic nevi, basal cell carcinoma,\nbenign keratosis, actinic keratosis and intraepithelial carcinoma,\ndermatofibroma, vascular lesions, and atypical nevi. The aim is to compare the\nability of deep learning with the performance of highly trained dermatologists.\nOverall, the mean results show that all deep learning models outperformed\ndermatologists (at least 11%). The best ROC AUC values for melanoma and basal\ncell carcinoma are 94.40% (ResNet 152) and 99.30% (DenseNet 201) versus 82.26%\nand 88.82% of dermatologists, respectively. Also, DenseNet 201 had the highest\nmacro and micro averaged AUC values for overall classification (98.16%, 98.79%,\nrespectively).\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 23:27:59 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Rezvantalab", "Amirreza", ""], ["Safigholi", "Habib", ""], ["Karimijeshni", "Somayeh", ""]]}, {"id": "1810.10358", "submitter": "Lin Zhang", "authors": "Lin Zhang, Valery Vishnevskiy, Andras Jakab, Orcun Goksel", "title": "Implicit Modeling with Uncertainty Estimation for Intravoxel Incoherent\n  Motion Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intravoxel incoherent motion (IVIM) imaging allows contrast-agent free in\nvivo perfusion quantification with magnetic resonance imaging (MRI). However,\nits use is limited by typically low accuracy due to low signal-to-noise ratio\n(SNR) at large gradient encoding magnitudes as well as dephasing artefacts\ncaused by subject motion, which is particularly challenging in fetal MRI. To\nmitigate this problem, we propose an implicit IVIM signal acquisition model\nwith which we learn full posterior distribution of perfusion parameters using\nartificial neural networks. This posterior then encapsulates the uncertainty of\nthe inferred parameter estimates, which we validate herein via numerical\nexperiments with rejection-based Bayesian sampling. Compared to\nstate-of-the-art IVIM estimation method of segmented least-squares fitting, our\nproposed approach improves parameter estimation accuracy by 65% on synthetic\nanisotropic perfusion data. On paired rescans of in vivo fetal MRI, our method\nincreases repeatability of parameter estimation in placenta by 46%.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:22:10 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Zhang", "Lin", ""], ["Vishnevskiy", "Valery", ""], ["Jakab", "Andras", ""], ["Goksel", "Orcun", ""]]}, {"id": "1810.10363", "submitter": "Yang Xi", "authors": "Tianlun Zhang, Xi Yang", "title": "G-SMOTE: A GMM-based synthetic minority oversampling technique for\n  imbalanced learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced Learning is an important learning algorithm for the classification\nmodels, which have enjoyed much popularity on many applications. Typically,\nimbalanced learning algorithms can be partitioned into two types, i.e., data\nlevel approaches and algorithm level approaches. In this paper, the focus is to\ndevelop a robust synthetic minority oversampling technique which falls the\numbrella of data level approaches. On one hand, we proposed a method to\ngenerate synthetic samples in a high dimensional feature space, instead of a\nlinear sampling space. On the other hand, in the proposed imbalanced learning\nframework, Gaussian Mixture Model is employed to distinguish the outliers from\nminority class instances and filter out the synthetic majority class instances.\nLast and more importantly, an adaptive optimization method is proposed to\noptimize these parameters in sampling process. By doing so, an effectiveness\nand efficiency imbalanced learning framework is developed.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:46:25 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Zhang", "Tianlun", ""], ["Yang", "Xi", ""]]}, {"id": "1810.10368", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin, Gideon Dresdner, Heiko Strathmann, Gunnar R\\\"atsch", "title": "Scalable Gaussian Processes on Discrete Domains", "comments": "Published at IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3082761", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods on discrete domains have shown great promise for many\nchallenging data types, for instance, biological sequence data and molecular\nstructure data. Scalable kernel methods like Support Vector Machines may offer\ngood predictive performances but do not intrinsically provide uncertainty\nestimates. In contrast, probabilistic kernel methods like Gaussian Processes\noffer uncertainty estimates in addition to good predictive performance but fall\nshort in terms of scalability. While the scalability of Gaussian processes can\nbe improved using sparse inducing point approximations, the selection of these\ninducing points remains challenging. We explore different techniques for\nselecting inducing points on discrete domains, including greedy selection,\ndeterminantal point processes, and simulated annealing. We find that simulated\nannealing, which can select inducing points that are not in the training set,\ncan perform competitively with support vector machines and full Gaussian\nprocesses on synthetic data, as well as on challenging real-world DNA sequence\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:55:00 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 10:11:50 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 16:57:43 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Fortuin", "Vincent", ""], ["Dresdner", "Gideon", ""], ["Strathmann", "Heiko", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1810.10369", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and Arslan Munir", "title": "The Faults in Our Pi Stars: Security Issues and Open Challenges in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1807.06064,\n  arXiv:1712.03632, arXiv:1803.02811, arXiv:1710.00814 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the inception of Deep Reinforcement Learning (DRL) algorithms, there\nhas been a growing interest in both research and industrial communities in the\npromising potentials of this paradigm. The list of current and envisioned\napplications of deep RL ranges from autonomous navigation and robotics to\ncontrol applications in the critical infrastructure, air traffic control,\ndefense technologies, and cybersecurity. While the landscape of opportunities\nand the advantages of deep RL algorithms are justifiably vast, the security\nrisks and issues in such algorithms remain largely unexplored. To facilitate\nand motivate further research on these critical challenges, this paper presents\na foundational treatment of the security problem in DRL. We formulate the\nsecurity requirements of DRL, and provide a high-level threat model through the\nclassification and identification of vulnerabilities, attack vectors, and\nadversarial capabilities. Furthermore, we present a review of current\nliterature on security of deep RL from both offensive and defensive\nperspectives. Lastly, we enumerate critical research venues and open problems\nin mitigation and prevention of intentional attacks against deep RL as a\nroadmap for further research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 07:05:17 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Behzadan", "Vahid", ""], ["Munir", "Arslan", ""]]}, {"id": "1810.10380", "submitter": "Anna Veronika Dorogush", "authors": "Anna Veronika Dorogush, Vasily Ershov, Dmitriy Kruchinin", "title": "Why every GBDT speed benchmark is wrong", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a comprehensive study of different ways to make speed\nbenchmarks of gradient boosted decision trees algorithm. We show main problems\nof several straight forward ways to make benchmarks, explain, why a speed\nbenchmarking is a challenging task and provide a set of reasonable requirements\nfor a benchmark to be fair and useful.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 13:09:03 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Dorogush", "Anna Veronika", ""], ["Ershov", "Vasily", ""], ["Kruchinin", "Dmitriy", ""]]}, {"id": "1810.10425", "submitter": "Gaetano Manzo", "authors": "Gaetano Manzo, Juan Sebastian Ot\\'alora Montenegro, and Gianluca Rizzo", "title": "A Deep Learning Mechanism for Efficient Information Dissemination in\n  Vehicular Floating Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handling the tremendous amount of network data, produced by the explosive\ngrowth of mobile traffic volume, is becoming of main priority to achieve\ndesired performance targets efficiently. Opportunistic communication such as\nFloatingContent (FC), can be used to offload part of the cellular traffic\nvolume to vehicular-to-vehicular communication (V2V), leaving the\ninfrastructure the task of coordinating the communication. Existing FC\ndimensioning approaches have limitations, mainly due to unrealistic assumptions\nand on a coarse partitioning of users, which results in over-dimensioning.\nShaping the opportunistic communication area is a crucial task to achieve\ndesired application performance efficiently. In this work, we propose a\nsolution for this open challenge. In particular, the broadcasting areas called\nAnchor Zone (AZ), are selected via a deep learning approach to minimize\ncommunication resources achieving desired message availability. No assumption\nrequired to fit the classifier in both synthetic and real mobility. A numerical\nstudy is made to validate the effectiveness and efficiency of the proposed\nmethod. The predicted AZ configuration can achieve an accuracy of 89.7%within\n98% of confidence level. By cause of the learning approach, the method performs\neven better in real scenarios, saving up to 27% of resources compared to\nprevious work analytically modelled\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 14:36:54 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Manzo", "Gaetano", ""], ["Montenegro", "Juan Sebastian Ot\u00e1lora", ""], ["Rizzo", "Gianluca", ""]]}, {"id": "1810.10433", "submitter": "Scott Emmons", "authors": "Scott Emmons and Peter J. Mucha", "title": "A Map Equation with Metadata: Varying the Role of Attributes in\n  Community Detection", "comments": null, "journal-ref": "Phys. Rev. E 100, 022301 (2019)", "doi": "10.1103/PhysRevE.100.022301", "report-no": null, "categories": "cs.SI physics.data-an physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the community detection literature studies structural communities,\ncommunities defined solely by the connectivity patterns of the network. Often,\nnetworks contain additional metadata which can inform community detection such\nas the grade and gender of students in a high school social network. In this\nwork, we introduce a tuning parameter to the content map equation that allows\nusers of the Infomap community detection algorithm to control the metadata's\nrelative importance for identifying network structure. On synthetic networks,\nwe show that our algorithm can overcome the structural detectability limit when\nthe metadata is well-aligned with community structure. On real-world networks,\nwe show how our algorithm can achieve greater mutual information with the\nmetadata at a cost in the traditional map equation. Our tuning parameter, like\nthe focusing knob of a microscope, allows users to \"zoom in\" and \"zoom out\" on\ncommunities with varying levels of focus on the metadata.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 15:03:20 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 20:20:11 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Emmons", "Scott", ""], ["Mucha", "Peter J.", ""]]}, {"id": "1810.10460", "submitter": "Elliot J. Crowley", "authors": "Jack Turner, Elliot J. Crowley, Valentin Radu, Jos\\'e Cano, Amos\n  Storkey, Michael O'Boyle", "title": "Distilling with Performance Enhanced Students", "comments": "Preprint. Paper title has changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The task of accelerating large neural networks on general purpose hardware\nhas, in recent years, prompted the use of channel pruning to reduce network\nsize. However, the efficacy of pruning based approaches has since been called\ninto question. In this paper, we turn to distillation for model\ncompression---specifically, attention transfer---and develop a simple method\nfor discovering performance enhanced student networks. We combine channel\nsaliency metrics with empirical observations of runtime performance to design\nmore accurate networks for a given latency budget. We apply our methodology to\nresidual and densely-connected networks, and show that we are able to find\nresource-efficient student networks on different hardware platforms while\nmaintaining very high accuracy. These performance-enhanced student networks\nachieve up to 10% boosts in top-1 ImageNet accuracy over their channel-pruned\ncounterparts for the same inference time.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 15:45:36 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:19:50 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Turner", "Jack", ""], ["Crowley", "Elliot J.", ""], ["Radu", "Valentin", ""], ["Cano", "Jos\u00e9", ""], ["Storkey", "Amos", ""], ["O'Boyle", "Michael", ""]]}, {"id": "1810.10469", "submitter": "Tommy Tram", "authors": "Tommy Tram, Anton Jansson, Robin Gr\\\"onberg, Mohammad Ali, Jonas\n  Sj\\\"oberg", "title": "Learning Negotiating Behavior Between Cars in Intersections using Deep\n  Q-Learning", "comments": "6 pages, 7 figures, Accepted to IEEE International Conference on\n  Intelligent Transportation Systems (ITSC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns automated vehicles negotiating with other vehicles,\ntypically human driven, in crossings with the goal to find a decision algorithm\nby learning typical behaviors of other vehicles. The vehicle observes distance\nand speed of vehicles on the intersecting road and use a policy that adapts its\nspeed along its pre-defined trajectory to pass the crossing efficiently. Deep\nQ-learning is used on simulated traffic with different predefined driver\nbehaviors and intentions. The results show a policy that is able to cross the\nintersection avoiding collision with other vehicles 98% of the time, while at\nthe same time not being too passive. Moreover, inferring information over time\nis important to distinguish between different intentions and is shown by\ncomparing the collision rate between a Deep Recurrent Q-Network at 0.85% and a\nDeep Q-learning at 1.75%.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 16:06:33 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Tram", "Tommy", ""], ["Jansson", "Anton", ""], ["Gr\u00f6nberg", "Robin", ""], ["Ali", "Mohammad", ""], ["Sj\u00f6berg", "Jonas", ""]]}, {"id": "1810.10482", "submitter": "Rajat Sen", "authors": "Rajat Sen, Kirthevasan Kandasamy and Sanjay Shakkottai", "title": "Noisy Blackbox Optimization with Multi-Fidelity Queries: A Tree Search\n  Approach", "comments": "18 pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of black-box optimization of a noisy function in the\npresence of low-cost approximations or fidelities, which is motivated by\nproblems like hyper-parameter tuning. In hyper-parameter tuning evaluating the\nblack-box function at a point involves training a learning algorithm on a large\ndata-set at a particular hyper-parameter and evaluating the validation error.\nEven a single such evaluation can be prohibitively expensive. Therefore, it is\nbeneficial to use low-cost approximations, like training the learning algorithm\non a sub-sampled version of the whole data-set. These low-cost\napproximations/fidelities can however provide a biased and noisy estimate of\nthe function value. In this work, we incorporate the multi-fidelity setup in\nthe powerful framework of noisy black-box optimization through tree-like\nhierarchical partitions. We propose a multi-fidelity bandit based tree-search\nalgorithm for the problem and provide simple regret bounds for our algorithm.\nFinally, we validate the performance of our algorithm on real and synthetic\ndatasets, where it outperforms several benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 16:38:07 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Sen", "Rajat", ""], ["Kandasamy", "Kirthevasan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1810.10489", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa and Mihaela van der Schaar", "title": "Forecasting Individualized Disease Trajectories using Interpretable Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease progression models are instrumental in predicting individual-level\nhealth trajectories and understanding disease dynamics. Existing models are\ncapable of providing either accurate predictions of patients prognoses or\nclinically interpretable representations of disease pathophysiology, but not\nboth. In this paper, we develop the phased attentive state space (PASS) model\nof disease progression, a deep probabilistic model that captures complex\nrepresentations for disease progression while maintaining clinical\ninterpretability. Unlike Markovian state space models which assume memoryless\ndynamics, PASS uses an attention mechanism to induce \"memoryful\" state\ntransitions, whereby repeatedly updated attention weights are used to focus on\npast state realizations that best predict future states. This gives rise to\ncomplex, non-stationary state dynamics that remain interpretable through the\ngenerated attention weights, which designate the relationships between the\nrealized state variables for individual patients. PASS uses phased LSTM units\n(with time gates controlled by parametrized oscillations) to generate the\nattention weights in continuous time, which enables handling\nirregularly-sampled and potentially missing medical observations. Experiments\non data from a realworld cohort of patients show that PASS successfully\nbalances the tradeoff between accuracy and interpretability: it demonstrates\nsuperior predictive accuracy and learns insightful individual-level\nrepresentations of disease progression.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 16:51:35 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1810.10531", "submitter": "Andrew Saxe", "authors": "Andrew M. Saxe, James L. McClelland, and Surya Ganguli", "title": "A mathematical theory of semantic development in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extensive body of empirical research has revealed remarkable regularities\nin the acquisition, organization, deployment, and neural representation of\nhuman semantic knowledge, thereby raising a fundamental conceptual question:\nwhat are the theoretical principles governing the ability of neural networks to\nacquire, organize, and deploy abstract knowledge by integrating across many\nindividual experiences? We address this question by mathematically analyzing\nthe nonlinear dynamics of learning in deep linear networks. We find exact\nsolutions to this learning dynamics that yield a conceptual explanation for the\nprevalence of many disparate phenomena in semantic cognition, including the\nhierarchical differentiation of concepts through rapid developmental\ntransitions, the ubiquity of semantic illusions between such transitions, the\nemergence of item typicality and category coherence as factors controlling the\nspeed of semantic processing, changing patterns of inductive projection over\ndevelopment, and the conservation of semantic similarity in neural\nrepresentations across species. Thus, surprisingly, our simple neural model\nqualitatively recapitulates many diverse regularities underlying semantic\ndevelopment, while providing analytic insight into how the statistical\nstructure of an environment can interact with nonlinear deep learning dynamics\nto give rise to these regularities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:20:27 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Saxe", "Andrew M.", ""], ["McClelland", "James L.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1810.10533", "submitter": "Hari Prasanna Das", "authors": "Hari Prasanna Das, Ioannis C. Konstantakopoulos, Aummul Baneen\n  Manasawala, Tanya Veeravalli, Huihan Liu and Costas J. Spanos", "title": "Segmentation Analysis in Human Centric Cyber-Physical Systems using\n  Graphical Lasso", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.05142", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalized gamification framework is introduced as a form of smart\ninfrastructure with potential to improve sustainability and energy efficiency\nby leveraging humans-in-the-loop strategy. The proposed framework enables a\nHuman-Centric Cyber-Physical System using an interface to allow building\nmanagers to interact with occupants. The interface is designed for occupant\nengagement-integration supporting learning of their preferences over resources\nin addition to understanding how preferences change as a function of external\nstimuli such as physical control, time or incentives. Towards intelligent and\nautonomous incentive design, a noble statistical learning algorithm performing\noccupants energy usage behavior segmentation is proposed. We apply the proposed\nalgorithm, Graphical Lasso, on energy resource usage data by the occupants to\nobtain feature correlations--dependencies. Segmentation analysis results in\ncharacteristic clusters demonstrating different energy usage behaviors. The\nfeatures--factors characterizing human decision-making are made explainable.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 11:08:13 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 02:14:17 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Das", "Hari Prasanna", ""], ["Konstantakopoulos", "Ioannis C.", ""], ["Manasawala", "Aummul Baneen", ""], ["Veeravalli", "Tanya", ""], ["Liu", "Huihan", ""], ["Spanos", "Costas J.", ""]]}, {"id": "1810.10535", "submitter": "WaiChing Sun", "authors": "Kun Wang, WaiChing Sun", "title": "Meta-modeling game for deriving theoretical-consistent,\n  micro-structural-based traction-separation laws via deep reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2018.11.026", "report-no": null, "categories": "cs.LG physics.comp-ph physics.geo-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new meta-modeling framework to employ deep\nreinforcement learning (DRL) to generate mechanical constitutive models for\ninterfaces. The constitutive models are conceptualized as information flow in\ndirected graphs. The process of writing constitutive models are simplified as a\nsequence of forming graph edges with the goal of maximizing the model score (a\nfunction of accuracy, robustness and forward prediction quality). Thus\nmeta-modeling can be formulated as a Markov decision process with well-defined\nstates, actions, rules, objective functions, and rewards. By using neural\nnetworks to estimate policies and state values, the computer agent is able to\nefficiently self-improve the constitutive model it generated through\nself-playing, in the same way AlphaGo Zero (the algorithm that outplayed the\nworld champion in the game of Go)improves its gameplay. Our numerical examples\nshow that this automated meta-modeling framework not only produces models which\noutperform existing cohesive models on benchmark traction-separation data but\nis also capable of detecting hidden mechanisms among micro-structural features\nand incorporating them in constitutive models to improve the forward prediction\naccuracy, which are difficult tasks to do manually.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 23:21:55 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Wang", "Kun", ""], ["Sun", "WaiChing", ""]]}, {"id": "1810.10581", "submitter": "Abhik Singla", "authors": "Abhik Singla, Partha Pratim Roy and Debi Prosad Dogra", "title": "Visual Rendering of Shapes on 2D Display Devices Guided by Hand Gestures", "comments": "Submitted to Elsevier Displays Journal, 32 pages, 18 figures, 7\n  tables", "journal-ref": null, "doi": "10.1016/j.displa.2019.03.001", "report-no": null, "categories": "cs.HC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing of touchless user interface is gaining popularity in various\ncontexts. Using such interfaces, users can interact with electronic devices\neven when the hands are dirty or non-conductive. Also, user with partial\nphysical disability can interact with electronic devices using such systems.\nResearch in this direction has got major boost because of the emergence of\nlow-cost sensors such as Leap Motion, Kinect or RealSense devices. In this\npaper, we propose a Leap Motion controller-based methodology to facilitate\nrendering of 2D and 3D shapes on display devices. The proposed method tracks\nfinger movements while users perform natural gestures within the field of view\nof the sensor. In the next phase, trajectories are analyzed to extract extended\nNpen++ features in 3D. These features represent finger movements during the\ngestures and they are fed to unidirectional left-to-right Hidden Markov Model\n(HMM) for training. A one-to-one mapping between gestures and shapes is\nproposed. Finally, shapes corresponding to these gestures are rendered over the\ndisplay using MuPad interface. We have created a dataset of 5400 samples\nrecorded by 10 volunteers. Our dataset contains 18 geometric and 18\nnon-geometric shapes such as \"circle\", \"rectangle\", \"flower\", \"cone\", \"sphere\"\netc. The proposed methodology achieves an accuracy of 92.87% when evaluated\nusing 5-fold cross validation method. Our experiments revel that the extended\n3D features perform better than existing 3D features in the context of shape\nrepresentation and classification. The method can be used for developing useful\nHCI applications for smart display devices.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 16:59:52 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Singla", "Abhik", ""], ["Roy", "Partha Pratim", ""], ["Dogra", "Debi Prosad", ""]]}, {"id": "1810.10593", "submitter": "Adam Gleave", "authors": "Aaron Tucker and Adam Gleave and Stuart Russell", "title": "Inverse reinforcement learning for video games", "comments": "10 pages, 4 figures. Submitted to NIPS Deep RL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning achieves superhuman performance in a range of\nvideo game environments, but requires that a designer manually specify a reward\nfunction. It is often easier to provide demonstrations of a target behavior\nthan to design a reward function describing that behavior. Inverse\nreinforcement learning (IRL) algorithms can infer a reward from demonstrations\nin low-dimensional continuous control environments, but there has been little\nwork on applying IRL to high-dimensional video games. In our CNN-AIRL baseline,\nwe modify the state-of-the-art adversarial IRL (AIRL) algorithm to use CNNs for\nthe generator and discriminator. To stabilize training, we normalize the reward\nand increase the size of the discriminator training dataset. We additionally\nlearn a low-dimensional state representation using a novel autoencoder\narchitecture tuned for video game environments. This embedding is used as input\nto the reward network, improving the sample efficiency of expert\ndemonstrations. Our method achieves high-level performance on the simple\nCatcher video game, substantially outperforming the CNN-AIRL baseline. We also\nscore points on the Enduro Atari racing game, but do not match expert\nperformance, highlighting the need for further work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 20:00:50 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Tucker", "Aaron", ""], ["Gleave", "Adam", ""], ["Russell", "Stuart", ""]]}, {"id": "1810.10612", "submitter": "Frantzeska Lavda", "authors": "Frantzeska Lavda, Jason Ramapuram, Magda Gregorova, Alexandros\n  Kalousis", "title": "Continual Classification Learning Using Generative Models", "comments": "5 pages, 4 figures, under review in Continual learning Workshop NIPS\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning is the ability to sequentially learn over time by\naccommodating knowledge while retaining previously learned experiences. Neural\nnetworks can learn multiple tasks when trained on them jointly, but cannot\nmaintain performance on previously learned tasks when tasks are presented one\nat a time. This problem is called catastrophic forgetting. In this work, we\npropose a classification model that learns continuously from sequentially\nobserved tasks, while preventing catastrophic forgetting. We build on the\nlifelong generative capabilities of [10] and extend it to the classification\nsetting by deriving a new variational bound on the joint log likelihood, $\\log\np(x; y)$.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 20:41:13 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Lavda", "Frantzeska", ""], ["Ramapuram", "Jason", ""], ["Gregorova", "Magda", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1810.10625", "submitter": "Soorya Gopalakrishnan", "authors": "Soorya Gopalakrishnan, Zhinus Marzi, Metehan Cekic, Upamanyu Madhow,\n  Ramtin Pedarsani", "title": "Robust Adversarial Learning via Sparsifying Front Ends", "comments": "16 pages, 12 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is by now well-known that small adversarial perturbations can induce\nclassification errors in deep neural networks. In this paper, we take a\nbottom-up signal processing perspective to this problem and show that a\nsystematic exploitation of sparsity in natural data is a promising tool for\ndefense. For linear classifiers, we show that a sparsifying front end is\nprovably effective against $\\ell_{\\infty}$-bounded attacks, reducing output\ndistortion due to the attack by a factor of roughly $K/N$ where $N$ is the data\ndimension and $K$ is the sparsity level. We then extend this concept to deep\nnetworks, showing that a \"locally linear\" model can be used to develop a\ntheoretical foundation for crafting attacks and defenses. We also devise\nattacks based on the locally linear model that outperform the well-known FGSM\nattack. We supplement our theoretical results with experiments on the MNIST and\nCIFAR-10 datasets, showing the efficacy of the proposed sparsity-based defense\nschemes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 21:17:23 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 18:14:10 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 07:00:56 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Gopalakrishnan", "Soorya", ""], ["Marzi", "Zhinus", ""], ["Cekic", "Metehan", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1810.10627", "submitter": "Yao Ma", "authors": "Yao Ma, Ziyi Guo, Zhaochun Ren, Eric Zhao, Jiliang Tang and Dawei Yin", "title": "Streaming Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are essential representations of many real-world data such as social\nnetworks. Recent years have witnessed the increasing efforts made to extend the\nneural network models to graph-structured data. These methods, which are\nusually known as the graph neural networks, have been applied to advance many\ngraphs related tasks such as reasoning dynamics of the physical system, graph\nclassification, and node classification. Most of the existing graph neural\nnetwork models have been designed for static graphs, while many real-world\ngraphs are inherently dynamic. For example, social networks are naturally\nevolving as new users joining and new relations being created. Current graph\nneural network models cannot utilize the dynamic information in dynamic graphs.\nHowever, the dynamic information has been proven to enhance the performance of\nmany graph analytic tasks such as community detection and link prediction.\nHence, it is necessary to design dedicated graph neural networks for dynamic\ngraphs. In this paper, we propose DGNN, a new {\\bf D}ynamic {\\bf G}raph {\\bf\nN}eural {\\bf N}etwork model, which can model the dynamic information as the\ngraph evolving. In particular, the proposed framework can keep updating node\ninformation by capturing the sequential information of edges (interactions),\nthe time intervals between edges and information propagation coherently.\nExperimental results on various dynamic graphs demonstrate the effectiveness of\nthe proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 21:20:05 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 07:22:16 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ma", "Yao", ""], ["Guo", "Ziyi", ""], ["Ren", "Zhaochun", ""], ["Zhao", "Eric", ""], ["Tang", "Jiliang", ""], ["Yin", "Dawei", ""]]}, {"id": "1810.10637", "submitter": "Ruihao Zhu", "authors": "Ruihao Zhu, Eytan Modiano", "title": "Learning to Route Efficiently with End-to-End Feedback: The Value of\n  Networked Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce efficient algorithms which achieve nearly optimal regrets for\nthe problem of stochastic online shortest path routing with end-to-end\nfeedback. The setting is a natural application of the combinatorial stochastic\nbandits problem, a special case of the linear stochastic bandits problem. We\nshow how the difficulties posed by the large scale action set can be overcome\nby the networked structure of the action set. Our approach presents a novel\nconnection between bandit learning and shortest path algorithms. Our main\ncontribution is an adaptive exploration algorithm with nearly optimal\ninstance-dependent regret for any directed acyclic network. We then modify it\nso that nearly optimal worst case regret is achieved simultaneously. Driven by\nthe carefully designed Top-Two Comparison (TTC) technique, the algorithms are\nefficiently implementable. We further conduct extensive numerical experiments\nto show that our proposed algorithms not only achieve superior regret\nperformances, but also reduce the runtime drastically.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 21:47:19 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 02:19:20 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Zhu", "Ruihao", ""], ["Modiano", "Eytan", ""]]}, {"id": "1810.10659", "submitter": "Zhuwen Li", "authors": "Zhuwen Li, Qifeng Chen and Vladlen Koltun", "title": "Combinatorial Optimization with Graph Convolutional Networks and Guided\n  Tree Search", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based approach to computing solutions for certain\nNP-hard problems. Our approach combines deep learning techniques with useful\nalgorithmic elements from classic heuristics. The central component is a graph\nconvolutional network that is trained to estimate the likelihood, for each\nvertex in a graph, of whether this vertex is part of the optimal solution. The\nnetwork is designed and trained to synthesize a diverse set of solutions, which\nenables rapid exploration of the solution space via tree search. The presented\napproach is evaluated on four canonical NP-hard problems and five datasets,\nwhich include benchmark satisfiability problems and real social network graphs\nwith up to a hundred thousand nodes. Experimental results demonstrate that the\npresented approach substantially outperforms recent deep learning work, and\nperforms on par with highly optimized state-of-the-art heuristic solvers for\nsome NP-hard problems. Experiments indicate that our approach generalizes\nacross datasets, and scales to graphs that are orders of magnitude larger than\nthose used during training.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:12:44 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Li", "Zhuwen", ""], ["Chen", "Qifeng", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.10664", "submitter": "Pratik Shah", "authors": "Gregory Yauney, Aman Rana, Lawrence C. Wong, Perikumar Javia, Ali\n  Muftu and Pratik Shah", "title": "Automated Process Incorporating Machine Learning Segmentation and\n  Correlation of Oral Diseases with Systemic Health", "comments": "Submitted to IEEE Journal of Biomedical and Health Informatics, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging fluorescent disease biomarkers in tissues and skin is a non-invasive\nmethod to screen for health conditions. We report an automated process that\ncombines intraoral fluorescent porphyrin biomarker imaging, clinical\nexaminations and machine learning for correlation of systemic health conditions\nwith periodontal disease. 1215 intraoral fluorescent images, from 284\nconsenting adults aged 18-90, were analyzed using a machine learning classifier\nthat can segment periodontal inflammation. The classifier achieved an AUC of\n0.677 with precision and recall of 0.271 and 0.429, respectively, indicating a\nlearned association between disease signatures in collected images. Periodontal\ndiseases were more prevalent among males (p=0.0012) and older subjects\n(p=0.0224) in the screened population. Physicians independently examined the\ncollected images, assigning localized modified gingival indices (MGIs). MGIs\nand periodontal disease were then cross-correlated with responses to a medical\nhistory questionnaire, blood pressure and body mass index measurements, and\noptic nerve, tympanic membrane, neurological, and cardiac rhythm imaging\nexaminations. Gingivitis and early periodontal disease were associated with\nsubjects diagnosed with optic nerve abnormalities (p <0.0001) in their retinal\nscans. We also report significant co-occurrences of periodontal disease in\nsubjects reporting swollen joints (p=0.0422) and a family history of eye\ndisease (p=0.0337). These results indicate cross-correlation of poor\nperiodontal health with systemic health outcomes and stress the importance of\noral health screenings at the primary care level. Our screening process and\nanalysis method, using images and machine learning, can be generalized for\nautomated diagnoses and systemic health screenings for other diseases.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:42:20 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Yauney", "Gregory", ""], ["Rana", "Aman", ""], ["Wong", "Lawrence C.", ""], ["Javia", "Perikumar", ""], ["Muftu", "Ali", ""], ["Shah", "Pratik", ""]]}, {"id": "1810.10667", "submitter": "Amirreza Shaban", "authors": "Amirreza Shaban, Ching-An Cheng, Nathan Hatch, Byron Boots", "title": "Truncated Back-propagation for Bilevel Optimization", "comments": null, "journal-ref": "The International Conference on Artificial Intelligence and\n  Statistics (AISTATS) 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization has been recently revisited for designing and analyzing\nalgorithms in hyperparameter tuning and meta learning tasks. However, due to\nits nested structure, evaluating exact gradients for high-dimensional problems\nis computationally challenging. One heuristic to circumvent this difficulty is\nto use the approximate gradient given by performing truncated back-propagation\nthrough the iterative optimization procedure that solves the lower-level\nproblem. Although promising empirical performance has been reported, its\ntheoretical properties are still unclear. In this paper, we analyze the\nproperties of this family of approximate gradients and establish sufficient\nconditions for convergence. We validate this on several hyperparameter tuning\nand meta learning tasks. We find that optimization with the approximate\ngradient computed using few-step back-propagation often performs comparably to\noptimization with the exact gradient, while requiring far less memory and half\nthe computation time.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:49:36 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 19:49:06 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Shaban", "Amirreza", ""], ["Cheng", "Ching-An", ""], ["Hatch", "Nathan", ""], ["Boots", "Byron", ""]]}, {"id": "1810.10690", "submitter": "Zhe Wang", "authors": "Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, Vahid Tarokh", "title": "SpiderBoost and Momentum: Faster Stochastic Variance Reduction\n  Algorithms", "comments": "Appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SARAH and SPIDER are two recently developed stochastic variance-reduced\nalgorithms, and SPIDER has been shown to achieve a near-optimal first-order\noracle complexity in smooth nonconvex optimization. However, SPIDER uses an\naccuracy-dependent stepsize that slows down the convergence in practice, and\ncannot handle objective functions that involve nonsmooth regularizers. In this\npaper, we propose SpiderBoost as an improved scheme, which allows to use a much\nlarger constant-level stepsize while maintaining the same near-optimal oracle\ncomplexity, and can be extended with proximal mapping to handle composite\noptimization (which is nonsmooth and nonconvex) with provable convergence\nguarantee. In particular, we show that proximal SpiderBoost achieves an oracle\ncomplexity of $\\mathcal{O}(\\min\\{n^{1/2}\\epsilon^{-2},\\epsilon^{-3}\\})$ in\ncomposite nonconvex optimization, improving the state-of-the-art result by a\nfactor of $\\mathcal{O}(\\min\\{n^{1/6},\\epsilon^{-1/3}\\})$. We further develop a\nnovel momentum scheme to accelerate SpiderBoost for composite optimization,\nwhich achieves the near-optimal oracle complexity in theory and substantial\nimprovement in experiments.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 02:18:03 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 02:38:05 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 19:12:01 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Wang", "Zhe", ""], ["Ji", "Kaiyi", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1810.10695", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Gal Mishne", "title": "Spectral Embedding Norm: Looking Deep into the Spectrum of the Graph\n  Laplacian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of clusters from a dataset which includes multiple clusters\nand a significant background component is a non-trivial task of practical\nimportance. In image analysis this manifests for example in anomaly detection\nand target detection. The traditional spectral clustering algorithm, which\nrelies on the leading $K$ eigenvectors to detect $K$ clusters, fails in such\ncases. In this paper we propose the {\\it spectral embedding norm} which sums\nthe squared values of the first $I$ normalized eigenvectors, where $I$ can be\nsignificantly larger than $K$. We prove that this quantity can be used to\nseparate clusters from the background in unbalanced settings, including extreme\ncases such as outlier detection. The performance of the algorithm is not\nsensitive to the choice of $I$, and we demonstrate its application on synthetic\nand real-world remote sensing and neuroimaging datasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 02:51:54 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 19:38:40 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Mishne", "Gal", ""]]}, {"id": "1810.10702", "submitter": "Yu Bai", "authors": "Yu Bai, Qijia Jiang, Ju Sun", "title": "Subgradient Descent Learns Orthogonal Dictionaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns dictionary learning, i.e., sparse coding, a fundamental\nrepresentation learning problem. We show that a subgradient descent algorithm,\nwith random initialization, can provably recover orthogonal dictionaries on a\nnatural nonsmooth, nonconvex $\\ell_1$ minimization formulation of the problem,\nunder mild statistical assumptions on the data. This is in contrast to previous\nprovable methods that require either expensive computation or delicate\ninitialization schemes. Our analysis develops several tools for characterizing\nlandscapes of nonsmooth functions, which might be of independent interest for\nprovable training of deep networks with nonsmooth activations (e.g., ReLU),\namong numerous other applications. Preliminary experiments corroborate our\nanalysis and show that our algorithm works well empirically in recovering\northogonal dictionaries.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 03:07:58 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 05:26:18 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bai", "Yu", ""], ["Jiang", "Qijia", ""], ["Sun", "Ju", ""]]}, {"id": "1810.10703", "submitter": "Pramod Kaushik Mudrakarta", "authors": "Pramod Kaushik Mudrakarta, Mark Sandler, Andrey Zhmoginov, Andrew\n  Howard", "title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer\n  Learning", "comments": "published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method that enables parameter-efficient transfer and\nmulti-task learning with deep neural networks. The basic approach is to learn a\nmodel patch - a small set of parameters - that will specialize to each task,\ninstead of fine-tuning the last layer or the entire network. For instance, we\nshow that learning a set of scales and biases is sufficient to convert a\npretrained network to perform well on qualitatively different problems (e.g.\nconverting a Single Shot MultiBox Detection (SSD) model into a 1000-class image\nclassification model while reusing 98% of parameters of the SSD feature\nextractor). Similarly, we show that re-learning existing low-parameter layers\n(such as depth-wise convolutions) while keeping the rest of the network frozen\nalso improves transfer-learning accuracy significantly. Our approach allows\nboth simultaneous (multi-task) as well as sequential transfer learning. In\nseveral multi-task learning problems, despite using much fewer parameters than\ntraditional logits-only fine-tuning, we match single-task performance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 03:12:37 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 02:03:00 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mudrakarta", "Pramod Kaushik", ""], ["Sandler", "Mark", ""], ["Zhmoginov", "Andrey", ""], ["Howard", "Andrew", ""]]}, {"id": "1810.10731", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, David R. O'Brien, Kendra Albert, Salome\n  Vilojen", "title": "Law and Adversarial Machine Learning", "comments": "Minor edits. Corrected typos, Added references. 4 pages, submitted to\n  NIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When machine learning systems fail because of adversarial manipulation, how\nshould society expect the law to respond? Through scenarios grounded in\nadversarial ML literature, we explore how some aspects of computer crime,\ncopyright, and tort law interface with perturbation, poisoning, model stealing\nand model inversion attacks to show how some attacks are more likely to result\nin liability than others. We end with a call for action to ML researchers to\ninvest in transparent benchmarks of attacks and defenses; architect ML systems\nwith forensics in mind and finally, think more about adversarial machine\nlearning in the context of civil liberties. The paper is targeted towards ML\nresearchers who have no legal background.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 06:17:34 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:45:10 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 02:02:46 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["O'Brien", "David R.", ""], ["Albert", "Kendra", ""], ["Vilojen", "Salome", ""]]}, {"id": "1810.10770", "submitter": "Frank Nielsen", "authors": "Erika Gomes-Gon\\c{c}alves, Henryk Gzyl and Frank Nielsen", "title": "Geometry and clustering with metrics derived from separable Bregman\n  divergences", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separable Bregman divergences induce Riemannian metric spaces that are\nisometric to the Euclidean space after monotone embeddings. We investigate\nfixed rate quantization and its codebook Voronoi diagrams, and report on\nexperimental performances of partition-based, hierarchical, and soft clustering\nalgorithms with respect to these Riemann-Bregman distances.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 08:41:24 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Gomes-Gon\u00e7alves", "Erika", ""], ["Gzyl", "Henryk", ""], ["Nielsen", "Frank", ""]]}, {"id": "1810.10775", "submitter": "Ilija Bogunovic", "authors": "Ilija Bogunovic and Jonathan Scarlett and Stefanie Jegelka and Volkan\n  Cevher", "title": "Adversarially Robust Optimization with Gaussian Processes", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of Gaussian process (GP) optimization\nwith an added robustness requirement: The returned point may be perturbed by an\nadversary, and we require the function value to remain as high as possible even\nafter this perturbation. This problem is motivated by settings in which the\nunderlying functions during optimization and implementation stages are\ndifferent, or when one is interested in finding an entire region of good inputs\nrather than only a single point. We show that standard GP optimization\nalgorithms do not exhibit the desired robustness properties, and provide a\nnovel confidence-bound based algorithm StableOpt for this purpose. We\nrigorously establish the required number of samples for StableOpt to find a\nnear-optimal point, and we complement this guarantee with an\nalgorithm-independent lower bound. We experimentally demonstrate several\npotential applications of interest using real-world data sets, and we show that\nStableOpt consistently succeeds in finding a stable maximizer where several\nbaseline methods fail.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 08:47:46 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 20:37:11 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Bogunovic", "Ilija", ""], ["Scarlett", "Jonathan", ""], ["Jegelka", "Stefanie", ""], ["Cevher", "Volkan", ""]]}, {"id": "1810.10777", "submitter": "Vidyadhar Upadhya", "authors": "Vidyadhar Upadhya, P.S. Sastry", "title": "Efficient Learning of Restricted Boltzmann Machines Using Covariance\n  Estimates", "comments": "Proceedings of Asian Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning RBMs using standard algorithms such as CD(k) involves gradient\ndescent on the negative log-likelihood. One of the terms in the gradient, which\ninvolves expectation w.r.t. the model distribution, is intractable and is\nobtained through an MCMC estimate. In this work we show that the Hessian of the\nlog-likelihood can be written in terms of covariances of hidden and visible\nunits and hence, all elements of the Hessian can also be estimated using the\nsame MCMC samples with small extra computational costs. Since inverting the\nHessian may be computationally expensive, we propose an algorithm that uses\ninverse of the diagonal approximation of the Hessian, instead. This essentially\nresults in parameter-specific adaptive learning rates for the gradient descent\nprocess and improves the efficiency of learning RBMs compared to the standard\nmethods. Specifically we show that using the inverse of diagonal approximation\nof Hessian in the stochastic DC (difference of convex functions) program\napproach results in very efficient learning of RBMs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 08:51:19 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 04:58:01 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Upadhya", "Vidyadhar", ""], ["Sastry", "P. S.", ""]]}, {"id": "1810.10786", "submitter": "Stefan Engblom", "authors": "Jing Liu and Gijs van der Schot and Stefan Engblom", "title": "Supervised Classification Methods for Flash X-ray single particle\n  diffraction Imaging", "comments": null, "journal-ref": null, "doi": "10.1364/OE.27.003884", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Flash X-ray single-particle diffraction Imaging (FXI) experiments,\nwhich operate on modern X-ray Free Electron Lasers (XFELs), can record millions\nof interpretable diffraction patterns from individual biomolecules per day. Due\nto the stochastic nature of the XFELs, those patterns will to a varying degree\ninclude scatterings from contaminated samples. Also, the heterogeneity of the\nsample biomolecules is unavoidable and complicates data processing. Reducing\nthe data volumes and selecting high-quality single-molecule patterns are\ntherefore critical steps in the experimental set-up.\n  In this paper, we present two supervised template-based learning methods for\nclassifying FXI patterns. Our Eigen-Image and Log-Likelihood classifier can\nfind the best-matched template for a single-molecule pattern within a few\nmilliseconds. It is also straightforward to parallelize them so as to fully\nmatch the XFEL repetition rate, thereby enabling processing at site.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:02:03 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Liu", "Jing", ""], ["van der Schot", "Gijs", ""], ["Engblom", "Stefan", ""]]}, {"id": "1810.10798", "submitter": "Anastasia Borovykh", "authors": "Anastasia Borovykh", "title": "A Gaussian Process perspective on Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we cast the well-known convolutional neural network in a\nGaussian process perspective. In this way we hope to gain additional insights\ninto the performance of convolutional networks, in particular understand under\nwhat circumstances they tend to perform well and what assumptions are\nimplicitly made in the network. While for fully-connected networks the\nproperties of convergence to Gaussian processes have been studied extensively,\nlittle is known about situations in which the output from a convolutional\nnetwork approaches a multivariate normal distribution.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:18:20 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 15:29:23 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Borovykh", "Anastasia", ""]]}, {"id": "1810.10815", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Shiyin Lu, Zhi-Hua Zhou", "title": "Adaptive Online Learning in Dynamic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study online convex optimization in dynamic environments,\nand aim to bound the dynamic regret with respect to any sequence of\ncomparators. Existing work have shown that online gradient descent enjoys an\n$O(\\sqrt{T}(1+P_T))$ dynamic regret, where $T$ is the number of iterations and\n$P_T$ is the path-length of the comparator sequence. However, this result is\nunsatisfactory, as there exists a large gap from the $\\Omega(\\sqrt{T(1+P_T)})$\nlower bound established in our paper. To address this limitation, we develop a\nnovel online method, namely adaptive learning for dynamic environment (Ader),\nwhich achieves an optimal $O(\\sqrt{T(1+P_T)})$ dynamic regret. The basic idea\nis to maintain a set of experts, each attaining an optimal dynamic regret for a\nspecific path-length, and combines them with an expert-tracking algorithm.\nFurthermore, we propose an improved Ader based on the surrogate loss, and in\nthis way the number of gradient evaluations per round is reduced from $O(\\log\nT)$ to $1$. Finally, we extend Ader to the setting that a sequence of dynamical\nmodels is available to characterize the comparators.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 10:13:04 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zhang", "Lijun", ""], ["Lu", "Shiyin", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1810.10866", "submitter": "Yunsheng Bai", "authors": "Yunsheng Bai, Hao Ding, Yizhou Sun, Wei Wang", "title": "Convolutional Set Matching for Graph Similarity", "comments": "NIPS 2018 Workshop: Relational Representation Learning. Note:\n  Substantial text overlap with arXiv:1809.04440", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GSimCNN (Graph Similarity Computation via Convolutional Neural\nNetworks) for predicting the similarity score between two graphs. As the core\noperation of graph similarity search, pairwise graph similarity computation is\na challenging problem due to the NP-hard nature of computing many graph\ndistance/similarity metrics. We demonstrate our model using the Graph Edit\nDistance (GED) as the example metric. Experiments on three real graph datasets\ndemonstrate that our model achieves the state-of-the-art performance on graph\nsimilarity search.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:22:48 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 22:33:48 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 17:04:14 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Bai", "Yunsheng", ""], ["Ding", "Hao", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "1810.10895", "submitter": "Xiaotian Yu", "authors": "Han Shao, Xiaotian Yu, Irwin King and Michael R. Lyu", "title": "Almost Optimal Algorithms for Linear Stochastic Bandits with\n  Heavy-Tailed Payoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear stochastic bandits, it is commonly assumed that payoffs are with\nsub-Gaussian noises. In this paper, under a weaker assumption on noises, we\nstudy the problem of \\underline{lin}ear stochastic {\\underline b}andits with\nh{\\underline e}avy-{\\underline t}ailed payoffs (LinBET), where the\ndistributions have finite moments of order $1+\\epsilon$, for some $\\epsilon\\in\n(0,1]$. We rigorously analyze the regret lower bound of LinBET as\n$\\Omega(T^{\\frac{1}{1+\\epsilon}})$, implying that finite moments of order 2\n(i.e., finite variances) yield the bound of $\\Omega(\\sqrt{T})$, with $T$ being\nthe total number of rounds to play bandits. The provided lower bound also\nindicates that the state-of-the-art algorithms for LinBET are far from optimal.\nBy adopting median of means with a well-designed allocation of decisions and\ntruncation based on historical information, we develop two novel bandit\nalgorithms, where the regret upper bounds match the lower bound up to\npolylogarithmic factors. To the best of our knowledge, we are the first to\nsolve LinBET optimally in the sense of the polynomial order on $T$. Our\nproposed algorithms are evaluated based on synthetic datasets, and outperform\nthe state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 14:29:02 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 13:47:50 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Shao", "Han", ""], ["Yu", "Xiaotian", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1810.10927", "submitter": "Ekaterina Lobacheva Ms", "authors": "Nadezhda Chirkova, Ekaterina Lobacheva, Dmitry Vetrov", "title": "Bayesian Compression for Natural Language Processing", "comments": "Published in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing, a lot of the tasks are successfully solved\nwith recurrent neural networks, but such models have a huge number of\nparameters. The majority of these parameters are often concentrated in the\nembedding layer, which size grows proportionally to the vocabulary length. We\npropose a Bayesian sparsification technique for RNNs which allows compressing\nthe RNN dozens or hundreds of times without time-consuming hyperparameters\ntuning. We also generalize the model for vocabulary sparsification to filter\nout unnecessary words and compress the RNN even further. We show that the\nchoice of the kept words is interpretable. Code is available on github:\nhttps://github.com/tipt0p/SparseBayesianRNN\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:27:23 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 17:18:13 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Chirkova", "Nadezhda", ""], ["Lobacheva", "Ekaterina", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.10929", "submitter": "Han Jindong", "authors": "Mingtao Dong and Jindong Han", "title": "HAR-Net:Fusing Deep Representation and Hand-crafted Features for Human\n  Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable computing and context awareness are the focuses of study in the\nfield of artificial intelligence recently. One of the most appealing as well as\nchallenging applications is the Human Activity Recognition (HAR) utilizing\nsmart phones. Conventional HAR based on Support Vector Machine relies on\nsubjective manually extracted features. This approach is time and energy\nconsuming as well as immature in prediction due to the partial view toward\nwhich features to be extracted by human. With the rise of deep learning,\nartificial intelligence has been making progress toward being a mature\ntechnology. This paper proposes a new approach based on deep learning and\ntraditional feature engineering called HAR-Net to address the issue related to\nHAR. The study used the data collected by gyroscopes and acceleration sensors\nin android smart phones. The raw sensor data was put into the HAR-Net proposed.\nThe HAR-Net fusing the hand-crafted features and high-level features extracted\nfrom convolutional network to make prediction. The performance of the proposed\nmethod was proved to be 0.9% higher than the original MC-SVM approach. The\nexperimental results on the UCI dataset demonstrate that fusing the two kinds\nof features can make up for the shortage of traditional feature engineering and\ndeep learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:30:07 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Dong", "Mingtao", ""], ["Han", "Jindong", ""]]}, {"id": "1810.10939", "submitter": "Bogdan Kulynych", "authors": "Bogdan Kulynych, Jamie Hayes, Nikita Samarin, Carmela Troncoso", "title": "Evading classifiers in discrete domains with provable optimality\n  guarantees", "comments": "NeurIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning models for security-critical applications such as bot,\nmalware, or spam detection, operate in constrained discrete domains. These\napplications would benefit from having provable guarantees against adversarial\nexamples. The existing literature on provable adversarial robustness of models,\nhowever, exclusively focuses on robustness to gradient-based attacks in domains\nsuch as images. These attacks model the adversarial cost, e.g., amount of\ndistortion applied to an image, as a $p$-norm. We argue that this approach is\nnot well-suited to model adversarial costs in constrained domains where not all\nexamples are feasible.\n  We introduce a graphical framework that (1) generalizes existing attacks in\ndiscrete domains, (2) can accommodate complex cost functions beyond $p$-norms,\nincluding financial cost incurred when attacking a classifier, and (3)\nefficiently produces valid adversarial examples with guarantees of minimal\nadversarial cost. These guarantees directly translate into a notion of\nadversarial robustness that takes into account domain constraints and the\nadversary's capabilities. We show how our framework can be used to evaluate\nsecurity by crafting adversarial examples that evade a Twitter-bot detection\nclassifier with provably minimal number of changes; and to build privacy\ndefenses by crafting adversarial examples that evade a privacy-invasive\nwebsite-fingerprinting classifier.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:53:19 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 14:26:22 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 15:10:25 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kulynych", "Bogdan", ""], ["Hayes", "Jamie", ""], ["Samarin", "Nikita", ""], ["Troncoso", "Carmela", ""]]}, {"id": "1810.10948", "submitter": "Jianlin Su", "authors": "Jianlin Su", "title": "Training Generative Adversarial Networks Via Turing Test", "comments": "fix some clerical errors, add some experimental data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, we introduce a new mode for training Generative Adversarial\nNetworks (GANs). Rather than minimizing the distance of evidence distribution\n$\\tilde{p}(x)$ and the generative distribution $q(x)$, we minimize the distance\nof $\\tilde{p}(x_r)q(x_f)$ and $\\tilde{p}(x_f)q(x_r)$. This adversarial pattern\ncan be interpreted as a Turing test in GANs. It allows us to use information of\nreal samples during training generator and accelerates the whole training\nprocedure. We even find that just proportionally increasing the size of\ndiscriminator and generator, it succeeds on 256x256 resolution without\nadjusting hyperparameters carefully.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:08:02 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 08:49:53 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Su", "Jianlin", ""]]}, {"id": "1810.10952", "submitter": "Yuankai Wu", "authors": "Yuankai Wu, Huachun Tan, Bin Ran", "title": "Differential Variable Speed Limits Control for Freeway Recurrent\n  Bottlenecks via Deep Reinforcement learning", "comments": "24 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable speed limits (VSL) control is a flexible way to improve traffic\ncondition,increase safety and reduce emission. There is an emerging trend of\nusing reinforcement learning technique for VSL control and recent studies have\nshown promising results. Currently, deep learning is enabling reinforcement\nlearning to develope autonomous control agents for problems that were\npreviously intractable. In this paper, we propose a more effective deep\nreinforcement learning (DRL) model for differential variable speed limits\n(DVSL) control, in which the dynamic and different speed limits among lanes can\nbe imposed. The proposed DRL models use a novel actor-critic architecture which\ncan learn a large number of discrete speed limits in a continues action space.\nDifferent reward signals, e.g. total travel time, bottleneck speed, emergency\nbraking, and vehicular emission are used to train the DVSL controller, and\ncomparison between these reward signals are conducted. We test proposed DRL\nbaased DVSL controllers on a simulated freeway recurrent bottleneck. Results\nshow that the efficiency, safety and emissions can be improved by the proposed\nmethod. We also show some interesting findings through the visulization of the\ncontrol policies generated from DRL models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:11:29 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Wu", "Yuankai", ""], ["Tan", "Huachun", ""], ["Ran", "Bin", ""]]}, {"id": "1810.10956", "submitter": "Tiago Carvalho", "authors": "Kemilly Dearo Garcia, Tiago Carvalho, Jo\\~ao Mendes-Moreira, Jo\\~ao\n  M.P. Cardoso and Andr\\'e C.P.L.F. de Carvalho", "title": "A Preliminary Study on Hyperparameter Configuration for Human Activity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition (HAR) is a classification task that aims to\nclassify human activities or predict human behavior by means of features\nextracted from sensors data. Typical HAR systems use wearable sensors and/or\nhandheld and mobile devices with built-in sensing capabilities. Due to the\nwidespread use of smartphones and to the inclusion of various sensors in all\ncontemporary smartphones (e.g., accelerometers and gyroscopes), they are\ncommonly used for extracting and collecting data from sensors and even for\nimplementing HAR systems. When using mobile devices, e.g., smartphones, HAR\nsystems need to deal with several constraints regarding battery, computation\nand memory. These constraints enforce the need of a system capable of managing\nits resources and maintain acceptable levels of classification accuracy.\nMoreover, several factors can influence activity recognition, such as\nclassification models, sensors availability and size of data window for feature\nextraction, making stable accuracy a difficult task. In this paper, we present\na semi-supervised classifier and a study regarding the influence of\nhyperparameter configuration in classification accuracy, depending on the user\nand the activities performed by each user. This study focuses on sensing data\nprovided by the PAMAP2 dataset. Experimental results show that it is possible\nto maintain classification accuracy by adjusting hyperparameters, like window\nsize and windows overlap factor, depending on user and activity performed.\nThese experiments motivate the development of a system able to automatically\nadapt hyperparameter settings for the activity performed by each user.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:26:30 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Garcia", "Kemilly Dearo", ""], ["Carvalho", "Tiago", ""], ["Mendes-Moreira", "Jo\u00e3o", ""], ["Cardoso", "Jo\u00e3o M. P.", ""], ["de Carvalho", "Andr\u00e9 C. P. L. F.", ""]]}, {"id": "1810.10957", "submitter": "Ishan Jindal", "authors": "Ishan Jindal and Matthew Nokleby", "title": "Tensor Matched Kronecker-Structured Subspace Detection for Missing\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of detecting whether a tensor signal having many\nmissing entities lies within a given low dimensional Kronecker-Structured (KS)\nsubspace. This is a matched subspace detection problem. Tensor matched subspace\ndetection problem is more challenging because of the intertwined signal\ndimensions. We solve this problem by projecting the signal onto the Kronecker\nstructured subspace, which is a Kronecker product of different subspaces\ncorresponding to each signal dimension. Under this framework, we define the KS\nsubspaces and the orthogonal projection of the signal onto the KS subspace. We\nprove that reliable detection is possible as long as the cardinality of the\nmissing signal is greater than the dimensions of the KS subspace by bounding\nthe residual energy of the sampling signal with high probability.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:27:14 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Jindal", "Ishan", ""], ["Nokleby", "Matthew", ""]]}, {"id": "1810.10958", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "SilentPhone: Inferring User Unavailability based Opportune Moments to\n  Minimize Call Interruptions", "comments": "EAI Endorsed Transactions on Mobile Communications and Applications,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of cell phones has made them the most personal and\nubiquitous communication devices nowadays. Typically, the ringing notifications\nof mobile phones are used to inform the users about the incoming calls.\nHowever, the notifications of inappropriate incoming calls sometimes cause\ninterruptions not only for the users but also the surrounding people. In this\npaper, we present a data-driven approach to infer the opportune moments for\nsuch phone call interruptions based on user's unavailability, i.e., when a user\nis unable to answer the incoming phone calls, by analyzing individual's past\nphone log data, and to discover the corresponding phone silent mode configuring\nrules for the purpose of minimizing call interruptions in an automated\nintelligent system. Experiments on the real mobile phone datasets show that our\napproach is able to identify the opportune moments for call interruptions and\ngenerates corresponding silent mode configuring rules by capturing the dominant\nbehavior of individual users' at various times-of-the-day and days-of-the week.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 14:56:02 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "1810.10962", "submitter": "Lei Deng", "authors": "Zhaodong Chen, Lei Deng, Guoqi Li, Jiawei Sun, Xing Hu, Xin Ma, Yuan\n  Xie", "title": "Batch Normalization Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) thrive in recent years in which Batch\nNormalization (BN) plays an indispensable role. However, it has been observed\nthat BN is costly due to the reduction operations. In this paper, we propose\nalleviating this problem through sampling only a small fraction of data for\nnormalization at each iteration. Specifically, we model it as a statistical\nsampling problem and identify that by sampling less correlated data, we can\nlargely reduce the requirement of the number of data for statistics estimation\nin BN, which directly simplifies the reduction operations. Based on this\nconclusion, we propose two sampling strategies, \"Batch Sampling\" (randomly\nselect several samples from each batch) and \"Feature Sampling\" (randomly select\na small patch from each feature map of all samples), that take both\ncomputational efficiency and sample correlation into consideration.\nFurthermore, we introduce an extremely simple variant of BN, termed as Virtual\nDataset Normalization (VDN), that can normalize the activations well with few\nsynthetical random samples. All the proposed methods are evaluated on various\ndatasets and networks, where an overall training speedup by up to 20% on GPU is\npractically achieved without the support of any specialized libraries, and the\nloss on accuracy and convergence rate are negligible. Finally, we extend our\nwork to the \"micro-batch normalization\" problem and yield comparable\nperformance with existing approaches at the case of tiny batch size.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:31:49 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 01:54:47 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Chen", "Zhaodong", ""], ["Deng", "Lei", ""], ["Li", "Guoqi", ""], ["Sun", "Jiawei", ""], ["Hu", "Xing", ""], ["Ma", "Xin", ""], ["Xie", "Yuan", ""]]}, {"id": "1810.10971", "submitter": "Ilya Chevyrev", "authors": "Ilya Chevyrev and Harald Oberhauser", "title": "Signature moments to characterize laws of stochastic processes", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The normalized sequence of moments characterizes the law of any\nfinite-dimensional random variable. We prove an analogous result for\npath-valued random variables, that is stochastic processes, by using the\nnormalized sequence of signature moments. We use this to define a metric for\nlaws of stochastic processes. This metric can be efficiently estimated from\nfinite samples, even if the stochastic processes themselves evolve in\nhigh-dimensional state spaces. As an application, we provide a non-parametric\ntwo-sample hypothesis test for laws of stochastic processes.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:48:20 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Chevyrev", "Ilya", ""], ["Oberhauser", "Harald", ""]]}, {"id": "1810.10977", "submitter": "Erva Ulu", "authors": "Yining Wang and Erva Ulu and Aarti Singh and Levent Burak Kara", "title": "Efficient Load Sampling for Worst-Case Structural Analysis Under Force\n  Location Uncertainty", "comments": "Proceedings of the ASME 2018 International Design Engineering\n  Technical Conferences & Computers and Information in Engineering Conference\n  (IDETC/CIE 2018) (In Print)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task in structural design is to quantify the structural\nperformance of an object under the external forces it may experience during its\nuse. The problem proves to be computationally very challenging as the external\nforces' contact locations and magnitudes may exhibit significant variations. We\npresent an efficient analysis approach to determine the most critical force\ncontact location in such problems with force location uncertainty. Given an\ninput 3D model and regions on its boundary where arbitrary normal forces may\nmake contact, our algorithm predicts the worst-case force configuration\nresponsible for creating the highest stress within the object. Our approach\nuses a computationally tractable experimental design method to select number of\nsample force locations based on geometry only, without inspecting the stress\nresponse that requires computationally expensive finite-element analysis. Then,\nwe construct a simple regression model on these samples and corresponding\nmaximum stresses. Combined with a simple ranking based post-processing step,\nour method provides a practical solution to worst-case structural analysis\nproblem. The results indicate that our approach achieves significant\nimprovements over the existing work and brute force approaches. We demonstrate\nthat further speed- up can be obtained when small amount of an error tolerance\nin maximum stress is allowed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:55:23 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Wang", "Yining", ""], ["Ulu", "Erva", ""], ["Singh", "Aarti", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1810.10987", "submitter": "Martin Weidner", "authors": "Hyungsik Roger Moon, Martin Weidner", "title": "Nuclear Norm Regularized Estimation of Panel Regression Models", "comments": "61 pages main text, 36 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate panel regression models with interactive fixed\neffects. We propose two new estimation methods that are based on minimizing\nconvex objective functions. The first method minimizes the sum of squared\nresiduals with a nuclear (trace) norm regularization. The second method\nminimizes the nuclear norm of the residuals. We establish the consistency of\nthe two resulting estimators. Those estimators have a very important\ncomputational advantage compared to the existing least squares (LS) estimator,\nin that they are defined as minimizers of a convex objective function. In\naddition, the nuclear norm penalization helps to resolve a potential\nidentification problem for interactive fixed effect models, in particular when\nthe regressors are low-rank and the number of the factors is unknown. We also\nshow how to construct estimators that are asymptotically equivalent to the\nleast squares (LS) estimator in Bai (2009) and Moon and Weidner (2017) by using\nour nuclear norm regularized or minimized estimators as initial values for a\nfinite number of LS minimizing iteration steps. This iteration avoids any\nnon-convex minimization, while the original LS estimation problem is generally\nnon-convex, and can have multiple local minima.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 17:21:30 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 22:45:35 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Moon", "Hyungsik Roger", ""], ["Weidner", "Martin", ""]]}, {"id": "1810.10999", "submitter": "Matthew MacKay", "authors": "Matthew MacKay, Paul Vicol, Jimmy Ba, Roger Grosse", "title": "Reversible Recurrent Neural Networks", "comments": "Published as a conference paper at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) provide state-of-the-art performance in\nprocessing sequential data but are memory intensive to train, limiting the\nflexibility of RNN models which can be trained. Reversible RNNs---RNNs for\nwhich the hidden-to-hidden transition can be reversed---offer a path to reduce\nthe memory requirements of training, as hidden states need not be stored and\ninstead can be recomputed during backpropagation. We first show that perfectly\nreversible RNNs, which require no storage of the hidden activations, are\nfundamentally limited because they cannot forget information from their hidden\nstate. We then provide a scheme for storing a small number of bits in order to\nallow perfect reversal with forgetting. Our method achieves comparable\nperformance to traditional models while reducing the activation memory cost by\na factor of 10--15. We extend our technique to attention-based\nsequence-to-sequence models, where it maintains performance while reducing\nactivation memory cost by a factor of 5--10 in the encoder, and a factor of\n10--15 in the decoder.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 17:44:45 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["MacKay", "Matthew", ""], ["Vicol", "Paul", ""], ["Ba", "Jimmy", ""], ["Grosse", "Roger", ""]]}, {"id": "1810.11043", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Pieter Abbeel, Sergey Levine, Chelsea Finn", "title": "One-Shot Hierarchical Imitation Learning of Compound Visuomotor Tasks", "comments": "Video results available at https://sites.google.com/view/one-shot-hil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning multi-stage vision-based tasks on a real\nrobot from a single video of a human performing the task, while leveraging\ndemonstration data of subtasks with other objects. This problem presents a\nnumber of major challenges. Video demonstrations without teleoperation are easy\nfor humans to provide, but do not provide any direct supervision. Learning\npolicies from raw pixels enables full generality but calls for large function\napproximators with many parameters to be learned. Finally, compound tasks can\nrequire impractical amounts of demonstration data, when treated as a monolithic\nskill. To address these challenges, we propose a method that learns both how to\nlearn primitive behaviors from video demonstrations and how to dynamically\ncompose these behaviors to perform multi-stage tasks by \"watching\" a human\ndemonstrator. Our results on a simulated Sawyer robot and real PR2 robot\nillustrate our method for learning a variety of order fulfillment and kitchen\nserving tasks with novel objects and raw pixel inputs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:05:08 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Tianhe", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1810.11059", "submitter": "Ayush Sekhari", "authors": "Dylan J. Foster, Ayush Sekhari, Karthik Sridharan", "title": "Uniform Convergence of Gradients for Non-Convex Learning and\n  Optimization", "comments": "To appear in Neural Information Processing Systems (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate 1) the rate at which refined properties of the empirical\nrisk---in particular, gradients---converge to their population counterparts in\nstandard non-convex learning tasks, and 2) the consequences of this convergence\nfor optimization. Our analysis follows the tradition of norm-based capacity\ncontrol. We propose vector-valued Rademacher complexities as a simple,\ncomposable, and user-friendly tool to derive dimension-free uniform convergence\nbounds for gradients in non-convex learning problems. As an application of our\ntechniques, we give a new analysis of batch gradient descent methods for\nnon-convex generalized linear models and non-convex robust regression, showing\nhow to use any algorithm that finds approximate stationary points to obtain\noptimal sample complexity, even when dimension is high or possibly infinite and\nmultiple passes over the dataset are allowed.\n  Moving to non-smooth models we show----in contrast to the smooth case---that\neven for a single ReLU it is not possible to obtain dimension-independent\nconvergence rates for gradients in the worst case. On the positive side, it is\nstill possible to obtain dimension-independent rates under a new type of\ndistributional assumption.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:31:44 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 05:42:58 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Foster", "Dylan J.", ""], ["Sekhari", "Ayush", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1810.11066", "submitter": "Meghan Cowan", "authors": "Meghan Cowan, Thierry Moreau, Tianqi Chen, Luis Ceze", "title": "Automating Generation of Low Precision Deep Learning Operators", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art deep learning models have made steady progress in the fields\nof computer vision and natural language processing, at the expense of growing\nmodel sizes and computational complexity. Deploying these models on low power\nand mobile devices poses a challenge due to their limited compute capabilities\nand strict energy budgets. One solution that has generated significant research\ninterest is deploying highly quantized models that operate on low precision\ninputs and weights less than eight bits, trading off accuracy for performance.\nThese models have a significantly reduced memory footprint (up to 32x\nreduction) and can replace multiply-accumulates with bitwise operations during\ncompute intensive convolution and fully connected layers.\n  Most deep learning frameworks rely on highly engineered linear algebra\nlibraries such as ATLAS or Intel's MKL to implement efficient deep learning\noperators. To date, none of the popular deep learning directly support low\nprecision operators, partly due to a lack of optimized low precision libraries.\nIn this paper we introduce a work flow to quickly generate high performance low\nprecision deep learning operators for arbitrary precision that target multiple\nCPU architectures and include optimizations such as memory tiling and\nvectorization. We present an extensive case study on low power ARM Cortex-A53\nCPU, and show how we can generate 1-bit, 2-bit convolutions with speedups up to\n16x over an optimized 16-bit integer baseline and 2.3x better than handwritten\nimplementations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:52:48 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Cowan", "Meghan", ""], ["Moreau", "Thierry", ""], ["Chen", "Tianqi", ""], ["Ceze", "Luis", ""]]}, {"id": "1810.11071", "submitter": "Hamideh Hajiabadi", "authors": "Hamideh Hajiabadi, Reza Monsefi, Hadi Sadoghi Yazdi", "title": "RELF: Robust Regression Extended with Ensemble Loss Function", "comments": "18 Pages, 7 figures, Accepted in Applied Intelligence- Springer The\n  International Journal of Research on Intelligent Systems for Real Life\n  Complex Problems", "journal-ref": null, "doi": "10.1007/s10489-018-1341-9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble techniques are powerful approaches that combine several weak\nlearners to build a stronger one. As a meta-learning framework, ensemble\ntechniques can easily be applied to many machine learning methods. Inspired by\nensemble techniques, in this paper we propose an ensemble loss functions\napplied to a simple regressor. We then propose a half-quadratic learning\nalgorithm in order to find the parameter of the regressor and the optimal\nweights associated with each loss function. Moreover, we show that our proposed\nloss function is robust in noisy environments. For a particular class of loss\nfunctions, we show that our proposed ensemble loss function is Bayes consistent\nand robust. Experimental evaluations on several datasets demonstrate that our\nproposed ensemble loss function significantly improves the performance of a\nsimple regressor in comparison with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 19:05:16 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Hajiabadi", "Hamideh", ""], ["Monsefi", "Reza", ""], ["Yazdi", "Hadi Sadoghi", ""]]}, {"id": "1810.11098", "submitter": "Ming Yu", "authors": "Ming Yu, Zhuoran Yang, Tuo Zhao, Mladen Kolar, Zhaoran Wang", "title": "Provable Gaussian Embedding with One Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of machine learning methods heavily relies on having an\nappropriate representation for data at hand. Traditionally, machine learning\napproaches relied on user-defined heuristics to extract features encoding\nstructural information about data. However, recently there has been a surge in\napproaches that learn how to encode the data automatically in a low dimensional\nspace. Exponential family embedding provides a probabilistic framework for\nlearning low-dimensional representation for various types of high-dimensional\ndata. Though successful in practice, theoretical underpinnings for exponential\nfamily embeddings have not been established. In this paper, we study the\nGaussian embedding model and develop the first theoretical results for\nexponential family embedding models. First, we show that, under mild condition,\nthe embedding structure can be learned from one observation by leveraging the\nparameter sharing between different contexts even though the data are dependent\nwith each other. Second, we study properties of two algorithms used for\nlearning the embedding structure and establish convergence results for each of\nthem. The first algorithm is based on a convex relaxation, while the other\nsolved the non-convex formulation of the problem directly. Experiments\ndemonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 20:34:37 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Ming", ""], ["Yang", "Zhuoran", ""], ["Zhao", "Tuo", ""], ["Kolar", "Mladen", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1810.11155", "submitter": "Bayan Saparbayeva", "authors": "Bayan Saparbayeva, Michael Minyi Zhang, Lizhen Lin", "title": "Communication Efficient Parallel Algorithms for Optimization on\n  Manifolds", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed an explosion in the development of models,\ntheory and computational algorithms for \"big data\" analysis. In particular,\ndistributed computing has served as a natural and dominating paradigm for\nstatistical inference. However, the existing literature on parallel inference\nalmost exclusively focuses on Euclidean data and parameters. While this\nassumption is valid for many applications, it is increasingly more common to\nencounter problems where the data or the parameters lie on a non-Euclidean\nspace, like a manifold for example. Our work aims to fill a critical gap in the\nliterature by generalizing parallel inference algorithms to optimization on\nmanifolds. We show that our proposed algorithm is both communication efficient\nand carries theoretical convergence guarantees. In addition, we demonstrate the\nperformance of our algorithm to the estimation of Fr\\'echet means on simulated\nspherical data and the low-rank matrix completion problem over Grassmann\nmanifolds applied to the Netflix prize data set.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 01:05:40 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 04:18:34 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 16:45:30 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Saparbayeva", "Bayan", ""], ["Zhang", "Michael Minyi", ""], ["Lin", "Lizhen", ""]]}, {"id": "1810.11158", "submitter": "Bolton Bailey", "authors": "Bolton Bailey, Matus Telgarsky", "title": "Size-Noise Tradeoffs in Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the ability of generative networks to convert their\ninput noise distributions into other distributions. Firstly, we demonstrate a\nconstruction that allows ReLU networks to increase the dimensionality of their\nnoise distribution by implementing a \"space-filling\" function based on iterated\ntent maps. We show this construction is optimal by analyzing the number of\naffine pieces in functions computed by multivariate ReLU networks. Secondly, we\nprovide efficient ways (using polylog $(1/\\epsilon)$ nodes) for networks to\npass between univariate uniform and normal distributions, using a Taylor series\napproximation and a binary search gadget for computing function inverses.\nLastly, we indicate how high dimensional distributions can be efficiently\ntransformed into low dimensional distributions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 01:26:30 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Bailey", "Bolton", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1810.11165", "submitter": "Tharindu Adikari", "authors": "Tharindu Adikari, Stark C. Draper", "title": "Efficient learning of neighbor representations for boundary trees and\n  forests", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a semiparametric approach to neighbor-based classification. We\nbuild off the recently proposed Boundary Trees algorithm by Mathy et al.(2015)\nwhich enables fast neighbor-based classification, regression and retrieval in\nlarge datasets. While boundary trees use an Euclidean measure of similarity,\nthe Differentiable Boundary Tree algorithm by Zoran et al.(2017) was introduced\nto learn low-dimensional representations of complex input data, on which\nsemantic similarity can be calculated to train boundary trees. As is pointed\nout by its authors, the differentiable boundary tree approach contains a few\nlimitations that prevents it from scaling to large datasets. In this paper, we\nintroduce Differentiable Boundary Sets, an algorithm that overcomes the\ncomputational issues of the differentiable boundary tree scheme and also\nimproves its classification accuracy and data representability. Our algorithm\nis efficiently implementable with existing tools and offers a significant\nreduction in training time. We test and compare the algorithms on the well\nknown MNIST handwritten digits dataset and the newer Fashion-MNIST dataset by\nXiao et al.(2017).\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 02:01:30 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Adikari", "Tharindu", ""], ["Draper", "Stark C.", ""]]}, {"id": "1810.11177", "submitter": "Zi Wang", "authors": "Victoria Xia and Zi Wang and Leslie Pack Kaelbling", "title": "Learning sparse relational transition models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a representation for describing transition models in complex\nuncertain domains using relational rules. For any action, a rule selects a set\nof relevant objects and computes a distribution over properties of just those\nobjects in the resulting state given their properties in the previous state. An\niterative greedy algorithm is used to construct a set of deictic references\nthat determine which objects are relevant in any given state. Feed-forward\nneural networks are used to learn the transition distribution on the relevant\nobjects' properties. This strategy is demonstrated to be both more versatile\nand more sample efficient than learning a monolithic transition model in a\nsimulated domain in which a robot pushes stacks of objects on a cluttered\ntable.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:45:22 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Xia", "Victoria", ""], ["Wang", "Zi", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1810.11187", "submitter": "Abhishek Das", "authors": "Abhishek Das, Th\\'eophile Gervet, Joshua Romoff, Dhruv Batra, Devi\n  Parikh, Michael Rabbat, Joelle Pineau", "title": "TarMAC: Targeted Multi-Agent Communication", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a targeted communication architecture for multi-agent\nreinforcement learning, where agents learn both what messages to send and whom\nto address them to while performing cooperative tasks in partially-observable\nenvironments. This targeting behavior is learnt solely from downstream\ntask-specific reward without any communication supervision. We additionally\naugment this with a multi-round communication approach where agents coordinate\nvia multiple rounds of communication before taking actions in the environment.\nWe evaluate our approach on a diverse set of cooperative multi-agent tasks, of\nvarying difficulties, with varying number of agents, in a variety of\nenvironments ranging from 2D grid layouts of shapes and simulated traffic\njunctions to 3D indoor environments, and demonstrate the benefits of targeted\nand multi-round communication. Moreover, we show that the targeted\ncommunication strategies learned by agents are interpretable and intuitive.\nFinally, we show that our architecture can be easily extended to mixed and\ncompetitive environments, leading to improved performance and sample complexity\nover recent state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 04:22:58 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 04:37:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Das", "Abhishek", ""], ["Gervet", "Th\u00e9ophile", ""], ["Romoff", "Joshua", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Rabbat", "Michael", ""], ["Pineau", "Joelle", ""]]}, {"id": "1810.11197", "submitter": "Amichai Painsky", "authors": "Amichai Painsky and Saharon Rosset", "title": "Lossless (and Lossy) Compression of Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods are among the state-of-the-art predictive modeling\napproaches. Applied to modern big data, these methods often require a large\nnumber of sub-learners, where the complexity of each learner typically grows\nwith the size of the dataset. This phenomenon results in an increasing demand\nfor storage space, which may be very costly. This problem mostly manifests in a\nsubscriber based environment, where a user-specific ensemble needs to be stored\non a personal device with strict storage limitations (such as a cellular\ndevice). In this work we introduce a novel method for lossless compression of\ntree-based ensemble methods, focusing on random forests. Our suggested method\nis based on probabilistic modeling of the ensemble's trees, followed by model\nclustering via Bregman divergence. This allows us to find a minimal set of\nmodels that provides an accurate description of the trees, and at the same time\nis small enough to store and maintain. Our compression scheme demonstrates high\ncompression rates on a variety of modern datasets. Importantly, our scheme\nenables predictions from the compressed format and a perfect reconstruction of\nthe original ensemble. In addition, we introduce a theoretically sound lossy\ncompression scheme, which allows us to control the trade-off between the\ndistortion and the coding rate.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 06:08:05 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Painsky", "Amichai", ""], ["Rosset", "Saharon", ""]]}, {"id": "1810.11203", "submitter": "Asma Nouira", "authors": "Asma Nouira (ICMPE), Nataliya Sokolovska (Sorbonne Universit\\'e),\n  Jean-Claude Crivello (ICMPE)", "title": "CrystalGAN: Learning to Discover Crystallographic Structures with\n  Generative Adversarial Networks", "comments": null, "journal-ref": "AAAI Spring Symposium: Combining Machine Learning with Knowledge\n  Engineering 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main motivation is to propose an efficient approach to generate novel\nmulti-element stable chemical compounds that can be used in real world\napplications. This task can be formulated as a combinatorial problem, and it\ntakes many hours of human experts to construct, and to evaluate new data.\nUnsupervised learning methods such as Generative Adversarial Networks (GANs)\ncan be efficiently used to produce new data. Cross-domain Generative\nAdversarial Networks were reported to achieve exciting results in image\nprocessing applications. However, in the domain of materials science, there is\na need to synthesize data with higher order complexity compared to observed\nsamples, and the state-of-the-art cross-domain GANs can not be adapted\ndirectly. In this contribution, we propose a novel GAN called CrystalGAN which\ngenerates new chemically stable crystallographic structures with increased\ndomain complexity. We introduce an original architecture, we provide the\ncorresponding loss functions, and we show that the CrystalGAN generates very\nreasonable data. We illustrate the efficiency of the proposed method on a real\noriginal problem of novel hydrides discovery that can be further used in\ndevelopment of hydrogen storage materials.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 06:50:04 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 20:06:31 GMT"}, {"version": "v3", "created": "Sat, 25 May 2019 10:30:49 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Nouira", "Asma", "", "ICMPE"], ["Sokolovska", "Nataliya", "", "Sorbonne Universit\u00e9"], ["Crivello", "Jean-Claude", "", "ICMPE"]]}, {"id": "1810.11205", "submitter": "Max-Heinrich Laves", "authors": "Max-Heinrich Laves, L\\\"uder A. Kahrs, and Tobias Ortmaier", "title": "Deep learning based 2.5D flow field estimation for maximum intensity\n  projections of 4D optical coherence tomography", "comments": "Accepted for SPIE Medical Imaging 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In microsurgery, lasers have emerged as precise tools for bone ablation. A\nchallenge is automatic control of laser bone ablation with 4D optical coherence\ntomography (OCT). OCT as high resolution imaging modality provides volumetric\nimages of tissue and foresees information of bone position and orientation\n(pose) as well as thickness. However, existing approaches for OCT based laser\nablation control rely on external tracking systems or invasively ablated\nartificial landmarks for tracking the pose of the OCT probe relative to the\ntissue. This can be superseded by estimating the scene flow caused by relative\nmovement between OCT-based laser ablation system and patient.\n  Therefore, this paper deals with 2.5D scene flow estimation of volumetric OCT\nimages for application in laser ablation. We present a semi-supervised\nconvolutional neural network based tracking scheme for subsequent 3D OCT\nvolumes and apply it to a realistic semi-synthetic data set of ex vivo human\ntemporal bone specimen. The scene flow is estimated in a two-stage approach. In\nthe first stage, 2D lateral scene flow is computed on census-transformed\nen-face arguments-of-maximum intensity projections. Subsequent to this, the\nprojections are warped by predicted lateral flow and 1D depth flow is\nestimated. The neural network is trained semi-supervised by combining error to\nground truth and the reconstruction error of warped images with assumptions of\nspatial flow smoothness. Quantitative evaluation reveals a mean endpoint error\nof $ (4.7\\pm{}3.5) $ voxel or $ 27.5 \\pm 20.5 \\mu\\mathrm{m} $ for scene flow\nestimation caused by simulated relative movement between the OCT probe and\nbone. The scene flow estimation for 4D OCT enables its use for markerless\ntracking of mastoid bone structures for image guidance in general, and\nautomated laser ablation control.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 07:10:51 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 00:35:59 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Laves", "Max-Heinrich", ""], ["Kahrs", "L\u00fcder A.", ""], ["Ortmaier", "Tobias", ""]]}, {"id": "1810.11209", "submitter": "Mingyuan Zhou", "authors": "Dandan Guo, Bo Chen, Hao Zhang, Mingyuan Zhou", "title": "Deep Poisson gamma dynamical systems", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop deep Poisson-gamma dynamical systems (DPGDS) to model sequentially\nobserved multivariate count data, improving previously proposed models by not\nonly mining deep hierarchical latent structure from the data, but also\ncapturing both first-order and long-range temporal dependencies. Using\nsophisticated but simple-to-implement data augmentation techniques, we derived\nclosed-form Gibbs sampling update equations by first backward and upward\npropagating auxiliary latent counts, and then forward and downward sampling\nlatent variables. Moreover, we develop stochastic gradient MCMC inference that\nis scalable to very long multivariate count time series. Experiments on both\nsynthetic and a variety of real-world data demonstrate that the proposed model\nnot only has excellent predictive performance, but also provides highly\ninterpretable multilayer latent structure to represent hierarchical and\ntemporal information propagation.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 07:28:20 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 01:01:02 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Guo", "Dandan", ""], ["Chen", "Bo", ""], ["Zhang", "Hao", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1810.11227", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "From the EM Algorithm to the CM-EM Algorithm for Global Convergence of\n  Mixture Models", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm for mixture models often results\nin slow or invalid convergence. The popular convergence proof affirms that the\nlikelihood increases with Q; Q is increasing in the M -step and non-decreasing\nin the E-step. The author found that (1) Q may and should decrease in some\nE-steps; (2) The Shannon channel from the E-step is improper and hence the\nexpectation is improper. The author proposed the CM-EM algorithm (CM means\nChannel's Matching), which adds a step to optimize the mixture ratios for the\nproper Shannon channel and maximizes G, average log-normalized-likelihood, in\nthe M-step. Neal and Hinton's Maximization-Maximization (MM) algorithm use F\ninstead of Q to speed the convergence. Maximizing G is similar to maximizing F.\nThe new convergence proof is similar to Beal's proof with the variational\nmethod. It first proves that the minimum relative entropy equals the minimum\nR-G (R is mutual information), then uses variational and iterative methods that\nShannon et al. use for rate-distortion functions to prove the global\nconvergence. Some examples show that Q and F should and may decrease in some\nE-steps. For the same example, the EM, MM, and CM-EM algorithms need about 36,\n18, and 9 iterations respectively.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 08:44:50 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1810.11295", "submitter": "Bhaskar Das", "authors": "Bhaskar Das, Jalal Almhana", "title": "Real-time Context-aware Learning System for IoT Applications", "comments": "34 pages, 12 figures, Journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a real-time context-aware learning system along with the\narchitecture that runs on the mobile devices, provide services to the user and\nmanage the IoT devices. In this system, an application running on mobile\ndevices collected data from the sensors, learned about the user-defined\ncontext, made predictions in real-time and manage IoT devices accordingly.\nHowever, the computational power of the mobile devices makes it challenging to\nrun machine learning algorithms with acceptable accuracy. To solve this issue,\nsome authors have run machine learning algorithms on the server and transmitted\nthe results to the mobile devices. Although the context-aware predictions made\nby the server are more accurate than their mobile counterpart, it heavily\ndepends on the network connection for the delivery of the results to the\ndevices, which negatively affects real-time context-learning. Therefore, in\nthis work, we describe a context-learning algorithm for mobile devices which is\nless demanding on the computational resources and maintains the accuracy of the\nprediction by updating itself from the learning parameters obtained from the\nserver periodically. Experimental results show that the proposed light-weight\ncontext-learning algorithm can achieve mean accuracy up to 97.51% while mean\nexecution time requires only 11ms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 12:50:56 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Das", "Bhaskar", ""], ["Almhana", "Jalal", ""]]}, {"id": "1810.11317", "submitter": "Tanujit Chakraborty", "authors": "Tanujit Chakraborty and Ashis Kumar Chakraborty", "title": "Superensemble Classifier for Improving Predictions in Imbalanced\n  Datasets", "comments": "arXiv admin note: text overlap with arXiv:1805.12381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from an imbalanced dataset is a tricky proposition. Because these\ndatasets are biased towards one class, most existing classifiers tend not to\nperform well on minority class examples. Conventional classifiers usually aim\nto optimize the overall accuracy without considering the relative distribution\nof each class. This article presents a superensemble classifier, to tackle and\nimprove predictions in imbalanced classification problems, that maps Hellinger\ndistance decision trees (HDDT) into radial basis function network (RBFN)\nframework. Regularity conditions for universal consistency and the idea of\nparameter optimization of the proposed model are provided. The proposed\ndistribution-free model can be applied for feature selection cum imbalanced\nclassification problems. We have also provided enough numerical evidence using\nvarious real-life data sets to assess the performance of the proposed model.\nIts effectiveness and competitiveness with respect to different\nstate-of-the-art models are shown.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:02:24 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Chakraborty", "Tanujit", ""], ["Chakraborty", "Ashis Kumar", ""]]}, {"id": "1810.11333", "submitter": "Alessia Amelio Dr.", "authors": "Radmila Jankovi\\'c, Alessia Amelio", "title": "Comparing Multilayer Perceptron and Multiple Regression Models for\n  Predicting Energy Use in the Balkans", "comments": "In proceedings of 4th Virtual International Conference on Science,\n  Technology and Management in Energy (eNergetics 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global demographic and economic changes have a critical impact on the total\nenergy consumption, which is why demographic and economic parameters have to be\ntaken into account when making predictions about the energy consumption. This\nresearch is based on the application of a multiple linear regression model and\na neural network model, in particular multilayer perceptron, for predicting the\nenergy consumption. Data from five Balkan countries has been considered in the\nanalysis for the period 1995-2014. Gross domestic product, total number of\npopulation, and CO2 emission were taken as predictor variables, while the\nenergy consumption was used as the dependent variable. The analyses showed that\nCO2 emissions have the highest impact on the energy consumption, followed by\nthe gross domestic product, while the population number has the lowest impact.\nThe results from both analyses are then used for making predictions on the same\ndata, after which the obtained values were compared with the real values. It\nwas observed that the multilayer perceptron model predicts better the energy\nconsumption than the regression model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:02:28 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Jankovi\u0107", "Radmila", ""], ["Amelio", "Alessia", ""]]}, {"id": "1810.11335", "submitter": "Jirong Yi", "authors": "Jirong Yi, Anh Duc Le, Tianming Wang, Xiaodong Wu, Weiyu Xu", "title": "Outlier Detection using Generative Models with Theoretical Performance\n  Guarantees", "comments": "38 Pages, 15 Figures, 10 Lemmas or Theorems with Proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV eess.IV math.IT math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers the problem of recovering signals from compressed\nmeasurements contaminated with sparse outliers, which has arisen in many\napplications. In this paper, we propose a generative model neural network\napproach for reconstructing the ground truth signals under sparse outliers. We\npropose an iterative alternating direction method of multipliers (ADMM)\nalgorithm for solving the outlier detection problem via $\\ell_1$ norm\nminimization, and a gradient descent algorithm for solving the outlier\ndetection problem via squared $\\ell_1$ norm minimization. We establish the\nrecovery guarantees for reconstruction of signals using generative models in\nthe presence of outliers, and give an upper bound on the number of outliers\nallowed for recovery. Our results are applicable to both the linear generator\nneural network and the nonlinear generator neural network with an arbitrary\nnumber of layers. We conduct extensive experiments using variational\nauto-encoder and deep convolutional generative adversarial networks, and the\nexperimental results show that the signals can be successfully reconstructed\nunder outliers using our approach. Our approach outperforms the traditional\nLasso and $\\ell_2$ minimization approach.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:11:04 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yi", "Jirong", ""], ["Le", "Anh Duc", ""], ["Wang", "Tianming", ""], ["Wu", "Xiaodong", ""], ["Xu", "Weiyu", ""]]}, {"id": "1810.11344", "submitter": "Ji Xu", "authors": "Ji Xu and Daniel Hsu and Arian Maleki", "title": "Benefits of over-parameterization with EM", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation Maximization (EM) is among the most popular algorithms for\nmaximum likelihood estimation, but it is generally only guaranteed to find its\nstationary points of the log-likelihood objective. The goal of this article is\nto present theoretical and empirical evidence that over-parameterization can\nhelp EM avoid spurious local optima in the log-likelihood. We consider the\nproblem of estimating the mean vectors of a Gaussian mixture model in a\nscenario where the mixing weights are known. Our study shows that the global\nbehavior of EM, when one uses an over-parameterized model in which the mixing\nweights are treated as unknown, is better than that when one uses the (correct)\nmodel with the mixing weights fixed to the known values. For symmetric\nGaussians mixtures with two components, we prove that introducing the\n(statistically redundant) weight parameters enables EM to find the global\nmaximizer of the log-likelihood starting from almost any initial mean\nparameters, whereas EM without this over-parameterization may very often fail.\nFor other Gaussian mixtures, we provide empirical evidence that shows similar\nbehavior. Our results corroborate the value of over-parameterization in solving\nnon-convex optimization problems, previously observed in other domains.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:22:20 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Xu", "Ji", ""], ["Hsu", "Daniel", ""], ["Maleki", "Arian", ""]]}, {"id": "1810.11347", "submitter": "Niklas Wolf Andreas Gebauer", "authors": "Niklas W. A. Gebauer, Michael Gastegger, Kristof T. Sch\\\"utt", "title": "Generating equilibrium molecules with deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of atomistic systems with desirable properties is a major challenge\nin chemistry and material science. Here we introduce a novel, autoregressive,\nconvolutional deep neural network architecture that generates molecular\nequilibrium structures by sequentially placing atoms in three-dimensional\nspace. The model estimates the joint probability over molecular configurations\nwith tractable conditional probabilities which only depend on distances between\natoms and their nuclear charges. It combines concepts from state-of-the-art\natomistic neural networks with auto-regressive generative models for images and\nspeech. We demonstrate that the architecture is capable of generating molecules\nclose to equilibrium for constitutional isomers of C$_7$O$_2$H$_{10}$.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:34:33 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Gebauer", "Niklas W. A.", ""], ["Gastegger", "Michael", ""], ["Sch\u00fctt", "Kristof T.", ""]]}, {"id": "1810.11363", "submitter": "Anna Veronika Dorogush", "authors": "Anna Veronika Dorogush, Vasily Ershov, Andrey Gulin", "title": "CatBoost: gradient boosting with categorical features support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present CatBoost, a new open-sourced gradient boosting\nlibrary that successfully handles categorical features and outperforms existing\npublicly available implementations of gradient boosting in terms of quality on\na set of popular publicly available datasets. The library has a GPU\nimplementation of learning algorithm and a CPU implementation of scoring\nalgorithm, which are significantly faster than other gradient boosting\nlibraries on ensembles of similar sizes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 13:08:24 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Dorogush", "Anna Veronika", ""], ["Ershov", "Vasily", ""], ["Gulin", "Andrey", ""]]}, {"id": "1810.11367", "submitter": "Eytan Adar", "authors": "Xin Rong, Joshua Luckson, Eytan Adar", "title": "LAMVI-2: A Visual Tool for Comparing and Tuning Word Embedding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning machine learning models, particularly deep learning architectures, is\na complex process. Automated hyperparameter tuning algorithms often depend on\nspecific optimization metrics. However, in many situations, a developer trades\none metric against another: accuracy versus overfitting, precision versus\nrecall, smaller models and accuracy, etc. With deep learning, not only are the\nmodel's representations opaque, the model's behavior when parameters \"knobs\"\nare changed may also be unpredictable. Thus, picking the \"best\" model often\nrequires time-consuming model comparison. In this work, we introduce LAMVI-2, a\nvisual analytics system to support a developer in comparing hyperparameter\nsettings and outcomes. By focusing on word-embedding models (\"deep learning for\ntext\") we integrate views to compare both high-level statistics as well as\ninternal model behaviors (e.g., comparing word 'distances'). We demonstrate how\ndevelopers can work with LAMVI-2 to more quickly and accurately narrow down an\nappropriate and effective application-specific model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 20:05:42 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Rong", "Xin", ""], ["Luckson", "Joshua", ""], ["Adar", "Eytan", ""]]}, {"id": "1810.11378", "submitter": "Jaime Roquero Gimenez", "authors": "Jaime Roquero Gimenez, James Zou", "title": "Improving the Stability of the Knockoff Procedure: Multiple Simultaneous\n  Knockoffs and Entropy Maximization", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Model-X knockoff procedure has recently emerged as a powerful approach\nfor feature selection with statistical guarantees. The advantage of knockoff is\nthat if we have a good model of the features X, then we can identify salient\nfeatures without knowing anything about how the outcome Y depends on X. An\nimportant drawback of knockoffs is its instability: running the procedure twice\ncan result in very different selected features, potentially leading to\ndifferent conclusions. Addressing this instability is critical for obtaining\nreproducible and robust results. Here we present a generalization of the\nknockoff procedure that we call simultaneous multi-knockoffs. We show that\nmulti-knockoff guarantees false discovery rate (FDR) control, and is\nsubstantially more stable and powerful compared to the standard (single)\nknockoff. Moreover we propose a new algorithm based on entropy maximization for\ngenerating Gaussian multi-knockoffs. We validate the improved stability and\npower of multi-knockoffs in systematic experiments. We also illustrate how\nmulti-knockoffs can improve the accuracy of detecting genetic mutations that\nare causally linked to phenotypes.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 15:21:50 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 01:43:59 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Gimenez", "Jaime Roquero", ""], ["Zou", "James", ""]]}, {"id": "1810.11383", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic", "title": "Some Requests for Machine Learning Research from the East African Tech\n  Scene", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on 46 in-depth interviews with scientists, engineers, and CEOs, this\ndocument presents a list of concrete machine research problems, progress on\nwhich would directly benefit tech ventures in East Africa.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 02:53:14 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 01:03:50 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Cvitkovic", "Milan", ""]]}, {"id": "1810.11414", "submitter": "Durmus Sahin", "authors": "Durmus Ozkan Sahin, Oguz Emre Kural, Erdal Kilic, Armagan Karabina", "title": "A Text Classification Application: Poet Detection from Poetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of the internet, the size of the text data increases\nday by day. Poems can be given as an example of the growing text. In this\nstudy, we aim to classify poetry according to poet. Firstly, data set\nconsisting of three different poetry of poets written in English have been\nconstructed. Then, text categorization techniques are implemented on it.\nChi-Square technique are used for feature selection. In addition, five\ndifferent classification algorithms are tried. These algorithms are Sequential\nminimal optimization, Naive Bayes, C4.5 decision tree, Random Forest and\nk-nearest neighbors. Although each classifier showed very different results,\nover the 70% classification success rate was taken by sequential minimal\noptimization technique.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:44:57 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Sahin", "Durmus Ozkan", ""], ["Kural", "Oguz Emre", ""], ["Kilic", "Erdal", ""], ["Karabina", "Armagan", ""]]}, {"id": "1810.11428", "submitter": "Matthias Bauer", "authors": "Matthias Bauer and Andriy Mnih", "title": "Resampled Priors for Variational Autoencoders", "comments": null, "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Learned Accept/Reject Sampling (LARS), a method for constructing\nricher priors using rejection sampling with a learned acceptance function. This\nwork is motivated by recent analyses of the VAE objective, which pointed out\nthat commonly used simple priors can lead to underfitting. As the distribution\ninduced by LARS involves an intractable normalizing constant, we show how to\nestimate it and its gradients efficiently. We demonstrate that LARS priors\nimprove VAE performance on several standard datasets both when they are learned\njointly with the rest of the model and when they are fitted to a pretrained\nmodel. Finally, we show that LARS can be combined with existing methods for\ndefining flexible priors for an additional boost in performance.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 17:17:48 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 09:35:33 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Bauer", "Matthias", ""], ["Mnih", "Andriy", ""]]}, {"id": "1810.11447", "submitter": "Karren Yang", "authors": "Karren D. Yang and Caroline Uhler", "title": "Scalable Unbalanced Optimal Transport using Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are an expressive class of neural\ngenerative models with tremendous success in modeling high-dimensional\ncontinuous measures. In this paper, we present a scalable method for unbalanced\noptimal transport (OT) based on the generative-adversarial framework. We\nformulate unbalanced OT as a problem of simultaneously learning a transport map\nand a scaling factor that push a source measure to a target measure in a\ncost-optimal manner. In addition, we propose an algorithm for solving this\nproblem based on stochastic alternating gradient updates, similar in practice\nto GANs. We also provide theoretical justification for this formulation,\nshowing that it is closely related to an existing static formulation by Liero\net al. (2018), and perform numerical experiments demonstrating how this\nmethodology can be applied to population modeling.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 17:53:08 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 00:26:49 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Yang", "Karren D.", ""], ["Uhler", "Caroline", ""]]}, {"id": "1810.11479", "submitter": "Changjian Shui", "authors": "Changjian Shui, Ihsen Hedhli, Christian Gagn\\'e", "title": "Accumulating Knowledge for Lifelong Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lifelong learning can be viewed as a continuous transfer learning procedure\nover consecutive tasks, where learning a given task depends on accumulated\nknowledge --- the so-called knowledge base. Most published work on lifelong\nlearning makes a batch processing of each task, implying that a data collection\nstep is required beforehand. We are proposing a new framework, lifelong online\nlearning, in which the learning procedure for each task is interactive. This is\ndone through a computationally efficient algorithm where the predicted result\nfor a given task is made by combining two intermediate predictions: by using\nonly the information from the current task and by relying on the accumulated\nknowledge. In this work, two challenges are tackled: making no assumption on\nthe task generation distribution, and processing with a possibly unknown number\nof instances for each task. We are providing a theoretical analysis of this\nalgorithm, with a cumulative error upper bound for each task. We find that\nunder some mild conditions, the algorithm can still benefit from a small\ncumulative error even when facing few interactions. Moreover, we provide\nexperimental results on both synthetic and real datasets that validate the\ncorrect behavior and practical usefulness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:18:36 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Shui", "Changjian", ""], ["Hedhli", "Ihsen", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1810.11491", "submitter": "Alexander Fabisch", "authors": "Alexander Fabisch", "title": "Empirical Evaluation of Contextual Policy Search with a Comparison-based\n  Surrogate Model and Active Covariance Matrix Adaptation", "comments": "Supplementary material for poster paper accepted at GECCO 2019;\n  https://doi.org/10.1145/3319619.3321935", "journal-ref": null, "doi": "10.1145/3319619.3321935", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual policy search (CPS) is a class of multi-task reinforcement\nlearning algorithms that is particularly useful for robotic applications. A\nrecent state-of-the-art method is Contextual Covariance Matrix Adaptation\nEvolution Strategies (C-CMA-ES). It is based on the standard black-box\noptimization algorithm CMA-ES. There are two useful extensions of CMA-ES that\nwe will transfer to C-CMA-ES and evaluate empirically: ACM-ES, which uses a\ncomparison-based surrogate model, and aCMA-ES, which uses an active update of\nthe covariance matrix. We will show that improvements with these methods can be\nimpressive in terms of sample-efficiency, although this is not relevant any\nmore for the robotic domain.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:35:27 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 21:20:16 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Fabisch", "Alexander", ""]]}, {"id": "1810.11497", "submitter": "Sanchit Agarwal", "authors": "Sanchit Agarwal, Rahul Goel, Tagyoung Chung, Abhishek Sethi, Arindam\n  Mandal, Spyros Matsoukas", "title": "Parsing Coordination for Spoken Language Understanding", "comments": "The paper was published in SLT 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical spoken language understanding systems provide narrow semantic parses\nusing a domain-specific ontology. The parses contain intents and slots that are\ndirectly consumed by downstream domain applications. In this work we discuss\nexpanding such systems to handle compound entities and intents by introducing a\ndomain-agnostic shallow parser that handles linguistic coordination. We show\nthat our model for parsing coordination learns domain-independent and\nslot-independent features and is able to segment conjunct boundaries of many\ndifferent phrasal categories. We also show that using adversarial training can\nbe effective for improving generalization across different slot types for\ncoordination parsing.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:44:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Agarwal", "Sanchit", ""], ["Goel", "Rahul", ""], ["Chung", "Tagyoung", ""], ["Sethi", "Abhishek", ""], ["Mandal", "Arindam", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1810.11507", "submitter": "Majid Jahani", "authors": "Majid Jahani, Xi He, Chenxin Ma, Aryan Mokhtari, Dheevatsa Mudigere,\n  Alejandro Ribeiro, and Martin Tak\\'a\\v{c}", "title": "Efficient Distributed Hessian Free Algorithm for Large-scale Empirical\n  Risk Minimization via Accumulating Sample Strategy", "comments": "Updated numerical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Distributed Accumulated Newton Conjugate gradiEnt\n(DANCE) method in which sample size is gradually increasing to quickly obtain a\nsolution whose empirical loss is under satisfactory statistical accuracy. Our\nproposed method is multistage in which the solution of a stage serves as a warm\nstart for the next stage which contains more samples (including the samples in\nthe previous stage). The proposed multistage algorithm reduces the number of\npasses over data to achieve the statistical accuracy of the full training set.\nMoreover, our algorithm in nature is easy to be distributed and shares the\nstrong scaling property indicating that acceleration is always expected by\nusing more computing nodes. Various iteration complexity results regarding\ndescent direction computation, communication efficiency and stopping criteria\nare analyzed under convex setting. Our numerical results illustrate that the\nproposed method outperforms other comparable methods for solving learning\nproblems including neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 19:06:36 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 02:41:37 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Jahani", "Majid", ""], ["He", "Xi", ""], ["Ma", "Chenxin", ""], ["Mokhtari", "Aryan", ""], ["Mudigere", "Dheevatsa", ""], ["Ribeiro", "Alejandro", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1810.11509", "submitter": "Matthew Klimek", "authors": "Matthew D. Klimek, Maxim Perelstein", "title": "Neural Network-Based Approach to Phase Space Integration", "comments": "13+2 pages, 9 figures. v2: Improved discussion, one new figure. No\n  changes to physics results or conclusions. v3: Minor clarifications and\n  improvements to figures, plus one new figure. No changes to results or\n  conclusions. Now 18 pages, 11 figures", "journal-ref": "SciPost Phys. 9, 053 (2020)", "doi": "10.21468/SciPostPhys.9.4.053", "report-no": null, "categories": "hep-ph hep-ex physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo methods are widely used in particle physics to integrate and\nsample probability distributions (differential cross sections or decay rates)\non multi-dimensional phase spaces. We present a Neural Network (NN) algorithm\noptimized to perform this task. The algorithm has been applied to several\nexamples of direct relevance for particle physics, including situations with\nnon-trivial features such as sharp resonances and soft/collinear enhancements.\nExcellent performance has been demonstrated in all examples, with the properly\ntrained NN achieving unweighting efficiencies of between 30% and 75%. In\ncontrast to traditional Monte Carlo algorithms such as VEGAS, the NN-based\napproach does not require that the phase space coordinates be aligned with\nresonant or other features in the cross section.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 19:13:33 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 06:36:32 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 07:03:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Klimek", "Matthew D.", ""], ["Perelstein", "Maxim", ""]]}, {"id": "1810.11514", "submitter": "Alessandro Tibo", "authors": "Alessandro Tibo, Manfred Jaeger, Paolo Frasconi", "title": "Learning and Interpreting Multi-Multi-Instance Learning Networks", "comments": "JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension of the multi-instance learning problem where\nexamples are organized as nested bags of instances (e.g., a document could be\nrepresented as a bag of sentences, which in turn are bags of words). This\nframework can be useful in various scenarios, such as text and image\nclassification, but also supervised learning over graphs. As a further\nadvantage, multi-multi instance learning enables a particular way of\ninterpreting predictions and the decision function. Our approach is based on a\nspecial neural network layer, called bag-layer, whose units aggregate bags of\ninputs of arbitrary size. We prove theoretically that the associated class of\nfunctions contains all Boolean functions over sets of sets of instances and we\nprovide empirical evidence that functions of this kind can be actually learned\non semi-synthetic datasets. We finally present experiments on text\nclassification, on citation graphs, and social graph data, which show that our\nmodel obtains competitive results with respect to accuracy when compared to\nother approaches such as convolutional networks on graphs, while at the same\ntime it supports a general approach to interpret the learnt model, as well as\nexplain individual predictions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 19:46:12 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 17:11:46 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 13:40:14 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 14:48:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Tibo", "Alessandro", ""], ["Jaeger", "Manfred", ""], ["Frasconi", "Paolo", ""]]}, {"id": "1810.11520", "submitter": "Jaehoon Oh", "authors": "Jaehoon Oh, Duyeon Kim, and Se-Young Yun", "title": "Spectrogram-channels u-net: a source separation model viewing each\n  channel as the spectrogram of each source", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound source separation has attracted attention from Music Information\nRetrieval(MIR) researchers, since it is related to many MIR tasks such as\nautomatic lyric transcription, singer identification, and voice conversion. In\nthis paper, we propose an intuitive spectrogram-based model for source\nseparation by adapting U-Net. We call it Spectrogram-Channels U-Net, which\nmeans each channel of the output corresponds to the spectrogram of separated\nsource itself. The proposed model can be used for not only singing voice\nseparation but also multi-instrument separation by changing only the number of\noutput channels. In addition, we propose a loss function that balances volumes\nbetween different sources. Finally, we yield performance that is\nstate-of-the-art on both separation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 20:23:17 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 15:08:52 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Oh", "Jaehoon", ""], ["Kim", "Duyeon", ""], ["Yun", "Se-Young", ""]]}, {"id": "1810.11530", "submitter": "Pascal Lamblin", "authors": "Bart van Merri\\\"enboer, Olivier Breuleux, Arnaud Bergeron, Pascal\n  Lamblin", "title": "Automatic differentiation in ML: Where we are and where we should be\n  going", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the current state of automatic differentiation (AD) for array\nprogramming in machine learning (ML), including the different approaches such\nas operator overloading (OO) and source transformation (ST) used for AD,\ngraph-based intermediate representations for programs, and source languages.\nBased on these insights, we introduce a new graph-based intermediate\nrepresentation (IR) which specifically aims to efficiently support\nfully-general AD for array programming. Unlike existing dataflow programming\nrepresentations in ML frameworks, our IR naturally supports function calls,\nhigher-order functions and recursion, making ML models easier to implement. The\nability to represent closures allows us to perform AD using ST without a tape,\nmaking the resulting derivative (adjoint) program amenable to ahead-of-time\noptimization using tools from functional language compilers, and enabling\nhigher-order derivatives. Lastly, we introduce a proof of concept compiler\ntoolchain called Myia which uses a subset of Python as a front end.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 21:09:07 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 21:16:54 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["van Merri\u00ebnboer", "Bart", ""], ["Breuleux", "Olivier", ""], ["Bergeron", "Arnaud", ""], ["Lamblin", "Pascal", ""]]}, {"id": "1810.11536", "submitter": "Zhihao Zhu", "authors": "Zhihao Zhu, Zhan Xue, Zejian Yuan", "title": "Automatic Graphics Program Generation using Attention-Based Hierarchical\n  Decoder", "comments": "Asian Conference on Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress on deep learning has made it possible to automatically\ntransform the screenshot of Graphic User Interface (GUI) into code by using the\nencoder-decoder framework. While the commonly adopted image encoder (e.g., CNN\nnetwork), might be capable of extracting image features to the desired level,\ninterpreting these abstract image features into hundreds of tokens of code puts\na particular challenge on the decoding power of the RNN-based code generator.\nConsidering the code used for describing GUI is usually hierarchically\nstructured, we propose a new attention-based hierarchical code generation\nmodel, which can describe GUI images in a finer level of details, while also\nbeing able to generate hierarchically structured code in consistency with the\nhierarchical layout of the graphic elements in the GUI. Our model follows the\nencoder-decoder framework, all the components of which can be trained jointly\nin an end-to-end manner. The experimental results show that our method\noutperforms other current state-of-the-art methods on both a publicly available\nGUI-code dataset as well as a dataset established by our own.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 21:28:10 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhu", "Zhihao", ""], ["Xue", "Zhan", ""], ["Yuan", "Zejian", ""]]}, {"id": "1810.11544", "submitter": "Anton Osokin", "authors": "Kirill Struminsky, Simon Lacoste-Julien, Anton Osokin", "title": "Quantifying Learning Guarantees for Convex but Inconsistent Surrogates", "comments": "Appears in: Advances in Neural Information Processing Systems 31\n  (NeurIPS 2018). 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study consistency properties of machine learning methods based on\nminimizing convex surrogates. We extend the recent framework of Osokin et al.\n(2017) for the quantitative analysis of consistency properties to the case of\ninconsistent surrogates. Our key technical contribution consists in a new lower\nbound on the calibration function for the quadratic surrogate, which is\nnon-trivial (not always zero) for inconsistent cases. The new bound allows to\nquantify the level of inconsistency of the setting and shows how learning with\ninconsistent surrogates can have guarantees on sample complexity and\noptimization difficulty. We apply our theory to two concrete cases: multi-class\nclassification with the tree-structured loss and ranking with the mean average\nprecision loss. The results show the approximation-computation trade-offs\ncaused by inconsistent surrogates and their potential benefits.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 22:10:48 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 08:47:58 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Struminsky", "Kirill", ""], ["Lacoste-Julien", "Simon", ""], ["Osokin", "Anton", ""]]}, {"id": "1810.11546", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Richard G. Clegg, Andrea Cavallaro, Hamed Haddadi", "title": "Mobile Sensor Data Anonymization", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/3302505.3310068", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion sensors such as accelerometers and gyroscopes measure the instant\nacceleration and rotation of a device, in three dimensions. Raw data streams\nfrom motion sensors embedded in portable and wearable devices may reveal\nprivate information about users without their awareness. For example, motion\ndata might disclose the weight or gender of a user, or enable their\nre-identification. To address this problem, we propose an on-device\ntransformation of sensor data to be shared for specific applications, such as\nmonitoring selected daily activities, without revealing information that\nenables user identification. We formulate the anonymization problem using an\ninformation-theoretic approach and propose a new multi-objective loss function\nfor training deep autoencoders. This loss function helps minimizing\nuser-identity information as well as data distortion to preserve the\napplication-specific utility. The training process regulates the encoder to\ndisregard user-identifiable patterns and tunes the decoder to shape the output\nindependently of users in the training set. The trained autoencoder can be\ndeployed on a mobile or wearable device to anonymize sensor data even for users\nwho are not included in the training dataset. Data from 24 users transformed by\nthe proposed anonymizing autoencoder lead to a promising trade-off between\nutility and privacy, with an accuracy for activity recognition above 92% and an\naccuracy for user identification below 7%.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 22:26:31 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 16:08:44 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 23:58:38 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Clegg", "Richard G.", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1810.11558", "submitter": "Humberto Gonzalez", "authors": "Qingzhu Gao, Humberto Gonzalez, and Parvez Ahammad", "title": "MCA-based Rule Mining Enables Interpretable Inference in Clinical\n  Psychiatry", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-24409-5_3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of interpretable machine learning models for clinical healthcare\napplications has the potential of changing the way we understand, treat, and\nultimately cure, diseases and disorders in many areas of medicine. These models\ncan serve not only as sources of predictions and estimates, but also as\ndiscovery tools for clinicians and researchers to reveal new knowledge from the\ndata. High dimensionality of patient information (e.g., phenotype, genotype,\nand medical history), lack of objective measurements, and the heterogeneity in\npatient populations often create significant challenges in developing\ninterpretable machine learning models for clinical psychiatry in practice. In\nthis paper we take a step towards the development of such interpretable models.\nFirst, by developing a novel categorical rule mining method based on\nMultivariate Correspondence Analysis (MCA) capable of handling datasets with\nlarge numbers of features, and second, by applying this method to build\ntransdiagnostic Bayesian Rule List models to screen for psychiatric disorders\nusing the Consortium for Neuropsychiatric Phenomics dataset. We show that our\nmethod is not only at least 100 times faster than state-of-the-art rule mining\ntechniques for datasets with 50 features, but also provides interpretability\nand comparable prediction accuracy across several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 23:51:08 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 22:44:07 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Gao", "Qingzhu", ""], ["Gonzalez", "Humberto", ""], ["Ahammad", "Parvez", ""]]}, {"id": "1810.11562", "submitter": "Henry Kvinge", "authors": "Henry Kvinge, Elin Farnell, Michael Kirby, Chris Peterson", "title": "Monitoring the shape of weather, soundscapes, and dynamical systems: a\n  new statistic for dimension-driven data analysis on large data sets", "comments": "Accepted to the 2018 IEEE International Conference on BIG DATA, 9\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality-reduction methods are a fundamental tool in the analysis of\nlarge data sets. These algorithms work on the assumption that the \"intrinsic\ndimension\" of the data is generally much smaller than the ambient dimension in\nwhich it is collected. Alongside their usual purpose of mapping data into a\nsmaller dimension with minimal information loss, dimensionality-reduction\ntechniques implicitly or explicitly provide information about the dimension of\nthe data set.\n  In this paper, we propose a new statistic that we call the $\\kappa$-profile\nfor analysis of large data sets. The $\\kappa$-profile arises from a\ndimensionality-reduction optimization problem: namely that of finding a\nprojection into $k$-dimensions that optimally preserves the secants between\npoints in the data set. From this optimal projection we extract $\\kappa,$ the\nnorm of the shortest projected secant from among the set of all normalized\nsecants. This $\\kappa$ can be computed for any $k$; thus the tuple of $\\kappa$\nvalues (indexed by dimension) becomes a $\\kappa$-profile. Algorithms such as\nthe Secant-Avoidance Projection algorithm and the Hierarchical Secant-Avoidance\nProjection algorithm, provide a computationally feasible means of estimating\nthe $\\kappa$-profile for large data sets, and thus a method of understanding\nand monitoring their behavior. As we demonstrate in this paper, the\n$\\kappa$-profile serves as a useful statistic in several representative\nsettings: weather data, soundscape data, and dynamical systems data.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 00:15:34 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kvinge", "Henry", ""], ["Farnell", "Elin", ""], ["Kirby", "Michael", ""], ["Peterson", "Chris", ""]]}, {"id": "1810.11571", "submitter": "Puning Zhao", "authors": "Puning Zhao and Lifeng Lai", "title": "Analysis of KNN Information Estimators for Smooth Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KSG mutual information estimator, which is based on the distances of each\nsample to its k-th nearest neighbor, is widely used to estimate mutual\ninformation between two continuous random variables. Existing work has analyzed\nthe convergence rate of this estimator for random variables whose densities are\nbounded away from zero in its support. In practice, however, KSG estimator also\nperforms well for a much broader class of distributions, including not only\nthose with bounded support and densities bounded away from zero, but also those\nwith bounded support but densities approaching zero, and those with unbounded\nsupport. In this paper, we analyze the convergence rate of the error of KSG\nestimator for smooth distributions, whose support of density can be both\nbounded and unbounded. As KSG mutual information estimator can be viewed as an\nadaptive recombination of KL entropy estimators, in our analysis, we also\nprovide convergence analysis of KL entropy estimator for a broad class of\ndistributions.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 00:56:28 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 06:55:13 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 22:28:40 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zhao", "Puning", ""], ["Lai", "Lifeng", ""]]}, {"id": "1810.11573", "submitter": "Fuad Noman", "authors": "Fuad Noman, Chee-Ming Ting, Sh-Hussain Salleh, and Hernando Ombao", "title": "Short-segment heart sound classification using an ensemble of deep\n  convolutional neural networks", "comments": "8 pages, 1 figure, conference", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682668", "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework based on deep convolutional neural networks\n(CNNs) for automatic heart sound classification using short-segments of\nindividual heart beats. We design a 1D-CNN that directly learns features from\nraw heart-sound signals, and a 2D-CNN that takes inputs of two- dimensional\ntime-frequency feature maps based on Mel-frequency cepstral coefficients\n(MFCC). We further develop a time-frequency CNN ensemble (TF-ECNN) combining\nthe 1D-CNN and 2D-CNN based on score-level fusion of the class probabilities.\nOn the large PhysioNet CinC challenge 2016 database, the proposed CNN models\noutperformed traditional classifiers based on support vector machine and hidden\nMarkov models with various hand-crafted time- and frequency-domain features.\nBest classification scores with 89.22% accuracy and 89.94% sensitivity were\nachieved by the ECNN, and 91.55% specificity and 88.82% modified accuracy by\nthe 2D-CNN alone on the test set.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 01:32:27 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Noman", "Fuad", ""], ["Ting", "Chee-Ming", ""], ["Salleh", "Sh-Hussain", ""], ["Ombao", "Hernando", ""]]}, {"id": "1810.11580", "submitter": "Guanhong Tao", "authors": "Guanhong Tao, Shiqing Ma, Yingqi Liu, Xiangyu Zhang", "title": "Attacks Meet Interpretability: Attribute-steered Detection of\n  Adversarial Samples", "comments": "Accepted to NIPS 2018 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors.\nRecent research has demonstrated the widespread presence and the devastating\nconsequences of such attacks. Existing defense techniques either assume prior\nknowledge of specific attacks or may not work well on complex models due to\ntheir underlying assumptions. We argue that adversarial sample attacks are\ndeeply entangled with interpretability of DNN models: while classification\nresults on benign inputs can be reasoned based on the human perceptible\nfeatures/attributes, results on adversarial samples can hardly be explained.\nTherefore, we propose a novel adversarial sample detection technique for face\nrecognition models, based on interpretability. It features a novel\nbi-directional correspondence inference between attributes and internal neurons\nto identify neurons critical for individual attributes. The activation values\nof critical neurons are enhanced to amplify the reasoning part of the\ncomputation and the values of other neurons are weakened to suppress the\nuninterpretable part. The classification results after such transformation are\ncompared with those of the original model to detect adversaries. Results show\nthat our technique can achieve 94% detection accuracy for 7 different kinds of\nattacks with 9.91% false positives on benign inputs. In contrast, a\nstate-of-the-art feature squeezing technique can only achieve 55% accuracy with\n23.3% false positives.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:32:32 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tao", "Guanhong", ""], ["Ma", "Shiqing", ""], ["Liu", "Yingqi", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "1810.11581", "submitter": "Kar-Ann Toh", "authors": "Kar-Ann Toh, Zhiping Lin, Zhengguo Li, Beomseok Oh and Lei Sun", "title": "Gradient-Free Learning Based on the Kernel and the Range Space", "comments": "The idea of kernel and range projection was first introduced in the\n  IEEE/ACIS ICIS conference which was held in Singapore in June 2018. This\n  article presents a full development of the method supported by extensive\n  numerical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we show that solving the system of linear equations by\nmanipulating the kernel and the range space is equivalent to solving the\nproblem of least squares error approximation. This establishes the ground for a\ngradient-free learning search when the system can be expressed in the form of a\nlinear matrix equation. When the nonlinear activation function is invertible,\nthe learning problem of a fully-connected multilayer feedforward neural network\ncan be easily adapted for this novel learning framework. By a series of kernel\nand range space manipulations, it turns out that such a network learning boils\ndown to solving a set of cross-coupling equations. By having the weights\nrandomly initialized, the equations can be decoupled and the network solution\nshows relatively good learning capability for real world data sets of small to\nmoderate dimensions. Based on the structural information of the matrix\nequation, the network representation is found to be dependent on the number of\ndata samples and the output dimension.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:49:37 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Toh", "Kar-Ann", ""], ["Lin", "Zhiping", ""], ["Li", "Zhengguo", ""], ["Oh", "Beomseok", ""], ["Sun", "Lei", ""]]}, {"id": "1810.11583", "submitter": "Matthew Riemer", "authors": "Matthew Riemer, Miao Liu, Gerald Tesauro", "title": "Learning Abstract Options", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building systems that autonomously create temporal abstractions from data is\na key challenge in scaling learning and planning in reinforcement learning. One\npopular approach for addressing this challenge is the options framework (Sutton\net al., 1999). However, only recently in (Bacon et al., 2017) was a policy\ngradient theorem derived for online learning of general purpose options in an\nend to end fashion. In this work, we extend previous work on this topic that\nonly focuses on learning a two-level hierarchy including options and primitive\nactions to enable learning simultaneously at multiple resolutions in time. We\nachieve this by considering an arbitrarily deep hierarchy of options where high\nlevel temporally extended options are composed of lower level options with\nfiner resolutions in time. We extend results from (Bacon et al., 2017) and\nderive policy gradient theorems for a deep hierarchy of options. Our proposed\nhierarchical option-critic architecture is capable of learning internal\npolicies, termination conditions, and hierarchical compositions over options\nwithout the need for any intrinsic rewards or subgoals. Our empirical results\nin both discrete and continuous environments demonstrate the efficiency of our\nframework.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:54:59 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 17:43:42 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 23:36:25 GMT"}, {"version": "v4", "created": "Tue, 31 Dec 2019 17:25:40 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Riemer", "Matthew", ""], ["Liu", "Miao", ""], ["Tesauro", "Gerald", ""]]}, {"id": "1810.11586", "submitter": "Azadeh Mozafari", "authors": "Azadeh Sadat Mozafari, Hugo Siqueira Gomes, Wilson Le\\~ao, Steeven\n  Janny, Christian Gagn\\'e", "title": "Attended Temperature Scaling: A Practical Approach for Calibrating Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Deep Neural Networks (DNNs) have been achieving impressive results\non wide range of tasks. However, they suffer from being well-calibrated. In\ndecision-making applications, such as autonomous driving or medical diagnosing,\nthe confidence of deep networks plays an important role to bring the trust and\nreliability to the system. To calibrate the deep networks' confidence, many\nprobabilistic and measure-based approaches are proposed. Temperature Scaling\n(TS) is a state-of-the-art among measure-based calibration methods which has\nlow time and memory complexity as well as effectiveness. In this paper, we\nstudy TS and show it does not work properly when the validation set that TS\nuses for calibration has small size or contains noisy-labeled samples. TS also\ncannot calibrate highly accurate networks as well as non-highly accurate ones.\nAccordingly, we propose Attended Temperature Scaling (ATS) which preserves the\nadvantages of TS while improves calibration in aforementioned challenging\nsituations. We provide theoretical justifications for ATS and assess its\neffectiveness on wide range of deep models and datasets. We also compare the\ncalibration results of TS and ATS on skin lesion detection application as a\npractical problem where well-calibrated system can play important role in\nmaking a decision.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 03:03:57 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 01:22:46 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 18:51:05 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mozafari", "Azadeh Sadat", ""], ["Gomes", "Hugo Siqueira", ""], ["Le\u00e3o", "Wilson", ""], ["Janny", "Steeven", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1810.11596", "submitter": "Zhen Li", "authors": "Zhiping Mao, Zhen Li, George Em Karniadakis", "title": "Nonlocal flocking dynamics: Learning the fractional order of PDEs from\n  particle simulations", "comments": "22 pages, 7 figures", "journal-ref": "Commun. Appl. Math. Comput. 2019, 1: 597-619", "doi": "10.1007/s42967-019-00031-y", "report-no": null, "categories": "math.NA physics.bio-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flocking refers to collective behavior of a large number of interacting\nentities, where the interactions between discrete individuals produce\ncollective motion on the large scale. We employ an agent-based model to\ndescribe the microscopic dynamics of each individual in a flock, and use a\nfractional PDE to model the evolution of macroscopic quantities of interest.\nThe macroscopic models with phenomenological interaction functions are derived\nby applying the continuum hypothesis to the microscopic model. Instead of\nspecifying the fPDEs with an ad hoc fractional order for nonlocal flocking\ndynamics, we learn the effective nonlocal influence function in fPDEs directly\nfrom particle trajectories generated by the agent-based simulations. We\ndemonstrate how the learning framework is used to connect the discrete\nagent-based model to the continuum fPDEs in 1D and 2D nonlocal flocking\ndynamics. In particular, a Cucker-Smale particle model is employed to describe\nthe microscale dynamics of each individual, while Euler equations with nonlocal\ninteraction terms are used to compute the evolution of macroscale quantities.\nThe trajectories generated by the particle simulations mimic the field data of\ntracking logs that can be obtained experimentally. They can be used to learn\nthe fractional order of the influence function using a Gaussian process\nregression model implemented with the Bayesian optimization. We show that the\nnumerical solution of the learned Euler equations solved by the finite volume\nscheme can yield correct density distributions consistent with the collective\nbehavior of the agent-based system. The proposed method offers new insights on\nhow to scale the discrete agent-based models to the continuum-based PDE models,\nand could serve as a paradigm on extracting effective governing equations for\nnonlocal flocking dynamics directly from particle trajectories.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 04:45:30 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 13:44:19 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mao", "Zhiping", ""], ["Li", "Zhen", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1810.11598", "submitter": "Ting Chen", "authors": "Ting Chen and Xiaohua Zhai and Neil Houlsby", "title": "Self-Supervised GAN to Counter Forgetting", "comments": "NeurIPS'18 Continual Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANs involve training two networks in an adversarial game, where each\nnetwork's task depends on its adversary. Recently, several works have framed\nGAN training as an online or continual learning problem. We focus on the\ndiscriminator, which must perform classification under an (adversarially)\nshifting data distribution. When trained on sequential tasks, neural networks\nexhibit \\emph{forgetting}. For GANs, discriminator forgetting leads to training\ninstability. To counter forgetting, we encourage the discriminator to maintain\nuseful representations by adding a self-supervision. Conditional GANs have a\nsimilar effect using labels. However, our self-supervised GAN does not require\nlabels, and closes the performance gap between conditional and unconditional\nmodels. We show that, in doing so, the self-supervised discriminator learns\nbetter representations than regular GANs.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 04:49:25 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 23:00:39 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Chen", "Ting", ""], ["Zhai", "Xiaohua", ""], ["Houlsby", "Neil", ""]]}, {"id": "1810.11624", "submitter": "David Guijo-Rubio", "authors": "David Guijo-Rubio, Antonio Manuel Dur\\'an-Rosal, Pedro Antonio\n  Guti\\'errez, Alicia Troncoso and C\\'esar Herv\\'as-Mart\\'inez", "title": "Time series clustering based on the characterisation of segment\n  typologies", "comments": "13 pages, 7 figures, 4 tables, 57 refs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series clustering is the process of grouping time series with respect to\ntheir similarity or characteristics. Previous approaches usually combine a\nspecific distance measure for time series and a standard clustering method.\nHowever, these approaches do not take the similarity of the different\nsubsequences of each time series into account, which can be used to better\ncompare the time series objects of the dataset. In this paper, we propose a\nnovel technique of time series clustering based on two clustering stages. In a\nfirst step, a least squares polynomial segmentation procedure is applied to\neach time series, which is based on a growing window technique that returns\ndifferent-length segments. Then, all the segments are projected into same\ndimensional space, based on the coefficients of the model that approximates the\nsegment and a set of statistical features. After mapping, a first hierarchical\nclustering phase is applied to all mapped segments, returning groups of\nsegments for each time series. These clusters are used to represent all time\nseries in the same dimensional space, after defining another specific mapping\nprocess. In a second and final clustering stage, all the time series objects\nare grouped. We consider internal clustering quality to automatically adjust\nthe main parameter of the algorithm, which is an error threshold for the\nsegmenta- tion. The results obtained on 84 datasets from the UCR Time Series\nClassification Archive have been compared against two state-of-the-art methods,\nshowing that the performance of this methodology is very promising.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 10:01:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Guijo-Rubio", "David", ""], ["Dur\u00e1n-Rosal", "Antonio Manuel", ""], ["Guti\u00e9rrez", "Pedro Antonio", ""], ["Troncoso", "Alicia", ""], ["Herv\u00e1s-Mart\u00ednez", "C\u00e9sar", ""]]}, {"id": "1810.11630", "submitter": "Wittawat Jitkrittum", "authors": "Wittawat Jitkrittum, Heishiro Kanagawa, Patsorn Sangkloy, James Hays,\n  Bernhard Sch\\\"olkopf, Arthur Gretton", "title": "Informative Features for Model Comparison", "comments": "Accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two candidate models, and a set of target observations, we address the\nproblem of measuring the relative goodness of fit of the two models. We propose\ntwo new statistical tests which are nonparametric, computationally efficient\n(runtime complexity is linear in the sample size), and interpretable. As a\nunique advantage, our tests can produce a set of examples (informative\nfeatures) indicating the regions in the data domain where one model fits\nsignificantly better than the other. In a real-world problem of comparing GAN\nmodels, the test power of our new test matches that of the state-of-the-art\ntest of relative goodness of fit, while being one order of magnitude faster.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 10:55:34 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jitkrittum", "Wittawat", ""], ["Kanagawa", "Heishiro", ""], ["Sangkloy", "Patsorn", ""], ["Hays", "James", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Gretton", "Arthur", ""]]}, {"id": "1810.11646", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Aahlad Manas Puli, Uri Shalit", "title": "Removing Hidden Confounding by Experimental Grounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational data is increasingly used as a means for making\nindividual-level causal predictions and intervention recommendations. The\nforemost challenge of causal inference from observational data is hidden\nconfounding, whose presence cannot be tested in data and can invalidate any\ncausal conclusion. Experimental data does not suffer from confounding but is\nusually limited in both scope and scale. We introduce a novel method of using\nlimited experimental data to correct the hidden confounding in causal effect\nmodels trained on larger observational data, even if the observational data\ndoes not fully overlap with the experimental data. Our method makes strictly\nweaker assumptions than existing approaches, and we prove conditions under\nwhich it yields a consistent estimator. We demonstrate our method's efficacy\nusing real-world data from a large educational experiment.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 13:59:05 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kallus", "Nathan", ""], ["Puli", "Aahlad Manas", ""], ["Shalit", "Uri", ""]]}, {"id": "1810.11671", "submitter": "Marek Wydmuch", "authors": "Marek Wydmuch, Kalina Jasinska, Mikhail Kuznetsov, R\\'obert\n  Busa-Fekete, Krzysztof Dembczy\\'nski", "title": "A no-regret generalization of hierarchical softmax to extreme\n  multi-label classification", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification (XMLC) is a problem of tagging an instance\nwith a small subset of relevant labels chosen from an extremely large pool of\npossible labels. Large label spaces can be efficiently handled by organizing\nlabels as a tree, like in the hierarchical softmax (HSM) approach commonly used\nfor multi-class problems. In this paper, we investigate probabilistic label\ntrees (PLTs) that have been recently devised for tackling XMLC problems. We\nshow that PLTs are a no-regret multi-label generalization of HSM when\nprecision@k is used as a model evaluation metric. Critically, we prove that\npick-one-label heuristic - a reduction technique from multi-label to\nmulti-class that is routinely used along with HSM - is not consistent in\ngeneral. We also show that our implementation of PLTs, referred to as\nextremeText (XT), obtains significantly better results than HSM with the\npick-one-label heuristic and XML-CNN, a deep network specifically designed for\nXMLC problems. Moreover, XT is competitive to many state-of-the-art approaches\nin terms of statistical performance, model size and prediction time which makes\nit amenable to deploy in an online system.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 16:27:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Wydmuch", "Marek", ""], ["Jasinska", "Kalina", ""], ["Kuznetsov", "Mikhail", ""], ["Busa-Fekete", "R\u00f3bert", ""], ["Dembczy\u0144ski", "Krzysztof", ""]]}, {"id": "1810.11693", "submitter": "Dilin Wang", "authors": "Qiang Liu and Dilin Wang", "title": "Stein Variational Gradient Descent as Moment Matching", "comments": "Conference on Neural Information Processing Systems (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein variational gradient descent (SVGD) is a non-parametric inference\nalgorithm that evolves a set of particles to fit a given distribution of\ninterest. We analyze the non-asymptotic properties of SVGD, showing that there\nexists a set of functions, which we call the Stein matching set, whose\nexpectations are exactly estimated by any set of particles that satisfies the\nfixed point equation of SVGD. This set is the image of Stein operator applied\non the feature maps of the positive definite kernel used in SVGD. Our results\nprovide a theoretical framework for analyzing the properties of SVGD with\ndifferent kernels, shedding insight into optimal kernel choice. In particular,\nwe show that SVGD with linear kernels yields exact estimation of means and\nvariances on Gaussian distributions, while random Fourier features enable\nprobabilistic bounds for distributional approximation. Our results offer a\nrefreshing view of the classical inference problem as fitting Stein's identity\nor solving the Stein equation, which may motivate more efficient algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 19:23:50 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Liu", "Qiang", ""], ["Wang", "Dilin", ""]]}, {"id": "1810.11698", "submitter": "Myriam Tami", "authors": "Myriam Tami, Marianne Clausel, Emilie Devijver, Adrien Dulac, Eric\n  Gaussier, Stefan Janaqi, Meriam Chebre", "title": "Uncertain Trees: Dealing with Uncertain Inputs in Regression Trees", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based ensemble methods, as Random Forests and Gradient Boosted Trees,\nhave been successfully used for regression in many applications and research\nstudies. Furthermore, these methods have been extended in order to deal with\nuncertainty in the output variable, using for example a quantile loss in Random\nForests (Meinshausen, 2006). To the best of our knowledge, no extension has\nbeen provided yet for dealing with uncertainties in the input variables, even\nthough such uncertainties are common in practical situations. We propose here\nsuch an extension by showing how standard regression trees optimizing a\nquadratic loss can be adapted and learned while taking into account the\nuncertainties in the inputs. By doing so, one no longer assumes that an\nobservation lies into a single region of the regression tree, but rather that\nit belongs to each region with a certain probability. Experiments conducted on\nseveral data sets illustrate the good behavior of the proposed extension.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:03:45 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 14:04:14 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Tami", "Myriam", ""], ["Clausel", "Marianne", ""], ["Devijver", "Emilie", ""], ["Dulac", "Adrien", ""], ["Gaussier", "Eric", ""], ["Janaqi", "Stefan", ""], ["Chebre", "Meriam", ""]]}, {"id": "1810.11701", "submitter": "Dongchi Yu", "authors": "Dongchi Yu, Lu Wang", "title": "Hull Form Optimization with Principal Component Analysis and Deep Neural\n  Network", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing and modifying complex hull forms for optimal vessel performances\nhave been a major challenge for naval architects. In the present study,\nPrincipal Component Analysis (PCA) is introduced to compress the geometric\nrepresentation of a group of existing vessels, and the resulting principal\nscores are manipulated to generate a large number of derived hull forms, which\nare evaluated computationally for their calm-water performances. The results\nare subsequently used to train a Deep Neural Network (DNN) to accurately\nestablish the relation between different hull forms and their associated\nperformances. Then, based on the fast, parallel DNN-based hull-form evaluation,\nthe large-scale search for optimal hull forms is performed.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:37:47 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Yu", "Dongchi", ""], ["Wang", "Lu", ""]]}, {"id": "1810.11711", "submitter": "Chandler Zuo", "authors": "Chandler Zuo", "title": "Regularization Effect of Fast Gradient Sign Method and its\n  Generalization", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast Gradient Sign Method (FGSM) is a popular method to generate adversarial\nexamples that make neural network models robust against perturbations. Despite\nits empirical success, its theoretical property is not well understood. This\npaper develops theory to explain the regularization effect of Generalized FGSM,\na class of methods to generate adversarial examples. Motivated from the\nrelationship between FGSM and LASSO penalty, the asymptotic properties of\nGeneralized FGSM are derived in the Generalized Linear Model setting, which is\nessentially the 1-layer neural network setting with certain activation\nfunctions. In such simple neural network models, I prove that Generalized FGSM\nestimation is root n-consistent and weakly oracle under proper conditions. The\nasymptotic results are also highly similar to penalized likelihood estimation.\nNevertheless, Generalized FGSM introduces additional bias when data sampling is\nnot sign neutral, a concept I introduce to describe the balance-ness of the\nnoise signs. Although the theory in this paper is developed under simple neural\nnetwork settings, I argue that it may give insights and justification for FGSM\nin deep neural network settings as well.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 21:22:06 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 04:44:50 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zuo", "Chandler", ""]]}, {"id": "1810.11726", "submitter": "Dhagash Mehta", "authors": "Timothy E. Wang, Yiming Gu, Dhagash Mehta, Xiaojun Zhao, Edgar A.\n  Bernal", "title": "Towards Robust Deep Neural Networks", "comments": "Added further discussions, and supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the topics of sensitivity and robustness in feedforward and\nconvolutional neural networks. Combining energy landscape techniques developed\nin computational chemistry with tools drawn from formal methods, we produce\nempirical evidence indicating that networks corresponding to lower-lying minima\nin the optimization landscape of the learning objective tend to be more robust.\nThe robustness estimate used is the inverse of a proposed sensitivity measure,\nwhich we define as the volume of an over-approximation of the reachable set of\nnetwork outputs under all additive $l_{\\infty}$-bounded perturbations on the\ninput data. We present a novel loss function which includes a sensitivity term\nin addition to the traditional task-oriented and regularization terms. In our\nexperiments on standard machine learning and computer vision datasets, we show\nthat the proposed loss function leads to networks which reliably optimize the\nrobustness measure as well as other related metrics of adversarial robustness\nwithout significant degradation in the classification error. Experimental\nresults indicate that the proposed method outperforms state-of-the-art\nsensitivity-based learning approaches with regards to robustness to adversarial\nattacks. We also show that although the introduced framework does not\nexplicitly enforce an adversarial loss, it achieves competitive overall\nperformance relative to methods that do.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 22:38:33 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 20:55:32 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Wang", "Timothy E.", ""], ["Gu", "Yiming", ""], ["Mehta", "Dhagash", ""], ["Zhao", "Xiaojun", ""], ["Bernal", "Edgar A.", ""]]}, {"id": "1810.11730", "submitter": "Hang Gao", "authors": "Hang Gao, Zheng Shou, Alireza Zareian, Hanwang Zhang, Shih-Fu Chang", "title": "Low-shot Learning via Covariance-Preserving Adversarial Augmentation\n  Networks", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems, pp. 981-991.\n  2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks suffer from over-fitting and catastrophic forgetting\nwhen trained with small data. One natural remedy for this problem is data\naugmentation, which has been recently shown to be effective. However, previous\nworks either assume that intra-class variances can always be generalized to new\nclasses, or employ naive generation methods to hallucinate finite examples\nwithout modeling their latent distributions. In this work, we propose\nCovariance-Preserving Adversarial Augmentation Networks to overcome existing\nlimits of low-shot learning. Specifically, a novel Generative Adversarial\nNetwork is designed to model the latent distribution of each novel class given\nits related base counterparts. Since direct estimation of novel classes can be\ninductively biased, we explicitly preserve covariance information as the\n`variability' of base examples during the generation process. Empirical results\nshow that our model can generate realistic yet diverse examples, leading to\nsubstantial improvements on the ImageNet benchmark over the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 23:09:10 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 20:13:47 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 16:42:32 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Gao", "Hang", ""], ["Shou", "Zheng", ""], ["Zareian", "Alireza", ""], ["Zhang", "Hanwang", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1810.11738", "submitter": "Francesco Paolo Casale", "authors": "Francesco Paolo Casale, Adrian V Dalca, Luca Saglietti, Jennifer\n  Listgarten, Nicolo Fusi", "title": "Gaussian Process Prior Variational Autoencoders", "comments": "Accepted at 32nd Conference on Neural Information Processing Systems\n  (NIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAE) are a powerful and widely-used class of models\nto learn complex data distributions in an unsupervised fashion. One important\nlimitation of VAEs is the prior assumption that latent sample representations\nare independent and identically distributed. However, for many important\ndatasets, such as time-series of images, this assumption is too strong:\naccounting for covariances between samples, such as those in time, can yield to\na more appropriate model specification and improve performance in downstream\ntasks. In this work, we introduce a new model, the Gaussian Process (GP) Prior\nVariational Autoencoder (GPPVAE), to specifically address this issue. The\nGPPVAE aims to combine the power of VAEs with the ability to model correlations\nafforded by GP priors. To achieve efficient inference in this new class of\nmodels, we leverage structure in the covariance matrix, and introduce a new\nstochastic backpropagation strategy that allows for computing stochastic\ngradients in a distributed and low-memory fashion. We show that our method\noutperforms conditional VAEs (CVAEs) and an adaptation of standard VAEs in two\nimage data applications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 00:57:23 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 05:00:52 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Casale", "Francesco Paolo", ""], ["Dalca", "Adrian V", ""], ["Saglietti", "Luca", ""], ["Listgarten", "Jennifer", ""], ["Fusi", "Nicolo", ""]]}, {"id": "1810.11740", "submitter": "Farzan Farnia", "authors": "Farzan Farnia, David Tse", "title": "A Convex Duality Framework for GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial network (GAN) is a minimax game between a generator\nmimicking the true model and a discriminator distinguishing the samples\nproduced by the generator from the real training samples. Given an\nunconstrained discriminator able to approximate any function, this game reduces\nto finding the generative model minimizing a divergence measure, e.g. the\nJensen-Shannon (JS) divergence, to the data distribution. However, in practice\nthe discriminator is constrained to be in a smaller class $\\mathcal{F}$ such as\nneural nets. Then, a natural question is how the divergence minimization\ninterpretation changes as we constrain $\\mathcal{F}$. In this work, we address\nthis question by developing a convex duality framework for analyzing GANs. For\na convex set $\\mathcal{F}$, this duality framework interprets the original GAN\nformulation as finding the generative model with minimum JS-divergence to the\ndistributions penalized to match the moments of the data distribution, with the\nmoments specified by the discriminators in $\\mathcal{F}$. We show that this\ninterpretation more generally holds for f-GAN and Wasserstein GAN. As a\nbyproduct, we apply the duality framework to a hybrid of f-divergence and\nWasserstein distance. Unlike the f-divergence, we prove that the proposed\nhybrid divergence changes continuously with the generative model, which\nsuggests regularizing the discriminator's Lipschitz constant in f-GAN and\nvanilla GAN. We numerically evaluate the power of the suggested regularization\nschemes for improving GAN's training performance.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 01:15:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Farnia", "Farzan", ""], ["Tse", "David", ""]]}, {"id": "1810.11750", "submitter": "Liwei Wang", "authors": "Liwei Wang, Lunjia Hu, Jiayuan Gu, Yue Wu, Zhiqiang Hu, Kun He and\n  John Hopcroft", "title": "Towards Understanding Learning Representations: To What Extent Do\n  Different Neural Networks Learn the Same Representation", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that learning good representations is one of the main\nreasons for the success of deep neural networks. Although highly intuitive,\nthere is a lack of theory and systematic approach quantitatively characterizing\nwhat representations do deep neural networks learn. In this work, we move a\ntiny step towards a theory and better understanding of the representations.\nSpecifically, we study a simpler problem: How similar are the representations\nlearned by two networks with identical architecture but trained from different\ninitializations. We develop a rigorous theory based on the neuron activation\nsubspace match model. The theory gives a complete characterization of the\nstructure of neuron activation subspace matches, where the core concepts are\nmaximum match and simple match which describe the overall and the finest\nsimilarity between sets of neurons in two networks respectively. We also\npropose efficient algorithms to find the maximum match and simple matches.\nFinally, we conduct extensive experiments using our algorithms. Experimental\nresults suggest that, surprisingly, representations learned by the same\nconvolutional layers of networks trained from different initializations are not\nas similar as prevalently expected, at least in terms of subspace match.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 02:27:31 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 21:14:59 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Wang", "Liwei", ""], ["Hu", "Lunjia", ""], ["Gu", "Jiayuan", ""], ["Wu", "Yue", ""], ["Hu", "Zhiqiang", ""], ["He", "Kun", ""], ["Hopcroft", "John", ""]]}, {"id": "1810.11754", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky, Venkatadheeraj Pichapati", "title": "On Learning Markov Chains", "comments": "To appear at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating an unknown discrete distribution from its samples\nis a fundamental tenet of statistical learning. Over the past decade, it\nattracted significant research effort and has been solved for a variety of\ndivergence measures. Surprisingly, an equally important problem, estimating an\nunknown Markov chain from its samples, is still far from understood. We\nconsider two problems related to the min-max risk (expected loss) of estimating\nan unknown $k$-state Markov chain from its $n$ sequential samples: predicting\nthe conditional distribution of the next sample with respect to the\nKL-divergence, and estimating the transition matrix with respect to a natural\nloss induced by KL or a more general $f$-divergence measure.\n  For the first measure, we determine the min-max prediction risk to within a\nlinear factor in the alphabet size, showing it is $\\Omega(k\\log\\log n\\ / n)$\nand $\\mathcal{O}(k^2\\log\\log n\\ / n)$. For the second, if the transition\nprobabilities can be arbitrarily small, then only trivial uniform risk upper\nbounds can be derived. We therefore consider transition probabilities that are\nbounded away from zero, and resolve the problem for essentially all\nsufficiently smooth $f$-divergences, including KL-, $L_2$-, Chi-squared,\nHellinger, and Alpha-divergences.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 03:20:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""], ["Pichapati", "Venkatadheeraj", ""]]}, {"id": "1810.11755", "submitter": "Anji Liu", "authors": "Anji Liu, Jianshu Chen, Mingze Yu, Yu Zhai, Xuewen Zhou, Ji Liu", "title": "Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo\n  Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) algorithms have achieved great success on many\nchallenging benchmarks (e.g., Computer Go). However, they generally require a\nlarge number of rollouts, making their applications costly. Furthermore, it is\nalso extremely challenging to parallelize MCTS due to its inherent sequential\nnature: each rollout heavily relies on the statistics (e.g., node visitation\ncounts) estimated from previous simulations to achieve an effective\nexploration-exploitation tradeoff. In spite of these difficulties, we develop\nan algorithm, WU-UCT, to effectively parallelize MCTS, which achieves linear\nspeedup and exhibits only limited performance loss with an increasing number of\nworkers. The key idea in WU-UCT is a set of statistics that we introduce to\ntrack the number of on-going yet incomplete simulation queries (named as\nunobserved samples). These statistics are used to modify the UCT tree policy in\nthe selection steps in a principled manner to retain effective\nexploration-exploitation tradeoff when we parallelize the most time-consuming\nexpansion and simulation steps. Experiments on a proprietary benchmark and the\nAtari Game benchmark demonstrate the linear speedup and the superior\nperformance of WU-UCT comparing to existing techniques.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 03:24:01 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 16:42:24 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 21:10:56 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 03:48:32 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2020 22:03:23 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Liu", "Anji", ""], ["Chen", "Jianshu", ""], ["Yu", "Mingze", ""], ["Zhai", "Yu", ""], ["Zhou", "Xuewen", ""], ["Liu", "Ji", ""]]}, {"id": "1810.11758", "submitter": "Hao-Hsuan Chang", "authors": "Hao-Hsuan Chang, Hao Song, Yang Yi, Jianzhong Zhang, Haibo He, Lingjia\n  Liu", "title": "Distributive Dynamic Spectrum Access through Deep Reinforcement\n  Learning: A Reservoir Computing Based Approach", "comments": "This work is accepted in IEEE IoT Journal 2018", "journal-ref": null, "doi": "10.1109/JIOT.2018.2872441", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic spectrum access (DSA) is regarded as an effective and efficient\ntechnology to share radio spectrum among different networks. As a secondary\nuser (SU), a DSA device will face two critical problems: avoiding causing\nharmful interference to primary users (PUs), and conducting effective\ninterference coordination with other secondary users. These two problems become\neven more challenging for a distributed DSA network where there is no\ncentralized controllers for SUs. In this paper, we investigate communication\nstrategies of a distributive DSA network under the presence of spectrum sensing\nerrors. To be specific, we apply the powerful machine learning tool, deep\nreinforcement learning (DRL), for SUs to learn \"appropriate\" spectrum access\nstrategies in a distributed fashion assuming NO knowledge of the underlying\nsystem statistics. Furthermore, a special type of recurrent neural network\n(RNN), called the reservoir computing (RC), is utilized to realize DRL by\ntaking advantage of the underlying temporal correlation of the DSA network.\nUsing the introduced machine learning-based strategy, SUs could make spectrum\naccess decisions distributedly relying only on their own current and past\nspectrum sensing outcomes. Through extensive experiments, our results suggest\nthat the RC-based spectrum access strategy can help the SU to significantly\nreduce the chances of collision with PUs and other SUs. We also show that our\nscheme outperforms the myopic method which assumes the knowledge of system\nstatistics, and converges faster than the Q-learning method when the number of\nchannels is large.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 04:02:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chang", "Hao-Hsuan", ""], ["Song", "Hao", ""], ["Yi", "Yang", ""], ["Zhang", "Jianzhong", ""], ["He", "Haibo", ""], ["Liu", "Lingjia", ""]]}, {"id": "1810.11760", "submitter": "Luis Lamb", "authors": "Felipe Grando, Lisando Z. Granville and Luis C. Lamb", "title": "Machine Learning in Network Centrality Measures: Tutorial and Outlook", "comments": "7 tables, 9 figures, version accepted at ACM Computing Surveys.\n  https://doi.org/10.1145/3237192", "journal-ref": "ACM Comput. Surv. 51, 5, Article 102 (October 2018), 32 pages", "doi": "10.1145/3237192", "report-no": null, "categories": "cs.LG cs.NE cs.NI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks are ubiquitous to several Computer Science domains.\nCentrality measures are an important analysis mechanism to uncover vital\nelements of complex networks. However, these metrics have high computational\ncosts and requirements that hinder their applications in large real-world\nnetworks. In this tutorial, we explain how the use of neural network learning\nalgorithms can render the application of the metrics in complex networks of\narbitrary size. Moreover, the tutorial describes how to identify the best\nconfiguration for neural network training and learning such for tasks, besides\npresenting an easy way to generate and acquire training data. We do so by means\nof a general methodology, using complex network models adaptable to any\napplication. We show that a regression model generated by the neural network\nsuccessfully approximates the metric values and therefore are a robust,\neffective alternative in real-world applications. The methodology and proposed\nmachine learning model use only a fraction of time with respect to other\napproximation algorithms, which is crucial in complex network applications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 04:51:08 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Grando", "Felipe", ""], ["Granville", "Lisando Z.", ""], ["Lamb", "Luis C.", ""]]}, {"id": "1810.11764", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Skjalg Leps{\\o}y, Attilio Fiandrotti, Gianluca\n  Francini", "title": "Learning Sparse Neural Networks via Sensitivity-Driven Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing number of parameters in deep neural networks poses\nchallenges for memory-limited applications. Regularize-and-prune methods aim at\nmeeting these challenges by sparsifying the network weights. In this context we\nquantify the output sensitivity to the parameters (i.e. their relevance to the\nnetwork output) and introduce a regularization term that gradually lowers the\nabsolute value of parameters with low sensitivity. Thus, a very large fraction\nof the parameters approach zero and are eventually set to zero by simple\nthresholding. Our method surpasses most of the recent techniques both in terms\nof sparsity and error rates. In some cases, the method reaches twice the\nsparsity obtained by other techniques at equal error rates.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 06:15:51 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Leps\u00f8y", "Skjalg", ""], ["Fiandrotti", "Attilio", ""], ["Francini", "Gianluca", ""]]}, {"id": "1810.11776", "submitter": "Niklas Pfister", "authors": "Niklas Pfister, Stefan Bauer and Jonas Peters", "title": "Learning stable and predictive structures in kinetic systems: Benefits\n  of a causal approach", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1905688116", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning kinetic systems from data is one of the core challenges in many\nfields. Identifying stable models is essential for the generalization\ncapabilities of data-driven inference. We introduce a computationally efficient\nframework, called CausalKinetiX, that identifies structure from discrete time,\nnoisy observations, generated from heterogeneous experiments. The algorithm\nassumes the existence of an underlying, invariant kinetic model, a key\ncriterion for reproducible research. Results on both simulated and real-world\nexamples suggest that learning the structure of kinetic systems benefits from a\ncausal perspective. The identified variables and models allow for a concise\ndescription of the dynamics across multiple experimental settings and can be\nused for prediction in unseen experiments. We observe significant improvements\ncompared to well established approaches focusing solely on predictive\nperformance, especially for out-of-sample generalization.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 07:47:54 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 12:07:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Pfister", "Niklas", ""], ["Bauer", "Stefan", ""], ["Peters", "Jonas", ""]]}, {"id": "1810.11783", "submitter": "Huan Zhang", "authors": "Huan Zhang, Pengchuan Zhang, Cho-Jui Hsieh", "title": "RecurJac: An Efficient Recursive Algorithm for Bounding Jacobian Matrix\n  of Neural Networks and Its Applications", "comments": "Work done during internship at Microsoft Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Jacobian matrix (or the gradient for single-output networks) is directly\nrelated to many important properties of neural networks, such as the function\nlandscape, stationary points, (local) Lipschitz constants and robustness to\nadversarial attacks. In this paper, we propose a recursive algorithm, RecurJac,\nto compute both upper and lower bounds for each element in the Jacobian matrix\nof a neural network with respect to network's input, and the network can\ncontain a wide range of activation functions. As a byproduct, we can\nefficiently obtain a (local) Lipschitz constant, which plays a crucial role in\nneural network robustness verification, as well as the training stability of\nGANs. Experiments show that (local) Lipschitz constants produced by our method\nis of better quality than previous approaches, thus providing better robustness\nverification results. Our algorithm has polynomial time complexity, and its\ncomputation time is reasonable even for relatively large networks.\nAdditionally, we use our bounds of Jacobian matrix to characterize the\nlandscape of the neural network, for example, to determine whether there exist\nstationary points in a local neighborhood. Source code available at\n\\url{http://github.com/huanzhang12/RecurJac-Jacobian-bounds}.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 09:25:08 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 07:01:58 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Zhang", "Huan", ""], ["Zhang", "Pengchuan", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.11787", "submitter": "Karanbir Chahal", "authors": "Karanbir Chahal, Manraj Singh Grover, Kuntal Dey", "title": "A Hitchhiker's Guide On Distributed Training of Deep Neural Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has led to tremendous advancements in the field of Artificial\nIntelligence. One caveat however is the substantial amount of compute needed to\ntrain these deep learning models. Training a benchmark dataset like ImageNet on\na single machine with a modern GPU can take upto a week, distributing training\non multiple machines has been observed to drastically bring this time down.\nRecent work has brought down ImageNet training time to a time as low as 4\nminutes by using a cluster of 2048 GPUs. This paper surveys the various\nalgorithms and techniques used to distribute training and presents the current\nstate of the art for a modern distributed training framework. More\nspecifically, we explore the synchronous and asynchronous variants of\ndistributed Stochastic Gradient Descent, various All Reduce gradient\naggregation strategies and best practices for obtaining higher throughout and\nlower latency over a cluster such as mixed precision training, large batch\ntraining and gradient compression.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 09:37:47 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chahal", "Karanbir", ""], ["Grover", "Manraj Singh", ""], ["Dey", "Kuntal", ""]]}, {"id": "1810.11793", "submitter": "Hiromu Yakura", "authors": "Hiromu Yakura, Jun Sakuma", "title": "Robust Audio Adversarial Example for a Physical Attack", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/741", "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to generate audio adversarial examples that can attack a\nstate-of-the-art speech recognition model in the physical world. Previous work\nassumes that generated adversarial examples are directly fed to the recognition\nmodel, and is not able to perform such a physical attack because of\nreverberation and noise from playback environments. In contrast, our method\nobtains robust adversarial examples by simulating transformations caused by\nplayback or recording in the physical world and incorporating the\ntransformations into the generation process. Evaluation and a listening\nexperiment demonstrated that our adversarial examples are able to attack\nwithout being noticed by humans. This result suggests that audio adversarial\nexamples generated by the proposed method may become a real threat.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 10:50:24 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 23:18:45 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 08:40:25 GMT"}, {"version": "v4", "created": "Mon, 19 Aug 2019 02:22:51 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yakura", "Hiromu", ""], ["Sakuma", "Jun", ""]]}, {"id": "1810.11829", "submitter": "Thodoris Lykouris", "authors": "Avrim Blum, Suriya Gunasekar, Thodoris Lykouris, Nathan Srebro", "title": "On preserving non-discrimination when combining expert advice", "comments": "Appeared in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interplay between sequential decision making and avoiding\ndiscrimination against protected groups, when examples arrive online and do not\nfollow distributional assumptions. We consider the most basic extension of\nclassical online learning: \"Given a class of predictors that are individually\nnon-discriminatory with respect to a particular metric, how can we combine them\nto perform as well as the best predictor, while preserving non-discrimination?\"\nSurprisingly we show that this task is unachievable for the prevalent notion of\n\"equalized odds\" that requires equal false negative rates and equal false\npositive rates across groups. On the positive side, for another notion of\nnon-discrimination, \"equalized error rates\", we show that running separate\ninstances of the classical multiplicative weights algorithm for each group\nachieves this guarantee. Interestingly, even for this notion, we show that\nalgorithms with stronger performance guarantees than multiplicative weights\ncannot preserve non-discrimination.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 16:28:30 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 21:37:00 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Blum", "Avrim", ""], ["Gunasekar", "Suriya", ""], ["Lykouris", "Thodoris", ""], ["Srebro", "Nathan", ""]]}, {"id": "1810.11843", "submitter": "Stephen Pasteris", "authors": "Stephen Pasteris, Fabio Vitale, Kevin Chan, Shiqiang Wang, Mark\n  Herbster", "title": "MaxHedge: Maximising a Maximum Online", "comments": "Published in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new online learning framework where, at each trial, the\nlearner is required to select a subset of actions from a given known action\nset. Each action is associated with an energy value, a reward and a cost. The\nsum of the energies of the actions selected cannot exceed a given energy\nbudget. The goal is to maximise the cumulative profit, where the profit\nobtained on a single trial is defined as the difference between the maximum\nreward among the selected actions and the sum of their costs. Action energy\nvalues and the budget are known and fixed. All rewards and costs associated\nwith each action change over time and are revealed at each trial only after the\nlearner's selection of actions. Our framework encompasses several online\nlearning problems where the environment changes over time; and the solution\ntrades-off between minimising the costs and maximising the maximum reward of\nthe selected subset of actions, while being constrained to an action energy\nbudget. The algorithm that we propose is efficient and general in that it may\nbe specialised to multiple natural online combinatorial problems.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 17:38:32 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 13:22:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Pasteris", "Stephen", ""], ["Vitale", "Fabio", ""], ["Chan", "Kevin", ""], ["Wang", "Shiqiang", ""], ["Herbster", "Mark", ""]]}, {"id": "1810.11857", "submitter": "Wenbo Ren", "authors": "Wenbo Ren, Jia Liu, Ness Shroff", "title": "Exploring $k$ out of Top $\\rho$ Fraction of Arms in Stochastic Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of identifying any $k$ distinct arms among the\ntop $\\rho$ fraction (e.g., top 5\\%) of arms from a finite or infinite set with\na probably approximately correct (PAC) tolerance $\\epsilon$. We consider two\ncases: (i) when the threshold of the top arms' expected rewards is known and\n(ii) when it is unknown. We prove lower bounds for the four variants (finite or\ninfinite arms, and known or unknown threshold), and propose algorithms for\neach. Two of these algorithms are shown to be sample complexity optimal (up to\nconstant factors) and the other two are optimal up to a log factor. Results in\nthis paper provide up to $\\rho n/k$ reductions compared with the\n\"$k$-exploration\" algorithms that focus on finding the (PAC) best $k$ arms out\nof $n$ arms. We also numerically show improvements over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 18:40:16 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 06:24:53 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Ren", "Wenbo", ""], ["Liu", "Jia", ""], ["Shroff", "Ness", ""]]}, {"id": "1810.11861", "submitter": "Andrew Wilson", "authors": "William Herlands, Daniel B. Neill, Hannes Nickisch, Andrew Gordon\n  Wilson", "title": "Change Surfaces for Expressive Multidimensional Changepoints and\n  Counterfactual Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying changes in model parameters is fundamental in machine learning\nand statistics. However, standard changepoint models are limited in\nexpressiveness, often addressing unidimensional problems and assuming\ninstantaneous changes. We introduce change surfaces as a multidimensional and\nhighly expressive generalization of changepoints. We provide a model-agnostic\nformalization of change surfaces, illustrating how they can provide variable,\nheterogeneous, and non-monotonic rates of change across multiple dimensions.\nAdditionally, we show how change surfaces can be used for counterfactual\nprediction. As a concrete instantiation of the change surface framework, we\ndevelop Gaussian Process Change Surfaces (GPCS). We demonstrate counterfactual\nprediction with Bayesian posterior mean and credible sets, as well as massive\nscalability by introducing novel methods for additive non-separable kernels.\nUsing two large spatio-temporal datasets we employ GPCS to discover and\ncharacterize complex changes that can provide scientific and policy relevant\ninsights. Specifically, we analyze twentieth century measles incidence across\nthe United States and discover previously unknown heterogeneous changes after\nthe introduction of the measles vaccine. Additionally, we apply the model to\nrequests for lead testing kits in New York City, discovering distinct spatial\nand demographic patterns.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 19:08:18 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 11:56:42 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Herlands", "William", ""], ["Neill", "Daniel B.", ""], ["Nickisch", "Hannes", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1810.11867", "submitter": "Erik Lindgren", "authors": "Erik M. Lindgren, Murat Kocaoglu, Alexandros G. Dimakis, Sriram\n  Vishwanath", "title": "Experimental Design for Cost-Aware Learning of Causal Graphs", "comments": "In NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimum cost intervention design problem: Given the essential\ngraph of a causal graph and a cost to intervene on a variable, identify the set\nof interventions with minimum total cost that can learn any causal graph with\nthe given essential graph. We first show that this problem is NP-hard. We then\nprove that we can achieve a constant factor approximation to this problem with\na greedy algorithm. We then constrain the sparsity of each intervention. We\ndevelop an algorithm that returns an intervention design that is nearly optimal\nin terms of size for sparse graphs with sparse interventions and we discuss how\nto use it when there are costs on the vertices.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 19:28:59 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Lindgren", "Erik M.", ""], ["Kocaoglu", "Murat", ""], ["Dimakis", "Alexandros G.", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1810.11874", "submitter": "Yanyao Shen", "authors": "Yanyao Shen and Sujay Sanghavi", "title": "Learning with Bad Training Data via Iterative Trimmed Loss Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a simple and generic framework to tackle the problem\nof learning model parameters when a fraction of the training samples are\ncorrupted. We first make a simple observation: in a variety of such settings,\nthe evolution of training accuracy (as a function of training epochs) is\ndifferent for clean and bad samples. Based on this we propose to iteratively\nminimize the trimmed loss, by alternating between (a) selecting samples with\nlowest current loss, and (b) retraining a model on only these samples. We prove\nthat this process recovers the ground truth (with linear convergence rate) in\ngeneralized linear models with standard statistical assumptions.\nExperimentally, we demonstrate its effectiveness in three settings: (a) deep\nimage classifiers with errors only in labels, (b) generative adversarial\nnetworks with bad training images, and (c) deep image classifiers with\nadversarial (image, label) pairs (i.e., backdoor attacks). For the well-studied\nsetting of random label noise, our algorithm achieves state-of-the-art\nperformance without having access to any a-priori guaranteed clean samples.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 20:10:22 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 22:35:31 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Shen", "Yanyao", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1810.11893", "submitter": "Ulrich Paquet", "authors": "Ulrich Paquet and Marco Fraccaro", "title": "An Efficient Implementation of Riemannian Manifold Hamiltonian Monte\n  Carlo for Gaussian Process Models", "comments": "Technical report accompanying arXiv:1604.01972, \"An Adaptive\n  Resample-Move Algorithm for Estimating Normalizing Constants\" (2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report presents pseudo-code for a Riemannian manifold\nHamiltonian Monte Carlo (RMHMC) method to efficiently simulate samples from\n$N$-dimensional posterior distributions $p(x|y)$, where $x \\in R^N$ is drawn\nfrom a Gaussian Process (GP) prior, and observations $y_n$ are independent\ngiven $x_n$. Sufficient technical and algorithmic details are provided for the\nimplementation of RMHMC for distributions arising from GP priors.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 22:10:26 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Paquet", "Ulrich", ""], ["Fraccaro", "Marco", ""]]}, {"id": "1810.11896", "submitter": "Nima Anari", "authors": "Nima Anari, Constantinos Daskalakis, Wolfgang Maass, Christos H.\n  Papadimitriou, Amin Saberi, Santosh Vempala", "title": "Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of\n  Neurons", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze linear independence of rank one tensors produced by tensor powers\nof randomly perturbed vectors. This enables efficient decomposition of sums of\nhigh-order tensors. Our analysis builds upon [BCMV14] but allows for a wider\nrange of perturbation models, including discrete ones. We give an application\nto recovering assemblies of neurons.\n  Assemblies are large sets of neurons representing specific memories or\nconcepts. The size of the intersection of two assemblies has been shown in\nexperiments to represent the extent to which these memories co-occur or these\nconcepts are related; the phenomenon is called association of assemblies. This\nsuggests that an animal's memory is a complex web of associations, and poses\nthe problem of recovering this representation from cognitive data. Motivated by\nthis problem, we study the following more general question: Can we reconstruct\nthe Venn diagram of a family of sets, given the sizes of their $\\ell$-wise\nintersections? We show that as long as the family of sets is randomly\nperturbed, it is enough for the number of measurements to be polynomially\nlarger than the number of nonempty regions of the Venn diagram to fully\nreconstruct the diagram.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 22:15:48 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Anari", "Nima", ""], ["Daskalakis", "Constantinos", ""], ["Maass", "Wolfgang", ""], ["Papadimitriou", "Christos H.", ""], ["Saberi", "Amin", ""], ["Vempala", "Santosh", ""]]}, {"id": "1810.11899", "submitter": "Hongkuan Zhou", "authors": "Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan,\n  Viktor Prasanna", "title": "Accurate, Efficient and Scalable Graph Embedding", "comments": "10 pages. 2019 IEEE International Parallel and Distributed Processing\n  Symposium (IPDPS)", "journal-ref": null, "doi": "10.1109/IPDPS.2019.00056", "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Graph Convolutional Network (GCN) model and its variants are powerful\ngraph embedding tools for facilitating classification and clustering on graphs.\nHowever, a major challenge is to reduce the complexity of layered GCNs and make\nthem parallelizable and scalable on very large graphs -- state-of the art\ntechniques are unable to achieve scalability without losing accuracy and\nefficiency. In this paper, we propose novel parallelization techniques for\ngraph sampling-based GCNs that achieve superior scalable performance on very\nlarge graphs without compromising accuracy. Specifically, our GCN guarantees\nwork-efficient training and produces order of magnitude savings in computation\nand communication. To scale GCN training on tightly-coupled shared memory\nsystems, we develop parallelization strategies for the key steps in training:\nFor the graph sampling step, we exploit parallelism within and across multiple\nsampling instances, and devise an efficient data structure for concurrent\naccesses that provides theoretical guarantee of near-linear speedup with number\nof processing units. For the feature propagation step within the sampled graph,\nwe improve cache utilization and reduce DRAM communication by data\npartitioning. We prove that our partitioning strategy is a 2-approximation for\nminimizing the communication time compared to the optimal strategy. We\ndemonstrate that our parallel graph embedding outperforms state-of-the-art\nmethods in scalability (with respect to number of processors, graph size and\nGCN model size), efficiency and accuracy on several large datasets. On a\n40-core Xeon platform, our parallel training achieves $64\\times$ speedup (with\nAVX) in the sampling step and $25\\times$ speedup in the feature propagation\nstep, compared to the serial implementation, resulting in a net speedup of\n$21\\times$.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 22:44:51 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 04:49:54 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 17:51:08 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zeng", "Hanqing", ""], ["Zhou", "Hongkuan", ""], ["Srivastava", "Ajitesh", ""], ["Kannan", "Rajgopal", ""], ["Prasanna", "Viktor", ""]]}, {"id": "1810.11905", "submitter": "Shanshan Wu", "authors": "Shanshan Wu, Sujay Sanghavi, Alexandros G. Dimakis", "title": "Sparse Logistic Regression Learns All Discrete Pairwise Graphical Models", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the effectiveness of a classical algorithm for recovering the\nMarkov graph of a general discrete pairwise graphical model from i.i.d.\nsamples. The algorithm is (appropriately regularized) maximum conditional\nlog-likelihood, which involves solving a convex program for each node; for\nIsing models this is $\\ell_1$-constrained logistic regression, while for more\ngeneral alphabets an $\\ell_{2,1}$ group-norm constraint needs to be used. We\nshow that this algorithm can recover any arbitrary discrete pairwise graphical\nmodel, and also characterize its sample complexity as a function of model\nwidth, alphabet size, edge parameter accuracy, and the number of variables. We\nshow that along every one of these axes, it matches or improves on all existing\nresults and algorithms for this problem. Our analysis applies a sharp\ngeneralization error bound for logistic regression when the weight vector has\nan $\\ell_1$ constraint (or $\\ell_{2,1}$ constraint) and the sample vector has\nan $\\ell_{\\infty}$ constraint (or $\\ell_{2, \\infty}$ constraint). We also show\nthat the proposed convex programs can be efficiently solved in $\\tilde{O}(n^2)$\nrunning time (where $n$ is the number of variables) under the same statistical\nguarantees. We provide experimental results to support our analysis.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 23:40:42 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 03:40:47 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 20:53:05 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Wu", "Shanshan", ""], ["Sanghavi", "Sujay", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1810.11906", "submitter": "Mark Hamilton", "authors": "Mark Hamilton", "title": "Semi-Supervised Translation with MMD Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work aims to improve semi-supervised learning in a neural network\narchitecture by introducing a hybrid supervised and unsupervised cost function.\nThe unsupervised component is trained using a differentiable estimator of the\nMaximum Mean Discrepancy (MMD) distance between the network output and the\ntarget dataset. We introduce the notion of an $n$-channel network and several\nmethods to improve performance of these nets based on supervised\npre-initialization, and multi-scale kernels. This work investigates the\neffectiveness of these methods on language translation where very few quality\ntranslations are known \\textit{a priori}. We also present a thorough\ninvestigation of the hyper-parameter space of this method on both synthetic\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 23:40:54 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hamilton", "Mark", ""]]}, {"id": "1810.11908", "submitter": "Tatsuro Kawamoto", "authors": "Tatsuro Kawamoto, Masashi Tsubaki, Tomoyuki Obuchi", "title": "Mean-field theory of graph neural networks in graph partitioning", "comments": "16 pages, 6 figures, Thirty-second Conference on Neural Information\n  Processing Systems (NIPS2018)", "journal-ref": null, "doi": "10.1088/1742-5468/ab3456", "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theoretical performance analysis of the graph neural network (GNN) is\npresented. For classification tasks, the neural network approach has the\nadvantage in terms of flexibility that it can be employed in a data-driven\nmanner, whereas Bayesian inference requires the assumption of a specific model.\nA fundamental question is then whether GNN has a high accuracy in addition to\nthis flexibility. Moreover, whether the achieved performance is predominately a\nresult of the backpropagation or the architecture itself is a matter of\nconsiderable interest. To gain a better insight into these questions, a\nmean-field theory of a minimal GNN architecture is developed for the graph\npartitioning problem. This demonstrates a good agreement with numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:09:48 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kawamoto", "Tatsuro", ""], ["Tsubaki", "Masashi", ""], ["Obuchi", "Tomoyuki", ""]]}, {"id": "1810.11910", "submitter": "Matthew Riemer", "authors": "Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish,\n  Yuhai Tu, Gerald Tesauro", "title": "Learning to Learn without Forgetting by Maximizing Transfer and\n  Minimizing Interference", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of performance when it comes to continual learning over non-stationary\ndistributions of data remains a major challenge in scaling neural network\nlearning to more human realistic settings. In this work we propose a new\nconceptualization of the continual learning problem in terms of a temporally\nsymmetric trade-off between transfer and interference that can be optimized by\nenforcing gradient alignment across examples. We then propose a new algorithm,\nMeta-Experience Replay (MER), that directly exploits this view by combining\nexperience replay with optimization based meta-learning. This method learns\nparameters that make interference based on future gradients less likely and\ntransfer based on future gradients more likely. We conduct experiments across\ncontinual lifelong supervised learning benchmarks and non-stationary\nreinforcement learning environments demonstrating that our approach\nconsistently outperforms recently proposed baselines for continual learning.\nOur experiments show that the gap between the performance of MER and baseline\nalgorithms grows both as the environment gets more non-stationary and as the\nfraction of the total experiences stored gets smaller.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:13:50 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 19:23:28 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 03:32:40 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Riemer", "Matthew", ""], ["Cases", "Ignacio", ""], ["Ajemian", "Robert", ""], ["Liu", "Miao", ""], ["Rish", "Irina", ""], ["Tu", "Yuhai", ""], ["Tesauro", "Gerald", ""]]}, {"id": "1810.11911", "submitter": "Viet Huynh", "authors": "Nhat Ho, Viet Huynh, Dinh Phung, Michael I. Jordan", "title": "Probabilistic Multilevel Clustering via Composite Transportation\n  Distance", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel probabilistic approach to multilevel clustering problems\nbased on composite transportation distance, which is a variant of\ntransportation distance where the underlying metric is Kullback-Leibler\ndivergence. Our method involves solving a joint optimization problem over\nspaces of probability measures to simultaneously discover grouping structures\nwithin groups and among groups. By exploiting the connection of our method to\nthe problem of finding composite transportation barycenters, we develop fast\nand efficient optimization algorithms even for potentially large-scale\nmultilevel datasets. Finally, we present experimental results with both\nsynthetic and real data to demonstrate the efficiency and scalability of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:26:29 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Ho", "Nhat", ""], ["Huynh", "Viet", ""], ["Phung", "Dinh", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1810.11914", "submitter": "Dong Yin", "authors": "Dong Yin and Kannan Ramchandran and Peter Bartlett", "title": "Rademacher Complexity for Adversarially Robust Generalization", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models are vulnerable to adversarial attacks; for\nexample, adding adversarial perturbations that are imperceptible to humans can\noften make machine learning models produce wrong predictions with high\nconfidence. Moreover, although we may obtain robust models on the training\ndataset via adversarial training, in some problems the learned models cannot\ngeneralize well to the test data. In this paper, we focus on $\\ell_\\infty$\nattacks, and study the adversarially robust generalization problem through the\nlens of Rademacher complexity. For binary linear classifiers, we prove tight\nbounds for the adversarial Rademacher complexity, and show that the adversarial\nRademacher complexity is never smaller than its natural counterpart, and it has\nan unavoidable dimension dependence, unless the weight vector has bounded\n$\\ell_1$ norm. The results also extend to multi-class linear classifiers. For\n(nonlinear) neural networks, we show that the dimension dependence in the\nadversarial Rademacher complexity also exists. We further consider a surrogate\nadversarial loss for one-hidden layer ReLU network and prove margin bounds for\nthis setting. Our results indicate that having $\\ell_1$ norm constraints on the\nweight matrices might be a potential way to improve generalization in the\nadversarial setting. We demonstrate experimental results that validate our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:51:08 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 06:40:59 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 07:03:12 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 04:23:34 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Yin", "Dong", ""], ["Ramchandran", "Kannan", ""], ["Bartlett", "Peter", ""]]}, {"id": "1810.11943", "submitter": "Dilin Wang", "authors": "Dilin Wang, Hao Liu, Qiang Liu", "title": "Variational Inference with Tail-adaptive f-Divergence", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference with {\\alpha}-divergences has been widely used in\nmodern probabilistic machine learning. Compared to Kullback-Leibler (KL)\ndivergence, a major advantage of using {\\alpha}-divergences (with positive\n{\\alpha} values) is their mass-covering property. However, estimating and\noptimizing {\\alpha}-divergences require to use importance sampling, which could\nhave extremely large or infinite variances due to heavy tails of importance\nweights. In this paper, we propose a new class of tail-adaptive f-divergences\nthat adaptively change the convex function f with the tail of the importance\nweights, in a way that theoretically guarantees finite moments, while\nsimultaneously achieving mass-covering properties. We test our methods on\nBayesian neural networks, as well as deep reinforcement learning in which our\nmethod is applied to improve a recent soft actor-critic (SAC) algorithm. Our\nresults show that our approach yields significant advantages compared with\nexisting methods based on classical KL and {\\alpha}-divergences.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 03:52:53 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 02:56:59 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 17:26:00 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Dilin", ""], ["Liu", "Hao", ""], ["Liu", "Qiang", ""]]}, {"id": "1810.11945", "submitter": "Shinji Takaki", "authors": "Shinji Takaki, Toru Nakashika, Xin Wang, Junichi Yamagishi", "title": "STFT spectral loss for training a neural speech waveform model", "comments": "Submitted to the 2019 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a new loss using short-time Fourier transform (STFT)\nspectra for the aim of training a high-performance neural speech waveform model\nthat predicts raw continuous speech waveform samples directly. Not only\namplitude spectra but also phase spectra obtained from generated speech\nwaveforms are used to calculate the proposed loss. We also mathematically show\nthat training of the waveform model on the basis of the proposed loss can be\ninterpreted as maximum likelihood training that assumes the amplitude and phase\nspectra of generated speech waveforms following Gaussian and von Mises\ndistributions, respectively. Furthermore, this paper presents a simple network\narchitecture as the speech waveform model, which is composed of uni-directional\nlong short-term memories (LSTMs) and an auto-regressive structure. Experimental\nresults showed that the proposed neural model synthesized high-quality speech\nwaveforms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 04:05:35 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 05:35:57 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Takaki", "Shinji", ""], ["Nakashika", "Toru", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1810.11946", "submitter": "Xin Wang", "authors": "Xin Wang, Shinji Takaki, Junichi Yamagishi", "title": "Neural source-filter-based waveform model for statistical parametric\n  speech synthesis", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural waveform models such as the WaveNet are used in many recent\ntext-to-speech systems, but the original WaveNet is quite slow in waveform\ngeneration because of its autoregressive (AR) structure. Although faster non-AR\nmodels were recently reported, they may be prohibitively complicated due to the\nuse of a distilling training method and the blend of other disparate training\ncriteria. This study proposes a non-AR neural source-filter waveform model that\ncan be directly trained using spectrum-based training criteria and the\nstochastic gradient descent method. Given the input acoustic features, the\nproposed model first uses a source module to generate a sine-based excitation\nsignal and then uses a filter module to transform the excitation signal into\nthe output speech waveform. Our experiments demonstrated that the proposed\nmodel generated waveforms at least 100 times faster than the AR WaveNet and the\nquality of its synthetic speech is close to that of speech generated by the AR\nWaveNet. Ablation test results showed that both the sine-wave excitation signal\nand the spectrum-based training criteria were essential to the performance of\nthe proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 04:10:40 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 00:16:54 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 07:17:59 GMT"}, {"version": "v4", "created": "Sat, 27 Apr 2019 02:00:59 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Wang", "Xin", ""], ["Takaki", "Shinji", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1810.11953", "submitter": "Stephan Rabanser", "authors": "Stephan Rabanser, Stephan G\\\"unnemann, Zachary C. Lipton", "title": "Failing Loudly: An Empirical Study of Methods for Detecting Dataset\n  Shift", "comments": "Advances in Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We might hope that when faced with unexpected inputs, well-designed software\nsystems would fire off warnings. Machine learning (ML) systems, however, which\ndepend strongly on properties of their inputs (e.g. the i.i.d. assumption),\ntend to fail silently. This paper explores the problem of building ML systems\nthat fail loudly, investigating methods for detecting dataset shift,\nidentifying exemplars that most typify the shift, and quantifying shift\nmalignancy. We focus on several datasets and various perturbations to both\ncovariates and label distributions with varying magnitudes and fractions of\ndata affected. Interestingly, we show that across the dataset shifts that we\nexplore, a two-sample-testing-based approach, using pre-trained classifiers for\ndimensionality reduction, performs best. Moreover, we demonstrate that\ndomain-discriminating approaches tend to be helpful for characterizing shifts\nqualitatively and determining if they are harmful.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 04:50:18 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 11:03:45 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 09:47:56 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 14:56:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Rabanser", "Stephan", ""], ["G\u00fcnnemann", "Stephan", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1810.11959", "submitter": "Geraci Joseph", "authors": "Siddhant Jain, Jalal Ziauddin, Paul Leonchyk, Joseph Geraci", "title": "An Amalgamation of Classical and Quantum Machine Learning For the\n  Classification of Adenocarcinoma and Squamous Cell Carcinoma Patients", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately classify disease subtypes is of vital importance,\nespecially in oncology where this capability could have a life saving impact.\nHere we report a classification between two subtypes of non-small cell lung\ncancer, namely Adeno- carcinoma vs Squamous cell carcinoma. The data consists\nof approximately 20,000 gene expression values for each of 104 patients. The\ndata was curated from [1] [2]. We used an amalgamation of classical and and\nquantum machine learning models to successfully classify these patients. We\nutilized feature selection methods based on univariate statistics in addition\nto XGBoost [3]. A novel and proprietary data representation method developed by\none of the authors called QCrush was also used as it was designed to\nincorporate a maximal amount of information under the size constraints of the\nD-Wave quantum annealing computer. The machine learning was performed by a\nQuantum Boltzmann Machine. This paper will report our results, the various\nclassical methods, and the quantum machine learning approach we utilized.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 05:22:51 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jain", "Siddhant", ""], ["Ziauddin", "Jalal", ""], ["Leonchyk", "Paul", ""], ["Geraci", "Joseph", ""]]}, {"id": "1810.11960", "submitter": "Yusuke Yasuda", "authors": "Yusuke Yasuda, Xin Wang, Shinji Takaki, Junichi Yamagishi", "title": "Investigation of enhanced Tacotron text-to-speech synthesis systems with\n  self-attention for pitch accent language", "comments": "to be appeared at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  End-to-end speech synthesis is a promising approach that directly converts\nraw text to speech. Although it was shown that Tacotron2 outperforms classical\npipeline systems with regards to naturalness in English, its applicability to\nother languages is still unknown. Japanese could be one of the most difficult\nlanguages for which to achieve end-to-end speech synthesis, largely due to its\ncharacter diversity and pitch accents. Therefore, state-of-the-art systems are\nstill based on a traditional pipeline framework that requires a separate text\nanalyzer and duration model. Towards end-to-end Japanese speech synthesis, we\nextend Tacotron to systems with self-attention to capture long-term\ndependencies related to pitch accents and compare their audio quality with\nclassical pipeline systems under various conditions to show their pros and\ncons. In a large-scale listening test, we investigated the impacts of the\npresence of accentual-type labels, the use of force or predicted alignments,\nand acoustic features used as local condition parameters of the Wavenet\nvocoder. Our results reveal that although the proposed systems still do not\nmatch the quality of a top-line pipeline system for Japanese, we show important\nstepping stones towards end-to-end Japanese speech synthesis.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 05:25:21 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 09:27:41 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Yasuda", "Yusuke", ""], ["Wang", "Xin", ""], ["Takaki", "Shinji", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1810.11971", "submitter": "Yucen Luo", "authors": "Yucen Luo, Tian Tian, Jiaxin Shi, Jun Zhu, Bo Zhang", "title": "Semi-crowdsourced Clustering with Deep Generative Models", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the semi-supervised clustering problem where crowdsourcing\nprovides noisy information about the pairwise comparisons on a small subset of\ndata, i.e., whether a sample pair is in the same cluster. We propose a new\napproach that includes a deep generative model (DGM) to characterize low-level\nfeatures of the data, and a statistical relational model for noisy pairwise\nannotations on its subset. The two parts share the latent variables. To make\nthe model automatically trade-off between its complexity and fitting data, we\nalso develop its fully Bayesian variant. The challenge of inference is\naddressed by fast (natural-gradient) stochastic variational inference\nalgorithms, where we effectively combine variational message passing for the\nrelational part and amortized learning of the DGM under a unified framework.\nEmpirical results on synthetic and real-world datasets show that our model\noutperforms previous crowdsourced clustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 06:24:24 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Luo", "Yucen", ""], ["Tian", "Tian", ""], ["Shi", "Jiaxin", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1810.11975", "submitter": "Anirban Laha", "authors": "Anirban Laha, Saneem A. Chemmengath, Priyanka Agrawal, Mitesh M.\n  Khapra, Karthik Sankaranarayanan, Harish G. Ramaswamy", "title": "On Controllable Sparse Alternatives to Softmax", "comments": "To appear in NIPS 2018, Total 16 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Converting an n-dimensional vector to a probability distribution over n\nobjects is a commonly used component in many machine learning tasks like\nmulticlass classification, multilabel classification, attention mechanisms etc.\nFor this, several probability mapping functions have been proposed and employed\nin literature such as softmax, sum-normalization, spherical softmax, and\nsparsemax, but there is very little understanding in terms how they relate with\neach other. Further, none of the above formulations offer an explicit control\nover the degree of sparsity. To address this, we develop a unified framework\nthat encompasses all these formulations as special cases. This framework\nensures simple closed-form solutions and existence of sub-gradients suitable\nfor learning via backpropagation. Within this framework, we propose two novel\nsparse formulations, sparsegen-lin and sparsehourglass, that seek to provide a\ncontrol over the degree of desired sparsity. We further develop novel convex\nloss functions that help induce the behavior of aforementioned formulations in\nthe multilabel classification setting, showing improved performance. We also\ndemonstrate empirically that the proposed formulations, when used to compute\nattention weights, achieve better or comparable performance on standard seq2seq\ntasks like neural machine translation and abstractive summarization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 06:46:37 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 19:02:13 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Laha", "Anirban", ""], ["Chemmengath", "Saneem A.", ""], ["Agrawal", "Priyanka", ""], ["Khapra", "Mitesh M.", ""], ["Sankaranarayanan", "Karthik", ""], ["Ramaswamy", "Harish G.", ""]]}, {"id": "1810.11977", "submitter": "Haibin Chang", "authors": "Haibin Chang and Dongxiao Zhang", "title": "Identification of physical processes via combined data-driven and\n  data-assimilation methods", "comments": null, "journal-ref": "Journal of Computational Physics. 2019, 393, 337-350", "doi": "10.1016/j.jcp.2019.05.008", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of modern data collection and storage technologies,\ndata-driven approaches have been developed for discovering the governing\npartial differential equations (PDE) of physical problems. However, in the\nextant works the model parameters in the equations are either assumed to be\nknown or have a linear dependency. Therefore, most of the realistic physical\nprocesses cannot be identified with the current data-driven PDE discovery\napproaches. In this study, an innovative framework is developed that combines\ndata-driven and data-assimilation methods for simultaneously identifying\nphysical processes and inferring model parameters. Spatiotemporal measurement\ndata are first divided into a training data set and a testing data set. Using\nthe training data set, a data-driven method is developed to learn the governing\nequation of the considered physical problem by identifying the occurred (or\ndominated) processes and selecting the proper empirical model. Through\nintroducing a prediction error of the learned governing equation for the\ntesting data set, a data-assimilation method is devised to estimate the\nuncertain model parameters of the selected empirical model. For the contaminant\ntransport problem investigated, the results demonstrate that the proposed\nmethod can adequately identify the considered physical processes via\nconcurrently discovering the corresponding governing equations and inferring\nuncertain parameters of nonlinear models, even in the presence of measurement\nerrors. This work helps to broaden the applicable area of the research of data\ndriven discovery of governing equations of physical problems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 07:12:01 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "1810.12042", "submitter": "Marius Mosbach", "authors": "Marius Mosbach, Maksym Andriushchenko, Thomas Trost, Matthias Hein,\n  Dietrich Klakow", "title": "Logit Pairing Methods Can Fool Gradient-Based Attacks", "comments": "Accepted to NeurIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Kannan et al. [2018] proposed several logit regularization methods\nto improve the adversarial robustness of classifiers. We show that the\ncomputationally fast methods they propose - Clean Logit Pairing (CLP) and Logit\nSqueezing (LSQ) - just make the gradient-based optimization problem of crafting\nadversarial examples harder without providing actual robustness. We find that\nAdversarial Logit Pairing (ALP) may indeed provide robustness against\nadversarial examples, especially when combined with adversarial training, and\nwe examine it in a variety of settings. However, the increase in adversarial\naccuracy is much smaller than previously claimed. Finally, our results suggest\nthat the evaluation against an iterative PGD attack relies heavily on the\nparameters used and may result in false conclusions regarding robustness of a\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:30:20 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 16:08:33 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 08:13:30 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Mosbach", "Marius", ""], ["Andriushchenko", "Maksym", ""], ["Trost", "Thomas", ""], ["Hein", "Matthias", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1810.12065", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song", "title": "On the Convergence Rate of Training Recurrent Neural Networks", "comments": "V2/V3/V4 polish writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can local-search methods such as stochastic gradient descent (SGD) avoid\nbad local minima in training multi-layer neural networks? Why can they fit\nrandom labels even given non-convex and non-smooth architectures? Most existing\ntheory only covers networks with one hidden layer, so can we go deeper?\n  In this paper, we focus on recurrent neural networks (RNNs) which are\nmulti-layer networks widely used in natural language processing. They are\nharder to analyze than feedforward neural networks, because the $\\textit{same}$\nrecurrent unit is repeatedly applied across the entire time horizon of length\n$L$, which is analogous to feedforward networks of depth $L$. We show when the\nnumber of neurons is sufficiently large, meaning polynomial in the training\ndata size and in $L$, then SGD is capable of minimizing the regression loss in\nthe linear convergence rate. This gives theoretical evidence of how RNNs can\nmemorize data.\n  More importantly, in this paper we build general toolkits to analyze\nmulti-layer networks with ReLU activations. For instance, we prove why ReLU\nactivations can prevent exponential gradient explosion or vanishing, and build\na perturbation theory to analyze first-order approximation of multi-layer\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 11:45:02 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 15:25:15 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 11:47:47 GMT"}, {"version": "v4", "created": "Mon, 27 May 2019 10:08:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""], ["Song", "Zhao", ""]]}, {"id": "1810.12069", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Alexander Gepperth, Andrei Stoian, David Filliat", "title": "Marginal Replay vs Conditional Replay for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new replay-based method of continual classification learning\nthat we term \"conditional replay\" which generates samples and labels together\nby sampling from a distribution conditioned on the class. We compare\nconditional replay to another\n  replay-based continual learning paradigm (which we term \"marginal replay\")\nthat generates samples independently of their class and assigns labels in a\nseparate step.\n  The main improvement in conditional replay is that labels for generated\nsamples need not be inferred, which reduces the margin for error in complex\ncontinual classification learning tasks. We demonstrate the effectiveness of\nthis approach using novel and standard benchmarks constructed from MNIST and\nFashionMNIST data, and compare to the regularization-based \\textit{elastic\nweight consolidation} (EWC) method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 12:17:48 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 13:23:15 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 20:22:15 GMT"}, {"version": "v4", "created": "Sat, 29 Dec 2018 10:35:42 GMT"}, {"version": "v5", "created": "Wed, 23 Jan 2019 14:49:00 GMT"}, {"version": "v6", "created": "Mon, 1 Jul 2019 14:12:50 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["Gepperth", "Alexander", ""], ["Stoian", "Andrei", ""], ["Filliat", "David", ""]]}, {"id": "1810.12081", "submitter": "Lijun Wu", "authors": "Lijun Wu, Fei Tian, Yingce Xia, Yang Fan, Tao Qin, Jianhuang Lai,\n  Tie-Yan Liu", "title": "Learning to Teach with Dynamic Loss Functions", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching is critical to human society: it is with teaching that prospective\nstudents are educated and human civilization can be inherited and advanced. A\ngood teacher not only provides his/her students with qualified teaching\nmaterials (e.g., textbooks), but also sets up appropriate learning objectives\n(e.g., course projects and exams) considering different situations of a\nstudent. When it comes to artificial intelligence, treating machine learning\nmodels as students, the loss functions that are optimized act as perfect\ncounterparts of the learning objective set by the teacher. In this work, we\nexplore the possibility of imitating human teaching behaviors by dynamically\nand automatically outputting appropriate loss functions to train machine\nlearning models. Different from typical learning settings in which the loss\nfunction of a machine learning model is predefined and fixed, in our framework,\nthe loss function of a machine learning model (we call it student) is defined\nby another machine learning model (we call it teacher). The ultimate goal of\nteacher model is cultivating the student to have better performance measured on\ndevelopment dataset. Towards that end, similar to human teaching, the teacher,\na parametric model, dynamically outputs different loss functions that will be\nused and optimized by its student model at different training stages. We\ndevelop an efficient learning method for the teacher model that makes gradient\nbased optimization possible, exempt of the ineffective solutions such as policy\noptimization. We name our method as \"learning to teach with dynamic loss\nfunctions\" (L2T-DLF for short). Extensive experiments on real world tasks\nincluding image classification and neural machine translation demonstrate that\nour method significantly improves the quality of various student models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:03:38 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Wu", "Lijun", ""], ["Tian", "Fei", ""], ["Xia", "Yingce", ""], ["Fan", "Yang", ""], ["Qin", "Tao", ""], ["Lai", "Jianhuang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1810.12085", "submitter": "Emily Alsentzer", "authors": "Emily Alsentzer and Anne Kim", "title": "Extractive Summarization of EHR Discharge Notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient summarization is essential for clinicians to provide coordinated care\nand practice effective communication. Automated summarization has the potential\nto save time, standardize notes, aid clinical decision making, and reduce\nmedical errors. Here we provide an upper bound on extractive summarization of\ndischarge notes and develop an LSTM model to sequentially label topics of\nhistory of present illness notes. We achieve an F1 score of 0.876, which\nindicates that this model can be employed to create a dataset for evaluation of\nextractive summarization methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 16:36:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Alsentzer", "Emily", ""], ["Kim", "Anne", ""]]}, {"id": "1810.12091", "submitter": "Shelan Jeawak", "authors": "Shelan S. Jeawak, Christopher B. Jones, and Steven Schockaert", "title": "Embedding Geographic Locations for Modelling the Natural Environment\n  using Flickr Tags and Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-data from photo-sharing websites such as Flickr can be used to obtain\nrich bag-of-words descriptions of geographic locations, which have proven\nvaluable, among others, for modelling and predicting ecological features. One\nimportant insight from previous work is that the descriptions obtained from\nFlickr tend to be complementary to the structured information that is available\nfrom traditional scientific resources. To better integrate these two diverse\nsources of information, in this paper we consider a method for learning vector\nspace embeddings of geographic locations. We show experimentally that this\nmethod improves on existing approaches, especially in cases where structured\ninformation is available.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:22:34 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jeawak", "Shelan S.", ""], ["Jones", "Christopher B.", ""], ["Schockaert", "Steven", ""]]}, {"id": "1810.12125", "submitter": "Boyi Hou", "authors": "Boyi Hou, Qun Chen, Yanyan Wang, Youcef Nafa, Zhanhuai Li", "title": "Gradual Machine Learning for Entity Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually considered as a classification problem, entity resolution (ER) can be\nvery challenging on real data due to the prevalence of dirty values. The\nstate-of-the-art solutions for ER were built on a variety of learning models\n(most notably deep neural networks), which require lots of accurately labeled\ntraining data. Unfortunately, high-quality labeled data usually require\nexpensive manual work, and are therefore not readily available in many real\nscenarios. In this paper, we propose a novel learning paradigm for ER, called\ngradual machine learning, which aims to enable effective machine labeling\nwithout the requirement for manual labeling effort. It begins with some easy\ninstances in a task, which can be automatically labeled by the machine with\nhigh accuracy, and then gradually labels more challenging instances by\niterative factor graph inference. In gradual machine learning, the hard\ninstances in a task are gradually labeled in small stages based on the\nestimated evidential certainty provided by the labeled easier instances. Our\nextensive experiments on real data have shown that the performance of the\nproposed approach is considerably better than its unsupervised alternatives,\nand highly competitive compared to the state-of-the-art supervised techniques.\nUsing ER as a test case, we demonstrate that gradual machine learning is a\npromising paradigm potentially applicable to other challenging classification\ntasks requiring extensive labeling effort.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:47:52 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 11:58:22 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2019 08:40:51 GMT"}, {"version": "v4", "created": "Fri, 14 Jun 2019 01:12:48 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Hou", "Boyi", ""], ["Chen", "Qun", ""], ["Wang", "Yanyan", ""], ["Nafa", "Youcef", ""], ["Li", "Zhanhuai", ""]]}, {"id": "1810.12136", "submitter": "St\\'ephane Mallat", "authors": "St\\'ephane Mallat, Sixin Zhang, Gaspar Rochette", "title": "Phase Harmonic Correlations and Convolutional Neural Networks", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major issue in harmonic analysis is to capture the phase dependence of\nfrequency representations, which carries important signal properties. It seems\nthat convolutional neural networks have found a way. Over time-series and\nimages, convolutional networks often learn a first layer of filters which are\nwell localized in the frequency domain, with different phases. We show that a\nrectifier then acts as a filter on the phase of the resulting coefficients. It\ncomputes signal descriptors which are local in space, frequency and phase. The\nnon-linear phase filter becomes a multiplicative operator over phase harmonics\ncomputed with a Fourier transform along the phase. We prove that it defines a\nbi-Lipschitz and invertible representation. The correlations of phase harmonics\ncoefficients characterise coherent structures from their phase dependence\nacross frequencies. For wavelet filters, we show numerically that signals\nhaving sparse wavelet coefficients can be recovered from few phase harmonic\ncorrelations, which provide a compressive representation\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:12:09 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 14:02:45 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mallat", "St\u00e9phane", ""], ["Zhang", "Sixin", ""], ["Rochette", "Gaspar", ""]]}, {"id": "1810.12153", "submitter": "Matthew Matlock", "authors": "Matthew K. Matlock, Arghya Datta, Na Le Dang, Kevin Jiang, S. Joshua\n  Swamidass", "title": "Deep learning long-range information in undirected graphs with wave\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph algorithms are key tools in many fields of science and technology. Some\nof these algorithms depend on propagating information between distant nodes in\na graph. Recently, there have been a number of deep learning architectures\nproposed to learn on undirected graphs. However, most of these architectures\naggregate information in the local neighborhood of a node, and therefore they\nmay not be capable of efficiently propagating long-range information. To solve\nthis problem we examine a recently proposed architecture, wave, which\npropagates information back and forth across an undirected graph in waves of\nnonlinear computation. We compare wave to graph convolution, an architecture\nbased on local aggregation, and find that wave learns three different\ngraph-based tasks with greater efficiency and accuracy. These three tasks\ninclude (1) labeling a path connecting two nodes in a graph, (2) solving a maze\npresented as an image, and (3) computing voltages in a circuit. These tasks\nrange from trivial to very difficult, but wave can extrapolate from small\ntraining examples to much larger testing examples. These results show that wave\nmay be able to efficiently solve a wide range of problems that require\nlong-range information propagation across undirected graphs. An implementation\nof the wave network, and example code for the maze problem are included in the\ntflon deep learning toolkit (https://bitbucket.org/mkmatlock/tflon).\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:35:40 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Matlock", "Matthew K.", ""], ["Datta", "Arghya", ""], ["Dang", "Na Le", ""], ["Jiang", "Kevin", ""], ["Swamidass", "S. Joshua", ""]]}, {"id": "1810.12161", "submitter": "Faicel Chamroukhi", "authors": "Faicel Chamroukhi and Bao-Tuyen Huynh", "title": "Regularized Maximum Likelihood Estimation and Feature Selection in\n  Mixtures-of-Experts Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture of Experts (MoE) are successful models for modeling heterogeneous\ndata in many statistical learning problems including regression, clustering and\nclassification. Generally fitted by maximum likelihood estimation via the\nwell-known EM algorithm, their application to high-dimensional problems is\nstill therefore challenging. We consider the problem of fitting and feature\nselection in MoE models, and propose a regularized maximum likelihood\nestimation approach that encourages sparse solutions for heterogeneous\nregression data models with potentially high-dimensional predictors. Unlike\nstate-of-the art regularized MLE for MoE, the proposed modelings do not require\nan approximate of the penalty function. We develop two hybrid EM algorithms: an\nExpectation-Majorization-Maximization (EM/MM) algorithm, and an EM algorithm\nwith coordinate ascent algorithm. The proposed algorithms allow to\nautomatically obtaining sparse solutions without thresholding, and avoid matrix\ninversion by allowing univariate parameter updates. An experimental study shows\nthe good performance of the algorithms in terms of recovering the actual sparse\nsolutions, parameter estimation, and clustering of heterogeneous regression\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:42:04 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chamroukhi", "Faicel", ""], ["Huynh", "Bao-Tuyen", ""]]}, {"id": "1810.12162", "submitter": "Pranav Shyam", "authors": "Pranav Shyam, Wojciech Ja\\'skowski, Faustino Gomez", "title": "Model-Based Active Exploration", "comments": "ICML 2019. Code: https://github.com/nnaisense/max", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is an unsolved problem in Reinforcement Learning which\nis usually addressed by reactively rewarding the agent for fortuitously\nencountering novel situations. This paper introduces an efficient active\nexploration algorithm, Model-Based Active eXploration (MAX), which uses an\nensemble of forward models to plan to observe novel events. This is carried out\nby optimizing agent behaviour with respect to a measure of novelty derived from\nthe Bayesian perspective of exploration, which is estimated using the\ndisagreement between the futures predicted by the ensemble members. We show\nempirically that in semi-random discrete environments where directed\nexploration is critical to make progress, MAX is at least an order of magnitude\nmore efficient than strong baselines. MAX scales to high-dimensional continuous\nenvironments where it builds task-agnostic models that can be used for any\ndownstream task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:43:48 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 11:22:22 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 18:00:02 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 20:58:53 GMT"}, {"version": "v5", "created": "Thu, 13 Jun 2019 19:33:27 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Shyam", "Pranav", ""], ["Ja\u015bkowski", "Wojciech", ""], ["Gomez", "Faustino", ""]]}, {"id": "1810.12165", "submitter": "Luana Ruiz", "authors": "Luana Ruiz, Fernando Gama, Antonio G. Marques, Alejandro Ribeiro", "title": "Median activation functions for graph neural networks", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been shown to replicate convolutional\nneural networks' (CNNs) superior performance in many problems involving graphs.\nBy replacing regular convolutions with linear shift-invariant graph filters\n(LSI-GFs), GNNs take into account the (irregular) structure of the graph and\nprovide meaningful representations of network data. However, LSI-GFs fail to\nencode local nonlinear graph signal behavior, and so do regular activation\nfunctions, which are nonlinear but pointwise. To address this issue, we propose\nmedian activation functions with support on graph neighborhoods instead of\nindividual nodes. A GNN architecture with a trainable multirresolution version\nof this activation function is then tested on synthetic and real-word datasets,\nwhere we show that median activation functions can improve GNN capacity with\nmarginal increase in complexity.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 14:53:56 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 18:45:56 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Ruiz", "Luana", ""], ["Gama", "Fernando", ""], ["Marques", "Antonio G.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1810.12176", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Aiden Doherty, Stephen Roberts and Chris Holmes", "title": "Semi-unsupervised Learning of Human Activity using Deep Generative\n  Models", "comments": "4 pages, 2 figures, conference workshop pre-print Machine Learning\n  for Health (ML4H) Workshop at NeurIPS 2018 arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/94", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce 'semi-unsupervised learning', a problem regime related to\ntransfer learning and zero-shot learning where, in the training data, some\nclasses are sparsely labelled and others entirely unlabelled. Models able to\nlearn from training data of this type are potentially of great use as many\nreal-world datasets are like this. Here we demonstrate a new deep generative\nmodel for classification in this regime. Our model, a Gaussian mixture deep\ngenerative model, demonstrates superior semi-unsupervised classification\nperformance on MNIST to model M2 from Kingma and Welling (2014). We apply the\nmodel to human accelerometer data, performing activity classification and\nstructure discovery on windows of time series data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:06:43 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 12:48:45 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Willetts", "Matthew", ""], ["Doherty", "Aiden", ""], ["Roberts", "Stephen", ""], ["Holmes", "Chris", ""]]}, {"id": "1810.12177", "submitter": "Sebastien Marmin", "authors": "S\\'ebastien Marmin, Maurizio Filippone", "title": "Variational Calibration of Computer Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian calibration of black-box computer models offers an established\nframework to obtain a posterior distribution over model parameters. Traditional\nBayesian calibration involves the emulation of the computer model and an\nadditive model discrepancy term using Gaussian processes; inference is then\ncarried out using MCMC. These choices pose computational and statistical\nchallenges and limitations, which we overcome by proposing the use of\napproximate Deep Gaussian processes and variational inference techniques. The\nresult is a practical and scalable framework for calibration, which obtains\ncompetitive performance compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:07:07 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Marmin", "S\u00e9bastien", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1810.12188", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Lihong Li, Yuzhe Ma, Xiaojin Zhu", "title": "Adversarial Attacks on Stochastic Bandits", "comments": "accepted to NIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial attacks that manipulate the reward signals to control\nthe actions chosen by a stochastic multi-armed bandit algorithm. We propose the\nfirst attack against two popular bandit algorithms: $\\epsilon$-greedy and UCB,\n\\emph{without} knowledge of the mean rewards. The attacker is able to spend\nonly logarithmic effort, multiplied by a problem-specific parameter that\nbecomes smaller as the bandit problem gets easier to attack. The result means\nthe attacker can easily hijack the behavior of the bandit algorithm to promote\nor obstruct certain actions, say, a particular medical treatment. As bandits\nare seeing increasingly wide use in practice, our study exposes a significant\nsecurity threat.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:28:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Li", "Lihong", ""], ["Ma", "Yuzhe", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1810.12228", "submitter": "Pei Cao", "authors": "Pei Cao, Qi Shuai and Jiong Tang", "title": "Leveraging Gaussian Process and Voting-Empowered Many-Objective\n  Evaluation for Fault Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using piezoelectric impedance/admittance sensing for structural health\nmonitoring is promising, owing to the simplicity in circuitry design as well as\nthe high-frequency interrogation capability. The actual identification of fault\nlocation and severity using impedance/admittance measurements, nevertheless,\nremains to be an extremely challenging task. A first-principle based structural\nmodel using finite element discretization requires high dimensionality to\ncharacterize the high-frequency response. As such, direct inversion using the\nsensitivity matrix usually yields an under-determined problem. Alternatively,\nthe identification problem may be cast into an optimization framework in which\nfault parameters are identified through repeated forward finite element\nanalysis which however is oftentimes computationally prohibitive. This paper\npresents an efficient data-assisted optimization approach for fault\nidentification without using finite element model iteratively. We formulate a\nmany-objective optimization problem to identify fault parameters, where\nresponse surfaces of impedance measurements are constructed through Gaussian\nprocess-based calibration. To balance between solution diversity and\nconvergence, an -dominance enabled many-objective simulated annealing algorithm\nis established. As multiple solutions are expected, a voting score calculation\nprocedure is developed to further identify those solutions that yield better\nimplications regarding structural health condition. The effectiveness of the\nproposed approach is demonstrated by systematic numerical and experimental case\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 16:15:45 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Cao", "Pei", ""], ["Shuai", "Qi", ""], ["Tang", "Jiong", ""]]}, {"id": "1810.12233", "submitter": "Charlie Rogers-Smith", "authors": "Charlie Rogers-Smith, Henri Pesonen and Samuel Kaski", "title": "Approximate Bayesian Computation via Population Monte Carlo and\n  Classification", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximate Bayesian computation (ABC) methods can be used to sample from\nposterior distributions when the likelihood function is unavailable or\nintractable, as is often the case in biological systems. ABC methods suffer\nfrom inefficient particle proposals in high dimensions, and subjectivity in the\nchoice of summary statistics, discrepancy measure, and error tolerance.\nSequential Monte Carlo (SMC) methods have been combined with ABC to improve the\nefficiency of particle proposals, but suffer from subjectivity and require many\nsimulations from the likelihood function. Likelihood-Free Inference by Ratio\nEstimation (LFIRE) leverages classification to estimate the posterior density\ndirectly but does not explore the parameter space efficiently. This work\nproposes a classification approach that approximates population Monte Carlo\n(PMC), where model class probabilities from classification are used to update\nparticle weights. This approach, called Classification-PMC, blends adaptive\nproposals and classification, efficiently producing samples from the posterior\nwithout subjectivity. We show through a simulation study that\nClassification-PMC outperforms two state-of-the-art methods: ratio estimation\nand SMC ABC when it is computationally difficult to simulate from the\nlikelihood.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 16:22:17 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 14:07:59 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Rogers-Smith", "Charlie", ""], ["Pesonen", "Henri", ""], ["Kaski", "Samuel", ""]]}, {"id": "1810.12247", "submitter": "Curtis Hawthorne", "authors": "Curtis Hawthorne, Andriy Stasyuk, Adam Roberts, Ian Simon, Cheng-Zhi\n  Anna Huang, Sander Dieleman, Erich Elsen, Jesse Engel, Douglas Eck", "title": "Enabling Factorized Piano Music Modeling and Generation with the MAESTRO\n  Dataset", "comments": "Examples available at https://goo.gl/magenta/maestro-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating musical audio directly with neural networks is notoriously\ndifficult because it requires coherently modeling structure at many different\ntimescales. Fortunately, most music is also highly structured and can be\nrepresented as discrete note events played on musical instruments. Herein, we\nshow that by using notes as an intermediate representation, we can train a\nsuite of models capable of transcribing, composing, and synthesizing audio\nwaveforms with coherent musical structure on timescales spanning six orders of\nmagnitude (~0.1 ms to ~100 s), a process we call Wave2Midi2Wave. This large\nadvance in the state of the art is enabled by our release of the new MAESTRO\n(MIDI and Audio Edited for Synchronous TRacks and Organization) dataset,\ncomposed of over 172 hours of virtuosic piano performances captured with fine\nalignment (~3 ms) between note labels and audio waveforms. The networks and the\ndataset together present a promising approach toward creating new expressive\nand interpretable neural models of music.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 16:48:53 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 18:54:40 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 19:43:32 GMT"}, {"version": "v4", "created": "Sat, 12 Jan 2019 01:27:00 GMT"}, {"version": "v5", "created": "Thu, 17 Jan 2019 19:45:00 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Hawthorne", "Curtis", ""], ["Stasyuk", "Andriy", ""], ["Roberts", "Adam", ""], ["Simon", "Ian", ""], ["Huang", "Cheng-Zhi Anna", ""], ["Dieleman", "Sander", ""], ["Elsen", "Erich", ""], ["Engel", "Jesse", ""], ["Eck", "Douglas", ""]]}, {"id": "1810.12263", "submitter": "David Reeb", "authors": "David Reeb, Andreas Doerr, Sebastian Gerwinn, Barbara Rakitsch", "title": "Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization\n  Bounds", "comments": "11 pages main text, 12 pages appendix. v2: minor changes, new NeurIPS\n  style file. Final camera-ready version submitted to NeurIPS 2018", "journal-ref": "Advances in Neural Information Processing Systems 31 (Proceedings\n  of the NeurIPS Conference 2018),\n  https://papers.nips.cc/paper/7594-learning-gaussian-processes-by-minimizing-pac-bayesian-generalization-bounds", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) are a generic modelling tool for supervised\nlearning. While they have been successfully applied on large datasets, their\nuse in safety-critical applications is hindered by the lack of good performance\nguarantees. To this end, we propose a method to learn GPs and their sparse\napproximations by directly optimizing a PAC-Bayesian bound on their\ngeneralization performance, instead of maximizing the marginal likelihood.\nBesides its theoretical appeal, we find in our evaluation that our learning\nmethod is robust and yields significantly better generalization guarantees than\nother common GP approaches on several regression benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:21:50 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 11:48:46 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Reeb", "David", ""], ["Doerr", "Andreas", ""], ["Gerwinn", "Sebastian", ""], ["Rakitsch", "Barbara", ""]]}, {"id": "1810.12272", "submitter": "Dimitrios Diochnos", "authors": "Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Adversarial Risk and Robustness: General Definitions and Implications\n  for the Uniform Distribution", "comments": "Full version of a work with the same title that will appear in NIPS\n  2018, 31 pages containing 5 figures, 1 table, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial perturbations when the instances are uniformly\ndistributed over $\\{0,1\\}^n$. We study both \"inherent\" bounds that apply to any\nproblem and any classifier for such a problem as well as bounds that apply to\nspecific problems and specific hypothesis classes.\n  As the current literature contains multiple definitions of adversarial risk\nand robustness, we start by giving a taxonomy for these definitions based on\ntheir goals, we identify one of them as the one guaranteeing misclassification\nby pushing the instances to the error region. We then study some classic\nalgorithms for learning monotone conjunctions and compare their adversarial\nrisk and robustness under different definitions by attacking the hypotheses\nusing instances drawn from the uniform distribution. We observe that sometimes\nthese definitions lead to significantly different bounds. Thus, this study\nadvocates for the use of the error-region definition, even though other\ndefinitions, in other contexts, may coincide with the error-region definition.\n  Using the error-region definition of adversarial perturbations, we then study\ninherent bounds on risk and robustness of any classifier for any classification\nproblem whose instances are uniformly distributed over $\\{0,1\\}^n$. Using the\nisoperimetric inequality for the Boolean hypercube, we show that for initial\nerror $0.01$, there always exists an adversarial perturbation that changes\n$O(\\sqrt{n})$ bits of the instances to increase the risk to $0.5$, making\nclassifier's decisions meaningless. Furthermore, by also using the central\nlimit theorem we show that when $n\\to \\infty$, at most $c \\cdot \\sqrt{n}$ bits\nof perturbations, for a universal constant $c< 1.17$, suffice for increasing\nthe risk to $0.5$, and the same $c \\cdot \\sqrt{n} $ bits of perturbations on\naverage suffice to increase the risk to $1$, hence bounding the robustness by\n$c \\cdot \\sqrt{n}$.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:41:29 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Diochnos", "Dimitrios I.", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1810.12273", "submitter": "James Vuckovic", "authors": "James Vuckovic", "title": "Kalman Gradient Descent: Adaptive Variance Reduction in Stochastic\n  Optimization", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Kalman Gradient Descent, a stochastic optimization algorithm\nthat uses Kalman filtering to adaptively reduce gradient variance in stochastic\ngradient descent by filtering the gradient estimates. We present both a\ntheoretical analysis of convergence in a non-convex setting and experimental\nresults which demonstrate improved performance on a variety of machine learning\nareas including neural networks and black box variational inference. We also\npresent a distributed version of our algorithm that enables large-dimensional\noptimization, and we extend our algorithm to SGD with momentum and RMSProp.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:42:39 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Vuckovic", "James", ""]]}, {"id": "1810.12278", "submitter": "Ethan Rudd", "authors": "Richard Harang and Ethan M. Rudd", "title": "Towards Principled Uncertainty Estimation for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the cost of misclassifying a sample is high, it is useful to have an\naccurate estimate of uncertainty in the prediction for that sample. There are\nalso multiple types of uncertainty which are best estimated in different ways,\nfor example, uncertainty that is intrinsic to the training set may be\nwell-handled by a Bayesian approach, while uncertainty introduced by shifts\nbetween training and query distributions may be better-addressed by\ndensity/support estimation. In this paper, we examine three types of\nuncertainty: model capacity uncertainty, intrinsic data uncertainty, and open\nset uncertainty, and review techniques that have been derived to address each\none. We then introduce a unified hierarchical model, which combines methods\nfrom Bayesian inference, invertible latent density inference, and\ndiscriminative classification in a single end-to-end deep neural network\ntopology to yield efficient per-sample uncertainty estimation in a detection\ncontext. This approach addresses all three uncertainty types and can readily\naccommodate prior/base rates for binary detection. We then discuss how to\nextend this model to a more generic multiclass recognition context.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:46:55 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 23:37:03 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Harang", "Richard", ""], ["Rudd", "Ethan M.", ""]]}, {"id": "1810.12281", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Chaoqi Wang, Bowen Xu, Roger Grosse", "title": "Three Mechanisms of Weight Decay Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight decay is one of the standard tricks in the neural network toolbox, but\nthe reasons for its regularization effect are poorly understood, and recent\nresults have cast doubt on the traditional interpretation in terms of $L_2$\nregularization. Literal weight decay has been shown to outperform $L_2$\nregularization for optimizers for which they differ. We empirically investigate\nweight decay for three optimization algorithms (SGD, Adam, and K-FAC) and a\nvariety of network architectures. We identify three distinct mechanisms by\nwhich weight decay exerts a regularization effect, depending on the particular\noptimization algorithm and architecture: (1) increasing the effective learning\nrate, (2) approximately regularizing the input-output Jacobian norm, and (3)\nreducing the effective damping coefficient for second-order optimization. Our\nresults provide insight into how to improve the regularization of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:51:25 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhang", "Guodong", ""], ["Wang", "Chaoqi", ""], ["Xu", "Bowen", ""], ["Grosse", "Roger", ""]]}, {"id": "1810.12282", "submitter": "Katelyn Gao", "authors": "Charles Packer, Katelyn Gao, Jernej Kos, Philipp Kr\\\"ahenb\\\"uhl,\n  Vladlen Koltun, Dawn Song", "title": "Assessing Generalization in Deep Reinforcement Learning", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved breakthrough results on many\ntasks, but agents often fail to generalize beyond the environment they were\ntrained in. As a result, deep RL algorithms that promote generalization are\nreceiving increasing attention. However, works in this area use a wide variety\nof tasks and experimental setups for evaluation. The literature lacks a\ncontrolled assessment of the merits of different generalization schemes. Our\naim is to catalyze community-wide progress on generalization in deep RL. To\nthis end, we present a benchmark and experimental protocol, and conduct a\nsystematic empirical study. Our framework contains a diverse set of\nenvironments, our methodology covers both in-distribution and\nout-of-distribution generalization, and our evaluation includes deep RL\nalgorithms that specifically tackle generalization. Our key finding is that\n`vanilla' deep RL algorithms generalize better than specialized schemes that\nwere proposed specifically to tackle generalization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:51:46 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 17:58:23 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Packer", "Charles", ""], ["Gao", "Katelyn", ""], ["Kos", "Jernej", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Koltun", "Vladlen", ""], ["Song", "Dawn", ""]]}, {"id": "1810.12283", "submitter": "David Eriksson", "authors": "David Eriksson, Kun Dong, Eric Hans Lee, David Bindel, Andrew Gordon\n  Wilson", "title": "Scaling Gaussian Process Regression with Derivatives", "comments": "Appears at Advances in Neural Information Processing Systems 32\n  (NIPS), 2018", "journal-ref": "Advances in Neural Information Processing Systems 32 (NIPS), 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) with derivatives are useful in many applications,\nincluding Bayesian optimization, implicit surface reconstruction, and terrain\nreconstruction. Fitting a GP to function values and derivatives at $n$ points\nin $d$ dimensions requires linear solves and log determinants with an ${n(d+1)\n\\times n(d+1)}$ positive definite matrix -- leading to prohibitive\n$\\mathcal{O}(n^3d^3)$ computations for standard direct methods. We propose\niterative solvers using fast $\\mathcal{O}(nd)$ matrix-vector multiplications\n(MVMs), together with pivoted Cholesky preconditioning that cuts the iterations\nto convergence by several orders of magnitude, allowing for fast kernel\nlearning and prediction. Our approaches, together with dimensionality\nreduction, enables Bayesian optimization with derivatives to scale to\nhigh-dimensional problems and large evaluation budgets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:51:54 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Eriksson", "David", ""], ["Dong", "Kun", ""], ["Lee", "Eric Hans", ""], ["Bindel", "David", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1810.12361", "submitter": "Murat A. Erdogdu", "authors": "Murat A. Erdogdu, Lester Mackey, Ohad Shamir", "title": "Global Non-convex Optimization with Discretized Diffusions", "comments": "19 pages, NeurIPS 2018 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Euler discretization of the Langevin diffusion is known to converge to the\nglobal minimizers of certain convex and non-convex optimization problems. We\nshow that this property holds for any suitably smooth diffusion and that\ndifferent diffusions are suitable for optimizing different classes of convex\nand non-convex functions. This allows us to design diffusions suitable for\nglobally optimizing convex and non-convex functions not covered by the existing\nLangevin theory. Our non-asymptotic analysis delivers computable optimization\nand integration error bounds based on easily accessed properties of the\nobjective and chosen diffusion. Central to our approach are new explicit Stein\nfactor bounds on the solutions of Poisson equations. We complement these\nresults with improved optimization guarantees for targets other than the\nstandard Gibbs measure.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:09:23 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 08:28:28 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Erdogdu", "Murat A.", ""], ["Mackey", "Lester", ""], ["Shamir", "Ohad", ""]]}, {"id": "1810.12369", "submitter": "Siddarth Srinivasan", "authors": "Siddarth Srinivasan, Carlton Downey, Byron Boots", "title": "Learning and Inference in Hilbert Space with Quantum Graphical Models", "comments": "13 pages total, 9 pages content, 3 pages appendix; NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Graphical Models (QGMs) generalize classical graphical models by\nadopting the formalism for reasoning about uncertainty from quantum mechanics.\nUnlike classical graphical models, QGMs represent uncertainty with density\nmatrices in complex Hilbert spaces. Hilbert space embeddings (HSEs) also\ngeneralize Bayesian inference in Hilbert spaces. We investigate the link\nbetween QGMs and HSEs and show that the sum rule and Bayes rule for QGMs are\nequivalent to the kernel sum rule in HSEs and a special case of Nadaraya-Watson\nkernel regression, respectively. We show that these operations can be\nkernelized, and use these insights to propose a Hilbert Space Embedding of\nHidden Quantum Markov Models (HSE-HQMM) to model dynamics. We present\nexperimental results showing that HSE-HQMMs are competitive with\nstate-of-the-art models like LSTMs and PSRNNs on several datasets, while also\nproviding a nonparametric method for maintaining a probability distribution\nover continuous-valued features.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:22:49 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Srinivasan", "Siddarth", ""], ["Downey", "Carlton", ""], ["Boots", "Byron", ""]]}, {"id": "1810.12399", "submitter": "Jinsong Wu", "authors": "Rachad Atat, Lingjia Liu, Jinsong Wu, Guangyu Li, Chunxuan Ye, Yang Yi", "title": "Big Data Meet Cyber-Physical Systems: A Panoramic Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The world is witnessing an unprecedented growth of cyber-physical systems\n(CPS), which are foreseen to revolutionize our world {via} creating new\nservices and applications in a variety of sectors such as environmental\nmonitoring, mobile-health systems, intelligent transportation systems and so\non. The {information and communication technology }(ICT) sector is experiencing\na significant growth in { data} traffic, driven by the widespread usage of\nsmartphones, tablets and video streaming, along with the significant growth of\nsensors deployments that are anticipated in the near future. {It} is expected\nto outstandingly increase the growth rate of raw sensed data. In this paper, we\npresent the CPS taxonomy {via} providing a broad overview of data collection,\nstorage, access, processing and analysis. Compared with other survey papers,\nthis is the first panoramic survey on big data for CPS, where our objective is\nto provide a panoramic summary of different CPS aspects. Furthermore, CPS\n{require} cybersecurity to protect {them} against malicious attacks and\nunauthorized intrusion, which {become} a challenge with the enormous amount of\ndata that is continuously being generated in the network. {Thus, we also}\nprovide an overview of the different security solutions proposed for CPS big\ndata storage, access and analytics. We also discuss big data meeting green\nchallenges in the contexts of CPS.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 20:41:47 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Atat", "Rachad", ""], ["Liu", "Lingjia", ""], ["Wu", "Jinsong", ""], ["Li", "Guangyu", ""], ["Ye", "Chunxuan", ""], ["Yi", "Yang", ""]]}, {"id": "1810.12406", "submitter": "Patrick Chen", "authors": "Patrick H. Chen, Si Si, Sanjiv Kumar, Yang Li, Cho-Jui Hsieh", "title": "Learning to Screen for Fast Softmax Inference on Large Vocabulary Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models have been widely used in various NLP tasks, including\nmachine translation, next word prediction and conversational agents. However,\nit is challenging to deploy these models on mobile devices due to their slow\nprediction speed, where the bottleneck is to compute top candidates in the\nsoftmax layer. In this paper, we introduce a novel softmax layer approximation\nalgorithm by exploiting the clustering structure of context vectors. Our\nalgorithm uses a light-weight screening model to predict a much smaller set of\ncandidate words based on the given context, and then conducts an exact softmax\nonly within that subset. Training such a procedure end-to-end is challenging as\ntraditional clustering methods are discrete and non-differentiable, and thus\nunable to be used with back-propagation in the training process. Using the\nGumbel softmax, we are able to train the screening model end-to-end on the\ntraining set to exploit data distribution. The algorithm achieves an order of\nmagnitude faster inference than the original softmax layer for predicting\ntop-$k$ words in various tasks such as beam search in machine translation or\nnext words prediction. For example, for machine translation task on German to\nEnglish dataset with around 25K vocabulary, we can achieve 20.4 times speed up\nwith 98.9\\% precision@1 and 99.3\\% precision@5 with the original softmax layer\nprediction, while state-of-the-art ~\\citep{MSRprediction} only achieves 6.7x\nspeedup with 98.7\\% precision@1 and 98.1\\% precision@5 for the same task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 20:59:56 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Chen", "Patrick H.", ""], ["Si", "Si", ""], ["Kumar", "Sanjiv", ""], ["Li", "Yang", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.12411", "submitter": "Sergiy Bokhnyak", "authors": "Heng xin Fun, Sergiy V Bokhnyak, Francesco Saverio Zuppichini", "title": "Counting in Language with RNNs", "comments": "Withdrawing due to lack of key acknowledgements and follow up work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine a possible reason for the LSTM outperforming the GRU\non language modeling and more specifically machine translation. We hypothesize\nthat this has to do with counting. This is a consistent theme across the\nliterature of long term dependence, counting, and language modeling for RNNs.\nUsing the simplified forms of language -- Context-Free and Context-Sensitive\nLanguages -- we show how exactly the LSTM performs its counting based on their\ncell states during inference and why the GRU cannot perform as well.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 21:11:07 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 14:07:15 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Fun", "Heng xin", ""], ["Bokhnyak", "Sergiy V", ""], ["Zuppichini", "Francesco Saverio", ""]]}, {"id": "1810.12418", "submitter": "Xi Liu", "authors": "Ping-Chun Hsieh, Xi Liu, Anirban Bhattacharya, P. R. Kumar", "title": "Stay With Me: Lifetime Maximization Through Heteroscedastic Linear\n  Bandits With Reneging", "comments": "To appear in ICML 2019. More rounds of experiments are performed\n  before being taken average of compared to versions before", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential decision making for lifetime maximization is a critical problem in\nmany real-world applications, such as medical treatment and portfolio\nselection. In these applications, a \"reneging\" phenomenon, where participants\nmay disengage from future interactions after observing an unsatisfiable\noutcome, is rather prevalent. To address the above issue, this paper proposes a\nmodel of heteroscedastic linear bandits with reneging, which allows each\nparticipant to have a distinct \"satisfaction level,\" with any interaction\noutcome falling short of that level resulting in that participant reneging.\nMoreover, it allows the variance of the outcome to be context-dependent. Based\non this model, we develop a UCB-type policy, namely HR-UCB, and prove that it\nachieves $\\mathcal{O}\\big(\\sqrt{{T}(\\log({T}))^{3}}\\big)$ regret. Finally, we\nvalidate the performance of HR-UCB via simulations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 21:36:21 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 15:08:36 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 06:38:50 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 06:23:38 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Hsieh", "Ping-Chun", ""], ["Liu", "Xi", ""], ["Bhattacharya", "Anirban", ""], ["Kumar", "P. R.", ""]]}, {"id": "1810.12429", "submitter": "Ziyang Tang", "authors": "Qiang Liu, Lihong Li, Ziyang Tang, Dengyong Zhou", "title": "Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation", "comments": "21 pages, 5 figures, NIPS 2018 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the off-policy estimation problem of estimating the expected\nreward of a target policy using samples collected by a different behavior\npolicy. Importance sampling (IS) has been a key technique to derive (nearly)\nunbiased estimators, but is known to suffer from an excessively high variance\nin long-horizon problems. In the extreme case of in infinite-horizon problems,\nthe variance of an IS-based estimator may even be unbounded. In this paper, we\npropose a new off-policy estimation method that applies IS directly on the\nstationary state-visitation distributions to avoid the exploding variance issue\nfaced by existing estimators.Our key contribution is a novel approach to\nestimating the density ratio of two stationary distributions, with trajectories\nsampled from only the behavior distribution. We develop a mini-max loss\nfunction for the estimation problem, and derive a closed-form solution for the\ncase of RKHS. We support our method with both theoretical and empirical\nanalyses.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:03:58 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Liu", "Qiang", ""], ["Li", "Lihong", ""], ["Tang", "Ziyang", ""], ["Zhou", "Dengyong", ""]]}, {"id": "1810.12437", "submitter": "Akihiko Nishimura", "authors": "Akihiko Nishimura and Marc A. Suchard", "title": "Prior-preconditioned conjugate gradient method for accelerated Gibbs\n  sampling in \"large $n$ & large $p$\" Bayesian sparse regression", "comments": "35 pages, 7 figures + Supplement (42 pages, 18 figures); Software\n  package available --- see documentation at\n  https://bayes-bridge.readthedocs.io and source code at\n  https://github.com/aki-nishimura/bayes-bridge", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a modern observational study based on healthcare databases, the number of\nobservations and of predictors typically range in the order of $10^5$ ~ $10^6$\nand of $10^4$ ~ $10^5$. Despite the large sample size, data rarely provide\nsufficient information to reliably estimate such a large number of parameters.\nSparse regression techniques provide potential solutions, one notable approach\nbeing the Bayesian methods based on shrinkage priors. In the \"large n & large\np\" setting, however, posterior computation encounters a major bottleneck at\nrepeated sampling from a high-dimensional Gaussian distribution, whose\nprecision matrix $\\Phi$ is expensive to compute and factorize. In this article,\nwe present a novel algorithm to speed up this bottleneck based on the following\nobservation: we can cheaply generate a random vector $b$ such that the solution\nto the linear system $\\Phi \\beta = b$ has the desired Gaussian distribution. We\ncan then solve the linear system by the conjugate gradient (CG) algorithm\nthrough matrix-vector multiplications by $\\Phi$; this involves no explicit\nfactorization or calculation of $\\bPhi$ itself. Rapid convergence of CG in this\ncontext is guaranteed by the theory of prior-preconditioning we develop. We\napply our algorithm to a clinically relevant large-scale observational study\nwith n = 72,489 patients and p = 22,175 clinical covariates, designed to assess\nthe relative risk of adverse events from two alternative blood anti-coagulants.\nOur algorithm demonstrates an order of magnitude speed-up in the posterior\ncomputation.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:21:56 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 15:24:01 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 16:44:40 GMT"}, {"version": "v4", "created": "Fri, 17 Jan 2020 17:35:58 GMT"}, {"version": "v5", "created": "Tue, 20 Jul 2021 18:01:22 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Nishimura", "Akihiko", ""], ["Suchard", "Marc A.", ""]]}, {"id": "1810.12448", "submitter": "Onur Tasar", "authors": "Onur Tasar, Yuliya Tarabalka, Pierre Alliez", "title": "Incremental Learning for Semantic Segmentation of Large-Scale Remote\n  Sensing Data", "comments": null, "journal-ref": "IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND\n  REMOTE SENSING, 12, 2019, 3524-3537", "doi": "10.1109/JSTARS.2019.2925416", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of remarkable success of the convolutional neural networks on\nsemantic segmentation, they suffer from catastrophic forgetting: a significant\nperformance drop for the already learned classes when new classes are added on\nthe data, having no annotations for the old classes. We propose an incremental\nlearning methodology, enabling to learn segmenting new classes without\nhindering dense labeling abilities for the previous classes, although the\nentire previous data are not accessible. The key points of the proposed\napproach are adapting the network to learn new as well as old classes on the\nnew training data, and allowing it to remember the previously learned\ninformation for the old classes. For adaptation, we keep a frozen copy of the\npreviously trained network, which is used as a memory for the updated network\nin absence of annotations for the former classes. The updated network minimizes\na loss function, which balances the discrepancy between outputs for the\nprevious classes from the memory and updated networks, and the\nmis-classification rate between outputs for the new classes from the updated\nnetwork and the new ground-truth. For remembering, we either regularly feed\nsamples from the stored, little fraction of the previous data or use the memory\nnetwork, depending on whether the new data are collected from completely\ndifferent geographic areas or from the same city. Our experimental results\nprove that it is possible to add new classes to the network, while maintaining\nits performance for the previous classes, despite the whole previous training\ndata are not available.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:51:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tasar", "Onur", ""], ["Tarabalka", "Yuliya", ""], ["Alliez", "Pierre", ""]]}, {"id": "1810.12460", "submitter": "Ashkan Esmaeili", "authors": "Ashkan Esmaeili, Farokh Marvasti", "title": "A Novel Approach to Quantized Matrix Completion Using Huber Loss Measure", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2891134", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel and robust approach to Quantized Matrix\nCompletion (QMC). First, we propose a rank minimization problem with\nconstraints induced by quantization bounds. Next, we form an unconstrained\noptimization problem by regularizing the rank function with Huber loss. Huber\nloss is leveraged to control the violation from quantization bounds due to two\nproperties: 1- It is differentiable, 2- It is less sensitive to outliers than\nthe quadratic loss. A Smooth Rank Approximation is utilized to endorse lower\nrank on the genuine data matrix. Thus, an unconstrained optimization problem\nwith differentiable objective function is obtained allowing us to advantage\nfrom Gradient Descent (GD) technique. Novel and firm theoretical analysis on\nproblem model and convergence of our algorithm to the global solution are\nprovided. Another contribution of our work is that our method does not require\nprojections or initial rank estimation unlike the state- of-the-art. In the\nNumerical Experiments Section, the noticeable outperformance of our proposed\nmethod in learning accuracy and computational complexity compared to those of\nthe state-of- the-art literature methods is illustrated as the main\ncontribution.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 23:44:29 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Esmaeili", "Ashkan", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1810.12464", "submitter": "Rasool Fakoor", "authors": "Thomas Powers, Rasool Fakoor, Siamak Shakeri, Abhinav Sethy, Amanjit\n  Kainth, Abdel-rahman Mohamed, Ruhi Sarikaya", "title": "Differentiable Greedy Networks", "comments": "Work in progress and under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal selection of a subset of items from a given set is a hard problem\nthat requires combinatorial optimization. In this paper, we propose a subset\nselection algorithm that is trainable with gradient-based methods yet achieves\nnear-optimal performance via submodular optimization. We focus on the task of\nidentifying a relevant set of sentences for claim verification in the context\nof the FEVER task. Conventional methods for this task look at sentences on\ntheir individual merit and thus do not optimize the informativeness of\nsentences as a set. We show that our proposed method which builds on the idea\nof unfolding a greedy algorithm into a computational graph allows both\ninterpretability and gradient-based training. The proposed differentiable\ngreedy network (DGN) outperforms discrete optimization algorithms as well as\nother baseline methods in terms of precision and recall.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 00:24:22 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Powers", "Thomas", ""], ["Fakoor", "Rasool", ""], ["Shakeri", "Siamak", ""], ["Sethy", "Abhinav", ""], ["Kainth", "Amanjit", ""], ["Mohamed", "Abdel-rahman", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1810.12473", "submitter": "Roberto Souza", "authors": "Roberto Souza, Richard Frayne", "title": "A Hybrid Frequency-domain/Image-domain Deep Network for Magnetic\n  Resonance Image Reconstruction", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decreasing magnetic resonance (MR) image acquisition times can potentially\nreduce procedural cost and make MR examinations more accessible. Compressed\nsensing (CS)-based image reconstruction methods, for example, decrease MR\nacquisition time by reconstructing high-quality images from data that were\noriginally sampled at rates inferior to the Nyquist-Shannon sampling theorem.\nIn this work we propose a hybrid architecture that works both in the k-space\n(or frequency-domain) and the image (or spatial) domains. Our network is\ncomposed of a complex-valued residual U-net in the k-space domain, an inverse\nFast Fourier Transform (iFFT) operation, and a real-valued U-net in the image\ndomain. Our experiments demonstrated, using MR raw k-space data, that the\nproposed hybrid approach can potentially improve CS reconstruction compared to\ndeep-learning networks that operate only in the image domain. In this study we\ncompare our method with four previously published deep neural networks and\nexamine their ability to reconstruct images that are subsequently used to\ngenerate regional volume estimates. We evaluated undersampling ratios of 75%\nand 80%. Our technique was ranked second in the quantitative analysis, but\nqualitative analysis indicated that our reconstruction performed the best in\nhard to reconstruct regions, such as the cerebellum. All images reconstructed\nwith our method were successfully post-processed, and showed good volumetry\nagreement compared with the fully sampled reconstruction measures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 01:10:19 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Souza", "Roberto", ""], ["Frayne", "Richard", ""]]}, {"id": "1810.12482", "submitter": "Tomas Geffner", "authors": "Tomas Geffner, Justin Domke", "title": "Using Large Ensembles of Control Variates for Variational Inference", "comments": "Neural Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference is increasingly being addressed with stochastic\noptimization. In this setting, the gradient's variance plays a crucial role in\nthe optimization procedure, since high variance gradients lead to poor\nconvergence. A popular approach used to reduce gradient's variance involves the\nuse of control variates. Despite the good results obtained, control variates\ndeveloped for variational inference are typically looked at in isolation. In\nthis paper we clarify the large number of control variates that are available\nby giving a systematic view of how they are derived. We also present a Bayesian\nrisk minimization framework in which the quality of a procedure for combining\ncontrol variates is quantified by its effect on optimization convergence rates,\nwhich leads to a very simple combination rule. Results show that combining a\nlarge number of control variates this way significantly improves the\nconvergence of inference over using the typical gradient estimators or a\nreduced number of control variates.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 01:48:19 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 11:03:48 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Geffner", "Tomas", ""], ["Domke", "Justin", ""]]}, {"id": "1810.12506", "submitter": "Yeping Hu", "authors": "Yeping Hu, Wei Zhan, Masayoshi Tomizuka", "title": "A Framework for Probabilistic Generic Traffic Scene Prediction", "comments": "2018 IEEE 21st International Conference on Intelligent Transportation\n  Systems (ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a given scenario, simultaneously and accurately predicting every possible\ninteraction of traffic participants is an important capability for autonomous\nvehicles. The majority of current researches focused on the prediction of an\nsingle entity without incorporating the environment information. Although some\napproaches aimed to predict multiple vehicles, they either predicted each\nvehicle independently with no considerations on possible interaction with\nsurrounding entities or generated discretized joint motions which cannot be\ndirectly used in decision making and motion planning for autonomous vehicle. In\nthis paper, we present a probabilistic framework that is able to jointly\npredict continuous motions for multiple interacting road participants under any\ndriving scenarios and is capable of forecasting the duration of each\ninteraction, which can enhance the prediction performance and efficiency. The\nproposed traffic scene prediction framework contains two hierarchical modules:\nthe upper module and the lower module. The upper module forecasts the intention\nof the predicted vehicle, while the lower module predicts motions for\ninteracting scene entities. An exemplar real-world scenario is used to\nimplement and examine the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 03:04:45 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Hu", "Yeping", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1810.12513", "submitter": "Shin Ando Ph. D.", "authors": "Shin Ando", "title": "Weak-supervision for Deep Representation Learning under Class Imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is a pervasive issue among classification models including\ndeep learning, whose capacity to extract task-specific features is affected in\nimbalanced settings. However, the challenges of handling imbalance among a\nlarge number of classes, commonly addressed by deep learning, have not received\na significant amount of attention in previous studies. In this paper, we\npropose an extension of the deep over-sampling framework, to exploit\nautomatically-generated abstract-labels, i.e., a type of side-information used\nin weak-label learning, to enhance deep representation learning against class\nimbalance. We attempt to exploit the labels to guide the deep representation of\ninstances towards different subspaces, to induce a soft-separation of inherent\nsubtasks of the classification problem. Our empirical study shows that the\nproposed framework achieves a substantial improvement on image classification\nbenchmarks with imbalanced among large and small numbers of classes.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 03:37:09 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Ando", "Shin", ""]]}, {"id": "1810.12544", "submitter": "Dong Huang", "authors": "Dong Huang, Chang-Dong Wang, Hongxing Peng, Jianhuang Lai, Chee-Keong\n  Kwoh", "title": "Enhanced Ensemble Clustering via Fast Propagation of Cluster-wise\n  Similarities", "comments": "To appear in IEEE Transactions on Systems, Man, and Cybernetics:\n  Systems. The MATLAB source code of this work is available at:\n  http://www.researchgate.net/publication/328581758", "journal-ref": null, "doi": "10.1109/TSMC.2018.2876202", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble clustering has been a popular research topic in data mining and\nmachine learning. Despite its significant progress in recent years, there are\nstill two challenging issues in the current ensemble clustering research.\nFirst, most of the existing algorithms tend to investigate the ensemble\ninformation at the object-level, yet often lack the ability to explore the rich\ninformation at higher levels of granularity. Second, they mostly focus on the\ndirect connections (e.g., direct intersection or pair-wise co-occurrence) in\nthe multiple base clusterings, but generally neglect the multi-scale indirect\nrelationship hidden in them. To address these two issues, this paper presents a\nnovel ensemble clustering approach based on fast propagation of cluster-wise\nsimilarities via random walks. We first construct a cluster similarity graph\nwith the base clusters treated as graph nodes and the cluster-wise Jaccard\ncoefficient exploited to compute the initial edge weights. Upon the constructed\ngraph, a transition probability matrix is defined, based on which the random\nwalk process is conducted to propagate the graph structural information.\nSpecifically, by investigating the propagating trajectories starting from\ndifferent nodes, a new cluster-wise similarity matrix can be derived by\nconsidering the trajectory relationship. Then, the newly obtained cluster-wise\nsimilarity matrix is mapped from the cluster-level to the object-level to\nachieve an enhanced co-association (ECA) matrix, which is able to\nsimultaneously capture the object-wise co-occurrence relationship as well as\nthe multi-scale cluster-wise relationship in ensembles. Finally, two novel\nconsensus functions are proposed to obtain the consensus clustering result.\nExtensive experiments on a variety of real-world datasets have demonstrated the\neffectiveness and efficiency of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 06:34:50 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Huang", "Dong", ""], ["Wang", "Chang-Dong", ""], ["Peng", "Hongxing", ""], ["Lai", "Jianhuang", ""], ["Kwoh", "Chee-Keong", ""]]}, {"id": "1810.12558", "submitter": "Mahammad Humayoo", "authors": "Mahammad Humayoo and Xueqi Cheng", "title": "Relative Importance Sampling For Off-Policy Actor-Critic in Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy learning is more unstable compared to on-policy learning in\nreinforcement learning (RL). One reason for the instability of off-policy\nlearning is a discrepancy between the target ($\\pi$) and behavior (b) policy\ndistributions. The discrepancy between $\\pi$ and b distributions can be\nalleviated by employing a smooth variant of the importance sampling (IS), such\nas the relative importance sampling (RIS). RIS has parameter $\\beta\\in[0, 1]$\nwhich controls smoothness. To cope with instability, we present the first\nrelative importance sampling-off-policy actor-critic (RIS-Off-PAC) model-free\nalgorithms in RL. In our method, the network yields a target policy (the\nactor), a value function (the critic) assessing the current policy ($\\pi$)\nusing samples drawn from behavior policy. We use action value generated from\nthe behavior policy in reward function to train our algorithm rather than from\nthe target policy. We also use deep neural networks to train both actor and\ncritic. We evaluated our algorithm on a number of Open AI Gym benchmark\nproblems and demonstrate better or comparable performance to several\nstate-of-the-art RL baselines.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 07:41:08 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 07:13:50 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 00:27:31 GMT"}, {"version": "v4", "created": "Thu, 11 Jul 2019 02:42:41 GMT"}, {"version": "v5", "created": "Tue, 16 Jul 2019 01:35:44 GMT"}, {"version": "v6", "created": "Fri, 19 Jul 2019 03:08:45 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Humayoo", "Mahammad", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1810.12563", "submitter": "Haowen Luo", "authors": "Haowen Luo", "title": "Shorten Spatial-spectral RNN with Parallel-GRU for Hyperspectral Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) attained a good performance in\nhyperspectral sensing image (HSI) classification, but CNNs consider spectra as\norderless vectors. Therefore, considering the spectra as sequences, recurrent\nneural networks (RNNs) have been applied in HSI classification, for RNNs is\nskilled at dealing with sequential data. However, for a long-sequence task,\nRNNs is difficult for training and not as effective as we expected. Besides,\nspatial contextual features are not considered in RNNs. In this study, we\npropose a Shorten Spatial-spectral RNN with Parallel-GRU (St-SS-pGRU) for HSI\nclassification. A shorten RNN is more efficient and easier for training than\nband-by-band RNN. By combining converlusion layer, the St-SSpGRU model\nconsiders not only spectral but also spatial feature, which results in a better\nperformance. An architecture named parallel-GRU is also proposed and applied in\nSt-SS-pGRU. With this architecture, the model gets a better performance and is\nmore robust.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 07:57:27 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Luo", "Haowen", ""]]}, {"id": "1810.12576", "submitter": "Alexander Matyasko", "authors": "Alexander Matyasko, Lap-Pui Chau", "title": "Improved Network Robustness with Adversary Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Ideally, what confuses neural network should be confusing to humans. However,\nrecent experiments have shown that small, imperceptible perturbations can\nchange the network prediction. To address this gap in perception, we propose a\nnovel approach for learning robust classifier. Our main idea is: adversarial\nexamples for the robust classifier should be indistinguishable from the regular\ndata of the adversarial target. We formulate a problem of learning robust\nclassifier in the framework of Generative Adversarial Networks (GAN), where the\nadversarial attack on classifier acts as a generator, and the critic network\nlearns to distinguish between regular and adversarial images. The classifier\ncost is augmented with the objective that its adversarial examples should\nconfuse the adversary critic. To improve the stability of the adversarial\nmapping, we introduce adversarial cycle-consistency constraint which ensures\nthat the adversarial mapping of the adversarial examples is close to the\noriginal. In the experiments, we show the effectiveness of our defense. Our\nmethod surpasses in terms of robustness networks trained with adversarial\ntraining. Additionally, we verify in the experiments with human annotators on\nMTurk that adversarial examples are indeed visually confusing. Codes for the\nproject are available at https://github.com/aam-at/adversary_critic.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 08:33:46 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Matyasko", "Alexander", ""], ["Chau", "Lap-Pui", ""]]}, {"id": "1810.12582", "submitter": "Lingbing Guo", "authors": "Lingbing Guo, Qingheng Zhang, Weiyi Ge, Wei Hu, and Yuzhong Qu", "title": "DSKG: A Deep Sequential Model for Knowledge Graph Completion", "comments": "CCKS (China Conference on Knowledge Graph and Semantic Computing)\n  Best English Paper Award 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) completion aims to fill the missing facts in a KG, where\na fact is represented as a triple in the form of $(subject, relation, object)$.\nCurrent KG completion models compel two-thirds of a triple provided (e.g.,\n$subject$ and $relation$) to predict the remaining one. In this paper, we\npropose a new model, which uses a KG-specific multi-layer recurrent neural\nnetwork (RNN) to model triples in a KG as sequences. It outperformed several\nstate-of-the-art KG completion models on the conventional entity prediction\ntask for many evaluation metrics, based on two benchmark datasets and a more\ndifficult dataset. Furthermore, our model is enabled by the sequential\ncharacteristic and thus capable of predicting the whole triples only given one\nentity. Our experiments demonstrated that our model achieved promising\nperformance on this new triple prediction task.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 08:45:01 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 09:51:05 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Guo", "Lingbing", ""], ["Zhang", "Qingheng", ""], ["Ge", "Weiyi", ""], ["Hu", "Wei", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1810.12598", "submitter": "Lauri Juvela", "authors": "Lauri Juvela, Bajibabu Bollepalli, Junichi Yamagishi, Paavo Alku", "title": "Waveform generation for text-to-speech synthesis using pitch-synchronous\n  multi-scale generative adversarial networks", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art in text-to-speech synthesis has recently improved\nconsiderably due to novel neural waveform generation methods, such as WaveNet.\nHowever, these methods suffer from their slow sequential inference process,\nwhile their parallel versions are difficult to train and even more expensive\ncomputationally. Meanwhile, generative adversarial networks (GANs) have\nachieved impressive results in image generation and are making their way into\naudio applications; parallel inference is among their lucrative properties. By\nadopting recent advances in GAN training techniques, this investigation studies\nwaveform generation for TTS in two domains (speech signal and glottal\nexcitation). Listening test results show that while direct waveform generation\nwith GAN is still far behind WaveNet, a GAN-based glottal excitation model can\nachieve quality and voice similarity on par with a WaveNet vocoder.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 09:23:56 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Juvela", "Lauri", ""], ["Bollepalli", "Bajibabu", ""], ["Yamagishi", "Junichi", ""], ["Alku", "Paavo", ""]]}, {"id": "1810.12611", "submitter": "Asifullah Khan", "authors": "Aqsa Saeed Qureshi, Asifullah Khan", "title": "Adaptive Transfer Learning in Deep Neural Networks: Wind Power\n  Prediction using Knowledge Transfer from Region to Region and Between\n  Different Task Domains", "comments": "28 pages, 21 figures, and 11 tables", "journal-ref": null, "doi": "10.1111/coin.12236", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer Learning (TL) in Deep Neural Networks is gaining importance because\nin most of the applications, the labeling of data is costly and time-consuming.\nAdditionally, TL also provides an effective weight initialization strategy for\nDeep Neural Networks . This paper introduces the idea of Adaptive Transfer\nLearning in Deep Neural Networks (ATL-DNN) for wind power prediction.\nSpecifically, we show in case of wind power prediction that adaptive TL of Deep\nNeural Networks system can be adaptively modified as regards training on a\ndifferent wind farm is concerned. The proposed ATL-DNN technique is tested for\nshort-term wind power prediction, where continuously arriving information has\nto be exploited. Adaptive TL not only helps in providing good weight\ninitialization, but is also helpful to utilize the incoming data for effective\nlearning. Additionally, the proposed ATL-DNN technique is shown to transfer\nknowledge between different task domains (wind power to wind speed prediction)\nand from one region to another region. The simulation results show that the\nproposed ATL-DNN technique achieves average values of 0.0637,0.0986, and 0.0984\nfor the Mean-Absolute-Error, Root-Mean-Squared-Error, and\nStandard-Deviation-Error, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 09:47:32 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 11:27:20 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Qureshi", "Aqsa Saeed", ""], ["Khan", "Asifullah", ""]]}, {"id": "1810.12613", "submitter": "Bhalaji Nagarajan Mr", "authors": "Bhalaji Nagarajan, V Ramana Murthy Oruganti", "title": "Deep Learning as Feature Encoding for Emotion Recognition", "comments": "Issues pertaining with experimental results reported in paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is popular as an end-to-end framework extracting the prominent\nfeatures and performing the classification also. In this paper, we extensively\ninvestigate deep networks as an alternate to feature encoding technique of low\nlevel descriptors for emotion recognition on the benchmark EmoDB dataset.\nFusion performance with such obtained encoded features with other available\nfeatures is also investigated. Highest performance to date in the literature is\nobserved.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 09:53:28 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 10:57:31 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Nagarajan", "Bhalaji", ""], ["Oruganti", "V Ramana Murthy", ""]]}, {"id": "1810.12679", "submitter": "Pablo A. Alvarado", "authors": "Pablo A. Alvarado, Mauricio A. \\'Alvarez, Dan Stowell", "title": "Sparse Gaussian Process Audio Source Separation Using Spectrum Priors in\n  the Time-Domain", "comments": "Paper submitted to the 44th International Conference on Acoustics,\n  Speech, and Signal Processing, ICASSP 2019. To be held in Brighton, United\n  Kingdom, between May 12 and May 17, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) audio source separation is a time-domain approach that\ncircumvents the inherent phase approximation issue of spectrogram based\nmethods. Furthermore, through its kernel, GPs elegantly incorporate prior\nknowledge about the sources into the separation model. Despite these compelling\nadvantages, the computational complexity of GP inference scales cubically with\nthe number of audio samples. As a result, source separation GP models have been\nrestricted to the analysis of short audio frames. We introduce an efficient\napplication of GPs to time-domain audio source separation, without compromising\nperformance. For this purpose, we used GP regression, together with spectral\nmixture kernels, and variational sparse GPs. We compared our method with\nLD-PSDTF (positive semi-definite tensor factorization), KL-NMF\n(Kullback-Leibler non-negative matrix factorization), and IS-NMF (Itakura-Saito\nNMF). Results show that the proposed method outperforms these techniques.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 11:46:35 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 09:49:35 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 12:18:46 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Alvarado", "Pablo A.", ""], ["\u00c1lvarez", "Mauricio A.", ""], ["Stowell", "Dan", ""]]}, {"id": "1810.12683", "submitter": "Emilie Morvant", "authors": "Ga\\\"el Letarte, Emilie Morvant (LHC), Pascal Germain (MODAL)", "title": "Pseudo-Bayesian Learning with Kernel Fourier Transform as Prior", "comments": "Published at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit Rahimi and Recht (2007)'s kernel random Fourier features (RFF)\nmethod through the lens of the PAC-Bayesian theory. While the primary goal of\nRFF is to approximate a kernel, we look at the Fourier transform as a prior\ndistribution over trigonometric hypotheses. It naturally suggests learning a\nposterior on these hypotheses. We derive generalization bounds that are\noptimized by learning a pseudo-posterior obtained from a closed-form\nexpression. Based on this study, we consider two learning strategies: The first\none finds a compact landmarks-based representation of the data where each\nlandmark is given by a distribution-tailored similarity measure, while the\nsecond one provides a PAC-Bayesian justification to the kernel alignment method\nof Sinha and Duchi (2016).\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 11:55:06 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 14:05:25 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Letarte", "Ga\u00ebl", "", "LHC"], ["Morvant", "Emilie", "", "LHC"], ["Germain", "Pascal", "", "MODAL"]]}, {"id": "1810.12692", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "Research Issues in Mining User Behavioral Rules for Context-Aware\n  Intelligent Mobile Applications", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-awareness in smart mobile applications is a growing area of study,\nbecause of it's intelligence in the applications. In order to build\ncontext-aware intelligent applications, mining contextual behavioral rules of\nindividual smartphone users utilizing their phone log data is the key. However,\nto mine these rules, a number of issues, such as the quality of smartphone\ndata, understanding the relevancy of contexts, discretization of continuous\ncontextual data, discovery of useful behavioral rules of individuals and their\nordering, knowledge-based interactive post-mining for semantic understanding,\nand dynamic updating and management of rules according to their present\nbehavior, are investigated. In this paper, we briefly discuss these issues and\ntheir potential solution directions for mining individuals' behavioral rules,\nfor the purpose of building various context-aware intelligent mobile\napplications. We also summarize a number of real-life rule-based applications\nthat intelligently assist individual smartphone users according to their\nbehavioral rules in their daily activities.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 12:10:43 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "1810.12698", "submitter": "Vaidheeswaran Archana", "authors": "Muru Selvakumar, Suriyadeepan Ramamoorthy, Vaidheeswaran Archana,\n  Malaikannan Sankarasubbu", "title": "Compositional Attention Networks for Interpretability in Natural\n  Language Question Answering", "comments": "8 pages,10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAC Net is a compositional attention network designed for Visual Question\nAnswering. We propose a modified MAC net architecture for Natural Language\nQuestion Answering. Question Answering typically requires Language\nUnderstanding and multi-step Reasoning. MAC net's unique architecture - the\nseparation between memory and control, facilitates data-driven iterative\nreasoning. This makes it an ideal candidate for solving tasks that involve\nlogical reasoning. Our experiments with 20 bAbI tasks demonstrate the value of\nMAC net as a data-efficient and interpretable architecture for Natural Language\nQuestion Answering. The transparent nature of MAC net provides a highly\ngranular view of the reasoning steps taken by the network in answering a query.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 12:23:35 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Selvakumar", "Muru", ""], ["Ramamoorthy", "Suriyadeepan", ""], ["Archana", "Vaidheeswaran", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "1810.12715", "submitter": "Sven Gowal", "authors": "Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel,\n  Chongli Qin, Jonathan Uesato, Relja Arandjelovic, Timothy Mann, Pushmeet\n  Kohli", "title": "On the Effectiveness of Interval Bound Propagation for Training\n  Verifiably Robust Models", "comments": "[v2] Best paper at NeurIPS SECML 2018 Workshop [v4] Accepted at ICCV\n  2019 under the title \"Scalable Verified Training for Provably Robust Image\n  Classification\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that it is possible to train deep neural networks that\nare provably robust to norm-bounded adversarial perturbations. Most of these\nmethods are based on minimizing an upper bound on the worst-case loss over all\npossible adversarial perturbations. While these techniques show promise, they\noften result in difficult optimization procedures that remain hard to scale to\nlarger networks. Through a comprehensive analysis, we show how a simple\nbounding technique, interval bound propagation (IBP), can be exploited to train\nlarge provably robust neural networks that beat the state-of-the-art in\nverified accuracy. While the upper bound computed by IBP can be quite weak for\ngeneral networks, we demonstrate that an appropriate loss and clever\nhyper-parameter schedule allow the network to adapt such that the IBP bound is\ntight. This results in a fast and stable learning algorithm that outperforms\nmore sophisticated methods and achieves state-of-the-art results on MNIST,\nCIFAR-10 and SVHN. It also allows us to train the largest model to be verified\nbeyond vacuous bounds on a downscaled version of ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 13:12:47 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 11:48:21 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 16:53:04 GMT"}, {"version": "v4", "created": "Thu, 29 Aug 2019 12:23:52 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Gowal", "Sven", ""], ["Dvijotham", "Krishnamurthy", ""], ["Stanforth", "Robert", ""], ["Bunel", "Rudy", ""], ["Qin", "Chongli", ""], ["Uesato", "Jonathan", ""], ["Arandjelovic", "Relja", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1810.12722", "submitter": "Thomas Niesler", "authors": "Lerato Lerato and Thomas Niesler", "title": "Feature Trajectory Dynamic Time Warping for Clustering of Speech\n  Segments", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic time warping (DTW) can be used to compute the similarity between two\nsequences of generally differing length. We propose a modification to DTW that\nperforms individual and independent pairwise alignment of feature trajectories.\nThe modified technique, termed feature trajectory dynamic time warping (FTDTW),\nis applied as a similarity measure in the agglomerative hierarchical clustering\nof speech segments. Experiments using MFCC and PLP parametrisations extracted\nfrom TIMIT and from the Spoken Arabic Digit Dataset (SADD) show consistent and\nstatistically significant improvements in the quality of the resulting clusters\nin terms of F-measure and normalised mutual information (NMI).\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 13:30:19 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Lerato", "Lerato", ""], ["Niesler", "Thomas", ""]]}, {"id": "1810.12730", "submitter": "Fuming Fang", "authors": "Fuming Fang, Xin Wang, Junichi Yamagishi, Isao Echizen", "title": "Audiovisual speaker conversion: jointly and simultaneously transforming\n  facial expression and acoustic characteristics", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An audiovisual speaker conversion method is presented for simultaneously\ntransforming the facial expressions and voice of a source speaker into those of\na target speaker. Transforming the facial and acoustic features together makes\nit possible for the converted voice and facial expressions to be highly\ncorrelated and for the generated target speaker to appear and sound natural. It\nuses three neural networks: a conversion network that fuses and transforms the\nfacial and acoustic features, a waveform generation network that produces the\nwaveform from both the converted facial and acoustic features, and an image\nreconstruction network that outputs an RGB facial image also based on both the\nconverted features. The results of experiments using an emotional audiovisual\ndatabase showed that the proposed method achieved significantly higher\nnaturalness compared with one that separately transformed acoustic and facial\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:20:32 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 15:36:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Fang", "Fuming", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""]]}, {"id": "1810.12743", "submitter": "Loc Tran H", "authors": "Loc Hoang Tran, Trang Hoang, Bui Hoang Nam Huynh", "title": "Hypergraph based semi-supervised learning algorithms applied to speech\n  recognition problem: a novel approach", "comments": "11 pages, 1 figure, 2 tables. arXiv admin note: substantial text\n  overlap with arXiv:1212.0388", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most network-based speech recognition methods are based on the assumption\nthat the labels of two adjacent speech samples in the network are likely to be\nthe same. However, assuming the pairwise relationship between speech samples is\nnot complete. The information a group of speech samples that show very similar\npatterns and tend to have similar labels is missed. The natural way overcoming\nthe information loss of the above assumption is to represent the feature data\nof speech samples as the hypergraph. Thus, in this paper, the three\nun-normalized, random walk, and symmetric normalized hypergraph Laplacian based\nsemi-supervised learning methods applied to hypergraph constructed from the\nfeature data of speech samples in order to predict the labels of speech samples\nare introduced. Experiment results show that the sensitivity performance\nmeasures of these three hypergraph Laplacian based semi-supervised learning\nmethods are greater than the sensitivity performance measures of the Hidden\nMarkov Model method (the current state of the art method applied to speech\nrecognition problem) and graph based semi-supervised learning methods (i.e. the\ncurrent state of the art network-based method for classification problems)\napplied to network created from the feature data of speech samples.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 13:37:14 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Tran", "Loc Hoang", ""], ["Hoang", "Trang", ""], ["Huynh", "Bui Hoang Nam", ""]]}, {"id": "1810.12744", "submitter": "Thomas Niesler", "authors": "Lerato Lerato and Thomas Niesler", "title": "Cluster Size Management in Multi-Stage Agglomerative Hierarchical\n  Clustering of Acoustic Speech Segments", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agglomerative hierarchical clustering (AHC) requires only the similarity\nbetween objects to be known. This is attractive when clustering signals of\nvarying length, such as speech, which are not readily represented in\nfixed-dimensional vector space. However, AHC is characterised by $O(N^2)$ space\nand time complexity, making it infeasible for partitioning large datasets. This\nhas recently been addressed by an approach based on the iterative re-clustering\nof independent subsets of the larger dataset. We show that, due to its\niterative nature, this procedure can sometimes lead to unchecked growth of\nindividual subsets, thereby compromising its effectiveness. We propose the\nintegration of a simple space management strategy into the iterative process,\nand show experimentally that this leads to no loss in performance in terms of\nF-measure while guaranteeing that a threshold space complexity is not breached.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:00:59 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Lerato", "Lerato", ""], ["Niesler", "Thomas", ""]]}, {"id": "1810.12750", "submitter": "Vincent Dutordoir", "authors": "Vincent Dutordoir, Hugh Salimbeni, Marc Deisenroth, James Hensman", "title": "Gaussian Process Conditional Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Density Estimation (CDE) models deal with estimating conditional\ndistributions. The conditions imposed on the distribution are the inputs of the\nmodel. CDE is a challenging task as there is a fundamental trade-off between\nmodel complexity, representational capacity and overfitting. In this work, we\npropose to extend the model's input with latent variables and use Gaussian\nprocesses (GP) to map this augmented input onto samples from the conditional\ndistribution. Our Bayesian approach allows for the modeling of small datasets,\nbut we also provide the machinery for it to be applied to big data using\nstochastic variational inference. Our approach can be used to model densities\neven in sparse data regions, and allows for sharing learned structure between\nconditions. We illustrate the effectiveness and wide-reaching applicability of\nour model on a variety of real-world problems, such as spatio-temporal density\nestimation of taxi drop-offs, non-Gaussian noise modeling, and few-shot\nlearning on omniglot images.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:05:54 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Dutordoir", "Vincent", ""], ["Salimbeni", "Hugh", ""], ["Deisenroth", "Marc", ""], ["Hensman", "James", ""]]}, {"id": "1810.12754", "submitter": "Guoqiang Zhong", "authors": "Guoqiang Zhong, Guohua Yue and Xiao Ling", "title": "Recurrent Attention Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) has been successfully applied in many sequence\nlearning problems. Such as handwriting recognition, image description, natural\nlanguage processing and video motion analysis. After years of development,\nresearchers have improved the internal structure of the RNN and introduced many\nvariants. Among others, Gated Recurrent Unit (GRU) is one of the most widely\nused RNN model. However, GRU lacks the capability of adaptively paying\nattention to certain regions or locations, so that it may cause information\nredundancy or loss during leaning. In this paper, we propose a RNN model,\ncalled Recurrent Attention Unit (RAU), which seamlessly integrates the\nattention mechanism into the interior of GRU by adding an attention gate. The\nattention gate can enhance GRU's ability to remember long-term memory and help\nmemory cells quickly discard unimportant content. RAU is capable of extracting\ninformation from the sequential data by adaptively selecting a sequence of\nregions or locations and pay more attention to the selected regions during\nlearning. Extensive experiments on image classification, sentiment\nclassification and language modeling show that RAU consistently outperforms GRU\nand other baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:09:19 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Zhong", "Guoqiang", ""], ["Yue", "Guohua", ""], ["Ling", "Xiao", ""]]}, {"id": "1810.12757", "submitter": "Gil Keren", "authors": "Gil Keren, Jing Han, Bj\\\"orn Schuller", "title": "Scaling Speech Enhancement in Unseen Environments with Noise Embeddings", "comments": null, "journal-ref": "The Fifth CHiME Challenge Workshop, 2018", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of speech enhancement generalisation to unseen\nenvironments by performing two manipulations. First, we embed an additional\nrecording from the environment alone, and use this embedding to alter\nactivations in the main enhancement subnetwork. Second, we scale the number of\nnoise environments present at training time to 16,784 different environments.\nExperiment results show that both manipulations reduce word error rates of a\npretrained speech recognition system and improve enhancement quality according\nto a number of performance measures. Specifically, our best model reduces the\nword error rate from 34.04% on noisy speech to 15.46% on the enhanced speech.\nEnhanced audio samples can be found in\nhttps://speechenhancement.page.link/samples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 13:05:54 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Keren", "Gil", ""], ["Han", "Jing", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1810.12758", "submitter": "Cheng Qian", "authors": "Cheng Qian, Nicholas D. Sidiropoulos, Magda Amiridi, Amin Emad", "title": "From Gene Expression to Drug Response: A Collaborative Filtering\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the response of cancer cells to drugs is an important problem in\npharmacogenomics. Recent efforts in generation of large scale datasets\nprofiling gene expression and drug sensitivity in cell lines have provided a\nunique opportunity to study this problem. However, one major challenge is the\nsmall number of samples (cell lines) compared to the number of features (genes)\neven in these large datasets. We propose a collaborative filtering (CF) like\nalgorithm for modeling gene-drug relationship to identify patients most likely\nto benefit from a treatment. Due to the correlation of gene expressions in\ndifferent cell lines, the gene expression matrix is approximately low-rank,\nwhich suggests that drug responses could be estimated from a reduced dimension\nlatent space of the gene expression. Towards this end, we propose a joint\nlow-rank matrix factorization and latent linear regression approach.\nExperiments with data from the Genomics of Drug Sensitivity in Cancer database\nare included to show that the proposed method can predict drug-gene\nassociations better than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 13:25:35 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 03:05:47 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Qian", "Cheng", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Amiridi", "Magda", ""], ["Emad", "Amin", ""]]}, {"id": "1810.12770", "submitter": "Supriyo Mandal", "authors": "Supriyo Mandal and Abyayananda Maiti", "title": "Explicit Feedbacks Meet with Implicit Feedbacks : A Combined Approach\n  for Recommendation System", "comments": "12 pages. Accepted in Complex Networks, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems recommend items more accurately by analyzing users'\npotential interest on different brands' items. In conjunction with users'\nrating similarity, the presence of users' implicit feedbacks like clicking\nitems, viewing items specifications, watching videos etc. have been proved to\nbe helpful for learning users' embedding, that helps better rating prediction\nof users. Most existing recommender systems focus on modeling of ratings and\nimplicit feedbacks ignoring users' explicit feedbacks. Explicit feedbacks can\nbe used to validate the reliability of the particular users and can be used to\nlearn about the users' characteristic. Users' characteristic mean what type of\nreviewers they are. In this paper, we explore three different models for\nrecommendation with more accuracy focusing on users' explicit feedbacks and\nimplicit feedbacks. First one is RHC-PMF that predicts users' rating more\naccurately based on user's three explicit feedbacks (rating, helpfulness score\nand centrality) and second one is RV-PMF, where user's implicit feedback (view\nrelationship) is considered. Last one is RHCV-PMF, where both type of feedbacks\nare considered. In this model users' explicit feedbacks' similarity indicate\nthe similarity of their reliability and characteristic and implicit feedback's\nsimilarity indicates their preference similarity. Extensive experiments on real\nworld dataset, i.e. Amazon.com online review dataset shows that our models\nperform better compare to base-line models in term of users' rating prediction.\nRHCV-PMF model also performs better rating prediction compare to baseline\nmodels for cold start users and cold start items.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 06:03:29 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Mandal", "Supriyo", ""], ["Maiti", "Abyayananda", ""]]}, {"id": "1810.12782", "submitter": "Hao Zhou", "authors": "Hao Zhou, Ke Chen", "title": "Transferable Positive/Negative Speech Emotion Recognition via Class-wise\n  Adversarial Domain Adaptation", "comments": "5 pages, 3 figures, accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech emotion recognition plays an important role in building more\nintelligent and human-like agents. Due to the difficulty of collecting speech\nemotional data, an increasingly popular solution is leveraging a related and\nrich source corpus to help address the target corpus. However, domain shift\nbetween the corpora poses a serious challenge, making domain shift adaptation\ndifficult to function even on the recognition of positive/negative emotions. In\nthis work, we propose class-wise adversarial domain adaptation to address this\nchallenge by reducing the shift for all classes between different corpora.\nExperiments on the well-known corpora EMODB and Aibo demonstrate that our\nmethod is effective even when only a very limited number of target labeled\nexamples are provided.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:47:51 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 11:55:23 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Zhou", "Hao", ""], ["Chen", "Ke", ""]]}, {"id": "1810.12814", "submitter": "Bart Olsthoorn", "authors": "Bart Olsthoorn, R. Matthias Geilhufe, Stanislav S. Borysov, Alexander\n  V. Balatsky", "title": "Band gap prediction for large organic crystal structures with machine\n  learning", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": "10.1002/qute.201900023", "report-no": null, "categories": "cond-mat.mtrl-sci physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning models are capable of capturing the structure-property\nrelationship from a dataset of computationally demanding ab initio\ncalculations. Over the past two years, the Organic Materials Database (OMDB)\nhas hosted a growing number of calculated electronic properties of previously\nsynthesized organic crystal structures. The complexity of the organic crystals\ncontained within the OMDB, which have on average 82 atoms per unit cell, makes\nthis database a challenging platform for machine learning applications. In this\npaper, the focus is on predicting the band gap which represents one of the\nbasic properties of a crystalline materials. With this aim, a consistent\ndataset of 12 500 crystal structures and their corresponding DFT band gap are\nreleased, freely available for download at https://omdb.mathub.io/dataset. An\nensemble of two state-of-the-art models reach a mean absolute error (MAE) of\n0.388 eV, which corresponds to a percentage error of 13% for an average band\ngap of 3.05 eV. Finally, the trained models are employed to predict the band\ngap for 260 092 materials contained within the Crystallography Open Database\n(COD) and made available online so that the predictions can be obtained for any\narbitrary crystal structure uploaded by a user.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:34:54 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 09:37:04 GMT"}, {"version": "v3", "created": "Mon, 3 Dec 2018 08:57:47 GMT"}, {"version": "v4", "created": "Fri, 5 Jul 2019 12:42:15 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Olsthoorn", "Bart", ""], ["Geilhufe", "R. Matthias", ""], ["Borysov", "Stanislav S.", ""], ["Balatsky", "Alexander V.", ""]]}, {"id": "1810.12823", "submitter": "Dongsoo Lee", "authors": "Dongsoo Lee, Parichay Kapoor, Byeongwook Kim", "title": "DeepTwist: Learning Model Compression via Occasional Weight Distortion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression has been introduced to reduce the required hardware\nresources while maintaining the model accuracy. Lots of techniques for model\ncompression, such as pruning, quantization, and low-rank approximation, have\nbeen suggested along with different inference implementation characteristics.\nAdopting model compression is, however, still challenging because the design\ncomplexity of model compression is rapidly increasing due to additional\nhyper-parameters and computation overhead in order to achieve a high\ncompression ratio. In this paper, we propose a simple and efficient model\ncompression framework called DeepTwist which distorts weights in an occasional\nmanner without modifying the underlying training algorithms. The ideas of\ndesigning weight distortion functions are intuitive and straightforward given\nformats of compressed weights. We show that our proposed framework improves\ncompression rate significantly for pruning, quantization, and low-rank\napproximation techniques while the efforts of additional retraining and/or\nhyper-parameter search are highly reduced. Regularization effects of DeepTwist\nare also reported.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:48:30 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Lee", "Dongsoo", ""], ["Kapoor", "Parichay", ""], ["Kim", "Byeongwook", ""]]}, {"id": "1810.12856", "submitter": "Alex Sun", "authors": "Alexander Y. Sun", "title": "Discovering state-parameter mappings in subsurface models using\n  generative adversarial networks", "comments": null, "journal-ref": null, "doi": "10.1029/2018GL080404", "report-no": null, "categories": "physics.data-an cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in geophysical modeling is related to the\nidentification and approximation of causal structures among physical processes.\nHowever, resolving the bidirectional mappings between physical parameters and\nmodel state variables (i.e., solving the forward and inverse problems) is\nchallenging, especially when parameter dimensionality is high. Deep learning\nhas opened a new door toward knowledge representation and complex pattern\nidentification. In particular, the recently introduced generative adversarial\nnetworks (GANs) hold strong promises in learning cross-domain mappings for\nimage translation. This study presents a state-parameter identification GAN\n(SPID-GAN) for simultaneously learning bidirectional mappings between a\nhigh-dimensional parameter space and the corresponding model state space.\nSPID-GAN is demonstrated using a series of representative problems from\nsubsurface flow modeling. Results show that SPID-GAN achieves satisfactory\nperformance in identifying the bidirectional state-parameter mappings,\nproviding a new deep-learning-based, knowledge representation paradigm for a\nwide array of complex geophysical problems.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:55:37 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Sun", "Alexander Y.", ""]]}, {"id": "1810.12881", "submitter": "Mingjie Sun", "authors": "Mingjie Sun, Jian Tang, Huichen Li, Bo Li, Chaowei Xiao, Yao Chen,\n  Dawn Song", "title": "Data Poisoning Attack against Unsupervised Node Embedding Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised node embedding methods (e.g., DeepWalk, LINE, and node2vec) have\nattracted growing interests given their simplicity and effectiveness. However,\nalthough these methods have been proved effective in a variety of applications,\nnone of the existing work has analyzed the robustness of them. This could be\nvery risky if these methods are attacked by an adversarial party. In this\npaper, we take the task of link prediction as an example, which is one of the\nmost fundamental problems for graph analysis, and introduce a data positioning\nattack to node embedding methods. We give a complete characterization of\nattacker's utilities and present efficient solutions to adversarial attacks for\ntwo popular node embedding methods: DeepWalk and LINE. We evaluate our proposed\nattack model on multiple real-world graphs. Experimental results show that our\nproposed model can significantly affect the results of link prediction by\nslightly changing the graph structures (e.g., adding or removing a few edges).\nWe also show that our proposed model is very general and can be transferable\nacross different embedding methods. Finally, we conduct a case study on a\ncoauthor network to better understand our attack method.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:25:30 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 04:09:57 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Sun", "Mingjie", ""], ["Tang", "Jian", ""], ["Li", "Huichen", ""], ["Li", "Bo", ""], ["Xiao", "Chaowei", ""], ["Chen", "Yao", ""], ["Song", "Dawn", ""]]}, {"id": "1810.12894", "submitter": "Yuri Burda", "authors": "Yuri Burda, Harrison Edwards, Amos Storkey, Oleg Klimov", "title": "Exploration by Random Network Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an exploration bonus for deep reinforcement learning methods\nthat is easy to implement and adds minimal overhead to the computation\nperformed. The bonus is the error of a neural network predicting features of\nthe observations given by a fixed randomly initialized neural network. We also\nintroduce a method to flexibly combine intrinsic and extrinsic rewards. We find\nthat the random network distillation (RND) bonus combined with this increased\nflexibility enables significant progress on several hard exploration Atari\ngames. In particular we establish state of the art performance on Montezuma's\nRevenge, a game famously difficult for deep reinforcement learning methods. To\nthe best of our knowledge, this is the first method that achieves better than\naverage human performance on this game without using demonstrations or having\naccess to the underlying state of the game, and occasionally completes the\nfirst level.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:44:42 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Burda", "Yuri", ""], ["Edwards", "Harrison", ""], ["Storkey", "Amos", ""], ["Klimov", "Oleg", ""]]}, {"id": "1810.12997", "submitter": "Andreas B\\\"armann", "authors": "Andreas B\\\"armann and Alexander Martin and Sebastian Pokutta and Oskar\n  Schneider", "title": "An Online-Learning Approach to Inverse Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate how to learn the objective function of a\ndecision-maker while only observing the problem input data and the\ndecision-maker's corresponding decisions over multiple rounds. We present exact\nalgorithms for this online version of inverse optimization which converge at a\nrate of $ \\mathcal{O}(1/\\sqrt{T}) $ in the number of observations~$T$ and\ncompare their further properties. Especially, they all allow taking decisions\nwhich are essentially as good as those of the observed decision-maker already\nafter relatively few iterations, but are suited best for different settings\neach. Our approach is based on online learning and works for linear objectives\nover arbitrary feasible sets for which we have a linear optimization oracle. As\nsuch, it generalizes previous approaches based on KKT-system decomposition and\ndualization. We also introduce several generalizations, such as the approximate\nlearning of non-linear objective functions, dynamically changing as well as\nparameterized objectives and the case of suboptimal observed decisions. When\napplied to the stochastic offline case, our algorithms are able to give\nguarantees on the quality of the learned objectives in expectation. Finally, we\nshow the effectiveness and possible applications of our methods in indicative\ncomputational experiments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 20:43:04 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 02:08:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["B\u00e4rmann", "Andreas", ""], ["Martin", "Alexander", ""], ["Pokutta", "Sebastian", ""], ["Schneider", "Oskar", ""]]}, {"id": "1810.13043", "submitter": "Lars Lorch", "authors": "Lars Lorch, Abir De, Samir Bhatt, William Trouleau, Utkarsh Upadhyay,\n  Manuel Gomez-Rodriguez", "title": "Stochastic Optimal Control of Epidemic Processes in Networks", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/65", "categories": "math.OC cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the development of models and control strategies of\nsusceptible-infected-susceptible (SIS) epidemic processes from the perspective\nof marked temporal point processes and stochastic optimal control of stochastic\ndifferential equations (SDEs) with jumps. In contrast to previous work, this\nnovel perspective is particularly well-suited to make use of fine-grained data\nabout disease outbreaks and lets us overcome the shortcomings of current\ncontrol strategies. Our control strategy resorts to treatment intensities to\ndetermine who to treat and when to do so to minimize the amount of infected\nindividuals over time. Preliminary experiments with synthetic data show that\nour control strategy consistently outperforms several alternatives. Looking\ninto the future, we believe our methodology provides a promising step towards\nthe development of practical data-driven control strategies of epidemic\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:43:36 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 04:33:39 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 02:03:57 GMT"}, {"version": "v4", "created": "Fri, 30 Nov 2018 23:10:45 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Lorch", "Lars", ""], ["De", "Abir", ""], ["Bhatt", "Samir", ""], ["Trouleau", "William", ""], ["Upadhyay", "Utkarsh", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1810.13044", "submitter": "Imtiaz Ziko", "authors": "Imtiaz Masud Ziko, Eric Granger and Ismail Ben Ayed", "title": "Scalable Laplacian K-modes", "comments": "13 pages, 11 figures. Accepted in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate Laplacian K-modes for joint clustering and density mode finding,\nand propose a concave-convex relaxation of the problem, which yields a parallel\nalgorithm that scales up to large datasets and high dimensions. We optimize a\ntight bound (auxiliary function) of our relaxation, which, at each iteration,\namounts to computing an independent update for each cluster-assignment\nvariable, with guaranteed convergence. Therefore, our bound optimizer can be\ntrivially distributed for large-scale data sets. Furthermore, we show that the\ndensity modes can be obtained as byproducts of the assignment variables via\nsimple maximum-value operations whose additional computational cost is linear\nin the number of data points. Our formulation does not need storing a full\naffinity matrix and computing its eigenvalue decomposition, neither does it\nperform expensive projection steps and Lagrangian-dual inner iterates for the\nsimplex constraints of each point. Furthermore, unlike mean-shift, our\ndensity-mode estimation does not require inner-loop gradient-ascent iterates.\nIt has a complexity independent of feature-space dimension, yields modes that\nare valid data points in the input set and is applicable to discrete domains as\nwell as arbitrary kernels. We report comprehensive experiments over various\ndata sets, which show that our algorithm yields very competitive performances\nin term of optimization quality (i.e., the value of the discrete-variable\nobjective at convergence) and clustering accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 00:01:31 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 19:30:18 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Ziko", "Imtiaz Masud", ""], ["Granger", "Eric", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "1810.13048", "submitter": "Junichi Yamagishi", "authors": "Cheng-I Lai, Alberto Abad, Korin Richmond, Junichi Yamagishi, Najim\n  Dehak, Simon King", "title": "Attentive Filtering Networks for Audio Replay Attack Detection", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An attacker may use a variety of techniques to fool an automatic speaker\nverification system into accepting them as a genuine user. Anti-spoofing\nmethods meanwhile aim to make the system robust against such attacks. The\nASVspoof 2017 Challenge focused specifically on replay attacks, with the\nintention of measuring the limits of replay attack detection as well as\ndeveloping countermeasures against them. In this work, we propose our replay\nattacks detection system - Attentive Filtering Network, which is composed of an\nattention-based filtering mechanism that enhances feature representations in\nboth the frequency and time domains, and a ResNet-based classifier. We show\nthat the network enables us to visualize the automatically acquired feature\nrepresentations that are helpful for spoofing detection. Attentive Filtering\nNetwork attains an evaluation EER of 8.99$\\%$ on the ASVspoof 2017 Version 2.0\ndataset. With system fusion, our best system further obtains a 30$\\%$ relative\nimprovement over the ASVspoof 2017 enhanced baseline system.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 00:23:16 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lai", "Cheng-I", ""], ["Abad", "Alberto", ""], ["Richmond", "Korin", ""], ["Yamagishi", "Junichi", ""], ["Dehak", "Najim", ""], ["King", "Simon", ""]]}, {"id": "1810.13069", "submitter": "Yining Wang", "authors": "Xi Chen, Yining Wang, Yuan Zhou", "title": "Dynamic Assortment Optimization with Changing Contextual Information", "comments": "4 pages, 4 figures. Minor revision and polishing of presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the dynamic assortment optimization problem under a\nfinite selling season of length $T$. At each time period, the seller offers an\narriving customer an assortment of substitutable products under a cardinality\nconstraint, and the customer makes the purchase among offered products\naccording to a discrete choice model. Most existing work associates each\nproduct with a real-valued fixed mean utility and assumes a multinomial logit\nchoice (MNL) model. In many practical applications, feature/contexutal\ninformation of products is readily available. In this paper, we incorporate the\nfeature information by assuming a linear relationship between the mean utility\nand the feature. In addition, we allow the feature information of products to\nchange over time so that the underlying choice model can also be\nnon-stationary. To solve the dynamic assortment optimization under this\nchanging contextual MNL model, we need to simultaneously learn the underlying\nunknown coefficient and makes the decision on the assortment. To this end, we\ndevelop an upper confidence bound (UCB) based policy and establish the regret\nbound on the order of $\\widetilde O(d\\sqrt{T})$, where $d$ is the dimension of\nthe feature and $\\widetilde O$ suppresses logarithmic dependence. We further\nestablished the lower bound $\\Omega(d\\sqrt{T}/K)$ where $K$ is the cardinality\nconstraint of an offered assortment, which is usually small. When $K$ is a\nconstant, our policy is optimal up to logarithmic factors. In the exploitation\nphase of the UCB algorithm, we need to solve a combinatorial optimization for\nassortment optimization based on the learned information. We further develop an\napproximation algorithm and an efficient greedy heuristic. The effectiveness of\nthe proposed policy is further demonstrated by our numerical studies.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 01:52:59 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 03:30:01 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Chen", "Xi", ""], ["Wang", "Yining", ""], ["Zhou", "Yuan", ""]]}, {"id": "1810.13098", "submitter": "Chao Li", "authors": "Chao Li, Zhun Sun, Jinshi Yu, Ming Hou and Qibin Zhao", "title": "Low-Rank Embedding of Kernels in Convolutional Neural Networks under\n  Random Shuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the convolutional neural networks (CNNs) have become popular for\nvarious image processing and computer vision task recently, it remains a\nchallenging problem to reduce the storage cost of the parameters for\nresource-limited platforms. In the previous studies, tensor decomposition (TD)\nhas achieved promising compression performance by embedding the kernel of a\nconvolutional layer into a low-rank subspace. However the employment of TD is\nnaively on the kernel or its specified variants. Unlike the conventional\napproaches, this paper shows that the kernel can be embedded into more general\nor even random low-rank subspaces. We demonstrate this by compressing the\nconvolutional layers via randomly-shuffled tensor decomposition (RsTD) for a\nstandard classification task using CIFAR-10. In addition, we analyze how the\nspatial similarity of the training data influences the low-rank structure of\nthe kernels. The experimental results show that the CNN can be significantly\ncompressed even if the kernels are randomly shuffled. Furthermore, the\nRsTD-based method yields more stable classification accuracy than the\nconventional TD-based methods in a large range of compression ratios.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 04:05:54 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Li", "Chao", ""], ["Sun", "Zhun", ""], ["Yu", "Jinshi", ""], ["Hou", "Ming", ""], ["Zhao", "Qibin", ""]]}, {"id": "1810.13105", "submitter": "Jennifer Jang", "authors": "Jennifer Jang, Heinrich Jiang", "title": "DBSCAN++: Towards fast and scalable density clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DBSCAN is a classical density-based clustering procedure with tremendous\npractical relevance. However, DBSCAN implicitly needs to compute the empirical\ndensity for each sample point, leading to a quadratic worst-case time\ncomplexity, which is too slow on large datasets. We propose DBSCAN++, a simple\nmodification of DBSCAN which only requires computing the densities for a chosen\nsubset of points. We show empirically that, compared to traditional DBSCAN,\nDBSCAN++ can provide not only competitive performance but also added robustness\nin the bandwidth hyperparameter while taking a fraction of the runtime. We also\npresent statistical consistency guarantees showing the trade-off between\ncomputational cost and estimation rates. Surprisingly, up to a certain point,\nwe can enjoy the same estimation rates while lowering computational cost,\nshowing that DBSCAN++ is a sub-quadratic algorithm that attains minimax optimal\nrates for level-set estimation, a quality that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 04:52:46 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 14:54:17 GMT"}, {"version": "v3", "created": "Fri, 17 May 2019 18:14:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Jang", "Jennifer", ""], ["Jiang", "Heinrich", ""]]}, {"id": "1810.13108", "submitter": "Andr\\'e Ricardo Belotto Da Silva", "authors": "Andr\\'e Belotto da Silva and Maxime Gazeau", "title": "A general system of differential equations to model first order adaptive\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First order optimization algorithms play a major role in large scale machine\nlearning. A new class of methods, called adaptive algorithms, were recently\nintroduced to adjust iteratively the learning rate for each coordinate. Despite\ngreat practical success in deep learning, their behavior and performance on\nmore general loss functions are not well understood. In this paper, we derive a\nnon-autonomous system of differential equations, which is the continuous time\nlimit of adaptive optimization methods. We prove global well-posedness of the\nsystem and we investigate the numerical time convergence of its forward Euler\napproximation. We study, furthermore, the convergence of its trajectories and\ngive conditions under which the differential system, underlying all adaptive\nalgorithms, is suitable for optimization. We discuss convergence to a critical\npoint in the non-convex case and give conditions for the dynamics to avoid\nsaddle points and local maxima. For convex and deterministic loss function, we\nintroduce a suitable Lyapunov functional which allow us to study its rate of\nconvergence. Several other properties of both the continuous and discrete\nsystems are briefly discussed. The differential system studied in the paper is\ngeneral enough to encompass many other classical algorithms (such as Heavy ball\nand Nesterov's accelerated method) and allow us to recover several known\nresults for these algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 05:12:11 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:21:22 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["da Silva", "Andr\u00e9 Belotto", ""], ["Gazeau", "Maxime", ""]]}, {"id": "1810.13118", "submitter": "Cem Keskin", "authors": "Cem Keskin and Shahram Izadi", "title": "SplineNets: Continuous Neural Decision Graphs", "comments": "Accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SplineNets, a practical and novel approach for using conditioning\nin convolutional neural networks (CNNs). SplineNets are continuous\ngeneralizations of neural decision graphs, and they can dramatically reduce\nruntime complexity and computation costs of CNNs, while maintaining or even\nincreasing accuracy. Functions of SplineNets are both dynamic (i.e.,\nconditioned on the input) and hierarchical (i.e., conditioned on the\ncomputational path). SplineNets employ a unified loss function with a desired\nlevel of smoothness over both the network and decision parameters, while\nallowing for sparse activation of a subset of nodes for individual samples. In\nparticular, we embed infinitely many function weights (e.g. filters) on smooth,\nlow dimensional manifolds parameterized by compact B-splines, which are indexed\nby a position parameter. Instead of sampling from a categorical distribution to\npick a branch, samples choose a continuous position to pick a function weight.\nWe further show that by maximizing the mutual information between spline\npositions and class labels, the network can be optimally utilized and\nspecialized for classification tasks. Experiments show that our approach can\nsignificantly increase the accuracy of ResNets with negligible cost in speed,\nmatching the precision of a 110 level ResNet with a 32 level SplineNet.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 06:20:24 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Keskin", "Cem", ""], ["Izadi", "Shahram", ""]]}, {"id": "1810.13135", "submitter": "Naima Chouikhi", "authors": "Naima Chouikhi and Adel M. Alimi", "title": "Adaptive Extreme Learning Machine for Recurrent Beta-basis Function\n  Neural Network Training", "comments": "14 pages and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beta Basis Function Neural Network (BBFNN) is a special kind of kernel basis\nneural networks. It is a feedforward network typified by the use of beta\nfunction as a hidden activation function. Beta is a flexible transfer function\nrepresenting richer forms than the common existing functions. As in every\nnetwork, the architecture setting as well as the learning method are two main\ngauntlets faced by BBFNN. In this paper, new architecture and training\nalgorithm are proposed for the BBFNN. An Extreme Learning Machine (ELM) is used\nas a training approach of BBFNN with the aim of quickening the training\nprocess. The peculiarity of ELM is permitting a certain decrement of the\ncomputing time and complexity regarding the already used BBFNN learning\nalgorithms such as backpropagation, OLS, etc. For the architectural design, a\nrecurrent structure is added to the common BBFNN architecture in order to make\nit more able to deal with complex, non linear and time varying problems.\nThroughout this paper, the conceived recurrent ELM-trained BBFNN is tested on a\nnumber of tasks related to time series prediction, classification and\nregression. Experimental results show noticeable achievements of the proposed\nnetwork compared to common feedforward and recurrent networks trained by ELM\nand using hyperbolic tangent as activation function. These achievements are in\nterms of accuracy and robustness against data breakdowns such as noise signals.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 07:31:08 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Chouikhi", "Naima", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1810.13155", "submitter": "Guoqiang Zhong", "authors": "Guoqiang Zhong, Wencong Jiao and Wei Gao", "title": "Structure Learning of Deep Neural Networks with Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with convolutional neural networks gaining significant achievements\nin many challenging machine learning fields, hand-crafted neural networks no\nlonger satisfy our requirements as designing a network will cost a lot, and\nautomatically generating architectures has attracted increasingly more\nattention and focus. Some research on auto-generated networks has achieved\npromising results. However, they mainly aim at picking a series of single\nlayers such as convolution or pooling layers one by one. There are many elegant\nand creative designs in the carefully hand-crafted neural networks, such as\nInception-block in GoogLeNet, residual block in residual network and dense\nblock in dense convolutional network. Based on reinforcement learning and\ntaking advantages of the superiority of these networks, we propose a novel\nautomatic process to design a multi-block neural network, whose architecture\ncontains multiple types of blocks mentioned above, with the purpose to do\nstructure learning of deep neural networks and explore the possibility whether\ndifferent blocks can be composed together to form a well-behaved neural\nnetwork. The optimal network is created by the Q-learning agent who is trained\nto sequentially pick different types of blocks. To verify the validity of our\nproposed method, we use the auto-generated multi-block neural network to\nconduct experiments on image benchmark datasets MNIST, SVHN and CIFAR-10 image\nclassification task with restricted computational resources. The results\ndemonstrate that our method is very effective, achieving comparable or better\nperformance than hand-crafted networks and advanced auto-generated neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 08:39:22 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Zhong", "Guoqiang", ""], ["Jiao", "Wencong", ""], ["Gao", "Wei", ""]]}, {"id": "1810.13163", "submitter": "Peter Bloem", "authors": "Peter Bloem, Steven de Rooij", "title": "A tutorial on MDL hypothesis testing for graph analysis", "comments": "arXiv admin note: text overlap with arXiv:1701.02026", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document provides a tutorial description of the use of the MDL principle\nin complex graph analysis. We give a brief summary of the preliminary subjects,\nand describe the basic principle, using the example of analysing the size of\nthe largest clique in a graph. We also provide a discussion of how to interpret\nthe results of such an analysis, making note of several common pitfalls.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 08:58:15 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Bloem", "Peter", ""], ["de Rooij", "Steven", ""]]}, {"id": "1810.13192", "submitter": "Qiang Hu", "authors": "Qiang Hu and Hao Zhang", "title": "Nearly-tight bounds on linear regions of piecewise linear neural\n  networks", "comments": "Counting linear regions of neural networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The developments of deep neural networks (DNN) in recent years have ushered a\nbrand new era of artificial intelligence. DNNs are proved to be excellent in\nsolving very complex problems, e.g., visual recognition and text understanding,\nto the extent of competing with or even surpassing people. Despite inspiring\nand encouraging success of DNNs, thorough theoretical analyses still lack to\nunravel the mystery of their magics. The design of DNN structure is dominated\nby empirical results in terms of network depth, number of neurons and\nactivations. A few of remarkable works published recently in an attempt to\ninterpret DNNs have established the first glimpses of their internal\nmechanisms. Nevertheless, research on exploring how DNNs operate is still at\nthe initial stage with plenty of room for refinement. In this paper, we extend\nprecedent research on neural networks with piecewise linear activations (PLNN)\nconcerning linear regions bounds. We present (i) the exact maximal number of\nlinear regions for single layer PLNNs; (ii) a upper bound for multi-layer\nPLNNs; and (iii) a tighter upper bound for the maximal number of liner regions\non rectifier networks. The derived bounds also indirectly explain why deep\nmodels are more powerful than shallow counterparts, and how non-linearity of\nactivation functions impacts on expressiveness of networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 10:08:40 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 12:25:27 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2018 12:25:51 GMT"}, {"version": "v4", "created": "Wed, 26 Dec 2018 14:55:57 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Hu", "Qiang", ""], ["Zhang", "Hao", ""]]}, {"id": "1810.13243", "submitter": "Akhilesh Gotmare", "authors": "Akhilesh Gotmare, Nitish Shirish Keskar, Caiming Xiong and Richard\n  Socher", "title": "A Closer Look at Deep Learning Heuristics: Learning rate restarts,\n  Warmup and Distillation", "comments": "We use empirical tools of mode connectivity and SVCCA to investigate\n  neural network training heuristics of learning rate restarts, warmup and\n  knowledge distillation. arXiv admin note: text overlap with arXiv:1806.06977", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence rate and final performance of common deep learning models\nhave significantly benefited from heuristics such as learning rate schedules,\nknowledge distillation, skip connections, and normalization layers. In the\nabsence of theoretical underpinnings, controlled experiments aimed at\nexplaining these strategies can aid our understanding of deep learning\nlandscapes and the training dynamics. Existing approaches for empirical\nanalysis rely on tools of linear interpolation and visualizations with\ndimensionality reduction, each with their limitations. Instead, we revisit such\nanalysis of heuristics through the lens of recently proposed methods for loss\nsurface and representation analysis, viz., mode connectivity and canonical\ncorrelation analysis (CCA), and hypothesize reasons for the success of the\nheuristics. In particular, we explore knowledge distillation and learning rate\nheuristics of (cosine) restarts and warmup using mode connectivity and CCA. Our\nempirical analysis suggests that: (a) the reasons often quoted for the success\nof cosine annealing are not evidenced in practice; (b) that the effect of\nlearning rate warmup is to prevent the deeper layers from creating training\ninstability; and (c) that the latent knowledge shared by the teacher is\nprimarily disbursed to the deeper layers.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:36:07 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Gotmare", "Akhilesh", ""], ["Keskar", "Nitish Shirish", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1810.13247", "submitter": "Nghia (Andy) Nguyen", "authors": "Mei Lin, Vanya Jaitly, Iris Wang, Zhihong Hu, Lei Chen, Md. Amer\n  Wahed, Zeyad Kanaan, Adan Rios, Andy N.D. Nguyen", "title": "Application of Deep Learning on Predicting Prognosis of Acute Myeloid\n  Leukemia with Cytogenetics, Age, and Mutations", "comments": "11 pages, 1 table, 1 figure. arXiv admin note: substantial text\n  overlap with arXiv:1801.01019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore how Deep Learning (DL) can be utilized to predict prognosis of\nacute myeloid leukemia (AML). Out of TCGA (The Cancer Genome Atlas) database,\n94 AML cases are used in this study. Input data include age, 10 common\ncytogenetic and 23 most common mutation results; output is the prognosis\n(diagnosis to death, DTD). In our DL network, autoencoders are stacked to form\na hierarchical DL model from which raw data are compressed and organized and\nhigh-level features are extracted. The network is written in R language and is\ndesigned to predict prognosis of AML for a given case (DTD of more than or less\nthan 730 days). The DL network achieves an excellent accuracy of 83% in\npredicting prognosis. As a proof-of-concept study, our preliminary results\ndemonstrate a practical application of DL in future practice of prognostic\nprediction using next-gen sequencing (NGS) data.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:03:35 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lin", "Mei", ""], ["Jaitly", "Vanya", ""], ["Wang", "Iris", ""], ["Hu", "Zhihong", ""], ["Chen", "Lei", ""], ["Wahed", "Md. Amer", ""], ["Kanaan", "Zeyad", ""], ["Rios", "Adan", ""], ["Nguyen", "Andy N. D.", ""]]}, {"id": "1810.13258", "submitter": "Luigi Carratino", "authors": "Alessandro Rudi, Daniele Calandriello, Luigi Carratino, Lorenzo\n  Rosasco", "title": "On Fast Leverage Score Sampling and Optimal Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leverage score sampling provides an appealing way to perform approximate\ncomputations for large matrices. Indeed, it allows to derive faithful\napproximations with a complexity adapted to the problem at hand. Yet,\nperforming leverage scores sampling is a challenge in its own right requiring\nfurther approximations. In this paper, we study the problem of leverage score\nsampling for positive definite matrices defined by a kernel. Our contribution\nis twofold. First we provide a novel algorithm for leverage score sampling and\nsecond, we exploit the proposed method in statistical learning by deriving a\nnovel solver for kernel ridge regression. Our main technical contribution is\nshowing that the proposed algorithms are currently the most efficient and\naccurate for these problems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 12:54:56 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 11:08:26 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Rudi", "Alessandro", ""], ["Calandriello", "Daniele", ""], ["Carratino", "Luigi", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1810.13259", "submitter": "Amichai Painsky", "authors": "Amichai Painsky, Meir Feder, Naftali Tishby", "title": "Non-linear Canonical Correlation Analysis: A Compressed Representation\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is a linear representation learning\nmethod that seeks maximally correlated variables in multi-view data. Non-linear\nCCA extends this notion to a broader family of transformations, which are more\npowerful in many real-world applications. Given the joint probability, the\nAlternating Conditional Expectation (ACE) algorithm provides an optimal\nsolution to the non-linear CCA problem. However, it suffers from limited\nperformance and an increasing computational burden when only a finite number of\nsamples is available. In this work we introduce an information-theoretic\ncompressed representation framework for the non-linear CCA problem (CRCCA),\nwhich extends the classical ACE approach. Our suggested framework seeks compact\nrepresentations of the data that allow a maximal level of correlation. This way\nwe control the trade-off between the flexibility and the complexity of the\nmodel. CRCCA provides theoretical bounds and optimality conditions, as we\nestablish fundamental connections to rate-distortion theory, the information\nbottleneck and remote source coding. In addition, it allows a soft\ndimensionality reduction, as the compression level is determined by the mutual\ninformation between the original noisy data and the extracted signals. Finally,\nwe introduce a simple implementation of the CRCCA framework, based on lattice\nquantization.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 12:57:35 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 08:46:32 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Painsky", "Amichai", ""], ["Feder", "Meir", ""], ["Tishby", "Naftali", ""]]}, {"id": "1810.13278", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, Debesh Jha, Michael Riegler, P{\\aa}l Halvorsen,\n  Hugo Lewi Hammer, H{\\aa}vard D. Johansen, Dag Johansen", "title": "The Medico-Task 2018: Disease Detection in the Gastrointestinal Tract\n  using Global Features and Deep Learning", "comments": "2 pages + 1 page for references, 1 figure, Conference paper", "journal-ref": "MediaEval 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our approach for the 2018 Medico Task classifying\ndiseases in the gastrointestinal tract. We have proposed a system based on\nglobal features and deep neural networks. The best approach combines two neural\nnetworks, and the reproducible experimental results signify the efficiency of\nthe proposed model with an accuracy rate of 95.80%, a precision of 95.87%, and\nan F1-score of 95.80%.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 13:35:23 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Thambawita", "Vajira", ""], ["Jha", "Debesh", ""], ["Riegler", "Michael", ""], ["Halvorsen", "P\u00e5l", ""], ["Hammer", "Hugo Lewi", ""], ["Johansen", "H\u00e5vard D.", ""], ["Johansen", "Dag", ""]]}, {"id": "1810.13296", "submitter": "Xiaoyu Lu", "authors": "Xiaoyu Lu, Tom Rainforth, Yuan Zhou, Jan-Willem van de Meent, Yee Whye\n  Teh", "title": "On Exploration, Exploitation and Learning in Adaptive Importance\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adaptive importance sampling (AIS) as an online learning problem and\nargue for the importance of the trade-off between exploration and exploitation\nin this adaptation. Borrowing ideas from the bandits literature, we propose\nDaisee, a partition-based AIS algorithm. We further introduce a notion of\nregret for AIS and show that Daisee has $\\mathcal{O}(\\sqrt{T}(\\log\nT)^{\\frac{3}{4}})$ cumulative pseudo-regret, where $T$ is the number of\niterations. We then extend Daisee to adaptively learn a hierarchical\npartitioning of the sample space for more efficient sampling and confirm the\nperformance of both algorithms empirically.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:13:55 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lu", "Xiaoyu", ""], ["Rainforth", "Tom", ""], ["Zhou", "Yuan", ""], ["van de Meent", "Jan-Willem", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1810.13306", "submitter": "Quanming Yao", "authors": "Quanming Yao, Mengshuo Wang, Yuqiang Chen, Wenyuan Dai, Yu-Feng Li,\n  Wei-Wei Tu, Qiang Yang, Yang Yu", "title": "Taking Human out of Learning Applications: A Survey on Automated Machine\n  Learning", "comments": "This is a preliminary and will be kept updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have deeply rooted in our everyday life. However,\nsince it is knowledge- and labor-intensive to pursue good learning performance,\nhuman experts are heavily involved in every aspect of machine learning. In\norder to make machine learning techniques easier to apply and reduce the demand\nfor experienced human experts, automated machine learning (AutoML) has emerged\nas a hot topic with both industrial and academic interest. In this paper, we\nprovide an up to date survey on AutoML. First, we introduce and define the\nAutoML problem, with inspiration from both realms of automation and machine\nlearning. Then, we propose a general AutoML framework that not only covers most\nexisting approaches to date but also can guide the design for new methods.\nSubsequently, we categorize and review the existing works from two aspects,\ni.e., the problem setup and the employed techniques. Finally, we provide a\ndetailed analysis of AutoML approaches and explain the reasons underneath their\nsuccessful applications. We hope this survey can serve as not only an\ninsightful guideline for AutoML beginners but also an inspiration for future\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:35:38 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 11:29:43 GMT"}, {"version": "v3", "created": "Thu, 17 Jan 2019 10:47:18 GMT"}, {"version": "v4", "created": "Mon, 16 Dec 2019 05:36:13 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yao", "Quanming", ""], ["Wang", "Mengshuo", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Li", "Yu-Feng", ""], ["Tu", "Wei-Wei", ""], ["Yang", "Qiang", ""], ["Yu", "Yang", ""]]}, {"id": "1810.13317", "submitter": "Abdi-Hakin Dirie", "authors": "Abdi-Hakin Dirie, Abubakar Abid, James Zou", "title": "Contrastive Multivariate Singular Spectrum Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Contrastive Multivariate Singular Spectrum Analysis, a novel\nunsupervised method for dimensionality reduction and signal decomposition of\ntime series data. By utilizing an appropriate background dataset, the method\ntransforms a target time series dataset in a way that evinces the sub-signals\nthat are enhanced in the target dataset, as opposed to only those that account\nfor the greatest variance. This shifts the goal from finding signals that\nexplain the most variance to signals that matter the most to the analyst. We\ndemonstrate our method on an illustrative synthetic example, as well as show\nthe utility of our method in the downstream clustering of electrocardiogram\nsignals from the public MHEALTH dataset.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:50:01 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Dirie", "Abdi-Hakin", ""], ["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1810.13333", "submitter": "Micha\\\"el Perrot", "authors": "Micha\\\"el Perrot, Ulrike von Luxburg", "title": "Boosting for Comparison-Based Learning", "comments": "This is the extended version (38 pages) of a paper accepted to the\n  International Joint Conference on Artificial Intelligence (IJCAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of classification in a comparison-based setting:\ngiven a set of objects, we only have access to triplet comparisons of the form\n\"object $x_i$ is closer to object $x_j$ than to object $x_k$.\" In this paper we\nintroduce TripletBoost, a new method that can learn a classifier just from such\ntriplet comparisons. The main idea is to aggregate the triplets information\ninto weak classifiers, which can subsequently be boosted to a strong\nclassifier. Our method has two main advantages: (i) it is applicable to data\nfrom any metric space, and (ii) it can deal with large scale problems using\nonly passively obtained and noisy triplets. We derive theoretical\ngeneralization guarantees and a lower bound on the number of necessary\ntriplets, and we empirically show that our method is both competitive with\nstate of the art approaches and resistant to noise.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:26:12 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 17:17:05 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Perrot", "Micha\u00ebl", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1810.13337", "submitter": "Pengcheng Yin", "authors": "Pengcheng Yin, Graham Neubig, Miltiadis Allamanis, Marc Brockschmidt,\n  Alexander L. Gaunt", "title": "Learning to Represent Edits", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of learning distributed representations of edits. By\ncombining a \"neural editor\" with an \"edit encoder\", our models learn to\nrepresent the salient information of an edit and can be used to apply edits to\nnew inputs. We experiment on natural language and source code edit data. Our\nevaluation yields promising results that suggest that our neural network models\nlearn to capture the structure and semantics of edits. We hope that this\ninteresting task and data source will inspire other researchers to work further\non this problem.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:29:30 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 05:16:03 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Yin", "Pengcheng", ""], ["Neubig", "Graham", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""], ["Gaunt", "Alexander L.", ""]]}, {"id": "1810.13348", "submitter": "Keyang Xu", "authors": "Keyang Xu, Mike Lam, Jingzhi Pang, Xin Gao, Charlotte Band, Piyush\n  Mathur MD, Frank Papay MD, Ashish K. Khanna MD, Jacek B. Cywinski MD, Kamal\n  Maheshwari MD, Pengtao Xie, Eric Xing", "title": "Multimodal Machine Learning for Automated ICD Coding", "comments": "Machine Learning for Healthcare 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a multimodal machine learning model to predict ICD-10\ndiagnostic codes. We developed separate machine learning models that can handle\ndata from different modalities, including unstructured text, semi-structured\ntext and structured tabular data. We further employed an ensemble method to\nintegrate all modality-specific models to generate ICD-10 codes. Key evidence\nwas also extracted to make our prediction more convincing and explainable. We\nused the Medical Information Mart for Intensive Care III (MIMIC -III) dataset\nto validate our approach. For ICD code prediction, our best-performing model\n(micro-F1 = 0.7633, micro-AUC = 0.9541) significantly outperforms other\nbaseline models including TF-IDF (micro-F1 = 0.6721, micro-AUC = 0.7879) and\nText-CNN model (micro-F1 = 0.6569, micro-AUC = 0.9235). For interpretability,\nour approach achieves a Jaccard Similarity Coefficient (JSC) of 0.1806 on text\ndata and 0.3105 on tabular data, where well-trained physicians achieve 0.2780\nand 0.5002 respectively.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:39:32 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 08:44:55 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 07:58:41 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Xu", "Keyang", ""], ["Lam", "Mike", ""], ["Pang", "Jingzhi", ""], ["Gao", "Xin", ""], ["Band", "Charlotte", ""], ["MD", "Piyush Mathur", ""], ["MD", "Frank Papay", ""], ["MD", "Ashish K. Khanna", ""], ["MD", "Jacek B. Cywinski", ""], ["MD", "Kamal Maheshwari", ""], ["Xie", "Pengtao", ""], ["Xing", "Eric", ""]]}, {"id": "1810.13373", "submitter": "David Barrett", "authors": "David G.T. Barrett, Ari S. Morcos and Jakob H. Macke", "title": "Analyzing biological and artificial neural networks: challenges with\n  opportunities for synergy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) transform stimuli across multiple processing\nstages to produce representations that can be used to solve complex tasks, such\nas object recognition in images. However, a full understanding of how they\nachieve this remains elusive. The complexity of biological neural networks\nsubstantially exceeds the complexity of DNNs, making it even more challenging\nto understand the representations that they learn. Thus, both machine learning\nand computational neuroscience are faced with a shared challenge: how can we\nanalyze their representations in order to understand how they solve complex\ntasks?\n  We review how data-analysis concepts and techniques developed by\ncomputational neuroscientists can be useful for analyzing representations in\nDNNs, and in turn, how recently developed techniques for analysis of DNNs can\nbe useful for understanding representations in biological neural networks. We\nexplore opportunities for synergy between the two fields, such as the use of\nDNNs as in-silico model systems for neuroscience, and how this synergy can lead\nto new hypotheses about the operating principles of biological neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:09:44 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Barrett", "David G. T.", ""], ["Morcos", "Ari S.", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1810.13395", "submitter": "Chaoyue Liu", "authors": "Chaoyue Liu, Mikhail Belkin", "title": "Accelerating SGD with momentum for over-parameterized learning", "comments": "new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nesterov SGD is widely used for training modern neural networks and other\nmachine learning models. Yet, its advantages over SGD have not been\ntheoretically clarified. Indeed, as we show in our paper, both theoretically\nand empirically, Nesterov SGD with any parameter selection does not in general\nprovide acceleration over ordinary SGD. Furthermore, Nesterov SGD may diverge\nfor step sizes that ensure convergence of ordinary SGD. This is in contrast to\nthe classical results in the deterministic scenario, where the same step size\nensures accelerated convergence of the Nesterov's method over optimal gradient\ndescent.\n  To address the non-acceleration issue, we introduce a compensation term to\nNesterov SGD. The resulting algorithm, which we call MaSS, converges for same\nstep sizes as SGD. We prove that MaSS obtains an accelerated convergence rates\nover SGD for any mini-batch size in the linear setting. For full batch, the\nconvergence rate of MaSS matches the well-known accelerated rate of the\nNesterov's method.\n  We also analyze the practically important question of the dependence of the\nconvergence rate and optimal hyper-parameters on the mini-batch size,\ndemonstrating three distinct regimes: linear scaling, diminishing returns and\nsaturation.\n  Experimental evaluation of MaSS for several standard architectures of deep\nnetworks, including ResNet and convolutional networks, shows improved\nperformance over SGD, Nesterov SGD and Adam.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:44:05 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 21:30:32 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 16:58:03 GMT"}, {"version": "v4", "created": "Mon, 18 Feb 2019 18:53:41 GMT"}, {"version": "v5", "created": "Fri, 27 Sep 2019 17:38:08 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Liu", "Chaoyue", ""], ["Belkin", "Mikhail", ""]]}, {"id": "1810.13400", "submitter": "Brandon Amos", "authors": "Brandon Amos, Ivan Dario Jimenez Rodriguez, Jacob Sacks, Byron Boots,\n  J. Zico Kolter", "title": "Differentiable MPC for End-to-end Planning and Control", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present foundations for using Model Predictive Control (MPC) as a\ndifferentiable policy class for reinforcement learning in continuous state and\naction spaces. This provides one way of leveraging and combining the advantages\nof model-free and model-based approaches. Specifically, we differentiate\nthrough MPC by using the KKT conditions of the convex approximation at a fixed\npoint of the controller. Using this strategy, we are able to learn the cost and\ndynamics of a controller via end-to-end learning. Our experiments focus on\nimitation learning in the pendulum and cartpole domains, where we learn the\ncost and dynamics terms of an MPC policy class. We show that our MPC policies\nare significantly more data-efficient than a generic neural network and that\nour method is superior to traditional system identification in a setting where\nthe expert is unrealizable.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:46:38 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 18:58:30 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 17:49:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Amos", "Brandon", ""], ["Rodriguez", "Ivan Dario Jimenez", ""], ["Sacks", "Jacob", ""], ["Boots", "Byron", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1810.13421", "submitter": "Saeid Haghighatshoar", "authors": "Saeid Haghighatshoar, and Giuseppe Caire", "title": "Multiple Measurement Vectors Problem: A Decoupling Property and its\n  Applications", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a Compressed Sensing (CS) problem known as Multiple Measurement\nVectors (MMV) problem, which arises in joint estimation of multiple signal\nrealizations when the signal samples have a common (joint) sparse support over\na fixed known dictionary. Although there is a vast literature on the analysis\nof MMV, it is not yet fully known how the number of signal samples and their\nstatistical correlations affects the performance of the joint estimation in\nMMV. Moreover, in many instances of MMV the underlying sparsifying dictionary\nmay not be precisely known, and it is still an open problem to quantify how the\ndictionary mismatch may affect the estimation performance.\n  In this paper, we focus on $\\ell_{2,1}$-norm regularized least squares\n($\\ell_{2,1}$-LS) as a well-known and widely-used MMV algorithm in the\nliterature. We prove an interesting decoupling property for $\\ell_{2,1}$-LS,\nwhere we show that it can be decomposed into two phases: i) use all the signal\nsamples to estimate the signal covariance matrix (coupled phase), ii) plug in\nthe resulting covariance estimate as the true covariance matrix into the\nMinimum Mean Squared Error (MMSE) estimator to reconstruct each signal sample\nindividually (decoupled phase). As a consequence of this decomposition, we are\nable to provide further insights on the performance of $\\ell_{2,1}$-LS for MMV.\nIn particular, we address how the signal correlations and dictionary mismatch\naffects its performance. Moreover, we show that by using the decoupling\nproperty one can obtain a variety of MMV algorithms with performances even\nbetter than that of $\\ell_{2,1}$-LS. We also provide numerical simulations to\nvalidate our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:33:06 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 12:40:07 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Haghighatshoar", "Saeid", ""], ["Caire", "Giuseppe", ""]]}, {"id": "1810.13425", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Irene Kim, Rushil Anirudh, Peer-Timo Bremer", "title": "Understanding Deep Neural Networks through Input Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for understanding the functioning of complex machine learning\nmodels are becoming increasingly popular, not only to improve the validation\nprocess, but also to extract new insights about the data via exploratory\nanalysis. Though a large class of such tools currently exists, most assume that\npredictions are point estimates and use a sensitivity analysis of these\nestimates to interpret the model. Using lightweight probabilistic networks we\nshow how including prediction uncertainties in the sensitivity analysis leads\nto: (i) more robust and generalizable models; and (ii) a new approach for model\ninterpretation through uncertainty decomposition. In particular, we introduce a\nnew regularization that takes both the mean and variance of a prediction into\naccount and demonstrate that the resulting networks provide improved\ngeneralization to unseen data. Furthermore, we propose a new technique to\nexplain prediction uncertainties through uncertainties in the input domain,\nthus providing new ways to validate and interpret deep learning models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:36:31 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 02:56:55 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Kim", "Irene", ""], ["Anirudh", "Rushil", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1810.13427", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Rushil Anirudh, Rahul Sridhar and Peer-Timo\n  Bremer", "title": "Unsupervised Dimension Selection using a Blue Noise Spectrum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised dimension selection is an important problem that seeks to reduce\ndimensionality of data, while preserving the most useful characteristics. While\ndimensionality reduction is commonly utilized to construct low-dimensional\nembeddings, they produce feature spaces that are hard to interpret. Further, in\napplications such as sensor design, one needs to perform reduction directly in\nthe input domain, instead of constructing transformed spaces. Consequently,\ndimension selection (DS) aims to solve the combinatorial problem of identifying\nthe top-$k$ dimensions, which is required for effective experiment design,\nreducing data while keeping it interpretable, and designing better sensing\nmechanisms. In this paper, we develop a novel approach for DS based on graph\nsignal analysis to measure feature influence. By analyzing synthetic graph\nsignals with a blue noise spectrum, we show that we can measure the importance\nof each dimension. Using experiments in supervised learning and image masking,\nwe demonstrate the superiority of the proposed approach over existing\ntechniques in capturing crucial characteristics of high dimensional spaces,\nusing only a small subset of the original features.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:40:40 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Anirudh", "Rushil", ""], ["Sridhar", "Rahul", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1810.13431", "submitter": "Rihui Ou", "authors": "Rihui Ou, Deborshee Sen, Alexander L Young, David B Dunson", "title": "Targeted stochastic gradient Markov chain Monte Carlo for hidden Markov\n  models with rare latent states", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) algorithms for hidden Markov models often\nrely on the forward-backward sampler. This makes them computationally slow as\nthe length of the time series increases, motivating the recent development of\nsub-sampling-based approaches. These approximate the full posterior by using\nsmall random subsequences of the data at each MCMC iteration within stochastic\ngradient MCMC. In the presence of imbalanced data resulting from rare latent\nstates, subsequences often exclude rare latent state data, leading to\ninaccurate inference and prediction/detection of rare events. We propose a\ntargeted sub-sampling (TASS) approach that over-samples observations\ncorresponding to rare latent states when calculating the stochastic gradient of\nparameters associated with them. TASS uses an initial clustering of the data to\nconstruct subsequence weights that reduce the variance in gradient estimation.\nThis leads to improved sampling efficiency, in particular in settings where the\nrare latent states correspond to extreme observations. We demonstrate\nsubstantial gains in predictive and inferential accuracy on real and synthetic\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:44:20 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 18:04:44 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Ou", "Rihui", ""], ["Sen", "Deborshee", ""], ["Young", "Alexander L", ""], ["Dunson", "David B", ""]]}, {"id": "1810.13444", "submitter": "John Dabiri", "authors": "Kristy L. Schlueter-Kuck and John O. Dabiri", "title": "Model parameter estimation using coherent structure coloring", "comments": "Accepted in the Journal of Fluid Mechanics", "journal-ref": null, "doi": "10.1017/jfm.2018.898", "report-no": null, "categories": "physics.flu-dyn cs.LG physics.ao-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lagrangian data assimilation is a complex problem in oceanic and atmospheric\nmodeling. Tracking drifters in large-scale geophysical flows can involve\nuncertainty in drifter location, complex inertial effects, and other factors\nwhich make comparing them to simulated Lagrangian trajectories from numerical\nmodels extremely challenging. Temporal and spatial discretization, factors\nnecessary in modeling large scale flows, also contribute to separation between\nreal and simulated drifter trajectories. The chaotic advection inherent in\nthese turbulent flows tends to separate even closely spaced tracer particles,\nmaking error metrics based solely on drifter displacements unsuitable for\nestimating model parameters. We propose to instead use error in the coherent\nstructure coloring (CSC) field to assess model skill. The CSC field provides a\nspatial representation of the underlying coherent patterns in the flow, and we\nshow that it is a more robust metric for assessing model accuracy. Through the\nuse of two test cases, one considering spatial uncertainty in particle\ninitialization, and one examining the influence of stochastic error along a\ntrajectory and temporal discretization, we show that error in the coherent\nstructure coloring field can be used to accurately determine single or multiple\nsimultaneously unknown model parameters, whereas a conventional error metric\nbased on error in drifter displacement fails. Because the CSC field enhances\nthe difference in error between correct and incorrect model parameters, error\nminima in model parameter sweeps become more distinct. The effectiveness and\nrobustness of this method for single and multi-parameter estimation in\nanalytical flows suggests that Lagrangian data assimilation for real oceanic\nand atmospheric models would benefit from a similar approach.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:57:26 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Schlueter-Kuck", "Kristy L.", ""], ["Dabiri", "John O.", ""]]}]