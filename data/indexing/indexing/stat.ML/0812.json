[{"id": "0812.0922", "submitter": "Dominik Dannheim", "authors": "Dominik Dannheim, Tancredi Carli, Karl-Johan Grahn, Peter Speckmayer,\n  Alexander Voigt", "title": "PDE-Foam - a probability-density estimation method using self-adapting\n  phase-space binning", "comments": "19 pages, 11 figures; replaced with revised version accepted for\n  publication in NIM A and corrected typos in description of Fig. 7 and 8", "journal-ref": "Nuclear Inst. and Methods in Physics Research, A 606 (2009), pp.\n  717-727", "doi": "10.1016/j.nima.2009.05.028", "report-no": null, "categories": "physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability Density Estimation (PDE) is a multivariate discrimination\ntechnique based on sampling signal and background densities defined by event\nsamples from data or Monte-Carlo (MC) simulations in a multi-dimensional phase\nspace. In this paper, we present a modification of the PDE method that uses a\nself-adapting binning method to divide the multi-dimensional phase space in a\nfinite number of hyper-rectangles (cells). The binning algorithm adjusts the\nsize and position of a predefined number of cells inside the multi-dimensional\nphase space, minimising the variance of the signal and background densities\ninside the cells. The implementation of the binning algorithm PDE-Foam is based\non the MC event-generation package Foam. We present performance results for\nrepresentative examples (toy models) and discuss the dependence of the obtained\nresults on the choice of parameters. The new PDE-Foam shows improved\nclassification capability for small training samples and reduced classification\ntime compared to the original PDE method based on range searching.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2008 12:38:32 GMT"}, {"version": "v2", "created": "Thu, 5 Feb 2009 09:18:39 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2009 09:36:57 GMT"}], "update_date": "2009-07-22", "authors_parsed": [["Dannheim", "Dominik", ""], ["Carli", "Tancredi", ""], ["Grahn", "Karl-Johan", ""], ["Speckmayer", "Peter", ""], ["Voigt", "Alexander", ""]]}, {"id": "0812.1615", "submitter": "Tshilidzi Marwala", "authors": "D. Moon and T. Marwala", "title": "Missing Data using Decision Forest and Computational Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoder neural network is implemented to estimate the missing data.\nGenetic algorithm is implemented for network optimization and estimating the\nmissing data. Missing data is treated as Missing At Random mechanism by\nimplementing maximum likelihood algorithm. The network performance is\ndetermined by calculating the mean square error of the network prediction. The\nnetwork is further optimized by implementing Decision Forest. The impact of\nmissing data is then investigated and decision forrests are found to improve\nthe results.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2008 04:33:38 GMT"}], "update_date": "2008-12-10", "authors_parsed": [["Moon", "D.", ""], ["Marwala", "T.", ""]]}, {"id": "0812.1938", "submitter": "Seth Sullivant", "authors": "Seth Sullivant, Kelli Talaska, Jan Draisma", "title": "Trek separation for Gaussian graphical models", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS760 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 3, 1665-1685", "doi": "10.1214/09-AOS760", "report-no": "IMS-AOS-AOS760", "categories": "stat.ML math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models are semi-algebraic subsets of the cone of positive\ndefinite covariance matrices. Submatrices with low rank correspond to\ngeneralizations of conditional independence constraints on collections of\nrandom variables. We give a precise graph-theoretic characterization of when\nsubmatrices of the covariance matrix have small rank for a general class of\nmixed graphs that includes directed acyclic and undirected graphs as special\ncases. Our new trek separation criterion generalizes the familiar\n$d$-separation criterion. Proofs are based on the trek rule, the resulting\nmatrix factorizations and classical theorems of algebraic combinatorics on the\nexpansions of determinants of path polynomials.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2008 15:30:27 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2009 21:28:21 GMT"}, {"version": "v3", "created": "Mon, 4 Oct 2010 11:38:56 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Sullivant", "Seth", ""], ["Talaska", "Kelli", ""], ["Draisma", "Jan", ""]]}, {"id": "0812.1949", "submitter": "Finn Macleod Dr", "authors": "Finn Macleod, James Gleeson", "title": "Prediction with Restricted Resources and Finite Automata", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain an index of the complexity of a random sequence by allowing the\nrole of the measure in classical probability theory to be played by a function\nwe call the generating mechanism. Typically, this generating mechanism will be\na finite automata. We generate a set of biased sequences by applying a finite\nstate automata with a specified number, $m$, of states to the set of all binary\nsequences. Thus we can index the complexity of our random sequence by the\nnumber of states of the automata. We detail optimal algorithms to predict\nsequences generated in this way.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2008 16:22:26 GMT"}], "update_date": "2008-12-11", "authors_parsed": [["Macleod", "Finn", ""], ["Gleeson", "James", ""]]}, {"id": "0812.2309", "submitter": "Tobias Abenius", "authors": "Tobias Abenius", "title": "Classification of Cell Images Using MPEG-7-influenced Descriptors and\n  Support Vector Machines in Cell Morphology", "comments": "For associated files and erratum, see\n  http://Tobbe.nu/pub/2008/cell.morph.mpeg7.svm/", "journal-ref": null, "doi": null, "report-no": "ISSN 1651-6389", "categories": "stat.AP cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Counting and classifying blood cells is an important diagnostic tool in\nmedicine. Support Vector Machines are increasingly popular and efficient and\ncould replace artificial neural network systems. Here a method to classify\nblood cells is proposed using SVM. A set of statistics on images are\nimplemented in C++. The MPEG-7 descriptors Scalable Color Descriptor, Color\nStructure Descriptor, Color Layout Descriptor and Homogeneous Texture\nDescriptor are extended in size and combined with textural features\ncorresponding to textural properties perceived visually by humans. From a set\nof images of human blood cells these statistics are collected. A SVM is\nimplemented and trained to classify the cell images. The cell images come from\na CellaVision DM-96 machine which classify cells from images from microscopy.\nThe output images and classification of the CellaVision machine is taken as\nground truth, a truth that is 90-95% correct. The problem is divided in two --\nthe primary and the simplified. The primary problem is to classify the same\nclasses as the CellaVision machine. The simplified problem is to differ between\nthe five most common types of white blood cells. An encouraging result is\nachieved in both cases -- error rates of 10.8% and 3.1% -- considering that the\nSVM is misled by the errors in ground truth. Conclusion is that further\ninvestigation of performance is worthwhile.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2008 08:27:02 GMT"}], "update_date": "2008-12-15", "authors_parsed": [["Abenius", "Tobias", ""]]}, {"id": "0812.3201", "submitter": "Yichao Wu", "authors": "Jianqing Fan, Richard Samworth, Yichao Wu", "title": "Ultrahigh dimensional variable selection: beyond the linear model", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection in high-dimensional space characterizes many contemporary\nproblems in scientific discovery and decision making. Many frequently-used\ntechniques are based on independence screening; examples include correlation\nranking (Fan and Lv, 2008) or feature selection using a two-sample t-test in\nhigh-dimensional classification (Tibshirani et al., 2003). Within the context\nof the linear model, Fan and Lv (2008)showed that this simple correlation\nranking possesses a sure independence screening property under certain\nconditions and that its revision, called iteratively sure independent screening\n(ISIS), is needed when the features are marginally unrelated but jointly\nrelated to the response variable. In this paper, we extend ISIS, without\nexplicit definition of residuals, to a general pseudo-likelihood framework,\nwhich includes generalized linear models as a special case. Even in the\nleast-squares setting, the new method improves ISIS by allowing variable\ndeletion in the iterative process. Our technique allows us to select important\nfeatures in high-dimensional classification where the popularly used two-sample\nt-method fails. A new technique is introduced to reduce the false discovery\nrate in the feature screening stage. Several simulated and two real data\nexamples are presented to illustrate the methodology.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2008 03:34:06 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Fan", "Jianqing", ""], ["Samworth", "Richard", ""], ["Wu", "Yichao", ""]]}, {"id": "0812.4618", "submitter": "Yu Ding", "authors": "Yu Ding, Yiu-Cho Chung, Kun Huang, and Orlando P. Simonetti", "title": "Identifying Relevant Eigenimages - a Random Matrix Approach", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cond-mat.dis-nn physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensional reduction of high dimensional data can be achieved by keeping\nonly the relevant eigenmodes after principal component analysis. However,\ndifferentiating relevant eigenmodes from the random noise eigenmodes is\nproblematic. A new method based on the random matrix theory and a statistical\ngoodness-of-fit test is proposed in this paper. It is validated by numerical\nsimulations and applied to real-time magnetic resonance cardiac cine images.\n", "versions": [{"version": "v1", "created": "Thu, 25 Dec 2008 17:18:27 GMT"}], "update_date": "2008-12-31", "authors_parsed": [["Ding", "Yu", ""], ["Chung", "Yiu-Cho", ""], ["Huang", "Kun", ""], ["Simonetti", "Orlando P.", ""]]}, {"id": "0812.4648", "submitter": "Kyung-Ah Sohn", "authors": "Kyung-Ah Sohn, Eric P. Xing", "title": "A hierarchical Dirichlet process mixture model for haplotype\n  reconstruction from multi-population data", "comments": "Published in at http://dx.doi.org/10.1214/08-AOAS225 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 2, 791-821", "doi": "10.1214/08-AOAS225", "report-no": "IMS-AOAS-AOAS225", "categories": "stat.ML q-bio.GN q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The perennial problem of \"how many clusters?\" remains an issue of substantial\ninterest in data mining and machine learning communities, and becomes\nparticularly salient in large data sets such as populational genomic data where\nthe number of clusters needs to be relatively large and open-ended. This\nproblem gets further complicated in a co-clustering scenario in which one needs\nto solve multiple clustering problems simultaneously because of the presence of\ncommon centroids (e.g., ancestors) shared by clusters (e.g., possible descents\nfrom a certain ancestor) from different multiple-cluster samples (e.g.,\ndifferent human subpopulations). In this paper we present a hierarchical\nnonparametric Bayesian model to address this problem in the context of\nmulti-population haplotype inference. Uncovering the haplotypes of single\nnucleotide polymorphisms is essential for many biological and medical\napplications. While it is uncommon for the genotype data to be pooled from\nmultiple ethnically distinct populations, few existing programs have explicitly\nleveraged the individual ethnic information for haplotype inference. In this\npaper we present a new haplotype inference program, Haploi, which makes use of\nsuch information and is readily applicable to genotype sequences with thousands\nof SNPs from heterogeneous populations, with competent and sometimes superior\nspeed and accuracy comparing to the state-of-the-art programs. Underlying\nHaploi is a new haplotype distribution model based on a nonparametric Bayesian\nformalism known as the hierarchical Dirichlet process, which represents a\ntractable surrogate to the coalescent process. The proposed model is\nexchangeable, unbounded, and capable of coupling demographic information of\ndifferent populations.\n", "versions": [{"version": "v1", "created": "Fri, 26 Dec 2008 06:40:01 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2009 08:17:58 GMT"}], "update_date": "2009-08-20", "authors_parsed": [["Sohn", "Kyung-Ah", ""], ["Xing", "Eric P.", ""]]}, {"id": "0812.4905", "submitter": "Jure Leskovec", "authors": "Jure Leskovec, Deepayan Chakrabarti, Jon Kleinberg, Christos Faloutsos\n  and Zoubin Ghahramani", "title": "Kronecker Graphs: An Approach to Modeling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we model networks with a mathematically tractable model that allows\nfor rigorous analysis of network properties? Networks exhibit a long list of\nsurprising properties: heavy tails for the degree distribution; small\ndiameters; and densification and shrinking diameters over time. Most present\nnetwork models either fail to match several of the above properties, are\ncomplicated to analyze mathematically, or both. In this paper we propose a\ngenerative model for networks that is both mathematically tractable and can\ngenerate networks that have the above mentioned properties. Our main idea is to\nuse the Kronecker product to generate graphs that we refer to as \"Kronecker\ngraphs\".\n  First, we prove that Kronecker graphs naturally obey common network\nproperties. We also provide empirical evidence showing that Kronecker graphs\ncan effectively model the structure of real networks.\n  We then present KronFit, a fast and scalable algorithm for fitting the\nKronecker graph generation model to large real networks. A naive approach to\nfitting would take super- exponential time. In contrast, KronFit takes linear\ntime, by exploiting the structure of Kronecker matrix multiplication and by\nusing statistical simulation techniques.\n  Experiments on large real and synthetic networks show that KronFit finds\naccurate parameters that indeed very well mimic the properties of target\nnetworks. Once fitted, the model parameters can be used to gain insights about\nthe network structure, and the resulting synthetic graphs can be used for null-\nmodels, anonymization, extrapolations, and graph summarization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2008 13:22:23 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2009 21:52:11 GMT"}], "update_date": "2009-08-22", "authors_parsed": [["Leskovec", "Jure", ""], ["Chakrabarti", "Deepayan", ""], ["Kleinberg", "Jon", ""], ["Faloutsos", "Christos", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "0812.5087", "submitter": "Mladen Kolar", "authors": "Mladen Kolar, Le Song, Amr Ahmed, Eric P. Xing", "title": "Estimating time-varying networks", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS308 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 1, 94-123", "doi": "10.1214/09-AOAS308", "report-no": "IMS-AOAS-AOAS308", "categories": "stat.ML q-bio.MN q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic networks are a plausible representation of the relational\ninformation among entities in dynamic systems such as living cells or social\ncommunities. While there is a rich literature in estimating a static or\ntemporally invariant network from observation data, little has been done toward\nestimating time-varying networks from time series of entity attributes. In this\npaper we present two new machine learning methods for estimating time-varying\nnetworks, which both build on a temporally smoothed $l_1$-regularized logistic\nregression formalism that can be cast as a standard convex-optimization problem\nand solved efficiently using generic solvers scalable to large networks. We\nreport promising results on recovering simulated time-varying networks. For\nreal data sets, we reverse engineer the latent sequence of temporally rewiring\npolitical networks between Senators from the US Senate voting records and the\nlatent evolving regulatory networks underlying 588 genes across the life cycle\nof Drosophila melanogaster from the microarray time course.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2008 15:45:59 GMT"}, {"version": "v2", "created": "Wed, 20 Oct 2010 06:26:24 GMT"}], "update_date": "2010-10-21", "authors_parsed": [["Kolar", "Mladen", ""], ["Song", "Le", ""], ["Ahmed", "Amr", ""], ["Xing", "Eric P.", ""]]}]