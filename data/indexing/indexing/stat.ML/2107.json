[{"id": "2107.00052", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Hugo Berard, Gauthier Gidel, Ioannis Mitliagkas, Simon\n  Lacoste-Julien", "title": "Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth\n  Games: Convergence Analysis under Expected Co-coercivity", "comments": "35 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two of the most prominent algorithms for solving unconstrained smooth games\nare the classical stochastic gradient descent-ascent (SGDA) and the recently\nintroduced stochastic consensus optimization (SCO) (Mescheder et al., 2017).\nSGDA is known to converge to a stationary point for specific classes of games,\nbut current convergence analyses require a bounded variance assumption. SCO is\nused successfully for solving large-scale adversarial problems, but its\nconvergence guarantees are limited to its deterministic variant. In this work,\nwe introduce the expected co-coercivity condition, explain its benefits, and\nprovide the first last-iterate convergence guarantees of SGDA and SCO under\nthis condition for solving a class of stochastic variational inequality\nproblems that are potentially non-monotone. We prove linear convergence of both\nmethods to a neighborhood of the solution when they use constant step-size, and\nwe propose insightful stepsize-switching rules to guarantee convergence to the\nexact solution. In addition, our convergence guarantees hold under the\narbitrary sampling paradigm, and as such, we give insights into the complexity\nof minibatching.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:32:46 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Loizou", "Nicolas", ""], ["Berard", "Hugo", ""], ["Gidel", "Gauthier", ""], ["Mitliagkas", "Ioannis", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2107.00055", "submitter": "Roy Dong", "authors": "Roy Dong and Lillian J. Ratliff", "title": "Which Echo Chamber? Regions of Attraction in Learning with\n  Decision-Dependent Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data-driven methods are deployed in real-world settings, the processes\nthat generate the observed data will often react to the decisions of the\nlearner. For example, a data source may have some incentive for the algorithm\nto provide a particular label (e.g. approve a bank loan), and manipulate their\nfeatures accordingly. Work in strategic classification and decision-dependent\ndistributions seeks to characterize the closed-loop behavior of deploying\nlearning algorithms by explicitly considering the effect of the classifier on\nthe underlying data distribution. More recently, works in performative\nprediction seek to classify the closed-loop behavior by considering general\nproperties of the mapping from classifier to data distribution, rather than an\nexplicit form. Building on this notion, we analyze repeated risk minimization\nas the perturbed trajectories of the gradient flows of performative risk\nminimization. We consider the case where there may be multiple local minimizers\nof performative risk, motivated by real world situations where the initial\nconditions may have significant impact on the long-term behavior of the system.\nAs a motivating example, we consider a company whose current employee\ndemographics affect the applicant pool they interview: the initial demographics\nof the company can affect the long-term hiring policies of the company. We\nprovide sufficient conditions to characterize the region of attraction for the\nvarious equilibria in this settings. Additionally, we introduce the notion of\nperformative alignment, which provides a geometric condition on the convergence\nof repeated risk minimization to performative risk minimizers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:38:08 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dong", "Roy", ""], ["Ratliff", "Lillian J.", ""]]}, {"id": "2107.00068", "submitter": "Zixiu Wang", "authors": "Zixiu Wang, Yiwen Guo and Hu Ding", "title": "Robust Coreset for Continuous-and-Bounded Learning (with Outliers)", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this big data era, we often confront large-scale data in many machine\nlearning tasks. A common approach for dealing with large-scale data is to build\na small summary, {\\em e.g.,} coreset, that can efficiently represent the\noriginal input. However, real-world datasets usually contain outliers and most\nexisting coreset construction methods are not resilient against outliers (in\nparticular, the outliers can be located arbitrarily in the space by an\nadversarial attacker). In this paper, we propose a novel robust coreset method\nfor the {\\em continuous-and-bounded learning} problem (with outliers) which\nincludes a broad range of popular optimization objectives in machine learning,\nlike logistic regression and $ k $-means clustering. Moreover, our robust\ncoreset can be efficiently maintained in fully-dynamic environment. To the best\nof our knowledge, this is the first robust and fully-dynamic coreset\nconstruction method for these optimization problems. We also conduct the\nexperiments to evaluate the effectiveness of our robust coreset in practice.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 19:24:20 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Zixiu", ""], ["Guo", "Yiwen", ""], ["Ding", "Hu", ""]]}, {"id": "2107.00096", "submitter": "Pascal Notin", "authors": "Pascal Notin, Jos\\'e Miguel Hern\\'andez-Lobato, Yarin Gal", "title": "Improving black-box optimization in VAE latent space using decoder\n  uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimization in the latent space of variational autoencoders is a promising\napproach to generate high-dimensional discrete objects that maximize an\nexpensive black-box property (e.g., drug-likeness in molecular generation,\nfunction approximation with arithmetic expressions). However, existing methods\nlack robustness as they may decide to explore areas of the latent space for\nwhich no data was available during training and where the decoder can be\nunreliable, leading to the generation of unrealistic or invalid objects. We\npropose to leverage the epistemic uncertainty of the decoder to guide the\noptimization process. This is not trivial though, as a naive estimation of\nuncertainty in the high-dimensional and structured settings we consider would\nresult in high estimator variance. To solve this problem, we introduce an\nimportance sampling-based estimator that provides more robust estimates of\nepistemic uncertainty. Our uncertainty-guided optimization approach does not\nrequire modifications of the model architecture nor the training process. It\nproduces samples with a better trade-off between black-box objective and\nvalidity of the generated samples, sometimes improving both simultaneously. We\nillustrate these advantages across several experimental settings in digit\ngeneration, arithmetic expression approximation and molecule generation for\ndrug design.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 20:46:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Notin", "Pascal", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Gal", "Yarin", ""]]}, {"id": "2107.00179", "submitter": "Hongji Wei", "authors": "T. Tony Cai and Hongji Wei", "title": "Distributed Nonparametric Function Estimation: Optimal Rate of\n  Convergence and Cost of Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DC cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed minimax estimation and distributed adaptive estimation under\ncommunication constraints for Gaussian sequence model and white noise model are\nstudied. The minimax rate of convergence for distributed estimation over a\ngiven Besov class, which serves as a benchmark for the cost of adaptation, is\nestablished. We then quantify the exact communication cost for adaptation and\nconstruct an optimally adaptive procedure for distributed estimation over a\nrange of Besov classes. The results demonstrate significant differences between\nnonparametric function estimation in the distributed setting and the\nconventional centralized setting. For global estimation, adaptation in general\ncannot be achieved for free in the distributed setting. The new technical tools\nto obtain the exact characterization for the cost of adaptation can be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 02:16:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Cai", "T. Tony", ""], ["Wei", "Hongji", ""]]}, {"id": "2107.00204", "submitter": "Yi Liu", "authors": "Wenjun Zeng and Yi Liu", "title": "Markov Decision Process modeled with Bandits for Sequential Decision\n  Making in Linear-flow", "comments": "Accepted by 2021 KDD Multi-Armed Bandits and Reinforcement Learning\n  Workshop: https://sites.google.com/view/marble-kdd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In membership/subscriber acquisition and retention, we sometimes need to\nrecommend marketing content for multiple pages in sequence. Different from\ngeneral sequential decision making process, the use cases have a simpler flow\nwhere customers per seeing recommended content on each page can only return\nfeedback as moving forward in the process or dropping from it until a\ntermination state. We refer to this type of problems as sequential decision\nmaking in linear--flow. We propose to formulate the problem as an MDP with\nBandits where Bandits are employed to model the transition probability matrix.\nAt recommendation time, we use Thompson sampling (TS) to sample the transition\nprobabilities and allocate the best series of actions with analytical solution\nthrough exact dynamic programming. The way that we formulate the problem allows\nus to leverage TS's efficiency in balancing exploration and exploitation and\nBandit's convenience in modeling actions' incompatibility. In the simulation\nstudy, we observe the proposed MDP with Bandits algorithm outperforms\nQ-learning with $\\epsilon$-greedy and decreasing $\\epsilon$, independent\nBandits, and interaction Bandits. We also find the proposed algorithm's\nperformance is the most robust to changes in the across-page interdependence\nstrength.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 03:54:36 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zeng", "Wenjun", ""], ["Liu", "Yi", ""]]}, {"id": "2107.00352", "submitter": "Yifei Wang", "authors": "Yifei Wang, Yisen Wang, Jiansheng Yang, Zhouchen Lin", "title": "Reparameterized Sampling for Generative Adversarial Networks", "comments": "ECML PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, sampling methods have been successfully applied to enhance the\nsample quality of Generative Adversarial Networks (GANs). However, in practice,\nthey typically have poor sample efficiency because of the independent proposal\nsampling from the generator. In this work, we propose REP-GAN, a novel sampling\nmethod that allows general dependent proposals by REParameterizing the Markov\nchains into the latent space of the generator. Theoretically, we show that our\nreparameterized proposal admits a closed-form Metropolis-Hastings acceptance\nratio. Empirically, extensive experiments on synthetic and real datasets\ndemonstrate that our REP-GAN largely improves the sample efficiency and obtains\nbetter sample quality simultaneously.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:34:55 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Yifei", ""], ["Wang", "Yisen", ""], ["Yang", "Jiansheng", ""], ["Lin", "Zhouchen", ""]]}, {"id": "2107.00360", "submitter": "Marco Huber", "authors": "Nina Schaaf, Omar de Mitri, Hang Beom Kim, Alexander Windberger, Marco\n  F. Huber", "title": "Towards Measuring Bias in Image Classification", "comments": "Accepted for publication at the 30th International Conference on\n  Artificial Neural Networks (ICANN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have become de fact state-of-the-art for\nthe main computer vision tasks. However, due to the complex underlying\nstructure their decisions are hard to understand which limits their use in some\ncontext of the industrial world. A common and hard to detect challenge in\nmachine learning (ML) tasks is data bias. In this work, we present a systematic\napproach to uncover data bias by means of attribution maps. For this purpose,\nfirst an artificial dataset with a known bias is created and used to train\nintentionally biased CNNs. The networks' decisions are then inspected using\nattribution maps. Finally, meaningful metrics are used to measure the\nattribution maps' representativeness with respect to the known bias. The\nproposed study shows that some attribution map techniques highlight the\npresence of bias in the data better than others and metrics can support the\nidentification of bias.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:50:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Schaaf", "Nina", ""], ["de Mitri", "Omar", ""], ["Kim", "Hang Beom", ""], ["Windberger", "Alexander", ""], ["Huber", "Marco F.", ""]]}, {"id": "2107.00363", "submitter": "Nicolas Dewolf", "authors": "Nicolas Dewolf, Bernard De Baets, Willem Waegeman", "title": "Well-calibrated prediction intervals for regression problems", "comments": "submitted to AI Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last few decades, various methods have been proposed for estimating\nprediction intervals in regression settings, including Bayesian methods,\nensemble methods, direct interval estimation methods and conformal prediction\nmethods. An important issue is the calibration of these methods: the generated\nprediction intervals should have a predefined coverage level, without being\noverly conservative. In this work, we review the above four classes of methods\nfrom a conceptual and experimental point of view. Results on benchmark data\nsets from various domains highlight large fluctuations in performance from one\ndata set to another. These observations can be attributed to the violation of\ncertain assumptions that are inherent to some classes of methods. We illustrate\nhow conformal prediction can be used as a general calibration procedure for\nmethods that deliver poor results without a calibration step.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:59:36 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dewolf", "Nicolas", ""], ["De Baets", "Bernard", ""], ["Waegeman", "Willem", ""]]}, {"id": "2107.00371", "submitter": "Sheng Gao", "authors": "Sheng Gao, Zongming Ma", "title": "Sparse GCA and Thresholded Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generalized correlation analysis (GCA) is concerned with uncovering linear\nrelationships across multiple datasets. It generalizes canonical correlation\nanalysis that is designed for two datasets. We study sparse GCA when there are\npotentially multiple generalized correlation tuples in data and the loading\nmatrix has a small number of nonzero rows. It includes sparse CCA and sparse\nPCA of correlation matrices as special cases. We first formulate sparse GCA as\ngeneralized eigenvalue problems at both population and sample levels via a\ncareful choice of normalization constraints. Based on a Lagrangian form of the\nsample optimization problem, we propose a thresholded gradient descent\nalgorithm for estimating GCA loading vectors and matrices in high dimensions.\nWe derive tight estimation error bounds for estimators generated by the\nalgorithm with proper initialization. We also demonstrate the prowess of the\nalgorithm on a number of synthetic datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:15:20 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Gao", "Sheng", ""], ["Ma", "Zongming", ""]]}, {"id": "2107.00379", "submitter": "Hanna Tseran", "authors": "Hanna Tseran, Guido Mont\\'ufar", "title": "On the Expected Complexity of Maxout Networks", "comments": "41 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with neural networks relies on the complexity of the representable\nfunctions, but more importantly, the particular assignment of typical\nparameters to functions of different complexity. Taking the number of\nactivation regions as a complexity measure, recent works have shown that the\npractical complexity of deep ReLU networks is often far from the theoretical\nmaximum. In this work we show that this phenomenon also occurs in networks with\nmaxout (multi-argument) activation functions and when considering the decision\nboundaries in classification tasks. We also show that the parameter space has a\nmultitude of full-dimensional regions with widely different complexity, and\nobtain nontrivial lower bounds on the expected complexity. Finally, we\ninvestigate different parameter initialization procedures and show that they\ncan increase the speed of convergence in training.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:36:32 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Tseran", "Hanna", ""], ["Mont\u00fafar", "Guido", ""]]}, {"id": "2107.00429", "submitter": "Giovanni Volpe", "authors": "Yu-Wei Chang and Laura Natali and Oveis Jamialahmadi and Stefano Romeo\n  and Joana B. Pereira and Giovanni Volpe", "title": "Neural Network Training with Highly Incomplete Datasets", "comments": "11 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training and validation rely on the availability of large\nhigh-quality datasets. However, in many cases only incomplete datasets are\navailable, particularly in health care applications, where each patient\ntypically undergoes different clinical procedures or can drop out of a study.\nSince the data to train the neural networks need to be complete, most studies\ndiscard the incomplete datapoints, which reduces the size of the training data,\nor impute the missing features, which can lead to artefacts. Alas, both\napproaches are inadequate when a large portion of the data is missing. Here, we\nintroduce GapNet, an alternative deep-learning training approach that can use\nhighly incomplete datasets. First, the dataset is split into subsets of samples\ncontaining all values for a certain cluster of features. Then, these subsets\nare used to train individual neural networks. Finally, this ensemble of neural\nnetworks is combined into a single neural network whose training is fine-tuned\nusing all complete datapoints. Using two highly incomplete real-world medical\ndatasets, we show that GapNet improves the identification of patients with\nunderlying Alzheimer's disease pathology and of patients at risk of\nhospitalization due to Covid-19. By distilling the information available in\nincomplete datasets without having to reduce their size or to impute missing\nvalues, GapNet will permit to extract valuable information from a wide range of\ndatasets, benefiting diverse fields from medicine to engineering.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:21:45 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chang", "Yu-Wei", ""], ["Natali", "Laura", ""], ["Jamialahmadi", "Oveis", ""], ["Romeo", "Stefano", ""], ["Pereira", "Joana B.", ""], ["Volpe", "Giovanni", ""]]}, {"id": "2107.00464", "submitter": "Junchi Li", "authors": "Chris Junchi Li, Yaodong Yu, Nicolas Loizou, Gauthier Gidel, Yi Ma,\n  Nicolas Le Roux, Michael I. Jordan", "title": "On the Convergence of Stochastic Extragradient for Bilinear Games with\n  Restarted Iteration Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic bilinear minimax optimization problem, presenting an\nanalysis of the Stochastic ExtraGradient (SEG) method with constant step size,\nand presenting variations of the method that yield favorable convergence. We\nfirst note that the last iterate of the basic SEG method only contracts to a\nfixed neighborhood of the Nash equilibrium, independent of the step size. This\ncontrasts sharply with the standard setting of minimization where standard\nstochastic algorithms converge to a neighborhood that vanishes in proportion to\nthe square-root (constant) step size. Under the same setting, however, we prove\nthat when augmented with iteration averaging, SEG provably converges to the\nNash equilibrium, and such a rate is provably accelerated by incorporating a\nscheduled restarting procedure. In the interpolation setting, we achieve an\noptimal convergence rate up to tight constants. We present numerical\nexperiments that validate our theoretical findings and demonstrate the\neffectiveness of the SEG method when equipped with iteration averaging and\nrestarting.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:51:36 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Chris Junchi", ""], ["Yu", "Yaodong", ""], ["Loizou", "Nicolas", ""], ["Gidel", "Gauthier", ""], ["Ma", "Yi", ""], ["Roux", "Nicolas Le", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2107.00520", "submitter": "Aahlad Manas Puli", "authors": "Aahlad Puli, Lily H. Zhang, Eric K. Oermann, Rajesh Ranganath", "title": "Predictive Modeling in the Presence of Nuisance-Induced Spurious\n  Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep predictive models often make use of spurious correlations between the\nlabel and the covariates that differ between training and test distributions.\nIn many classification tasks, spurious correlations are induced by a changing\nrelationship between the label and some nuisance variables correlated with the\ncovariates. For example, in classifying animals in natural images, the\nbackground, which is the nuisance, can predict the type of animal. This\nnuisance-label relationship does not always hold. We formalize a family of\ndistributions that only differ in the nuisance-label relationship and introduce\na distribution where this relationship is broken called the nuisance-randomized\ndistribution. We introduce a set of predictive models built from the\nnuisance-randomized distribution with representations, that when conditioned\non, do not correlate the label and the nuisance. For models in this set, we\nlower bound the performance for any member of the family with the mutual\ninformation between the representation and the label under the\nnuisance-randomized distribution. To build predictive models that maximize the\nperformance lower bound, we develop Nuisance-Randomized Distillation (NURD). We\nevaluate NURD on a synthetic example, colored-MNIST, and classifying chest\nX-rays. When using non-lung patches as the nuisance in classifying chest\nX-rays, NURD produces models that predict pneumonia under strong spurious\ncorrelations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:12:59 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 08:41:13 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Puli", "Aahlad", ""], ["Zhang", "Lily H.", ""], ["Oermann", "Eric K.", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2107.00531", "submitter": "Chimdimma Noelyn Onah", "authors": "Chimdimma Noelyn Onah, Richard Allmendinger, Julia Handl, Ken W. Dunn", "title": "Towards a fairer reimbursement system for burn patients using\n  cost-sensitive classification", "comments": "Joint KDD 2021 Health Day and 2021 KDD Workshop on Applied Data\n  Science for Healthcare: State of XAI and trustworthiness in Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The adoption of the Prospective Payment System (PPS) in the UK National\nHealth Service (NHS) has led to the creation of patient groups called Health\nResource Groups (HRG). HRGs aim to identify groups of clinically similar\npatients that share similar resource usage for reimbursement purposes. These\ngroups are predominantly identified based on expert advice, with homogeneity\nchecked using the length of stay (LOS). However, for complex patients such as\nthose encountered in burn care, LOS is not a perfect proxy of resource usage,\nleading to incomplete homogeneity checks. To improve homogeneity in resource\nusage and severity, we propose a data-driven model and the inclusion of\npatient-level costing. We investigate whether a data-driven approach that\nconsiders additional measures of resource usage can lead to a more\ncomprehensive model. In particular, a cost-sensitive decision tree model is\nadopted to identify features of importance and rules that allow for a focused\nsegmentation on resource usage (LOS and patient-level cost) and clinical\nsimilarity (severity of burn). The proposed approach identified groups with\nincreased homogeneity compared to the current HRG groups, allowing for a more\nequitable reimbursement of hospital care costs if adopted.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 15:23:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Onah", "Chimdimma Noelyn", ""], ["Allmendinger", "Richard", ""], ["Handl", "Julia", ""], ["Dunn", "Ken W.", ""]]}, {"id": "2107.00593", "submitter": "Lucius Bynum", "authors": "Lucius E.J. Bynum, Joshua R. Loftus, Julia Stoyanovich", "title": "Impact Remediation: Optimal Interventions to Reduce Inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A significant body of research in the data sciences considers unfair\ndiscrimination against social categories such as race or gender that could\noccur or be amplified as a result of algorithmic decisions. Simultaneously,\nreal-world disparities continue to exist, even before algorithmic decisions are\nmade. In this work, we draw on insights from the social sciences and humanistic\nstudies brought into the realm of causal modeling and constrained optimization,\nand develop a novel algorithmic framework for tackling pre-existing real-world\ndisparities. The purpose of our framework, which we call the \"impact\nremediation framework,\" is to measure real-world disparities and discover the\noptimal intervention policies that could help improve equity or access to\nopportunity for those who are underserved with respect to an outcome of\ninterest. We develop a disaggregated approach to tackling pre-existing\ndisparities that relaxes the typical set of assumptions required for the use of\nsocial categories in structural causal models. Our approach flexibly\nincorporates counterfactuals and is compatible with various ontological\nassumptions about the nature of social categories. We demonstrate impact\nremediation with a real-world case study and compare our disaggregated approach\nto an existing state-of-the-art approach, comparing its structure and resulting\npolicy recommendations. In contrast to most work on optimal policy learning, we\nexplore disparity reduction itself as an objective, explicitly focusing the\npower of algorithms on reducing inequality.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:35:12 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Bynum", "Lucius E. J.", ""], ["Loftus", "Joshua R.", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "2107.00594", "submitter": "Salah Zaiem", "authors": "Salah Zaiem, Titouan Parcollet and Slim Essid", "title": "Pretext Tasks selection for multitask self-supervised speech\n  representation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through solving pretext tasks, self-supervised learning leverages unlabeled\ndata to extract useful latent representations replacing traditional input\nfeatures in the downstream task. In various application domains, including\ncomputer vision, natural language processing and audio/speech signal\nprocessing, a wide range of features where engineered through decades of\nresearch efforts. As it turns out, learning to predict such features has proven\nto be a particularly relevant pretext task leading to building useful\nself-supervised representations that prove to be effective for downstream\ntasks. However, methods and common practices for combining such pretext tasks,\nwhere each task targets a different group of features for better performance on\nthe downstream task have not been explored and understood properly. In fact,\nthe process relies almost exclusively on a computationally heavy experimental\nprocedure, which becomes intractable with the increase of the number of pretext\ntasks. This paper introduces a method to select a group of pretext tasks among\na set of candidates. The method we propose estimates properly calibrated\nweights for the partial losses corresponding to the considered pretext tasks\nduring the self-supervised training process. The experiments conducted on\nspeaker recognition and automatic speech recognition validate our approach, as\nthe groups selected and weighted with our method perform better than classic\nbaselines, thus facilitating the selection and combination of relevant\npseudo-labels for self-supervised representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:36:29 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zaiem", "Salah", ""], ["Parcollet", "Titouan", ""], ["Essid", "Slim", ""]]}, {"id": "2107.00595", "submitter": "Ziwei Ji", "authors": "Ziwei Ji, Nathan Srebro, Matus Telgarsky", "title": "Fast Margin Maximization via Dual Acceleration", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and analyze a momentum-based gradient method for training linear\nclassifiers with an exponentially-tailed loss (e.g., the exponential or\nlogistic loss), which maximizes the classification margin on separable data at\na rate of $\\widetilde{\\mathcal{O}}(1/t^2)$. This contrasts with a rate of\n$\\mathcal{O}(1/\\log(t))$ for standard gradient descent, and $\\mathcal{O}(1/t)$\nfor normalized gradient descent. This momentum-based method is derived via the\nconvex dual of the maximum-margin problem, and specifically by applying\nNesterov acceleration to this dual, which manages to result in a simple and\nintuitive method in the primal. This dual view can also be used to derive a\nstochastic variant, which performs adaptive non-uniform sampling via the dual\nvariables.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:36:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ji", "Ziwei", ""], ["Srebro", "Nathan", ""], ["Telgarsky", "Matus", ""]]}, {"id": "2107.00630", "submitter": "Diederik P. Kingma Dr.", "authors": "Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho", "title": "Variational Diffusion Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diffusion-based generative models have demonstrated a capacity for\nperceptually impressive synthesis, but can they also be great likelihood-based\nmodels? We answer this in the affirmative, and introduce a family of\ndiffusion-based generative models that obtain state-of-the-art likelihoods on\nstandard image density estimation benchmarks. Unlike other diffusion-based\nmodels, our method allows for efficient optimization of the noise schedule\njointly with the rest of the model. We show that the variational lower bound\n(VLB) simplifies to a remarkably short expression in terms of the\nsignal-to-noise ratio of the diffused data, thereby improving our theoretical\nunderstanding of this model class. Using this insight, we prove an equivalence\nbetween several models proposed in the literature. In addition, we show that\nthe continuous-time VLB is invariant to the noise schedule, except for the\nsignal-to-noise ratio at its endpoints. This enables us to learn a noise\nschedule that minimizes the variance of the resulting VLB estimator, leading to\nfaster optimization. Combining these advances with architectural improvements,\nwe obtain state-of-the-art likelihoods on image density estimation benchmarks,\noutperforming autoregressive models that have dominated these benchmarks for\nmany years, with often significantly faster optimization. In addition, we show\nhow to turn the model into a bits-back compression scheme, and demonstrate\nlossless compression rates close to the theoretical optimum.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:43:20 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 22:40:20 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kingma", "Diederik P.", ""], ["Salimans", "Tim", ""], ["Poole", "Ben", ""], ["Ho", "Jonathan", ""]]}, {"id": "2107.00637", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Samuele Papa, Michele De Vita, Bernhard Sch\\\"olkopf,\n  Ole Winther, Francesco Locatello", "title": "Generalization and Robustness Implications in Object-Centric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea behind object-centric representation learning is that natural scenes\ncan better be modeled as compositions of objects and their relations as opposed\nto distributed representations. This inductive bias can be injected into neural\nnetworks to potentially improve systematic generalization and learning\nefficiency of downstream tasks in scenes with multiple objects. In this paper,\nwe train state-of-the-art unsupervised models on five common multi-object\ndatasets and evaluate segmentation accuracy and downstream object property\nprediction. In addition, we study systematic generalization and robustness by\ninvestigating the settings where either single objects are out-of-distribution\n-- e.g., having unseen colors, textures, and shapes -- or global properties of\nthe scene are altered -- e.g., by occlusions, cropping, or increasing the\nnumber of objects. From our experimental study, we find object-centric\nrepresentations to be generally useful for downstream tasks and robust to\nshifts in the data distribution, especially if shifts affect single objects.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:51:11 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dittadi", "Andrea", ""], ["Papa", "Samuele", ""], ["De Vita", "Michele", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Winther", "Ole", ""], ["Locatello", "Francesco", ""]]}, {"id": "2107.00656", "submitter": "William Korcari Mr.", "authors": "Lisa Benato, Erik Buhmann, Martin Erdmann, Peter Fackeldey, Jonas\n  Glombitza, Nikolai Hartmann, Gregor Kasieczka, William Korcari, Thomas Kuhr,\n  Jan Steinheimer, Horst St\\\"ocker, Tilman Plehn and Kai Zhou", "title": "Shared Data and Algorithms for Deep Learning in Fundamental Physics", "comments": "13 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM hep-ph nucl-th physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a collection of datasets from fundamental physics research --\nincluding particle physics, astroparticle physics, and hadron- and nuclear\nphysics -- for supervised machine learning studies. These datasets, containing\nhadronic top quarks, cosmic-ray induced air showers, phase transitions in\nhadronic matter, and generator-level histories, are made public to simplify\nfuture work on cross-disciplinary machine learning and transfer learning in\nfundamental physics. Based on these data, we present a simple yet flexible\ngraph-based neural network architecture that can easily be applied to a wide\nrange of supervised learning tasks in these domains. We show that our approach\nreaches performance close to state-of-the-art dedicated methods on all\ndatasets. To simplify adaptation for various problems, we provide\neasy-to-follow instructions on how graph-based representations of data\nstructures, relevant for fundamental physics, can be constructed and provide\ncode implementations for several of them. Implementations are also provided for\nour proposed method and all reference algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:00:00 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Benato", "Lisa", ""], ["Buhmann", "Erik", ""], ["Erdmann", "Martin", ""], ["Fackeldey", "Peter", ""], ["Glombitza", "Jonas", ""], ["Hartmann", "Nikolai", ""], ["Kasieczka", "Gregor", ""], ["Korcari", "William", ""], ["Kuhr", "Thomas", ""], ["Steinheimer", "Jan", ""], ["St\u00f6cker", "Horst", ""], ["Plehn", "Tilman", ""], ["Zhou", "Kai", ""]]}, {"id": "2107.00685", "submitter": "Zehao Dou", "authors": "Zehao Dou, Zhuoran Yang, Zhaoran Wang, Simon S.Du", "title": "Gap-Dependent Bounds for Two-Player Markov Games", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most popular methods in the field of reinforcement learning,\nQ-learning has received increasing attention. Recently, there have been more\ntheoretical works on the regret bound of algorithms that belong to the\nQ-learning class in different settings. In this paper, we analyze the\ncumulative regret when conducting Nash Q-learning algorithm on 2-player\nturn-based stochastic Markov games (2-TBSG), and propose the very first gap\ndependent logarithmic upper bounds in the episodic tabular setting. This bound\nmatches the theoretical lower bound only up to a logarithmic term. Furthermore,\nwe extend the conclusion to the discounted game setting with infinite horizon\nand propose a similar gap dependent logarithmic regret bound. Also, under the\nlinear MDP assumption, we obtain another logarithmic regret for 2-TBSG, in both\ncentralized and independent settings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:25:07 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Dou", "Zehao", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Du", "Simon S.", ""]]}, {"id": "2107.00745", "submitter": "Vaden Masrani", "authors": "Vaden Masrani, Rob Brekelmans, Thang Bui, Frank Nielsen, Aram\n  Galstyan, Greg Ver Steeg, Frank Wood", "title": "q-Paths: Generalizing the Geometric Annealing Path using Power Means", "comments": "arXiv admin note: text overlap with arXiv:2012.07823", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many common machine learning methods involve the geometric annealing path, a\nsequence of intermediate densities between two distributions of interest\nconstructed using the geometric average. While alternatives such as the\nmoment-averaging path have demonstrated performance gains in some settings,\ntheir practical applicability remains limited by exponential family endpoint\nassumptions and a lack of closed form energy function. In this work, we\nintroduce $q$-paths, a family of paths which is derived from a generalized\nnotion of the mean, includes the geometric and arithmetic mixtures as special\ncases, and admits a simple closed form involving the deformed logarithm\nfunction from nonextensive thermodynamics. Following previous analysis of the\ngeometric path, we interpret our $q$-paths as corresponding to a\n$q$-exponential family of distributions, and provide a variational\nrepresentation of intermediate densities as minimizing a mixture of\n$\\alpha$-divergences to the endpoints. We show that small deviations away from\nthe geometric path yield empirical gains for Bayesian inference using\nSequential Monte Carlo and generative model evaluation using Annealed\nImportance Sampling.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:09:06 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Masrani", "Vaden", ""], ["Brekelmans", "Rob", ""], ["Bui", "Thang", ""], ["Nielsen", "Frank", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""], ["Wood", "Frank", ""]]}, {"id": "2107.00758", "submitter": "Greg D'Eon", "authors": "Greg d'Eon, Jason d'Eon, James R. Wright, Kevin Leyton-Brown", "title": "The Spotlight: A General Method for Discovering Systematic Errors in\n  Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning models often make systematic errors on rare subsets of\nthe data. However, such systematic errors can be difficult to identify, as\nmodel performance can only be broken down across sensitive groups when these\ngroups are known and explicitly labelled. This paper introduces a method for\ndiscovering systematic errors, which we call the spotlight. The key idea is\nthat similar inputs tend to have similar representations in the final hidden\nlayer of a neural network. We leverage this structure by \"shining a spotlight\"\non this representation space to find contiguous regions where the model\nperforms poorly. We show that the spotlight surfaces semantically meaningful\nareas of weakness in a wide variety of model architectures, including image\nclassifiers, language models, and recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:58:00 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["d'Eon", "Greg", ""], ["d'Eon", "Jason", ""], ["Wright", "James R.", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "2107.00801", "submitter": "Atsutoshi Kumagai", "authors": "Atsutoshi Kumagai and Tomoharu Iwata and Yasuhiro Fujiwara", "title": "Meta-Learning for Relative Density-Ratio Estimation", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ratio of two probability densities, called a density-ratio, is a vital\nquantity in machine learning. In particular, a relative density-ratio, which is\na bounded extension of the density-ratio, has received much attention due to\nits stability and has been used in various applications such as outlier\ndetection and dataset comparison. Existing methods for (relative) density-ratio\nestimation (DRE) require many instances from both densities. However,\nsufficient instances are often unavailable in practice. In this paper, we\npropose a meta-learning method for relative DRE, which estimates the relative\ndensity-ratio from a few instances by using knowledge in related datasets.\nSpecifically, given two datasets that consist of a few instances, our model\nextracts the datasets' information by using neural networks and uses it to\nobtain instance embeddings appropriate for the relative DRE. We model the\nrelative density-ratio by a linear model on the embedded space, whose global\noptimum solution can be obtained as a closed-form solution. The closed-form\nsolution enables fast and effective adaptation to a few instances, and its\ndifferentiability enables us to train our model such that the expected test\nerror for relative DRE can be explicitly minimized after adapting to a few\ninstances. We empirically demonstrate the effectiveness of the proposed method\nby using three problems: relative DRE, dataset comparison, and outlier\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 02:13:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kumagai", "Atsutoshi", ""], ["Iwata", "Tomoharu", ""], ["Fujiwara", "Yasuhiro", ""]]}, {"id": "2107.00816", "submitter": "Atsutoshi Kumagai", "authors": "Atsutoshi Kumagai and Tomoharu Iwata and Yasuhiro Fujiwara", "title": "Few-shot Learning for Unsupervised Feature Selection", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a few-shot learning method for unsupervised feature selection,\nwhich is a task to select a subset of relevant features in unlabeled data.\nExisting methods usually require many instances for feature selection. However,\nsufficient instances are often unavailable in practice. The proposed method can\nselect a subset of relevant features in a target task given a few unlabeled\ntarget instances by training with unlabeled instances in multiple source tasks.\nOur model consists of a feature selector and decoder. The feature selector\noutputs a subset of relevant features taking a few unlabeled instances as input\nsuch that the decoder can reconstruct the original features of unseen instances\nfrom the selected ones. The feature selector uses the Concrete random variables\nto select features via gradient descent. To encode task-specific properties\nfrom a few unlabeled instances to the model, the Concrete random variables and\ndecoder are modeled using permutation-invariant neural networks that take a few\nunlabeled instances as input. Our model is trained by minimizing the expected\ntest reconstruction error given a few unlabeled instances that is calculated\nwith datasets in source tasks. We experimentally demonstrate that the proposed\nmethod outperforms existing feature selection methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 03:52:51 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kumagai", "Atsutoshi", ""], ["Iwata", "Tomoharu", ""], ["Fujiwara", "Yasuhiro", ""]]}, {"id": "2107.00819", "submitter": "Mingda Qiao", "authors": "Guy Blanc, Jane Lange, Mingda Qiao, Li-Yang Tan", "title": "Decision tree heuristics can fail, even in the smoothed setting", "comments": "To appear in RANDOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy decision tree learning heuristics are mainstays of machine learning\npractice, but theoretical justification for their empirical success remains\nelusive. In fact, it has long been known that there are simple target functions\nfor which they fail badly (Kearns and Mansour, STOC 1996).\n  Recent work of Brutzkus, Daniely, and Malach (COLT 2020) considered the\nsmoothed analysis model as a possible avenue towards resolving this disconnect.\nWithin the smoothed setting and for targets $f$ that are $k$-juntas, they\nshowed that these heuristics successfully learn $f$ with depth-$k$ decision\ntree hypotheses. They conjectured that the same guarantee holds more generally\nfor targets that are depth-$k$ decision trees.\n  We provide a counterexample to this conjecture: we construct targets that are\ndepth-$k$ decision trees and show that even in the smoothed setting, these\nheuristics build trees of depth $2^{\\Omega(k)}$ before achieving high accuracy.\nWe also show that the guarantees of Brutzkus et al. cannot extend to the\nagnostic setting: there are targets that are very close to $k$-juntas, for\nwhich these heuristics build trees of depth $2^{\\Omega(k)}$ before achieving\nhigh accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 04:24:55 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Blanc", "Guy", ""], ["Lange", "Jane", ""], ["Qiao", "Mingda", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2107.00833", "submitter": "Sarah Dean", "authors": "Mihaela Curmei, Sarah Dean, Benjamin Recht", "title": "Quantifying Availability and Discovery in Recommender Systems via\n  Stochastic Reachability", "comments": "to appear ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider how preference models in interactive recommendation\nsystems determine the availability of content and users' opportunities for\ndiscovery. We propose an evaluation procedure based on stochastic reachability\nto quantify the maximum probability of recommending a target piece of content\nto an user for a set of allowable strategic modifications. This framework\nallows us to compute an upper bound on the likelihood of recommendation with\nminimal assumptions about user behavior. Stochastic reachability can be used to\ndetect biases in the availability of content and diagnose limitations in the\nopportunities for discovery granted to users. We show that this metric can be\ncomputed efficiently as a convex program for a variety of practical settings,\nand further argue that reachability is not inherently at odds with accuracy. We\ndemonstrate evaluations of recommendation algorithms trained on large datasets\nof explicit and implicit ratings. Our results illustrate how preference models,\nselection rules, and user interventions impact reachability and how these\neffects can be distributed unevenly.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 16:18:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Curmei", "Mihaela", ""], ["Dean", "Sarah", ""], ["Recht", "Benjamin", ""]]}, {"id": "2107.00848", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Aniket Didolkar, Sarthak Mittal, Anirudh Goyal,\n  Guillaume Lajoie, Stefan Bauer, Danilo Rezende, Yoshua Bengio, Michael Mozer,\n  Christopher Pal", "title": "Systematic Evaluation of Causal Discovery in Visual Model Based\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inducing causal relationships from observations is a classic problem in\nmachine learning. Most work in causality starts from the premise that the\ncausal variables themselves are observed. However, for AI agents such as robots\ntrying to make sense of their environment, the only observables are low-level\nvariables like pixels in images. To generalize well, an agent must induce\nhigh-level variables, particularly those which are causal or are affected by\ncausal variables. A central goal for AI and causality is thus the joint\ndiscovery of abstract representations and causal structure. However, we note\nthat existing environments for studying causal induction are poorly suited for\nthis objective because they have complicated task-specific causal graphs which\nare impossible to manipulate parametrically (e.g., number of nodes, sparsity,\ncausal chain length, etc.). In this work, our goal is to facilitate research in\nlearning representations of high-level variables as well as causal structures\namong them. In order to systematically probe the ability of methods to identify\nthese variables and structures, we design a suite of benchmarking RL\nenvironments. We evaluate various representation learning algorithms from the\nliterature and find that explicitly incorporating structure and modularity in\nmodels can help causal induction in model-based reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 05:44:56 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Didolkar", "Aniket", ""], ["Mittal", "Sarthak", ""], ["Goyal", "Anirudh", ""], ["Lajoie", "Guillaume", ""], ["Bauer", "Stefan", ""], ["Rezende", "Danilo", ""], ["Bengio", "Yoshua", ""], ["Mozer", "Michael", ""], ["Pal", "Christopher", ""]]}, {"id": "2107.00871", "submitter": "Kazuya Takabatake", "authors": "Kazuya Takabatake, Shotaro Akaho", "title": "Reconsidering Dependency Networks from an Information Geometry\n  Perspective", "comments": "28pages, 7figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Dependency networks (Heckerman et al., 2000) are potential probabilistic\ngraphical models for systems comprising a large number of variables. Like\nBayesian networks, the structure of a dependency network is represented by a\ndirected graph, and each node has a conditional probability table. Learning and\ninference are realized locally on individual nodes; therefore, computation\nremains tractable even with a large number of variables. However, the\ndependency network's learned distribution is the stationary distribution of a\nMarkov chain called pseudo-Gibbs sampling and has no closed-form expressions.\nThis technical disadvantage has impeded the development of dependency networks.\nIn this paper, we consider a certain manifold for each node. Then, we can\ninterpret pseudo-Gibbs sampling as iterative m-projections onto these\nmanifolds. This interpretation provides a theoretical bound for the location\nwhere the stationary distribution of pseudo-Gibbs sampling exists in\ndistribution space. Furthermore, this interpretation involves structure and\nparameter learning algorithms as optimization problems. In addition, we compare\ndependency and Bayesian networks experimentally. The results demonstrate that\nthe dependency network and the Bayesian network have roughly the same\nperformance in terms of the accuracy of their learned distributions. The\nresults also show that the dependency network can learn much faster than the\nBayesian network.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 07:05:11 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Takabatake", "Kazuya", ""], ["Akaho", "Shotaro", ""]]}, {"id": "2107.00995", "submitter": "Flore Sentenac", "authors": "Nathan Noiry, Flore Sentenac, Vianney Perchet", "title": "Online Matching in Sparse Random Graphs: Non-Asymptotic Performances of\n  Greedy Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by sequential budgeted allocation problems, we investigate online\nmatching problems where connections between vertices are not i.i.d., but they\nhave fixed degree distributions -- the so-called configuration model. We\nestimate the competitive ratio of the simplest algorithm, GREEDY, by\napproximating some relevant stochastic discrete processes by their continuous\ncounterparts, that are solutions of an explicit system of partial differential\nequations. This technique gives precise bounds on the estimation errors, with\narbitrarily high probability as the problem size increases. In particular, it\nallows the formal comparison between different configuration models. We also\nprove that, quite surprisingly, GREEDY can have better performance guarantees\nthan RANKING, another celebrated algorithm for online matching that usually\noutperforms the former.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 12:18:19 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Noiry", "Nathan", ""], ["Sentenac", "Flore", ""], ["Perchet", "Vianney", ""]]}, {"id": "2107.00996", "submitter": "Adel Bibi", "authors": "Motasem Alfarra, Adel Bibi, Naeemullah Khan, Philip H. S. Torr, and\n  Bernard Ghanem", "title": "DeformRS: Certifying Input Deformations with Randomized Smoothing", "comments": "First two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to input deformations in the form of\nvector fields of pixel displacements and to other parameterized geometric\ndeformations e.g. translations, rotations, etc. Current input deformation\ncertification methods either (i) do not scale to deep networks on large input\ndatasets, or (ii) can only certify a specific class of deformations, e.g. only\nrotations. We reformulate certification in randomized smoothing setting for\nboth general vector field and parameterized deformations and propose\nDeformRS-VF and DeformRS-Par, respectively. Our new formulation scales to large\nnetworks on large input datasets. For instance, DeformRS-Par certifies rich\ndeformations, covering translations, rotations, scaling, affine deformations,\nand other visually aligned deformations such as ones parameterized by\nDiscrete-Cosine-Transform basis. Extensive experiments on MNIST, CIFAR10 and\nImageNet show that DeformRS-Par outperforms existing state-of-the-art in\ncertified accuracy, e.g. improved certified accuracy of 6% against perturbed\nrotations in the set [-10,10] degrees on ImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 12:20:15 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Alfarra", "Motasem", ""], ["Bibi", "Adel", ""], ["Khan", "Naeemullah", ""], ["Torr", "Philip H. S.", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2107.01103", "submitter": "Subhabrata Majumdar", "authors": "Subhabrata Majumdar, Snigdhansu Chatterjee", "title": "Generalized Multivariate Signs for Nonparametric Hypothesis Testing in\n  High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data, where the dimension of the feature space is much\nlarger than sample size, arise in a number of statistical applications. In this\ncontext, we construct the generalized multivariate sign transformation, defined\nas a vector divided by its norm. For different choices of the norm function,\nthe resulting transformed vector adapts to certain geometrical features of the\ndata distribution. Building up on this idea, we obtain one-sample and\ntwo-sample testing procedures for mean vectors of high-dimensional data using\nthese generalized sign vectors. These tests are based on U-statistics using\nkernel inner products, do not require prohibitive assumptions, and are amenable\nto a fast randomization-based implementation. Through experiments in a number\nof data settings, we show that tests using generalized signs display higher\npower than existing tests, while maintaining nominal type-I error rates.\nFinally, we provide example applications on the MNIST and Minnesota Twin\nStudies genomic data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 14:31:44 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Majumdar", "Subhabrata", ""], ["Chatterjee", "Snigdhansu", ""]]}, {"id": "2107.01105", "submitter": "John Bronskill", "authors": "John Bronskill, Daniela Massiceti, Massimiliano Patacchiola, Katja\n  Hofmann, Sebastian Nowozin, Richard E. Turner", "title": "Memory Efficient Meta-Learning with Large Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta learning approaches to few-shot classification are computationally\nefficient at test time requiring just a few optimization steps or single\nforward pass to learn a new task, but they remain highly memory-intensive to\ntrain. This limitation arises because a task's entire support set, which can\ncontain up to 1000 images, must be processed before an optimization step can be\ntaken. Harnessing the performance gains offered by large images thus requires\neither parallelizing the meta-learner across multiple GPUs, which may not be\navailable, or trade-offs between task and image size when memory constraints\napply. We improve on both options by proposing LITE, a general and memory\nefficient episodic training scheme that enables meta-training on large tasks\ncomposed of large images on a single GPU. We achieve this by observing that the\ngradients for a task can be decomposed into a sum of gradients over the task's\ntraining images. This enables us to perform a forward pass on a task's entire\ntraining set but realize significant memory savings by back-propagating only a\nrandom subset of these images which we show is an unbiased approximation of the\nfull gradient. We use LITE to train meta-learners and demonstrate new\nstate-of-the-art accuracy on the real-world ORBIT benchmark and 3 of the 4\nparts of the challenging VTAB+MD benchmark relative to leading meta-learners.\nLITE also enables meta-learners to be competitive with transfer learning\napproaches but at a fraction of the test-time computational cost, thus serving\nas a counterpoint to the recent narrative that transfer learning is all you\nneed for few-shot classification.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 14:37:13 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Bronskill", "John", ""], ["Massiceti", "Daniela", ""], ["Patacchiola", "Massimiliano", ""], ["Hofmann", "Katja", ""], ["Nowozin", "Sebastian", ""], ["Turner", "Richard E.", ""]]}, {"id": "2107.01131", "submitter": "Junya Chen", "authors": "Qing Guo, Junya Chen, Dong Wang, Yuewei Yang, Xinwei Deng, Lawrence\n  Carin, Fan Li, Chenyang Tao", "title": "Tight Mutual Information Estimation With Contrastive Fenchel-Legendre\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Successful applications of InfoNCE and its variants have popularized the use\nof contrastive variational mutual information (MI) estimators in machine\nlearning. While featuring superior stability, these estimators crucially depend\non costly large-batch training, and they sacrifice bound tightness for variance\nreduction. To overcome these limitations, we revisit the mathematics of popular\nvariational MI bounds from the lens of unnormalized statistical modeling and\nconvex optimization. Our investigation not only yields a new unified\ntheoretical framework encompassing popular variational MI bounds but also leads\nto a novel, simple, and powerful contrastive MI estimator named as FLO.\nTheoretically, we show that the FLO estimator is tight, and it provably\nconverges under stochastic gradient descent. Empirically, our FLO estimator\novercomes the limitations of its predecessors and learns more efficiently. The\nutility of FLO is verified using an extensive set of benchmarks, which also\nreveals the trade-offs in practical MI estimation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:20:41 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Guo", "Qing", ""], ["Chen", "Junya", ""], ["Wang", "Dong", ""], ["Yang", "Yuewei", ""], ["Deng", "Xinwei", ""], ["Carin", "Lawrence", ""], ["Li", "Fan", ""], ["Tao", "Chenyang", ""]]}, {"id": "2107.01152", "submitter": "Junya Chen", "authors": "Junya Chen, Zhe Gan, Xuan Li, Qing Guo, Liqun Chen, Shuyang Gao,\n  Tagyoung Chung, Yi Xu, Belinda Zeng, Wenlian Lu, Fan Li, Lawrence Carin,\n  Chenyang Tao", "title": "Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive\n  Learners With FlatNCE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  InfoNCE-based contrastive representation learners, such as SimCLR, have been\ntremendously successful in recent years. However, these contrastive schemes are\nnotoriously resource demanding, as their effectiveness breaks down with\nsmall-batch training (i.e., the log-K curse, whereas K is the batch-size). In\nthis work, we reveal mathematically why contrastive learners fail in the\nsmall-batch-size regime, and present a novel simple, non-trivial contrastive\nobjective named FlatNCE, which fixes this issue. Unlike InfoNCE, our FlatNCE no\nlonger explicitly appeals to a discriminative classification goal for\ncontrastive learning. Theoretically, we show FlatNCE is the mathematical dual\nformulation of InfoNCE, thus bridging the classical literature on energy\nmodeling; and empirically, we demonstrate that, with minimal modification of\ncode, FlatNCE enables immediate performance boost independent of the\nsubject-matter engineering efforts. The significance of this work is furthered\nby the powerful generalization of contrastive learning techniques, and the\nintroduction of new tools to monitor and diagnose contrastive training. We\nsubstantiate our claims with empirical evidence on CIFAR10, ImageNet, and other\ndatasets, where FlatNCE consistently outperforms InfoNCE.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:50:43 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "Junya", ""], ["Gan", "Zhe", ""], ["Li", "Xuan", ""], ["Guo", "Qing", ""], ["Chen", "Liqun", ""], ["Gao", "Shuyang", ""], ["Chung", "Tagyoung", ""], ["Xu", "Yi", ""], ["Zeng", "Belinda", ""], ["Lu", "Wenlian", ""], ["Li", "Fan", ""], ["Carin", "Lawrence", ""], ["Tao", "Chenyang", ""]]}, {"id": "2107.01214", "submitter": "Benjamin Miller", "authors": "Benjamin Kurt Miller, Alex Cole, Patrick Forr\\'e, Gilles Louppe,\n  Christoph Weniger", "title": "Truncated Marginal Neural Ratio Estimation", "comments": "9 pages. 23 pages with references and supplemental material. Code\n  available at http://github.com/bkmi/tmnre/ Underlying library\n  http://github.com/undark-lab/swyft/", "journal-ref": null, "doi": "10.5281/zenodo.5043707", "report-no": null, "categories": "stat.ML astro-ph.IM cs.LG hep-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Parametric stochastic simulators are ubiquitous in science, often featuring\nhigh-dimensional input parameters and/or an intractable likelihood. Performing\nBayesian parameter inference in this context can be challenging. We present a\nneural simulator-based inference algorithm which simultaneously offers\nsimulation efficiency and fast empirical posterior testability, which is unique\namong modern algorithms. Our approach is simulation efficient by simultaneously\nestimating low-dimensional marginal posteriors instead of the joint posterior\nand by proposing simulations targeted to an observation of interest via a prior\nsuitably truncated by an indicator function. Furthermore, by estimating a\nlocally amortized posterior our algorithm enables efficient empirical tests of\nthe robustness of the inference results. Such tests are important for\nsanity-checking inference in real-world applications, which do not feature a\nknown ground truth. We perform experiments on a marginalized version of the\nsimulation-based inference benchmark and two complex and narrow posteriors,\nhighlighting the simulator efficiency of our algorithm as well as the quality\nof the estimated marginal posteriors. Implementation on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 18:00:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Miller", "Benjamin Kurt", ""], ["Cole", "Alex", ""], ["Forr\u00e9", "Patrick", ""], ["Louppe", "Gilles", ""], ["Weniger", "Christoph", ""]]}, {"id": "2107.01285", "submitter": "Toby Hocking", "authors": "Jonathan Hillman and Toby Dylan Hocking", "title": "Optimizing ROC Curves with a Sort-Based Surrogate Loss Function for\n  Binary Classification and Changepoint Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Receiver Operating Characteristic (ROC) curves are plots of true positive\nrate versus false positive rate which are useful for evaluating binary\nclassification models, but difficult to use for learning since the Area Under\nthe Curve (AUC) is non-convex. ROC curves can also be used in other problems\nthat have false positive and true positive rates such as changepoint detection.\nWe show that in this more general context, the ROC curve can have loops, points\nwith highly sub-optimal error rates, and AUC greater than one. This observation\nmotivates a new optimization objective: rather than maximizing the AUC, we\nwould like a monotonic ROC curve with AUC=1 that avoids points with large\nvalues for Min(FP,FN). We propose a convex relaxation of this objective that\nresults in a new surrogate loss function called the AUM, short for Area Under\nMin(FP, FN). Whereas previous loss functions are based on summing over all\nlabeled examples or pairs, the AUM requires a sort and a sum over the sequence\nof points on the ROC curve. We show that AUM directional derivatives can be\nefficiently computed and used in a gradient descent learning algorithm. In our\nempirical study of supervised binary classification and changepoint detection\nproblems, we show that our new AUM minimization learning algorithm results in\nimproved AUC and comparable speed relative to previous baselines.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 21:21:19 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hillman", "Jonathan", ""], ["Hocking", "Toby Dylan", ""]]}, {"id": "2107.01323", "submitter": "Qiong Zhang", "authors": "Qiong Zhang, Jiahua Chen", "title": "Minimum Wasserstein Distance Estimator under Finite Location-scale\n  Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When a population exhibits heterogeneity, we often model it via a finite\nmixture: decompose it into several different but homogeneous subpopulations.\nContemporary practice favors learning the mixtures by maximizing the likelihood\nfor statistical efficiency and the convenient EM-algorithm for numerical\ncomputation. Yet the maximum likelihood estimate (MLE) is not well defined for\nthe most widely used finite normal mixture in particular and for finite\nlocation-scale mixture in general. We hence investigate feasible alternatives\nto MLE such as minimum distance estimators. Recently, the Wasserstein distance\nhas drawn increased attention in the machine learning community. It has\nintuitive geometric interpretation and is successfully employed in many new\napplications. Do we gain anything by learning finite location-scale mixtures\nvia a minimum Wasserstein distance estimator (MWDE)? This paper investigates\nthis possibility in several respects. We find that the MWDE is consistent and\nderive a numerical solution under finite location-scale mixtures. We study its\nrobustness against outliers and mild model mis-specifications. Our moderate\nscaled simulation study shows the MWDE suffers some efficiency loss against a\npenalized version of MLE in general without noticeable gain in robustness. We\nreaffirm the general superiority of the likelihood based learning strategies\neven for the non-regular finite location-scale mixtures.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:06:49 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Qiong", ""], ["Chen", "Jiahua", ""]]}, {"id": "2107.01333", "submitter": "Shuyan Wang", "authors": "Shuyan Wang, Peter Spirtes", "title": "A Uniformly Consistent Estimator of non-Gaussian Causal Effects Under\n  the k-Triangle-Faithfulness Assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kalisch and B\\\"{u}hlmann (2007) showed that for linear Gaussian models, under\nthe Causal Markov Assumption, the Strong Causal Faithfulness Assumption, and\nthe assumption of causal sufficiency, the PC algorithm is a uniformly\nconsistent estimator of the Markov Equivalence Class of the true causal DAG for\nlinear Gaussian models; it follows from this that for the identifiable causal\neffects in the Markov Equivalence Class, there are uniformly consistent\nestimators of causal effects as well. The $k$-Triangle-Faithfulness Assumption\nis a strictly weaker assumption that avoids some implausible implications of\nthe Strong Causal Faithfulness Assumption and also allows for uniformly\nconsistent estimates of Markov Equivalence Classes (in a weakened sense), and\nof identifiable causal effects. However, both of these assumptions are\nrestricted to linear Gaussian models. We propose the Generalized $k$-Triangle\nFaithfulness, which can be applied to any smooth distribution. In addition,\nunder the Generalized $k$-Triangle Faithfulness Assumption, we describe the\nEdge Estimation Algorithm that provides uniformly consistent estimates of\ncausal effects in some cases (and otherwise outputs \"can't tell\"), and the\n\\textit{Very Conservative }$SGS$ Algorithm that (in a slightly weaker sense) is\na uniformly consistent estimator of the Markov equivalence class of the true\nDAG.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 03:26:48 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Shuyan", ""], ["Spirtes", "Peter", ""]]}, {"id": "2107.01408", "submitter": "Hyungi Lee", "authors": "Hyungi Lee, Eunggu Yun, Hongseok Yang, Juho Lee", "title": "Scale Mixtures of Neural Network Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works have revealed that infinitely-wide feed-forward or recurrent\nneural networks of any architecture correspond to Gaussian processes referred\nto as $\\mathrm{NNGP}$. While these works have extended the class of neural\nnetworks converging to Gaussian processes significantly, however, there has\nbeen little focus on broadening the class of stochastic processes that such\nneural networks converge to. In this work, inspired by the scale mixture of\nGaussian random variables, we propose the scale mixture of $\\mathrm{NNGP}$ for\nwhich we introduce a prior distribution on the scale of the last-layer\nparameters. We show that simply introducing a scale prior on the last-layer\nparameters can turn infinitely-wide neural networks of any architecture into a\nricher class of stochastic processes. Especially, with certain scale priors, we\nobtain heavy-tailed stochastic processes, and we recover Student's $t$\nprocesses in the case of inverse gamma priors. We further analyze the\ndistributions of the neural networks initialized with our prior setting and\ntrained with gradient descents and obtain similar results as for\n$\\mathrm{NNGP}$. We present a practical posterior-inference algorithm for the\nscale mixture of $\\mathrm{NNGP}$ and empirically demonstrate its usefulness on\nregression and classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:02:18 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lee", "Hyungi", ""], ["Yun", "Eunggu", ""], ["Yang", "Hongseok", ""], ["Lee", "Juho", ""]]}, {"id": "2107.01473", "submitter": "Anton Johansson", "authors": "Anton Johansson, Niklas Engsner, Claes Stranneg{\\aa}rd, Petter Mostad", "title": "Slope and generalization properties of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are very successful tools in for example advanced\nclassification. From a statistical point of view, fitting a neural network may\nbe seen as a kind of regression, where we seek a function from the input space\nto a space of classification probabilities that follows the \"general\" shape of\nthe data, but avoids overfitting by avoiding memorization of individual data\npoints. In statistics, this can be done by controlling the geometric complexity\nof the regression function. We propose to do something similar when fitting\nneural networks by controlling the slope of the network.\n  After defining the slope and discussing some of its theoretical properties,\nwe go on to show empirically in examples, using ReLU networks, that the\ndistribution of the slope of a well-trained neural network classifier is\ngenerally independent of the width of the layers in a fully connected network,\nand that the mean of the distribution only has a weak dependence on the model\narchitecture in general. The slope is of similar size throughout the relevant\nvolume, and varies smoothly. It also behaves as predicted in rescaling\nexamples. We discuss possible applications of the slope concept, such as using\nit as a part of the loss function or stopping criterion during network\ntraining, or ranking data sets in terms of their complexity.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 17:54:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Johansson", "Anton", ""], ["Engsner", "Niklas", ""], ["Stranneg\u00e5rd", "Claes", ""], ["Mostad", "Petter", ""]]}, {"id": "2107.01509", "submitter": "Max Simchowitz", "authors": "Max Simchowitz, Christopher Tosh, Akshay Krishnamurthy, Daniel Hsu,\n  Thodoris Lykouris, Miroslav Dud\\'ik, Robert E. Schapire", "title": "Bayesian decision-making under misspecified priors with applications to\n  meta-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling and other Bayesian sequential decision-making algorithms\nare among the most popular approaches to tackle explore/exploit trade-offs in\n(contextual) bandits. The choice of prior in these algorithms offers\nflexibility to encode domain knowledge but can also lead to poor performance\nwhen misspecified. In this paper, we demonstrate that performance degrades\ngracefully with misspecification. We prove that the expected reward accrued by\nThompson sampling (TS) with a misspecified prior differs by at most\n$\\tilde{\\mathcal{O}}(H^2 \\epsilon)$ from TS with a well specified prior, where\n$\\epsilon$ is the total-variation distance between priors and $H$ is the\nlearning horizon. Our bound does not require the prior to have any parametric\nform. For priors with bounded support, our bound is independent of the\ncardinality or structure of the action space, and we show that it is tight up\nto universal constants in the worst case.\n  Building on our sensitivity analysis, we establish generic PAC guarantees for\nalgorithms in the recently studied Bayesian meta-learning setting and derive\ncorollaries for various families of priors. Our results generalize along two\naxes: (1) they apply to a broader family of Bayesian decision-making\nalgorithms, including a Monte-Carlo implementation of the knowledge gradient\nalgorithm (KG), and (2) they apply to Bayesian POMDPs, the most general\nBayesian decision-making setting, encompassing contextual bandits as a special\ncase. Through numerical simulations, we illustrate how prior misspecification\nand the deployment of one-step look-ahead (as in KG) can impact the convergence\nof meta-learning in multi-armed and contextual bandits with structured and\ncorrelated priors.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 23:17:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Simchowitz", "Max", ""], ["Tosh", "Christopher", ""], ["Krishnamurthy", "Akshay", ""], ["Hsu", "Daniel", ""], ["Lykouris", "Thodoris", ""], ["Dud\u00edk", "Miroslav", ""], ["Schapire", "Robert E.", ""]]}, {"id": "2107.01561", "submitter": "Ao Liu", "authors": "Ao Liu, Xiaoyu Chen, Sijia Liu, Lirong Xia, Chuang Gan", "title": "Certifiably Robust Interpretation via Renyi Differential Privacy", "comments": "19 page main text + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent discovery that the interpretation maps of CNNs could\neasily be manipulated by adversarial attacks against network interpretability,\nwe study the problem of interpretation robustness from a new perspective of\n\\Renyi differential privacy (RDP). The advantages of our Renyi-Robust-Smooth\n(RDP-based interpretation method) are three-folds. First, it can offer provable\nand certifiable top-$k$ robustness. That is, the top-$k$ important attributions\nof the interpretation map are provably robust under any input perturbation with\nbounded $\\ell_d$-norm (for any $d\\geq 1$, including $d = \\infty$). Second, our\nproposed method offers $\\sim10\\%$ better experimental robustness than existing\napproaches in terms of the top-$k$ attributions. Remarkably, the accuracy of\nRenyi-Robust-Smooth also outperforms existing approaches. Third, our method can\nprovide a smooth tradeoff between robustness and computational efficiency.\nExperimentally, its top-$k$ attributions are {\\em twice} more robust than\nexisting approaches when the computational resources are highly constrained.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 06:58:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liu", "Ao", ""], ["Chen", "Xiaoyu", ""], ["Liu", "Sijia", ""], ["Xia", "Lirong", ""], ["Gan", "Chuang", ""]]}, {"id": "2107.01590", "submitter": "Deyu Ming", "authors": "Deyu Ming and Daniel Williamson and Serge Guillas", "title": "Deep Gaussian Process Emulation using Stochastic Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep Gaussian process (DGP) inference method for computer\nmodel emulation using stochastic imputation. By stochastically imputing the\nlatent layers, the approach transforms the DGP into the linked GP, a\nstate-of-the-art surrogate model formed by linking a system of feed-forward\ncoupled GPs. This transformation renders a simple while efficient DGP training\nprocedure that only involves optimizations of conventional stationary GPs. In\naddition, the analytically tractable mean and variance of the linked GP allows\none to implement predictions from DGP emulators in a fast and accurate manner.\nWe demonstrate the method in a series of synthetic examples and real-world\napplications, and show that it is a competitive candidate for efficient DGP\nsurrogate modeling in comparison to the variational inference and the\nfully-Bayesian approach. A $\\texttt{Python}$ package $\\texttt{dgpsi}$\nimplementing the method is also produced and available at\nhttps://github.com/mingdeyu/DGP.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 10:46:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ming", "Deyu", ""], ["Williamson", "Daniel", ""], ["Guillas", "Serge", ""]]}, {"id": "2107.01606", "submitter": "Geir Kjetil Nilsen Mr", "authors": "Geir K. Nilsen and Antonella Z. Munthe-Kaas and Hans J. Skaug and\n  Morten Brun", "title": "A Comparison of the Delta Method and the Bootstrap in Deep Learning\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We validate the recently introduced deep learning classification adapted\nDelta method by a comparison with the classical Bootstrap. We show that there\nis a strong linear relationship between the quantified predictive epistemic\nuncertainty levels obtained from the two methods when applied on two\nLeNet-based neural network classifiers using the MNIST and CIFAR-10 datasets.\nFurthermore, we demonstrate that the Delta method offers a five times\ncomputation time reduction compared to the Bootstrap.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 12:40:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nilsen", "Geir K.", ""], ["Munthe-Kaas", "Antonella Z.", ""], ["Skaug", "Hans J.", ""], ["Brun", "Morten", ""]]}, {"id": "2107.01629", "submitter": "Ziwei Cong", "authors": "Ziwei Cong, Jia Liu, Puneet Manchanda", "title": "The Role of \"Live\" in Livestreaming Markets: Evidence Using Orthogonal\n  Random Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.GN q-fin.EC stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The common belief about the growing medium of livestreaming is that its value\nlies in its \"live\" component. In this paper, we leverage data from a large\nlivestreaming platform to examine this belief. We are able to do this as this\nplatform also allows viewers to purchase the recorded version of the\nlivestream. We summarize the value of livestreaming content by estimating how\ndemand responds to price before, on the day of, and after the livestream. We do\nthis by proposing a generalized Orthogonal Random Forest framework. This\nframework allows us to estimate heterogeneous treatment effects in the presence\nof high-dimensional confounders whose relationships with the treatment policy\n(i.e., price) are complex but partially known. We find significant dynamics in\nthe price elasticity of demand over the temporal distance to the scheduled\nlivestreaming day and after. Specifically, demand gradually becomes less price\nsensitive over time to the livestreaming day and is inelastic on the\nlivestreaming day. Over the post-livestream period, demand is still sensitive\nto price, but much less than the pre-livestream period. This indicates that the\nvlaue of livestreaming persists beyond the live component. Finally, we provide\nsuggestive evidence for the likely mechanisms driving our results. These are\nquality uncertainty reduction for the patterns pre- and post-livestream and the\npotential of real-time interaction with the creator on the day of the\nlivestream.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:50:54 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cong", "Ziwei", ""], ["Liu", "Jia", ""], ["Manchanda", "Puneet", ""]]}, {"id": "2107.01658", "submitter": "Aramayis Dallakyan", "authors": "Aramayis Dallakyan and Mohsen Pourahmadi", "title": "Learning Bayesian Networks through Birkhoff Polytope: A Relaxation\n  Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish a novel framework for learning a directed acyclic graph (DAG)\nwhen data are generated from a Gaussian, linear structural equation model. It\nconsists of two parts: (1) introduce a permutation matrix as a new parameter\nwithin a regularized Gaussian log-likelihood to represent variable ordering;\nand (2) given the ordering, estimate the DAG structure through sparse Cholesky\nfactor of the inverse covariance matrix. For permutation matrix estimation, we\npropose a relaxation technique that avoids the NP-hard combinatorial problem of\norder estimation. Given an ordering, a sparse Cholesky factor is estimated\nusing a cyclic coordinatewise descent algorithm which decouples row-wise. Our\nframework recovers DAGs without the need for an expensive verification of the\nacyclicity constraint or enumeration of possible parent sets. We establish\nnumerical convergence of the algorithm, and consistency of the Cholesky factor\nestimator when the order of variables is known. Through several simulated and\nmacro-economic datasets, we study the scope and performance of the proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 15:04:02 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dallakyan", "Aramayis", ""], ["Pourahmadi", "Mohsen", ""]]}, {"id": "2107.01718", "submitter": "Nabarun Deb", "authors": "Nabarun Deb, Promit Ghosal, and Bodhisattva Sen", "title": "Rates of Estimation of Optimal Transport Maps using Plug-in Estimators\n  via Barycentric Projections", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport maps between two probability distributions $\\mu$ and $\\nu$\non $\\mathbb{R}^d$ have found extensive applications in both machine learning\nand statistics. In practice, these maps need to be estimated from data sampled\naccording to $\\mu$ and $\\nu$. Plug-in estimators are perhaps most popular in\nestimating transport maps in the field of computational optimal transport. In\nthis paper, we provide a comprehensive analysis of the rates of convergences\nfor general plug-in estimators defined via barycentric projections. Our main\ncontribution is a new stability estimate for barycentric projections which\nproceeds under minimal smoothness assumptions and can be used to analyze\ngeneral plug-in estimators. We illustrate the usefulness of this stability\nestimate by first providing rates of convergence for the natural\ndiscrete-discrete and semi-discrete estimators of optimal transport maps. We\nthen use the same stability estimate to show that, under additional smoothness\nassumptions of Besov type or Sobolev type, wavelet based or kernel smoothed\nplug-in estimators respectively speed up the rates of convergence and\nsignificantly mitigate the curse of dimensionality suffered by the natural\ndiscrete-discrete/semi-discrete estimators. As a by-product of our analysis, we\nalso obtain faster rates of convergence for plug-in estimators of\n$W_2(\\mu,\\nu)$, the Wasserstein distance between $\\mu$ and $\\nu$, under the\naforementioned smoothness assumptions, thereby complementing recent results in\nChizat et al. (2020). Finally, we illustrate the applicability of our results\nin obtaining rates of convergence for Wasserstein barycenters between two\nprobability distributions and obtaining asymptotic detection thresholds for\nsome recent optimal-transport based tests of independence.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 19:50:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Deb", "Nabarun", ""], ["Ghosal", "Promit", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "2107.01734", "submitter": "Francesco Sanna Passino", "authors": "Francesco Sanna Passino and Nicholas A. Heard", "title": "Latent structure blockmodels for Bayesian spectral graph clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral embedding of network adjacency matrices often produces node\nrepresentations living approximately around low-dimensional submanifold\nstructures. In particular, hidden substructure is expected to arise when the\ngraph is generated from a latent position model. Furthermore, the presence of\ncommunities within the network might generate community-specific submanifold\nstructures in the embedding, but this is not explicitly accounted for in most\nstatistical models for networks. In this article, a class of models called\nlatent structure block models (LSBM) is proposed to address such scenarios,\nallowing for graph clustering when community-specific one dimensional manifold\nstructure is present. LSBMs focus on a specific class of latent space model,\nthe random dot product graph (RDPG), and assign a latent submanifold to the\nlatent positions of each community. A Bayesian model for the embeddings arising\nfrom LSBMs is discussed, and shown to have a good performance on simulated and\nreal world network data. The model is able to correctly recover the underlying\ncommunities living in a one-dimensional manifold, even when the parametric form\nof the underlying curves is unknown, achieving remarkable results on a variety\nof real data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 21:09:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Passino", "Francesco Sanna", ""], ["Heard", "Nicholas A.", ""]]}, {"id": "2107.01777", "submitter": "Shashank Singh", "authors": "Shashank Singh, Justin Khim", "title": "Statistical Theory for Imbalanced Binary Classification", "comments": "Parts of this paper have been revised from arXiv:2004.04715v2\n  [math.ST]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within the vast body of statistical theory developed for binary\nclassification, few meaningful results exist for imbalanced classification, in\nwhich data are dominated by samples from one of the two classes. Existing\ntheory faces at least two main challenges. First, meaningful results must\nconsider more complex performance measures than classification accuracy. To\naddress this, we characterize a novel generalization of the Bayes-optimal\nclassifier to any performance metric computed from the confusion matrix, and we\nuse this to show how relative performance guarantees can be obtained in terms\nof the error of estimating the class probability function under uniform\n($\\mathcal{L}_\\infty$) loss. Second, as we show, optimal classification\nperformance depends on certain properties of class imbalance that have not\npreviously been formalized. Specifically, we propose a novel sub-type of class\nimbalance, which we call Uniform Class Imbalance. We analyze how Uniform Class\nImbalance influences optimal classifier performance and show that it\nnecessitates different classifier behavior than other types of class imbalance.\nWe further illustrate these two contributions in the case of $k$-nearest\nneighbor classification, for which we develop novel guarantees. Together, these\nresults provide some of the first meaningful finite-sample statistical theory\nfor imbalanced binary classification.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 03:55:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Singh", "Shashank", ""], ["Khim", "Justin", ""]]}, {"id": "2107.01784", "submitter": "Robin Karlsson", "authors": "Robin Karlsson, David Robert Wong, Simon Thompson, Kazuya Takeda", "title": "Learning a Model for Inferring a Spatial Road Lane Network Graph using\n  Self-Supervision", "comments": "Accepted for IEEE ITSC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interconnected road lanes are a central concept for navigating urban roads.\nCurrently, most autonomous vehicles rely on preconstructed lane maps as\ndesigning an algorithmic model is difficult. However, the generation and\nmaintenance of such maps is costly and hinders large-scale adoption of\nautonomous vehicle technology. This paper presents the first self-supervised\nlearning method to train a model to infer a spatially grounded lane-level road\nnetwork graph based on a dense segmented representation of the road scene\ngenerated from onboard sensors. A formal road lane network model is presented\nand proves that any structured road scene can be represented by a directed\nacyclic graph of at most depth three while retaining the notion of intersection\nregions, and that this is the most compressed representation. The formal model\nis implemented by a hybrid neural and search-based model, utilizing a novel\nbarrier function loss formulation for robust learning from partial labels.\nExperiments are conducted for all common road intersection layouts. Results\nshow that the model can generalize to new road layouts, unlike previous\napproaches, demonstrating its potential for real-world application as a\npractical learning-based lane-level map generator.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 04:34:51 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Karlsson", "Robin", ""], ["Wong", "David Robert", ""], ["Thompson", "Simon", ""], ["Takeda", "Kazuya", ""]]}, {"id": "2107.01820", "submitter": "Michael Thrun PhD", "authors": "Alfred Ultsch, J\\\"org Hoffmann, Maximilian R\\\"ohnert, Malte Von Bonin,\n  Uta Oelschl\\\"agel, Cornelia Brendel, Michael C. Thrun", "title": "An Explainable AI System for the Diagnosis of High Dimensional\n  Biomedical Data", "comments": "22 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical state of the art flow cytometry data samples consists of measures of\nmore than 100.000 cells in 10 or more features. AI systems are able to diagnose\nsuch data with almost the same accuracy as human experts. However, there is one\ncentral challenge in such systems: their decisions have far-reaching\nconsequences for the health and life of people, and therefore, the decisions of\nAI systems need to be understandable and justifiable by humans. In this work,\nwe present a novel explainable AI method, called ALPODS, which is able to\nclassify (diagnose) cases based on clusters, i.e., subpopulations, in the\nhigh-dimensional data. ALPODS is able to explain its decisions in a form that\nis understandable for human experts. For the identified subpopulations, fuzzy\nreasoning rules expressed in the typical language of domain experts are\ngenerated. A visualization method based on these rules allows human experts to\nunderstand the reasoning used by the AI system. A comparison to a selection of\nstate of the art explainable AI systems shows that ALPODS operates efficiently\non known benchmark data and also on everyday routine case data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:00:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ultsch", "Alfred", ""], ["Hoffmann", "J\u00f6rg", ""], ["R\u00f6hnert", "Maximilian", ""], ["Von Bonin", "Malte", ""], ["Oelschl\u00e4gel", "Uta", ""], ["Brendel", "Cornelia", ""], ["Thrun", "Michael C.", ""]]}, {"id": "2107.01835", "submitter": "Juliette Achddou", "authors": "Juliette Achddou (PSL, DI-ENS, VALDA ), Olivier Capp\\'e (LTCI, VALDA\n  ), Aur\\'elien Garivier (UMPA-ENSL)", "title": "Fast Rate Learning in Stochastic First Price Bidding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-price auctions have largely replaced traditional bidding approaches\nbased on Vickrey auctions in programmatic advertising. As far as learning is\nconcerned, first-price auctions are more challenging because the optimal\nbidding strategy does not only depend on the value of the item but also\nrequires some knowledge of the other bids. They have already given rise to\nseveral works in sequential learning, many of which consider models for which\nthe value of the buyer or the opponents' maximal bid is chosen in an\nadversarial manner. Even in the simplest settings, this gives rise to\nalgorithms whose regret grows as $\\sqrt{T}$ with respect to the time horizon\n$T$. Focusing on the case where the buyer plays against a stationary stochastic\nenvironment, we show how to achieve significantly lower regret: when the\nopponents' maximal bid distribution is known we provide an algorithm whose\nregret can be as low as $\\log^2(T)$; in the case where the distribution must be\nlearnt sequentially, a generalization of this algorithm can achieve $T^{1/3+\n\\epsilon}$ regret, for any $\\epsilon>0$. To obtain these results, we introduce\ntwo novel ideas that can be of interest in their own right. First, by\ntransposing results obtained in the posted price setting, we provide conditions\nunder which the first-price biding utility is locally quadratic around its\noptimum. Second, we leverage the observation that, on small sub-intervals, the\nconcentration of the variations of the empirical distribution function may be\ncontrolled more accurately than by using the classical\nDvoretzky-Kiefer-Wolfowitz inequality. Numerical simulations confirm that our\nalgorithms converge much faster than alternatives proposed in the literature\nfor various bid distributions, including for bids collected on an actual\nprogrammatic advertising platform.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:48:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Achddou", "Juliette", "", "PSL, DI-ENS, VALDA"], ["Capp\u00e9", "Olivier", "", "LTCI, VALDA"], ["Garivier", "Aur\u00e9lien", "", "UMPA-ENSL"]]}, {"id": "2107.01848", "submitter": "Alain Rakotomamonjy", "authors": "Alain Rakotomamonjy (DocApp - LITIS), Liva Ralaivola", "title": "Differentially Private Sliced Wasserstein Distance", "comments": null, "journal-ref": "International Conference of Machine Learning, Jul 2021, Virtual,\n  France", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing machine learning methods that are privacy preserving is today a\ncentral topic of research, with huge practical impacts. Among the numerous ways\nto address privacy-preserving learning, we here take the perspective of\ncomputing the divergences between distributions under the Differential Privacy\n(DP) framework -- being able to compute divergences between distributions is\npivotal for many machine learning problems, such as learning generative models\nor domain adaptation problems. Instead of resorting to the popular\ngradient-based sanitization method for DP, we tackle the problem at its roots\nby focusing on the Sliced Wasserstein Distance and seamlessly making it\ndifferentially private. Our main contribution is as follows: we analyze the\nproperty of adding a Gaussian perturbation to the intrinsic randomized\nmechanism of the Sliced Wasserstein Distance, and we establish the\nsensitivityof the resulting differentially private mechanism. One of our\nimportant findings is that this DP mechanism transforms the Sliced Wasserstein\ndistance into another distance, that we call the Smoothed Sliced Wasserstein\nDistance. This new differentially private distribution distance can be plugged\ninto generative models and domain adaptation algorithms in a transparent way,\nand we empirically show that it yields highly competitive performance compared\nwith gradient-based DP approaches from the literature, with almost no loss in\naccuracy for the domain adaptation problems that we consider.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:06:02 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Rakotomamonjy", "Alain", "", "DocApp - LITIS"], ["Ralaivola", "Liva", ""]]}, {"id": "2107.01850", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang, Chandler Squires, Caroline Uhler", "title": "Matching a Desired Causal State via Shift Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transforming a causal system from a given initial state to a desired target\nstate is an important task permeating multiple fields including control theory,\nbiology, and materials science. In causal models, such transformations can be\nachieved by performing a set of interventions. In this paper, we consider the\nproblem of identifying a shift intervention that matches the desired mean of a\nsystem through active learning. We define the Markov equivalence class that is\nidentifiable from shift interventions and propose two active learning\nstrategies that are guaranteed to exactly match a desired mean. We then derive\na worst-case lower bound for the number of interventions required and show that\nthese strategies are optimal for certain classes of graphs. In particular, we\nshow that our strategies may require exponentially fewer interventions than the\npreviously considered approaches, which optimize for structure learning in the\nunderlying causal graph. In line with our theoretical results, we also\ndemonstrate experimentally that our proposed active learning strategies require\nfewer interventions compared to several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:11:36 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Jiaqi", ""], ["Squires", "Chandler", ""], ["Uhler", "Caroline", ""]]}, {"id": "2107.01876", "submitter": "Xiangyu Zheng", "authors": "Xiangyu Zheng, Xinwei Sun, Wei Chen, Tie-Yan Liu", "title": "Causally Invariant Predictor with Shift-Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an invariant causal predictor that is robust to\ndistribution shift across domains and maximally reserves the transferable\ninvariant information. Based on a disentangled causal factorization, we\nformulate the distribution shift as soft interventions in the system, which\ncovers a wide range of cases for distribution shift as we do not make prior\nspecifications on the causal structure or the intervened variables. Instead of\nimposing regularizations to constrain the invariance of the predictor, we\npropose to predict by the intervened conditional expectation based on the\ndo-operator and then prove that it is invariant across domains. More\nimportantly, we prove that the proposed predictor is the robust predictor that\nminimizes the worst-case quadratic loss among the distributions of all domains.\nFor empirical learning, we propose an intuitive and flexible estimating method\nbased on data regeneration and present a local causal discovery procedure to\nguide the regeneration step. The key idea is to regenerate data such that the\nregenerated distribution is compatible with the intervened graph, which allows\nus to incorporate standard supervised learning methods with the regenerated\ndata. Experimental results on both synthetic and real data demonstrate the\nefficacy of our predictor in improving the predictive accuracy and robustness\nacross domains.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:07:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zheng", "Xiangyu", ""], ["Sun", "Xinwei", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2107.01952", "submitter": "Giorgos Bouritsas", "authors": "Giorgos Bouritsas, Andreas Loukas, Nikolaos Karalias, Michael M.\n  Bronstein", "title": "Partition and Code: learning how to compress graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.SI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we use machine learning to compress graph data? The absence of ordering\nin graphs poses a significant challenge to conventional compression algorithms,\nlimiting their attainable gains as well as their ability to discover relevant\npatterns. On the other hand, most graph compression approaches rely on\ndomain-dependent handcrafted representations and cannot adapt to different\nunderlying graph distributions. This work aims to establish the necessary\nprinciples a lossless graph compression method should follow to approach the\nentropy storage lower bound. Instead of making rigid assumptions about the\ngraph distribution, we formulate the compressor as a probabilistic model that\ncan be learned from data and generalise to unseen instances. Our \"Partition and\nCode\" framework entails three steps: first, a partitioning algorithm decomposes\nthe graph into elementary structures, then these are mapped to the elements of\na small dictionary on which we learn a probability distribution, and finally,\nan entropy encoder translates the representation into bits. All three steps are\nparametric and can be trained with gradient descent. We theoretically compare\nthe compression quality of several graph encodings and prove, under mild\nconditions, a total ordering of their expected description lengths. Moreover,\nwe show that, under the same conditions, PnC achieves compression gains w.r.t.\nthe baselines that grow either linearly or quadratically with the number of\nvertices. Our algorithms are quantitatively evaluated on diverse real-world\nnetworks obtaining significant performance improvements with respect to\ndifferent families of non-parametric and parametric graph compressors.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:41:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bouritsas", "Giorgos", ""], ["Loukas", "Andreas", ""], ["Karalias", "Nikolaos", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "2107.01959", "submitter": "Edward Wagstaff", "authors": "Edward Wagstaff, Fabian B. Fuchs, Martin Engelcke, Michael A. Osborne,\n  Ingmar Posner", "title": "Universal Approximation of Functions on Sets", "comments": "54 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modelling functions of sets, or equivalently, permutation-invariant\nfunctions, is a long-standing challenge in machine learning. Deep Sets is a\npopular method which is known to be a universal approximator for continuous set\nfunctions. We provide a theoretical analysis of Deep Sets which shows that this\nuniversal approximation property is only guaranteed if the model's latent space\nis sufficiently high-dimensional. If the latent space is even one dimension\nlower than necessary, there exist piecewise-affine functions for which Deep\nSets performs no better than a na\\\"ive constant baseline, as judged by\nworst-case error. Deep Sets may be viewed as the most efficient incarnation of\nthe Janossy pooling paradigm. We identify this paradigm as encompassing most\ncurrently popular set-learning methods. Based on this connection, we discuss\nthe implications of our results for set learning more broadly, and identify\nsome open questions on the universality of Janossy pooling in general.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:56:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wagstaff", "Edward", ""], ["Fuchs", "Fabian B.", ""], ["Engelcke", "Martin", ""], ["Osborne", "Michael A.", ""], ["Posner", "Ingmar", ""]]}, {"id": "2107.01988", "submitter": "Pietro Gori", "authors": "Robin Louiset and Pietro Gori and Benoit Dufumier and Josselin Houenou\n  and Antoine Grigis and Edouard Duchesnay", "title": "UCSL : A Machine Learning Expectation-Maximization framework for\n  Unsupervised Clustering driven by Supervised Learning", "comments": "ECML/PKDD 2021", "journal-ref": "ECML/PKDD 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subtype Discovery consists in finding interpretable and consistent sub-parts\nof a dataset, which are also relevant to a certain supervised task. From a\nmathematical point of view, this can be defined as a clustering task driven by\nsupervised learning in order to uncover subgroups in line with the supervised\nprediction. In this paper, we propose a general Expectation-Maximization\nensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised\nLearning). Our method is generic, it can integrate any clustering method and\ncan be driven by both binary classification and regression. We propose to\nconstruct a non-linear model by merging multiple linear estimators, one per\ncluster. Each hyperplane is estimated so that it correctly discriminates - or\npredict - only one cluster. We use SVC or Logistic Regression for\nclassification and SVR for regression. Furthermore, to perform cluster analysis\nwithin a more suitable space, we also propose a dimension-reduction algorithm\nthat projects the data onto an orthonormal space relevant to the supervised\ntask. We analyze the robustness and generalization capability of our algorithm\nusing synthetic and experimental datasets. In particular, we validate its\nability to identify suitable consistent sub-types by conducting a\npsychiatric-diseases cluster analysis with known ground-truth labels. The gain\nof the proposed method over previous state-of-the-art techniques is about +1.9\npoints in terms of balanced accuracy. Finally, we make codes and examples\navailable in a scikit-learn-compatible Python package at\nhttps://github.com/neurospin-projects/2021_rlouiset_ucsl\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:55:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Louiset", "Robin", ""], ["Gori", "Pietro", ""], ["Dufumier", "Benoit", ""], ["Houenou", "Josselin", ""], ["Grigis", "Antoine", ""], ["Duchesnay", "Edouard", ""]]}, {"id": "2107.01994", "submitter": "Pietro Gori", "authors": "Mateus Riva and Florian Yger and Pietro Gori and Roberto M. Cesar Jr.\n  and Isabelle Bloch", "title": "Template-Based Graph Clustering", "comments": "ECML-PKDD, Workshop on Graph Embedding and Minin (GEM) 2020", "journal-ref": "ECML-PKDD, Workshop on Graph Embedding and Minin (GEM) 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel graph clustering method guided by additional information\non the underlying structure of the clusters (or communities). The problem is\nformulated as the matching of a graph to a template with smaller dimension,\nhence matching $n$ vertices of the observed graph (to be clustered) to the $k$\nvertices of a template graph, using its edges as support information, and\nrelaxed on the set of orthonormal matrices in order to find a $k$ dimensional\nembedding. With relevant priors that encode the density of the clusters and\ntheir relationships, our method outperforms classical methods, especially for\nchallenging cases.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:13:34 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Riva", "Mateus", ""], ["Yger", "Florian", ""], ["Gori", "Pietro", ""], ["Cesar", "Roberto M.", "Jr."], ["Bloch", "Isabelle", ""]]}, {"id": "2107.02010", "submitter": "Pietro Gori", "authors": "Jean Feydy and Pierre Roussillon and Alain Trouv\\'e and Pietro Gori", "title": "Fast and Scalable Optimal Transport for Brain Tractograms", "comments": "MICCAI 2019", "journal-ref": "MICCAI 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new multiscale algorithm for solving regularized Optimal\nTransport problems on the GPU, with a linear memory footprint. Relying on\nSinkhorn divergences which are convex, smooth and positive definite loss\nfunctions, this method enables the computation of transport plans between\nmillions of points in a matter of minutes. We show the effectiveness of this\napproach on brain tractograms modeled either as bundles of fibers or as track\ndensity maps. We use the resulting smooth assignments to perform label transfer\nfor atlas-based segmentation of fiber tractograms. The parameters -- blur and\nreach -- of our method are meaningful, defining the minimum and maximum\ndistance at which two fibers are compared with each other. They can be set\naccording to anatomical knowledge. Furthermore, we also propose to estimate a\nprobabilistic atlas of a population of track density maps as a Wasserstein\nbarycenter. Our CUDA implementation is endowed with a user-friendly PyTorch\ninterface, freely available on the PyPi repository (pip install geomloss) and\nat www.kernel-operations.io/geomloss.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:28:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Feydy", "Jean", ""], ["Roussillon", "Pierre", ""], ["Trouv\u00e9", "Alain", ""], ["Gori", "Pietro", ""]]}, {"id": "2107.02070", "submitter": "Wilson Mongwe", "authors": "Wilson Tsakane Mongwe, Rendani Mbuvha, Tshilidzi Marwala", "title": "Antithetic Riemannian Manifold And Quantum-Inspired Hamiltonian Monte\n  Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Markov Chain Monte Carlo inference of target posterior distributions in\nmachine learning is predominately conducted via Hamiltonian Monte Carlo and its\nvariants. This is due to Hamiltonian Monte Carlo based samplers ability to\nsuppress random-walk behaviour. As with other Markov Chain Monte Carlo methods,\nHamiltonian Monte Carlo produces auto-correlated samples which results in high\nvariance in the estimators, and low effective sample size rates in the\ngenerated samples. Adding antithetic sampling to Hamiltonian Monte Carlo has\nbeen previously shown to produce higher effective sample rates compared to\nvanilla Hamiltonian Monte Carlo. In this paper, we present new algorithms which\nare antithetic versions of Riemannian Manifold Hamiltonian Monte Carlo and\nQuantum-Inspired Hamiltonian Monte Carlo. The Riemannian Manifold Hamiltonian\nMonte Carlo algorithm improves on Hamiltonian Monte Carlo by taking into\naccount the local geometry of the target, which is beneficial for target\ndensities that may exhibit strong correlations in the parameters.\nQuantum-Inspired Hamiltonian Monte Carlo is based on quantum particles that can\nhave random mass. Quantum-Inspired Hamiltonian Monte Carlo uses a random mass\nmatrix which results in better sampling than Hamiltonian Monte Carlo on spiky\nand multi-modal distributions such as jump diffusion processes. The analysis is\nperformed on jump diffusion process using real world financial market data, as\nwell as on real world benchmark classification tasks using Bayesian logistic\nregression.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:03:07 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mongwe", "Wilson Tsakane", ""], ["Mbuvha", "Rendani", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "2107.02085", "submitter": "Anand Dixit", "authors": "Anand Dixit and Vivekananda Roy", "title": "Analyzing Relevance Vector Machines using a single penalty approach", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance vector machine (RVM) is a popular sparse Bayesian learning model\ntypically used for prediction. Recently it has been shown that improper priors\nassumed on multiple penalty parameters in RVM may lead to an improper\nposterior. Currently in the literature, the sufficient conditions for posterior\npropriety of RVM do not allow improper priors over the multiple penalty\nparameters. In this article, we propose a single penalty relevance vector\nmachine (SPRVM) model in which multiple penalty parameters are replaced by a\nsingle penalty and we consider a semi Bayesian approach for fitting the SPRVM.\nThe necessary and sufficient conditions for posterior propriety of SPRVM are\nmore liberal than those of RVM and allow for several improper priors over the\npenalty parameter. Additionally, we also prove the geometric ergodicity of the\nGibbs sampler used to analyze the SPRVM model and hence can estimate the\nasymptotic standard errors associated with the Monte Carlo estimate of the\nmeans of the posterior predictive distribution. Such a Monte Carlo standard\nerror cannot be computed in the case of RVM, since the rate of convergence of\nthe Gibbs sampler used to analyze RVM is not known. The predictive performance\nof RVM and SPRVM is compared by analyzing three real life datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:26:09 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dixit", "Anand", ""], ["Roy", "Vivekananda", ""]]}, {"id": "2107.02139", "submitter": "Lin Chen", "authors": "Lin Chen, Hossein Esfandiari, Gang Fu, Vahab S. Mirrokni, Qian Yu", "title": "Feature Cross Search via Submodular Optimization", "comments": "Accepted to ESA 2021. Authors are ordered alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study feature cross search as a fundamental primitive in\nfeature engineering. The importance of feature cross search especially for the\nlinear model has been known for a while, with well-known textbook examples. In\nthis problem, the goal is to select a small subset of features, combine them to\nform a new feature (called the crossed feature) by considering their Cartesian\nproduct, and find feature crosses to learn an \\emph{accurate} model. In\nparticular, we study the problem of maximizing a normalized Area Under the\nCurve (AUC) of the linear model trained on the crossed feature column.\n  First, we show that it is not possible to provide an $n^{1/\\log\\log\nn}$-approximation algorithm for this problem unless the exponential time\nhypothesis fails. This result also rules out the possibility of solving this\nproblem in polynomial time unless $\\mathsf{P}=\\mathsf{NP}$. On the positive\nside, by assuming the \\naive\\ assumption, we show that there exists a simple\ngreedy $(1-1/e)$-approximation algorithm for this problem. This result is\nestablished by relating the AUC to the total variation of the commutator of two\nprobability measures and showing that the total variation of the commutator is\nmonotone and submodular. To show this, we relate the submodularity of this\nfunction to the positive semi-definiteness of a corresponding kernel matrix.\nThen, we use Bochner's theorem to prove the positive semi-definiteness by\nshowing that its inverse Fourier transform is non-negative everywhere. Our\ntechniques and structural results might be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 16:58:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chen", "Lin", ""], ["Esfandiari", "Hossein", ""], ["Fu", "Gang", ""], ["Mirrokni", "Vahab S.", ""], ["Yu", "Qian", ""]]}, {"id": "2107.02145", "submitter": "Mark Grobman", "authors": "Niv Vosco and Alon Shenkler and Mark Grobman", "title": "Tiled Squeeze-and-Excite: Channel Attention With Local Spatial Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the amount of spatial context required for\nchannel attention. To this end we study the popular squeeze-and-excite (SE)\nblock which is a simple and lightweight channel attention mechanism. SE blocks\nand its numerous variants commonly use global average pooling (GAP) to create a\nsingle descriptor for each channel. Here, we empirically analyze the amount of\nspatial context needed for effective channel attention and find that limited\nlocalcontext on the order of seven rows or columns of the original image is\nsufficient to match the performance of global context. We propose tiled\nsqueeze-and-excite (TSE), which is a framework for building SE-like blocks that\nemploy several descriptors per channel, with each descriptor based on local\ncontext only. We further show that TSE is a drop-in replacement for the SE\nblock and can be used in existing SE networks without re-training. This implies\nthat local context descriptors are similar both to each other and to the global\ncontext descriptor. Finally, we show that TSE has important practical\nimplications for deployment of SE-networks to dataflow AI accelerators due to\ntheir reduced pipeline buffering requirements. For example, using TSE reduces\nthe amount of activation pipeline buffering in EfficientDetD2 by 90% compared\nto SE (from 50M to 4.77M) without loss of accuracy. Our code and pre-trained\nmodels will be publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:10:14 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Vosco", "Niv", ""], ["Shenkler", "Alon", ""], ["Grobman", "Mark", ""]]}, {"id": "2107.02146", "submitter": "Ali Mahzarnia", "authors": "Ali Mahzarnia and Jun Song", "title": "Multivariate functional group sparse regression: functional predictor\n  selection", "comments": "The R package that is developed for this paper is available at\n  GitHub. See https://github.com/Ali-Mahzarnia/MFSGrp", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST q-bio.NC stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose methods for functional predictor selection and the\nestimation of smooth functional coefficients simultaneously in a\nscalar-on-function regression problem under high-dimensional multivariate\nfunctional data setting. In particular, we develop two methods for functional\ngroup-sparse regression under a generic Hilbert space of infinite dimension. We\nshow the convergence of algorithms and the consistency of the estimation and\nthe selection (oracle property) under infinite-dimensional Hilbert spaces.\nSimulation studies show the effectiveness of the methods in both the selection\nand the estimation of functional coefficients. The applications to the\nfunctional magnetic resonance imaging (fMRI) reveal the regions of the human\nbrain related to ADHD and IQ.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:11:28 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 15:03:06 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mahzarnia", "Ali", ""], ["Song", "Jun", ""]]}, {"id": "2107.02212", "submitter": "Kristy Choi", "authors": "Kristy Choi, Madeline Liao, Stefano Ermon", "title": "Featurized Density Ratio Estimation", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Density ratio estimation serves as an important technique in the unsupervised\nmachine learning toolbox. However, such ratios are difficult to estimate for\ncomplex, high-dimensional data, particularly when the densities of interest are\nsufficiently different. In our work, we propose to leverage an invertible\ngenerative model to map the two distributions into a common feature space prior\nto estimation. This featurization brings the densities closer together in\nlatent space, sidestepping pathological scenarios where the learned density\nratios in input space can be arbitrarily inaccurate. At the same time, the\ninvertibility of our feature map guarantees that the ratios computed in feature\nspace are equivalent to those in input space. Empirically, we demonstrate the\nefficacy of our approach in a variety of downstream tasks that require access\nto accurate density ratios such as mutual information estimation, targeted\nsampling in deep generative models, and classification with data augmentation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:30:26 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Choi", "Kristy", ""], ["Liao", "Madeline", ""], ["Ermon", "Stefano", ""]]}, {"id": "2107.02233", "submitter": "Salva R\\\"uhling Cachay", "authors": "Salva R\\\"uhling Cachay, Benedikt Boecking, Artur Dubrawski", "title": "End-to-End Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aggregating multiple sources of weak supervision (WS) can ease the\ndata-labeling bottleneck prevalent in many machine learning applications, by\nreplacing the tedious manual collection of ground truth labels. Current state\nof the art approaches that do not use any labeled training data, however,\nrequire two separate modeling steps: Learning a probabilistic latent variable\nmodel based on the WS sources -- making assumptions that rarely hold in\npractice -- followed by downstream model training. Importantly, the first step\nof modeling does not consider the performance of the downstream model. To\naddress these caveats we propose an end-to-end approach for directly learning\nthe downstream model by maximizing its agreement with probabilistic labels\ngenerated by reparameterizing previous probabilistic posteriors with a neural\nnetwork. Our results show improved performance over prior work in terms of end\nmodel performance on downstream test sets, as well as in terms of improved\nrobustness to dependencies among weak supervision sources.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:10:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cachay", "Salva R\u00fchling", ""], ["Boecking", "Benedikt", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2107.02237", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Akshay Krishnamurthy", "title": "Efficient First-Order Contextual Bandits: Prediction, Allocation, and\n  Triangular Discrimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recurring theme in statistical learning, online learning, and beyond is\nthat faster convergence rates are possible for problems with low noise, often\nquantified by the performance of the best hypothesis; such results are known as\nfirst-order or small-loss guarantees. While first-order guarantees are\nrelatively well understood in statistical and online learning, adapting to low\nnoise in contextual bandits (and more broadly, decision making) presents major\nalgorithmic challenges. In a COLT 2017 open problem, Agarwal, Krishnamurthy,\nLangford, Luo, and Schapire asked whether first-order guarantees are even\npossible for contextual bandits and -- if so -- whether they can be attained by\nefficient algorithms. We give a resolution to this question by providing an\noptimal and efficient reduction from contextual bandits to online regression\nwith the logarithmic (or, cross-entropy) loss. Our algorithm is simple and\npractical, readily accommodates rich function classes, and requires no\ndistributional assumptions beyond realizability. In a large-scale empirical\nevaluation, we find that our approach typically outperforms comparable\nnon-first-order methods.\n  On the technical side, we show that the logarithmic loss and an\ninformation-theoretic quantity called the triangular discrimination play a\nfundamental role in obtaining first-order guarantees, and we combine this\nobservation with new refinements to the regression oracle reduction framework\nof Foster and Rakhlin. The use of triangular discrimination yields novel\nresults even for the classical statistical learning model, and we anticipate\nthat it will find broader use.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:20:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Foster", "Dylan J.", ""], ["Krishnamurthy", "Akshay", ""]]}, {"id": "2107.02266", "submitter": "Koulik Khamaru", "authors": "Koulik Khamaru, Yash Deshpande, Lester Mackey, Martin J. Wainwright", "title": "Near-optimal inference in adaptive linear regression", "comments": "41 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When data is collected in an adaptive manner, even simple methods like\nordinary least squares can exhibit non-normal asymptotic behavior. As an\nundesirable consequence, hypothesis tests and confidence intervals based on\nasymptotic normality can lead to erroneous results. We propose an online\ndebiasing estimator to correct these distributional anomalies in least squares\nestimation. Our proposed method takes advantage of the covariance structure\npresent in the dataset and provides sharper estimates in directions for which\nmore information has accrued. We establish an asymptotic normality property for\nour proposed online debiasing estimator under mild conditions on the data\ncollection process, and provide asymptotically exact confidence intervals. We\nadditionally prove a minimax lower bound for the adaptive linear regression\nproblem, thereby providing a baseline by which to compare estimators. There are\nvarious conditions under which our proposed estimator achieves the minimax\nlower bound up to logarithmic factors. We demonstrate the usefulness of our\ntheory via applications to multi-armed bandit, autoregressive time series\nestimation, and active learning with exploration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:05:11 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 02:57:42 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Khamaru", "Koulik", ""], ["Deshpande", "Yash", ""], ["Mackey", "Lester", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "2107.02363", "submitter": "Andrew Davison", "authors": "Andrew Davison and Morgane Austern", "title": "Asymptotics of Network Embeddings Learned via Subsampling", "comments": "98 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network data are ubiquitous in modern machine learning, with tasks of\ninterest including node classification, node clustering and link prediction. A\nfrequent approach begins by learning an Euclidean embedding of the network, to\nwhich algorithms developed for vector-valued data are applied. For large\nnetworks, embeddings are learned using stochastic gradient methods where the\nsub-sampling scheme can be freely chosen. Despite the strong empirical\nperformance of such methods, they are not well understood theoretically. Our\nwork encapsulates representation methods using a subsampling approach, such as\nnode2vec, into a single unifying framework. We prove, under the assumption that\nthe graph is exchangeable, that the distribution of the learned embedding\nvectors asymptotically decouples. Moreover, we characterize the asymptotic\ndistribution and provided rates of convergence, in terms of the latent\nparameters, which includes the choice of loss function and the embedding\ndimension. This provides a theoretical foundation to understand what the\nembedding vectors represent and how well these methods perform on downstream\ntasks. Notably, we observe that typically used loss functions may lead to\nshortcomings, such as a lack of Fisher consistency.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:54:53 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Davison", "Andrew", ""], ["Austern", "Morgane", ""]]}, {"id": "2107.02377", "submitter": "Kaixuan Huang", "authors": "Kaixuan Huang, Sham M. Kakade, Jason D. Lee, Qi Lei", "title": "A Short Note on the Relationship of Information Gain and Eluder\n  Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eluder dimension and information gain are two widely used methods of\ncomplexity measures in bandit and reinforcement learning. Eluder dimension was\noriginally proposed as a general complexity measure of function classes, but\nthe common examples of where it is known to be small are function spaces\n(vector spaces). In these cases, the primary tool to upper bound the eluder\ndimension is the elliptic potential lemma. Interestingly, the elliptic\npotential lemma also features prominently in the analysis of linear\nbandits/reinforcement learning and their nonparametric generalization, the\ninformation gain. We show that this is not a coincidence -- eluder dimension\nand information gain are equivalent in a precise sense for reproducing kernel\nHilbert spaces.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 04:01:22 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Huang", "Kaixuan", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""]]}, {"id": "2107.02397", "submitter": "Shijun Zhang", "authors": "Zuowei Shen and Haizhao Yang and Shijun Zhang", "title": "Deep Network Approximation: Achieving Arbitrary Accuracy with Fixed\n  Number of Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops simple feed-forward neural networks that achieve the\nuniversal approximation property for all continuous functions with a fixed\nfinite number of neurons. These neural networks are simple because they are\ndesigned with a simple and computable continuous activation function $\\sigma$\nleveraging a triangular-wave function and a softsign function. We prove that\n$\\sigma$-activated networks with width $36d(2d+1)$ and depth $11$ can\napproximate any continuous function on a $d$-dimensioanl hypercube within an\narbitrarily small error. Hence, for supervised learning and its related\nregression problems, the hypothesis space generated by these networks with a\nsize not smaller than $36d(2d+1)\\times 11$ is dense in the space of continuous\nfunctions. Furthermore, classification functions arising from image and signal\nclassification are in the hypothesis space generated by $\\sigma$-activated\nnetworks with width $36d(2d+1)$ and depth $12$, when there exist pairwise\ndisjoint closed bounded subsets of $\\mathbb{R}^d$ such that the samples of the\nsame class are located in the same subset.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 05:24:30 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:21:55 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Shen", "Zuowei", ""], ["Yang", "Haizhao", ""], ["Zhang", "Shijun", ""]]}, {"id": "2107.02463", "submitter": "Florian Haselbeck", "authors": "Florian Haselbeck and Dominik G. Grimm", "title": "EVARS-GPR: EVent-triggered Augmented Refitting of Gaussian Process\n  Regression for Seasonal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series forecasting is a growing domain with diverse applications.\nHowever, changes of the system behavior over time due to internal or external\ninfluences are challenging. Therefore, predictions of a previously learned\nfore-casting model might not be useful anymore. In this paper, we present\nEVent-triggered Augmented Refitting of Gaussian Process Regression for Seasonal\nData (EVARS-GPR), a novel online algorithm that is able to handle sudden shifts\nin the target variable scale of seasonal data. For this purpose, EVARS-GPR\ncom-bines online change point detection with a refitting of the prediction\nmodel using data augmentation for samples prior to a change point. Our\nexperiments on sim-ulated data show that EVARS-GPR is applicable for a wide\nrange of output scale changes. EVARS-GPR has on average a 20.8 % lower RMSE on\ndifferent real-world datasets compared to methods with a similar computational\nresource con-sumption. Furthermore, we show that our algorithm leads to a\nsix-fold reduction of the averaged runtime in relation to all comparison\npartners with a periodical refitting strategy. In summary, we present a\ncomputationally efficient online fore-casting algorithm for seasonal time\nseries with changes of the target variable scale and demonstrate its\nfunctionality on simulated as well as real-world data. All code is publicly\navailable on GitHub: https://github.com/grimmlab/evars-gpr.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:20:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Haselbeck", "Florian", ""], ["Grimm", "Dominik G.", ""]]}, {"id": "2107.02474", "submitter": "Vincent Moens", "authors": "Vincent Moens, Aivar Sootla, Haitham Bou Ammar, Jun Wang", "title": "Implicit Variational Conditional Sampling with Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a method for conditional sampling with normalizing flows when only\npart of an observation is available. We rely on the following fact: if the\nflow's domain can be partitioned in such a way that the flow restrictions to\nsubdomains keep the bijectivity property, a lower bound to the conditioning\nvariable log-probability can be derived. Simulation from the variational\nconditional flow then amends to solving an equality constraint. Our\ncontribution is three-fold: a) we provide detailed insights on the choice of\nvariational distributions; b) we propose how to partition the input space of\nthe flow to preserve bijectivity property; c) we propose a set of methods to\noptimise the variational distribution in specific cases. Through extensive\nexperiments, we show that our sampling method can be applied with success to\ninvertible residual networks for inference and classification.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:40:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moens", "Vincent", ""], ["Sootla", "Aivar", ""], ["Ammar", "Haitham Bou", ""], ["Wang", "Jun", ""]]}, {"id": "2107.02480", "submitter": "Anna Guitart Atienza", "authors": "Anna Guitart, Ana Fern\\'andez del R\\'io and \\'Africa Peri\\'a\\~nez", "title": "Midwifery Learning and Forecasting: Predicting Content Demand with\n  User-Generated Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Every day, 800 women and 6,700 newborns die from complications related to\npregnancy or childbirth. A well-trained midwife can prevent most of these\nmaternal and newborn deaths. Data science models together with logs generated\nby users of online learning applications for midwives can help to improve their\nlearning competencies. The goal is to use these rich behavioral data to push\ndigital learning towards personalized content and to provide an adaptive\nlearning journey. In this work, we evaluate various forecasting methods to\ndetermine the interest of future users on the different kind of contents\navailable in the app, broken down by profession and region.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:48:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Guitart", "Anna", ""], ["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "2107.02495", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison", "title": "InfoNCE is a variational autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a popular self-supervised learning method, InfoNCE, is a special\ncase of a new family of unsupervised learning methods, the self-supervised\nvariational autoencoder (SSVAE). SSVAEs circumvent the usual VAE requirement to\nreconstruct the data by using a carefully chosen implicit decoder. The InfoNCE\nobjective was motivated as a simplified parametric mutual information\nestimator. Under one choice of prior, the SSVAE objective (i.e. the ELBO) is\nexactly equal to the mutual information (up to constants). Under an alternative\nchoice of prior, the SSVAE objective is exactly equal to the simplified\nparametric mutual information estimator used in InfoNCE (up to constants).\nImportantly, the use of simplified parametric mutual information estimators is\nbelieved to be critical to obtain good high-level representations, and the\nSSVAE framework naturally provides a principled justification for using prior\ninformation to choose these estimators.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 09:24:57 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Aitchison", "Laurence", ""]]}, {"id": "2107.02510", "submitter": "Changwoo Lee", "authors": "Changwoo J. Lee, Zhao Tang Luo, Huiyan Sang", "title": "T-LoHo: A Bayesian Regularization Model for Structured Sparsity and\n  Smoothness on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern complex data can be represented as a graph. In models dealing\nwith graph-structured data, multivariate parameters are not just sparse but\nhave structured sparsity and smoothness in the sense that both zero and\nnon-zero parameters tend to cluster together. We propose a new prior for high\ndimensional parameters with graphical relations, referred to as a Tree-based\nLow-rank Horseshoe(T-LoHo) model, that generalizes the popular univariate\nBayesian horseshoe shrinkage prior to the multivariate setting to detect\nstructured sparsity and smoothness simultaneously. The prior can be embedded in\nmany hierarchical high dimensional models. To illustrate its utility, we apply\nit to regularize a Bayesian high-dimensional regression problem where the\nregression coefficients are linked on a graph. The resulting clusters have\nflexible shapes and satisfy the cluster contiguity constraint with respect to\nthe graph. We design an efficient Markov chain Monte Carlo algorithm that\ndelivers full Bayesian inference with uncertainty measures for model parameters\nincluding the number of clusters. We offer theoretical investigations of the\nclustering effects and posterior concentration results. Finally, we illustrate\nthe performance of the model with simulation studies and real data applications\nsuch as anomaly detection in road networks. The results indicate substantial\nimprovements over other competing methods such as sparse fused lasso.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:10:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Lee", "Changwoo J.", ""], ["Luo", "Zhao Tang", ""], ["Sang", "Huiyan", ""]]}, {"id": "2107.02526", "submitter": "Francesco Farina", "authors": "Francesco Farina, Lawrence Phillips, Nicola J Richmond", "title": "Intrinsic uncertainties and where to find them", "comments": "Presented at the ICML 2021 Workshop on Uncertainty and Robustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for uncertainty estimation that both describes and\nextends many existing methods. We consider typical hyperparameters involved in\nclassical training as random variables and marginalise them out to capture\nvarious sources of uncertainty in the parameter space. We investigate which\nforms and combinations of marginalisation are most useful from a practical\npoint of view on standard benchmarking data sets. Moreover, we discuss how some\nmarginalisations may produce reliable estimates of uncertainty without the need\nfor extensive hyperparameter tuning and/or large-scale ensembling.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:35:35 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Farina", "Francesco", ""], ["Phillips", "Lawrence", ""], ["Richmond", "Nicola J", ""]]}, {"id": "2107.02645", "submitter": "Martijn G\\\"osgens", "authors": "Martijn G\\\"osgens, Remco van der Hofstad, Nelly Litvak", "title": "The Hyperspherical Geometry of Community Detection: Modularity as a\n  Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Louvain algorithm is currently one of the most popular community\ndetection methods. This algorithm finds communities by maximizing a quantity\ncalled modularity. In this work, we describe a metric space of clusterings,\nwhere clusterings are described by a binary vector indexed by the vertex-pairs.\nWe extend this geometry to a hypersphere and prove that maximizing modularity\nis equivalent to minimizing the angular distance to some modularity vector over\nthe set of clustering vectors. This equivalence allows us to view the Louvain\nalgorithm as a nearest-neighbor search that approximately minimizes the\ndistance to this modularity vector. By replacing this modularity vector by a\ndifferent vector, many alternative community detection methods can be obtained.\nWe explore this wider class and compare it to existing modularity-based\nmethods. Our experiments show that these alternatives may outperform\nmodularity-based methods. For example, when communities are large compared to\nvertex neighborhoods, a vector based on numbers of common neighbors outperforms\nexisting community detection methods. While the focus of the present work is\ncommunity detection in networks, the proposed methodology can be applied to any\nclustering problem where pair-wise similarity data is available.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:32:32 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["G\u00f6sgens", "Martijn", ""], ["van der Hofstad", "Remco", ""], ["Litvak", "Nelly", ""]]}, {"id": "2107.02655", "submitter": "Pietro Gori", "authors": "Giammarco La Barbera and Pietro Gori and Haithem Boussaid and Bruno\n  Belucci and Alessandro Delmonte and Jeanne Goulin and Sabine Sarnacki and\n  Laurence Rouet and Isabelle Bloch", "title": "Automatic size and pose homogenization with spatial transformer network\n  to improve and accelerate pediatric segmentation", "comments": "ISBI 2021", "journal-ref": "ISBI 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to a high heterogeneity in pose and size and to a limited number of\navailable data, segmentation of pediatric images is challenging for deep\nlearning methods. In this work, we propose a new CNN architecture that is pose\nand scale invariant thanks to the use of Spatial Transformer Network (STN). Our\narchitecture is composed of three sequential modules that are estimated\ntogether during training: (i) a regression module to estimate a similarity\nmatrix to normalize the input image to a reference one; (ii) a differentiable\nmodule to find the region of interest to segment; (iii) a segmentation module,\nbased on the popular UNet architecture, to delineate the object. Unlike the\noriginal UNet, which strives to learn a complex mapping, including pose and\nscale variations, from a finite training dataset, our segmentation module\nlearns a simpler mapping focusing on images with normalized pose and size.\nFurthermore, the use of an automatic bounding box detection through STN allows\nsaving time and especially memory, while keeping similar performance. We test\nthe proposed method in kidney and renal tumor segmentation on abdominal\npediatric CT scanners. Results indicate that the estimated STN homogenization\nof size and pose accelerates the segmentation (25h), compared to standard\ndata-augmentation (33h), while obtaining a similar quality for the kidney\n(88.01\\% of Dice score) and improving the renal tumor delineation (from 85.52\\%\nto 87.12\\%).\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:50:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["La Barbera", "Giammarco", ""], ["Gori", "Pietro", ""], ["Boussaid", "Haithem", ""], ["Belucci", "Bruno", ""], ["Delmonte", "Alessandro", ""], ["Goulin", "Jeanne", ""], ["Sarnacki", "Sabine", ""], ["Rouet", "Laurence", ""], ["Bloch", "Isabelle", ""]]}, {"id": "2107.02658", "submitter": "Tianjin Huang", "authors": "Tianjin huang, Yulong Pei, Vlado Menkovski and Mykola Pechenizkiy", "title": "On Generalization of Graph Autoencoders with Adversarial Training", "comments": "ECML 2021 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is an approach for increasing model's resilience against\nadversarial perturbations. Such approaches have been demonstrated to result in\nmodels with feature representations that generalize better. However, limited\nworks have been done on adversarial training of models on graph data. In this\npaper, we raise such a question { does adversarial training improve the\ngeneralization of graph representations. We formulate L2 and L1 versions of\nadversarial training in two powerful node embedding methods: graph autoencoder\n(GAE) and variational graph autoencoder (VGAE). We conduct extensive\nexperiments on three main applications, i.e. link prediction, node clustering,\ngraph anomaly detection of GAE and VGAE, and demonstrate that both L2 and L1\nadversarial training boost the generalization of GAE and VGAE.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:53:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["huang", "Tianjin", ""], ["Pei", "Yulong", ""], ["Menkovski", "Vlado", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2107.02729", "submitter": "Sara Magliacane", "authors": "Biwei Huang, Fan Feng, Chaochao Lu, Sara Magliacane, Kun Zhang", "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Most approaches in reinforcement learning (RL) are data-hungry and specific\nto fixed environments. In this paper, we propose a principled framework for\nadaptive RL, called AdaRL, that adapts reliably to changes across domains.\nSpecifically, we construct a generative environment model for the structural\nrelationships among variables in the system and embed the changes in a compact\nway, which provides a clear and interpretable picture for locating what and\nwhere the changes are and how to adapt. Based on the environment model, we\ncharacterize a minimal set of representations, including both domain-specific\nfactors and domain-shared state representations, that suffice for reliable and\nlow-cost transfer. Moreover, we show that by explicitly leveraging a compact\nrepresentation to encode changes, we can adapt the policy with only a few\nsamples without further policy optimization in the target domain. We illustrate\nthe efficacy of AdaRL through a series of experiments that allow for changes in\ndifferent components of Cartpole and Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:56:25 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 07:21:38 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Huang", "Biwei", ""], ["Feng", "Fan", ""], ["Lu", "Chaochao", ""], ["Magliacane", "Sara", ""], ["Zhang", "Kun", ""]]}, {"id": "2107.02732", "submitter": "Matt Jordan", "authors": "Matt Jordan, Alexandros G. Dimakis", "title": "Provable Lipschitz Certification for Generative Models", "comments": "Accepted into ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a scalable technique for upper bounding the Lipschitz constant of\ngenerative models. We relate this quantity to the maximal norm over the set of\nattainable vector-Jacobian products of a given generative model. We approximate\nthis set by layerwise convex approximations using zonotopes. Our approach\ngeneralizes and improves upon prior work using zonotope transformers and we\nextend to Lipschitz estimation of neural networks with large output dimension.\nThis provides efficient and tight bounds on small networks and can scale to\ngenerative models on VAE and DCGAN architectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:00:29 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Jordan", "Matt", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "2107.02738", "submitter": "Lee Cohen", "authors": "Lee Cohen, Ulrike Schmidt-Kraepelin, Yishay Mansour", "title": "Dueling Bandits with Team Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the dueling teams problem, a new online-learning setting in\nwhich the learner observes noisy comparisons of disjoint pairs of $k$-sized\nteams from a universe of $n$ players. The goal of the learner is to minimize\nthe number of duels required to identify, with high probability, a Condorcet\nwinning team, i.e., a team which wins against any other disjoint team (with\nprobability at least $1/2$). Noisy comparisons are linked to a total order on\nthe teams. We formalize our model by building upon the dueling bandits setting\n(Yue et al.2012) and provide several algorithms, both for stochastic and\ndeterministic settings. For the stochastic setting, we provide a reduction to\nthe classical dueling bandits setting, yielding an algorithm that identifies a\nCondorcet winning team within $\\mathcal{O}((n + k \\log (k)) \\frac{\\max(\\log\\log\nn, \\log k)}{\\Delta^2})$ duels, where $\\Delta$ is a gap parameter. For\ndeterministic feedback, we additionally present a gap-independent algorithm\nthat identifies a Condorcet winning team within $\\mathcal{O}(nk\\log(k)+k^5)$\nduels.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:12:17 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cohen", "Lee", ""], ["Schmidt-Kraepelin", "Ulrike", ""], ["Mansour", "Yishay", ""]]}, {"id": "2107.02776", "submitter": "Stratis Tsirtsis", "authors": "Stratis Tsirtsis, Abir De, Manuel Gomez-Rodriguez", "title": "Counterfactual Explanations in Sequential Decision Making Under\n  Uncertainty", "comments": "To appear at the ICML 2021 workshop on Interpretable Machine Learning\n  in Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Methods to find counterfactual explanations have predominantly focused on one\nstep decision making processes. In this work, we initiate the development of\nmethods to find counterfactual explanations for decision making processes in\nwhich multiple, dependent actions are taken sequentially over time. We start by\nformally characterizing a sequence of actions and states using finite horizon\nMarkov decision processes and the Gumbel-Max structural causal model. Building\nupon this characterization, we formally state the problem of finding\ncounterfactual explanations for sequential decision making processes. In our\nproblem formulation, the counterfactual explanation specifies an alternative\nsequence of actions differing in at most k actions from the observed sequence\nthat could have led the observed process realization to a better outcome. Then,\nwe introduce a polynomial time algorithm based on dynamic programming to build\na counterfactual policy that is guaranteed to always provide the optimal\ncounterfactual explanation on every possible realization of the counterfactual\nenvironment dynamics. We validate our algorithm using both synthetic and real\ndata from cognitive behavioral therapy and show that the counterfactual\nexplanations our algorithm finds can provide valuable insights to enhance\nsequential decision making under uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:38:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Tsirtsis", "Stratis", ""], ["De", "Abir", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2107.02780", "submitter": "Rahul Singh", "authors": "Anish Agarwal and Rahul Singh", "title": "Causal Inference with Corrupted Data: Measurement Error, Missing Values,\n  Discretization, and Differential Privacy", "comments": "99 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even the most carefully curated economic data sets have variables that are\nnoisy, missing, discretized, or privatized. The standard workflow for empirical\nresearch involves data cleaning followed by data analysis that typically\nignores the bias and variance consequences of data cleaning. We formulate a\nsemiparametric model for causal inference with corrupted data to encompass both\ndata cleaning and data analysis. We propose a new end-to-end procedure for data\ncleaning, estimation, and inference with data cleaning-adjusted confidence\nintervals. We prove root-n consistency, Gaussian approximation, and\nsemiparametric efficiency for our estimator of the causal parameter by finite\nsample arguments. Our key assumption is that the true covariates are\napproximately low rank. In our analysis, we provide nonasymptotic theoretical\ncontributions to matrix completion, statistical learning, and semiparametric\nstatistics. We verify the coverage of the data cleaning-adjusted confidence\nintervals in simulations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:42:49 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Agarwal", "Anish", ""], ["Singh", "Rahul", ""]]}, {"id": "2107.02821", "submitter": "Gregor Kasieczka", "authors": "Gregor Kasieczka, Benjamin Nachman, David Shih", "title": "New Methods and Datasets for Group Anomaly Detection From Fundamental\n  Physics", "comments": "Accepted for ANDEA (Anomaly and Novelty Detection, Explanation and\n  Accommodation) Workshop at KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ex hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of anomalous overdensities in data - group or collective\nanomaly detection - is a rich problem with a large number of real world\napplications. However, it has received relatively little attention in the\nbroader ML community, as compared to point anomalies or other types of single\ninstance outliers. One reason for this is the lack of powerful benchmark\ndatasets. In this paper, we first explain how, after the Nobel-prize winning\ndiscovery of the Higgs boson, unsupervised group anomaly detection has become a\nnew frontier of fundamental physics (where the motivation is to find new\nparticles and forces). Then we propose a realistic synthetic benchmark dataset\n(LHCO2020) for the development of group anomaly detection algorithms. Finally,\nwe compare several existing statistically-sound techniques for unsupervised\ngroup anomaly detection, and demonstrate their performance on the LHCO2020\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 18:00:57 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kasieczka", "Gregor", ""], ["Nachman", "Benjamin", ""], ["Shih", "David", ""]]}, {"id": "2107.02847", "submitter": "Shaohan Chen", "authors": "Shaohan Chen, Nikolaos V. Sahinidis and Chuanhou Gao", "title": "Transfer Learning in Information Criteria-based Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the effectiveness of transfer learning based on\nMallows' Cp. We propose a procedure that combines transfer learning with\nMallows' Cp (TLCp) and prove that it outperforms the conventional Mallows' Cp\ncriterion in terms of accuracy and stability. Our theoretical results indicate\nthat, for any sample size in the target domain, the proposed TLCp estimator\nperforms better than the Cp estimator by the mean squared error (MSE) metric in\nthe case of orthogonal predictors, provided that i) the dissimilarity between\nthe tasks from source domain and target domain is small, and ii) the procedure\nparameters (complexity penalties) are tuned according to certain explicit\nrules. Moreover, we show that our transfer learning framework can be extended\nto other feature selection criteria, such as the Bayesian information\ncriterion. By analyzing the solution of the orthogonalized Cp, we identify an\nestimator that asymptotically approximates the solution of the Cp criterion in\nthe case of non-orthogonal predictors. Similar results are obtained for the\nnon-orthogonal TLCp. Finally, simulation studies and applications with real\ndata demonstrate the usefulness of the TLCp scheme.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 19:12:15 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Chen", "Shaohan", ""], ["Sahinidis", "Nikolaos V.", ""], ["Gao", "Chuanhou", ""]]}, {"id": "2107.02868", "submitter": "Olivia Brown", "authors": "Olivia Brown, Andrew Curtis, Justin Goodwin", "title": "Principles for Evaluation of AI/ML Model Performance and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Department of Defense (DoD) has significantly increased its investment in\nthe design, evaluation, and deployment of Artificial Intelligence and Machine\nLearning (AI/ML) capabilities to address national security needs. While there\nare numerous AI/ML successes in the academic and commercial sectors, many of\nthese systems have also been shown to be brittle and nonrobust. In a complex\nand ever-changing national security environment, it is vital that the DoD\nestablish a sound and methodical process to evaluate the performance and\nrobustness of AI/ML models before these new capabilities are deployed to the\nfield. This paper reviews the AI/ML development process, highlights common best\npractices for AI/ML model evaluation, and makes recommendations to DoD\nevaluators to ensure the deployment of robust AI/ML capabilities for national\nsecurity needs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 19:59:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Brown", "Olivia", ""], ["Curtis", "Andrew", ""], ["Goodwin", "Justin", ""]]}, {"id": "2107.02911", "submitter": "Alkis Gotovos", "authors": "Alkis Gotovos, Rebekka Burkholz, John Quackenbush, and Stefanie\n  Jegelka", "title": "Scaling up Continuous-Time Markov Chains Helps Resolve\n  Underspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling the time evolution of discrete sets of items (e.g., genetic\nmutations) is a fundamental problem in many biomedical applications. We\napproach this problem through the lens of continuous-time Markov chains, and\nshow that the resulting learning task is generally underspecified in the usual\nsetting of cross-sectional data. We explore a perhaps surprising remedy:\nincluding a number of additional independent items can help determine time\norder, and hence resolve underspecification. This is in sharp contrast to the\ncommon practice of limiting the analysis to a small subset of relevant items,\nwhich is followed largely due to poor scaling of existing methods. To put our\ntheoretical insight into practice, we develop an approximate likelihood\nmaximization method for learning continuous-time Markov chains, which can scale\nto hundreds of items and is orders of magnitude faster than previous methods.\nWe demonstrate the effectiveness of our approach on synthetic and real cancer\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 21:14:49 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Gotovos", "Alkis", ""], ["Burkholz", "Rebekka", ""], ["Quackenbush", "John", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "2107.02926", "submitter": "Deep Ray", "authors": "Dhruv V Patel, Deep Ray, Assad A Oberai", "title": "Solution of Physics-based Bayesian Inverse Problems with Deep Generative\n  Priors", "comments": "Paper: 18 pages, 5 figures. Supplementary: 9 pages, 6 Figures, 2\n  Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inverse problems are notoriously difficult to solve because they can have no\nsolutions, multiple solutions, or have solutions that vary significantly in\nresponse to small perturbations in measurements. Bayesian inference, which\nposes an inverse problem as a stochastic inference problem, addresses these\ndifficulties and provides quantitative estimates of the inferred field and the\nassociated uncertainty. However, it is difficult to employ when inferring\nvectors of large dimensions, and/or when prior information is available through\npreviously acquired samples. In this paper, we describe how deep generative\nadversarial networks can be used to represent the prior distribution in\nBayesian inference and overcome these challenges. We apply these ideas to\ninverse problems that are diverse in terms of the governing physical\nprinciples, sources of prior knowledge, type of measurement, and the extent of\navailable information about measurement noise. In each case we apply the\nproposed approach to infer the most likely solution and quantitative estimates\nof uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 22:23:27 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Patel", "Dhruv V", ""], ["Ray", "Deep", ""], ["Oberai", "Assad A", ""]]}, {"id": "2107.02951", "submitter": "Anish Sevekari", "authors": "Holden Lee, Chirag Pabbaraju, Anish Sevekari, Andrej Risteski", "title": "Universal Approximation for Log-concave Distributions using\n  Well-conditioned Normalizing Flows", "comments": "40 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are a widely used class of latent-variable generative\nmodels with a tractable likelihood. Affine-coupling (Dinh et al, 2014-16)\nmodels are a particularly common type of normalizing flows, for which the\nJacobian of the latent-to-observable-variable transformation is triangular,\nallowing the likelihood to be computed in linear time. Despite the widespread\nusage of affine couplings, the special structure of the architecture makes\nunderstanding their representational power challenging. The question of\nuniversal approximation was only recently resolved by three parallel papers\n(Huang et al.,2020;Zhang et al.,2020;Koehler et al.,2020) -- who showed\nreasonably regular distributions can be approximated arbitrarily well using\naffine couplings -- albeit with networks with a nearly-singular Jacobian. As\nill-conditioned Jacobians are an obstacle for likelihood-based training, the\nfundamental question remains: which distributions can be approximated using\nwell-conditioned affine coupling flows?\n  In this paper, we show that any log-concave distribution can be approximated\nusing well-conditioned affine-coupling flows. In terms of proof techniques, we\nuncover and leverage deep connections between affine coupling architectures,\nunderdamped Langevin dynamics (a stochastic differential equation often used to\nsample from Gibbs measures) and H\\'enon maps (a structured dynamical system\nthat appears in the study of symplectic diffeomorphisms). Our results also\ninform the practice of training affine couplings: we approximate a padded\nversion of the input distribution with iid Gaussians -- a strategy which\nKoehler et al.(2020) empirically observed to result in better-conditioned\nflows, but had hitherto no theoretical grounding. Our proof can thus be seen as\nproviding theoretical evidence for the benefits of Gaussian padding when\ntraining normalizing flows.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 00:13:50 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Lee", "Holden", ""], ["Pabbaraju", "Chirag", ""], ["Sevekari", "Anish", ""], ["Risteski", "Andrej", ""]]}, {"id": "2107.02990", "submitter": "Vathy Kamulete", "authors": "Vathy M. Kamulete", "title": "Test for non-negligible adverse shifts", "comments": "14 pages, 4 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical tests for dataset shift are susceptible to false alarms: they are\nsensitive to minor differences where there is in fact adequate sample coverage\nand predictive performance. We propose instead a robust framework for tests of\ndataset shift based on outlier scores, D-SOS for short. D-SOS detects adverse\nshifts and can identify false alarms caused by benign ones. It posits that a\nnew (test) sample is not substantively worse than an old (training) sample, and\nnot that the two are equal. The key idea is to reduce observations to outlier\nscores and compare contamination rates. Beyond comparing distributions, users\ncan define what worse means in terms of predictive performance and other\nrelevant notions. We show how versatile and practical D-SOS is for a wide range\nof real and simulated datasets. Unlike tests of equal distribution and of\ngoodness-of-fit, the D-SOS tests are uniquely tailored to serve as robust\nperformance metrics to monitor model drift and dataset shift.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:07:40 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kamulete", "Vathy M.", ""]]}, {"id": "2107.03003", "submitter": "Kai Wang", "authors": "Kai Wang, Bryan Wilder, Sze-chuan Suen, Bistra Dilkina, Milind Tambe", "title": "Harnessing Heterogeneity: Learning from Decomposed Feedback in Bayesian\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is significant interest in learning and optimizing a complex system\ncomposed of multiple sub-components, where these components may be agents or\nautonomous sensors. Among the rich literature on this topic, agent-based and\ndomain-specific simulations can capture complex dynamics and subgroup\ninteraction, but optimizing over such simulations can be computationally and\nalgorithmically challenging. Bayesian approaches, such as Gaussian processes\n(GPs), can be used to learn a computationally tractable approximation to the\nunderlying dynamics but typically neglect the detailed information about\nsubgroups in the complicated system. We attempt to find the best of both worlds\nby proposing the idea of decomposed feedback, which captures group-based\nheterogeneity and dynamics. We introduce a novel decomposed GP regression to\nincorporate the subgroup decomposed feedback. Our modified regression has\nprovably lower variance -- and thus a more accurate posterior -- compared to\nprevious approaches; it also allows us to introduce a decomposed GP-UCB\noptimization algorithm that leverages subgroup feedback. The Bayesian nature of\nour method makes the optimization algorithm trackable with a theoretical\nguarantee on convergence and no-regret property. To demonstrate the wide\napplicability of this work, we execute our algorithm on two disparate social\nproblems: infectious disease control in a heterogeneous population and\nallocation of distributed weather sensors. Experimental results show that our\nnew method provides significant improvement compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:57:22 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Kai", ""], ["Wilder", "Bryan", ""], ["Suen", "Sze-chuan", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "2107.03018", "submitter": "Shouta Sugahara", "authors": "Shouta Sugahara and Maomi Ueno", "title": "Exact Learning Augmented Naive Bayes Classifier", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier studies have shown that classification accuracies of Bayesian\nnetworks (BNs) obtained by maximizing the conditional log likelihood (CLL) of a\nclass variable, given the feature variables, were higher than those obtained by\nmaximizing the marginal likelihood (ML). However, differences between the\nperformances of the two scores in the earlier studies may be attributed to the\nfact that they used approximate learning algorithms, not exact ones. This paper\ncompares the classification accuracies of BNs with approximate learning using\nCLL to those with exact learning using ML. The results demonstrate that the\nclassification accuracies of BNs obtained by maximizing the ML are higher than\nthose obtained by maximizing the CLL for large data. However, the results also\ndemonstrate that the classification accuracies of exact learning BNs using the\nML are much worse than those of other methods when the sample size is small and\nthe class variable has numerous parents. To resolve the problem, we propose an\nexact learning augmented naive Bayes classifier (ANB), which ensures a class\nvariable with no parents. The proposed method is guaranteed to asymptotically\nestimate the identical class posterior to that of the exactly learned BN.\nComparison experiments demonstrated the superior performance of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 05:03:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sugahara", "Shouta", ""], ["Ueno", "Maomi", ""]]}, {"id": "2107.03066", "submitter": "Mamikon Gulian", "authors": "Nat Trask, Mamikon Gulian, Andy Huang, Kookjin Lee", "title": "Probabilistic partition of unity networks: clustering based deep\n  approximation", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partition of unity networks (POU-Nets) have been shown capable of realizing\nalgebraic convergence rates for regression and solution of PDEs, but require\nempirical tuning of training parameters. We enrich POU-Nets with a Gaussian\nnoise model to obtain a probabilistic generalization amenable to gradient-based\nminimization of a maximum likelihood loss. The resulting architecture provides\nspatial representations of both noiseless and noisy data as Gaussian mixtures\nwith closed form expressions for variance which provides an estimator of local\nerror. The training process yields remarkably sharp partitions of input space\nbased upon correlation of function values. This classification of training\npoints is amenable to a hierarchical refinement strategy that significantly\nimproves the localization of the regression, allowing for higher-order\npolynomial approximation to be utilized. The framework scales more favorably to\nlarge data sets as compared to Gaussian process regression and allows for\nspatially varying uncertainty, leveraging the expressive power of deep neural\nnetworks while bypassing expensive training associated with other probabilistic\ndeep learning methods. Compared to standard deep neural networks, the framework\ndemonstrates hp-convergence without the use of regularizers to tune the\nlocalization of partitions. We provide benchmarks quantifying performance in\nhigh/low-dimensions, demonstrating that convergence rates depend only on the\nlatent dimension of data within high-dimensional space. Finally, we introduce a\nnew open-source data set of PDE-based simulations of a semiconductor device and\nperform unsupervised extraction of a physically interpretable reduced-order\nbasis.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:02:00 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Trask", "Nat", ""], ["Gulian", "Mamikon", ""], ["Huang", "Andy", ""], ["Lee", "Kookjin", ""]]}, {"id": "2107.03144", "submitter": "Parnian Kassraie", "authors": "Parnian Kassraie, Andreas Krause", "title": "Neural Contextual Bandits without Regret", "comments": "37 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Contextual bandits are a rich model for sequential decision making given side\ninformation, with important applications, e.g., in recommender systems. We\npropose novel algorithms for contextual bandits harnessing neural networks to\napproximate the unknown reward function. We resolve the open problem of proving\nsublinear regret bounds in this setting for general context sequences,\nconsidering both fully-connected and convolutional networks. To this end, we\nfirst analyze NTK-UCB, a kernelized bandit optimization algorithm employing the\nNeural Tangent Kernel (NTK), and bound its regret in terms of the NTK maximum\ninformation gain $\\gamma_T$, a complexity parameter capturing the difficulty of\nlearning. Our bounds on $\\gamma_T$ for the NTK may be of independent interest.\nWe then introduce our neural network based algorithm NN-UCB, and show that its\nregret closely tracks that of NTK-UCB. Under broad non-parametric assumptions\nabout the reward function, our approach converges to the optimal policy at a\n$\\tilde{\\mathcal{O}}(T^{-1/2d})$ rate, where $d$ is the dimension of the\ncontext.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 11:11:34 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kassraie", "Parnian", ""], ["Krause", "Andreas", ""]]}, {"id": "2107.03183", "submitter": "Kaspar Thommen", "authors": "Kaspar Thommen", "title": "A Closed-Form Approximation to the Conjugate Prior of the Dirichlet and\n  Beta Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the conjugate prior of the Dirichlet and beta distributions and\nexplore it with numerical examples to gain an intuitive understanding of the\ndistribution itself, its hyperparameters, and conditions concerning its\nconvergence. Due to the prior's intractability, we proceed to define and\nanalyze a closed-form approximation. Finally, we provide an algorithm\nimplementing this approximation that enables fully tractable Bayesian conjugate\ntreatment of Dirichlet and beta likelihoods without the need for Monte Carlo\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:32:29 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Thommen", "Kaspar", ""]]}, {"id": "2107.03186", "submitter": "Todor Davchev", "authors": "Todor Davchev, Sarah Bechtle, Subramanian Ramamoorthy, Franziska Meier", "title": "Learning Time-Invariant Reward Functions through Model-Based Inverse\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning is a paradigm motivated by the goal of\nlearning general reward functions from demonstrated behaviours. Yet the notion\nof generality for learnt costs is often evaluated in terms of robustness to\nvarious spatial perturbations only, assuming deployment at fixed speeds of\nexecution. However, this is impractical in the context of robotics and building\ntime-invariant solutions is of crucial importance. In this work, we propose a\nformulation that allows us to 1) vary the length of execution by learning\ntime-invariant costs, and 2) relax the temporal alignment requirements for\nlearning from demonstration. We apply our method to two different types of cost\nformulations and evaluate their performance in the context of learning reward\nfunctions for simulated placement and peg in hole tasks. Our results show that\nour approach enables learning temporally invariant rewards from misaligned\ndemonstration that can also generalise spatially to out of distribution tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:44:09 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Davchev", "Todor", ""], ["Bechtle", "Sarah", ""], ["Ramamoorthy", "Subramanian", ""], ["Meier", "Franziska", ""]]}, {"id": "2107.03217", "submitter": "Songhao Wang", "authors": "Qun Meng, Songhao Wang, Szu Hui Ng", "title": "Combined Global and Local Search for Optimization with Gaussian Process\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Gaussian process (GP) model based optimization is widely applied in\nsimulation and machine learning. In general, it first estimates a GP model\nbased on a few observations from the true response and then employs this model\nto guide the search, aiming to quickly locate the global optimum. Despite its\nsuccessful applications, it has several limitations that may hinder its broader\nusage. First, building an accurate GP model can be difficult and\ncomputationally expensive, especially when the response function is multi-modal\nor varies significantly over the design space. Second, even with an appropriate\nmodel, the search process can be trapped in suboptimal regions before moving to\nthe global optimum due to the excessive effort spent around the current best\nsolution. In this work, we adopt the Additive Global and Local GP (AGLGP) model\nin the optimization framework. The model is rooted in the inducing-points-based\nGP sparse approximations and is combined with independent local models in\ndifferent regions. With these properties, the AGLGP model is suitable for\nmulti-modal responses with relatively large data sizes. Based on this AGLGP\nmodel, we propose a Combined Global and Local search for Optimization (CGLO)\nalgorithm. It first divides the whole design space into disjoint local regions\nand identifies a promising region with the global model. Next, a local model in\nthe selected region is fit to guide detailed search within this region. The\nalgorithm then switches back to the global step when a good local solution is\nfound. The global and local natures of CGLO enable it to enjoy the benefits of\nboth global and local search to efficiently locate the global optimum.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:40:37 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Meng", "Qun", ""], ["Wang", "Songhao", ""], ["Ng", "Szu Hui", ""]]}, {"id": "2107.03230", "submitter": "Luka Grb\\v{c}i\\'c", "authors": "Luka Grb\\v{c}i\\'c, Sini\\v{s}a Dru\\v{z}eta, Goran Mau\\v{s}a, Tomislav\n  Lipi\\'c, Darija Vuki\\'c Lu\\v{s}i\\'c, Marta Alvir, Ivana Lu\\v{c}in, Ante\n  Sikirica, Davor Davidovi\\'c, Vanja Trava\\v{s}, Daniela Kalafatovi\\'c,\n  Kristina Pikelj, Hana Fajkovi\\'c, Toni Holjevi\\'c and Lado Kranj\\v{c}evi\\'c", "title": "Coastal water quality prediction based on machine learning with feature\n  interpretation and spatio-temporal analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Coastal water quality management is a public health concern, as poor coastal\nwater quality can harbor pathogens that are dangerous to human health.\nTourism-oriented countries need to actively monitor the condition of coastal\nwater at tourist popular sites during the summer season. In this study, routine\nmonitoring data of $Escherichia\\ Coli$ and enterococci across 15 public beaches\nin the city of Rijeka, Croatia, were used to build machine learning models for\npredicting their levels based on environmental parameters as well as to\ninvestigate their relationships with environmental stressors. Gradient Boosting\n(Catboost, Xgboost), Random Forests, Support Vector Regression and Artificial\nNeural Networks were trained with measurements from all sampling sites and used\nto predict $E.\\ Coli$ and enterococci values based on environmental features.\nThe evaluation of stability and generalizability with 10-fold cross validation\nanalysis of the machine learning models, showed that the Catboost algorithm\nperformed best with R$^2$ values of 0.71 and 0.68 for predicting $E.\\ Coli$ and\nenterococci, respectively, compared to other evaluated ML algorithms including\nXgboost, Random Forests, Support Vector Regression and Artificial Neural\nNetworks. We also use the SHapley Additive exPlanations technique to identify\nand interpret which features have the most predictive power. The results show\nthat site salinity measured is the most important feature for forecasting both\n$E.\\ Coli$ and enterococci levels. Finally, the spatial and temporal accuracy\nof both ML models were examined at sites with the lowest coastal water quality.\nThe spatial $E. Coli$ and enterococci models achieved strong R$^2$ values of\n0.85 and 0.83, while the temporal models achieved R$^2$ values of 0.74 and\n0.67. The temporal model also achieved moderate R$^2$ values of 0.44 and 0.46\nat a site with high coastal water quality.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:00:14 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 07:09:03 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Grb\u010di\u0107", "Luka", ""], ["Dru\u017eeta", "Sini\u0161a", ""], ["Mau\u0161a", "Goran", ""], ["Lipi\u0107", "Tomislav", ""], ["Lu\u0161i\u0107", "Darija Vuki\u0107", ""], ["Alvir", "Marta", ""], ["Lu\u010din", "Ivana", ""], ["Sikirica", "Ante", ""], ["Davidovi\u0107", "Davor", ""], ["Trava\u0161", "Vanja", ""], ["Kalafatovi\u0107", "Daniela", ""], ["Pikelj", "Kristina", ""], ["Fajkovi\u0107", "Hana", ""], ["Holjevi\u0107", "Toni", ""], ["Kranj\u010devi\u0107", "Lado", ""]]}, {"id": "2107.03280", "submitter": "David Zhao", "authors": "Benjamin LeRoy and David Zhao", "title": "MD-split+: Practical Local Conformal Inference in High Dimensions", "comments": "Appearing in ICML 2021 workshop on distribution-free uncertainty\n  quantification", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantifying uncertainty in model predictions is a common goal for\npractitioners seeking more than just point predictions. One tool for\nuncertainty quantification that requires minimal assumptions is conformal\ninference, which can help create probabilistically valid prediction regions for\nblack box models. Classical conformal prediction only provides marginal\nvalidity, whereas in many situations locally valid prediction regions are\ndesirable. Deciding how best to partition the feature space X when applying\nlocalized conformal prediction is still an open question. We present MD-split+,\na practical local conformal approach that creates X partitions based on\nlocalized model performance of conditional density estimation models. Our\nmethod handles complex real-world data settings where such models may be\nmisspecified, and scales to high-dimensional inputs. We discuss how our local\npartitions philosophically align with expected behavior from an unattainable\nconditional conformal inference approach. We also empirically compare our\nmethod against other local conformal approaches.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:19:16 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["LeRoy", "Benjamin", ""], ["Zhao", "David", ""]]}, {"id": "2107.03313", "submitter": "Fabio Valerio Massoli", "authors": "Fabio Valerio Massoli, Lucia Vadicamo, Giuseppe Amato, Fabrizio Falchi", "title": "A Leap among Entanglement and Neural Networks: A Quantum Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, Quantum Computing witnessed massive improvements both in\nterms of resources availability and algorithms development. The ability to\nharness quantum phenomena to solve computational problems is a long-standing\ndream that has drawn the scientific community's interest since the late '80s.\nIn such a context, we pose our contribution. First, we introduce basic concepts\nrelated to quantum computations, and then we explain the core functionalities\nof technologies that implement the Gate Model and Adiabatic Quantum Computing\nparadigms. Finally, we gather, compare and analyze the current state-of-the-art\nconcerning Quantum Perceptrons and Quantum Neural Networks implementations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:08:07 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Massoli", "Fabio Valerio", ""], ["Vadicamo", "Lucia", ""], ["Amato", "Giuseppe", ""], ["Falchi", "Fabrizio", ""]]}, {"id": "2107.03315", "submitter": "Devin Guillory", "authors": "Devin Guillory, Vaishaal Shankar, Sayna Ebrahimi, Trevor Darrell,\n  Ludwig Schmidt", "title": "Predicting with Confidence on Unseen Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has shown that the performance of machine learning models can\nvary substantially when models are evaluated on data drawn from a distribution\nthat is close to but different from the training distribution. As a result,\npredicting model performance on unseen distributions is an important challenge.\nOur work connects techniques from domain adaptation and predictive uncertainty\nliterature, and allows us to predict model accuracy on challenging unseen\ndistributions without access to labeled data. In the context of distribution\nshift, distributional distances are often used to adapt models and improve\ntheir performance on new domains, however accuracy estimation, or other forms\nof predictive uncertainty, are often neglected in these investigations. Through\ninvestigating a wide range of established distributional distances, such as\nFrechet distance or Maximum Mean Discrepancy, we determine that they fail to\ninduce reliable estimates of performance under distribution shift. On the other\nhand, we find that the difference of confidences (DoC) of a classifier's\npredictions successfully estimates the classifier's performance change over a\nvariety of shifts. We specifically investigate the distinction between\nsynthetic and natural distribution shifts and observe that despite its\nsimplicity DoC consistently outperforms other quantifications of distributional\ndifference. $DoC$ reduces predictive error by almost half ($46\\%$) on several\nrealistic and challenging distribution shifts, e.g., on the ImageNet-Vid-Robust\nand ImageNet-Rendition datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:50:18 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Guillory", "Devin", ""], ["Shankar", "Vaishaal", ""], ["Ebrahimi", "Sayna", ""], ["Darrell", "Trevor", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "2107.03317", "submitter": "Benoit Fuentes Dr.", "authors": "Benoit Fuentes, Ga\\\"el Richard", "title": "Probabilistic semi-nonnegative matrix factorization: a Skellam-based\n  framework", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a new probabilistic model to address semi-nonnegative matrix\nfactorization (SNMF), called Skellam-SNMF. It is a hierarchical generative\nmodel consisting of prior components, Skellam-distributed hidden variables and\nobserved data. Two inference algorithms are derived: Expectation-Maximization\n(EM) algorithm for maximum \\emph{a posteriori} estimation and Variational Bayes\nEM (VBEM) for full Bayesian inference, including the estimation of parameters\nprior distribution. From this Skellam-based model, we also introduce a new\ndivergence $\\mathcal{D}$ between a real-valued target data $x$ and two\nnonnegative parameters $\\lambda_{0}$ and $\\lambda_{1}$ such that\n$\\mathcal{D}\\left(x\\mid\\lambda_{0},\\lambda_{1}\\right)=0\\Leftrightarrow\nx=\\lambda_{0}-\\lambda_{1}$, which is a generalization of the Kullback-Leibler\n(KL) divergence. Finally, we conduct experimental studies on those new\nalgorithms in order to understand their behavior and prove that they can\noutperform the classic SNMF approach on real data in a task of automatic\nclustering.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:56:22 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Fuentes", "Benoit", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "2107.03322", "submitter": "Yunzhang Zhu", "authors": "Yunzhang Zhu and Renxiong Liu", "title": "An algorithmic view of $\\ell_2$ regularization and some path-following\n  algorithms", "comments": "62 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish an equivalence between the $\\ell_2$-regularized solution path\nfor a convex loss function, and the solution of an ordinary differentiable\nequation (ODE). Importantly, this equivalence reveals that the solution path\ncan be viewed as the flow of a hybrid of gradient descent and Newton method\napplying to the empirical loss, which is similar to a widely used optimization\ntechnique called trust region method. This provides an interesting algorithmic\nview of $\\ell_2$ regularization, and is in contrast to the conventional view\nthat the $\\ell_2$ regularization solution path is similar to the gradient flow\nof the empirical loss.New path-following algorithms based on homotopy methods\nand numerical ODE solvers are proposed to numerically approximate the solution\npath. In particular, we consider respectively Newton method and gradient\ndescent method as the basis algorithm for the homotopy method, and establish\ntheir approximation error rates over the solution path. Importantly, our theory\nsuggests novel schemes to choose grid points that guarantee an arbitrarily\nsmall suboptimality for the solution path. In terms of computational cost, we\nprove that in order to achieve an $\\epsilon$-suboptimality for the entire\nsolution path, the number of Newton steps required for the Newton method is\n$\\mathcal O(\\epsilon^{-1/2})$, while the number of gradient steps required for\nthe gradient descent method is $\\mathcal O\\left(\\epsilon^{-1}\n\\ln(\\epsilon^{-1})\\right)$. Finally, we use $\\ell_2$-regularized logistic\nregression as an illustrating example to demonstrate the effectiveness of the\nproposed path-following algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:00:13 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhu", "Yunzhang", ""], ["Liu", "Renxiong", ""]]}, {"id": "2107.03325", "submitter": "David Kepplinger", "authors": "David Kepplinger", "title": "Robust Variable Selection and Estimation Via Adaptive Elastic Net\n  S-Estimators for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heavy-tailed error distributions and predictors with anomalous values are\nubiquitous in high-dimensional regression problems and can seriously jeopardize\nthe validity of statistical analyses if not properly addressed. For more\nreliable estimation under these adverse conditions, we propose a new robust\nregularized estimator for simultaneous variable selection and coefficient\nestimation. This estimator, called adaptive PENSE, possesses the oracle\nproperty without prior knowledge of the scale of the residuals and without any\nmoment conditions on the error distribution. The proposed estimator gives\nreliable results even under very heavy-tailed error distributions and aberrant\ncontamination in the predictors or residuals. Importantly, even in these\nchallenging settings variable selection by adaptive PENSE remains stable.\nNumerical studies on simulated and real data sets highlight superior\nfinite-sample performance in a vast range of settings compared to other robust\nregularized estimators in the case of contaminated samples and competitiveness\ncompared to classical regularized estimators in clean samples.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:04:08 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 15:52:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kepplinger", "David", ""]]}, {"id": "2107.03331", "submitter": "Aram Davtyan", "authors": "Aram Davtyan, Sepehr Sameni, Llukman Cerkezi, Givi Meishvilli, Adam\n  Bielski, Paolo Favaro", "title": "KaFiStO: A Kalman Filtering Framework for Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is often cast as a deterministic problem, where the solution is\nfound through some iterative procedure such as gradient descent. However, when\ntraining neural networks the loss function changes over (iteration) time due to\nthe randomized selection of a subset of the samples. This randomization turns\nthe optimization problem into a stochastic one. We propose to consider the loss\nas a noisy observation with respect to some reference optimum. This\ninterpretation of the loss allows us to adopt Kalman filtering as an optimizer,\nas its recursive formulation is designed to estimate unknown parameters from\nnoisy measurements. Moreover, we show that the Kalman Filter dynamical model\nfor the evolution of the unknown parameters can be used to capture the gradient\ndynamics of advanced methods such as Momentum and Adam. We call this stochastic\noptimization method KaFiStO. KaFiStO is an easy to implement, scalable, and\nefficient method to train neural networks. We show that it also yields\nparameter estimates that are on par with or better than existing optimization\nalgorithms across several neural network architectures and machine learning\ntasks, such as computer vision and language modeling.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:13:57 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Davtyan", "Aram", ""], ["Sameni", "Sepehr", ""], ["Cerkezi", "Llukman", ""], ["Meishvilli", "Givi", ""], ["Bielski", "Adam", ""], ["Favaro", "Paolo", ""]]}, {"id": "2107.03342", "submitter": "Jakob Gawlikowski", "authors": "Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali,\n  Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel,\n  Peter Jung, Ribana Roscher, Muhammad Shahzad, Wen Yang, Richard Bamler, Xiao\n  Xiang Zhu", "title": "A Survey of Uncertainty in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to their increasing spread, confidence in neural network predictions\nbecame more and more important. However, basic neural networks do not deliver\ncertainty estimates or suffer from over or under confidence. Many researchers\nhave been working on understanding and quantifying uncertainty in a neural\nnetwork's prediction. As a result, different types and sources of uncertainty\nhave been identified and a variety of approaches to measure and quantify\nuncertainty in neural networks have been proposed. This work gives a\ncomprehensive overview of uncertainty estimation in neural networks, reviews\nrecent advances in the field, highlights current challenges, and identifies\npotential research opportunities. It is intended to give anyone interested in\nuncertainty estimation in neural networks a broad overview and introduction,\nwithout presupposing prior knowledge in this field. A comprehensive\nintroduction to the most crucial sources of uncertainty is given and their\nseparation into reducible model uncertainty and not reducible data uncertainty\nis presented. The modeling of these uncertainties based on deterministic neural\nnetworks, Bayesian neural networks, ensemble of neural networks, and test-time\ndata augmentation approaches is introduced and different branches of these\nfields as well as the latest developments are discussed. For a practical\napplication, we discuss different measures of uncertainty, approaches for the\ncalibration of neural networks and give an overview of existing baselines and\nimplementations. Different examples from the wide spectrum of challenges in\ndifferent fields give an idea of the needs and challenges regarding\nuncertainties in practical applications. Additionally, the practical\nlimitations of current methods for mission- and safety-critical real world\napplications are discussed and an outlook on the next steps towards a broader\nusage of such methods is given.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:39:28 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Gawlikowski", "Jakob", ""], ["Tassi", "Cedrique Rovile Njieutcheu", ""], ["Ali", "Mohsin", ""], ["Lee", "Jongseok", ""], ["Humt", "Matthias", ""], ["Feng", "Jianxiang", ""], ["Kruspe", "Anna", ""], ["Triebel", "Rudolph", ""], ["Jung", "Peter", ""], ["Roscher", "Ribana", ""], ["Shahzad", "Muhammad", ""], ["Yang", "Wen", ""], ["Bamler", "Richard", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "2107.03354", "submitter": "Tianbo Li", "authors": "Tianbo Li, Tianze Luo, Yiping Ke, Sinno Jialin Pan", "title": "Mitigating Performance Saturation in Neural Marked Point Processes:\n  Architectures and Loss Functions", "comments": "9 pages, 4 figures, accepted by KDD-21 research track. The source\n  code is available at https://github.com/ltz0120/Graph-Convolutional-\n  Hawkes-Processes-GCHP", "journal-ref": null, "doi": "10.1145/3447548.3467436", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attributed event sequences are commonly encountered in practice. A recent\nresearch line focuses on incorporating neural networks with the statistical\nmodel -- marked point processes, which is the conventional tool for dealing\nwith attributed event sequences. Neural marked point processes possess good\ninterpretability of probabilistic models as well as the representational power\nof neural networks. However, we find that performance of neural marked point\nprocesses is not always increasing as the network architecture becomes more\ncomplicated and larger, which is what we call the performance saturation\nphenomenon. This is due to the fact that the generalization error of neural\nmarked point processes is determined by both the network representational\nability and the model specification at the same time. Therefore we can draw two\nmajor conclusions: first, simple network structures can perform no worse than\ncomplicated ones for some cases; second, using a proper probabilistic\nassumption is as equally, if not more, important as improving the complexity of\nthe network. Based on this observation, we propose a simple graph-based network\nstructure called GCHP, which utilizes only graph convolutional layers, thus it\ncan be easily accelerated by the parallel mechanism. We directly consider the\ndistribution of interarrival times instead of imposing a specific assumption on\nthe conditional intensity function, and propose to use a likelihood ratio loss\nwith a moment matching mechanism for optimization and model selection.\nExperimental results show that GCHP can significantly reduce training time and\nthe likelihood ratio loss with interarrival time probability assumptions can\ngreatly improve the model performance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:59:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Li", "Tianbo", ""], ["Luo", "Tianze", ""], ["Ke", "Yiping", ""], ["Pan", "Sinno Jialin", ""]]}, {"id": "2107.03375", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo and Yang Gao", "title": "Differentiable Architecture Pruning for Transfer Learning", "comments": "19 pages (main + appendix), 7 figures and 1 table, Workshop @ ICML\n  2021, 24th July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new gradient-based approach for extracting sub-architectures\nfrom a given large model. Contrarily to existing pruning methods, which are\nunable to disentangle the network architecture and the corresponding weights,\nour architecture-pruning scheme produces transferable new structures that can\nbe successfully retrained to solve different tasks. We focus on a\ntransfer-learning setup where architectures can be trained on a large data set\nbut very few data points are available for fine-tuning them on new tasks. We\ndefine a new gradient-based algorithm that trains architectures of arbitrarily\nlow complexity independently from the attached weights. Given a search space\ndefined by an existing large neural model, we reformulate the architecture\nsearch task as a complexity-penalized subset-selection problem and solve it\nthrough a two-temperature relaxation scheme. We provide theoretical convergence\nguarantees and validate the proposed transfer-learning strategy on real data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 17:44:59 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Colombo", "Nicolo", ""], ["Gao", "Yang", ""]]}, {"id": "2107.03433", "submitter": "Matei Moldoveanu", "authors": "Matei Moldoveanu, Abdellatif Zaidi", "title": "In-Network Learning: Distributed Training and Inference in Networks", "comments": "Submitted to the IEEE Journal on Selected Areas in Communications\n  (JSAC) Series on Machine Learning for Communications and Networks. arXiv\n  admin note: substantial text overlap with arXiv:2104.14929", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely perceived that leveraging the success of modern machine learning\ntechniques to mobile devices and wireless networks has the potential of\nenabling important new services. This, however, poses significant challenges,\nessentially due to that both data and processing power are highly distributed\nin a wireless network. In this paper, we develop a learning algorithm and an\narchitecture that make use of multiple data streams and processing units, not\nonly during the training phase but also during the inference phase. In\nparticular, the analysis reveals how inference propagates and fuses across a\nnetwork. We study the design criterion of our proposed method and its bandwidth\nrequirements. Also, we discuss implementation aspects using neural networks in\ntypical wireless radio access; and provide experiments that illustrate benefits\nover state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:35:08 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Moldoveanu", "Matei", ""], ["Zaidi", "Abdellatif", ""]]}, {"id": "2107.03455", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh, Abishek Sankararaman and Kannan Ramchandran", "title": "Model Selection for Generic Contextual Bandits", "comments": "40 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:2006.02612", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of model selection for the general stochastic\ncontextual bandits under the realizability assumption. We propose a successive\nrefinement based algorithm called Adaptive Contextual Bandit ({\\ttfamily ACB}),\nthat works in phases and successively eliminates model classes that are too\nsimple to fit the given instance. We prove that this algorithm is adaptive,\ni.e., the regret rate order-wise matches that of {\\ttfamily FALCON}, the\nstate-of-art contextual bandit algorithm of Levi et. al '20, that needs\nknowledge of the true model class. The price of not knowing the correct model\nclass is only an additive term contributing to the second order term in the\nregret bound. This cost possess the intuitive property that it becomes smaller\nas the model class becomes easier to identify, and vice-versa. We then show\nthat a much simpler explore-then-commit (ETC) style algorithm also obtains a\nregret rate of matching that of {\\ttfamily FALCON}, despite not knowing the\ntrue model class. However, the cost of model selection is higher in ETC as\nopposed to in {\\ttfamily ACB}, as expected. Furthermore, {\\ttfamily ACB}\napplied to the linear bandit setting with unknown sparsity, order-wise recovers\nthe model selection guarantees previously established by algorithms tailored to\nthe linear setting.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 19:35:31 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ghosh", "Avishek", ""], ["Sankararaman", "Abishek", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2107.03483", "submitter": "Shai Ben-David", "authors": "Tosca Lechner, Shai Ben-David, Sushant Agarwal and Nivasini\n  Ananthakrishnan", "title": "Impossibility results for fair representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing awareness to fairness in machine learning and the\nrealization of the central role that data representation has in data processing\ntasks, there is an obvious interest in notions of fair data representations.\nThe goal of such representations is that a model trained on data under the\nrepresentation (e.g., a classifier) will be guaranteed to respect some fairness\nconstraints.\n  Such representations are useful when they can be fixed for training models on\nvarious different tasks and also when they serve as data filtering between the\nraw data (known to the representation designer) and potentially malicious\nagents that use the data under the representation to learn predictive models\nand make decisions.\n  A long list of recent research papers strive to provide tools for achieving\nthese goals.\n  However, we prove that this is basically a futile effort. Roughly stated, we\nprove that no representation can guarantee the fairness of classifiers for\ndifferent tasks trained using it; even the basic goal of achieving\nlabel-independent Demographic Parity fairness fails once the marginal data\ndistribution shifts. More refined notions of fairness, like Odds Equality,\ncannot be guaranteed by a representation that does not take into account the\ntask specific labeling rule with respect to which such fairness will be\nevaluated (even if the marginal data distribution is known a priory).\nFurthermore, except for trivial cases, no representation can guarantee Odds\nEquality fairness for any two different tasks, while allowing accurate label\npredictions for both.\n  While some of our conclusions are intuitive, we formulate (and prove) crisp\nstatements of such impossibilities, often contrasting impressions conveyed by\nmany recent works on fair representations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 21:12:55 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lechner", "Tosca", ""], ["Ben-David", "Shai", ""], ["Agarwal", "Sushant", ""], ["Ananthakrishnan", "Nivasini", ""]]}, {"id": "2107.03502", "submitter": "Yusuke Tashiro", "authors": "Yusuke Tashiro, Jiaming Song, Yang Song, Stefano Ermon", "title": "CSDI: Conditional Score-based Diffusion Models for Probabilistic Time\n  Series Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The imputation of missing values in time series has many applications in\nhealthcare and finance. While autoregressive models are natural candidates for\ntime series imputation, score-based diffusion models have recently outperformed\nexisting counterparts including autoregressive models in many tasks such as\nimage generation and audio synthesis, and would be promising for time series\nimputation. In this paper, we propose Conditional Score-based Diffusion models\nfor Imputation (CSDI), a novel time series imputation method that utilizes\nscore-based diffusion models conditioned on observed data. Unlike existing\nscore-based approaches, the conditional diffusion model is explicitly trained\nfor imputation and can exploit correlations between observed values. On\nhealthcare and environmental data, CSDI improves by 40-70% over existing\nprobabilistic imputation methods on popular performance metrics. In addition,\ndeterministic imputation by CSDI reduces the error by 5-20% compared to the\nstate-of-the-art deterministic imputation methods. Furthermore, CSDI can also\nbe applied to time series interpolation and probabilistic forecasting, and is\ncompetitive with existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 22:20:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Tashiro", "Yusuke", ""], ["Song", "Jiaming", ""], ["Song", "Yang", ""], ["Ermon", "Stefano", ""]]}, {"id": "2107.03584", "submitter": "Ryan Giordano", "authors": "Ryan Giordano, Runjing Liu, Michael I. Jordan, Tamara Broderick", "title": "Evaluating Sensitivity to the Stick-Breaking Prior in Bayesian\n  Nonparametrics", "comments": "65 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian models based on the Dirichlet process and other stick-breaking\npriors have been proposed as core ingredients for clustering, topic modeling,\nand other unsupervised learning tasks. Prior specification is, however,\nrelatively difficult for such models, given that their flexibility implies that\nthe consequences of prior choices are often relatively opaque. Moreover, these\nchoices can have a substantial effect on posterior inferences. Thus,\nconsiderations of robustness need to go hand in hand with nonparametric\nmodeling. In the current paper, we tackle this challenge by exploiting the fact\nthat variational Bayesian methods, in addition to having computational\nadvantages in fitting complex nonparametric models, also yield sensitivities\nwith respect to parametric and nonparametric aspects of Bayesian models. In\nparticular, we demonstrate how to assess the sensitivity of conclusions to the\nchoice of concentration parameter and stick-breaking distribution for\ninferences under Dirichlet process mixtures and related mixture models. We\nprovide both theoretical and empirical support for our variational approach to\nBayesian sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 03:40:18 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 16:44:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Giordano", "Ryan", ""], ["Liu", "Runjing", ""], ["Jordan", "Michael I.", ""], ["Broderick", "Tamara", ""]]}, {"id": "2107.03633", "submitter": "Hongkang Yang", "authors": "Hongkang Yang and Weinan E", "title": "Generalization Error of GAN from the Discriminator's Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generative adversarial network (GAN) is a well-known model for learning\nhigh-dimensional distributions, but the mechanism for its generalization\nability is not understood. In particular, GAN is vulnerable to the memorization\nphenomenon, the eventual convergence to the empirical distribution. We consider\na simplified GAN model with the generator replaced by a density, and analyze\nhow the discriminator contributes to generalization. We show that with early\nstopping, the generalization error measured by Wasserstein metric escapes from\nthe curse of dimensionality, despite that in the long term, memorization is\ninevitable. In addition, we present a hardness of learning result for WGAN.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:58:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yang", "Hongkang", ""], ["E", "Weinan", ""]]}, {"id": "2107.03719", "submitter": "Thomas Elsken", "authors": "Thomas Elsken, Benedikt Staffler, Arber Zela, Jan Hendrik Metzen,\n  Frank Hutter", "title": "Bag of Tricks for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While neural architecture search methods have been successful in previous\nyears and led to new state-of-the-art performance on various problems, they\nhave also been criticized for being unstable, being highly sensitive with\nrespect to their hyperparameters, and often not performing better than random\nsearch. To shed some light on this issue, we discuss some practical\nconsiderations that help improve the stability, efficiency and overall\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 09:57:39 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Elsken", "Thomas", ""], ["Staffler", "Benedikt", ""], ["Zela", "Arber", ""], ["Metzen", "Jan Hendrik", ""], ["Hutter", "Frank", ""]]}, {"id": "2107.03730", "submitter": "Arber Qoku", "authors": "Arber Qoku and Florian Buettner", "title": "Encoding Domain Information with Sparse Priors for Inferring Explainable\n  Latent Variables", "comments": "5 pages, 6 figures, Joint KDD 2021 Health Day and 2021 KDD Workshop\n  on Applied Data Science for Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Latent variable models are powerful statistical tools that can uncover\nrelevant variation between patients or cells, by inferring unobserved hidden\nstates from observable high-dimensional data. A major shortcoming of current\nmethods, however, is their inability to learn sparse and interpretable hidden\nstates. Additionally, in settings where partial knowledge on the latent\nstructure of the data is readily available, a statistically sound integration\nof prior information into current methods is challenging. To address these\nissues, we propose spex-LVM, a factorial latent variable model with sparse\npriors to encourage the inference of explainable factors driven by\ndomain-relevant information. spex-LVM utilizes existing knowledge of curated\nbiomedical pathways to automatically assign annotated attributes to latent\nfactors, yielding interpretable results tailored to the corresponding domain of\ninterest. Evaluations on simulated and real single-cell RNA-seq datasets\ndemonstrate that our model robustly identifies relevant structure in an\ninherently explainable manner, distinguishes technical noise from sources of\nbiomedical variation, and provides dataset-specific adaptations of existing\npathway annotations. Implementation is available at\nhttps://github.com/MLO-lab/spexlvm.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:19:32 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Qoku", "Arber", ""], ["Buettner", "Florian", ""]]}, {"id": "2107.03759", "submitter": "Luong-Ha Nguyen", "authors": "Luong-Ha Nguyen and James-A. Goulet", "title": "Analytically Tractable Hidden-States Inference in Bayesian Neural\n  Networks", "comments": "37 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With few exceptions, neural networks have been relying on backpropagation and\ngradient descent as the inference engine in order to learn the model\nparameters, because the closed-form Bayesian inference for neural networks has\nbeen considered to be intractable. In this paper, we show how we can leverage\nthe tractable approximate Gaussian inference's (TAGI) capabilities to infer\nhidden states, rather than only using it for inferring the network's\nparameters. One novel aspect it allows is to infer hidden states through the\nimposition of constraints designed to achieve specific objectives, as\nillustrated through three examples: (1) the generation of adversarial-attack\nexamples, (2) the usage of a neural network as a black-box optimization method,\nand (3) the application of inference on continuous-action reinforcement\nlearning. These applications showcase how tasks that were previously reserved\nto gradient-based optimization approaches can now be approached with\nanalytically tractable inference\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:11:25 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nguyen", "Luong-Ha", ""], ["Goulet", "James-A.", ""]]}, {"id": "2107.03770", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou", "title": "Federated Learning as a Mean-Field Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.OC math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish a connection between federated learning, a concept from machine\nlearning, and mean-field games, a concept from game theory and control theory.\nIn this analogy, the local federated learners are considered as the players and\nthe aggregation of the gradients in a central server is the mean-field effect.\nWe present federated learning as a differential game and discuss the properties\nof the equilibrium of this game. We hope this novel view to federated learning\nbrings together researchers from these two distinct areas to work on\nfundamental problems of large-scale distributed and privacy-preserving learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:31:51 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mehrjou", "Arash", ""]]}, {"id": "2107.03826", "submitter": "Pierre C. Bellec", "authors": "Pierre C Bellec, Yiwei Shen, Cun-Hui Zhang", "title": "Asymptotic normality of robust $M$-estimators with convex penalty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops asymptotic normality results for individual coordinates\nof robust M-estimators with convex penalty in high-dimensions, where the\ndimension $p$ is at most of the same order as the sample size $n$, i.e,\n$p/n\\le\\gamma$ for some fixed constant $\\gamma>0$. The asymptotic normality\nrequires a bias correction and holds for most coordinates of the M-estimator\nfor a large class of loss functions including the Huber loss and its smoothed\nversions regularized with a strongly convex penalty.\n  The asymptotic variance that characterizes the width of the resulting\nconfidence intervals is estimated with data-driven quantities. This estimate of\nthe variance adapts automatically to low ($p/n\\to0)$ or high ($p/n \\le \\gamma$)\ndimensions and does not involve the proximal operators seen in previous works\non asymptotic normality of M-estimators. For the Huber loss, the estimated\nvariance has a simple expression involving an effective degrees-of-freedom as\nwell as an effective sample size. The case of the Huber loss with Elastic-Net\npenalty is studied in details and a simulation study confirms the theoretical\nfindings. The asymptotic normality results follow from Stein formulae for\nhigh-dimensional random vectors on the sphere developed in the paper which are\nof independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:12:46 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Bellec", "Pierre C", ""], ["Shen", "Yiwei", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "2107.03836", "submitter": "John Lazarsfeld", "authors": "John Lazarsfeld and Aaron Johnson", "title": "Consistency of the Maximal Information Coefficient Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maximal Information Coefficient (MIC) of Reshef et al. (Science, 2011) is\na statistic for measuring dependence between variable pairs in large datasets.\nIn this note, we prove that MIC is a consistent estimator of the corresponding\npopulation statistic MIC$_*$. This corrects an error in an argument of Reshef\net al. (JMLR, 2016), which we describe.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:28:06 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lazarsfeld", "John", ""], ["Johnson", "Aaron", ""]]}, {"id": "2107.03860", "submitter": "Alexandra Peste", "authors": "Alexandra Peste, Dan Alistarh, Christoph H. Lampert", "title": "SSSE: Efficiently Erasing Samples from Trained Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of large amounts of user-provided data has been key to the\nsuccess of machine learning for many real-world tasks. Recently, an increasing\nawareness has emerged that users should be given more control about how their\ndata is used. In particular, users should have the right to prohibit the use of\ntheir data for training machine learning systems, and to have it erased from\nalready trained systems. While several sample erasure methods have been\nproposed, all of them have drawbacks which have prevented them from gaining\nwidespread adoption. Most methods are either only applicable to very specific\nfamilies of models, sacrifice too much of the original model's accuracy, or\nthey have prohibitive memory or computational requirements. In this paper, we\npropose an efficient and effective algorithm, SSSE, for samples erasure, that\nis applicable to a wide class of machine learning models. From a second-order\nanalysis of the model's loss landscape we derive a closed-form update step of\nthe model parameters that only requires access to the data to be erased, not to\nthe original training set. Experiments on three datasets, CelebFaces attributes\n(CelebA), Animals with Attributes 2 (AwA2) and CIFAR10, show that in certain\ncases SSSE can erase samples almost as well as the optimal, yet impractical,\ngold standard of training a new model from scratch with only the permitted\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:17:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Peste", "Alexandra", ""], ["Alistarh", "Dan", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2107.03863", "submitter": "Felix Leopoldo Rios", "authors": "Felix L. Rios, Giusi Moffa, Jack Kuipers", "title": "Benchpress: a scalable and platform-independent workflow for\n  benchmarking structure learning algorithms for graphical models", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing the relationship between the variables in a study domain and\nmodelling the data generating mechanism is a fundamental problem in many\nempirical sciences. Probabilistic graphical models are one common approach to\ntackle the problem. Learning the graphical structure is computationally\nchallenging and a fervent area of current research with a plethora of\nalgorithms being developed. To facilitate the benchmarking of different\nmethods, we present a novel automated workflow, called benchpress for producing\nscalable, reproducible, and platform-independent benchmarks of structure\nlearning algorithms for probabilistic graphical models. Benchpress is\ninterfaced via a simple JSON-file, which makes it accessible for all users,\nwhile the code is designed in a fully modular fashion to enable researchers to\ncontribute additional methodologies. Benchpress currently provides an interface\nto a large number of state-of-the-art algorithms from libraries such as BiDAG,\nbnlearn, GOBNILP, pcalg, r.blip, scikit-learn, TETRAD, and trilearn as well as\na variety of methods for data generating models and performance evaluation.\nAlongside user-defined models and randomly generated datasets, the software\ntool also includes a number of standard datasets and graphical models from the\nliterature, which may be included in a benchmarking workflow. We demonstrate\nthe applicability of this workflow for learning Bayesian networks in four\ntypical data scenarios. The source code and documentation is publicly available\nfrom http://github.com/felixleopoldo/benchpress.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:19:28 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Rios", "Felix L.", ""], ["Moffa", "Giusi", ""], ["Kuipers", "Jack", ""]]}, {"id": "2107.03900", "submitter": "Hari Bandi", "authors": "Hari Bandi and Dimitris Bertsimas", "title": "The Price of Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systemic bias with respect to gender, race and ethnicity, often unconscious,\nis prevalent in datasets involving choices among individuals. Consequently,\nsociety has found it challenging to alleviate bias and achieve diversity in a\nway that maintains meritocracy in such settings. We propose (a) a novel\noptimization approach based on optimally flipping outcome labels and training\nclassification models simultaneously to discover changes to be made in the\nselection process so as to achieve diversity without significantly affecting\nmeritocracy, and (b) a novel implementation tool employing optimal\nclassification trees to provide insights on which attributes of individuals\nlead to flipping of their labels, and to help make changes in the current\nselection processes in a manner understandable by human decision makers. We\npresent case studies on three real-world datasets consisting of parole,\nadmissions to the bar and lending decisions, and demonstrate that the price of\ndiversity is low and sometimes negative, that is we can modify our selection\nprocesses in a way that enhances diversity without affecting meritocracy\nsignificantly, and sometimes improving it.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:23:27 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Bandi", "Hari", ""], ["Bertsimas", "Dimitris", ""]]}, {"id": "2107.03903", "submitter": "Aleksandr Petiushko", "authors": "Alexander Ivanov, Gleb Nosovskiy, Alexey Chekunov, Denis Fedoseev,\n  Vladislav Kibkalo, Mikhail Nikulin, Fedor Popelenskiy, Stepan Komkov, Ivan\n  Mazurenko, Aleksandr Petiushko", "title": "Manifold Hypothesis in Data Analysis: Double Geometrically-Probabilistic\n  Approach to Manifold Dimension Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold hypothesis states that data points in high-dimensional space\nactually lie in close vicinity of a manifold of much lower dimension. In many\ncases this hypothesis was empirically verified and used to enhance unsupervised\nand semi-supervised learning. Here we present new approach to manifold\nhypothesis checking and underlying manifold dimension estimation. In order to\ndo it we use two very different methods simultaneously - one geometric, another\nprobabilistic - and check whether they give the same result. Our geometrical\nmethod is a modification for sparse data of a well-known box-counting algorithm\nfor Minkowski dimension calculation. The probabilistic method is new. Although\nit exploits standard nearest neighborhood distance, it is different from\nmethods which were previously used in such situations. This method is robust,\nfast and includes special preliminary data transformation. Experiments on real\ndatasets show that the suggested approach based on two methods combination is\npowerful and effective.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:35:54 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ivanov", "Alexander", ""], ["Nosovskiy", "Gleb", ""], ["Chekunov", "Alexey", ""], ["Fedoseev", "Denis", ""], ["Kibkalo", "Vladislav", ""], ["Nikulin", "Mikhail", ""], ["Popelenskiy", "Fedor", ""], ["Komkov", "Stepan", ""], ["Mazurenko", "Ivan", ""], ["Petiushko", "Aleksandr", ""]]}, {"id": "2107.03920", "submitter": "David Zhao", "authors": "Niccol\\`o Dalmasso, David Zhao, Rafael Izbicki, Ann B. Lee", "title": "Likelihood-Free Frequentist Inference: Bridging Classical Statistics and\n  Machine Learning in Simulation and Uncertainty Quantification", "comments": "49 pages, 12 figures, code available at\n  https://github.com/Mr8ND/ACORE-LFI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many areas of science make extensive use of computer simulators that\nimplicitly encode likelihood functions of complex systems. Classical\nstatistical methods are poorly suited for these so-called likelihood-free\ninference (LFI) settings, outside the asymptotic and low-dimensional regimes.\nAlthough new machine learning methods, such as normalizing flows, have\nrevolutionized the sample efficiency and capacity of LFI methods, it remains an\nopen question whether they produce reliable measures of uncertainty. This paper\npresents a statistical framework for LFI that unifies classical statistics with\nmodern machine learning to: (1) efficiently construct frequentist confidence\nsets and hypothesis tests with finite-sample guarantees of nominal coverage\n(type I error control) and power; (2) provide practical diagnostics for\nassessing empirical coverage over the entire parameter space. We refer to our\nframework as likelihood-free frequentist inference (LF2I). Any method that\nestimates a test statistic, like the likelihood ratio, can be plugged into our\nframework to create valid confidence sets and compute diagnostics, without\ncostly Monte Carlo samples at fixed parameter settings. In this work, we\nspecifically study the power of two test statistics (ACORE and BFF), which,\nrespectively, maximize versus integrate an odds function over the parameter\nspace. Our study offers multifaceted perspectives on the challenges in LF2I.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:52:18 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 14:43:11 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Dalmasso", "Niccol\u00f2", ""], ["Zhao", "David", ""], ["Izbicki", "Rafael", ""], ["Lee", "Ann B.", ""]]}, {"id": "2107.03940", "submitter": "Yann Issartel", "authors": "Cristina Butucea and Yann Issartel", "title": "Locally differentially private estimation of nonlinear functionals of\n  discrete distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating non-linear functionals of discrete\ndistributions in the context of local differential privacy. The initial data\n$x_1,\\ldots,x_n \\in [K]$ are supposed i.i.d. and distributed according to an\nunknown discrete distribution $p = (p_1,\\ldots,p_K)$. Only $\\alpha$-locally\ndifferentially private (LDP) samples $z_1,...,z_n$ are publicly available,\nwhere the term 'local' means that each $z_i$ is produced using one individual\nattribute $x_i$. We exhibit privacy mechanisms (PM) that are interactive (i.e.\nthey are allowed to use already published confidential data) or\nnon-interactive. We describe the behavior of the quadratic risk for estimating\nthe power sum functional $F_{\\gamma} = \\sum_{k=1}^K p_k^{\\gamma}$, $\\gamma >0$\nas a function of $K, \\, n$ and $\\alpha$. In the non-interactive case, we study\ntwo plug-in type estimators of $F_{\\gamma}$, for all $\\gamma >0$, that are\nsimilar to the MLE analyzed by Jiao et al. (2017) in the multinomial model.\nHowever, due to the privacy constraint the rates we attain are slower and\nsimilar to those obtained in the Gaussian model by Collier et al. (2020). In\nthe interactive case, we introduce for all $\\gamma >1$ a two-step procedure\nwhich attains the faster parametric rate $(n \\alpha^2)^{-1/2}$ when $\\gamma\n\\geq 2$. We give lower bounds results over all $\\alpha$-LDP mechanisms and all\nestimators using the private samples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:11:10 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Butucea", "Cristina", ""], ["Issartel", "Yann", ""]]}, {"id": "2107.04050", "submitter": "Barna Pasztor", "authors": "Barna Pasztor, Ilija Bogunovic, Andreas Krause", "title": "Efficient Model-Based Multi-Agent Mean-Field Reinforcement Learning", "comments": "28 pages, 2 figures, Preprint, Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in multi-agent systems is highly challenging due to the inherent\ncomplexity introduced by agents' interactions. We tackle systems with a huge\npopulation of interacting agents (e.g., swarms) via Mean-Field Control (MFC).\nMFC considers an asymptotically infinite population of identical agents that\naim to collaboratively maximize the collective reward. Specifically, we\nconsider the case of unknown system dynamics where the goal is to\nsimultaneously optimize for the rewards and learn from experience. We propose\nan efficient model-based reinforcement learning algorithm\n$\\text{M}^3\\text{-UCRL}$ that runs in episodes and provably solves this\nproblem. $\\text{M}^3\\text{-UCRL}$ uses upper-confidence bounds to balance\nexploration and exploitation during policy learning. Our main theoretical\ncontributions are the first general regret bounds for model-based RL for MFC,\nobtained via a novel mean-field type analysis. $\\text{M}^3\\text{-UCRL}$ can be\ninstantiated with different models such as neural networks or Gaussian\nProcesses, and effectively combined with neural network policy learning. We\nempirically demonstrate the convergence of $\\text{M}^3\\text{-UCRL}$ on the\nswarm motion problem of controlling an infinite population of agents seeking to\nmaximize location-dependent reward and avoid congested areas.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:01:02 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Pasztor", "Barna", ""], ["Bogunovic", "Ilija", ""], ["Krause", "Andreas", ""]]}, {"id": "2107.04061", "submitter": "Jacob Gardner", "authors": "Misha Padidar, Xinran Zhu, Leo Huang, Jacob R. Gardner, David Bindel", "title": "Scaling Gaussian Processes with Derivative Information Using Variational\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Gaussian processes with derivative information are useful in many settings\nwhere derivative information is available, including numerous Bayesian\noptimization and regression tasks that arise in the natural sciences.\nIncorporating derivative observations, however, comes with a dominating\n$O(N^3D^3)$ computational cost when training on $N$ points in $D$ input\ndimensions. This is intractable for even moderately sized problems. While\nrecent work has addressed this intractability in the low-$D$ setting, the\nhigh-$N$, high-$D$ setting is still unexplored and of great value, particularly\nas machine learning problems increasingly become high dimensional. In this\npaper, we introduce methods to achieve fully scalable Gaussian process\nregression with derivatives using variational inference. Analogous to the use\nof inducing values to sparsify the labels of a training set, we introduce the\nconcept of inducing directional derivatives to sparsify the partial derivative\ninformation of a training set. This enables us to construct a variational\nposterior that incorporates derivative information but whose size depends\nneither on the full dataset size $N$ nor the full dimensionality $D$. We\ndemonstrate the full scalability of our approach on a variety of tasks, ranging\nfrom a high dimensional stellarator fusion regression task to training graph\nconvolutional neural networks on Pubmed using Bayesian optimization.\nSurprisingly, we find that our approach can improve regression performance even\nin settings where only label data is available.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:23:59 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Padidar", "Misha", ""], ["Zhu", "Xinran", ""], ["Huang", "Leo", ""], ["Gardner", "Jacob R.", ""], ["Bindel", "David", ""]]}, {"id": "2107.04091", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek and Pawe{\\l} Pe{\\l}ka", "title": "Ensembles of Randomized NNs for Pattern-based Time Series Forecasting", "comments": "arXiv admin note: text overlap with arXiv:2107.01705", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an ensemble forecasting approach based on randomized\nneural networks. Improved randomized learning streamlines the fitting abilities\nof individual learners by generating network parameters in accordance with the\ndata and target function features. A pattern-based representation of time\nseries makes the proposed approach suitable for forecasting time series with\nmultiple seasonality. We propose six strategies for controlling the diversity\nof ensemble members. Case studies conducted on four real-world forecasting\nproblems verified the effectiveness and superior performance of the proposed\nensemble forecasting approach. It outperformed statistical models as well as\nstate-of-the-art machine learning models in terms of forecasting accuracy. The\nproposed approach has several advantages: fast and easy training, simple\narchitecture, ease of implementation, high accuracy and the ability to deal\nwith nonstationarity and multiple seasonality in time series.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 20:13:50 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Dudek", "Grzegorz", ""], ["Pe\u0142ka", "Pawe\u0142", ""]]}, {"id": "2107.04126", "submitter": "Eduardo C. Garrido-Merch\\'an", "authors": "Lucia Asencio Mart\\'in, Eduardo C. Garrido-Merch\\'an", "title": "Many Objective Bayesian Optimization", "comments": "arXiv admin note: text overlap with arXiv:2101.08061", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some real problems require the evaluation of expensive and noisy objective\nfunctions. Moreover, the analytical expression of these objective functions may\nbe unknown. These functions are known as black-boxes, for example, estimating\nthe generalization error of a machine learning algorithm and computing its\nprediction time in terms of its hyper-parameters. Multi-objective Bayesian\noptimization (MOBO) is a set of methods that has been successfully applied for\nthe simultaneous optimization of black-boxes. Concretely, BO methods rely on a\nprobabilistic model of the objective functions, typically a Gaussian process.\nThis model generates a predictive distribution of the objectives. However, MOBO\nmethods have problems when the number of objectives in a multi-objective\noptimization problem are 3 or more, which is the many objective setting. In\nparticular, the BO process is more costly as more objectives are considered,\ncomputing the quality of the solution via the hyper-volume is also more costly\nand, most importantly, we have to evaluate every objective function, wasting\nexpensive computational, economic or other resources. However, as more\nobjectives are involved in the optimization problem, it is highly probable that\nsome of them are redundant and not add information about the problem solution.\nA measure that represents how similar are GP predictive distributions is\nproposed. We also propose a many objective Bayesian optimization algorithm that\nuses this metric to determine whether two objectives are redundant. The\nalgorithm stops evaluating one of them if the similarity is found, saving\nresources and not hurting the performance of the multi-objective BO algorithm.\nWe show empirical evidence in a set of toy, synthetic, benchmark and real\nexperiments that GPs predictive distributions of the effectiveness of the\nmetric and the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 21:57:07 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Mart\u00edn", "Lucia Asencio", ""], ["Garrido-Merch\u00e1n", "Eduardo C.", ""]]}, {"id": "2107.04136", "submitter": "Rebecca E. Morrison", "authors": "Rebecca E Morrison, Ricardo Baptista, Estelle L Basor", "title": "Diagonal Nonlinear Transformations Preserve Structure in Covariance and\n  Precision Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a multivariate normal distribution, the sparsity of the covariance and\nprecision matrices encodes complete information about independence and\nconditional independence properties. For general distributions, the covariance\nand precision matrices reveal correlations and so-called partial correlations\nbetween variables, but these do not, in general, have any correspondence with\nrespect to independence properties. In this paper, we prove that, for a certain\nclass of non-Gaussian distributions, these correspondences still hold, exactly\nfor the covariance and approximately for the precision. The distributions --\nsometimes referred to as \"nonparanormal\" -- are given by diagonal\ntransformations of multivariate normal random variables. We provide several\nanalytic and numerical examples illustrating these results.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 22:31:48 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Morrison", "Rebecca E", ""], ["Baptista", "Ricardo", ""], ["Basor", "Estelle L", ""]]}, {"id": "2107.04150", "submitter": "Tomas Geffner", "authors": "Tomas Geffner and Justin Domke", "title": "MCMC Variational Inference via Uncorrected Hamiltonian Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an unnormalized target distribution we want to obtain approximate\nsamples from it and a tight lower bound on its (log) normalization constant log\nZ. Annealed Importance Sampling (AIS) with Hamiltonian MCMC is a powerful\nmethod that can be used to do this. Its main drawback is that it uses\nnon-differentiable transition kernels, which makes tuning its many parameters\nhard. We propose a framework to use an AIS-like procedure with Uncorrected\nHamiltonian MCMC, called Uncorrected Hamiltonian Annealing. Our method leads to\ntight and differentiable lower bounds on log Z. We show empirically that our\nmethod yields better performances than other competing approaches, and that the\nability to tune its parameters using reparameterization gradients may lead to\nlarge performance improvements.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 23:59:45 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Geffner", "Tomas", ""], ["Domke", "Justin", ""]]}, {"id": "2107.04205", "submitter": "Ke Sun", "authors": "Alexander Soen and Ke Sun", "title": "On the Variance of the Fisher Information for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fisher information matrix (FIM) has been applied to the realm of deep\nlearning. It is closely related to the loss landscape, the variance of the\nparameters, second order optimization, and deep learning theory. The exact FIM\nis either unavailable in closed form or too expensive to compute. In practice,\nit is almost always estimated based on empirical samples. We investigate two\nsuch estimators based on two equivalent representations of the FIM. They are\nboth unbiased and consistent with respect to the underlying \"true\" FIM. Their\nestimation quality is characterized by their variance given in closed form. We\nbound their variances and analyze how the parametric structure of a deep neural\nnetwork can impact the variance. We discuss the meaning of this variance\nmeasure and our bounds in the context of deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 04:46:50 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Soen", "Alexander", ""], ["Sun", "Ke", ""]]}, {"id": "2107.04247", "submitter": "Kenji Kashima", "authors": "Ryuta Moriyasu, Taro Ikeda, Sho Kawaguchi, Kenji Kashima", "title": "Structured Hammerstein-Wiener Model Learning for Model Predictive\n  Control", "comments": "6 pages, 3 figures", "journal-ref": "IEEE Control Systems Letters, 2021", "doi": "10.1109/LCSYS.2021.3077201", "report-no": null, "categories": "math.OC cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to improve the reliability of optimal control using models\nconstructed by machine learning methods. Optimal control problems based on such\nmodels are generally non-convex and difficult to solve online. In this paper,\nwe propose a model that combines the Hammerstein-Wiener model with input convex\nneural networks, which have recently been proposed in the field of machine\nlearning. An important feature of the proposed model is that resulting optimal\ncontrol problems are effectively solvable exploiting their convexity and\npartial linearity while retaining flexible modeling ability. The practical\nusefulness of the method is examined through its application to the modeling\nand control of an engine airpath system.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:41:34 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Moriyasu", "Ryuta", ""], ["Ikeda", "Taro", ""], ["Kawaguchi", "Sho", ""], ["Kashima", "Kenji", ""]]}, {"id": "2107.04316", "submitter": "Janne R\\\"aty", "authors": "Janne R\\\"aty, Johannes Breidenbach, Marius Hauglin, Rasmus Astrup", "title": "Prediction of butt rot volume in Norway spruce forest stands using\n  harvester, remotely sensed and environmental data", "comments": "22 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Butt rot (BR) damages associated with Norway spruce (Picea abies [L.] Karst.)\naccount for considerable economic losses in timber production across the\nnorthern hemisphere. While information on BR damages is critical for optimal\ndecision-making in forest management, the maps of BR damages are typically\nlacking in forest information systems. We predicted timber volume damaged by BR\nat the stand-level in Norway using harvester information of 186,026 stems\n(clear-cuts), remotely sensed, and environmental data (e.g. climate and terrain\ncharacteristics). We utilized random forest (RF) models with two sets of\npredictor variables: (1) predictor variables available after harvest\n(theoretical case) and (2) predictor variables available prior to harvest\n(mapping case). We found that forest attributes characterizing the maturity of\nforest, such as remote sensing-based height, harvested timber volume and\nquadratic mean diameter at breast height, were among the most important\npredictor variables. Remotely sensed predictor variables obtained from airborne\nlaser scanning data and Sentinel-2 imagery were more important than the\nenvironmental variables. The theoretical case with a leave-stand-out\ncross-validation achieved an RMSE of 11.4 $m^3ha^{-1}$ (pseudo $R^2$: 0.66)\nwhereas the mapping case resulted in a pseudo $R^2$ of 0.60. When the spatially\ndistinct k-means clusters of harvested forest stands were used as units in the\ncross-validation, the RMSE value and pseudo $R^2$ associated with the mapping\ncase were 15.6 $m^3ha^{-1}$ and 0.37, respectively. This indicates that the\nknowledge about the BR status of spatially close stands is of high importance\nfor obtaining satisfactory error rates in the mapping of BR damages.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 09:09:32 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["R\u00e4ty", "Janne", ""], ["Breidenbach", "Johannes", ""], ["Hauglin", "Marius", ""], ["Astrup", "Rasmus", ""]]}, {"id": "2107.04346", "submitter": "Niklas Koenen", "authors": "Niklas Koenen, Marvin N. Wright, Peter Maa{\\ss} and Jens Behrmann", "title": "Generalization of the Change of Variables Formula with Applications to\n  Residual Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normalizing flows leverage the Change of Variables Formula (CVF) to define\nflexible density models. Yet, the requirement of smooth transformations\n(diffeomorphisms) in the CVF poses a significant challenge in the construction\nof these models. To enlarge the design space of flows, we introduce\n$\\mathcal{L}$-diffeomorphisms as generalized transformations which may violate\nthese requirements on zero Lebesgue-measure sets. This relaxation allows e.g.\nthe use of non-smooth activation functions such as ReLU. Finally, we apply the\nobtained results to planar, radial, and contractive residual flows.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 10:31:32 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Koenen", "Niklas", ""], ["Wright", "Marvin N.", ""], ["Maa\u00df", "Peter", ""], ["Behrmann", "Jens", ""]]}, {"id": "2107.04369", "submitter": "Arber Zela", "authors": "Ashwin Raaghav Narayanan, Arber Zela, Tonmoy Saikia, Thomas Brox,\n  Frank Hutter", "title": "Multi-headed Neural Ensemble Search", "comments": "8 pages, 12 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of CNN models trained with different seeds (also known as Deep\nEnsembles) are known to achieve superior performance over a single copy of the\nCNN. Neural Ensemble Search (NES) can further boost performance by adding\narchitectural diversity. However, the scope of NES remains prohibitive under\nlimited computational resources. In this work, we extend NES to multi-headed\nensembles, which consist of a shared backbone attached to multiple prediction\nheads. Unlike Deep Ensembles, these multi-headed ensembles can be trained end\nto end, which enables us to leverage one-shot NAS methods to optimize an\nensemble objective. With extensive empirical evaluations, we demonstrate that\nmulti-headed ensemble search finds robust ensembles 3 times faster, while\nhaving comparable performance to other ensemble search methods, in both\npredictive performance and uncertainty calibration.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 11:20:48 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Narayanan", "Ashwin Raaghav", ""], ["Zela", "Arber", ""], ["Saikia", "Tonmoy", ""], ["Brox", "Thomas", ""], ["Hutter", "Frank", ""]]}, {"id": "2107.04381", "submitter": "Sascha Meyen", "authors": "Sascha Meyen, Frieder G\\\"oppert, Helen Alber, Ulrike von Luxburg,\n  Volker H. Franz", "title": "Specialists Outperform Generalists in Ensemble Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider an ensemble of $k$ individual classifiers whose accuracies are\nknown. Upon receiving a test point, each of the classifiers outputs a predicted\nlabel and a confidence in its prediction for this particular test point. In\nthis paper, we address the question of whether we can determine the accuracy of\nthe ensemble. Surprisingly, even when classifiers are combined in the\nstatistically optimal way in this setting, the accuracy of the resulting\nensemble classifier cannot be computed from the accuracies of the individual\nclassifiers-as would be the case in the standard setting of confidence weighted\nmajority voting. We prove tight upper and lower bounds on the ensemble\naccuracy. We explicitly construct the individual classifiers that attain the\nupper and lower bounds: specialists and generalists. Our theoretical results\nhave very practical consequences: (1) If we use ensemble methods and have the\nchoice to construct our individual (independent) classifiers from scratch, then\nwe should aim for specialist classifiers rather than generalists. (2) Our\nbounds can be used to determine how many classifiers are at least required to\nachieve a desired ensemble accuracy. Finally, we improve our bounds by\nconsidering the mutual information between the true label and the individual\nclassifier's output.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:16:10 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Meyen", "Sascha", ""], ["G\u00f6ppert", "Frieder", ""], ["Alber", "Helen", ""], ["von Luxburg", "Ulrike", ""], ["Franz", "Volker H.", ""]]}, {"id": "2107.04384", "submitter": "Sebastian Lee", "authors": "Sebastian Lee and Sebastian Goldt and Andrew Saxe", "title": "Continual Learning in the Teacher-Student Setup: Impact of Task\n  Similarity", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139:6109-6119, 2021", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning-the ability to learn many tasks in sequence-is critical\nfor artificial learning systems. Yet standard training methods for deep\nnetworks often suffer from catastrophic forgetting, where learning new tasks\nerases knowledge of earlier tasks. While catastrophic forgetting labels the\nproblem, the theoretical reasons for interference between tasks remain unclear.\nHere, we attempt to narrow this gap between theory and practice by studying\ncontinual learning in the teacher-student setup. We extend previous analytical\nwork on two-layer networks in the teacher-student setup to multiple teachers.\nUsing each teacher to represent a different task, we investigate how the\nrelationship between teachers affects the amount of forgetting and transfer\nexhibited by the student when the task switches. In line with recent work, we\nfind that when tasks depend on similar features, intermediate task similarity\nleads to greatest forgetting. However, feature similarity is only one way in\nwhich tasks may be related. The teacher-student approach allows us to\ndisentangle task similarity at the level of readouts (hidden-to-output weights)\nand features (input-to-hidden weights). We find a complex interplay between\nboth types of similarity, initial transfer/forgetting rates, maximum\ntransfer/forgetting, and long-term transfer/forgetting. Together, these results\nhelp illuminate the diverse factors contributing to catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:30:39 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Lee", "Sebastian", ""], ["Goldt", "Sebastian", ""], ["Saxe", "Andrew", ""]]}, {"id": "2107.04395", "submitter": "Nicolas Gillis", "authors": "Le Thi Khanh Hien, Duy Nhat Phan, Nicolas Gillis, Masoud Ahookhosh,\n  Panagiotis Patrinos", "title": "Block Alternating Bregman Majorization Minimization with Extrapolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA eess.SP math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a class of nonsmooth nonconvex optimization\nproblems whose objective is the sum of a block relative smooth function and a\nproper and lower semicontinuous block separable function. Although the analysis\nof block proximal gradient (BPG) methods for the class of block $L$-smooth\nfunctions have been successfully extended to Bregman BPG methods that deal with\nthe class of block relative smooth functions, accelerated Bregman BPG methods\nare scarce and challenging to design. Taking our inspiration from Nesterov-type\nacceleration and the majorization-minimization scheme, we propose a block\nalternating Bregman Majorization-Minimization framework with Extrapolation\n(BMME). We prove subsequential convergence of BMME to a first-order stationary\npoint under mild assumptions, and study its global convergence under stronger\nconditions. We illustrate the effectiveness of BMME on the penalized orthogonal\nnonnegative matrix factorization problem.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:47:00 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Hien", "Le Thi Khanh", ""], ["Phan", "Duy Nhat", ""], ["Gillis", "Nicolas", ""], ["Ahookhosh", "Masoud", ""], ["Patrinos", "Panagiotis", ""]]}, {"id": "2107.04480", "submitter": "Jean-S\\'ebastien Brouillon", "authors": "Jean-S\\'ebastien Brouillon, Emanuele Fabbiani, Pulkit Nahata, Florian\n  D\\\"orfler, Giancarlo Ferrari-Trecate", "title": "Bayesian Error-in-Variables Models for the Identification of Power\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing integration of intermittent renewable generation, especially\nat the distribution level,necessitates advanced planning and optimisation\nmethodologies contingent on the knowledge of thegrid, specifically the\nadmittance matrix capturing the topology and line parameters of an\nelectricnetwork. However, a reliable estimate of the admittance matrix may\neither be missing or quicklybecome obsolete for temporally varying grids. In\nthis work, we propose a data-driven identificationmethod utilising voltage and\ncurrent measurements collected from micro-PMUs. More precisely,we first present\na maximum likelihood approach and then move towards a Bayesian\nframework,leveraging the principles of maximum a posteriori estimation. In\ncontrast with most existing con-tributions, our approach not only factors in\nmeasurement noise on both voltage and current data,but is also capable of\nexploiting available a priori information such as sparsity patterns and\nknownline parameters. Simulations conducted on benchmark cases demonstrate\nthat, compared to otheralgorithms, our method can achieve significantly greater\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:10:47 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Brouillon", "Jean-S\u00e9bastien", ""], ["Fabbiani", "Emanuele", ""], ["Nahata", "Pulkit", ""], ["D\u00f6rfler", "Florian", ""], ["Ferrari-Trecate", "Giancarlo", ""]]}, {"id": "2107.04497", "submitter": "Vincent Mai", "authors": "Vincent Mai, Waleed Khamies, Liam Paull", "title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "comments": "Accepted at the Uncertainty in Deep Learning (UDL) workshop at ICML\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Heteroscedastic regression is the task of supervised learning where each\nlabel is subject to noise from a different distribution. This noise can be\ncaused by the labelling process, and impacts negatively the performance of the\nlearning algorithm as it violates the i.i.d. assumptions. In many situations\nhowever, the labelling process is able to estimate the variance of such\ndistribution for each label, which can be used as an additional information to\nmitigate this impact. We adapt an inverse-variance weighted mean square error,\nbased on the Gauss-Markov theorem, for parameter optimization on neural\nnetworks. We introduce Batch Inverse-Variance, a loss function which is robust\nto near-ground truth samples, and allows to control the effective learning\nrate. Our experimental results show that BIV improves significantly the\nperformance of the networks on two noisy datasets, compared to L2 loss,\ninverse-variance weighting, as well as a filtering-based baseline.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:39:31 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Mai", "Vincent", ""], ["Khamies", "Waleed", ""], ["Paull", "Liam", ""]]}, {"id": "2107.04518", "submitter": "Qi Lei", "authors": "Baihe Huang, Kaixuan Huang, Sham M. Kakade, Jason D. Lee, Qi Lei,\n  Runzhe Wang, Jiaqi Yang", "title": "Optimal Gradient-based Algorithms for Non-concave Bandit Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Bandit problems with linear or concave reward have been extensively studied,\nbut relatively few works have studied bandits with non-concave reward. This\nwork considers a large family of bandit problems where the unknown underlying\nreward function is non-concave, including the low-rank generalized linear\nbandit problems and two-layer neural network with polynomial activation bandit\nproblem. For the low-rank generalized linear bandit problem, we provide a\nminimax-optimal algorithm in the dimension, refuting both conjectures in\n[LMT21, JWWN19]. Our algorithms are based on a unified zeroth-order\noptimization paradigm that applies in great generality and attains optimal\nrates in several structured polynomial settings (in the dimension). We further\ndemonstrate the applicability of our algorithms in RL in the generative model\nsetting, resulting in improved sample complexity over prior approaches.\nFinally, we show that the standard optimistic algorithms (e.g., UCB) are\nsub-optimal by dimension factors. In the neural net setting (with polynomial\nactivation functions) with noiseless reward, we provide a bandit algorithm with\nsample complexity equal to the intrinsic algebraic dimension. Again, we show\nthat optimistic approaches have worse sample complexity, polynomial in the\nextrinsic dimension (which could be exponentially worse in the polynomial\ndegree).\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:04:24 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Huang", "Baihe", ""], ["Huang", "Kaixuan", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""], ["Wang", "Runzhe", ""], ["Yang", "Jiaqi", ""]]}, {"id": "2107.04520", "submitter": "Ruihan Wu", "authors": "Ruihan Wu, Chuan Guo, Yi Su, Kilian Q. Weinberger", "title": "Online Adaptation to Label Distribution Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models often encounter distribution shifts when deployed in\nthe real world. In this paper, we focus on adaptation to label distribution\nshift in the online setting, where the test-time label distribution is\ncontinually changing and the model must dynamically adapt to it without\nobserving the true label. Leveraging a novel analysis, we show that the lack of\ntrue label does not hinder estimation of the expected test loss, which enables\nthe reduction of online label shift adaptation to conventional online learning.\nInformed by this observation, we propose adaptation algorithms inspired by\nclassical online learning techniques such as Follow The Leader (FTL) and Online\nGradient Descent (OGD) and derive their regret bounds. We empirically verify\nour findings under both simulated and real world label distribution shifts and\nshow that OGD is particularly effective and robust to a variety of challenging\nlabel shift scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:12:19 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Wu", "Ruihan", ""], ["Guo", "Chuan", ""], ["Su", "Yi", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2107.04562", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan and H{\\aa}vard Rue", "title": "The Bayesian Learning Rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that many machine-learning algorithms are specific instances of a\nsingle algorithm called the Bayesian learning rule. The rule, derived from\nBayesian principles, yields a wide-range of algorithms from fields such as\noptimization, deep learning, and graphical models. This includes classical\nalgorithms such as ridge regression, Newton's method, and Kalman filter, as\nwell as modern deep-learning algorithms such as stochastic-gradient descent,\nRMSprop, and Dropout. The key idea in deriving such algorithms is to\napproximate the posterior using candidate distributions estimated by using\nnatural gradients. Different candidate distributions result in different\nalgorithms and further approximations to natural gradients give rise to\nvariants of those algorithms. Our work not only unifies, generalizes, and\nimproves existing algorithms, but also helps us design new ones.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:28:55 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Rue", "H\u00e5vard", ""]]}, {"id": "2107.04633", "submitter": "Taylor Dohmen", "authors": "Alvaro Velasquez, Andre Beckus, Taylor Dohmen, Ashutosh Trivedi, Noah\n  Topper, George Atia", "title": "Learning Probabilistic Reward Machines from Non-Markovian Stochastic\n  Reward Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The success of reinforcement learning in typical settings is, in part,\npredicated on underlying Markovian assumptions on the reward signal by which an\nagent learns optimal policies. In recent years, the use of reward machines has\nrelaxed this assumption by enabling a structured representation of\nnon-Markovian rewards. In particular, such representations can be used to\naugment the state space of the underlying decision process, thereby\nfacilitating non-Markovian reinforcement learning. However, these reward\nmachines cannot capture the semantics of stochastic reward signals. In this\npaper, we make progress on this front by introducing probabilistic reward\nmachines (PRMs) as a representation of non-Markovian stochastic rewards. We\npresent an algorithm to learn PRMs from the underlying decision process as well\nas to learn the PRM representation of a given decision-making policy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:00:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Velasquez", "Alvaro", ""], ["Beckus", "Andre", ""], ["Dohmen", "Taylor", ""], ["Trivedi", "Ashutosh", ""], ["Topper", "Noah", ""], ["Atia", "George", ""]]}, {"id": "2107.04649", "submitter": "John Miller", "authors": "John Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei\n  Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, Ludwig Schmidt", "title": "Accuracy on the Line: On the Strong Correlation Between\n  Out-of-Distribution and In-Distribution Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine learning systems to be reliable, we must understand their\nperformance in unseen, out-of-distribution environments. In this paper, we\nempirically show that out-of-distribution performance is strongly correlated\nwith in-distribution performance for a wide range of models and distribution\nshifts. Specifically, we demonstrate strong correlations between\nin-distribution and out-of-distribution performance on variants of CIFAR-10 &\nImageNet, a synthetic pose estimation task derived from YCB objects, satellite\nimagery classification in FMoW-WILDS, and wildlife classification in\niWildCam-WILDS. The strong correlations hold across model architectures,\nhyperparameters, training set size, and training duration, and are more precise\nthan what is expected from existing domain adaptation theory. To complete the\npicture, we also investigate cases where the correlation is weaker, for\ninstance some synthetic distribution shifts from CIFAR-10-C and the tissue\nclassification dataset Camelyon17-WILDS. Finally, we provide a candidate theory\nbased on a Gaussian data model that shows how changes in the data covariance\narising from distribution shift can affect the observed correlations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:48:23 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Miller", "John", ""], ["Taori", "Rohan", ""], ["Raghunathan", "Aditi", ""], ["Sagawa", "Shiori", ""], ["Koh", "Pang Wei", ""], ["Shankar", "Vaishaal", ""], ["Liang", "Percy", ""], ["Carmon", "Yair", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "2107.04652", "submitter": "Andrej Risteski", "authors": "Divyansh Pareek, Andrej Risteski", "title": "The Effects of Invertibility on the Representational Complexity of\n  Encoders in Variational Autoencoders", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training and using modern neural-network based latent-variable generative\nmodels (like Variational Autoencoders) often require simultaneously training a\ngenerative direction along with an inferential(encoding) direction, which\napproximates the posterior distribution over the latent variables. Thus, the\nquestion arises: how complex does the inferential model need to be, in order to\nbe able to accurately model the posterior distribution of a given generative\nmodel?\n  In this paper, we identify an important property of the generative map\nimpacting the required size of the encoder. We show that if the generative map\nis \"strongly invertible\" (in a sense we suitably formalize), the inferential\nmodel need not be much more complex. Conversely, we prove that there exist\nnon-invertible generative maps, for which the encoding direction needs to be\nexponentially larger (under standard assumptions in computational complexity).\nImportantly, we do not require the generative model to be layerwise invertible,\nwhich a lot of the related literature assumes and isn't satisfied by many\narchitectures used in practice (e.g. convolution and pooling based networks).\nThus, we provide theoretical support for the empirical wisdom that learning\ndeep generative models is harder when data lies on a low-dimensional manifold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:53:29 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pareek", "Divyansh", ""], ["Risteski", "Andrej", ""]]}, {"id": "2107.04661", "submitter": "Serge Assaad", "authors": "Serge Assaad, Shuxi Zeng, Henry Pfister, Fan Li, Lawrence Carin", "title": "H\\\"older Bounds for Sensitivity Analysis in Causal Reasoning", "comments": "Workshop on the Neglected Assumptions in Causal Inference at the\n  International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine interval estimation of the effect of a treatment T on an outcome Y\ngiven the existence of an unobserved confounder U. Using H\\\"older's inequality,\nwe derive a set of bounds on the confounding bias |E[Y|T=t]-E[Y|do(T=t)]| based\non the degree of unmeasured confounding (i.e., the strength of the connection\nU->T, and the strength of U->Y). These bounds are tight either when U is\nindependent of T or when U is independent of Y given T (when there is no\nunobserved confounding). We focus on a special case of this bound depending on\nthe total variation distance between the distributions p(U) and p(U|T=t), as\nwell as the maximum (over all possible values of U) deviation of the\nconditional expected outcome E[Y|U=u,T=t] from the average expected outcome\nE[Y|T=t]. We discuss possible calibration strategies for this bound to get\ninterval estimates for treatment effects, and experimentally validate the bound\nusing synthetic and semi-synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 20:26:36 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Assaad", "Serge", ""], ["Zeng", "Shuxi", ""], ["Pfister", "Henry", ""], ["Li", "Fan", ""], ["Carin", "Lawrence", ""]]}, {"id": "2107.04668", "submitter": "Ruda Zhang", "authors": "Ruda Zhang and Simon Mak and David Dunson", "title": "Gaussian Process Subspace Regression for Model Reduction", "comments": "20 pages, 4 figures; with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.NA math.NA stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace-valued functions arise in a wide range of problems, including\nparametric reduced order modeling (PROM). In PROM, each parameter point can be\nassociated with a subspace, which is used for Petrov-Galerkin projections of\nlarge system matrices. Previous efforts to approximate such functions use\ninterpolations on manifolds, which can be inaccurate and slow. To tackle this,\nwe propose a novel Bayesian nonparametric model for subspace prediction: the\nGaussian Process Subspace regression (GPS) model. This method is extrinsic and\nintrinsic at the same time: with multivariate Gaussian distributions on the\nEuclidean space, it induces a joint probability model on the Grassmann\nmanifold, the set of fixed-dimensional subspaces. The GPS adopts a simple yet\ngeneral correlation structure, and a principled approach for model selection.\nIts predictive distribution admits an analytical form, which allows for\nefficient subspace prediction over the parameter space. For PROM, the GPS\nprovides a probabilistic prediction at a new parameter point that retains the\naccuracy of local reduced models, at a computational complexity that does not\ndepend on system dimension, and thus is suitable for online computation. We\ngive four numerical examples to compare our method to subspace interpolation,\nas well as two methods that interpolate local reduced models. Overall, GPS is\nthe most data efficient, more computationally efficient than subspace\ninterpolation, and gives smooth predictions with uncertainty quantification.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 20:41:23 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhang", "Ruda", ""], ["Mak", "Simon", ""], ["Dunson", "David", ""]]}, {"id": "2107.04695", "submitter": "Christian Samuel Perone", "authors": "Christian S. Perone, Roberto Pereira Silveira, Thomas Paula", "title": "L2M: Practical posterior Laplace approximation with optimization-driven\n  second moment estimation", "comments": "6 pages, 1 figure, accepted for ICML 2021 UDL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification for deep neural networks has recently evolved\nthrough many techniques. In this work, we revisit Laplace approximation, a\nclassical approach for posterior approximation that is computationally\nattractive. However, instead of computing the curvature matrix, we show that,\nunder some regularity conditions, the Laplace approximation can be easily\nconstructed using the gradient second moment. This quantity is already\nestimated by many exponential moving average variants of Adagrad such as Adam\nand RMSprop, but is traditionally discarded after training. We show that our\nmethod (L2M) does not require changes in models or optimization, can be\nimplemented in a few lines of code to yield reasonable results, and it does not\nrequire any extra computational steps besides what is already being computed by\noptimizers, without introducing any new hyperparameter. We hope our method can\nopen new research directions on using quantities already computed by optimizers\nfor uncertainty estimation in deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:14:54 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Perone", "Christian S.", ""], ["Silveira", "Roberto Pereira", ""], ["Paula", "Thomas", ""]]}, {"id": "2107.04831", "submitter": "Johann Pfitzinger", "authors": "Johann Pfitzinger", "title": "Cluster Regularization via a Hierarchical Feature Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction tasks with high-dimensional nonorthogonal predictor sets pose a\nchallenge for least squares based fitting procedures. A large and productive\nliterature exists, discussing various regularized approaches to improving the\nout-of-sample robustness of parameter estimates. This paper proposes a novel\ncluster-based regularization - the hierarchical feature regression (HFR) -,\nwhich mobilizes insights from the domains of machine learning and graph theory\nto estimate parameters along a supervised hierarchical representation of the\npredictor set, shrinking parameters towards group targets. The method is\ninnovative in its ability to estimate optimal compositions of predictor groups,\nas well as the group targets endogenously. The HFR can be viewed as a\nsupervised factor regression, with the strength of shrinkage governed by a\npenalty on the extent of idiosyncratic variation captured in the fitting\nprocess. The method demonstrates good predictive accuracy and versatility,\noutperforming a panel of benchmark regularized estimators across a diverse set\nof simulated regression tasks, including dense, sparse and grouped data\ngenerating processes. An application to the prediction of economic growth is\nused to illustrate the HFR's effectiveness in an empirical setting, with\nfavorable comparisons to several frequentist and Bayesian alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 13:03:01 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pfitzinger", "Johann", ""]]}, {"id": "2107.04855", "submitter": "Tongliang Liu", "authors": "Xiaobo Xia, Shuo Shan, Mingming Gong, Nannan Wang, Fei Gao, Haikun\n  Wei, Tongliang Liu", "title": "Kernel Mean Estimation by Marginalized Corrupted Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Estimating the kernel mean in a reproducing kernel Hilbert space is a\ncritical component in many kernel learning algorithms. Given a finite sample,\nthe standard estimate of the target kernel mean is the empirical average.\nPrevious works have shown that better estimators can be constructed by\nshrinkage methods. In this work, we propose to corrupt data examples with noise\nfrom known distributions and present a new kernel mean estimator, called the\nmarginalized kernel mean estimator, which estimates kernel mean under the\ncorrupted distribution. Theoretically, we show that the marginalized kernel\nmean estimator introduces implicit regularization in kernel mean estimation.\nEmpirically, we show on a variety of datasets that the marginalized kernel mean\nestimator obtains much lower estimation error than the existing estimators.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 15:11:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Xia", "Xiaobo", ""], ["Shan", "Shuo", ""], ["Gong", "Mingming", ""], ["Wang", "Nannan", ""], ["Gao", "Fei", ""], ["Wei", "Haikun", ""], ["Liu", "Tongliang", ""]]}, {"id": "2107.05001", "submitter": "Shami Nisimov", "authors": "Shami Nisimov, Yaniv Gurwicz, Raanan Y. Rohekar, Gal Novik", "title": "Improving Efficiency and Accuracy of Causal Discovery Using a\n  Hierarchical Wrapper", "comments": "The 37th Conference on Uncertainty in Artificial Intelligence (UAI\n  2021), Workshop on Tractable Probabilistic Modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from observational data is an important tool in many\nbranches of science. Under certain assumptions it allows scientists to explain\nphenomena, predict, and make decisions. In the large sample limit, sound and\ncomplete causal discovery algorithms have been previously introduced, where a\ndirected acyclic graph (DAG), or its equivalence class, representing causal\nrelations is searched. However, in real-world cases, only finite training data\nis available, which limits the power of statistical tests used by these\nalgorithms, leading to errors in the inferred causal model. This is commonly\naddressed by devising a strategy for using as few as possible statistical\ntests. In this paper, we introduce such a strategy in the form of a recursive\nwrapper for existing constraint-based causal discovery algorithms, which\npreserves soundness and completeness. It recursively clusters the observed\nvariables using the normalized min-cut criterion from the outset, and uses a\nbaseline causal discovery algorithm during backtracking for learning local\nsub-graphs. It then combines them and ensures completeness. By an ablation\nstudy, using synthetic data, and by common real-world benchmarks, we\ndemonstrate that our approach requires significantly fewer statistical tests,\nlearns more accurate graphs, and requires shorter run-times than the baseline\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 09:24:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Nisimov", "Shami", ""], ["Gurwicz", "Yaniv", ""], ["Rohekar", "Raanan Y.", ""], ["Novik", "Gal", ""]]}, {"id": "2107.05134", "submitter": "Carles Domingo-Enrich", "authors": "Carles Domingo-Enrich, Alberto Bietti, Marylou Gabri\\'e, Joan Bruna,\n  Eric Vanden-Eijnden", "title": "Dual Training of Energy-Based Models with Overparametrized Shallow\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs) are generative models that are usually trained via\nmaximum likelihood estimation. This approach becomes challenging in generic\nsituations where the trained energy is nonconvex, due to the need to sample the\nGibbs distribution associated with this energy. Using general Fenchel duality\nresults, we derive variational principles dual to maximum likelihood EBMs with\nshallow overparametrized neural network energies, both in the active (aka\nfeature-learning) and lazy regimes. In the active regime, this dual formulation\nleads to a training algorithm in which one updates concurrently the particles\nin the sample space and the neurons in the parameter space of the energy. We\nalso consider a variant of this algorithm in which the particles are sometimes\nrestarted at random samples drawn from the data set, and show that performing\nthese restarts at every iteration step corresponds to score matching training.\nUsing intermediate parameter setups in our dual algorithm thereby gives a way\nto interpolate between maximum likelihood and score matching training. These\nresults are illustrated in simple numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 21:43:18 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Domingo-Enrich", "Carles", ""], ["Bietti", "Alberto", ""], ["Gabri\u00e9", "Marylou", ""], ["Bruna", "Joan", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "2107.05143", "submitter": "Pierre C. Bellec", "authors": "Pierre C Bellec, Yiwei Shen", "title": "Derivatives and residual distribution of regularized M-estimators with\n  application to adaptive tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies M-estimators with gradient-Lipschitz loss function\nregularized with convex penalty in linear models with Gaussian design matrix\nand arbitrary noise distribution. A practical example is the robust M-estimator\nconstructed with the Huber loss and the Elastic-Net penalty and the noise\ndistribution has heavy-tails. Our main contributions are three-fold. (i) We\nprovide general formulae for the derivatives of regularized M-estimators\n$\\hat\\beta(y,X)$ where differentiation is taken with respect to both $y$ and\n$X$; this reveals a simple differentiability structure shared by all convex\nregularized M-estimators. (ii) Using these derivatives, we characterize the\ndistribution of the residual $r_i = y_i-x_i^\\top\\hat\\beta$ in the intermediate\nhigh-dimensional regime where dimension and sample size are of the same order.\n(iii) Motivated by the distribution of the residuals, we propose a novel\nadaptive criterion to select tuning parameters of regularized M-estimators. The\ncriterion approximates the out-of-sample error up to an additive constant\nindependent of the estimator, so that minimizing the criterion provides a proxy\nfor minimizing the out-of-sample error. The proposed adaptive criterion does\nnot require the knowledge of the noise distribution or of the covariance of the\ndesign. Simulated data confirms the theoretical findings, regarding both the\ndistribution of the residuals and the success of the criterion as a proxy of\nthe out-of-sample error. Finally our results reveal new relationships between\nthe derivatives of $\\hat\\beta(y,X)$ and the effective degrees of freedom of the\nM-estimator, which are of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 23:20:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bellec", "Pierre C", ""], ["Shen", "Yiwei", ""]]}, {"id": "2107.05166", "submitter": "Soham Pal", "authors": "Soham Pal, Yash Gupta, Aditya Kanade, Shirish Shevade", "title": "Stateful Detection of Model Extraction Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-Learning-as-a-Service providers expose machine learning (ML) models\nthrough application programming interfaces (APIs) to developers. Recent work\nhas shown that attackers can exploit these APIs to extract good approximations\nof such ML models, by querying them with samples of their choosing. We propose\nVarDetect, a stateful monitor that tracks the distribution of queries made by\nusers of such a service, to detect model extraction attacks. Harnessing the\nlatent distributions learned by a modified variational autoencoder, VarDetect\nrobustly separates three types of attacker samples from benign samples, and\nsuccessfully raises an alarm for each. Further, with VarDetect deployed as an\nautomated defense mechanism, the extracted substitute models are found to\nexhibit poor performance and transferability, as intended. Finally, we\ndemonstrate that even adaptive attackers with prior knowledge of the deployment\nof VarDetect, are detected by it.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 02:18:26 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pal", "Soham", ""], ["Gupta", "Yash", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""]]}, {"id": "2107.05224", "submitter": "Beng Yee Gan Mr", "authors": "Beng Yee Gan, Daniel Leykam, and Dimitris G. Angelakis", "title": "Fock State-enhanced Expressivity of Quantum Machine Learning Models", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data-embedding process is one of the bottlenecks of quantum machine\nlearning, potentially negating any quantum speedups. In light of this, more\neffective data-encoding strategies are necessary. We propose a photonic-based\nbosonic data-encoding scheme that embeds classical data points using fewer\nencoding layers and circumventing the need for nonlinear optical components by\nmapping the data points into the high-dimensional Fock space. The expressive\npower of the circuit can be controlled via the number of input photons. Our\nwork shed some light on the unique advantages offers by quantum photonics on\nthe expressive power of quantum machine learning models. By leveraging the\nphoton-number dependent expressive power, we propose three different noisy\nintermediate-scale quantum-compatible binary classification methods with\ndifferent scaling of required resources suitable for different supervised\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 07:07:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Gan", "Beng Yee", ""], ["Leykam", "Daniel", ""], ["Angelakis", "Dimitris G.", ""]]}, {"id": "2107.05241", "submitter": "Vinod K Kurmi", "authors": "Blessen George and Vinod K. Kurmi and Vinay P. Namboodiri", "title": "Prb-GAN: A Probabilistic Framework for GAN Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generative adversarial networks (GANs) are very popular to generate realistic\nimages, but they often suffer from the training instability issues and the\nphenomenon of mode loss. In order to attain greater diversity in GAN\nsynthesized data, it is critical to solving the problem of mode loss. Our work\nexplores probabilistic approaches to GAN modelling that could allow us to\ntackle these issues. We present Prb-GANs, a new variation that uses dropout to\ncreate a distribution over the network parameters with the posterior learnt\nusing variational inference. We describe theoretically and validate\nexperimentally using simple and complex datasets the benefits of such an\napproach. We look into further improvements using the concept of uncertainty\nmeasures. Through a set of further modifications to the loss functions for each\nnetwork of the GAN, we are able to get results that show the improvement of GAN\nperformance. Our methods are extremely simple and require very little\nmodification to existing GAN architecture.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:04:13 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["George", "Blessen", ""], ["Kurmi", "Vinod K.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2107.05289", "submitter": "Manjesh Kumar Hanawal", "authors": "Rahul Vaze and Manjesh K. Hanawal", "title": "Continuous Time Bandits With Sampling Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a continuous-time multi-arm bandit problem (CTMAB), where the\nlearner can sample arms any number of times in a given interval and obtain a\nrandom reward from each sample, however, increasing the frequency of sampling\nincurs an additive penalty/cost. Thus, there is a tradeoff between obtaining\nlarge reward and incurring sampling cost as a function of the sampling\nfrequency. The goal is to design a learning algorithm that minimizes regret,\nthat is defined as the difference of the payoff of the oracle policy and that\nof the learning algorithm. CTMAB is fundamentally different than the usual\nmulti-arm bandit problem (MAB), e.g., even the single-arm case is non-trivial\nin CTMAB, since the optimal sampling frequency depends on the mean of the arm,\nwhich needs to be estimated. We first establish lower bounds on the regret\nachievable with any algorithm and then propose algorithms that achieve the\nlower bound up to logarithmic factors. For the single-arm case, we show that\nthe lower bound on the regret is $\\Omega((\\log T)^2/\\mu)$, where $\\mu$ is the\nmean of the arm, and $T$ is the time horizon. For the multiple arms case, we\nshow that the lower bound on the regret is $\\Omega((\\log T)^2 \\mu/\\Delta^2)$,\nwhere $\\mu$ now represents the mean of the best arm, and $\\Delta$ is the\ndifference of the mean of the best and the second-best arm. We then propose an\nalgorithm that achieves the bound up to constant terms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 10:00:35 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Vaze", "Rahul", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2107.05320", "submitter": "Amit Peleg", "authors": "Amit Peleg, Naama Pearl and Ron Meir", "title": "Metalearning Linear Bandits by Prior Update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Bayesian approaches to sequential decision-making assume that problem\nparameters are generated from a known prior, while in practice, such\ninformation is often lacking, and needs to be estimated through learning. This\nproblem is exacerbated in decision-making setups with partial information,\nwhere using a misspecified prior may lead to poor exploration and inferior\nperformance. In this work we prove, in the context of stochastic linear bandits\nand Gaussian priors, that as long as the prior estimate is sufficiently close\nto the true prior, the performance of an algorithm that uses the misspecified\nprior is close to that of the algorithm that uses the true prior. Next, we\naddress the task of learning the prior through metalearning, where a learner\nupdates its estimate of the prior across multiple task instances in order to\nimprove performance on future tasks. The estimated prior is then updated within\neach task based on incoming observations, while actions are selected in order\nto maximize expected reward. In this work we apply this scheme within a linear\nbandit setting, and provide algorithms and regret bounds, demonstrating its\neffectiveness, as compared to an algorithm that knows the correct prior. Our\nresults hold for a broad class of algorithms, including, for example, Thompson\nSampling and Information Directed Sampling.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:17:01 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Peleg", "Amit", ""], ["Pearl", "Naama", ""], ["Meir", "Ron", ""]]}, {"id": "2107.05326", "submitter": "Keisuke Fujii", "authors": "Keisuke Fujii, Naoya Takeishi, Kazushi Tsutsui, Emyo Fujioka, Nozomi\n  Nishiumi, Ryoya Tanaka, Mika Fukushiro, Kaoru Ide, Hiroyoshi Kohno, Ken Yoda,\n  Susumu Takahashi, Shizuko Hiryu, Yoshinobu Kawahara", "title": "Learning interaction rules from multi-animal trajectories via augmented\n  behavioral models", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Extracting the interaction rules of biological agents from moving sequences\npose challenges in various domains. Granger causality is a practical framework\nfor analyzing the interactions from observed time-series data; however, this\nframework ignores the structures of the generative process in animal behaviors,\nwhich may lead to interpretational problems and sometimes erroneous assessments\nof causality. In this paper, we propose a new framework for learning Granger\ncausality from multi-animal trajectories via augmented theory-based behavioral\nmodels with interpretable data-driven models. We adopt an approach for\naugmenting incomplete multi-agent behavioral models described by time-varying\ndynamical systems with neural networks. For efficient and interpretable\nlearning, our model leverages theory-based architectures separating navigation\nand motion processes, and the theory-guided regularization for reliable\nbehavioral modeling. This can provide interpretable signs of Granger-causal\neffects over time, i.e., when specific others cause the approach or separation.\nIn experiments using synthetic datasets, our method achieved better performance\nthan various baselines. We then analyzed multi-animal datasets of mice, flies,\nbirds, and bats, which verified our method and obtained novel biological\ninsights.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:33:56 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 00:49:33 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Fujii", "Keisuke", ""], ["Takeishi", "Naoya", ""], ["Tsutsui", "Kazushi", ""], ["Fujioka", "Emyo", ""], ["Nishiumi", "Nozomi", ""], ["Tanaka", "Ryoya", ""], ["Fukushiro", "Mika", ""], ["Ide", "Kaoru", ""], ["Kohno", "Hiroyoshi", ""], ["Yoda", "Ken", ""], ["Takahashi", "Susumu", ""], ["Hiryu", "Shizuko", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "2107.05328", "submitter": "Xiaofeng Liu", "authors": "YinchuanLi, XiaofengLiu, YunfengShao, QingWang and YanhuiGeng", "title": "Structured Directional Pruning via Perturbation Orthogonal Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured pruning is an effective compression technique to reduce the\ncomputation of neural networks, which is usually achieved by adding\nperturbations to reduce network parameters at the cost of slightly increasing\ntraining loss. A more reasonable approach is to find a sparse minimizer along\nthe flat minimum valley found by optimizers, i.e. stochastic gradient descent,\nwhich keeps the training loss constant. To achieve this goal, we propose the\nstructured directional pruning based on orthogonal projecting the perturbations\nonto the flat minimum valley. We also propose a fast solver sDprun and further\nprove that it achieves directional pruning asymptotically after sufficient\ntraining. Experiments using VGG-Net and ResNet on CIFAR-10 and CIFAR-100\ndatasets show that our method obtains the state-of-the-art pruned accuracy\n(i.e. 93.97% on VGG16, CIFAR-10 task) without retraining. Experiments using\nDNN, VGG-Net and WRN28X10 on MNIST, CIFAR-10 and CIFAR-100 datasets demonstrate\nour method performs structured directional pruning, reaching the same minimum\nvalley as the optimizer.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:35:47 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["YinchuanLi", "", ""], ["XiaofengLiu", "", ""], ["YunfengShao", "", ""], ["QingWang", "", ""], ["YanhuiGeng", "", ""]]}, {"id": "2107.05341", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Csaba Szepesv\\'ari", "title": "Nonparametric Regression with Shallow Overparameterized Neural Networks\n  Trained by GD with Early Stopping", "comments": "COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the ability of overparameterized shallow neural networks to learn\nLipschitz regression functions with and without label noise when trained by\nGradient Descent (GD). To avoid the problem that in the presence of noisy\nlabels, neural networks trained to nearly zero training error are inconsistent\non this class, we propose an early stopping rule that allows us to show optimal\nrates. This provides an alternative to the result of Hu et al. (2021) who\nstudied the performance of $\\ell 2$ -regularized GD for training shallow\nnetworks in nonparametric regression which fully relied on the infinite-width\nnetwork (Neural Tangent Kernel (NTK)) approximation. Here we present a simpler\nanalysis which is based on a partitioning argument of the input space (as in\nthe case of 1-nearest-neighbor rule) coupled with the fact that trained neural\nnetworks are smooth with respect to their inputs when trained by GD. In the\nnoise-free case the proof does not rely on any kernelization and can be\nregarded as a finite-width result. In the case of label noise, by slightly\nmodifying the proof, the noise is controlled using a technique of Yao, Rosasco,\nand Caponnetto (2007).\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:56:53 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2107.05405", "submitter": "Ray Jiang", "authors": "Ray Jiang, Shangtong Zhang, Veronica Chelu, Adam White, Hado van\n  Hasselt", "title": "Learning Expected Emphatic Traces for Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy sampling and experience replay are key for improving sample\nefficiency and scaling model-free temporal difference learning methods. When\ncombined with function approximation, such as neural networks, this combination\nis known as the deadly triad and is potentially unstable. Recently, it has been\nshown that stability and good performance at scale can be achieved by combining\nemphatic weightings and multi-step updates. This approach, however, is\ngenerally limited to sampling complete trajectories in order, to compute the\nrequired emphatic weighting. In this paper we investigate how to combine\nemphatic weightings with non-sequential, off-line data sampled from a replay\nbuffer. We develop a multi-step emphatic weighting that can be combined with\nreplay, and a time-reversed $n$-step TD learning algorithm to learn the\nrequired emphatic weighting. We show that these state weightings reduce\nvariance compared with prior approaches, while providing convergence\nguarantees. We tested the approach at scale on Atari 2600 video games, and\nobserved that the new X-ETD($n$) agent improved over baseline agents,\nhighlighting both the scalability and broad applicability of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:14:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jiang", "Ray", ""], ["Zhang", "Shangtong", ""], ["Chelu", "Veronica", ""], ["White", "Adam", ""], ["van Hasselt", "Hado", ""]]}, {"id": "2107.05446", "submitter": "Cian Eastwood", "authors": "Cian Eastwood, Ian Mason, Christopher K. I. Williams, Bernhard\n  Sch\\\"olkopf", "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature\n  Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source-free domain adaptation (SFDA) aims to adapt a model trained on\nlabelled data in a source domain to unlabelled data in a target domain without\naccess to the source-domain data during adaptation. Existing methods for SFDA\nleverage entropy-minimization techniques which: (i) apply only to\nclassification; (ii) destroy model calibration; and (iii) rely on the source\nmodel achieving a good level of feature-space class-separation in the target\ndomain. We address these issues for a particularly pervasive type of domain\nshift called measurement shift, characterized by a change in measurement system\n(e.g. a change in sensor or lighting). In the source domain, we store a\nlightweight and flexible approximation of the feature distribution under the\nsource data. In the target domain, we adapt the feature-extractor such that the\napproximate feature distribution under the target data realigns with that saved\non the source. We call this method Feature Restoration (FR) as it seeks to\nextract features with the same semantics from the target domain as were\npreviously extracted from the source. We additionally propose Bottom-Up Feature\nRestoration (BUFR), a bottom-up training scheme for FR which boosts performance\nby preserving learnt structure in the later layers of a network. Through\nexperiments we demonstrate that BUFR often outperforms existing SFDA methods in\nterms of accuracy, calibration, and data efficiency, while being less reliant\non the performance of the source model in the target domain.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:21:14 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Eastwood", "Cian", ""], ["Mason", "Ian", ""], ["Williams", "Christopher K. I.", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2107.05481", "submitter": "Jorg Bornschein", "authors": "Jorg Bornschein and Silvia Chiappa and Alan Malek and Rosemary Nan Ke", "title": "Prequential MDL for Causal Structure Learning with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the structure of Bayesian networks and causal relationships from\nobservations is a common goal in several areas of science and technology. We\nshow that the prequential minimum description length principle (MDL) can be\nused to derive a practical scoring function for Bayesian networks when flexible\nand overparametrized neural networks are used to model the conditional\nprobability distributions between observed variables. MDL represents an\nembodiment of Occam's Razor and we obtain plausible and parsimonious graph\nstructures without relying on sparsity inducing priors or other regularizers\nwhich must be tuned. Empirically we demonstrate competitive results on\nsynthetic and real-world data. The score often recovers the correct structure\neven in the presence of strongly nonlinear relationships between variables; a\nscenario were prior approaches struggle and usually fail. Furthermore we\ndiscuss how the the prequential score relates to recent work that infers causal\nstructure from the speed of adaptation when the observations come from a source\nundergoing distributional shift.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 22:35:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bornschein", "Jorg", ""], ["Chiappa", "Silvia", ""], ["Malek", "Alan", ""], ["Ke", "Rosemary Nan", ""]]}, {"id": "2107.05499", "submitter": "Sven Burger", "authors": "Matthias Plock, Sven Burger, Philipp-Immanuel Schneider", "title": "Recent advances in Bayesian optimization with applications to parameter\n  reconstruction in optical nano-metrology", "comments": "Proceedings article, SPIE conference \"Modeling Aspects in Optical\n  Metrology VIII\"", "journal-ref": "Proc. SPIE 11783, 117830J (2021)", "doi": "10.1117/12.2592266", "report-no": null, "categories": "physics.comp-ph physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter reconstruction is a common problem in optical nano metrology. It\ngenerally involves a set of measurements, to which one attempts to fit a\nnumerical model of the measurement process. The model evaluation typically\ninvolves to solve Maxwell's equations and is thus time consuming. This makes\nthe reconstruction computationally demanding. Several methods exist for fitting\nthe model to the measurements. On the one hand, Bayesian optimization methods\nfor expensive black-box optimization enable an efficient reconstruction by\ntraining a machine learning model of the squared sum of deviations. On the\nother hand, curve fitting algorithms, such as the Levenberg-Marquardt method,\ntake the deviations between all model outputs and corresponding measurement\nvalues into account which enables a fast local convergence. In this paper we\npresent a Bayesian Target Vector Optimization scheme which combines these two\napproaches. We compare the performance of the presented method against a\nstandard Levenberg-Marquardt-like algorithm, a conventional Bayesian\noptimization scheme, and the L-BFGS-B and Nelder-Mead simplex algorithms. As a\nstand-in for problems from nano metrology, we employ a non-linear least-square\nproblem from the NIST Standard Reference Database. We find that the presented\nmethod generally uses fewer calls of the model function than any of the\ncompeting schemes to achieve similar reconstruction performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 15:32:15 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Plock", "Matthias", ""], ["Burger", "Sven", ""], ["Schneider", "Philipp-Immanuel", ""]]}, {"id": "2107.05545", "submitter": "Kaixin Wang", "authors": "Kaixin Wang, Kuangqi Zhou, Qixin Zhang, Jie Shao, Bryan Hooi, Jiashi\n  Feng", "title": "Towards Better Laplacian Representation in Reinforcement Learning with\n  Generalized Graph Drawing", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Laplacian representation recently gains increasing attention for\nreinforcement learning as it provides succinct and informative representation\nfor states, by taking the eigenvectors of the Laplacian matrix of the\nstate-transition graph as state embeddings. Such representation captures the\ngeometry of the underlying state space and is beneficial to RL tasks such as\noption discovery and reward shaping. To approximate the Laplacian\nrepresentation in large (or even continuous) state spaces, recent works propose\nto minimize a spectral graph drawing objective, which however has infinitely\nmany global minimizers other than the eigenvectors. As a result, their learned\nLaplacian representation may differ from the ground truth. To solve this\nproblem, we reformulate the graph drawing objective into a generalized form and\nderive a new learning objective, which is proved to have eigenvectors as its\nunique global minimizer. It enables learning high-quality Laplacian\nrepresentations that faithfully approximate the ground truth. We validate this\nvia comprehensive experiments on a set of gridworld and continuous control\nenvironments. Moreover, we show that our learned Laplacian representations lead\nto more exploratory options and better reward shaping.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:14:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Kaixin", ""], ["Zhou", "Kuangqi", ""], ["Zhang", "Qixin", ""], ["Shao", "Jie", ""], ["Hooi", "Bryan", ""], ["Feng", "Jiashi", ""]]}, {"id": "2107.05582", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and Christos Tzamos", "title": "Forster Decomposition and Learning Halfspaces with Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Forster transform is an operation that turns a distribution into one with\ngood anti-concentration properties. While a Forster transform does not always\nexist, we show that any distribution can be efficiently decomposed as a\ndisjoint mixture of few distributions for which a Forster transform exists and\ncan be computed efficiently. As the main application of this result, we obtain\nthe first polynomial-time algorithm for distribution-independent PAC learning\nof halfspaces in the Massart noise model with strongly polynomial sample\ncomplexity, i.e., independent of the bit complexity of the examples. Previous\nalgorithms for this learning problem incurred sample complexity scaling\npolynomially with the bit complexity, even though such a dependence is not\ninformation-theoretically necessary.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:00:59 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Tzamos", "Christos", ""]]}, {"id": "2107.05585", "submitter": "Michael Menart", "authors": "Raef Bassily, Crist\\'obal Guzm\\'an, Michael Menart", "title": "Differentially Private Stochastic Optimization: New Results in Convex\n  and Non-Convex Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study differentially private stochastic optimization in convex and\nnon-convex settings. For the convex case, we focus on the family of non-smooth\ngeneralized linear losses (GLLs). Our algorithm for the $\\ell_2$ setting\nachieves optimal excess population risk in near-linear time, while the best\nknown differentially private algorithms for general convex losses run in\nsuper-linear time. Our algorithm for the $\\ell_1$ setting has nearly-optimal\nexcess population risk $\\tilde{O}\\big(\\sqrt{\\frac{\\log{d}}{n}}\\big)$, and\ncircumvents the dimension dependent lower bound of [AFKT21] for general\nnon-smooth convex losses. In the differentially private non-convex setting, we\nprovide several new algorithms for approximating stationary points of the\npopulation risk. For the $\\ell_1$-case with smooth losses and polyhedral\nconstraint, we provide the first nearly dimension independent rate, $\\tilde\nO\\big(\\frac{\\log^{2/3}{d}}{{n^{1/3}}}\\big)$ in linear time. For the constrained\n$\\ell_2$-case, with smooth losses, we obtain a linear-time algorithm with rate\n$\\tilde O\\big(\\frac{1}{n^{3/10}d^{1/10}}+\\big(\\frac{d}{n^2}\\big)^{1/5}\\big)$.\nFinally, for the $\\ell_2$-case we provide the first method for {\\em non-smooth\nweakly convex} stochastic optimization with rate $\\tilde\nO\\big(\\frac{1}{n^{1/4}}+\\big(\\frac{d}{n^2}\\big)^{1/6}\\big)$ which matches the\nbest existing non-private algorithm when $d= O(\\sqrt{n})$. We also extend all\nour results above for the non-convex $\\ell_2$ setting to the $\\ell_p$ setting,\nwhere $1 < p \\leq 2$, with only polylogarithmic (in the dimension) overhead in\nthe rates.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:06:08 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 18:24:17 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bassily", "Raef", ""], ["Guzm\u00e1n", "Crist\u00f3bal", ""], ["Menart", "Michael", ""]]}, {"id": "2107.05598", "submitter": "Johannes Brust", "authors": "Johannes J. Brust", "title": "Nonlinear Least Squares for Large-Scale Machine Learning using\n  Stochastic Jacobian Estimates", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For large nonlinear least squares loss functions in machine learning we\nexploit the property that the number of model parameters typically exceeds the\ndata in one batch. This implies a low-rank structure in the Hessian of the\nloss, which enables effective means to compute search directions. Using this\nproperty, we develop two algorithms that estimate Jacobian matrices and perform\nwell when compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:29:08 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Brust", "Johannes J.", ""]]}, {"id": "2107.05680", "submitter": "Arda Sahiner", "authors": "Arda Sahiner, Tolga Ergen, Batu Ozturkler, Burak Bartan, John Pauly,\n  Morteza Mardani, Mert Pilanci", "title": "Hidden Convexity of Wasserstein GANs: Interpretable Generative Models\n  with Closed-Form Solutions", "comments": "First two authors contributed equally to this work; 30 pages, 11\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) are commonly used for modeling complex\ndistributions of data. Both the generators and discriminators of GANs are often\nmodeled by neural networks, posing a non-transparent optimization problem which\nis non-convex and non-concave over the generator and discriminator,\nrespectively. Such networks are often heuristically optimized with gradient\ndescent-ascent (GDA), but it is unclear whether the optimization problem\ncontains any saddle points, or whether heuristic methods can find them in\npractice. In this work, we analyze the training of Wasserstein GANs with\ntwo-layer neural network discriminators through the lens of convex duality, and\nfor a variety of generators expose the conditions under which Wasserstein GANs\ncan be solved exactly with convex optimization approaches, or can be\nrepresented as convex-concave games. Using this convex duality interpretation,\nwe further demonstrate the impact of different activation functions of the\ndiscriminator. Our observations are verified with numerical results\ndemonstrating the power of the convex interpretation, with applications in\nprogressive training of convex architectures corresponding to linear generators\nand quadratic-activation discriminators for CelebA image generation. The code\nfor our experiments is available at https://github.com/ardasahiner/ProCoGAN.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:33:49 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Sahiner", "Arda", ""], ["Ergen", "Tolga", ""], ["Ozturkler", "Batu", ""], ["Bartan", "Burak", ""], ["Pauly", "John", ""], ["Mardani", "Morteza", ""], ["Pilanci", "Mert", ""]]}, {"id": "2107.05682", "submitter": "Angelica Louren\\c{c}o Oliveira", "authors": "Angelica Louren\\c{c}o Oliveira and Marcos Eduardo Valle", "title": "Least-Squares Linear Dilation-Erosion Regressor Trained using Stochastic\n  Descent Gradient or the Difference of Convex Methods", "comments": "15 pages", "journal-ref": "BRACIS 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hybrid morphological neural network for regression\ntasks called linear dilation-erosion regression ($\\ell$-DER). In few words, an\n$\\ell$-DER model is given by a convex combination of the composition of linear\nand elementary morphological operators. As a result, they yield continuous\npiecewise linear functions and, thus, are universal approximators. Apart from\nintroducing the $\\ell$-DER models, we present three approaches for training\nthese models: one based on stochastic descent gradient and two based on the\ndifference of convex programming problems. Finally, we evaluate the performance\nof the $\\ell$-DER model using 14 regression tasks. Although the approach based\non SDG revealed faster than the other two, the $\\ell$-DER trained using a\ndisciplined convex-concave programming problem outperformed the others in terms\nof the least mean absolute error score.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:41:59 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Oliveira", "Angelica Louren\u00e7o", ""], ["Valle", "Marcos Eduardo", ""]]}, {"id": "2107.05686", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Frederik Tr\\\"auble, Manuel W\\\"uthrich, Felix Widmaier,\n  Peter Gehler, Ole Winther, Francesco Locatello, Olivier Bachem, Bernhard\n  Sch\\\"olkopf, Stefan Bauer", "title": "Representation Learning for Out-Of-Distribution Generalization in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning data representations that are useful for various downstream tasks is\na cornerstone of artificial intelligence. While existing methods are typically\nevaluated on downstream tasks such as classification or generative image\nquality, we propose to assess representations through their usefulness in\ndownstream control tasks, such as reaching or pushing objects. By training over\n10,000 reinforcement learning policies, we extensively evaluate to what extent\ndifferent representation properties affect out-of-distribution (OOD)\ngeneralization. Finally, we demonstrate zero-shot transfer of these policies\nfrom simulation to the real world, without any domain randomization or\nfine-tuning. This paper aims to establish the first systematic characterization\nof the usefulness of learned representations for real-world OOD downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:49:48 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dittadi", "Andrea", ""], ["Tr\u00e4uble", "Frederik", ""], ["W\u00fcthrich", "Manuel", ""], ["Widmaier", "Felix", ""], ["Gehler", "Peter", ""], ["Winther", "Ole", ""], ["Locatello", "Francesco", ""], ["Bachem", "Olivier", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "2107.05719", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao, Michael P. Kim, Roshni Sahoo, Tengyu Ma, Stefano Ermon", "title": "Calibrating Predictions to Decisions: A Novel Approach to Multi-Class\n  Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When facing uncertainty, decision-makers want predictions they can trust. A\nmachine learning provider can convey confidence to decision-makers by\nguaranteeing their predictions are distribution calibrated -- amongst the\ninputs that receive a predicted class probabilities vector $q$, the actual\ndistribution over classes is $q$. For multi-class prediction problems, however,\nachieving distribution calibration tends to be infeasible, requiring sample\ncomplexity exponential in the number of classes $C$. In this work, we introduce\na new notion -- \\emph{decision calibration} -- that requires the predicted\ndistribution and true distribution to be ``indistinguishable'' to a set of\ndownstream decision-makers. When all possible decision makers are under\nconsideration, decision calibration is the same as distribution calibration.\nHowever, when we only consider decision makers choosing between a bounded\nnumber of actions (e.g. polynomial in $C$), our main result shows that\ndecisions calibration becomes feasible -- we design a recalibration algorithm\nthat requires sample complexity polynomial in the number of actions and the\nnumber of classes. We validate our recalibration algorithm empirically:\ncompared to existing methods, decision calibration improves decision-making on\nskin lesion and ImageNet classification with modern neural network predictors.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:17:28 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhao", "Shengjia", ""], ["Kim", "Michael P.", ""], ["Sahoo", "Roshni", ""], ["Ma", "Tengyu", ""], ["Ermon", "Stefano", ""]]}, {"id": "2107.05745", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Claudio Gentile and Mehryar Mohri and Julian\n  Zimmert", "title": "Adapting to Misspecification in Contextual Bandits", "comments": "Appeared at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major research direction in contextual bandits is to develop algorithms\nthat are computationally efficient, yet support flexible, general-purpose\nfunction approximation. Algorithms based on modeling rewards have shown strong\nempirical performance, but typically require a well-specified model, and can\nfail when this assumption does not hold. Can we design algorithms that are\nefficient and flexible, yet degrade gracefully in the face of model\nmisspecification? We introduce a new family of oracle-efficient algorithms for\n$\\varepsilon$-misspecified contextual bandits that adapt to unknown model\nmisspecification -- both for finite and infinite action settings. Given access\nto an online oracle for square loss regression, our algorithm attains optimal\nregret and -- in particular -- optimal dependence on the misspecification\nlevel, with no prior knowledge. Specializing to linear contextual bandits with\ninfinite actions in $d$ dimensions, we obtain the first algorithm that achieves\nthe optimal $O(d\\sqrt{T} + \\varepsilon\\sqrt{d}T)$ regret bound for unknown\nmisspecification level $\\varepsilon$.\n  On a conceptual level, our results are enabled by a new optimization-based\nperspective on the regression oracle reduction framework of Foster and Rakhlin,\nwhich we anticipate will find broader use.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:30:41 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Foster", "Dylan J.", ""], ["Gentile", "Claudio", ""], ["Mohri", "Mehryar", ""], ["Zimmert", "Julian", ""]]}, {"id": "2107.05766", "submitter": "Xin Bing", "authors": "Xin Bing and Florentina Bunea and Seth Strimas-Mackey and Marten\n  Wegkamp", "title": "Likelihood estimation of sparse topic distributions in topic models and\n  its applications to Wasserstein document distance calculations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the estimation of high-dimensional, discrete, possibly\nsparse, mixture models in topic models. The data consists of observed\nmultinomial counts of $p$ words across $n$ independent documents. In topic\nmodels, the $p\\times n$ expected word frequency matrix is assumed to be\nfactorized as a $p\\times K$ word-topic matrix $A$ and a $K\\times n$\ntopic-document matrix $T$. Since columns of both matrices represent conditional\nprobabilities belonging to probability simplices, columns of $A$ are viewed as\n$p$-dimensional mixture components that are common to all documents while\ncolumns of $T$ are viewed as the $K$-dimensional mixture weights that are\ndocument specific and are allowed to be sparse. The main interest is to provide\nsharp, finite sample, $\\ell_1$-norm convergence rates for estimators of the\nmixture weights $T$ when $A$ is either known or unknown. For known $A$, we\nsuggest MLE estimation of $T$. Our non-standard analysis of the MLE not only\nestablishes its $\\ell_1$ convergence rate, but reveals a remarkable property:\nthe MLE, with no extra regularization, can be exactly sparse and contain the\ntrue zero pattern of $T$. We further show that the MLE is both minimax optimal\nand adaptive to the unknown sparsity in a large class of sparse topic\ndistributions. When $A$ is unknown, we estimate $T$ by optimizing the\nlikelihood function corresponding to a plug in, generic, estimator $\\hat{A}$ of\n$A$. For any estimator $\\hat{A}$ that satisfies carefully detailed conditions\nfor proximity to $A$, the resulting estimator of $T$ is shown to retain the\nproperties established for the MLE. The ambient dimensions $K$ and $p$ are\nallowed to grow with the sample sizes. Our application is to the estimation of\n1-Wasserstein distances between document generating distributions. We propose,\nestimate and analyze new 1-Wasserstein distances between two probabilistic\ndocument representations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:22:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bing", "Xin", ""], ["Bunea", "Florentina", ""], ["Strimas-Mackey", "Seth", ""], ["Wegkamp", "Marten", ""]]}, {"id": "2107.05802", "submitter": "Brett Larsen", "authors": "Brett W. Larsen, Stanislav Fort, Nic Becker, Surya Ganguli", "title": "How many degrees of freedom do we need to train deep networks: a loss\n  landscape perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A variety of recent works, spanning pruning, lottery tickets, and training\nwithin random subspaces, have shown that deep neural networks can be trained\nusing far fewer degrees of freedom than the total number of parameters. We\nexplain this phenomenon by first examining the success probability of hitting a\ntraining loss sub-level set when training within a random subspace of a given\ntraining dimensionality. We find a sharp phase transition in the success\nprobability from $0$ to $1$ as the training dimension surpasses a threshold.\nThis threshold training dimension increases as the desired final loss\ndecreases, but decreases as the initial loss decreases. We then theoretically\nexplain the origin of this phase transition, and its dependence on\ninitialization and final desired loss, in terms of precise properties of the\nhigh dimensional geometry of the loss landscape. In particular, we show via\nGordon's escape theorem, that the training dimension plus the Gaussian width of\nthe desired loss sub-level set, projected onto a unit sphere surrounding the\ninitialization, must exceed the total number of parameters for the success\nprobability to be large. In several architectures and datasets, we measure the\nthreshold training dimension as a function of initialization and demonstrate\nthat it is a small fraction of the total number of parameters, thereby\nimplying, by our theory, that successful training with so few dimensions is\npossible precisely because the Gaussian width of low loss sub-level sets is\nvery large. Moreover, this threshold training dimension provides a strong null\nmodel for assessing the efficacy of more sophisticated ways to reduce training\ndegrees of freedom, including lottery tickets as well a more optimal method we\nintroduce: lottery subspaces.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 01:29:24 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Larsen", "Brett W.", ""], ["Fort", "Stanislav", ""], ["Becker", "Nic", ""], ["Ganguli", "Surya", ""]]}, {"id": "2107.05834", "submitter": "Jingyi Zhang", "authors": "Jingyi Zhang and Xiaoxiao Sun", "title": "Oversampling Divide-and-conquer for Response-skewed Kernel Ridge\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The divide-and-conquer method has been widely used for estimating large-scale\nkernel ridge regression estimates. Unfortunately, when the response variable is\nhighly skewed, the divide-and-conquer kernel ridge regression (dacKRR) may\noverlook the underrepresented region and result in unacceptable results. We\ndevelop a novel response-adaptive partition strategy to overcome the\nlimitation. In particular, we propose to allocate the replicates of some\ncarefully identified informative observations to multiple nodes (local\nprocessors). The idea is analogous to the popular oversampling technique.\nAlthough such a technique has been widely used for addressing discrete label\nskewness, extending it to the dacKRR setting is nontrivial. We provide both\ntheoretical and practical guidance on how to effectively over-sample the\nobservations under the dacKRR setting. Furthermore, we show the proposed\nestimate has a smaller asymptotic mean squared error (AMSE) than that of the\nclassical dacKRR estimate under mild conditions. Our theoretical findings are\nsupported by both simulated and real-data analyses.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 04:01:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhang", "Jingyi", ""], ["Sun", "Xiaoxiao", ""]]}, {"id": "2107.05847", "submitter": "Martin Binder", "authors": "Bernd Bischl, Martin Binder, Michel Lang, Tobias Pielok, Jakob\n  Richter, Stefan Coors, Janek Thomas, Theresa Ullmann, Marc Becker, Anne-Laure\n  Boulesteix, Difan Deng, Marius Lindauer", "title": "Hyperparameter Optimization: Foundations, Algorithms, Best Practices and\n  Open Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most machine learning algorithms are configured by one or several\nhyperparameters that must be carefully chosen and often considerably impact\nperformance. To avoid a time consuming and unreproducible manual\ntrial-and-error process to find well-performing hyperparameter configurations,\nvarious automatic hyperparameter optimization (HPO) methods, e.g., based on\nresampling error estimation for supervised machine learning, can be employed.\nAfter introducing HPO from a general perspective, this paper reviews important\nHPO methods such as grid or random search, evolutionary algorithms, Bayesian\noptimization, Hyperband and racing. It gives practical recommendations\nregarding important choices to be made when conducting HPO, including the HPO\nalgorithms themselves, performance evaluation, how to combine HPO with ML\npipelines, runtime improvements, and parallelization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 04:55:47 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 22:34:27 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Bischl", "Bernd", ""], ["Binder", "Martin", ""], ["Lang", "Michel", ""], ["Pielok", "Tobias", ""], ["Richter", "Jakob", ""], ["Coors", "Stefan", ""], ["Thomas", "Janek", ""], ["Ullmann", "Theresa", ""], ["Becker", "Marc", ""], ["Boulesteix", "Anne-Laure", ""], ["Deng", "Difan", ""], ["Lindauer", "Marius", ""]]}, {"id": "2107.05849", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh, Sayak Ray Chowdhury and Kannan Ramchandran", "title": "Model Selection with Near Optimal Rates for Reinforcement Learning with\n  General Model Classes", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of model selection for the finite horizon episodic\nReinforcement Learning (RL) problem where the transition kernel $P^*$ belongs\nto a family of models $\\mathcal{P}^*$ with finite metric entropy. In the model\nselection framework, instead of $\\mathcal{P}^*$, we are given $M$ nested\nfamilies of transition kernels $\\cP_1 \\subset \\cP_2 \\subset \\ldots \\subset\n\\cP_M$. We propose and analyze a novel algorithm, namely \\emph{Adaptive\nReinforcement Learning (General)} (\\texttt{ARL-GEN}) that adapts to the\nsmallest such family where the true transition kernel $P^*$ lies.\n\\texttt{ARL-GEN} uses the Upper Confidence Reinforcement Learning\n(\\texttt{UCRL}) algorithm with value targeted regression as a blackbox and puts\na model selection module at the beginning of each epoch. Under a mild\nseparability assumption on the model classes, we show that \\texttt{ARL-GEN}\nobtains a regret of\n$\\Tilde{\\mathcal{O}}(d_{\\mathcal{E}}^*H^2+\\sqrt{d_{\\mathcal{E}}^* \\mathbb{M}^*\nH^2 T})$, with high probability, where $H$ is the horizon length, $T$ is the\ntotal number of steps, $d_{\\mathcal{E}}^*$ is the Eluder dimension and\n$\\mathbb{M}^*$ is the metric entropy corresponding to $\\mathcal{P}^*$. Note\nthat this regret scaling matches that of an oracle that knows $\\mathcal{P}^*$\nin advance. We show that the cost of model selection for \\texttt{ARL-GEN} is an\nadditive term in the regret having a weak dependence on $T$. Subsequently, we\nremove the separability assumption and consider the setup of linear mixture\nMDPs, where the transition kernel $P^*$ has a linear function approximation.\nWith this low rank structure, we propose novel adaptive algorithms for model\nselection, and obtain (order-wise) regret identical to that of an oracle with\nknowledge of the true model class.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 05:00:38 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ghosh", "Avishek", ""], ["Chowdhury", "Sayak Ray", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2107.05911", "submitter": "Yang Liu", "authors": "Yang Liu, Yatong Chen, Jiaheng Wei", "title": "Induced Domain Adaptation", "comments": "Preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We formulate the problem of induced domain adaptation (IDA) when the\nunderlying distribution/domain shift is introduced by the model being deployed.\nOur formulation is motivated by applications where the deployed machine\nlearning models interact with human agents, and will ultimately face responsive\nand interactive data distributions. We formalize the discussions of the\ntransferability of learning in our IDA setting by studying how the model\ntrained on the available source distribution (data) would translate to the\nperformance on the induced domain. We provide both upper bounds for the\nperformance gap due to the induced domain shift, as well as lower bound for the\ntrade-offs a classifier has to suffer on either the source training\ndistribution or the induced target distribution. We provide further\ninstantiated analysis for two popular domain adaptation settings with covariate\nshift and label shift. We highlight some key properties of IDA, as well as\ncomputational and learning challenges.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:21:37 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Yatong", ""], ["Wei", "Jiaheng", ""]]}, {"id": "2107.05913", "submitter": "Yang Liu", "authors": "Yang Liu and Jialu Wang", "title": "Can Less be More? When Increasing-to-Balancing Label Noise Rates\n  Considered Beneficial", "comments": "Preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we answer the question when inserting label noise (less\ninformative labels) can instead return us more accurate and fair models. We are\nprimarily inspired by two observations that 1) increasing a certain class of\ninstances' label noise to balance the noise rates (increasing-to-balancing)\nresults in an easier learning problem; 2) Increasing-to-balancing improves\nfairness guarantees against label bias. In this paper, we will first quantify\nthe trade-offs introduced by increasing a certain group of instances' label\nnoise rate w.r.t. the learning difficulties and performance guarantees. We\nanalytically demonstrate when such an increase proves to be beneficial, in\nterms of either improved generalization errors or the fairness guarantees. Then\nwe present a method to leverage our idea of inserting label noise for the task\nof learning with noisy labels, either without or with a fairness constraint.\nThe primary technical challenge we face is due to the fact that we would not\nknow which data instances are suffering from higher noise, and we would not\nhave the ground truth labels to verify any possible hypothesis. We propose a\ndetection method that informs us which group of labels might suffer from higher\nnoise, without using ground truth information. We formally establish the\neffectiveness of the proposed solution and demonstrate it with extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:31:57 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Liu", "Yang", ""], ["Wang", "Jialu", ""]]}, {"id": "2107.05984", "submitter": "Fernando Moreno-Pino", "authors": "Fernando Moreno-Pino, Pablo M. Olmos and Antonio Art\\'es-Rodr\\'iguez", "title": "Deep Autoregressive Models with Spectral Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is an important problem across many domains, playing\na crucial role in multiple real-world applications. In this paper, we propose a\nforecasting architecture that combines deep autoregressive models with a\nSpectral Attention (SA) module, which merges global and local frequency domain\ninformation in the model's embedded space. By characterizing in the spectral\ndomain the embedding of the time series as occurrences of a random process, our\nmethod can identify global trends and seasonality patterns. Two spectral\nattention models, global and local to the time series, integrate this\ninformation within the forecast and perform spectral filtering to remove time\nseries's noise. The proposed architecture has a number of useful properties: it\ncan be effectively incorporated into well-know forecast architectures,\nrequiring a low number of parameters and producing interpretable results that\nimprove forecasting accuracy. We test the Spectral Attention Autoregressive\nModel (SAAM) on several well-know forecast datasets, consistently demonstrating\nthat our model compares favorably to state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:08:47 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Moreno-Pino", "Fernando", ""], ["Olmos", "Pablo M.", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "2107.05997", "submitter": "Sebastian P\\\"olsterl", "authors": "Sebastian P\\\"olsterl and Christina Aigner and Christian Wachinger", "title": "Scalable, Axiomatic Explanations of Deep Alzheimer's Diagnosis from\n  Heterogeneous Data", "comments": "Accepted at 2021 International Conference on Medical Image Computing\n  and Computer Assisted Intervention (MICCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have an enormous potential to learn from complex\nbiomedical data. In particular, DNNs have been used to seamlessly fuse\nheterogeneous information from neuroanatomy, genetics, biomarkers, and\nneuropsychological tests for highly accurate Alzheimer's disease diagnosis. On\nthe other hand, their black-box nature is still a barrier for the adoption of\nsuch a system in the clinic, where interpretability is absolutely essential. We\npropose Shapley Value Explanation of Heterogeneous Neural Networks (SVEHNN) for\nexplaining the Alzheimer's diagnosis made by a DNN from the 3D point cloud of\nthe neuroanatomy and tabular biomarkers. Our explanations are based on the\nShapley value, which is the unique method that satisfies all fundamental axioms\nfor local explanations previously established in the literature. Thus, SVEHNN\nhas many desirable characteristics that previous work on interpretability for\nmedical decision making is lacking. To avoid the exponential time complexity of\nthe Shapley value, we propose to transform a given DNN into a Lightweight\nProbabilistic Deep Network without re-training, thus achieving a complexity\nonly quadratic in the number of features. In our experiments on synthetic and\nreal data, we show that we can closely approximate the exact Shapley value with\na dramatically reduced runtime and can reveal the hidden knowledge the network\nhas learned from the data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:25:54 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["P\u00f6lsterl", "Sebastian", ""], ["Aigner", "Christina", ""], ["Wachinger", "Christian", ""]]}, {"id": "2107.06006", "submitter": "Julien Bect", "authors": "S\\'ebastien Petit (L2S, GdR MASCOT-NUM), Julien Bect (L2S, GdR\n  MASCOT-NUM), Paul Feliot, Emmanuel Vazquez (L2S, GdR MASCOT-NUM)", "title": "Gaussian process interpolation: the choice of the family of models is\n  more important than that of the selection criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article revisits the fundamental problem of parameter selection for\nGaussian process interpolation. By choosing the mean and the covariance\nfunctions of a Gaussian process within parametric families, the user obtains a\nfamily of Bayesian procedures to perform predictions about the unknown\nfunction, and must choose a member of the family that will hopefully provide\ngood predictive performances. We base our study on the general concept of\nscoring rules, which provides an effective framework for building leave-one-out\nselection and validation criteria, and a notion of extended likelihood criteria\nbased on an idea proposed by Fasshauer and co-authors in 2009, which makes it\npossible to recover standard selection criteria such as, for instance, the\ngeneralized cross-validation criterion. Under this setting, we empirically show\non several test problems of the literature that the choice of an appropriate\nfamily of models is often more important than the choice of a particular\nselection criterion (e.g., the likelihood versus a leave-one-out selection\ncriterion). Moreover, our numerical results show that the regularity parameter\nof a Mat{\\'e}rn covariance can be selected effectively by most selection\ncriteria.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:57:56 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Petit", "S\u00e9bastien", "", "L2S, GdR MASCOT-NUM"], ["Bect", "Julien", "", "L2S, GdR\n  MASCOT-NUM"], ["Feliot", "Paul", "", "L2S, GdR MASCOT-NUM"], ["Vazquez", "Emmanuel", "", "L2S, GdR MASCOT-NUM"]]}, {"id": "2107.06008", "submitter": "Samuel Rikli", "authors": "Rikli Samuel, Bigler Daniel Nico, Pfenninger Moritz, Osterrieder Joerg", "title": "Wasserstein GAN: Deep Generation applied on Bitcoins financial time\n  series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling financial time series is challenging due to their high volatility\nand unexpected happenings on the market. Most financial models and algorithms\ntrying to fill the lack of historical financial time series struggle to perform\nand are highly vulnerable to overfitting. As an alternative, we introduce in\nthis paper a deep neural network called the WGAN-GP, a data-driven model that\nfocuses on sample generation. The WGAN-GP consists of a generator and\ndiscriminator function which utilize an LSTM architecture. The WGAN-GP is\nsupposed to learn the underlying structure of the input data, which in our\ncase, is the Bitcoin. Bitcoin is unique in its behavior; the prices fluctuate\nwhat makes guessing the price trend hardly impossible. Through adversarial\ntraining, the WGAN-GP should learn the underlying structure of the bitcoin and\ngenerate very similar samples of the bitcoin distribution. The generated\nsynthetic time series are visually indistinguishable from the real data. But\nthe numerical results show that the generated data were close to the real data\ndistribution but distinguishable. The model mainly shows a stable learning\nbehavior. However, the model has space for optimization, which could be\nachieved by adjusting the hyperparameters.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:59:05 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Samuel", "Rikli", ""], ["Nico", "Bigler Daniel", ""], ["Moritz", "Pfenninger", ""], ["Joerg", "Osterrieder", ""]]}, {"id": "2107.06068", "submitter": "Jonas Busk", "authors": "Jonas Busk, Peter Bj{\\o}rn J{\\o}rgensen, Arghya Bhowmik, Mikkel N.\n  Schmidt, Ole Winther, Tejs Vegge", "title": "Calibrated Uncertainty for Molecular Property Prediction using Ensembles\n  of Message Passing Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven methods based on machine learning have the potential to\naccelerate analysis of atomic structures. However, machine learning models can\nproduce overconfident predictions and it is therefore crucial to detect and\nhandle uncertainty carefully. Here, we extend a message passing neural network\ndesigned specifically for predicting properties of molecules and materials with\na calibrated probabilistic predictive distribution. The method presented in\nthis paper differs from the previous work by considering both aleatoric and\nepistemic uncertainty in a unified framework, and by re-calibrating the\npredictive distribution on unseen data. Through computer experiments, we show\nthat our approach results in accurate models for predicting molecular formation\nenergies with calibrated uncertainty in and out of the training data\ndistribution on two public molecular benchmark datasets, QM9 and PC9. The\nproposed method provides a general framework for training and evaluating neural\nnetwork ensemble models that are able to produce accurate predictions of\nproperties of molecules with calibrated uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:28:11 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Busk", "Jonas", ""], ["J\u00f8rgensen", "Peter Bj\u00f8rn", ""], ["Bhowmik", "Arghya", ""], ["Schmidt", "Mikkel N.", ""], ["Winther", "Ole", ""], ["Vegge", "Tejs", ""]]}, {"id": "2107.06207", "submitter": "Alexander Scheinker", "authors": "Alexander Scheinker", "title": "Adaptive Machine Learning for Time-Varying Systems: Low Dimensional\n  Latent Space Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.acc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) tools such as encoder-decoder convolutional neural\nnetworks (CNN) can represent incredibly complex nonlinear functions which map\nbetween combinations of images and scalars. For example, CNNs can be used to\nmap combinations of accelerator parameters and images which are 2D projections\nof the 6D phase space distributions of charged particle beams as they are\ntransported between various particle accelerator locations. Despite their\nstrengths, applying ML to time-varying systems, or systems with shifting\ndistributions, is an open problem, especially for large systems for which\ncollecting new data for re-training is impractical or interrupts operations.\nParticle accelerators are one example of large time-varying systems for which\ncollecting detailed training data requires lengthy dedicated beam measurements\nwhich may no longer be available during regular operations. We present a\nrecently developed method of adaptive ML for time-varying systems. Our approach\nis to map very high (N>100k) dimensional inputs (a combination of scalar\nparameters and images) into the low dimensional (N~2) latent space at the\noutput of the encoder section of an encoder-decoder CNN. We then actively tune\nthe low dimensional latent space-based representation of complex system\ndynamics by the addition of an adaptively tuned feedback vector directly before\nthe decoder sections builds back up to our image-based high-dimensional phase\nspace density representations. This method allows us to learn correlations\nwithin and to quickly tune the characteristics of incredibly high parameter\nsystems and to track their evolution in real time based on feedback without\nmassive new data sets for re-training.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:05:28 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Scheinker", "Alexander", ""]]}, {"id": "2107.06226", "submitter": "Masatoshi Uehara", "authors": "Masatoshi Uehara, Wen Sun", "title": "Pessimistic Model-based Offline RL: PAC Bounds and Posterior Sampling\n  under Partial Coverage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study model-based offline Reinforcement Learning with general function\napproximation. We present an algorithm named Constrained Pessimistic Policy\nOptimization (CPPO) which leverages a general function class and uses a\nconstraint to encode pessimism. Under the assumption that the ground truth\nmodel belongs to our function class, CPPO can learn with the offline data only\nproviding partial coverage, i.e., it can learn a policy that completes against\nany policy that is covered by the offline data, in polynomial sample complexity\nwith respect to the statistical complexity of the function class. We then\ndemonstrate that this algorithmic framework can be applied to many specialized\nMarkov Decision Processes where the additional structural assumptions can\nfurther refine the concept of partial coverage. One notable example is low-rank\nMDP with representation learning where the partial coverage is defined using\nthe concept of relative condition number measured by the underlying unknown\nground truth feature representation. Finally, we introduce and study the\nBayesian setting in offline RL. The key benefit of Bayesian offline RL is that\nalgorithmically, we do not need to explicitly construct pessimism or reward\npenalty which could be hard beyond models with linear structures. We present a\nposterior sampling-based incremental policy optimization algorithm (PS-PO)\nwhich proceeds by iteratively sampling a model from the posterior distribution\nand performing one-step incremental policy optimization inside the sampled\nmodel. Theoretically, in expectation with respect to the prior distribution,\nPS-PO can learn a near optimal policy under partial coverage with polynomial\nsample complexity.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:30:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Uehara", "Masatoshi", ""], ["Sun", "Wen", ""]]}, {"id": "2107.06239", "submitter": "Srikrishna Karanam", "authors": "Ren Li and Meng Zheng and Srikrishna Karanam and Terrence Chen and\n  Ziyan Wu", "title": "Everybody Is Unique: Towards Unbiased Human Mesh Recovery", "comments": "10 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of obese human mesh recovery, i.e., fitting a\nparametric human mesh to images of obese people. Despite obese person mesh\nfitting being an important problem with numerous applications (e.g.,\nhealthcare), much recent progress in mesh recovery has been restricted to\nimages of non-obese people. In this work, we identify this crucial gap in the\ncurrent literature by presenting and discussing limitations of existing\nalgorithms. Next, we present a simple baseline to address this problem that is\nscalable and can be easily used in conjunction with existing algorithms to\nimprove their performance. Finally, we present a generalized human mesh\noptimization algorithm that substantially improves the performance of existing\nmethods on both obese person images as well as community-standard benchmark\ndatasets. A key innovation of this technique is that it does not rely on\nsupervision from expensive-to-create mesh parameters. Instead, starting from\nwidely and cheaply available 2D keypoints annotations, our method automatically\ngenerates mesh parameters that can in turn be used to re-train and fine-tune\nany existing mesh estimation algorithm. This way, we show our method acts as a\ndrop-in to improve the performance of a wide variety of contemporary mesh\nestimation methods. We conduct extensive experiments on multiple datasets\ncomprising both standard and obese person images and demonstrate the efficacy\nof our proposed techniques.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:52:55 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Ren", ""], ["Zheng", "Meng", ""], ["Karanam", "Srikrishna", ""], ["Chen", "Terrence", ""], ["Wu", "Ziyan", ""]]}, {"id": "2107.06259", "submitter": "Wenshuo Guo", "authors": "Wenshuo Guo, Michael I. Jordan, Manolis Zampetakis", "title": "Robust Learning of Optimal Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning revenue-optimal multi-bidder auctions from\nsamples when the samples of bidders' valuations can be adversarially corrupted\nor drawn from distributions that are adversarially perturbed. First, we prove\ntight upper bounds on the revenue we can obtain with a corrupted distribution\nunder a population model, for both regular valuation distributions and\ndistributions with monotone hazard rate (MHR). We then propose new algorithms\nthat, given only an ``approximate distribution'' for the bidder's valuation,\ncan learn a mechanism whose revenue is nearly optimal simultaneously for all\n``true distributions'' that are $\\alpha$-close to the original distribution in\nKolmogorov-Smirnov distance. The proposed algorithms operate beyond the setting\nof bounded distributions that have been studied in prior works, and are\nguaranteed to obtain a fraction $1-O(\\alpha)$ of the optimal revenue under the\ntrue distribution when the distributions are MHR. Moreover, they are guaranteed\nto yield at least a fraction $1-O(\\sqrt{\\alpha})$ of the optimal revenue when\nthe distributions are regular. We prove that these upper bounds cannot be\nfurther improved, by providing matching lower bounds. Lastly, we derive sample\ncomplexity upper bounds for learning a near-optimal auction for both MHR and\nregular distributions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:37:21 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Guo", "Wenshuo", ""], ["Jordan", "Michael I.", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "2107.06268", "submitter": "Florian Ziel", "authors": "Florian Ziel", "title": "Smoothed Bernstein Online Aggregation for Day-Ahead Electricity Demand\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a winning method of the IEEE DataPort Competition on Day-Ahead\nElectricity Demand Forecasting: Post-COVID Paradigm. The day-ahead load\nforecasting approach is based on online forecast combination of multiple point\nprediction models. It contains four steps: i) data cleaning and preprocessing,\nii) a holiday adjustment procedure, iii) training of individual forecasting\nmodels, iv) forecast combination by smoothed Bernstein Online Aggregation\n(BOA). The approach is flexible and can quickly adopt to new energy system\nsituations as they occurred during and after COVID-19 shutdowns. The pool of\nindividual prediction models ranges from rather simple time series models to\nsophisticated models like generalized additive models (GAMs) and\nhigh-dimensional linear models estimated by lasso. They incorporate\nautoregressive, calendar and weather effects efficiently. All steps contain\nnovel concepts that contribute to the excellent forecasting performance of the\nproposed method. This holds particularly for the holiday adjustment procedure\nand the fully adaptive smoothed BOA approach.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:51:21 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ziel", "Florian", ""]]}, {"id": "2107.06277", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Jad Rahme, Aviral Kumar, Amy Zhang, Ryan P. Adams, Sergey\n  Levine", "title": "Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit\n  Partial Observability", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is a central challenge for the deployment of reinforcement\nlearning (RL) systems in the real world. In this paper, we show that the\nsequential structure of the RL problem necessitates new approaches to\ngeneralization beyond the well-studied techniques used in supervised learning.\nWhile supervised learning methods can generalize effectively without explicitly\naccounting for epistemic uncertainty, we show that, perhaps surprisingly, this\nis not the case in RL. We show that generalization to unseen test conditions\nfrom a limited number of training conditions induces implicit partial\nobservability, effectively turning even fully-observed MDPs into POMDPs.\nInformed by this observation, we recast the problem of generalization in RL as\nsolving the induced partially observed Markov decision process, which we call\nthe epistemic POMDP. We demonstrate the failure modes of algorithms that do not\nappropriately handle this partial observability, and suggest a simple\nensemble-based technique for approximately solving the partially observed\nproblem. Empirically, we demonstrate that our simple algorithm derived from the\nepistemic POMDP achieves significant gains in generalization over current\nmethods on the Procgen benchmark suite.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:59:25 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ghosh", "Dibya", ""], ["Rahme", "Jad", ""], ["Kumar", "Aviral", ""], ["Zhang", "Amy", ""], ["Adams", "Ryan P.", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.06317", "submitter": "Alihan H\\\"uy\\\"uk", "authors": "Alihan H\\\"uy\\\"uk, Daniel Jarrett, Mihaela van der Schaar", "title": "Inverse Contextual Bandits: Learning How Behavior Evolves over Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding an agent's priorities by observing their behavior is critical\nfor transparency and accountability in decision processes, such as in\nhealthcare. While conventional approaches to policy learning almost invariably\nassume stationarity in behavior, this is hardly true in practice: Medical\npractice is constantly evolving, and clinical professionals are constantly\nfine-tuning their priorities. We desire an approach to policy learning that\nprovides (1) interpretable representations of decision-making, accounts for (2)\nnon-stationarity in behavior, as well as operating in an (3) offline manner.\nFirst, we model the behavior of learning agents in terms of contextual bandits,\nand formalize the problem of inverse contextual bandits (ICB). Second, we\npropose two algorithms to tackle ICB, each making varying degrees of\nassumptions regarding the agent's learning strategy. Finally, through both real\nand simulated data for liver transplantations, we illustrate the applicability\nand explainability of our method, as well as validating its accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:24:18 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["H\u00fcy\u00fck", "Alihan", ""], ["Jarrett", "Daniel", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2107.06428", "submitter": "Brian Trippe", "authors": "Brian L. Trippe, Hilary K. Finucane, Tamara Broderick", "title": "For high-dimensional hierarchical models, consider exchangeability of\n  effects across covariates instead of across datasets", "comments": "10 pages plus supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchical Bayesian methods enable information sharing across multiple\nrelated regression problems. While standard practice is to model regression\nparameters (effects) as (1) exchangeable across datasets and (2) correlated to\ndiffering degrees across covariates, we show that this approach exhibits poor\nstatistical performance when the number of covariates exceeds the number of\ndatasets. For instance, in statistical genetics, we might regress dozens of\ntraits (defining datasets) for thousands of individuals (responses) on up to\nmillions of genetic variants (covariates). When an analyst has more covariates\nthan datasets, we argue that it is often more natural to instead model effects\nas (1) exchangeable across covariates and (2) correlated to differing degrees\nacross datasets. To this end, we propose a hierarchical model expressing our\nalternative perspective. We devise an empirical Bayes estimator for learning\nthe degree of correlation between datasets. We develop theory that demonstrates\nthat our method outperforms the classic approach when the number of covariates\ndominates the number of datasets, and corroborate this result empirically on\nseveral high-dimensional multiple regression and classification problems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 23:23:06 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Trippe", "Brian L.", ""], ["Finucane", "Hilary K.", ""], ["Broderick", "Tamara", ""]]}, {"id": "2107.06446", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov", "title": "Hierarchical Associative Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense Associative Memories or Modern Hopfield Networks have many appealing\nproperties of associative memory. They can do pattern completion, store a large\nnumber of memories, and can be described using a recurrent neural network with\na degree of biological plausibility and rich feedback between the neurons. At\nthe same time, up until now all the models of this class have had only one\nhidden layer, and have only been formulated with densely connected network\narchitectures, two aspects that hinder their machine learning applications.\nThis paper tackles this gap and describes a fully recurrent model of\nassociative memory with an arbitrary large number of layers, some of which can\nbe locally connected (convolutional), and a corresponding energy function that\ndecreases on the dynamical trajectory of the neurons' activations. The memories\nof the full network are dynamically \"assembled\" using primitives encoded in the\nsynaptic weights of the lower layers, with the \"assembling rules\" encoded in\nthe synaptic weights of the higher layers. In addition to the bottom-up\npropagation of information, typical of commonly used feedforward neural\nnetworks, the model described has rich top-down feedback from higher layers\nthat help the lower-layer neurons to decide on their response to the input\nstimuli.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 01:38:40 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Krotov", "Dmitry", ""]]}, {"id": "2107.06466", "submitter": "Baihe Huang", "authors": "Baihe Huang and Kaixuan Huang and Sham M. Kakade and Jason D. Lee and\n  Qi Lei and Runzhe Wang and Jiaqi Yang", "title": "Going Beyond Linear RL: Sample Efficient Neural Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Reinforcement Learning (RL) powered by neural net approximation of the Q\nfunction has had enormous empirical success. While the theory of RL has\ntraditionally focused on linear function approximation (or eluder dimension)\napproaches, little is known about nonlinear RL with neural net approximations\nof the Q functions. This is the focus of this work, where we study function\napproximation with two-layer neural networks (considering both ReLU and\npolynomial activation functions). Our first result is a computationally and\nstatistically efficient algorithm in the generative model setting under\ncompleteness for two-layer neural networks. Our second result considers this\nsetting but under only realizability of the neural net function class. Here,\nassuming deterministic dynamics, the sample complexity scales linearly in the\nalgebraic dimension. In all cases, our results significantly improve upon what\ncan be attained with linear (or eluder dimension) methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:03:56 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Huang", "Baihe", ""], ["Huang", "Kaixuan", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""], ["Wang", "Runzhe", ""], ["Yang", "Jiaqi", ""]]}, {"id": "2107.06473", "submitter": "Wenqi Fang", "authors": "Wenqi Fang, Guanlin Wu, Jingjing Li, Zheng Wang, Jiang Cao, Yang Ping", "title": "Spectrum Gaussian Processes Based On Tunable Basis Functions", "comments": "10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral approximation and variational inducing learning for the Gaussian\nprocess are two popular methods to reduce computational complexity. However, in\nprevious research, those methods always tend to adopt the orthonormal basis\nfunctions, such as eigenvectors in the Hilbert space, in the spectrum method,\nor decoupled orthogonal components in the variational framework. In this paper,\ninspired by quantum physics, we introduce a novel basis function, which is\ntunable, local and bounded, to approximate the kernel function in the Gaussian\nprocess. There are two adjustable parameters in these functions, which control\ntheir orthogonality to each other and limit their boundedness. And we conduct\nextensive experiments on open-source datasets to testify its performance.\nCompared to several state-of-the-art methods, it turns out that the proposed\nmethod can obtain satisfactory or even better results, especially with poorly\nchosen kernel functions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:51:24 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Fang", "Wenqi", ""], ["Wu", "Guanlin", ""], ["Li", "Jingjing", ""], ["Wang", "Zheng", ""], ["Cao", "Jiang", ""], ["Ping", "Yang", ""]]}, {"id": "2107.06475", "submitter": "Patryk Orzechowski", "authors": "Patryk Orzechowski and Jason H. Moore", "title": "Generative and reproducible benchmarks for comprehensive evaluation of\n  machine learning classifiers", "comments": "12 pages, 3 figures with subfigures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the strengths and weaknesses of machine learning (ML)\nalgorithms is crucial for determine their scope of application. Here, we\nintroduce the DIverse and GENerative ML Benchmark (DIGEN) - a collection of\nsynthetic datasets for comprehensive, reproducible, and interpretable\nbenchmarking of machine learning algorithms for classification of binary\noutcomes. The DIGEN resource consists of 40 mathematical functions which map\ncontinuous features to discrete endpoints for creating synthetic datasets.\nThese 40 functions were discovered using a heuristic algorithm designed to\nmaximize the diversity of performance among multiple popular machine learning\nalgorithms thus providing a useful test suite for evaluating and comparing new\nmethods. Access to the generative functions facilitates understanding of why a\nmethod performs poorly compared to other algorithms thus providing ideas for\nimprovement. The resource with extensive documentation and analyses is\nopen-source and available on GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:58:02 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Orzechowski", "Patryk", ""], ["Moore", "Jason H.", ""]]}, {"id": "2107.06534", "submitter": "Zeeshan Akhtar", "authors": "Zeeshan Akhtar, and Ketan Rajawat", "title": "Zeroth and First Order Stochastic Frank-Wolfe Algorithms for Constrained\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers stochastic convex optimization problems with two sets of\nconstraints: (a) deterministic constraints on the domain of the optimization\nvariable, which are difficult to project onto; and (b) deterministic or\nstochastic constraints that admit efficient projection. Problems of this form\narise frequently in the context of semidefinite programming as well as when\nvarious NP-hard problems are solved approximately via semidefinite relaxation.\nSince projection onto the first set of constraints is difficult, it becomes\nnecessary to explore projection-free algorithms, such as the stochastic\nFrank-Wolfe (FW) algorithm. On the other hand, the second set of constraints\ncannot be handled in the same way, and must be incorporated as an indicator\nfunction within the objective function, thereby complicating the application of\nFW methods. Similar problems have been studied before, and solved using\nfirst-order stochastic FW algorithms by applying homotopy and Nesterov's\nsmoothing techniques to the indicator function. This work improves upon these\nexisting results and puts forth momentum-based first-order methods that yield\nimproved convergence rates, at par with the best known rates for problems\nwithout the second set of constraints. Zeroth-order variants of the proposed\nalgorithms are also developed and again improve upon the state-of-the-art rate\nresults. The efficacy of the proposed algorithms is tested on relevant\napplications of sparse matrix estimation, clustering via semidefinite\nrelaxation, and uniform sparsest cut problem.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:01:30 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Akhtar", "Zeeshan", ""], ["Rajawat", "Ketan", ""]]}, {"id": "2107.06566", "submitter": "Erich Schubert", "authors": "Erik Thordsen and Erich Schubert", "title": "MESS: Manifold Embedding Motivated Super Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches in the field of machine learning and data analysis rely on\nthe assumption that the observed data lies on lower-dimensional manifolds. This\nassumption has been verified empirically for many real data sets. To make use\nof this manifold assumption one generally requires the manifold to be locally\nsampled to a certain density such that features of the manifold can be\nobserved. However, for increasing intrinsic dimensionality of a data set the\nrequired data density introduces the need for very large data sets, resulting\nin one of the many faces of the curse of dimensionality. To combat the\nincreased requirement for local data density we propose a framework to generate\nvirtual data points that faithful to an approximate embedding function\nunderlying the manifold observable in the data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:07:54 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Thordsen", "Erik", ""], ["Schubert", "Erich", ""]]}, {"id": "2107.06615", "submitter": "Simon Omlor", "authors": "Alexander Munteanu, Simon Omlor, David Woodruff", "title": "Oblivious sketching for logistic regression", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What guarantees are possible for solving logistic regression in one pass over\na data stream? To answer this question, we present the first data oblivious\nsketch for logistic regression. Our sketch can be computed in input sparsity\ntime over a turnstile data stream and reduces the size of a $d$-dimensional\ndata set from $n$ to only $\\operatorname{poly}(\\mu d\\log n)$ weighted points,\nwhere $\\mu$ is a useful parameter which captures the complexity of compressing\nthe data. Solving (weighted) logistic regression on the sketch gives an $O(\\log\nn)$-approximation to the original problem on the full data set. We also show\nhow to obtain an $O(1)$-approximation with slight modifications. Our sketches\nare fast, simple, easy to implement, and our experiments demonstrate their\npracticality.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 11:29:26 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Munteanu", "Alexander", ""], ["Omlor", "Simon", ""], ["Woodruff", "David", ""]]}, {"id": "2107.06650", "submitter": "Tian Zhou", "authors": "Tian Zhou, Hao He, Shengjun Pan, Niklas Karlsson, Bharatbhushan\n  Shetty, Brendan Kitts, Djordje Gligorijevic, San Gultekin, Tingyu Mao, Junwei\n  Pan, Jianlong Zhang and Aaron Flores", "title": "An Efficient Deep Distribution Network for Bid Shading in First-Price\n  Auctions", "comments": "In Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD'21), August 14-18, 2021, Singapore", "journal-ref": null, "doi": "10.1145/3447548.3467167", "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Since 2019, most ad exchanges and sell-side platforms (SSPs), in the online\nadvertising industry, shifted from second to first price auctions. Due to the\nfundamental difference between these auctions, demand-side platforms (DSPs)\nhave had to update their bidding strategies to avoid bidding unnecessarily high\nand hence overpaying. Bid shading was proposed to adjust the bid price intended\nfor second-price auctions, in order to balance cost and winning probability in\na first-price auction setup. In this study, we introduce a novel deep\ndistribution network for optimal bidding in both open (non-censored) and closed\n(censored) online first-price auctions. Offline and online A/B testing results\nshow that our algorithm outperforms previous state-of-art algorithms in terms\nof both surplus and effective cost per action (eCPX) metrics. Furthermore, the\nalgorithm is optimized in run-time and has been deployed into VerizonMedia DSP\nas production algorithm, serving hundreds of billions of bid requests per day.\nOnline A/B test shows that advertiser's ROI are improved by +2.4%, +2.4%, and\n+8.6% for impression based (CPM), click based (CPC), and conversion based (CPA)\ncampaigns respectively.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:44:39 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 17:24:42 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zhou", "Tian", ""], ["He", "Hao", ""], ["Pan", "Shengjun", ""], ["Karlsson", "Niklas", ""], ["Shetty", "Bharatbhushan", ""], ["Kitts", "Brendan", ""], ["Gligorijevic", "Djordje", ""], ["Gultekin", "San", ""], ["Mao", "Tingyu", ""], ["Pan", "Junwei", ""], ["Zhang", "Jianlong", ""], ["Flores", "Aaron", ""]]}, {"id": "2107.06658", "submitter": "Matthew Levine", "authors": "Matthew E. Levine and Andrew M. Stuart", "title": "A Framework for Machine Learning of Model Error in Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of data-informed predictive models for dynamical systems is\nof widespread interest in many disciplines. We present a unifying framework for\nblending mechanistic and machine-learning approaches to identify dynamical\nsystems from data. We compare pure data-driven learning with hybrid models\nwhich incorporate imperfect domain knowledge. We cast the problem in both\ncontinuous- and discrete-time, for problems in which the model error is\nmemoryless and in which it has significant memory, and we compare data-driven\nand hybrid approaches experimentally. Our formulation is agnostic to the chosen\nmachine learning model.\n  Using Lorenz '63 and Lorenz '96 Multiscale systems, we find that hybrid\nmethods substantially outperform solely data-driven approaches in terms of data\nhunger, demands for model complexity, and overall predictive performance. We\nalso find that, while a continuous-time framing allows for robustness to\nirregular sampling and desirable domain-interpretability, a discrete-time\nframing can provide similar or better predictive performance, especially when\ndata are undersampled and the vector field cannot be resolved.\n  We study model error from the learning theory perspective, defining excess\nrisk and generalization error; for a linear model of the error used to learn\nabout ergodic dynamical systems, both errors are bounded by terms that diminish\nwith the square-root of T. We also illustrate scenarios that benefit from\nmodeling with memory, proving that continuous-time recurrent neural networks\n(RNNs) can, in principle, learn memory-dependent model error and reconstruct\nthe original system arbitrarily well; numerical results depict challenges in\nrepresenting memory by this approach. We also connect RNNs to reservoir\ncomputing and thereby relate the learning of memory-dependent error to recent\nwork on supervised learning between Banach spaces using random features.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:47:48 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Levine", "Matthew E.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "2107.06675", "submitter": "Florian Ziel", "authors": "Florian Ziel", "title": "M5 Competition Uncertainty: Overdispersion, distributional forecasting,\n  GAMLSS and beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The M5 competition uncertainty track aims for probabilistic forecasting of\nsales of thousands of Walmart retail goods. We show that the M5 competition\ndata faces strong overdispersion and sporadic demand, especially zero demand.\nWe discuss resulting modeling issues concerning adequate probabilistic\nforecasting of such count data processes. Unfortunately, the majority of\npopular prediction methods used in the M5 competition (e.g. lightgbm and\nxgboost GBMs) fails to address the data characteristics due to the considered\nobjective functions. The distributional forecasting provides a suitable\nmodeling approach for to the overcome those problems. The GAMLSS framework\nallows flexible probabilistic forecasting using low dimensional distributions.\nWe illustrate, how the GAMLSS approach can be applied for the M5 competition\ndata by modeling the location and scale parameter of various distributions,\ne.g. the negative binomial distribution. Finally, we discuss software packages\nfor distributional modeling and their drawback, like the R package gamlss with\nits package extensions, and (deep) distributional forecasting libraries such as\nTensorFlow Probability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:05:55 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Ziel", "Florian", ""]]}, {"id": "2107.06876", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Marten Lienen, Stephan G\\\"unnemann", "title": "Scalable Optimal Transport in High Dimensions for Graph Distances,\n  Embedding Alignment, and More", "comments": "Published as a conference paper at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DS cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current best practice for computing optimal transport (OT) is via entropy\nregularization and Sinkhorn iterations. This algorithm runs in quadratic time\nas it requires the full pairwise cost matrix, which is prohibitively expensive\nfor large sets of objects. In this work we propose two effective log-linear\ntime approximations of the cost matrix: First, a sparse approximation based on\nlocality-sensitive hashing (LSH) and, second, a Nystr\\\"om approximation with\nLSH-based sparse corrections, which we call locally corrected Nystr\\\"om (LCN).\nThese approximations enable general log-linear time algorithms for\nentropy-regularized OT that perform well even for the complex, high-dimensional\nspaces common in deep learning. We analyse these approximations theoretically\nand evaluate them experimentally both directly and end-to-end as a component\nfor real-world applications. Using our approximations for unsupervised word\nembedding alignment enables us to speed up a state-of-the-art method by a\nfactor of 3 while also improving the accuracy by 3.1 percentage points without\nany additional model changes. For graph distance regression we propose the\ngraph transport network (GTN), which combines graph neural networks (GNNs) with\nenhanced Sinkhorn. GTN outcompetes previous models by 48% and still scales\nlog-linearly in the number of nodes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:40:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Klicpera", "Johannes", ""], ["Lienen", "Marten", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.06898", "submitter": "Ro Jefferson", "authors": "Johanna Erdmenger, Kevin T. Grosvenor, and Ro Jefferson", "title": "Towards quantifying information flows: relative entropy in deep neural\n  networks and the renormalization group", "comments": "41 pages, 8 figures; code available at\n  https://github.com/ro-jefferson/entropy_dnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th cond-mat.dis-nn cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the analogy between the renormalization group (RG) and deep\nneural networks, wherein subsequent layers of neurons are analogous to\nsuccessive steps along the RG. In particular, we quantify the flow of\ninformation by explicitly computing the relative entropy or Kullback-Leibler\ndivergence in both the one- and two-dimensional Ising models under decimation\nRG, as well as in a feedforward neural network as a function of depth. We\nobserve qualitatively identical behavior characterized by the monotonic\nincrease to a parameter-dependent asymptotic value. On the quantum field theory\nside, the monotonic increase confirms the connection between the relative\nentropy and the c-theorem. For the neural networks, the asymptotic behavior may\nhave implications for various information maximization methods in machine\nlearning, as well as for disentangling compactness and generalizability.\nFurthermore, while both the two-dimensional Ising model and the random neural\nnetworks we consider exhibit non-trivial critical points, the relative entropy\nappears insensitive to the phase structure of either system. In this sense,\nmore refined probes are required in order to fully elucidate the flow of\ninformation in these models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:00:01 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Erdmenger", "Johanna", ""], ["Grosvenor", "Kevin T.", ""], ["Jefferson", "Ro", ""]]}, {"id": "2107.06929", "submitter": "Sean Kulinski", "authors": "Sean Kulinski, Saurabh Bagchi, David I. Inouye", "title": "Feature Shift Detection: Localizing Which Features Have Shifted via\n  Conditional Distribution Tests", "comments": "NeurIPS 2020 Camera Ready", "journal-ref": "NeurIPS 33 (2020) 19523-19533", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While previous distribution shift detection approaches can identify if a\nshift has occurred, these approaches cannot localize which specific features\nhave caused a distribution shift -- a critical step in diagnosing or fixing any\nunderlying issue. For example, in military sensor networks, users will want to\ndetect when one or more of the sensors has been compromised, and critically,\nthey will want to know which specific sensors might be compromised. Thus, we\nfirst define a formalization of this problem as multiple conditional\ndistribution hypothesis tests and propose both non-parametric and parametric\nstatistical tests. For both efficiency and flexibility, we then propose to use\na test statistic based on the density model score function (i.e. gradient with\nrespect to the input) -- which can easily compute test statistics for all\ndimensions in a single forward and backward pass. Any density model could be\nused for computing the necessary statistics including deep density models such\nas normalizing flows or autoregressive models. We additionally develop methods\nfor identifying when and where a shift occurs in multivariate time-series data\nand show results for multiple scenarios using realistic attack models on both\nsimulated and real world data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:23:24 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kulinski", "Sean", ""], ["Bagchi", "Saurabh", ""], ["Inouye", "David I.", ""]]}, {"id": "2107.07014", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Hybrid Bayesian Neural Networks with Functional Probabilistic Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks provide a direct and natural way to extend standard\ndeep neural networks to support probabilistic deep learning through the use of\nprobabilistic layers that, traditionally, encode weight (and bias) uncertainty.\nIn particular, hybrid Bayesian neural networks utilize standard deterministic\nlayers together with few probabilistic layers judicially positioned in the\nnetworks for uncertainty estimation. A major aspect and benefit of Bayesian\ninference is that priors, in principle, provide the means to encode prior\nknowledge for use in inference and prediction. However, it is difficult to\nspecify priors on weights since the weights have no intuitive interpretation.\nFurther, the relationships of priors on weights to the functions computed by\nnetworks are difficult to characterize. In contrast, functions are intuitive to\ninterpret and are direct since they map inputs to outputs. Therefore, it is\nnatural to specify priors on functions to encode prior knowledge, and to use\nthem in inference and prediction based on functions. To support this, we\npropose hybrid Bayesian neural networks with functional probabilistic layers\nthat encode function (and activation) uncertainty. We discuss their foundations\nin functional Bayesian inference, functional variational inference, sparse\nGaussian processes, and sparse variational Gaussian processes. We further\nperform few proof-of-concept experiments using GPflus, a new library that\nprovides Gaussian process layers and supports their use with deterministic\nKeras layers to form hybrid neural network and Gaussian process models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 21:25:53 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "2107.07087", "submitter": "Elie Wolfe", "authors": "Noam Finkelstein, Beata Zjawin, Elie Wolfe, Ilya Shpitser, Robert W.\n  Spekkens", "title": "Entropic Inequality Constraints from $e$-separation Relations in\n  Directed Acyclic Graphs with Hidden Variables", "comments": "15 pages. This arXiv version is slightly updated relative to the\n  version in UAI proceedings. (Theorem 5 and Proposition 8 have been\n  strengthened, with Appendix C revised correspondingly. Appendix D has been\n  added.)", "journal-ref": null, "doi": null, "report-no": "Proc. UAI 2021", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graphs (DAGs) with hidden variables are often used to\ncharacterize causal relations between variables in a system. When some\nvariables are unobserved, DAGs imply a notoriously complicated set of\nconstraints on the distribution of observed variables. In this work, we present\nentropic inequality constraints that are implied by $e$-separation relations in\nhidden variable DAGs with discrete observed variables. The constraints can\nintuitively be understood to follow from the fact that the capacity of\nvariables along a causal pathway to convey information is restricted by their\nentropy; e.g. at the extreme case, a variable with entropy $0$ can convey no\ninformation. We show how these constraints can be used to learn about the true\ncausal model from an observed data distribution. In addition, we propose a\nmeasure of causal influence called the minimal mediary entropy, and demonstrate\nthat it can augment traditional measures such as the average causal effect.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 02:43:33 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Finkelstein", "Noam", ""], ["Zjawin", "Beata", ""], ["Wolfe", "Elie", ""], ["Shpitser", "Ilya", ""], ["Spekkens", "Robert W.", ""]]}, {"id": "2107.07098", "submitter": "Matthew Dowling", "authors": "Matthew Dowling, Piotr Sok\\'o{\\l}, Il Memming Park", "title": "Hida-Mat\\'ern Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the class of Hida-Mat\\'ern kernels, which is the canonical family\nof covariance functions over the entire space of stationary Gauss-Markov\nProcesses. It extends upon Mat\\'ern kernels, by allowing for flexible\nconstruction of priors over processes with oscillatory components. Any\nstationary kernel, including the widely used squared-exponential and spectral\nmixture kernels, are either directly within this class or are appropriate\nasymptotic limits, demonstrating the generality of this class. Taking advantage\nof its Markovian nature we show how to represent such processes as state space\nmodels using only the kernel and its derivatives. In turn this allows us to\nperform Gaussian Process inference more efficiently and side step the usual\ncomputational burdens. We also show how exploiting special properties of the\nstate space representation enables improved numerical stability in addition to\nfurther reductions of computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 03:25:10 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Dowling", "Matthew", ""], ["Sok\u00f3\u0142", "Piotr", ""], ["Park", "Il Memming", ""]]}, {"id": "2107.07115", "submitter": "Hideaki Ishibashi Ph.D", "authors": "Hideaki Ishibashi and Shotaro Akaho", "title": "Principal component analysis for Gaussian process posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an extension of principal component analysis for Gaussian\nprocess posteriors denoted by GP-PCA. Since GP-PCA estimates a low-dimensional\nspace of GP posteriors, it can be used for meta-learning, which is a framework\nfor improving the precision of a new task by estimating a structure of a set of\ntasks. The issue is how to define a structure of a set of GPs with an\ninfinite-dimensional parameter, such as coordinate system and a divergence. In\nthis study, we reduce the infiniteness of GP to the finite-dimensional case\nunder the information geometrical framework by considering a space of GP\nposteriors that has the same prior. In addition, we propose an approximation\nmethod of GP-PCA based on variational inference and demonstrate the\neffectiveness of GP-PCA as meta-learning through experiments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:40:02 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ishibashi", "Hideaki", ""], ["Akaho", "Shotaro", ""]]}, {"id": "2107.07160", "submitter": "Wilmer Arbelo Gonzalez", "authors": "Gilmer Valdes, Wilmer Arbelo, Yannet Interian, and Jerome H. Friedman", "title": "Lockout: Sparse Regularization of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Many regression and classification procedures fit a parameterized function\n$f(x;w)$ of predictor variables $x$ to data $\\{x_{i},y_{i}\\}_1^N$ based on some\nloss criterion $L(y,f)$. Often, regularization is applied to improve accuracy\nby placing a constraint $P(w)\\leq t$ on the values of the parameters $w$.\nAlthough efficient methods exist for finding solutions to these constrained\noptimization problems for all values of $t\\geq0$ in the special case when $f$\nis a linear function, none are available when $f$ is non-linear (e.g. Neural\nNetworks). Here we present a fast algorithm that provides all such solutions\nfor any differentiable function $f$ and loss $L$, and any constraint $P$ that\nis an increasing monotone function of the absolute value of each parameter.\nApplications involving sparsity inducing regularization of arbitrary Neural\nNetworks are discussed. Empirical results indicate that these sparse solutions\nare usually superior to their dense counterparts in both accuracy and\ninterpretability. This improvement in accuracy can often make Neural Networks\ncompetitive with, and sometimes superior to, state-of-the-art methods in the\nanalysis of tabular data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 07:17:20 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Valdes", "Gilmer", ""], ["Arbelo", "Wilmer", ""], ["Interian", "Yannet", ""], ["Friedman", "Jerome H.", ""]]}, {"id": "2107.07211", "submitter": "Vyacheslav Kungurtsev", "authors": "Vyacheslav Kungurtsev and Adam Cobb and Tara Javidi and Brian Jalaian", "title": "Decentralized Bayesian Learning with Metropolis-Adjusted Hamiltonian\n  Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning performed by a decentralized networks of agents is\nbecoming increasingly important with the prevalence of embedded software on\nautonomous devices. Bayesian approaches to learning benefit from offering more\ninformation as to the uncertainty of a random quantity, and Langevin and\nHamiltonian methods are effective at realizing sampling from an uncertain\ndistribution with large parameter dimensions. Such methods have only recently\nappeared in the decentralized setting, and either exclusively use stochastic\ngradient Langevin and Hamiltonian Monte Carlo approaches that require a\ndiminishing stepsize to asymptotically sample from the posterior and are known\nin practice to characterize uncertainty less faithfully than constant step-size\nmethods with a Metropolis adjustment, or assume strong convexity properties of\nthe potential function. We present the first approach to incorporating constant\nstepsize Metropolis-adjusted HMC in the decentralized sampling framework, show\ntheoretical guarantees for consensus and probability distance to the posterior\nstationary distribution, and demonstrate their effectiveness numerically on\nstandard real world problems, including decentralized learning of neural\nnetworks which is known to be highly non-convex.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 09:39:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kungurtsev", "Vyacheslav", ""], ["Cobb", "Adam", ""], ["Javidi", "Tara", ""], ["Jalaian", "Brian", ""]]}, {"id": "2107.07232", "submitter": "Alexandre Verine", "authors": "Alexandre Verine, Benjamin Negrevergne, Fabrice Rossi, Yann Chevaleyre", "title": "On the expressivity of bi-Lipschitz normalizing flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An invertible function is bi-Lipschitz if both the function and its inverse\nhave bounded Lipschitz constants. Nowadays, most Normalizing Flows are\nbi-Lipschitz by design or by training to limit numerical errors (among other\nthings). In this paper, we discuss the expressivity of bi-Lipschitz Normalizing\nFlows and identify several target distributions that are difficult to\napproximate using such models. Then, we characterize the expressivity of\nbi-Lipschitz Normalizing Flows by giving several lower bounds on the Total\nVariation distance between these particularly unfavorable distributions and\ntheir best possible approximation. Finally, we discuss potential remedies which\ninclude using more complex latent distributions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 10:13:46 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Verine", "Alexandre", ""], ["Negrevergne", "Benjamin", ""], ["Rossi", "Fabrice", ""], ["Chevaleyre", "Yann", ""]]}, {"id": "2107.07281", "submitter": "Carlos Villacampa-Calvo", "authors": "Bahram Jafrasteh and Carlos Villacampa-Calvo and Daniel\n  Hern\\'andez-Lobato", "title": "Input Dependent Sparse Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) are Bayesian models that provide uncertainty\nestimates associated to the predictions made. They are also very flexible due\nto their non-parametric nature. Nevertheless, GPs suffer from poor scalability\nas the number of training instances N increases. More precisely, they have a\ncubic cost with respect to $N$. To overcome this problem, sparse GP\napproximations are often used, where a set of $M \\ll N$ inducing points is\nintroduced during training. The location of the inducing points is learned by\nconsidering them as parameters of an approximate posterior distribution $q$.\nSparse GPs, combined with variational inference for inferring $q$, reduce the\ntraining cost of GPs to $\\mathcal{O}(M^3)$. Critically, the inducing points\ndetermine the flexibility of the model and they are often located in regions of\nthe input space where the latent function changes. A limitation is, however,\nthat for some learning tasks a large number of inducing points may be required\nto obtain a good prediction performance. To address this limitation, we propose\nhere to amortize the computation of the inducing points locations, as well as\nthe parameters of the variational posterior approximation q. For this, we use a\nneural network that receives the observed data as an input and outputs the\ninducing points locations and the parameters of $q$. We evaluate our method in\nseveral experiments, showing that it performs similar or better than other\nstate-of-the-art sparse variational GP approaches. However, with our method the\nnumber of inducing points is reduced drastically due to their dependency on the\ninput data. This makes our method scale to larger datasets and have faster\ntraining and prediction times.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 12:19:10 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Jafrasteh", "Bahram", ""], ["Villacampa-Calvo", "Carlos", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "2107.07322", "submitter": "Ziyu Xu", "authors": "Ziyu Xu, Ruodu Wang, Aaditya Ramdas", "title": "A unified framework for bandit multiple testing", "comments": "37 pages. 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In bandit multiple hypothesis testing, each arm corresponds to a different\nnull hypothesis that we wish to test, and the goal is to design adaptive\nalgorithms that correctly identify large set of interesting arms (true\ndiscoveries), while only mistakenly identifying a few uninteresting ones (false\ndiscoveries). One common metric in non-bandit multiple testing is the false\ndiscovery rate (FDR). We propose a unified, modular framework for bandit FDR\ncontrol that emphasizes the decoupling of exploration and summarization of\nevidence. We utilize the powerful martingale-based concept of ``e-processes''\nto ensure FDR control for arbitrary composite nulls, exploration rules and\nstopping times in generic problem settings. In particular, valid FDR control\nholds even if the reward distributions of the arms could be dependent, multiple\narms may be queried simultaneously, and multiple (cooperating or competing)\nagents may be querying arms, covering combinatorial semi-bandit type settings\nas well. Prior work has considered in great detail the setting where each arm's\nreward distribution is independent and sub-Gaussian, and a single arm is\nqueried at each step. Our framework recovers matching sample complexity\nguarantees in this special case, and performs comparably or better in practice.\nFor other settings, sample complexities will depend on the finer details of the\nproblem (composite nulls being tested, exploration algorithm, data dependence\nstructure, stopping rule) and we do not explore these; our contribution is to\nshow that the FDR guarantee is clean and entirely agnostic to these details.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:47:28 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xu", "Ziyu", ""], ["Wang", "Ruodu", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2107.07340", "submitter": "Arivazhagan Geetha Balasubramanian", "authors": "A. G. Balasubramanian, L. Guastoni, A. G\\\"uemes, A. Ianiro, S.\n  Discetti, P. Schlatter, H. Azizpour, R. Vinuesa", "title": "Predicting the near-wall region of turbulence through convolutional\n  neural networks", "comments": "Proc. 13th ERCOFTAC Symp. on Engineering Turbulence Modeling and\n  Measurements (ETMM13), Rhodes, Greece, September 15-17, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling the near-wall region of wall-bounded turbulent flows is a\nwidespread practice to reduce the computational cost of large-eddy simulations\n(LESs) at high Reynolds number. As a first step towards a data-driven\nwall-model, a neural-network-based approach to predict the near-wall behaviour\nin a turbulent open channel flow is investigated. The fully-convolutional\nnetwork (FCN) proposed by Guastoni et al. [preprint, arXiv:2006.12483] is\ntrained to predict the two-dimensional velocity-fluctuation fields at\n$y^{+}_{\\rm target}$, using the sampled fluctuations in wall-parallel planes\nlocated farther from the wall, at $y^{+}_{\\rm input}$. The data for training\nand testing is obtained from a direct numerical simulation (DNS) at friction\nReynolds numbers $Re_{\\tau} = 180$ and $550$. The turbulent\nvelocity-fluctuation fields are sampled at various wall-normal locations, i.e.\n$y^{+} = \\{15, 30, 50, 80, 100, 120, 150\\}$. At $Re_{\\tau}=550$, the FCN can\ntake advantage of the self-similarity in the logarithmic region of the flow and\npredict the velocity-fluctuation fields at $y^{+} = 50$ using the\nvelocity-fluctuation fields at $y^{+} = 100$ as input with less than 20% error\nin prediction of streamwise-fluctuations intensity. These results are an\nencouraging starting point to develop a neural-network based approach for\nmodelling turbulence at the wall in numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:58:26 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Balasubramanian", "A. G.", ""], ["Guastoni", "L.", ""], ["G\u00fcemes", "A.", ""], ["Ianiro", "A.", ""], ["Discetti", "S.", ""], ["Schlatter", "P.", ""], ["Azizpour", "H.", ""], ["Vinuesa", "R.", ""]]}, {"id": "2107.07352", "submitter": "Mike Laszkiewicz", "authors": "Mike Laszkiewicz, Johannes Lederer, Asja Fischer", "title": "Copula-Based Normalizing Flows", "comments": "Accepted for presentation at the ICML 2021 Workshop on Invertible\n  Neural Networks, Normalizing Flows, and Explicit Likelihood Models (INNF+\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normalizing flows, which learn a distribution by transforming the data to\nsamples from a Gaussian base distribution, have proven powerful density\napproximations. But their expressive power is limited by this choice of the\nbase distribution. We, therefore, propose to generalize the base distribution\nto a more elaborate copula distribution to capture the properties of the target\ndistribution more accurately. In a first empirical analysis, we demonstrate\nthat this replacement can dramatically improve the vanilla normalizing flows in\nterms of flexibility, stability, and effectivity for heavy-tailed data. Our\nresults suggest that the improvements are related to an increased local\nLipschitz-stability of the learned flow.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:22:28 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Laszkiewicz", "Mike", ""], ["Lederer", "Johannes", ""], ["Fischer", "Asja", ""]]}, {"id": "2107.07371", "submitter": "Jae-Kwang Kim", "authors": "Hengfang Wang and Jae Kwang Kim", "title": "Statistical inference using Regularized M-estimation in the reproducing\n  kernel Hilbert space for handling missing data", "comments": "arXiv admin note: text overlap with arXiv:2102.00058", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Imputation and propensity score weighting are two popular techniques for\nhandling missing data. We address these problems using the regularized\nM-estimation techniques in the reproducing kernel Hilbert space. Specifically,\nwe first use the kernel ridge regression to develop imputation for handling\nitem nonresponse. While this nonparametric approach is potentially promising\nfor imputation, its statistical properties are not investigated in the\nliterature. Under some conditions on the order of the tuning parameter, we\nfirst establish the root-$n$ consistency of the kernel ridge regression\nimputation estimator and show that it achieves the lower bound of the\nsemiparametric asymptotic variance. A nonparametric propensity score estimator\nusing the reproducing kernel Hilbert space is also developed by a novel\napplication of the maximum entropy method for the density ratio function\nestimation. We show that the resulting propensity score estimator is\nasymptotically equivalent to the kernel ridge regression imputation estimator.\nResults from a limited simulation study are also presented to confirm our\ntheory. The proposed method is applied to analyze the air pollution data\nmeasured in Beijing, China.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:51:39 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Wang", "Hengfang", ""], ["Kim", "Jae Kwang", ""]]}, {"id": "2107.07432", "submitter": "Ladislav Rampasek", "authors": "Ladislav Ramp\\'a\\v{s}ek, Guy Wolf", "title": "Hierarchical graph neural nets can capture long-range interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) based on message passing between neighboring\nnodes are known to be insufficient for capturing long-range interactions in\ngraphs. In this project we study hierarchical message passing models that\nleverage a multi-resolution representation of a given graph. This facilitates\nlearning of features that span large receptive fields without loss of local\ninformation, an aspect not studied in preceding work on hierarchical GNNs. We\nintroduce Hierarchical Graph Net (HGNet), which for any two connected nodes\nguarantees existence of message-passing paths of at most logarithmic length\nw.r.t. the input graph size. Yet, under mild assumptions, its internal\nhierarchy maintains asymptotic size equivalent to that of the input graph. We\nobserve that our HGNet outperforms conventional stacking of GCN layers\nparticularly in molecular property prediction benchmarks. Finally, we propose\ntwo benchmarking tasks designed to elucidate capability of GNNs to leverage\nlong-range interactions in graphs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:24:22 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ramp\u00e1\u0161ek", "Ladislav", ""], ["Wolf", "Guy", ""]]}, {"id": "2107.07436", "submitter": "Neil Jethani", "authors": "Neil Jethani, Mukund Sudarshan, Ian Covert, Su-In Lee, Rajesh\n  Ranganath", "title": "FastSHAP: Real-Time Shapley Value Estimation", "comments": "20 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley values are widely used to explain black-box models, but they are\ncostly to calculate because they require many model evaluations. We introduce\nFastSHAP, a method for estimating Shapley values in a single forward pass using\na learned explainer model. FastSHAP amortizes the cost of explaining many\ninputs via a learning approach inspired by the Shapley value's weighted least\nsquares characterization, and it can be trained using standard stochastic\ngradient optimization. We compare FastSHAP to existing estimation approaches,\nrevealing that it generates high-quality explanations with orders of magnitude\nspeedup.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:34:45 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Jethani", "Neil", ""], ["Sudarshan", "Mukund", ""], ["Covert", "Ian", ""], ["Lee", "Su-In", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2107.07443", "submitter": "Yonatan Carlos Carranza Alarc\\'on YcCa", "authors": "Yonatan Carlos Carranza Alarc\\'on, S\\'ebastien Destercke", "title": "Multi-label Chaining with Imprecise Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present two different strategies to extend the classical multi-label\nchaining approach to handle imprecise probability estimates. These estimates\nuse convex sets of distributions (or credal sets) in order to describe our\nuncertainty rather than a precise one. The main reasons one could have for\nusing such estimations are (1) to make cautious predictions (or no decision at\nall) when a high uncertainty is detected in the chaining and (2) to make better\nprecise predictions by avoiding biases caused in early decisions in the\nchaining. We adapt both strategies to the case of the naive credal classifier,\nshowing that this adaptations are computationally efficient. Our experimental\nresults on missing labels, which investigate how reliable these predictions are\nin both approaches, indicate that our approaches produce relevant cautiousness\non those hard-to-predict instances where the precise models fail.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:43:31 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 19:43:12 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Alarc\u00f3n", "Yonatan Carlos Carranza", ""], ["Destercke", "S\u00e9bastien", ""]]}, {"id": "2107.07455", "submitter": "Andrey Malinin Dr.", "authors": "Andrey Malinin and Neil Band and Ganshin, Alexander and German\n  Chesnokov and Yarin Gal and Mark J. F. Gales and Alexey Noskov and Andrey\n  Ploskonosov and Liudmila Prokhorenkova and Ivan Provilkov and Vatsal Raina\n  and Vyas Raina and Roginskiy, Denis and Mariya Shmatova and Panos Tigas and\n  Boris Yangel", "title": "Shifts: A Dataset of Real Distributional Shift Across Multiple\n  Large-Scale Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant research done on developing methods for improving\nrobustness to distributional shift and uncertainty estimation. In contrast,\nonly limited work has examined developing standard datasets and benchmarks for\nassessing these approaches. Additionally, most work on uncertainty estimation\nand robustness has developed new techniques based on small-scale regression or\nimage classification tasks. However, many tasks of practical interest have\ndifferent modalities, such as tabular data, audio, text, or sensor data, which\noffer significant challenges involving regression and discrete or continuous\nstructured prediction. Thus, given the current state of the field, a\nstandardized large-scale dataset of tasks across a range of modalities affected\nby distributional shifts is necessary. This will enable researchers to\nmeaningfully evaluate the plethora of recently developed uncertainty\nquantification methods, as well as assessment criteria and state-of-the-art\nbaselines. In this work, we propose the \\emph{Shifts Dataset} for evaluation of\nuncertainty estimates and robustness to distributional shift. The dataset,\nwhich has been collected from industrial sources and services, is composed of\nthree tasks, with each corresponding to a particular data modality: tabular\nweather prediction, machine translation, and self-driving car (SDC) vehicle\nmotion prediction. All of these data modalities and tasks are affected by real,\n`in-the-wild' distributional shifts and pose interesting challenges with\nrespect to uncertainty estimation. In this work we provide a description of the\ndataset and baseline results for all tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:59:34 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 17:39:44 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Malinin", "Andrey", ""], ["Band", "Neil", ""], ["Ganshin", "", ""], ["Alexander", "", ""], ["Chesnokov", "German", ""], ["Gal", "Yarin", ""], ["Gales", "Mark J. F.", ""], ["Noskov", "Alexey", ""], ["Ploskonosov", "Andrey", ""], ["Prokhorenkova", "Liudmila", ""], ["Provilkov", "Ivan", ""], ["Raina", "Vatsal", ""], ["Raina", "Vyas", ""], ["Roginskiy", "", ""], ["Denis", "", ""], ["Shmatova", "Mariya", ""], ["Tigas", "Panos", ""], ["Yangel", "Boris", ""]]}, {"id": "2107.07480", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Jonathan Lacotte, Mert Pilanci and Michael W.\n  Mahoney", "title": "Newton-LESS: Sparsification without Trade-offs for the Sketched Newton\n  Update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In second-order optimization, a potential bottleneck can be computing the\nHessian matrix of the optimized function at every iteration. Randomized\nsketching has emerged as a powerful technique for constructing estimates of the\nHessian which can be used to perform approximate Newton steps. This involves\nmultiplication by a random sketching matrix, which introduces a trade-off\nbetween the computational cost of sketching and the convergence rate of the\noptimization algorithm. A theoretically desirable but practically much too\nexpensive choice is to use a dense Gaussian sketching matrix, which produces\nunbiased estimates of the exact Newton step and which offers strong\nproblem-independent convergence guarantees. We show that the Gaussian sketching\nmatrix can be drastically sparsified, significantly reducing the computational\ncost of sketching, without substantially affecting its convergence properties.\nThis approach, called Newton-LESS, is based on a recently introduced sketching\ntechnique: LEverage Score Sparsified (LESS) embeddings. We prove that\nNewton-LESS enjoys nearly the same problem-independent local convergence rate\nas Gaussian embeddings, not just up to constant factors but even down to lower\norder terms, for a large class of optimization tasks. In particular, this leads\nto a new state-of-the-art convergence result for an iterative least squares\nsolver. Finally, we extend LESS embeddings to include uniformly sparsified\nrandom sign matrices which can be implemented efficiently and which perform\nwell in numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:33:05 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Lacotte", "Jonathan", ""], ["Pilanci", "Mert", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2107.07494", "submitter": "Tian Zhou", "authors": "Hao He, Tian Zhou, Lihua Ren, Niklas Karlsson, Aaron Flores", "title": "Mid-flight Forecasting for CPA Lines in Online Advertising", "comments": "41st International Symposium on Forecasting, June 27-30, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  For Verizon MediaDemand Side Platform(DSP), forecasting of ad campaign\nperformance not only feeds key information to the optimization server to allow\nthe system to operate on a high-performance mode, but also produces actionable\ninsights to the advertisers. In this paper, the forecasting problem for CPA\nlines in the middle of the flight is investigated by taking the bidding\nmechanism into account. The proposed methodology generates relationships\nbetween various key performance metrics and optimization signals. It can also\nbe used to estimate the sensitivity of ad campaign performance metrics to the\nadjustments of optimization signal, which is important to the design of a\ncampaign management system. The relationship between advertiser spends and\neffective Cost Per Action(eCPA) is also characterized, which serves as a\nguidance for mid-flight line adjustment to the advertisers. Several practical\nissues in implementation, such as downsampling of the dataset, are also\ndiscussed in the paper. At last, the forecasting results are validated against\nactual deliveries and demonstrates promising accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:48:15 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["He", "Hao", ""], ["Zhou", "Tian", ""], ["Ren", "Lihua", ""], ["Karlsson", "Niklas", ""], ["Flores", "Aaron", ""]]}, {"id": "2107.07511", "submitter": "Anastasios Angelopoulos", "authors": "Anastasios N. Angelopoulos, Stephen Bates", "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free\n  Uncertainty Quantification", "comments": "Blog and tutorial video\n  http://angelopoulos.ai/blog/posts/gentle-intro/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box machine learning learning methods are now routinely used in\nhigh-risk settings, like medical diagnostics, which demand uncertainty\nquantification to avoid consequential model failures. Distribution-free\nuncertainty quantification (distribution-free UQ) is a user-friendly paradigm\nfor creating statistically rigorous confidence intervals/sets for such\npredictions. Critically, the intervals/sets are valid without distributional\nassumptions or model assumptions, with explicit guarantees with finitely many\ndatapoints. Moreover, they adapt to the difficulty of the input; when the input\nexample is difficult, the uncertainty intervals/sets are large, signaling that\nthe model might be wrong. Without much work, one can use distribution-free\nmethods on any underlying algorithm, such as a neural network, to produce\nconfidence sets guaranteed to contain the ground truth with a user-specified\nprobability, such as 90%. Indeed, the methods are easy-to-understand and\ngeneral, applying to many modern prediction problems arising in the fields of\ncomputer vision, natural language processing, deep reinforcement learning, and\nso on. This hands-on introduction is aimed at a reader interested in the\npractical implementation of distribution-free UQ, including conformal\nprediction and related methods, who is not necessarily a statistician. We will\ninclude many explanatory illustrations, examples, and code samples in Python,\nwith PyTorch syntax. The goal is to provide the reader a working understanding\nof distribution-free UQ, allowing them to put confidence intervals on their\nalgorithms, with one self-contained document.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:59:50 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Angelopoulos", "Anastasios N.", ""], ["Bates", "Stephen", ""]]}, {"id": "2107.07618", "submitter": "Ismail Alarab", "authors": "Ismail Alarab, Simant Prakoonwit", "title": "Adversarial Attack for Uncertainty Estimation: Identifying Critical\n  Regions in Neural Networks", "comments": "15 pages, 6 figures, Submitted to Neural Processing Letters Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to capture data points near decision boundary in\nneural network that are often referred to a specific type of uncertainty. In\nour approach, we sought to perform uncertainty estimation based on the idea of\nadversarial attack method. In this paper, uncertainty estimates are derived\nfrom the input perturbations, unlike previous studies that provide\nperturbations on the model's parameters as in Bayesian approach. We are able to\nproduce uncertainty with couple of perturbations on the inputs. Interestingly,\nwe apply the proposed method to datasets derived from blockchain. We compare\nthe performance of model uncertainty with the most recent uncertainty methods.\nWe show that the proposed method has revealed a significant outperformance over\nother methods and provided less risk to capture model uncertainty in machine\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 21:30:26 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Alarab", "Ismail", ""], ["Prakoonwit", "Simant", ""]]}, {"id": "2107.07623", "submitter": "Luca Ganassali", "authors": "Luca Ganassali, Laurent Massouli\\'e, Marc Lelarge", "title": "Correlation detection in trees for partial graph alignment", "comments": "22 pages, 1 figure. Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider alignment of sparse graphs, which consists in finding a mapping\nbetween the nodes of two graphs which preserves most of the edges. Our approach\nis to compare local structures in the two graphs, matching two nodes if their\nneighborhoods are 'close enough': for correlated Erd\\H{o}s-R\\'enyi random\ngraphs, this problem can be locally rephrased in terms of testing whether a\npair of branching trees is drawn from either a product distribution, or a\ncorrelated distribution. We design an optimal test for this problem which gives\nrise to a message-passing algorithm for graph alignment, which provably returns\nin polynomial time a positive fraction of correctly matched vertices, and a\nvanishing fraction of mismatches. With an average degree $\\lambda = O(1)$ in\nthe graphs, and a correlation parameter $s \\in [0,1]$, this result holds with\n$\\lambda s$ large enough, and $1-s$ small enough, completing the recent\nstate-of-the-art diagram. Tighter conditions for determining whether partial\ngraph alignment (or correlation detection in trees) is feasible in polynomial\ntime are given in terms of Kullback-Leibler divergences.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 22:02:27 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ganassali", "Luca", ""], ["Massouli\u00e9", "Laurent", ""], ["Lelarge", "Marc", ""]]}, {"id": "2107.07640", "submitter": "Sergio Hernan Garrido Mejia", "authors": "Sergio Hernan Garrido Mejia, Elke Kirschbaum, Dominik Janzing", "title": "Obtaining Causal Information by Merging Datasets with MAXENT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The investigation of the question \"which treatment has a causal effect on a\ntarget variable?\" is of particular relevance in a large number of scientific\ndisciplines. This challenging task becomes even more difficult if not all\ntreatment variables were or even cannot be observed jointly with the target\nvariable. Another similarly important and challenging task is to quantify the\ncausal influence of a treatment on a target in the presence of confounders. In\nthis paper, we discuss how causal knowledge can be obtained without having\nobserved all variables jointly, but by merging the statistical information from\ndifferent datasets. We first show how the maximum entropy principle can be used\nto identify edges among random variables when assuming causal sufficiency and\nan extended version of faithfulness. Additionally, we derive bounds on the\ninterventional distribution and the average causal effect of a treatment on a\ntarget variable in the presence of confounders. In both cases we assume that\nonly subsets of the variables have been observed jointly.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 23:16:36 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Mejia", "Sergio Hernan Garrido", ""], ["Kirschbaum", "Elke", ""], ["Janzing", "Dominik", ""]]}, {"id": "2107.07687", "submitter": "Yuming Chen", "authors": "Yuming Chen, Daniel Sanz-Alonso, Rebecca Willett", "title": "Auto-differentiable Ensemble Kalman Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data assimilation is concerned with sequentially estimating a\ntemporally-evolving state. This task, which arises in a wide range of\nscientific and engineering applications, is particularly challenging when the\nstate is high-dimensional and the state-space dynamics are unknown. This paper\nintroduces a machine learning framework for learning dynamical systems in data\nassimilation. Our auto-differentiable ensemble Kalman filters (AD-EnKFs) blend\nensemble Kalman filters for state recovery with machine learning tools for\nlearning the dynamics. In doing so, AD-EnKFs leverage the ability of ensemble\nKalman filters to scale to high-dimensional states and the power of automatic\ndifferentiation to train high-dimensional surrogate models for the dynamics.\nNumerical results using the Lorenz-96 model show that AD-EnKFs outperform\nexisting methods that use expectation-maximization or particle filters to merge\ndata assimilation and machine learning. In addition, AD-EnKFs are easy to\nimplement and require minimal tuning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 03:25:30 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 18:32:48 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chen", "Yuming", ""], ["Sanz-Alonso", "Daniel", ""], ["Willett", "Rebecca", ""]]}, {"id": "2107.07724", "submitter": "Marco Sampaio", "authors": "Ricardo Barata, Miguel Leite, Ricardo Pacheco, Marco O. P. Sampaio,\n  Jo\\~ao Tiago Ascens\\~ao, Pedro Bizarro", "title": "Active learning for online training in imbalanced data streams under\n  cold start", "comments": "9 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Labeled data is essential in modern systems that rely on Machine Learning\n(ML) for predictive modelling. Such systems may suffer from the cold-start\nproblem: supervised models work well but, initially, there are no labels, which\nare costly or slow to obtain. This problem is even worse in imbalanced data\nscenarios. Online financial fraud detection is an example where labeling is: i)\nexpensive, or ii) it suffers from long delays, if relying on victims filing\ncomplaints. The latter may not be viable if a model has to be in place\nimmediately, so an option is to ask analysts to label events while minimizing\nthe number of annotations to control costs. We propose an Active Learning (AL)\nannotation system for datasets with orders of magnitude of class imbalance, in\na cold start streaming scenario. We present a computationally efficient\nOutlier-based Discriminative AL approach (ODAL) and design a novel 3-stage\nsequence of AL labeling policies where it is used as warm-up. Then, we perform\nempirical studies in four real world datasets, with various magnitudes of class\nimbalance. The results show that our method can more quickly reach a high\nperformance model than standard AL policies. Its observed gains over random\nsampling can reach 80% and be competitive with policies with an unlimited\nannotation budget or additional historical data (with 1/10 to 1/50 of the\nlabels).\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 06:49:20 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Barata", "Ricardo", ""], ["Leite", "Miguel", ""], ["Pacheco", "Ricardo", ""], ["Sampaio", "Marco O. P.", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2107.07799", "submitter": "Jie Chen", "authors": "Jie Chen, Ryosuke Shimmura and Joe Suzuki", "title": "Efficient proximal gradient algorithms for joint graphical lasso", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning an undirected graphical model from sparse data. While\nseveral efficient algorithms have been proposed for graphical lasso (GL), the\nalternating direction method of multipliers (ADMM) is the main approach taken\nconcerning for joint graphical lasso (JGL). We propose proximal gradient\nprocedures with and without a backtracking option for the JGL. These procedures\nare first-order and relatively simple, and the subproblems are solved\nefficiently in closed form. We further show the boundedness for the solution of\nthe JGL problem and the iterations in the algorithms. The numerical results\nindicate that the proposed algorithms can achieve high accuracy and precision,\nand their efficiency is competitive with state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 09:59:13 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chen", "Jie", ""], ["Shimmura", "Ryosuke", ""], ["Suzuki", "Joe", ""]]}, {"id": "2107.07828", "submitter": "Gabriel Romon", "authors": "Pierre C Bellec, Gabriel Romon", "title": "Chi-square and normal inference in high-dimensional multi-task\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper proposes chi-square and normal inference methodologies for the\nunknown coefficient matrix $B^*$ of size $p\\times T$ in a Multi-Task (MT)\nlinear model with $p$ covariates, $T$ tasks and $n$ observations under a\nrow-sparse assumption on $B^*$. The row-sparsity $s$, dimension $p$ and number\nof tasks $T$ are allowed to grow with $n$. In the high-dimensional regime\n$p\\ggg n$, in order to leverage row-sparsity, the MT Lasso is considered.\n  We build upon the MT Lasso with a de-biasing scheme to correct for the bias\ninduced by the penalty. This scheme requires the introduction of a new\ndata-driven object, coined the interaction matrix, that captures effective\ncorrelations between noise vector and residuals on different tasks. This matrix\nis psd, of size $T\\times T$ and can be computed efficiently.\n  The interaction matrix lets us derive asymptotic normal and $\\chi^2_T$\nresults under Gaussian design and $\\frac{sT+s\\log(p/s)}{n}\\to0$ which\ncorresponds to consistency in Frobenius norm. These asymptotic distribution\nresults yield valid confidence intervals for single entries of $B^*$ and valid\nconfidence ellipsoids for single rows of $B^*$, for both known and unknown\ndesign covariance $\\Sigma$. While previous proposals in grouped-variables\nregression require row-sparsity $s\\lesssim\\sqrt n$ up to constants depending on\n$T$ and logarithmic factors in $n,p$, the de-biasing scheme using the\ninteraction matrix provides confidence intervals and $\\chi^2_T$ confidence\nellipsoids under the conditions ${\\min(T^2,\\log^8p)}/{n}\\to 0$ and $$\n\\frac{sT+s\\log(p/s)+\\|\\Sigma^{-1}e_j\\|_0\\log p}{n}\\to0, \\quad\n\\frac{\\min(s,\\|\\Sigma^{-1}e_j\\|_0)}{\\sqrt n} \\sqrt{[T+\\log(p/s)]\\log p}\\to 0,\n$$ allowing row-sparsity $s\\ggg\\sqrt n$ when $\\|\\Sigma^{-1}e_j\\|_0 \\sqrt T\\lll\n\\sqrt{n}$ up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 11:19:49 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Bellec", "Pierre C", ""], ["Romon", "Gabriel", ""]]}, {"id": "2107.07853", "submitter": "Gunnar K\\\"onig", "authors": "Gunnar K\\\"onig, Timo Freiesleben, Moritz Grosse-Wentrup", "title": "A Causal Perspective on Meaningful and Robust Algorithmic Recourse", "comments": "ICML (International Conference on Machine Learning) Workshop on\n  Algorithmic Recourse", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Algorithmic recourse explanations inform stakeholders on how to act to revert\nunfavorable predictions. However, in general ML models do not predict well in\ninterventional distributions. Thus, an action that changes the prediction in\nthe desired way may not lead to an improvement of the underlying target. Such\nrecourse is neither meaningful nor robust to model refits. Extending the work\nof Karimi et al. (2021), we propose meaningful algorithmic recourse (MAR) that\nonly recommends actions that improve both prediction and target. We justify\nthis selection constraint by highlighting the differences between model audit\nand meaningful, actionable recourse explanations. Additionally, we introduce a\nrelaxation of MAR called effective algorithmic recourse (EAR), which, under\ncertain assumptions, yields meaningful recourse by only allowing interventions\non causes of the target.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:37:54 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["K\u00f6nig", "Gunnar", ""], ["Freiesleben", "Timo", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "2107.07875", "submitter": "Palash Ghosh", "authors": "Trikay Nalamada, Shruti Agarwal, Maria Jahja, Bibhas Chakraborty and\n  Palash Ghosh", "title": "A Penalized Shared-parameter Algorithm for Estimating Optimal Dynamic\n  Treatment Regimens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A dynamic treatment regimen (DTR) is a set of decision rules to personalize\ntreatments for an individual using their medical history. The Q-learning based\nQ-shared algorithm has been used to develop DTRs that involve decision rules\nshared across multiple stages of intervention. We show that the existing\nQ-shared algorithm can suffer from non-convergence due to the use of linear\nmodels in the Q-learning setup, and identify the condition in which Q-shared\nfails. Leveraging properties from expansion-constrained ordinary least-squares,\nwe give a penalized Q-shared algorithm that not only converges in settings that\nviolate the condition, but can outperform the original Q-shared algorithm even\nwhen the condition is satisfied. We give evidence for the proposed method in a\nreal-world application and several synthetic simulations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 05:31:14 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Nalamada", "Trikay", ""], ["Agarwal", "Shruti", ""], ["Jahja", "Maria", ""], ["Chakraborty", "Bibhas", ""], ["Ghosh", "Palash", ""]]}, {"id": "2107.07974", "submitter": "Wilbert Heeringa", "authors": "Wilbert Heeringa, Gosse Bouma, Martha Hofman, Eduard Drenth, Jan\n  Wijffels, Hans Van de Velde", "title": "POS tagging, lemmatization and dependency parsing of West Frisian", "comments": "6 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a lemmatizer/POS-tagger/dependency parser for West Frisian using a\ncorpus of 44,714 words in 3,126 sentences that were annotated according to the\nguidelines of Universal Dependency version 2. POS tags were assigned to words\nby using a Dutch POS tagger that was applied to a literal word-by-word\ntranslation, or to sentences of a Dutch parallel text. Best results were\nobtained when using literal translations that were created by using the Frisian\ntranslation program Oersetter. Morphologic and syntactic annotations were\ngenerated on the basis of a literal Dutch translation as well. The performance\nof the lemmatizer/tagger/annotator when it was trained using default parameters\nwas compared to the performance that was obtained when using the parameter\nvalues that were used for training the LassySmall UD 2.5 corpus. A significant\nimprovement was found for `lemma'. The Frisian lemmatizer/PoS tagger/dependency\nparser is released as a web app and as a web service.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:41:37 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 12:38:35 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Heeringa", "Wilbert", ""], ["Bouma", "Gosse", ""], ["Hofman", "Martha", ""], ["Drenth", "Eduard", ""], ["Wijffels", "Jan", ""], ["Van de Velde", "Hans", ""]]}, {"id": "2107.08001", "submitter": "Marylou Gabri\\'e", "authors": "Marylou Gabri\\'e, Grant M. Rotskoff, Eric Vanden-Eijnden", "title": "Efficient Bayesian Sampling Using Normalizing Flows to Assist Markov\n  Chain Monte Carlo Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows can generate complex target distributions and thus show\npromise in many applications in Bayesian statistics as an alternative or\ncomplement to MCMC for sampling posteriors. Since no data set from the target\nposterior distribution is available beforehand, the flow is typically trained\nusing the reverse Kullback-Leibler (KL) divergence that only requires samples\nfrom a base distribution. This strategy may perform poorly when the posterior\nis complicated and hard to sample with an untrained normalizing flow. Here we\nexplore a distinct training strategy, using the direct KL divergence as loss,\nin which samples from the posterior are generated by (i) assisting a local MCMC\nalgorithm on the posterior with a normalizing flow to accelerate its mixing\nrate and (ii) using the data generated this way to train the flow. The method\nonly requires a limited amount of \\textit{a~priori} input about the posterior,\nand can be used to estimate the evidence required for model validation, as we\nillustrate on examples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 16:40:36 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Gabri\u00e9", "Marylou", ""], ["Rotskoff", "Grant M.", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "2107.08020", "submitter": "Yiye Jiang", "authors": "Yiye Jiang, J\\'er\\'emie Bigot and Sofian Maabout", "title": "Online Graph Topology Learning from Matrix-valued Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the statistical analysis of matrix-valued time\nseries. These are data collected over a network of sensors (typically a set of\nspatial locations), recording, over time, observations of multiple\nmeasurements. From such data, we propose to learn, in an online fashion, a\ngraph that captures two aspects of dependency: one describing the sparse\nspatial relationship between sensors, and the other characterizing the\nmeasurement relationship. To this purpose, we introduce a novel multivariate\nautoregressive model to infer the graph topology encoded in the coefficient\nmatrix which captures the sparse Granger causality dependency structure present\nin such matrix-valued time series. We decompose the graph by imposing a\nKronecker sum structure on the coefficient matrix. We develop two online\napproaches to learn the graph in a recursive way. The first one uses Wald test\nfor the projected OLS estimation, where we derive the asymptotic distribution\nfor the estimator. For the second one, we formalize a Lasso-type optimization\nproblem. We rely on homotopy algorithms to derive updating rules for estimating\nthe coefficient matrix. Furthermore, we provide an adaptive tuning procedure\nfor the regularization parameter. Numerical experiments using both synthetic\nand real data, are performed to support the effectiveness of the proposed\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:21:14 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Jiang", "Yiye", ""], ["Bigot", "J\u00e9r\u00e9mie", ""], ["Maabout", "Sofian", ""]]}, {"id": "2107.08066", "submitter": "Yves-Laurent Kom Samo", "authors": "Yves-Laurent Kom Samo", "title": "LeanML: A Design Pattern To Slash Avoidable Wastes in Machine Learning\n  Projects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce the first application of the lean methodology to machine\nlearning projects. Similar to lean startups and lean manufacturing, we argue\nthat lean machine learning (LeanML) can drastically slash avoidable wastes in\ncommercial machine learning projects, reduce the business risk in investing in\nmachine learning capabilities and, in so doing, further democratize access to\nmachine learning. The lean design pattern we propose in this paper is based on\ntwo realizations. First, it is possible to estimate the best performance one\nmay achieve when predicting an outcome $y \\in \\mathcal{Y}$ using a given set of\nexplanatory variables $x \\in \\mathcal{X}$, for a wide range of performance\nmetrics, and without training any predictive model. Second, doing so is\nconsiderably easier, faster, and cheaper than learning the best predictive\nmodel. We derive formulae expressing the best $R^2$, MSE, classification\naccuracy, and log-likelihood per observation achievable when using $x$ to\npredict $y$ as a function of the mutual information $I\\left(y; x\\right)$, and\npossibly a measure of the variability of $y$ (e.g. its Shannon entropy in the\ncase of classification accuracy, and its variance in the case regression MSE).\nWe illustrate the efficacy of the LeanML design pattern on a wide range of\nregression and classification problems, synthetic and real-life.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:16:48 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Samo", "Yves-Laurent Kom", ""]]}, {"id": "2107.08089", "submitter": "Dena Asta", "authors": "Dena Asta", "title": "Non-Parametric Manifold Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an estimator for manifold distances based on graph Laplacian\nestimates of the Laplace-Beltrami operator. We show that the estimator is\nconsistent for suitable choices of graph Laplacians in the literature, based on\nan equidistributed sample of points drawn from a smooth density bounded away\nfrom zero on an unknown compact Riemannian submanifold of Euclidean space. The\nestimator resembles, and in fact its convergence properties are derived from, a\nspecial case of the Kontorovic dual reformulation of Wasserstein distance known\nas Connes' Distance Formula.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 19:32:34 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Asta", "Dena", ""]]}, {"id": "2107.08135", "submitter": "Ikko Yamane", "authors": "Ikko Yamane, Junya Honda, Florian Yger, Masashi Sugiyama", "title": "Mediated Uncoupled Learning: Learning Functions without Direct\n  Input-output Correspondences", "comments": "ICML 2021 version with correction to Figure 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary supervised learning is useful when we have paired training data of\ninput $X$ and output $Y$. However, such paired data can be difficult to collect\nin practice. In this paper, we consider the task of predicting $Y$ from $X$\nwhen we have no paired data of them, but we have two separate, independent\ndatasets of $X$ and $Y$ each observed with some mediating variable $U$, that\nis, we have two datasets $S_X = \\{(X_i, U_i)\\}$ and $S_Y = \\{(U'_j, Y'_j)\\}$. A\nnaive approach is to predict $U$ from $X$ using $S_X$ and then $Y$ from $U$\nusing $S_Y$, but we show that this is not statistically consistent. Moreover,\npredicting $U$ can be more difficult than predicting $Y$ in practice, e.g.,\nwhen $U$ has higher dimensionality. To circumvent the difficulty, we propose a\nnew method that avoids predicting $U$ but directly learns $Y = f(X)$ by\ntraining $f(X)$ with $S_{X}$ to predict $h(U)$ which is trained with $S_{Y}$ to\napproximate $Y$. We prove statistical consistency and error bounds of our\nmethod and experimentally confirm its practical usefulness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 22:13:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yamane", "Ikko", ""], ["Honda", "Junya", ""], ["Yger", "Florian", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2107.08140", "submitter": "Yang Li", "authors": "Yang Li, Kevin B Korb, Lloyd Allison", "title": "Markov Blanket Discovery using Minimum Message Length", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal discovery automates the learning of causal Bayesian networks from data\nand has been of active interest from their beginning. With the sourcing of\nlarge data sets off the internet, interest in scaling up to very large data\nsets has grown. One approach to this is to parallelize search using Markov\nBlanket (MB) discovery as a first step, followed by a process of combining MBs\nin a global causal model. We develop and explore three new methods of MB\ndiscovery using Minimum Message Length (MML) and compare them empirically to\nthe best existing methods, whether developed specifically as MB discovery or as\nfeature selection. Our best MML method is consistently competitive and has some\nadvantageous features.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 22:58:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Li", "Yang", ""], ["Korb", "Kevin B", ""], ["Allison", "Lloyd", ""]]}, {"id": "2107.08179", "submitter": "Panagiota Birmpa", "authors": "Panagiota Birmpa, Jinchao Feng, Markos A. Katsoulakis, Luc Rey-Bellet", "title": "Model Uncertainty and Correctability for Directed Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models are a fundamental tool in probabilistic\nmodeling, machine learning and artificial intelligence. They allow us to\nintegrate in a natural way expert knowledge, physical modeling, heterogeneous\nand correlated data and quantities of interest. For exactly this reason,\nmultiple sources of model uncertainty are inherent within the modular structure\nof the graphical model. In this paper we develop information-theoretic, robust\nuncertainty quantification methods and non-parametric stress tests for directed\ngraphical models to assess the effect and the propagation through the graph of\nmulti-sourced model uncertainties to quantities of interest. These methods\nallow us to rank the different sources of uncertainty and correct the graphical\nmodel by targeting its most impactful components with respect to the quantities\nof interest. Thus, from a machine learning perspective, we provide a\nmathematically rigorous approach to correctability that guarantees a systematic\nselection for improvement of components of a graphical model while controlling\npotential new errors created in the process in other parts of the model. We\ndemonstrate our methods in two physico-chemical examples, namely quantum\nscale-informed chemical kinetics and materials screening to improve the\nefficiency of fuel cells.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 04:30:37 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Birmpa", "Panagiota", ""], ["Feng", "Jinchao", ""], ["Katsoulakis", "Markos A.", ""], ["Rey-Bellet", "Luc", ""]]}, {"id": "2107.08195", "submitter": "Jiahua Luo", "authors": "Jiahua Luo (1), Chi-Man Vong (1) and Jie Du (2) ((1) Department of\n  Computer and Information Science, University of Macau, Macao SAR, China, (2)\n  School of Biomedical Engineering, Health Science Center, Shenzhen University,\n  Shenzhen, China)", "title": "Sparse Bayesian Learning with Diagonal Quasi-Newton Method For Large\n  Scale Classification", "comments": "11 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Sparse Bayesian Learning (SBL) constructs an extremely sparse probabilistic\nmodel with very competitive generalization. However, SBL needs to invert a big\ncovariance matrix with complexity O(M^3 ) (M: feature size) for updating the\nregularization priors, making it difficult for practical use. There are three\nissues in SBL: 1) Inverting the covariance matrix may obtain singular solutions\nin some cases, which hinders SBL from convergence; 2) Poor scalability to\nproblems with high dimensional feature space or large data size; 3) SBL easily\nsuffers from memory overflow for large-scale data. This paper addresses these\nissues with a newly proposed diagonal Quasi-Newton (DQN) method for SBL called\nDQN-SBL where the inversion of big covariance matrix is ignored so that the\ncomplexity and memory storage are reduced to O(M). The DQN-SBL is thoroughly\nevaluated on non-linear classifiers and linear feature selection using various\nbenchmark datasets of different sizes. Experimental results verify that DQN-SBL\nreceives competitive generalization with a very sparse model and scales well to\nlarge-scale problems.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 06:55:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Luo", "Jiahua", ""], ["Vong", "Chi-Man", ""], ["Du", "Jie", ""]]}, {"id": "2107.08209", "submitter": "Dirk Tasche", "authors": "Dirk Tasche", "title": "Minimising quantifier variance under prior probability shift", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the binary prevalence quantification problem under prior probability\nshift, we determine the asymptotic variance of the maximum likelihood\nestimator. We find that it is a function of the Brier score for the regression\nof the class label against the features under the test data set distribution.\nThis observation suggests that optimising the accuracy of a base classifier on\nthe training data set helps to reduce the variance of the related quantifier on\nthe test data set. Therefore, we also point out training criteria for the base\nclassifier that imply optimisation of both of the Brier scores on the training\nand the test data sets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 09:28:06 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 19:31:37 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tasche", "Dirk", ""]]}, {"id": "2107.08265", "submitter": "P.K. Srijith", "authors": "Ayush Jain (1), P. K. Srijith (1) and Mohammad Emtiyaz Khan (2) ((1)\n  Department of Computer Science and Engineering, Indian Institute of\n  Technology Hyderabad, India, (2) RIKEN Center for AI Project, Tokyo, Japan)", "title": "Subset-of-Data Variational Inference for Deep Gaussian-Processes\n  Regression", "comments": "Accepted in the 37th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Gaussian Processes (DGPs) are multi-layer, flexible extensions of\nGaussian processes but their training remains challenging. Sparse\napproximations simplify the training but often require optimization over a\nlarge number of inducing inputs and their locations across layers. In this\npaper, we simplify the training by setting the locations to a fixed subset of\ndata and sampling the inducing inputs from a variational distribution. This\nreduces the trainable parameters and computation cost without significant\nperformance degradations, as demonstrated by our empirical results on\nregression problems. Our modifications simplify and stabilize DGP training\nwhile making it amenable to sampling schemes for setting the inducing inputs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 15:55:35 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Jain", "Ayush", ""], ["Srijith", "P. K.", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2107.08273", "submitter": "Hengguan Huang", "authors": "Hengguan Huang, Hongfu Liu, Hao Wang, Chang Xiao and Ye Wang", "title": "STRODE: Stochastic Boundary Ordinary Differential Equation", "comments": "Accepted at ICML 2021; typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perception of time from sequentially acquired sensory inputs is rooted in\neveryday behaviors of individual organisms. Yet, most algorithms for\ntime-series modeling fail to learn dynamics of random event timings directly\nfrom visual or audio inputs, requiring timing annotations during training that\nare usually unavailable for real-world applications. For instance, neuroscience\nperspectives on postdiction imply that there exist variable temporal ranges\nwithin which the incoming sensory inputs can affect the earlier perception, but\nsuch temporal ranges are mostly unannotated for real applications such as\nautomatic speech recognition (ASR). In this paper, we present a probabilistic\nordinary differential equation (ODE), called STochastic boundaRy ODE (STRODE),\nthat learns both the timings and the dynamics of time series data without\nrequiring any timing annotations during training. STRODE allows the usage of\ndifferential equations to sample from the posterior point processes,\nefficiently and analytically. We further provide theoretical guarantees on the\nlearning of STRODE. Our empirical results show that our approach successfully\ninfers event timings of time series data. Our method achieves competitive or\nsuperior performances compared to existing state-of-the-art methods for both\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 16:25:46 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Huang", "Hengguan", ""], ["Liu", "Hongfu", ""], ["Wang", "Hao", ""], ["Xiao", "Chang", ""], ["Wang", "Ye", ""]]}, {"id": "2107.08346", "submitter": "Chen-Yu Wei", "authors": "Haipeng Luo, Chen-Yu Wei, Chung-Wei Lee", "title": "Policy Optimization in Adversarial MDPs: Improved Exploration via\n  Dilated Bonuses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Policy optimization is a widely-used method in reinforcement learning. Due to\nits local-search nature, however, theoretical guarantees on global optimality\noften rely on extra assumptions on the Markov Decision Processes (MDPs) that\nbypass the challenge of global exploration. To eliminate the need of such\nassumptions, in this work, we develop a general solution that adds dilated\nbonuses to the policy update to facilitate global exploration. To showcase the\npower and generality of this technique, we apply it to several episodic MDP\nsettings with adversarial losses and bandit feedback, improving and\ngeneralizing the state-of-the-art. Specifically, in the tabular case, we obtain\n$\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret where $T$ is the number of episodes,\nimproving the $\\widetilde{\\mathcal{O}}({T}^{2/3})$ regret bound by Shani et al.\n(2020). When the number of states is infinite, under the assumption that the\nstate-action values are linear in some low-dimensional features, we obtain\n$\\widetilde{\\mathcal{O}}({T}^{2/3})$ regret with the help of a simulator,\nmatching the result of Neu and Olkhovskaya (2020) while importantly removing\nthe need of an exploratory policy that their algorithm requires. When a\nsimulator is unavailable, we further consider a linear MDP setting and obtain\n$\\widetilde{\\mathcal{O}}({T}^{14/15})$ regret, which is the first result for\nlinear MDPs with adversarial losses and bandit feedback.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 02:30:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Luo", "Haipeng", ""], ["Wei", "Chen-Yu", ""], ["Lee", "Chung-Wei", ""]]}, {"id": "2107.08353", "submitter": "Chirag Gupta", "authors": "Chirag Gupta and Aaditya K. Ramdas", "title": "Top-label calibration", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of post-hoc calibration for multiclass classification,\nwith an emphasis on histogram binning. Multiple works have focused on\ncalibration with respect to the confidence of just the predicted class (or\n'top-label'). We find that the popular notion of confidence calibration [Guo et\nal., 2017] is not sufficiently strong -- there exist predictors that are not\ncalibrated in any meaningful way but are perfectly confidence calibrated. We\npropose a closely related (but subtly different) notion, top-label calibration,\nthat accurately captures the intuition and simplicity of confidence\ncalibration, but addresses its drawbacks. We formalize a histogram binning (HB)\nalgorithm that reduces top-label multiclass calibration to the binary case,\nprove that it has clean theoretical guarantees without distributional\nassumptions, and perform a methodical study of its practical performance. Some\nprediction tasks require stricter notions of multiclass calibration such as\nclass-wise or canonical calibration. We formalize appropriate HB algorithms\ncorresponding to each of these goals. In experiments with deep neural nets, we\nfind that our principled versions of HB are often better than temperature\nscaling, for both top-label and class-wise calibration. Code for this work will\nbe made publicly available at https://github.com/aigen/df-posthoc-calibration.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 03:27:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gupta", "Chirag", ""], ["Ramdas", "Aaditya K.", ""]]}, {"id": "2107.08444", "submitter": "Shay Moran", "authors": "Noga Alon and Steve Hanneke and Ron Holzman and Shay Moran", "title": "A Theory of PAC Learnability of Partial Concept Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We extend the theory of PAC learning in a way which allows to model a rich\nvariety of learning tasks where the data satisfy special properties that ease\nthe learning process. For example, tasks where the distance of the data from\nthe decision boundary is bounded away from zero. The basic and simple idea is\nto consider partial concepts: these are functions that can be undefined on\ncertain parts of the space. When learning a partial concept, we assume that the\nsource distribution is supported only on points where the partial concept is\ndefined.\n  This way, one can naturally express assumptions on the data such as lying on\na lower dimensional surface or margin conditions. In contrast, it is not at all\nclear that such assumptions can be expressed by the traditional PAC theory. In\nfact we exhibit easy-to-learn partial concept classes which provably cannot be\ncaptured by the traditional PAC theory. This also resolves a question posed by\nAttias, Kontorovich, and Mansour 2019.\n  We characterize PAC learnability of partial concept classes and reveal an\nalgorithmic landscape which is fundamentally different than the classical one.\nFor example, in the classical PAC model, learning boils down to Empirical Risk\nMinimization (ERM). In stark contrast, we show that the ERM principle fails in\nexplaining learnability of partial concept classes. In fact, we demonstrate\nclasses that are incredibly easy to learn, but such that any algorithm that\nlearns them must use an hypothesis space with unbounded VC dimension. We also\nfind that the sample compression conjecture fails in this setting.\n  Thus, this theory features problems that cannot be represented nor solved in\nthe traditional way. We view this as evidence that it might provide insights on\nthe nature of learnability in realistic scenarios which the classical theory\nfails to explain.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 13:29:26 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 19:25:35 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Alon", "Noga", ""], ["Hanneke", "Steve", ""], ["Holzman", "Ron", ""], ["Moran", "Shay", ""]]}, {"id": "2107.08459", "submitter": "Luca Martino", "authors": "Luca Martino, V\\'ictor Elvira", "title": "Compressed Monte Carlo with application in particle filtering", "comments": null, "journal-ref": "Information Sciences, Volume 553, April 2021, Pages 331-352", "doi": "10.1016/j.ins.2020.10.022", "report-no": null, "categories": "stat.CO cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian models have become very popular over the last years in several\nfields such as signal processing, statistics, and machine learning. Bayesian\ninference requires the approximation of complicated integrals involving\nposterior distributions. For this purpose, Monte Carlo (MC) methods, such as\nMarkov Chain Monte Carlo and importance sampling algorithms, are often\nemployed. In this work, we introduce the theory and practice of a Compressed MC\n(C-MC) scheme to compress the statistical information contained in a set of\nrandom samples. In its basic version, C-MC is strictly related to the\nstratification technique, a well-known method used for variance reduction\npurposes. Deterministic C-MC schemes are also presented, which provide very\ngood performance. The compression problem is strictly related to the moment\nmatching approach applied in different filtering techniques, usually called as\nGaussian quadrature rules or sigma-point methods. C-MC can be employed in a\ndistributed Bayesian inference framework when cheap and fast communications\nwith a central processor are required. Furthermore, C-MC is useful within\nparticle filtering and adaptive IS algorithms, as shown by three novel schemes\nintroduced in this work. Six numerical results confirm the benefits of the\nintroduced schemes, outperforming the corresponding benchmark methods. A\nrelated code is also provided.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:32:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Martino", "Luca", ""], ["Elvira", "V\u00edctor", ""]]}, {"id": "2107.08461", "submitter": "Qiyiwen Zhang", "authors": "Qiyiwen Zhang, Zhiqi Bu, Kan Chen, Qi Long", "title": "Differentially Private Bayesian Neural Networks on Accuracy, Privacy and\n  Reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural network (BNN) allows for uncertainty quantification in\nprediction, offering an advantage over regular neural networks that has not\nbeen explored in the differential privacy (DP) framework. We fill this\nimportant gap by leveraging recent development in Bayesian deep learning and\nprivacy accounting to offer a more precise analysis of the trade-off between\nprivacy and accuracy in BNN. We propose three DP-BNNs that characterize the\nweight uncertainty for the same network architecture in distinct ways, namely\nDP-SGLD (via the noisy gradient method), DP-BBP (via changing the parameters of\ninterest) and DP-MC Dropout (via the model architecture). Interestingly, we\nshow a new equivalence between DP-SGD and DP-SGLD, implying that some\nnon-Bayesian DP training naturally allows for uncertainty quantification.\nHowever, the hyperparameters such as learning rate and batch size, can have\ndifferent or even opposite effects in DP-SGD and DP-SGLD.\n  Extensive experiments are conducted to compare DP-BNNs, in terms of privacy\nguarantee, prediction accuracy, uncertainty quantification, calibration,\ncomputation speed, and generalizability to network architecture. As a result,\nwe observe a new tradeoff between the privacy and the reliability. When\ncompared to non-DP and non-Bayesian approaches, DP-SGLD is remarkably accurate\nunder strong privacy guarantee, demonstrating the great potential of DP-BNN in\nreal-world tasks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:37:07 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhang", "Qiyiwen", ""], ["Bu", "Zhiqi", ""], ["Chen", "Kan", ""], ["Long", "Qi", ""]]}, {"id": "2107.08465", "submitter": "Luca Martino", "authors": "Luca Martino, V\\'ictor Elvira, Javier L\\'opez-Santiago, Gustau\n  Camps-Valls", "title": "Compressed particle methods for expensive models with application in\n  Astronomy and Remote Sensing", "comments": "published in IEEE Transactions on Aerospace and Electronic Systems", "journal-ref": null, "doi": "10.1109/TAES.2021.3061791", "report-no": null, "categories": "cs.CE stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many inference problems, the evaluation of complex and costly models is\noften required. In this context, Bayesian methods have become very popular in\nseveral fields over the last years, in order to obtain parameter inversion,\nmodel selection or uncertainty quantification. Bayesian inference requires the\napproximation of complicated integrals involving (often costly) posterior\ndistributions. Generally, this approximation is obtained by means of Monte\nCarlo (MC) methods. In order to reduce the computational cost of the\ncorresponding technique, surrogate models (also called emulators) are often\nemployed. Another alternative approach is the so-called Approximate Bayesian\nComputation (ABC) scheme. ABC does not require the evaluation of the costly\nmodel but the ability to simulate artificial data according to that model.\nMoreover, in ABC, the choice of a suitable distance between real and artificial\ndata is also required. In this work, we introduce a novel approach where the\nexpensive model is evaluated only in some well-chosen samples. The selection of\nthese nodes is based on the so-called compressed Monte Carlo (CMC) scheme. We\nprovide theoretical results supporting the novel algorithms and give empirical\nevidence of the performance of the proposed method in several numerical\nexperiments. Two of them are real-world applications in astronomy and satellite\nremote sensing.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:45:23 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Martino", "Luca", ""], ["Elvira", "V\u00edctor", ""], ["L\u00f3pez-Santiago", "Javier", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "2107.08467", "submitter": "Ramin Hasani", "authors": "Sophie Gruenbacher, Mathias Lechner, Ramin Hasani, Daniela Rus, Thomas\n  A. Henzinger, Scott Smolka, Radu Grosu", "title": "GoTube: Scalable Stochastic Verification of Continuous-Depth Models", "comments": "17 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.DS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new stochastic verification algorithm that formally quantifies\nthe behavioral robustness of any time-continuous process formulated as a\ncontinuous-depth model. The algorithm solves a set of global optimization (Go)\nproblems over a given time horizon to construct a tight enclosure (Tube) of the\nset of all process executions starting from a ball of initial states. We call\nour algorithm GoTube. Through its construction, GoTube ensures that the\nbounding tube is conservative up to a desired probability. GoTube is\nimplemented in JAX and optimized to scale to complex continuous-depth models.\nCompared to advanced reachability analysis tools for time-continuous neural\nnetworks, GoTube provably does not accumulate over-approximation errors between\ntime steps and avoids the infamous wrapping effect inherent in symbolic\ntechniques. We show that GoTube substantially outperforms state-of-the-art\nverification tools in terms of the size of the initial ball, speed,\ntime-horizon, task completion, and scalability, on a large set of experiments.\nGoTube is stable and sets the state-of-the-art for its ability to scale up to\ntime horizons well beyond what has been possible before.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:59:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gruenbacher", "Sophie", ""], ["Lechner", "Mathias", ""], ["Hasani", "Ramin", ""], ["Rus", "Daniela", ""], ["Henzinger", "Thomas A.", ""], ["Smolka", "Scott", ""], ["Grosu", "Radu", ""]]}, {"id": "2107.08498", "submitter": "David Kohns Mr", "authors": "David Kohns and Tibor Szendrei", "title": "Decoupling Shrinkage and Selection for the Bayesian Quantile Regression", "comments": "First Draft: 18/07/2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the idea of decoupling shrinkage and sparsity for\ncontinuous priors to Bayesian Quantile Regression (BQR). The procedure follows\ntwo steps: In the first step, we shrink the quantile regression posterior\nthrough state of the art continuous priors and in the second step, we sparsify\nthe posterior through an efficient variant of the adaptive lasso, the signal\nadaptive variable selection (SAVS) algorithm. We propose a new variant of the\nSAVS which automates the choice of penalisation through quantile specific\nloss-functions that are valid in high dimensions. We show in large scale\nsimulations that our selection procedure decreases bias irrespective of the\ntrue underlying degree of sparsity in the data, compared to the un-sparsified\nregression posterior. We apply our two-step approach to a high dimensional\ngrowth-at-risk (GaR) exercise. The prediction accuracy of the un-sparsified\nposterior is retained while yielding interpretable quantile specific variable\nselection results. Our procedure can be used to communicate to policymakers\nwhich variables drive downside risk to the macro economy.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 17:22:33 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kohns", "David", ""], ["Szendrei", "Tibor", ""]]}, {"id": "2107.08595", "submitter": "Xiaowei Zhang", "authors": "Liang Ding, Rui Tuo, Xiaowei Zhang", "title": "High-Dimensional Simulation Optimization via Brownian Fields and Sparse\n  Grids", "comments": "Main body: 36 pages, 7 figures, 2 tables. Supplemental material: 32\n  pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  High-dimensional simulation optimization is notoriously challenging. We\npropose a new sampling algorithm that converges to a global optimal solution\nand suffers minimally from the curse of dimensionality. The algorithm consists\nof two stages. First, we take samples following a sparse grid experimental\ndesign and approximate the response surface via kernel ridge regression with a\nBrownian field kernel. Second, we follow the expected improvement strategy --\nwith critical modifications that boost the algorithm's sample efficiency -- to\niteratively sample from the next level of the sparse grid. Under mild\nconditions on the smoothness of the response surface and the simulation noise,\nwe establish upper bounds on the convergence rate for both noise-free and noisy\nsimulation samples. These upper bounds deteriorate only slightly in the\ndimension of the feasible set, and they can be improved if the objective\nfunction is known to be of a higher-order smoothness. Extensive numerical\nexperiments demonstrate that the proposed algorithm dramatically outperforms\ntypical alternatives in practice.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 03:03:27 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 01:57:21 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ding", "Liang", ""], ["Tuo", "Rui", ""], ["Zhang", "Xiaowei", ""]]}, {"id": "2107.08596", "submitter": "Isay Katsman", "authors": "Isay Katsman, Aaron Lou, Derek Lim, Qingxuan Jiang, Ser-Nam Lim,\n  Christopher De Sa", "title": "Equivariant Manifold Flows", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tractably modelling distributions over manifolds has long been an important\ngoal in the natural sciences. Recent work has focused on developing general\nmachine learning models to learn such distributions. However, for many\napplications these distributions must respect manifold symmetries -- a trait\nwhich most previous models disregard. In this paper, we lay the theoretical\nfoundations for learning symmetry-invariant distributions on arbitrary\nmanifolds via equivariant manifold flows. We demonstrate the utility of our\napproach by using it to learn gauge invariant densities over $SU(n)$ in the\ncontext of quantum field theory.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 03:04:44 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Katsman", "Isay", ""], ["Lou", "Aaron", ""], ["Lim", "Derek", ""], ["Jiang", "Qingxuan", ""], ["Lim", "Ser-Nam", ""], ["De Sa", "Christopher", ""]]}, {"id": "2107.08648", "submitter": "Philipp Windischhofer", "authors": "Chris Pollard, Philipp Windischhofer", "title": "Transport away your problems: Calibrating stochastic simulations with\n  optimal transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an hep-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic simulators are an indispensable tool in many branches of science.\nOften based on first principles, they deliver a series of samples whose\ndistribution implicitly defines a probability measure to describe the phenomena\nof interest. However, the fidelity of these simulators is not always sufficient\nfor all scientific purposes, necessitating the construction of ad-hoc\ncorrections to \"calibrate\" the simulation and ensure that its output is a\nfaithful representation of reality. In this paper, we leverage methods from\ntransportation theory to construct such corrections in a systematic way. We use\na neural network to compute minimal modifications to the individual samples\nproduced by the simulator such that the resulting distribution becomes properly\ncalibrated. We illustrate the method and its benefits in the context of\nexperimental particle physics, where the need for calibrated stochastic\nsimulators is particularly pronounced.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 07:11:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Pollard", "Chris", ""], ["Windischhofer", "Philipp", ""]]}, {"id": "2107.08649", "submitter": "Ariel Neufeld", "authors": "Dong-Young Lim, Ariel Neufeld, Sotirios Sabanis, Ying Zhang", "title": "Non-asymptotic estimates for TUSLA algorithm for non-convex learning\n  with applications to neural networks with ReLU activation function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non-convex stochastic optimization problems where the objective\nfunctions have super-linearly growing and discontinuous stochastic gradients.\nIn such a setting, we provide a non-asymptotic analysis for the tamed\nunadjusted stochastic Langevin algorithm (TUSLA) introduced in Lovas et al.\n(2021). In particular, we establish non-asymptotic error bounds for the TUSLA\nalgorithm in Wasserstein-1 and Wasserstein-2 distances. The latter result\nenables us to further derive non-asymptotic estimates for the expected excess\nrisk. To illustrate the applicability of the main results, we consider an\nexample from transfer learning with ReLU neural networks, which represents a\nkey paradigm in machine learning. Numerical experiments are presented for the\naforementioned example which supports our theoretical findings. Hence, in this\nsetting, we demonstrate both theoretically and numerically that the TUSLA\nalgorithm can solve the optimization problem involving neural networks with\nReLU activation function. Besides, we provide simulation results for synthetic\nexamples where popular algorithms, e.g. ADAM, AMSGrad, RMSProp, and (vanilla)\nSGD, may fail to find the minimizer of the objective functions due to the\nsuper-linear growth and the discontinuity of the corresponding stochastic\ngradient, while the TUSLA algorithm converges rapidly to the optimal solution.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 07:13:02 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lim", "Dong-Young", ""], ["Neufeld", "Ariel", ""], ["Sabanis", "Sotirios", ""], ["Zhang", "Ying", ""]]}, {"id": "2107.08686", "submitter": "Shaojie Li", "authors": "Shaojie Li and Yong Liu", "title": "Improved Learning Rates for Stochastic Optimization: Two Theoretical\n  Viewpoints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization performance of stochastic optimization stands a central place\nin learning theory. In this paper, we investigate the excess risk performance\nand towards improved learning rates for two popular approaches of stochastic\noptimization: empirical risk minimization (ERM) and stochastic gradient descent\n(SGD). Although there exists plentiful generalization analysis of ERM and SGD\nfor supervised learning, current theoretical understandings of ERM and SGD\neither have stronger assumptions in convex learning, e.g., strong convexity, or\nshow slow rates and less studied in nonconvex learning. Motivated by these\nproblems, we aim to provide improved rates under milder assumptions in convex\nlearning and derive faster rates in nonconvex learning. It is notable that our\nanalysis span two popular theoretical viewpoints: \\emph{stability} and\n\\emph{uniform convergence}. Specifically, in stability regime, we present high\nprobability learning rates of order $\\mathcal{O} (1/n)$ w.r.t. the sample size\n$n$ for ERM and SGD with milder assumptions in convex learning and similar high\nprobability rates of order $\\mathcal{O} (1/n)$ in nonconvex learning, rather\nthan in expectation. Furthermore, this type of learning rate is improved to\nfaster order $\\mathcal{O} (1/n^2)$ in uniform convergence regime. To our best\nknowledge, for ERM and SGD, the learning rates presented in this paper are all\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 08:46:14 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 14:45:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Shaojie", ""], ["Liu", "Yong", ""]]}, {"id": "2107.08756", "submitter": "Piotr Skalski Mr", "authors": "Iker Perez, Piotr Skalski, Alec Barns-Graham, Jason Wong, David Sutton", "title": "Path Integrals for the Attribution of Model Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Enabling interpretations of model uncertainties is of key importance in\nBayesian machine learning applications. Often, this requires to meaningfully\nattribute predictive uncertainties to source features in an image, text or\ncategorical array. However, popular attribution methods are particularly\ndesigned for classification and regression scores. In order to explain\nuncertainties, state of the art alternatives commonly procure counterfactual\nfeature vectors, and proceed by making direct comparisons. In this paper, we\nleverage path integrals to attribute uncertainties in Bayesian differentiable\nmodels. We present a novel algorithm that relies on in-distribution curves\nconnecting a feature vector to some counterfactual counterpart, and we retain\ndesirable properties of interpretability methods. We validate our approach on\nbenchmark image data sets with varying resolution, and show that it\nsignificantly simplifies interpretability over the existing alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:07:34 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 14:32:43 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Perez", "Iker", ""], ["Skalski", "Piotr", ""], ["Barns-Graham", "Alec", ""], ["Wong", "Jason", ""], ["Sutton", "David", ""]]}, {"id": "2107.08761", "submitter": "Thomas Bartz-Beielstein", "authors": "Eva Bartz and Martin Zaefferer and Olaf Mersmann and Thomas\n  Bartz-Beielstein", "title": "Experimental Investigation and Evaluation of Model-based Hyperparameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning algorithms such as random forests or xgboost are gaining\nmore importance and are increasingly incorporated into production processes in\norder to enable comprehensive digitization and, if possible, automation of\nprocesses. Hyperparameters of these algorithms used have to be set\nappropriately, which can be referred to as hyperparameter tuning or\noptimization. Based on the concept of tunability, this article presents an\noverview of theoretical and practical results for popular machine learning\nalgorithms. This overview is accompanied by an experimental analysis of 30\nhyperparameters from six relevant machine learning algorithms. In particular,\nit provides (i) a survey of important hyperparameters, (ii) two parameter\ntuning studies, and (iii) one extensive global parameter tuning study, as well\nas (iv) a new way, based on consensus ranking, to analyze results from multiple\nalgorithms. The R package mlr is used as a uniform interface to the machine\nlearning models. The R package SPOT is used to perform the actual tuning\n(optimization). All additional code is provided together with this paper.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:37:37 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bartz", "Eva", ""], ["Zaefferer", "Martin", ""], ["Mersmann", "Olaf", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2107.08784", "submitter": "Xiao Liu", "authors": "Xiao Liu, Rong Pan", "title": "Boost-R: Gradient Boosted Trees for Recurrence Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrence data arise from multi-disciplinary domains spanning reliability,\ncyber security, healthcare, online retailing, etc. This paper investigates an\nadditive-tree-based approach, known as Boost-R (Boosting for Recurrence Data),\nfor recurrent event data with both static and dynamic features. Boost-R\nconstructs an ensemble of gradient boosted additive trees to estimate the\ncumulative intensity function of the recurrent event process, where a new tree\nis added to the ensemble by minimizing the regularized L2 distance between the\nobserved and predicted cumulative intensity. Unlike conventional regression\ntrees, a time-dependent function is constructed by Boost-R on each tree leaf.\nThe sum of these functions, from multiple trees, yields the ensemble estimator\nof the cumulative intensity. The divide-and-conquer nature of tree-based\nmethods is appealing when hidden sub-populations exist within a heterogeneous\npopulation. The non-parametric nature of regression trees helps to avoid\nparametric assumptions on the complex interactions between event processes and\nfeatures. Critical insights and advantages of Boost-R are investigated through\ncomprehensive numerical examples. Datasets and computer code of Boost-R are\nmade available on GitHub. To our best knowledge, Boost-R is the first gradient\nboosted additive-tree-based approach for modeling large-scale recurrent event\ndata with both static and dynamic feature information.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:44:09 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Xiao", ""], ["Pan", "Rong", ""]]}, {"id": "2107.08881", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Matko Bo\\v{s}njak, Thomas Kipf, Alexander\n  Lerchner, Raia Hadsell, Razvan Pascanu, Charles Blundell", "title": "Reasoning-Modulated Representations", "comments": "ICML 2021 Workshop on Self-Supervised Learning for Reasoning and\n  Perception (Spotlight Talk). 7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks leverage robust internal representations in order to\ngeneralise. Learning them is difficult, and often requires a large training set\nthat covers the data distribution densely. We study a common setting where our\ntask is not purely opaque. Indeed, very often we may have access to information\nabout the underlying system (e.g. that observations must obey certain laws of\nphysics) that any \"tabula rasa\" neural network would need to re-learn from\nscratch, penalising data efficiency. We incorporate this information into a\npre-trained reasoning module, and investigate its role in shaping the\ndiscovered representations in diverse self-supervised learning settings from\npixels. Our approach paves the way for a new class of data-efficient\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:57:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Bo\u0161njak", "Matko", ""], ["Kipf", "Thomas", ""], ["Lerchner", "Alexander", ""], ["Hadsell", "Raia", ""], ["Pascanu", "Razvan", ""], ["Blundell", "Charles", ""]]}, {"id": "2107.08924", "submitter": "Ian Osband", "authors": "Ian Osband, Zheng Wen, Mohammad Asghari, Morteza Ibrahimi, Xiyuan Lu,\n  and Benjamin Van Roy", "title": "Epistemic Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \\textit{epistemic neural network} (ENN) as an interface for\nuncertainty modeling in deep learning. All existing approaches to uncertainty\nmodeling can be expressed as ENNs, and any ENN can be identified with a\nBayesian neural network. However, this new perspective provides several\npromising directions for future research. Where prior work has developed\nprobabilistic inference tools for neural networks; we ask instead, `which\nneural networks are suitable as tools for probabilistic inference?'. We propose\na clear and simple metric for progress in ENNs: the KL-divergence with respect\nto a target distribution. We develop a computational testbed based on inference\nin a neural network Gaussian process and release our code as a benchmark at\n\\url{https://github.com/deepmind/enn}. We evaluate several canonical approaches\nto uncertainty modeling in deep learning, and find they vary greatly in their\nperformance. We provide insight to the sensitivity of these results and show\nthat our metric is highly correlated with performance in sequential decision\nproblems. Finally, we provide indications that new ENN architectures can\nimprove performance in both the statistical quality and computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:37:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Osband", "Ian", ""], ["Wen", "Zheng", ""], ["Asghari", "Mohammad", ""], ["Ibrahimi", "Morteza", ""], ["Lu", "Xiyuan", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "2107.08928", "submitter": "William Blanzeisky", "authors": "William Blanzeisky, P\\'adraig Cunningham, Kenneth Kennedy", "title": "Introducing a Family of Synthetic Datasets for Research on Bias in\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A significant impediment to progress in research on bias in machine learning\n(ML) is the availability of relevant datasets. This situation is unlikely to\nchange much given the sensitivity of such data. For this reason, there is a\nrole for synthetic data in this research. In this short paper, we present one\nsuch family of synthetic data sets. We provide an overview of the data,\ndescribe how the level of bias can be varied, and present a simple example of\nan experiment on the data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:40:22 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Blanzeisky", "William", ""], ["Cunningham", "P\u00e1draig", ""], ["Kennedy", "Kenneth", ""]]}, {"id": "2107.08933", "submitter": "Khaled Koutini", "authors": "Khaled Koutini, Hamid Eghbal-zadeh, Florian Henkel, Jan Schl\\\"uter,\n  Gerhard Widmer", "title": "Over-Parameterization and Generalization in Audio Classification", "comments": "Presented at the ICML 2021 Workshop on Overparameterization: Pitfalls\n  & Opportunities", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have been dominating classification\ntasks in various domains, such as machine vision, machine listening, and\nnatural language processing. In machine listening, while generally exhibiting\nvery good generalization capabilities, CNNs are sensitive to the specific audio\nrecording device used, which has been recognized as a substantial problem in\nthe acoustic scene classification (DCASE) community. In this study, we\ninvestigate the relationship between over-parameterization of acoustic scene\nclassification models, and their resulting generalization abilities.\nSpecifically, we test scaling CNNs in width and depth, under different\nconditions. Our results indicate that increasing width improves generalization\nto unseen devices, even without an increase in the number of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:48:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Koutini", "Khaled", ""], ["Eghbal-zadeh", "Hamid", ""], ["Henkel", "Florian", ""], ["Schl\u00fcter", "Jan", ""], ["Widmer", "Gerhard", ""]]}, {"id": "2107.09028", "submitter": "Antonios Alexos", "authors": "Antonios Alexos, Alex Boyd, Stephan Mandt", "title": "Structured Stochastic Gradient MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic gradient Markov chain Monte Carlo (SGMCMC) is considered the gold\nstandard for Bayesian inference in large-scale models, such as Bayesian neural\nnetworks. Since practitioners face speed versus accuracy tradeoffs in these\nmodels, variational inference (VI) is often the preferable option.\nUnfortunately, VI makes strong assumptions on both the factorization and\nfunctional form of the posterior. In this work, we propose a new non-parametric\nvariational approximation that makes no assumptions about the approximate\nposterior's functional form and allows practitioners to specify the exact\ndependencies the algorithm should respect or break. The approach relies on a\nnew Langevin-type algorithm that operates on a modified energy function, where\nparts of the latent variables are averaged over samples from earlier iterations\nof the Markov chain. This way, statistical dependencies can be broken in a\ncontrolled way, allowing the chain to mix faster. This scheme can be further\nmodified in a ''dropout'' manner, leading to even more scalability. By\nimplementing the scheme on a ResNet-20 architecture, we obtain better\npredictive likelihoods and larger effective sample sizes than full SGMCMC.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:18:10 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alexos", "Antonios", ""], ["Boyd", "Alex", ""], ["Mandt", "Stephan", ""]]}, {"id": "2107.09031", "submitter": "Sebastian Zeng", "authors": "Sebastian Zeng, Florian Graf, Christoph Hofer, Roland Kwitt", "title": "Topological Attention for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of (point) forecasting $ \\textit{univariate} $ time series is\nconsidered. Most approaches, ranging from traditional statistical methods to\nrecent learning-based techniques with neural networks, directly operate on raw\ntime series observations. As an extension, we study whether $\\textit{local\ntopological properties}$, as captured via persistent homology, can serve as a\nreliable signal that provides complementary information for learning to\nforecast. To this end, we propose $\\textit{topological attention}$, which\nallows attending to local topological features within a time horizon of\nhistorical data. Our approach easily integrates into existing end-to-end\ntrainable forecasting models, such as $\\texttt{N-BEATS}$, and in combination\nwith the latter exhibits state-of-the-art performance on the large-scale M4\nbenchmark dataset of 100,000 diverse time series from different domains.\nAblation experiments, as well as a comparison to a broad range of forecasting\nmethods in a setting where only a single time series is available for training,\ncorroborate the beneficial nature of including local topological information\nthrough an attention mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:24:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zeng", "Sebastian", ""], ["Graf", "Florian", ""], ["Hofer", "Christoph", ""], ["Kwitt", "Roland", ""]]}, {"id": "2107.09044", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Behzad Haghgoo, Annie S. Chen, Aditi Raghunathan,\n  Pang Wei Koh, Shiori Sagawa, Percy Liang, Chelsea Finn", "title": "Just Train Twice: Improving Group Robustness without Training Group\n  Information", "comments": "International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard training via empirical risk minimization (ERM) can produce models\nthat achieve high accuracy on average but low accuracy on certain groups,\nespecially in the presence of spurious correlations between the input and\nlabel. Prior approaches that achieve high worst-group accuracy, like group\ndistributionally robust optimization (group DRO) require expensive group\nannotations for each training point, whereas approaches that do not use such\ngroup annotations typically achieve unsatisfactory worst-group accuracy. In\nthis paper, we propose a simple two-stage approach, JTT, that first trains a\nstandard ERM model for several epochs, and then trains a second model that\nupweights the training examples that the first model misclassified.\nIntuitively, this upweights examples from groups on which standard ERM models\nperform poorly, leading to improved worst-group performance. Averaged over four\nimage classification and natural language processing tasks with spurious\ncorrelations, JTT closes 75% of the gap in worst-group accuracy between\nstandard ERM and group DRO, while only requiring group annotations on a small\nvalidation set in order to tune hyperparameters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:52:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Haghgoo", "Behzad", ""], ["Chen", "Annie S.", ""], ["Raghunathan", "Aditi", ""], ["Koh", "Pang Wei", ""], ["Sagawa", "Shiori", ""], ["Liang", "Percy", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.09088", "submitter": "Dylan Ashley", "authors": "Miroslav \\v{S}trupl, Francesco Faccio, Dylan R. Ashley, Rupesh Kumar\n  Srivastava, J\\\"urgen Schmidhuber", "title": "Reward-Weighted Regression Converges to a Global Optimum", "comments": "10 pages in main text + 2 pages of references + 4 pages of\n  appendices, 2 figures in main text; source code available at\n  https://github.com/dylanashley/reward-weighted-regression", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reward-Weighted Regression (RWR) belongs to a family of widely known\niterative Reinforcement Learning algorithms based on the\nExpectation-Maximization framework. In this family, learning at each iteration\nconsists of sampling a batch of trajectories using the current policy and\nfitting a new policy to maximize a return-weighted log-likelihood of actions.\nAlthough RWR is known to yield monotonic improvement of the policy under\ncertain circumstances, whether and under which conditions RWR converges to the\noptimal policy have remained open questions. In this paper, we provide for the\nfirst time a proof that RWR converges to a global optimum when no function\napproximation is used.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:01:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["\u0160trupl", "Miroslav", ""], ["Faccio", "Francesco", ""], ["Ashley", "Dylan R.", ""], ["Srivastava", "Rupesh Kumar", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2107.09091", "submitter": "Soumyabrata Pal", "authors": "Arya Mazumdar, Soumyabrata Pal", "title": "Support Recovery in Universal One-bit Compressed Sensing", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DM cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-bit compressed sensing (1bCS) is an extreme-quantized signal acquisition\nmethod that has been widely studied in the past decade. In 1bCS, linear samples\nof a high dimensional signal are quantized to only one bit per sample (sign of\nthe measurement). Assuming the original signal vector to be sparse, existing\nresults either aim to find the support of the vector, or approximate the signal\nwithin an $\\epsilon$-ball. The focus of this paper is support recovery, which\noften also computationally facilitates approximate signal recovery. A universal\nmeasurement matrix for 1bCS refers to one set of measurements that work for all\nsparse signals. With universality, it is known that $\\tilde{\\Theta}(k^2)$ 1bCS\nmeasurements are necessary and sufficient for support recovery (where $k$\ndenotes the sparsity). In this work, we show that it is possible to universally\nrecover the support with a small number of false positives with\n$\\tilde{O}(k^{3/2})$ measurements. If the dynamic range of the signal vector is\nknown, then with a different technique, this result can be improved to only\n$\\tilde{O}(k)$ measurements. Further results on support recovery are also\nprovided.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:10:51 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Mazumdar", "Arya", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "2107.09133", "submitter": "Daniel Kunin", "authors": "Daniel Kunin, Javier Sagastuy-Brena, Lauren Gillespie, Eshed Margalit,\n  Hidenori Tanaka, Surya Ganguli, Daniel L. K. Yamins", "title": "Rethinking the limiting dynamics of SGD: modified loss, phase space\n  oscillations, and anomalous diffusion", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the limiting dynamics of deep neural networks trained\nwith stochastic gradient descent (SGD). We find empirically that long after\nperformance has converged, networks continue to move through parameter space by\na process of anomalous diffusion in which distance travelled grows as a power\nlaw in the number of gradient updates with a nontrivial exponent. We reveal an\nintricate interaction between the hyperparameters of optimization, the\nstructure in the gradient noise, and the Hessian matrix at the end of training\nthat explains this anomalous diffusion. To build this understanding, we first\nderive a continuous-time model for SGD with finite learning rates and batch\nsizes as an underdamped Langevin equation. We study this equation in the\nsetting of linear regression, where we can derive exact, analytic expressions\nfor the phase space dynamics of the parameters and their instantaneous\nvelocities from initialization to stationarity. Using the Fokker-Planck\nequation, we show that the key ingredient driving these dynamics is not the\noriginal training loss, but rather the combination of a modified loss, which\nimplicitly regularizes the velocity, and probability currents, which cause\noscillations in phase space. We identify qualitative and quantitative\npredictions of this theory in the dynamics of a ResNet-18 model trained on\nImageNet. Through the lens of statistical physics, we uncover a mechanistic\norigin for the anomalous limiting dynamics of deep neural networks trained with\nSGD.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:18:57 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kunin", "Daniel", ""], ["Sagastuy-Brena", "Javier", ""], ["Gillespie", "Lauren", ""], ["Margalit", "Eshed", ""], ["Tanaka", "Hidenori", ""], ["Ganguli", "Surya", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "2107.09144", "submitter": "Harsha Vardhan Tetali", "authors": "Harsha Vardhan Tetali, Joel B. Harley, Benjamin D. Haeffele", "title": "Wave-Informed Matrix Factorization withGlobal Optimality Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent success of representation learning methods, which includes\ndeep learning as a special case, there has been considerable interest in\ndeveloping representation learning techniques that can incorporate known\nphysical constraints into the learned representation. As one example, in many\napplications that involve a signal propagating through physical media (e.g.,\noptics, acoustics, fluid dynamics, etc), it is known that the dynamics of the\nsignal must satisfy constraints imposed by the wave equation. Here we propose a\nmatrix factorization technique that decomposes such signals into a sum of\ncomponents, where each component is regularized to ensure that it satisfies\nwave equation constraints. Although our proposed formulation is non-convex, we\nprove that our model can be efficiently solved to global optimality in\npolynomial time. We demonstrate the benefits of our work by applications in\nstructural health monitoring, where prior work has attempted to solve this\nproblem using sparse dictionary learning approaches that do not come with any\ntheoretical guarantees regarding convergence to global optimality and employ\nheuristics to capture desired physical constraints.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:34:47 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Tetali", "Harsha Vardhan", ""], ["Harley", "Joel B.", ""], ["Haeffele", "Benjamin D.", ""]]}, {"id": "2107.09145", "submitter": "Wooseok Ha", "authors": "Wooseok Ha, Chandan Singh, Francois Lanusse, Eli Song, Song Dang,\n  Kangmin He, Srigokul Upadhyayula, Bin Yu", "title": "Adaptive wavelet distillation from neural networks through\n  interpretations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep-learning models have achieved impressive prediction performance,\nbut often sacrifice interpretability and computational efficiency.\nInterpretability is crucial in many disciplines, such as science and medicine,\nwhere models must be carefully vetted or where interpretation is the goal\nitself. Moreover, interpretable models are concise and often yield\ncomputational efficiency. Here, we propose adaptive wavelet distillation (AWD),\na method which aims to distill information from a trained neural network into a\nwavelet transform. Specifically, AWD penalizes feature attributions of a neural\nnetwork in the wavelet domain to learn an effective multi-resolution wavelet\ntransform. The resulting model is highly predictive, concise, computationally\nefficient, and has properties (such as a multi-scale structure) which make it\neasy to interpret. In close collaboration with domain experts, we showcase how\nAWD addresses challenges in two real-world settings: cosmological parameter\ninference and molecular-partner prediction. In both cases, AWD yields a\nscientifically interpretable and concise model which gives predictive\nperformance better than state-of-the-art neural networks. Moreover, AWD\nidentifies predictive features that are scientifically meaningful in the\ncontext of respective domains. All code and models are released in a\nfull-fledged package available on Github\n(https://github.com/Yu-Group/adaptive-wavelets).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:40:35 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ha", "Wooseok", ""], ["Singh", "Chandan", ""], ["Lanusse", "Francois", ""], ["Song", "Eli", ""], ["Dang", "Song", ""], ["He", "Kangmin", ""], ["Upadhyayula", "Srigokul", ""], ["Yu", "Bin", ""]]}, {"id": "2107.09150", "submitter": "Abhishek Kaul", "authors": "Abhishek Kaul and George Michailidis", "title": "Inference for Change Points in High Dimensional Mean Shift Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider the problem of constructing confidence intervals for the\nlocations of change points in a high-dimensional mean shift model. To that end,\nwe develop a locally refitted least squares estimator and obtain component-wise\nand simultaneous rates of estimation of the underlying change points. The\nsimultaneous rate is the sharpest available in the literature by at least a\nfactor of $\\log p,$ while the component-wise one is optimal. These results\nenable existence of limiting distributions. Component-wise distributions are\ncharacterized under both vanishing and non-vanishing jump size regimes, while\njoint distributions for any finite subset of change point estimates are\ncharacterized under the latter regime, which also yields asymptotic\nindependence of these estimates. The combined results are used to construct\nasymptotically valid component-wise and simultaneous confidence intervals for\nthe change point parameters. The results are established under a high\ndimensional scaling, allowing for diminishing jump sizes, in the presence of\ndiverging number of change points and under subexponential errors. They are\nillustrated on synthetic data and on sensor measurements from smartphones for\nactivity recognition.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:56:15 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kaul", "Abhishek", ""], ["Michailidis", "George", ""]]}, {"id": "2107.09158", "submitter": "Brenden Petersen", "authors": "Mikel Landajuela Larma, Brenden K. Petersen, Soo K. Kim, Claudio P.\n  Santiago, Ruben Glatt, T. Nathan Mundhenk, Jacob F. Pettit, Daniel M. Faissol", "title": "Improving exploration in policy gradient search: Application to symbolic\n  optimization", "comments": "Published in 1st Mathematical Reasoning in General Artificial\n  Intelligence Workshop, ICLR 2021", "journal-ref": "1st Mathematical Reasoning in General Artificial Intelligence\n  Workshop, ICLR 2021", "doi": null, "report-no": "LLNL-CONF-820015", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning strategies designed to automate mathematical tasks\nleverage neural networks to search large combinatorial spaces of mathematical\nsymbols. In contrast to traditional evolutionary approaches, using a neural\nnetwork at the core of the search allows learning higher-level symbolic\npatterns, providing an informed direction to guide the search. When no labeled\ndata is available, such networks can still be trained using reinforcement\nlearning. However, we demonstrate that this approach can suffer from an early\ncommitment phenomenon and from initialization bias, both of which limit\nexploration. We present two exploration methods to tackle these issues,\nbuilding upon ideas of entropy regularization and distribution initialization.\nWe show that these techniques can improve the performance, increase sample\nefficiency, and lower the complexity of solutions for the task of symbolic\nregression.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 21:11:07 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Larma", "Mikel Landajuela", ""], ["Petersen", "Brenden K.", ""], ["Kim", "Soo K.", ""], ["Santiago", "Claudio P.", ""], ["Glatt", "Ruben", ""], ["Mundhenk", "T. Nathan", ""], ["Pettit", "Jacob F.", ""], ["Faissol", "Daniel M.", ""]]}, {"id": "2107.09194", "submitter": "William Stephenson", "authors": "William T. Stephenson and Zachary Frangella and Madeleine Udell and\n  Tamara Broderick", "title": "Can we globally optimize cross-validation loss? Quasiconvexity in ridge\n  regression", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models like LASSO and ridge regression are extensively used in practice due\nto their interpretability, ease of use, and strong theoretical guarantees.\nCross-validation (CV) is widely used for hyperparameter tuning in these models,\nbut do practical optimization methods minimize the true out-of-sample loss? A\nrecent line of research promises to show that the optimum of the CV loss\nmatches the optimum of the out-of-sample loss (possibly after simple\ncorrections). It remains to show how tractable it is to minimize the CV loss.\nIn the present paper, we show that, in the case of ridge regression, the CV\nloss may fail to be quasiconvex and thus may have multiple local optima. We can\nguarantee that the CV loss is quasiconvex in at least one case: when the\nspectrum of the covariate matrix is nearly flat and the noise in the observed\nresponses is not too high. More generally, we show that quasiconvexity status\nis independent of many properties of the observed data (response norm,\ncovariate-matrix right singular vectors and singular-value scaling) and has a\ncomplex dependence on the few that remain. We empirically confirm our theory\nusing simulated experiments.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 23:22:24 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Stephenson", "William T.", ""], ["Frangella", "Zachary", ""], ["Udell", "Madeleine", ""], ["Broderick", "Tamara", ""]]}, {"id": "2107.09207", "submitter": "Ziyun Zhang", "authors": "Thomas Y. Hou, Zhenzhen Li, and Ziyun Zhang", "title": "Asymptotic Escape of Spurious Critical Points on the Low-rank Matrix\n  Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Riemannian gradient descent algorithm on the low-rank matrix\nmanifold almost surely escapes some spurious critical points on the boundary of\nthe manifold. Given that the low-rank matrix manifold is an incomplete set,\nthis result is the first to overcome this difficulty and partially justify the\nglobal use of the Riemannian gradient descent on the manifold. The spurious\ncritical points are some rank-deficient matrices that capture only part of the\nSVD components of the ground truth. They exhibit very singular behavior and\nevade the classical analysis of strict saddle points. We show that using the\ndynamical low-rank approximation and a rescaled gradient flow, some of the\nspurious critical points can be converted to classical strict saddle points,\nwhich leads to the desired result. Numerical experiments are provided to\nsupport our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 00:25:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hou", "Thomas Y.", ""], ["Li", "Zhenzhen", ""], ["Zhang", "Ziyun", ""]]}, {"id": "2107.09224", "submitter": "Zheng Wen", "authors": "Xiuyuan Lu, Ian Osband, Benjamin Van Roy, Zheng Wen", "title": "Evaluating Probabilistic Inference in Deep Learning: Beyond Marginal\n  Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge for any intelligent system is prediction: given some\ninputs $X_1,..,X_\\tau$ can you predict outcomes $Y_1,.., Y_\\tau$. The KL\ndivergence $\\mathbf{d}_{\\mathrm{KL}}$ provides a natural measure of prediction\nquality, but the majority of deep learning research looks only at the marginal\npredictions per input $X_t$. In this technical report we propose a scoring rule\n$\\mathbf{d}_{\\mathrm{KL}}^\\tau$, parameterized by $\\tau \\in \\mathcal{N}$ that\nevaluates the joint predictions at $\\tau$ inputs simultaneously. We show that\nthe commonly-used $\\tau=1$ can be insufficient to drive good decisions in many\nsettings of interest. We also show that, as $\\tau$ grows, performing well\naccording to $\\mathbf{d}_{\\mathrm{KL}}^\\tau$ recovers universal guarantees for\nany possible decision. Finally, we provide problem-dependent guidance on the\nscale of $\\tau$ for which our score provides sufficient guarantees for good\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 01:55:01 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Lu", "Xiuyuan", ""], ["Osband", "Ian", ""], ["Van Roy", "Benjamin", ""], ["Wen", "Zheng", ""]]}, {"id": "2107.09301", "submitter": "Nikolaos Mourdoukoutas", "authors": "Nikolaos Mourdoukoutas, Marco Federici, Georges Pantalos, Mark van der\n  Wilk and Vincent Fortuin", "title": "A Bayesian Approach to Invariant Deep Neural Networks", "comments": "8 pages, 3 figures, To be published in ICML UDL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian neural network architecture that can learn\ninvariances from data alone by inferring a posterior distribution over\ndifferent weight-sharing schemes. We show that our model outperforms other\nnon-invariant architectures, when trained on datasets that contain specific\ninvariances. The same holds true when no data augmentation is performed.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 07:33:58 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Mourdoukoutas", "Nikolaos", ""], ["Federici", "Marco", ""], ["Pantalos", "Georges", ""], ["van der Wilk", "Mark", ""], ["Fortuin", "Vincent", ""]]}, {"id": "2107.09338", "submitter": "Qingzhong Ai", "authors": "Qingzhong Ai, Shiyu Liu, Zenglin Xu", "title": "Kernel Selection for Stein Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein variational gradient descent (SVGD) and its variants have shown\npromising successes in approximate inference for complex distributions.\nHowever, their empirical performance depends crucially on the choice of optimal\nkernel. Unfortunately, RBF kernel with median heuristics is a common choice in\nprevious approaches which has been proved sub-optimal. Inspired by the paradigm\nof multiple kernel learning, our solution to this issue is using a combination\nof multiple kernels to approximate the optimal kernel instead of a single one\nwhich may limit the performance and flexibility. To do so, we extend Kernelized\nStein Discrepancy (KSD) to its multiple kernel view called Multiple Kernelized\nStein Discrepancy (MKSD). Further, we leverage MKSD to construct a general\nalgorithm based on SVGD, which be called Multiple Kernel SVGD (MK-SVGD).\nBesides, we automatically assign a weight to each kernel without any other\nparameters. The proposed method not only gets rid of optimal kernel dependence\nbut also maintains computational effectiveness. Experiments on various tasks\nand models show the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 08:48:42 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ai", "Qingzhong", ""], ["Liu", "Shiyu", ""], ["Xu", "Zenglin", ""]]}, {"id": "2107.09355", "submitter": "Haotian Jiang", "authors": "Haotian Jiang, Zhong Li, Qianxiao Li", "title": "Approximation Theory of Convolutional Architectures for Time Series\n  Modelling", "comments": "Published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation properties of convolutional architectures applied\nto time series modelling, which can be formulated mathematically as a\nfunctional approximation problem. In the recurrent setting, recent results\nreveal an intricate connection between approximation efficiency and memory\nstructures in the data generation process. In this paper, we derive parallel\nresults for convolutional architectures, with WaveNet being a prime example.\nOur results reveal that in this new setting, approximation efficiency is not\nonly characterised by memory, but also additional fine structures in the target\nrelationship. This leads to a novel definition of spectrum-based regularity\nthat measures the complexity of temporal relationships under the convolutional\napproximation scheme. These analyses provide a foundation to understand the\ndifferences between architectural choices for time series modelling and can\ngive theoretically grounded guidance for practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:19:26 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jiang", "Haotian", ""], ["Li", "Zhong", ""], ["Li", "Qianxiao", ""]]}, {"id": "2107.09384", "submitter": "Dirk Ostwald", "authors": "Dirk Ostwald and Franziska Us\\'ee", "title": "An induction proof of the backpropagation algorithm in matrix notation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST q-bio.NC stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Backpropagation (BP) is a core component of the contemporary deep learning\nincarnation of neural networks. Briefly, BP is an algorithm that exploits the\ncomputational architecture of neural networks to efficiently evaluate the\ngradient of a cost function during neural network parameter optimization. The\nvalidity of BP rests on the application of a multivariate chain rule to the\ncomputational architecture of neural networks and their associated objective\nfunctions. Introductions to deep learning theory commonly present the\ncomputational architecture of neural networks in matrix form, but eschew a\nparallel formulation and justification of BP in the framework of matrix\ndifferential calculus. This entails several drawbacks for the theory and\ndidactics of deep learning. In this work, we overcome these limitations by\nproviding a full induction proof of the BP algorithm in matrix notation.\nSpecifically, we situate the BP algorithm in the framework of matrix\ndifferential calculus, encompass affine-linear potential functions, prove the\nvalidity of the BP algorithm in inductive form, and exemplify the\nimplementation of the matrix form BP algorithm in computer code.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 10:02:17 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ostwald", "Dirk", ""], ["Us\u00e9e", "Franziska", ""]]}, {"id": "2107.09422", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Ravichandra Addanki, Peter W. Battaglia, David Budden, Andreea Deac,\n  Jonathan Godwin, Thomas Keck, Wai Lok Sibon Li, Alvaro Sanchez-Gonzalez,\n  Jacklynn Stott, Shantanu Thakoor, Petar Veli\\v{c}kovi\\'c", "title": "Large-scale graph representation learning with very deep GNNs and\n  self-supervision", "comments": "To appear at KDD Cup 2021. 13 pages, 3 figures. All authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively and efficiently deploying graph neural networks (GNNs) at scale\nremains one of the most challenging aspects of graph representation learning.\nMany powerful solutions have only ever been validated on comparatively small\ndatasets, often with counter-intuitive outcomes -- a barrier which has been\nbroken by the Open Graph Benchmark Large-Scale Challenge (OGB-LSC). We entered\nthe OGB-LSC with two large-scale GNNs: a deep transductive node classifier\npowered by bootstrapping, and a very deep (up to 50-layer) inductive graph\nregressor regularised by denoising objectives. Our models achieved an\naward-level (top-3) performance on both the MAG240M and PCQM4M benchmarks. In\ndoing so, we demonstrate evidence of scalable self-supervised graph\nrepresentation learning, and utility of very deep GNNs -- both very important\nopen issues. Our code is publicly available at:\nhttps://github.com/deepmind/deepmind-research/tree/master/ogb_lsc.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:35:25 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Addanki", "Ravichandra", ""], ["Battaglia", "Peter W.", ""], ["Budden", "David", ""], ["Deac", "Andreea", ""], ["Godwin", "Jonathan", ""], ["Keck", "Thomas", ""], ["Li", "Wai Lok Sibon", ""], ["Sanchez-Gonzalez", "Alvaro", ""], ["Stott", "Jacklynn", ""], ["Thakoor", "Shantanu", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "2107.09519", "submitter": "Gaetan Frusque Dr.", "authors": "Frusque Gaetan, Michau Gabriel and Fink Olga", "title": "Canonical Polyadic Decomposition and Deep Learning for Machine Fault\n  Detection", "comments": "9 pages, 5 figures, conference paper from PHM Society European\n  Conference 2021 (Vol. 6, No. 1)", "journal-ref": "In PHM Society European Conference (Vol. 6, No. 1, pp. 9-9) 2021,\n  June", "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic monitoring for machine fault detection is a recent and expanding\nresearch path that has already provided promising results for industries.\nHowever, it is impossible to collect enough data to learn all types of faults\nfrom a machine. Thus, new algorithms, trained using data from healthy\nconditions only, were developed to perform unsupervised anomaly detection. A\nkey issue in the development of these algorithms is the noise in the signals,\nas it impacts the anomaly detection performance. In this work, we propose a\npowerful data-driven and quasi non-parametric denoising strategy for spectral\ndata based on a tensor decomposition: the Non-negative Canonical Polyadic (CP)\ndecomposition. This method is particularly adapted for machine emitting\nstationary sound. We demonstrate in a case study, the Malfunctioning Industrial\nMachine Investigation and Inspection (MIMII) baseline, how the use of our\ndenoising strategy leads to a sensible improvement of the unsupervised anomaly\ndetection. Such approaches are capable to make sound-based monitoring of\nindustrial processes more reliable.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:06:50 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Gaetan", "Frusque", ""], ["Gabriel", "Michau", ""], ["Olga", "Fink", ""]]}, {"id": "2107.09532", "submitter": "Sophie Langer Dr.", "authors": "Michael Kohler, Sophie Langer and Ulrich Reif", "title": "Estimation of a regression function on a manifold by fully connected\n  deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of a regression function from independent and identically\ndistributed data is considered. The $L_2$ error with integration with respect\nto the distribution of the predictor variable is used as the error criterion.\nThe rate of convergence of least squares estimates based on fully connected\nspaces of deep neural networks with ReLU activation function is analyzed for\nsmooth regression functions. It is shown that in case that the distribution of\nthe predictor variable is concentrated on a manifold, these estimates achieve a\nrate of convergence which depends on the dimension of the manifold and not on\nthe number of components of the predictor variable.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:43:59 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kohler", "Michael", ""], ["Langer", "Sophie", ""], ["Reif", "Ulrich", ""]]}, {"id": "2107.09542", "submitter": "Steve Hanneke", "authors": "Steve Hanneke", "title": "Open Problem: Is There an Online Learning Algorithm That Learns Whenever\n  Online Learning Is Possible?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This open problem asks whether there exists an online learning algorithm for\nbinary classification that guarantees, for all target concepts, to make a\nsublinear number of mistakes, under only the assumption that the (possibly\nrandom) sequence of points X allows that such a learning algorithm can exist\nfor that sequence. As a secondary problem, it also asks whether a specific\nconcise condition completely determines whether a given (possibly random)\nsequence of points X admits the existence of online learning algorithms\nguaranteeing a sublinear number of mistakes for all target concepts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:57:37 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hanneke", "Steve", ""]]}, {"id": "2107.09597", "submitter": "Satoshi Hayakawa", "authors": "Satoshi Hayakawa, Harald Oberhauser, Terry Lyons", "title": "Positively Weighted Kernel Quadrature via Subsampling", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study kernel quadrature rules with positive weights for probability\nmeasures on general domains. Our theoretical analysis combines the spectral\nproperties of the kernel with random sampling of points. This results in\neffective algorithms to construct kernel quadrature rules with positive weights\nand small worst-case error. Besides additional robustness, our numerical\nexperiments indicate that this can achieve fast convergence rates that compete\nwith the optimal bounds in well-known examples.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 16:18:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hayakawa", "Satoshi", ""], ["Oberhauser", "Harald", ""], ["Lyons", "Terry", ""]]}, {"id": "2107.09660", "submitter": "Arnab Auddy", "authors": "Arnab Auddy and Ming Yuan", "title": "On Estimating Rank-One Spiked Tensors in the Presence of Heavy Tailed\n  Errors", "comments": "46 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.NA math.IT math.NA stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the estimation of a rank-one spiked tensor in the\npresence of heavy tailed noise. Our results highlight some of the fundamental\nsimilarities and differences in the tradeoff between statistical and\ncomputational efficiencies under heavy tailed and Gaussian noise. In\nparticular, we show that, for $p$ th order tensors, the tradeoff manifests in\nan identical fashion as the Gaussian case when the noise has finite $4(p-1)$ th\nmoment. The difference in signal strength requirements, with or without\ncomputational constraints, for us to estimate the singular vectors at the\noptimal rate, interestingly, narrows for noise with heavier tails and vanishes\nwhen the noise only has finite fourth moment. Moreover, if the noise has less\nthan fourth moment, tensor SVD, perhaps the most natural approach, is\nsuboptimal even though it is computationally intractable. Our analysis exploits\na close connection between estimating the rank-one spikes and the spectral norm\nof a random tensor with iid entries. In particular, we show that the order of\nthe spectral norm of a random tensor can be precisely characterized by the\nmoment of its entries, generalizing classical results for random matrices. In\naddition to the theoretical guarantees, we propose estimation procedures for\nthe heavy tailed regime, which are easy to implement and efficient to run.\nNumerical experiments are presented to demonstrate their practical merits.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:45:55 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Auddy", "Arnab", ""], ["Yuan", "Ming", ""]]}, {"id": "2107.09773", "submitter": "Vardis Kandiros", "authors": "Yuval Dagan, Constantinos Daskalakis, Nishanth Dikkala, Surbhi Goel,\n  Anthimos Vardis Kandiros", "title": "Statistical Estimation from Dependent Data", "comments": "41 pages, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a general statistical estimation problem wherein binary labels\nacross different observations are not independent conditioned on their feature\nvectors, but dependent, capturing settings where e.g. these observations are\ncollected on a spatial domain, a temporal domain, or a social network, which\ninduce dependencies. We model these dependencies in the language of Markov\nRandom Fields and, importantly, allow these dependencies to be substantial, i.e\ndo not assume that the Markov Random Field capturing these dependencies is in\nhigh temperature. As our main contribution we provide algorithms and\nstatistically efficient estimation rates for this model, giving several\ninstantiations of our bounds in logistic regression, sparse logistic\nregression, and neural network settings with dependent data. Our estimation\nguarantees follow from novel results for estimating the parameters (i.e.\nexternal fields and interaction strengths) of Ising models from a {\\em single}\nsample. {We evaluate our estimation approach on real networked data, showing\nthat it outperforms standard regression approaches that ignore dependencies,\nacross three text classification datasets: Cora, Citeseer and Pubmed.}\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 21:18:06 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dagan", "Yuval", ""], ["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Goel", "Surbhi", ""], ["Kandiros", "Anthimos Vardis", ""]]}, {"id": "2107.09802", "submitter": "Walid Krichene", "authors": "Steve Chien, Prateek Jain, Walid Krichene, Steffen Rendle, Shuang\n  Song, Abhradeep Thakurta, Li Zhang", "title": "Private Alternating Least Squares: Practical Private Matrix Completion\n  with Tighter Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of differentially private (DP) matrix completion under\nuser-level privacy. We design a joint differentially private variant of the\npopular Alternating-Least-Squares (ALS) method that achieves: i) (nearly)\noptimal sample complexity for matrix completion (in terms of number of items,\nusers), and ii) the best known privacy/utility trade-off both theoretically, as\nwell as on benchmark data sets. In particular, we provide the first global\nconvergence analysis of ALS with noise introduced to ensure DP, and show that,\nin comparison to the best known alternative (the Private Frank-Wolfe algorithm\nby Jain et al. (2018)), our error bounds scale significantly better with\nrespect to the number of items and users, which is critical in practical\nproblems. Extensive validation on standard benchmarks demonstrate that the\nalgorithm, in combination with carefully designed sampling procedures, is\nsignificantly more accurate than existing techniques, thus promising to be the\nfirst practical DP embedding model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:19:11 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chien", "Steve", ""], ["Jain", "Prateek", ""], ["Krichene", "Walid", ""], ["Rendle", "Steffen", ""], ["Song", "Shuang", ""], ["Thakurta", "Abhradeep", ""], ["Zhang", "Li", ""]]}, {"id": "2107.09853", "submitter": "Akira Furui D.Eng.", "authors": "Akira Furui, Takuya Igaue, Toshio Tsuji", "title": "EMG Pattern Recognition via Bayesian Inference with Scale Mixture-Based\n  Stochastic Generative Models", "comments": "This paper is accepted for publication in Expert Systems with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electromyogram (EMG) has been utilized to interface signals for prosthetic\nhands and information devices owing to its ability to reflect human motion\nintentions. Although various EMG classification methods have been introduced\ninto EMG-based control systems, they do not fully consider the stochastic\ncharacteristics of EMG signals. This paper proposes an EMG pattern\nclassification method incorporating a scale mixture-based generative model. A\nscale mixture model is a stochastic EMG model in which the EMG variance is\nconsidered as a random variable, enabling the representation of uncertainty in\nthe variance. This model is extended in this study and utilized for EMG pattern\nclassification. The proposed method is trained by variational Bayesian\nlearning, thereby allowing the automatic determination of the model complexity.\nFurthermore, to optimize the hyperparameters of the proposed method with a\npartial discriminative approach, a mutual information-based determination\nmethod is introduced. Simulation and EMG analysis experiments demonstrated the\nrelationship between the hyperparameters and classification accuracy of the\nproposed method as well as the validity of the proposed method. The comparison\nusing public EMG datasets revealed that the proposed method outperformed the\nvarious conventional classifiers. These results indicated the validity of the\nproposed method and its applicability to EMG-based control systems. In EMG\npattern recognition, a classifier based on a generative model that reflects the\nstochastic characteristics of EMG signals can outperform the conventional\ngeneral-purpose classifier.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 02:51:19 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Furui", "Akira", ""], ["Igaue", "Takuya", ""], ["Tsuji", "Toshio", ""]]}, {"id": "2107.09912", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Kefan Dong, Jonathan Lee, Emma Brunskill", "title": "Design of Experiments for Stochastic Contextual Linear Bandits", "comments": "Initial submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the stochastic linear contextual bandit setting there exist several\nminimax procedures for exploration with policies that are reactive to the data\nbeing acquired. In practice, there can be a significant engineering overhead to\ndeploy these algorithms, especially when the dataset is collected in a\ndistributed fashion or when a human in the loop is needed to implement a\ndifferent policy. Exploring with a single non-reactive policy is beneficial in\nsuch cases. Assuming some batch contexts are available, we design a single\nstochastic policy to collect a good dataset from which a near-optimal policy\ncan be extracted. We present a theoretical analysis as well as numerical\nexperiments on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 07:25:37 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 23:20:28 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Zanette", "Andrea", ""], ["Dong", "Kefan", ""], ["Lee", "Jonathan", ""], ["Brunskill", "Emma", ""]]}, {"id": "2107.09949", "submitter": "Eura Shin", "authors": "Eura Shin, Pedja Klasnja, Susan Murphy, Finale Doshi-Velez", "title": "Online structural kernel selection for mobile health", "comments": "Workshop paper in ICML IMLH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the need for efficient and personalized learning in mobile\nhealth, we investigate the problem of online kernel selection for Gaussian\nProcess regression in the multi-task setting. We propose a novel generative\nprocess on the kernel composition for this purpose. Our method demonstrates\nthat trajectories of kernel evolutions can be transferred between users to\nimprove learning and that the kernels themselves are meaningful for an mHealth\nprediction goal.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:58:53 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Shin", "Eura", ""], ["Klasnja", "Pedja", ""], ["Murphy", "Susan", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2107.09950", "submitter": "Nikolaos Dionelis", "authors": "Nikolaos Dionelis", "title": "Boundary of Distribution Support Generator (BDSG): Sample Generation on\n  the Boundary", "comments": "5 pages, 2020 IEEE International Conference on Image Processing\n  (ICIP)", "journal-ref": "2020 IEEE International Conference on Image Processing (ICIP)", "doi": null, "report-no": "2020 IEEE International Conference on Image Processing (ICIP)", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative models, such as Generative Adversarial Networks (GANs), have been\nused for unsupervised anomaly detection. While performance keeps improving,\nseveral limitations exist particularly attributed to difficulties at capturing\nmultimodal supports and to the ability to approximate the underlying\ndistribution closer to the tails, i.e. the boundary of the distribution's\nsupport. This paper proposes an approach that attempts to alleviate such\nshortcomings. We propose an invertible-residual-network-based model, the\nBoundary of Distribution Support Generator (BDSG). GANs generally do not\nguarantee the existence of a probability distribution and here, we use the\nrecently developed Invertible Residual Network (IResNet) and Residual Flow\n(ResFlow), for density estimation. These models have not yet been used for\nanomaly detection. We leverage IResNet and ResFlow for Out-of-Distribution\n(OoD) sample detection and for sample generation on the boundary using a\ncompound loss function that forces the samples to lie on the boundary. The BDSG\naddresses non-convex support, disjoint components, and multimodal\ndistributions. Results on synthetic data and data from multimodal\ndistributions, such as MNIST and CIFAR-10, demonstrate competitive performance\ncompared to methods from the literature.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 09:00:32 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dionelis", "Nikolaos", ""]]}, {"id": "2107.09957", "submitter": "Deep Patel", "authors": "Deep Patel and P.S. Sastry", "title": "Memorization in Deep Neural Networks: Does the Loss Function matter?", "comments": "Accepted at PAKDD 2021. 12 pages and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks, often owing to the overparameterization, are shown to\nbe capable of exactly memorizing even randomly labelled data. Empirical studies\nhave also shown that none of the standard regularization techniques mitigate\nsuch overfitting. We investigate whether the choice of the loss function can\naffect this memorization. We empirically show, with benchmark data sets MNIST\nand CIFAR-10, that a symmetric loss function, as opposed to either\ncross-entropy or squared error loss, results in significant improvement in the\nability of the network to resist such overfitting. We then provide a formal\ndefinition for robustness to memorization and provide a theoretical explanation\nas to why the symmetric losses provide this robustness. Our results clearly\nbring out the role loss functions alone can play in this phenomenon of\nmemorization.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 09:08:51 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 05:36:24 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Patel", "Deep", ""], ["Sastry", "P. S.", ""]]}, {"id": "2107.10013", "submitter": "Ren Hu", "authors": "Ren Hu and Qifeng Li", "title": "Optimal Operation of Power Systems with Energy Storage under\n  Uncertainty: A Scenario-based Method with Strategic Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-period dynamics of energy storage (ES), intermittent renewable\ngeneration and uncontrollable power loads, make the optimization of power\nsystem operation (PSO) challenging. A multi-period optimal PSO under\nuncertainty is formulated using the chance-constrained optimization (CCO)\nmodeling paradigm, where the constraints include the nonlinear energy storage\nand AC power flow models. Based on the emerging scenario optimization method\nwhich does not rely on pre-known probability distribution functions, this paper\ndevelops a novel solution method for this challenging CCO problem. The proposed\nmeth-od is computationally effective for mainly two reasons. First, the\noriginal AC power flow constraints are approximated by a set of\nlearning-assisted quadratic convex inequalities based on a generalized least\nabsolute shrinkage and selection operator. Second, considering the physical\npatterns of data and motived by learning-based sampling, the strategic sampling\nmethod is developed to significantly reduce the required number of scenarios\nthrough different sampling strategies. The simulation results on IEEE standard\nsystems indicate that 1) the proposed strategic sampling significantly improves\nthe computational efficiency of the scenario-based approach for solving the\nchance-constrained optimal PSO problem, 2) the data-driven convex approximation\nof power flow can be promising alternatives of nonlinear and nonconvex AC power\nflow.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:21:50 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Hu", "Ren", ""], ["Li", "Qifeng", ""]]}, {"id": "2107.10014", "submitter": "Dominik Kloepfer", "authors": "Dominik Kloepfer, Angelica I. Aviles-Rivero, Daniel Heydecker", "title": "Delving Into Deep Walkers: A Convergence Analysis of Random-Walk-Based\n  Vertex Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph vertex embeddings based on random walks have become increasingly\ninfluential in recent years, showing good performance in several tasks as they\nefficiently transform a graph into a more computationally digestible format\nwhile preserving relevant information. However, the theoretical properties of\nsuch algorithms, in particular the influence of hyperparameters and of the\ngraph structure on their convergence behaviour, have so far not been\nwell-understood. In this work, we provide a theoretical analysis for\nrandom-walks based embeddings techniques. Firstly, we prove that, under some\nweak assumptions, vertex embeddings derived from random walks do indeed\nconverge both in the single limit of the number of random walks $N \\to \\infty$\nand in the double limit of both $N$ and the length of each random walk\n$L\\to\\infty$. Secondly, we derive concentration bounds quantifying the converge\nrate of the corpora for the single and double limits. Thirdly, we use these\nresults to derive a heuristic for choosing the hyperparameters $N$ and $L$. We\nvalidate and illustrate the practical importance of our findings with a range\nof numerical and visual experiments on several graphs drawn from real-world\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:23:04 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Kloepfer", "Dominik", ""], ["Aviles-Rivero", "Angelica I.", ""], ["Heydecker", "Daniel", ""]]}, {"id": "2107.10030", "submitter": "Jeremie Dona", "authors": "J\\'er\\'emie Dona (MLIA), Patrick Gallinari (MLIA)", "title": "Differentiable Feature Selection, a Reparameterization Approach", "comments": null, "journal-ref": "European Conference (ECML-PKDD), In press", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of feature selection for reconstruction which consists\nin choosing a small subset of features from which whole data instances can be\nreconstructed. This is of particular importance in several contexts involving\nfor example costly physical measurements, sensor placement or information\ncompression. To break the intrinsic combinatorial nature of this problem, we\nformulate the task as optimizing a binary mask distribution enabling an\naccurate reconstruction. We then face two main challenges. One concerns\ndifferentiability issues due to the binary distribution. The second one\ncorresponds to the elimination of redundant information by selecting variables\nin a correlated fashion which requires modeling the covariance of the binary\ndistribution. We address both issues by introducing a relaxation of the problem\nvia a novel reparameterization of the logitNormal distribution. We demonstrate\nthat the proposed method provides an effective exploration scheme and leads to\nefficient feature selection for reconstruction through evaluation on several\nhigh dimensional image benchmarks. We show that the method leverages the\nintrinsic geometry of the data, facilitating reconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:52:34 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dona", "J\u00e9r\u00e9mie", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2107.10043", "submitter": "Nir Shlezinger", "authors": "Guy Revach, Nir Shlezinger, Xiaoyong Ni, Adria Lopez Escoriza, Ruud J.\n  G. van Sloun, and Yonina C. Eldar", "title": "KalmanNet: Neural Network Aided Kalman Filtering for Partially Known\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time state estimation of dynamical systems is a fundamental task in\nsignal processing and control. For systems that are well-represented by a fully\nknown linear Gaussian state space (SS) model, the celebrated Kalman filter (KF)\nis a low complexity optimal solution. However, both linearity of the underlying\nSS model and accurate knowledge of it are often not encountered in practice.\nHere, we present KalmanNet, a real-time state estimator that learns from data\nto carry out Kalman filtering under non-linear dynamics with partial\ninformation. By incorporating the structural SS model with a dedicated\nrecurrent neural network module in the flow of the KF, we retain data\nefficiency and interpretability of the classic algorithm while implicitly\nlearning complex dynamics from data. We numerically demonstrate that KalmanNet\novercomes nonlinearities and model mismatch, outperforming classic filtering\nmethods operating with both mismatched and accurate domain knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:26:46 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Revach", "Guy", ""], ["Shlezinger", "Nir", ""], ["Ni", "Xiaoyong", ""], ["Escoriza", "Adria Lopez", ""], ["van Sloun", "Ruud J. G.", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2107.10066", "submitter": "Th\\'eo Galy-Fajou", "authors": "Th\\'eo Galy-Fajou, Manfred Opper", "title": "Adaptive Inducing Points Selection For Gaussian Processes", "comments": "Accepted at Continual Learning Workshop - ICML 2020 :\n  https://sites.google.com/view/cl-icml/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian Processes (\\textbf{GPs}) are flexible non-parametric models with\nstrong probabilistic interpretation. While being a standard choice for\nperforming inference on time series, GPs have few techniques to work in a\nstreaming setting. \\cite{bui2017streaming} developed an efficient variational\napproach to train online GPs by using sparsity techniques: The whole set of\nobservations is approximated by a smaller set of inducing points (\\textbf{IPs})\nand moved around with new data. Both the number and the locations of the IPs\nwill affect greatly the performance of the algorithm. In addition to optimizing\ntheir locations, we propose to adaptively add new points, based on the\nproperties of the GP and the structure of the data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 13:22:46 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Galy-Fajou", "Th\u00e9o", ""], ["Opper", "Manfred", ""]]}, {"id": "2107.10072", "submitter": "Wenbo Gong", "authors": "Wenbo Gong, Yingzhen Li", "title": "Interpreting diffusion score matching using normalizing flow", "comments": "8 pages, International Conference on Machine Learning (ICML) INNF+\n  2021 Workshop Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scoring matching (SM), and its related counterpart, Stein discrepancy (SD)\nhave achieved great success in model training and evaluations. However, recent\nresearch shows their limitations when dealing with certain types of\ndistributions. One possible fix is incorporating the original score matching\n(or Stein discrepancy) with a diffusion matrix, which is called diffusion score\nmatching (DSM) (or diffusion Stein discrepancy (DSD)). However, the lack of\ninterpretation of the diffusion limits its usage within simple distributions\nand manually chosen matrix. In this work, we plan to fill this gap by\ninterpreting the diffusion matrix using normalizing flows. Specifically, we\ntheoretically prove that DSM (or DSD) is equivalent to the original score\nmatching (or Stein discrepancy) evaluated in the transformed space defined by\nthe normalizing flow, where the diffusion matrix is the inverse of the flow's\nJacobian matrix. In addition, we also build its connection to Riemannian\nmanifolds and further extend it to continuous flows, where the change of DSM is\ncharacterized by an ODE.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 13:27:32 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Gong", "Wenbo", ""], ["Li", "Yingzhen", ""]]}, {"id": "2107.10098", "submitter": "S\\'ebastien Lachapelle", "authors": "S\\'ebastien Lachapelle, Pau Rodr\\'iguez L\\'opez, R\\'emi Le Priol,\n  Alexandre Lacoste, Simon Lacoste-Julien", "title": "Discovering Latent Causal Variables via Mechanism Sparsity: A New\n  Principle for Nonlinear ICA", "comments": "Appears in: Workshop on the Neglected Assumptions in Causal Inference\n  (NACI) at the 38 th International Conference on Machine Learning, 2021. 19\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It can be argued that finding an interpretable low-dimensional representation\nof a potentially high-dimensional phenomenon is central to the scientific\nenterprise. Independent component analysis (ICA) refers to an ensemble of\nmethods which formalize this goal and provide estimation procedure for\npractical application. This work proposes mechanism sparsity regularization as\na new principle to achieve nonlinear ICA when latent factors depend sparsely on\nobserved auxiliary variables and/or past latent factors. We show that the\nlatent variables can be recovered up to a permutation if one regularizes the\nlatent mechanisms to be sparse and if some graphical criterion is satisfied by\nthe data generating process. As a special case, our framework shows how one can\nleverage unknown-target interventions on the latent factors to disentangle\nthem, thus drawing further connections between ICA and causality. We validate\nour theoretical results with toy experiments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:22:14 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Lachapelle", "S\u00e9bastien", ""], ["L\u00f3pez", "Pau Rodr\u00edguez", ""], ["Priol", "R\u00e9mi Le", ""], ["Lacoste", "Alexandre", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2107.10110", "submitter": "Shuyu Cheng", "authors": "Shuyu Cheng, Guoqiang Wu, Jun Zhu", "title": "On the Convergence of Prior-Guided Zeroth-Order Optimization Algorithms", "comments": "Code available at https://github.com/csy530216/pg-zoo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zeroth-order (ZO) optimization is widely used to handle challenging tasks,\nsuch as query-based black-box adversarial attacks and reinforcement learning.\nVarious attempts have been made to integrate prior information into the\ngradient estimation procedure based on finite differences, with promising\nempirical results. However, their convergence properties are not well\nunderstood. This paper makes an attempt to fill this gap by analyzing the\nconvergence of prior-guided ZO algorithms under a greedy descent framework with\nvarious gradient estimators. We provide a convergence guarantee for the\nprior-guided random gradient-free (PRGF) algorithms. Moreover, to further\naccelerate over greedy descent methods, we present a new accelerated random\nsearch (ARS) algorithm that incorporates prior information, together with a\nconvergence analysis. Finally, our theoretical results are confirmed by\nexperiments on several numerical benchmarks as well as adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:39:40 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Cheng", "Shuyu", ""], ["Wu", "Guoqiang", ""], ["Zhu", "Jun", ""]]}, {"id": "2107.10125", "submitter": "Sebastian Ober", "authors": "Sebastian W. Ober, Laurence Aitchison", "title": "A variational approximate posterior for the deep Wishart process", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work introduced deep kernel processes as an entirely kernel-based\nalternative to NNs (Aitchison et al. 2020). Deep kernel processes flexibly\nlearn good top-layer representations by alternately sampling the kernel from a\ndistribution over positive semi-definite matrices and performing nonlinear\ntransformations. A particular deep kernel process, the deep Wishart process\n(DWP), is of particular interest because its prior is equivalent to deep\nGaussian process (DGP) priors. However, inference in DWPs has not yet been\npossible due to the lack of sufficiently flexible distributions over positive\nsemi-definite matrices. Here, we give a novel approach to obtaining flexible\ndistributions over positive semi-definite matrices by generalising the Bartlett\ndecomposition of the Wishart probability density. We use this new distribution\nto develop an approximate posterior for the DWP that includes dependency across\nlayers. We develop a doubly-stochastic inducing-point inference scheme for the\nDWP and show experimentally that inference in the DWP gives improved\nperformance over doing inference in a DGP with the equivalent prior.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:48:27 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ober", "Sebastian W.", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2107.10127", "submitter": "Yang Li", "authors": "Yang Li and Jinqiao Duan", "title": "Extracting Governing Laws from Sample Path Data of Non-Gaussian\n  Stochastic Dynamical Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.03769", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in data science are leading to new progresses in the analysis and\nunderstanding of complex dynamics for systems with experimental and\nobservational data. With numerous physical phenomena exhibiting bursting,\nflights, hopping, and intermittent features, stochastic differential equations\nwith non-Gaussian L\\'evy noise are suitable to model these systems. Thus it is\ndesirable and essential to infer such equations from available data to\nreasonably predict dynamical behaviors. In this work, we consider a data-driven\nmethod to extract stochastic dynamical systems with non-Gaussian asymmetric\n(rather than the symmetric) L\\'evy process, as well as Gaussian Brownian\nmotion. We establish a theoretical framework and design a numerical algorithm\nto compute the asymmetric L\\'evy jump measure, drift and diffusion (i.e.,\nnonlocal Kramers-Moyal formulas), hence obtaining the stochastic governing law,\nfrom noisy data. Numerical experiments on several prototypical examples confirm\nthe efficacy and accuracy of this method. This method will become an effective\ntool in discovering the governing laws from available data sets and in\nunderstanding the mechanisms underlying complex random phenomena.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:50:36 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Li", "Yang", ""], ["Duan", "Jinqiao", ""]]}, {"id": "2107.10143", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ildus Sadrtdinov, Nadezhda Chirkova, Ekaterina Lobacheva", "title": "On the Memorization Properties of Contrastive Learning", "comments": "Published in Workshop on Overparameterization: Pitfalls &\n  Opportunities at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memorization studies of deep neural networks (DNNs) help to understand what\npatterns and how do DNNs learn, and motivate improvements to DNN training\napproaches. In this work, we investigate the memorization properties of SimCLR,\na widely used contrastive self-supervised learning approach, and compare them\nto the memorization of supervised learning and random labels training. We find\nthat both training objects and augmentations may have different complexity in\nthe sense of how SimCLR learns them. Moreover, we show that SimCLR is similar\nto random labels training in terms of the distribution of training objects\ncomplexity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:21:58 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Sadrtdinov", "Ildus", ""], ["Chirkova", "Nadezhda", ""], ["Lobacheva", "Ekaterina", ""]]}, {"id": "2107.10199", "submitter": "Andrzej Banburski", "authors": "Andrzej Banburski, Fernanda De La Torre, Nishka Pant, Ishana Shastri,\n  Tomaso Poggio", "title": "Distribution of Classification Margins: Are All Data Equal?", "comments": "Previously online as CBMM Memo 115 on the CBMM MIT site", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent theoretical results show that gradient descent on deep neural networks\nunder exponential loss functions locally maximizes classification margin, which\nis equivalent to minimizing the norm of the weight matrices under margin\nconstraints. This property of the solution however does not fully characterize\nthe generalization performance. We motivate theoretically and show empirically\nthat the area under the curve of the margin distribution on the training set is\nin fact a good measure of generalization. We then show that, after data\nseparation is achieved, it is possible to dynamically reduce the training set\nby more than 99% without significant loss of performance. Interestingly, the\nresulting subset of \"high capacity\" features is not consistent across different\ntraining runs, which is consistent with the theoretical claim that all training\npoints should converge to the same asymptotic margin under SGD and in the\npresence of both batch normalization and weight decay.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:41:57 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Banburski", "Andrzej", ""], ["De La Torre", "Fernanda", ""], ["Pant", "Nishka", ""], ["Shastri", "Ishana", ""], ["Poggio", "Tomaso", ""]]}, {"id": "2107.10209", "submitter": "Alex Tang", "authors": "Pranjal Awasthi, Alex Tang, Aravindan Vijayaraghavan", "title": "Efficient Algorithms for Learning Depth-2 Neural Networks with General\n  ReLU Activations", "comments": "36 pages (including appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present polynomial time and sample efficient algorithms for learning an\nunknown depth-2 feedforward neural network with general ReLU activations, under\nmild non-degeneracy assumptions. In particular, we consider learning an unknown\nnetwork of the form $f(x) = {a}^{\\mathsf{T}}\\sigma({W}^\\mathsf{T}x+b)$, where\n$x$ is drawn from the Gaussian distribution, and $\\sigma(t) := \\max(t,0)$ is\nthe ReLU activation. Prior works for learning networks with ReLU activations\nassume that the bias $b$ is zero. In order to deal with the presence of the\nbias terms, our proposed algorithm consists of robustly decomposing multiple\nhigher order tensors arising from the Hermite expansion of the function $f(x)$.\nUsing these ideas we also establish identifiability of the network parameters\nunder minimal assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:06:03 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Tang", "Alex", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "2107.10211", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Kyle Hsu, Jianing Li, Chelsea Finn, Roger Grosse", "title": "Differentiable Annealed Importance Sampling and the Perils of Gradient\n  Noise", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annealed importance sampling (AIS) and related algorithms are highly\neffective tools for marginal likelihood estimation, but are not fully\ndifferentiable due to the use of Metropolis-Hastings (MH) correction steps.\nDifferentiability is a desirable property as it would admit the possibility of\noptimizing marginal likelihood as an objective using gradient-based methods. To\nthis end, we propose a differentiable AIS algorithm by abandoning MH steps,\nwhich further unlocks mini-batch computation. We provide a detailed convergence\nanalysis for Bayesian linear regression which goes beyond previous analyses by\nexplicitly accounting for non-perfect transitions. Using this analysis, we\nprove that our algorithm is consistent in the full-batch setting and provide a\nsublinear convergence rate. However, we show that the algorithm is inconsistent\nwhen mini-batch gradients are used due to a fundamental incompatibility between\nthe goals of last-iterate convergence to the posterior and elimination of the\npathwise stochastic error. This result is in stark contrast to our experience\nwith stochastic optimization and stochastic gradient Langevin dynamics, where\nthe effects of gradient noise can be washed out by taking more steps of a\nsmaller size. Our negative result relies crucially on our explicit\nconsideration of convergence to the stationary distribution, and it helps\nexplain the difficulty of developing practically effective AIS-like algorithms\nthat exploit mini-batch gradients.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:10:14 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Zhang", "Guodong", ""], ["Hsu", "Kyle", ""], ["Li", "Jianing", ""], ["Finn", "Chelsea", ""], ["Grosse", "Roger", ""]]}, {"id": "2107.10450", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Davin Choo, Rishikesh Gajjala, Sutanu Gayen,\n  Yuhao Wang", "title": "Learning Sparse Fixed-Structure Gaussian Bayesian Networks", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian Bayesian networks (a.k.a. linear Gaussian structural equation\nmodels) are widely used to model causal interactions among continuous\nvariables. In this work, we study the problem of learning a fixed-structure\nGaussian Bayesian network up to a bounded error in total variation distance. We\nanalyze the commonly used node-wise least squares regression (LeastSquares) and\nprove that it has a near-optimal sample complexity. We also study a couple of\nnew algorithms for the problem:\n  - BatchAvgLeastSquares takes the average of several batches of least squares\nsolutions at each node, so that one can interpolate between the batch size and\nthe number of batches. We show that BatchAvgLeastSquares also has near-optimal\nsample complexity.\n  - CauchyEst takes the median of solutions to several batches of linear\nsystems at each node. We show that the algorithm specialized to polytrees,\nCauchyEstTree, has near-optimal sample complexity.\n  Experimentally, we show that for uncontaminated, realizable data, the\nLeastSquares algorithm performs best, but in the presence of contamination or\nDAG misspecification, CauchyEst/CauchyEstTree and BatchAvgLeastSquares\nrespectively perform better.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 04:17:46 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Choo", "Davin", ""], ["Gajjala", "Rishikesh", ""], ["Gayen", "Sutanu", ""], ["Wang", "Yuhao", ""]]}, {"id": "2107.10483", "submitter": "Phillip Lippe", "authors": "Phillip Lippe, Taco Cohen, Efstratios Gavves", "title": "Efficient Neural Causal Discovery without Acyclicity Constraints", "comments": "8th Causal Inference Workshop at UAI 2021 (contributed talk). 34\n  pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning the structure of a causal graphical model using both observational\nand interventional data is a fundamental problem in many scientific fields. A\npromising direction is continuous optimization for score-based methods, which\nefficiently learn the causal graph in a data-driven manner. However, to date,\nthose methods require constrained optimization to enforce acyclicity or lack\nconvergence guarantees. In this paper, we present ENCO, an efficient structure\nlearning method for directed, acyclic causal graphs leveraging observational\nand interventional data. ENCO formulates the graph search as an optimization of\nindependent edge likelihoods, with the edge orientation being modeled as a\nseparate parameter. Consequently, we can provide convergence guarantees of ENCO\nunder mild conditions without constraining the score function with respect to\nacyclicity. In experiments, we show that ENCO can efficiently recover graphs\nwith hundreds of nodes, an order of magnitude larger than what was previously\npossible, while handling deterministic variables and latent confounders.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:01:41 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lippe", "Phillip", ""], ["Cohen", "Taco", ""], ["Gavves", "Efstratios", ""]]}, {"id": "2107.10492", "submitter": "Aditya Gopalan", "authors": "Aditya Gopalan, Venkatesh Saligrama and Braghadeesh Lakshminarayanan", "title": "Bandit Quickest Changepoint Detection", "comments": "26 pages including appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting abrupt changes in temporal behavior patterns is of interest in many\nindustrial and security applications. Abrupt changes are often local and\nobservable primarily through a well-aligned sensing action (e.g., a camera with\na narrow field-of-view). Due to resource constraints, continuous monitoring of\nall of the sensors is impractical. We propose the bandit quickest changepoint\ndetection framework as a means of balancing sensing cost with detection delay.\nIn this framework, sensing actions (or sensors) are sequentially chosen, and\nonly measurements corresponding to chosen actions are observed. We derive an\ninformation-theoretic lower bound on the detection delay for a general class of\nfinitely parameterized probability distributions. We then propose a\ncomputationally efficient online sensing scheme, which seamlessly balances the\nneed for exploration of different sensing options with exploitation of querying\ninformative actions. We derive expected delay bounds for the proposed scheme\nand show that these bounds match our information-theoretic lower bounds at low\nfalse alarm rates, establishing optimality of the proposed method. We then\nperform a number of experiments on synthetic and real datasets demonstrating\nthe efficacy of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:25:35 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Gopalan", "Aditya", ""], ["Saligrama", "Venkatesh", ""], ["Lakshminarayanan", "Braghadeesh", ""]]}, {"id": "2107.10567", "submitter": "Kyu Beom Lee", "authors": "Kyu-Beom Lee and Hyu-Soung Shin", "title": "An overcome of far-distance limitation on tunnel CCTV-based accident\n  detection in AI deep-learning frameworks", "comments": "6 pages, 3 figures, to be presented in \"2021 INTERNATIONAL CONFERENCE\n  ON TUNNELS AND UNDERGROUND SPACES\" conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Tunnel CCTVs are installed to low height and long-distance interval. However,\nbecause of the limitation of installation height, severe perspective effect in\ndistance occurs, and it is almost impossible to detect vehicles in far distance\nfrom the CCTV in the existing tunnel CCTV-based accident detection system\n(Pflugfelder 2005). To overcome the limitation, a vehicle object is detected\nthrough an object detection algorithm based on an inverse perspective transform\nby re-setting the region of interest (ROI). It can detect vehicles that are far\naway from the CCTV. To verify this process, this paper creates each dataset\nconsisting of images and bounding boxes based on the original and warped images\nof the CCTV at the same time, and then compares performance of the deep\nlearning object detection models trained with the two datasets. As a result,\nthe model that trained the warped image was able to detect vehicle objects more\naccurately at the position far from the CCTV compared to the model that trained\nthe original image.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:42:25 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lee", "Kyu-Beom", ""], ["Shin", "Hyu-Soung", ""]]}, {"id": "2107.10663", "submitter": "Naichen Shi", "authors": "Naichen Shi, Fan Lai, Raed Al Kontar, Mosharaf Chowdhury", "title": "Fed-ensemble: Improving Generalization through Model Ensembling in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose Fed-ensemble: a simple approach that bringsmodel\nensembling to federated learning (FL). Instead of aggregating localmodels to\nupdate a single global model, Fed-ensemble uses random permutations to update a\ngroup of K models and then obtains predictions through model averaging.\nFed-ensemble can be readily utilized within established FL methods and does not\nimpose a computational overhead as it only requires one of the K models to be\nsent to a client in each communication round. Theoretically, we show that\npredictions on newdata from all K models belong to the same predictive\nposterior distribution under a neural tangent kernel regime. This result in\nturn sheds light onthe generalization advantages of model averaging. We also\nillustrate thatFed-ensemble has an elegant Bayesian interpretation. Empirical\nresults show that our model has superior performance over several FL\nalgorithms,on a wide range of data sets, and excels in heterogeneous settings\noften encountered in FL applications.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:40:14 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shi", "Naichen", ""], ["Lai", "Fan", ""], ["Kontar", "Raed Al", ""], ["Chowdhury", "Mosharaf", ""]]}, {"id": "2107.10703", "submitter": "Alexandre Drouin", "authors": "Philippe Brouillard, Perouz Taslakian, Alexandre Lacoste, Sebastien\n  Lachapelle, Alexandre Drouin", "title": "Typing assumptions improve identification in causal discovery", "comments": "Accepted for presentation as a contributed talk at the Workshop on\n  the Neglected Assumptions in Causal Inference (NACI) at the 38th\n  International Conference on Machine Learning, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from observational data is a challenging task to which an\nexact solution cannot always be identified. Under assumptions about the\ndata-generative process, the causal graph can often be identified up to an\nequivalence class. Proposing new realistic assumptions to circumscribe such\nequivalence classes is an active field of research. In this work, we propose a\nnew set of assumptions that constrain possible causal relationships based on\nthe nature of the variables. We thus introduce typed directed acyclic graphs,\nin which variable types are used to determine the validity of causal\nrelationships. We demonstrate, both theoretically and empirically, that the\nproposed assumptions can result in significant gains in the identification of\nthe causal graph.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:23:08 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Brouillard", "Philippe", ""], ["Taslakian", "Perouz", ""], ["Lacoste", "Alexandre", ""], ["Lachapelle", "Sebastien", ""], ["Drouin", "Alexandre", ""]]}, {"id": "2107.10731", "submitter": "Lauro Sandor Langosco di Langosco", "authors": "Lauro Langosco di Langosco, Vincent Fortuin, Heiko Strathmann", "title": "Neural Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Particle-based approximate Bayesian inference approaches such as Stein\nVariational Gradient Descent (SVGD) combine the flexibility and convergence\nguarantees of sampling methods with the computational benefits of variational\ninference. In practice, SVGD relies on the choice of an appropriate kernel\nfunction, which impacts its ability to model the target distribution -- a\nchallenging problem with only heuristic solutions. We propose Neural\nVariational Gradient Descent (NVGD), which is based on parameterizing the\nwitness function of the Stein discrepancy by a deep neural network whose\nparameters are learned in parallel to the inference, mitigating the necessity\nto make any kernel choices whatsoever. We empirically evaluate our method on\npopular synthetic inference problems, real-world Bayesian linear regression,\nand Bayesian neural network inference.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 15:10:50 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 10:57:04 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["di Langosco", "Lauro Langosco", ""], ["Fortuin", "Vincent", ""], ["Strathmann", "Heiko", ""]]}, {"id": "2107.10835", "submitter": "James Bagrow", "authors": "James P. Bagrow and Sune Lehmann", "title": "Recovering lost and absent information in temporal networks", "comments": "19 pages, 5 figures, 1 table, plus supporting information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The full range of activity in a temporal network is captured in its edge\nactivity data -- time series encoding the tie strengths or on-off dynamics of\neach edge in the network. However, in many practical applications, edge-level\ndata are unavailable, and the network analyses must rely instead on node\nactivity data which aggregates the edge-activity data and thus is less\ninformative. This raises the question: Is it possible to use the static network\nto recover the richer edge activities from the node activities? Here we show\nthat recovery is possible, often with a surprising degree of accuracy given how\nmuch information is lost, and that the recovered data are useful for subsequent\nnetwork analysis tasks. Recovery is more difficult when network density\nincreases, either topologically or dynamically, but exploiting dynamical and\ntopological sparsity enables effective solutions to the recovery problem. We\nformally characterize the difficulty of the recovery problem both theoretically\nand empirically, proving the conditions under which recovery errors can be\nbounded and showing that, even when these conditions are not met, good quality\nsolutions can still be derived. Effective recovery carries both promise and\nperil, as it enables deeper scientific study of complex systems but in the\ncontext of social systems also raises privacy concerns when social information\ncan be aggregated across multiple data sources.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:49:27 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bagrow", "James P.", ""], ["Lehmann", "Sune", ""]]}, {"id": "2107.10867", "submitter": "Marco Tezzele", "authors": "Francesco Romor and Marco Tezzele and Gianluigi Rozza", "title": "A local approach to parameter space reduction for regression and\n  classification tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequently, the parameter space, chosen for shape design or other\napplications that involve the definition of a surrogate model, present\nsubdomains where the objective function of interest is highly regular or well\nbehaved. So, it could be approximated more accurately if restricted to those\nsubdomains and studied separately. The drawback of this approach is the\npossible scarcity of data in some applications, but in those, where a quantity\nof data, moderately abundant considering the parameter space dimension and the\ncomplexity of the objective function, is available, partitioned or local\nstudies are beneficial. In this work we propose a new method called local\nactive subspaces (LAS), which explores the synergies of active subspaces with\nsupervised clustering techniques in order to perform a more efficient dimension\nreduction in the parameter space for the design of accurate response surfaces.\nWe also developed a procedure to exploit the local active subspace information\nfor classification tasks. Using this technique as a preprocessing step onto the\nparameter space, or output space in case of vectorial outputs, brings\nremarkable results for the purpose of surrogate modelling.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:06:04 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Romor", "Francesco", ""], ["Tezzele", "Marco", ""], ["Rozza", "Gianluigi", ""]]}, {"id": "2107.10869", "submitter": "Nathaniel Strawn", "authors": "Nate Strawn", "title": "Filament Plots for Data Visualization", "comments": "33 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We construct a computationally inexpensive 3D extension of Andrew's plots by\nconsidering curves generated by Frenet-Serret equations and induced by\noptimally smooth 2D Andrew's plots. We consider linear isometries from a\nEuclidean data space to infinite dimensional spaces of 2D curves, and\nparametrize the linear isometries that produce (on average) optimally smooth\ncurves over a given dataset. This set of optimal isometries admits many degrees\nof freedom, and (using recent results on generalized Gauss sums) we identify a\nparticular a member of this set which admits an asymptotic projective \"tour\"\nproperty. Finally, we consider the unit-length 3D curves (filaments) induced by\nthese 2D Andrew's plots, where the linear isometry property preserves distances\nas \"relative total square curvatures\". This work concludes by illustrating\nfilament plots for several datasets. Code is available at\nhttps://github.com/n8epi/filaments\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:20:33 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Strawn", "Nate", ""]]}, {"id": "2107.10884", "submitter": "Wu Lin", "authors": "Wu Lin, Frank Nielsen, Mohammad Emtiyaz Khan, Mark Schmidt", "title": "Structured second-order methods via natural gradient descent", "comments": "ICML workshop paper. arXiv admin note: substantial text overlap with\n  arXiv:2102.07405", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose new structured second-order methods and structured\nadaptive-gradient methods obtained by performing natural-gradient descent on\nstructured parameter spaces. Natural-gradient descent is an attractive approach\nto design new algorithms in many settings such as gradient-free,\nadaptive-gradient, and second-order methods. Our structured methods not only\nenjoy a structural invariance but also admit a simple expression. Finally, we\ntest the efficiency of our proposed methods on both deterministic non-convex\nproblems and deep learning problems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 19:03:53 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lin", "Wu", ""], ["Nielsen", "Frank", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Schmidt", "Mark", ""]]}, {"id": "2107.10947", "submitter": "Nhat Ho", "authors": "Nhat Ho and Stephen G. Walker", "title": "On Integral Theorems: Monte Carlo Estimators and Optimal Functions", "comments": "18 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:2106.06608", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.CA stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of integral theorems based on cyclic functions and\nRiemann sums approximating integrals theorem. The Fourier integral theorem,\nderived as a combination of a transform and inverse transform, arises as a\nspecial case. The integral theorems provide natural estimators of density\nfunctions via Monte Carlo integration. Assessments of the quality of the\ndensity estimators can be used to obtain optimal cyclic functions which\nminimize square integrals. Our proof techniques rely on a variational approach\nin ordinary differential equations and the Cauchy residue theorem in complex\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 22:25:21 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Ho", "Nhat", ""], ["Walker", "Stephen G.", ""]]}, {"id": "2107.10955", "submitter": "Xiaodong Li", "authors": "Xingmei Lou, Yu Hu, Xiaodong Li", "title": "Linear Polytree Structural Equation Models: Structural Learning and\n  Inverse Correlation Estimation", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the problem of learning the directed acyclic graph (DAG)\nwhen data are generated from a linear structural equation model (SEM) and the\ncausal structure can be characterized by a polytree. Specially, under both\nGaussian and sub-Gaussian models, we study the sample size conditions for the\nwell-known Chow-Liu algorithm to exactly recover the equivalence class of the\npolytree, which is uniquely represented by a CPDAG. We also study the error\nrate for the estimation of the inverse correlation matrix under such models.\nOur theoretical findings are illustrated by comprehensive numerical\nsimulations, and experiments on benchmark data also demonstrate the robustness\nof the method when the ground truth graphical structure can only be\napproximated by a polytree.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 23:22:20 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lou", "Xingmei", ""], ["Hu", "Yu", ""], ["Li", "Xiaodong", ""]]}, {"id": "2107.10959", "submitter": "Zhe Fei", "authors": "Zhe Fei, Qi Zheng, Hyokyoung G. Hong, Yi Li", "title": "Inference for High Dimensional Censored Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the availability of high dimensional genetic biomarkers, it is of\ninterest to identify heterogeneous effects of these predictors on patients'\nsurvival, along with proper statistical inference. Censored quantile regression\nhas emerged as a powerful tool for detecting heterogeneous effects of\ncovariates on survival outcomes. To our knowledge, there is little work\navailable to draw inference on the effects of high dimensional predictors for\ncensored quantile regression. This paper proposes a novel procedure to draw\ninference on all predictors within the framework of global censored quantile\nregression, which investigates covariate-response associations over an interval\nof quantile levels, instead of a few discrete values. The proposed estimator\ncombines a sequence of low dimensional model estimates that are based on\nmulti-sample splittings and variable selection. We show that, under some\nregularity conditions, the estimator is consistent and asymptotically follows a\nGaussian process indexed by the quantile level. Simulation studies indicate\nthat our procedure can properly quantify the uncertainty of the estimates in\nhigh dimensional settings. We apply our method to analyze the heterogeneous\neffects of SNPs residing in lung cancer pathways on patients' survival, using\nthe Boston Lung Cancer Survival Cohort, a cancer epidemiology study on the\nmolecular mechanism of lung cancer.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 23:57:06 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Fei", "Zhe", ""], ["Zheng", "Qi", ""], ["Hong", "Hyokyoung G.", ""], ["Li", "Yi", ""]]}, {"id": "2107.10960", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Harikrishna Narasimhan, Andrew Cotter", "title": "Implicit Rate-Constrained Optimization of Non-decomposable Objectives", "comments": "ICML 2021; Code available at\n  https://github.com/google-research/google-research/tree/master/implicit_constrained_optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a popular family of constrained optimization problems arising in\nmachine learning that involve optimizing a non-decomposable evaluation metric\nwith a certain thresholded form, while constraining another metric of interest.\nExamples of such problems include optimizing the false negative rate at a fixed\nfalse positive rate, optimizing precision at a fixed recall, optimizing the\narea under the precision-recall or ROC curves, etc. Our key idea is to\nformulate a rate-constrained optimization that expresses the threshold\nparameter as a function of the model parameters via the Implicit Function\ntheorem. We show how the resulting optimization problem can be solved using\nstandard gradient based methods. Experiments on benchmark datasets demonstrate\nthe effectiveness of our proposed method over existing state-of-the art\napproaches for these problems. The code for the proposed method is available at\nhttps://github.com/google-research/google-research/tree/master/implicit_constrained_optimization .\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 00:04:39 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 02:05:02 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 00:45:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kumar", "Abhishek", ""], ["Narasimhan", "Harikrishna", ""], ["Cotter", "Andrew", ""]]}, {"id": "2107.10970", "submitter": "Yu-Chia Chen", "authors": "Yu-Chia Chen, Marina Meil\\u{a}", "title": "The decomposition of the higher-order homology embedding constructed\n  from the $k$-Laplacian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The null space of the $k$-th order Laplacian $\\mathbf{\\mathcal L}_k$, known\nas the {\\em $k$-th homology vector space}, encodes the non-trivial topology of\na manifold or a network. Understanding the structure of the homology embedding\ncan thus disclose geometric or topological information from the data. The study\nof the null space embedding of the graph Laplacian $\\mathbf{\\mathcal L}_0$ has\nspurred new research and applications, such as spectral clustering algorithms\nwith theoretical guarantees and estimators of the Stochastic Block Model. In\nthis work, we investigate the geometry of the $k$-th homology embedding and\nfocus on cases reminiscent of spectral clustering. Namely, we analyze the {\\em\nconnected sum} of manifolds as a perturbation to the direct sum of their\nhomology embeddings. We propose an algorithm to factorize the homology\nembedding into subspaces corresponding to a manifold's simplest topological\ncomponents. The proposed framework is applied to the {\\em shortest homologous\nloop detection} problem, a problem known to be NP-hard in general. Our spectral\nloop detection algorithm scales better than existing methods and is effective\non diverse data such as point clouds and images.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 00:40:01 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 16:14:16 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Yu-Chia", ""], ["Meil\u0103", "Marina", ""]]}, {"id": "2107.11059", "submitter": "Mario W\\\"uthrich V.", "authors": "Ronald Richman and Mario V. W\\\"uthrich", "title": "LocalGLMnet: interpretable deep learning for tabular data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.ST stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning models have gained great popularity in statistical modeling\nbecause they lead to very competitive regression models, often outperforming\nclassical statistical models such as generalized linear models. The\ndisadvantage of deep learning models is that their solutions are difficult to\ninterpret and explain, and variable selection is not easily possible because\ndeep learning models solve feature engineering and variable selection\ninternally in a nontransparent way. Inspired by the appealing structure of\ngeneralized linear models, we propose a new network architecture that shares\nsimilar features as generalized linear models, but provides superior predictive\npower benefiting from the art of representation learning. This new architecture\nallows for variable selection of tabular data and for interpretation of the\ncalibrated deep learning model, in fact, our approach provides an additive\ndecomposition in the spirit of Shapley values and integrated gradients.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 07:38:33 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Richman", "Ronald", ""], ["W\u00fcthrich", "Mario V.", ""]]}, {"id": "2107.11114", "submitter": "Alban Farchi", "authors": "Alban Farchi, Marc Bocquet, Patrick Laloyaux, Massimo Bonavita,\n  Quentin Malartic", "title": "A comparison of combined data assimilation and machine learning methods\n  for offline and online model error correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that it is possible to combine machine learning\nmethods with data assimilation to reconstruct a dynamical system using only\nsparse and noisy observations of that system. The same approach can be used to\ncorrect the error of a knowledge-based model. The resulting surrogate model is\nhybrid, with a statistical part supplementing a physical part. In practice, the\ncorrection can be added as an integrated term (i.e. in the model resolvent) or\ndirectly inside the tendencies of the physical model. The resolvent correction\nis easy to implement. The tendency correction is more technical, in particular\nit requires the adjoint of the physical model, but also more flexible. We use\nthe two-scale Lorenz model to compare the two methods. The accuracy in\nlong-range forecast experiments is somewhat similar between the surrogate\nmodels using the resolvent correction and the tendency correction. By contrast,\nthe surrogate models using the tendency correction significantly outperform the\nsurrogate models using the resolvent correction in data assimilation\nexperiments. Finally, we show that the tendency correction opens the\npossibility to make online model error correction, i.e. improving the model\nprogressively as new observations become available. The resulting algorithm can\nbe seen as a new formulation of weak-constraint 4D-Var. We compare online and\noffline learning using the same framework with the two-scale Lorenz system, and\nshow that with online learning, it is possible to extract all the information\nfrom sparse and noisy observations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:57:45 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Farchi", "Alban", ""], ["Bocquet", "Marc", ""], ["Laloyaux", "Patrick", ""], ["Bonavita", "Massimo", ""], ["Malartic", "Quentin", ""]]}, {"id": "2107.11136", "submitter": "Di Wang", "authors": "Lijie Hu and Shuo Ni and Hanshen Xiao and Di Wang", "title": "High Dimensional Differentially Private Stochastic Optimization with\n  Heavy-tailed Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As one of the most fundamental problems in machine learning, statistics and\ndifferential privacy, Differentially Private Stochastic Convex Optimization\n(DP-SCO) has been extensively studied in recent years. However, most of the\nprevious work can only handle either regular data distribution or irregular\ndata in the low dimensional space case. To better understand the challenges\narising from irregular data distribution, in this paper we provide the first\nstudy on the problem of DP-SCO with heavy-tailed data in the high dimensional\nspace. In the first part we focus on the problem over some polytope constraint\n(such as the $\\ell_1$-norm ball). We show that if the loss function is smooth\nand its gradient has bounded second order moment, it is possible to get a (high\nprobability) error bound (excess population risk) of $\\tilde{O}(\\frac{\\log\nd}{(n\\epsilon)^\\frac{1}{3}})$ in the $\\epsilon$-DP model, where $n$ is the\nsample size and $d$ is the dimensionality of the underlying space. Next, for\nLASSO, if the data distribution that has bounded fourth-order moments, we\nimprove the bound to $\\tilde{O}(\\frac{\\log d}{(n\\epsilon)^\\frac{2}{5}})$ in the\n$(\\epsilon, \\delta)$-DP model. In the second part of the paper, we study sparse\nlearning with heavy-tailed data. We first revisit the sparse linear model and\npropose a truncated DP-IHT method whose output could achieve an error of\n$\\tilde{O}(\\frac{s^{*2}\\log d}{n\\epsilon})$, where $s^*$ is the sparsity of the\nunderlying parameter. Then we study a more general problem over the sparsity\n({\\em i.e.,} $\\ell_0$-norm) constraint, and show that it is possible to achieve\nan error of $\\tilde{O}(\\frac{s^{*\\frac{3}{2}}\\log d}{n\\epsilon})$, which is\nalso near optimal up to a factor of $\\tilde{O}{(\\sqrt{s^*})}$, if the loss\nfunction is smooth and strongly convex.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 11:03:21 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Hu", "Lijie", ""], ["Ni", "Shuo", ""], ["Xiao", "Hanshen", ""], ["Wang", "Di", ""]]}, {"id": "2107.11153", "submitter": "James Whittington", "authors": "James C.R. Whittington, Rishabh Kabra, Loic Matthey, Christopher P.\n  Burgess, Alexander Lerchner", "title": "Constellation: Learning relational abstractions over objects for\n  compositional imagination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning structured representations of visual scenes is currently a major\nbottleneck to bridging perception with reasoning. While there has been exciting\nprogress with slot-based models, which learn to segment scenes into sets of\nobjects, learning configurational properties of entire groups of objects is\nstill under-explored. To address this problem, we introduce Constellation, a\nnetwork that learns relational abstractions of static visual scenes, and\ngeneralises these abstractions over sensory particularities, thus offering a\npotential basis for abstract relational reasoning. We further show that this\nbasis, along with language association, provides a means to imagine sensory\ncontent in new ways. This work is a first step in the explicit representation\nof visual relationships and using them for complex cognitive procedures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 11:59:40 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Whittington", "James C. R.", ""], ["Kabra", "Rishabh", ""], ["Matthey", "Loic", ""], ["Burgess", "Christopher P.", ""], ["Lerchner", "Alexander", ""]]}, {"id": "2107.11231", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Alessandro Barp, Mark Girolami, Michael I.\n  Jordan", "title": "Optimization on manifolds: A symplectic approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been great interest in using tools from dynamical systems and\nnumerical analysis of differential equations to understand and construct new\noptimization methods. In particular, recently a new paradigm has emerged that\napplies ideas from mechanics and geometric integration to obtain accelerated\noptimization methods on Euclidean spaces. This has important consequences given\nthat accelerated methods are the workhorses behind many machine learning\napplications. In this paper we build upon these advances and propose a\nframework for dissipative and constrained Hamiltonian systems that is suitable\nfor solving optimization problems on arbitrary smooth manifolds. Importantly,\nthis allows us to leverage the well-established theory of symplectic\nintegration to derive \"rate-matching\" dissipative integrators. This brings a\nnew perspective to optimization on manifolds whereby convergence guarantees\nfollow by construction from classical arguments in symplectic geometry and\nbackward error analysis. Moreover, we construct two dissipative generalizations\nof leapfrog that are straightforward to implement: one for Lie groups and\nhomogeneous spaces, that relies on the tractable geodesic flow or a retraction\nthereof, and the other for constrained submanifolds that is based on a\ndissipative generalization of the famous RATTLE integrator.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 13:43:34 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Barp", "Alessandro", ""], ["Girolami", "Mark", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2107.11253", "submitter": "Quentin Malartic", "authors": "Quentin Malartic, Alban Farchi, Marc Bocquet", "title": "State, global and local parameter estimation using local ensemble Kalman\n  filters: applications to online machine learning of chaotic dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG nlin.CD physics.ao-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent methodological paper, we have shown how to learn chaotic dynamics\nalong with the state trajectory from sequentially acquired observations, using\nlocal ensemble Kalman filters. Here, we more systematically investigate the\npossibilty to use a local ensemble Kalman filter with either covariance\nlocalization or local domains, in order to retrieve the state and a mix of key\nglobal and local parameters. Global parameters are meant to represent the\nsurrogate dynamics, for instance through a neural network, which is reminiscent\nof data-driven machine learning of dynamics, while the local parameters\ntypically stand for the forcings of the model. A family of algorithms for\ncovariance and local domain localization is proposed in this joint state and\nparameter filter context. In particular, we show how to rigorously update\nglobal parameters using a local domain EnKF such as the LETKF, an inherently\nlocal method. The approach is tested with success on the 40-variable Lorenz\nmodel using several of the local EnKF flavors. A two-dimensional illustration\nbased on a multi-layer Lorenz model is finally provided. It uses radiance-like\nnon-local observations, and both local domains and covariance localization in\norder to learn the chaotic dynamics, the local forcings, and the couplings\nbetween layers. This paper more generally addresses the key question of online\nestimation of both global and local model parameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:12:20 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 08:46:24 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Malartic", "Quentin", ""], ["Farchi", "Alban", ""], ["Bocquet", "Marc", ""]]}, {"id": "2107.11357", "submitter": "Richard Pymar", "authors": "Chris Harris, Richard Pymar, Colin Rowat", "title": "Joint Shapley values: a measure of joint feature importance", "comments": "Source code available at\n  https://github.com/harris-chris/joint-shapley-values", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Shapley value is one of the most widely used model-agnostic measures of\nfeature importance in explainable AI: it has clear axiomatic foundations, is\nguaranteed to uniquely exist, and has a clear interpretation as a feature's\naverage effect on a model's prediction. We introduce joint Shapley values,\nwhich directly extend the Shapley axioms. This preserves the classic Shapley\nvalue's intuitions: joint Shapley values measure a set of features' average\neffect on a model's prediction. We prove the uniqueness of joint Shapley\nvalues, for any order of explanation. Results for games show that joint Shapley\nvalues present different insights from existing interaction indices, which\nassess the effect of a feature within a set of features. Deriving joint Shapley\nvalues in ML attribution problems thus gives us the first measure of the joint\neffect of sets of features on model predictions. In a dataset with binary\nfeatures, we present a presence-adjusted method for calculating global values\nthat retains the efficiency property.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 17:22:37 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Harris", "Chris", ""], ["Pymar", "Richard", ""], ["Rowat", "Colin", ""]]}, {"id": "2107.11419", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama, Edouard Fouch\\'e, Junya Honda", "title": "Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider nonstationary multi-armed bandit problems where the model\nparameters of the arms change over time. We introduce the adaptive resetting\nbandit (ADR-bandit), which is a class of bandit algorithms that leverages\nadaptive windowing techniques from the data stream community. We first provide\nnew guarantees on the quality of estimators resulting from adaptive windowing\ntechniques, which are of independent interest in the data mining community.\nFurthermore, we conduct a finite-time analysis of ADR-bandit in two typical\nenvironments: an abrupt environment where changes occur instantaneously and a\ngradual environment where changes occur progressively. We demonstrate that\nADR-bandit has nearly optimal performance when the abrupt or global changes\noccur in a coordinated manner that we call global changes. We demonstrate that\nforced exploration is unnecessary when we restrict the interest to the global\nchanges. Unlike the existing nonstationary bandit algorithms, ADR-bandit has\noptimal performance in stationary environments as well as nonstationary\nenvironments with global changes. Our experiments show that the proposed\nalgorithms outperform the existing approaches in synthetic and real-world\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 19:02:52 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Komiyama", "Junpei", ""], ["Fouch\u00e9", "Edouard", ""], ["Honda", "Junya", ""]]}, {"id": "2107.11433", "submitter": "Rui Yuan", "authors": "Rui Yuan, Robert M. Gower, Alessandro Lazaric", "title": "A general sample complexity analysis of vanilla policy gradient", "comments": "ICML 2021 Workshop on \"Reinforcement learning theory\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The policy gradient (PG) is one of the most popular methods for solving\nreinforcement learning (RL) problems. However, a solid theoretical\nunderstanding of even the \"vanilla\" PG has remained elusive for long time. In\nthis paper, we apply recent tools developed for the analysis of SGD in\nnon-convex optimization to obtain convergence guarantees for both REINFORCE and\nGPOMDP under smoothness assumption on the objective function and weak\nconditions on the second moment of the norm of the estimated gradient. When\ninstantiated under common assumptions on the policy space, our general result\nimmediately recovers existing $\\widetilde{\\mathcal{O}}(\\epsilon^{-4})$ sample\ncomplexity guarantees, but for wider ranges of parameters (e.g., step size and\nbatch size $m$) with respect to previous literature. Notably, our result\nincludes the single trajectory case (i.e., $m=1$) and it provides a more\naccurate analysis of the dependency on problem-specific parameters by fixing\nprevious results available in the literature. We believe that the integration\nof state-of-the-art tools from non-convex optimization may lead to identify a\nmuch broader range of problems where PG methods enjoy strong theoretical\nguarantees.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 19:38:17 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yuan", "Rui", ""], ["Gower", "Robert M.", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "2107.11533", "submitter": "Hung Tran-The", "authors": "Hung Tran-The, Sunil Gupta, Thanh Nguyen-Tang, Santu Rana, Svetha\n  Venkatesh", "title": "Combining Online Learning and Offline Learning for Contextual Bandits\n  with Deficient Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address policy learning with logged data in contextual bandits. Current\noffline-policy learning algorithms are mostly based on inverse propensity score\n(IPS) weighting requiring the logging policy to have \\emph{full support} i.e. a\nnon-zero probability for any context/action of the evaluation policy. However,\nmany real-world systems do not guarantee such logging policies, especially when\nthe action space is large and many actions have poor or missing rewards. With\nsuch \\emph{support deficiency}, the offline learning fails to find optimal\npolicies. We propose a novel approach that uses a hybrid of offline learning\nwith online exploration. The online exploration is used to explore unsupported\nactions in the logged data whilst offline learning is used to exploit supported\nactions from the logged data avoiding unnecessary explorations. Our approach\ndetermines an optimal policy with theoretical guarantees using the minimal\nnumber of online explorations. We demonstrate our algorithms' effectiveness\nempirically on a diverse collection of datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 05:07:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tran-The", "Hung", ""], ["Gupta", "Sunil", ""], ["Nguyen-Tang", "Thanh", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2107.11609", "submitter": "Umberto Michelucci", "authors": "Umberto Michelucci, Michela Sperti, Dario Piga, Francesca Venturini,\n  Marco A. Deriu", "title": "A Model-Agnostic Algorithm for Bayes Error Determination in Binary\n  Classification", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the intrinsic limit determination algorithm (ILD\nAlgorithm), a novel technique to determine the best possible performance,\nmeasured in terms of the AUC (area under the ROC curve) and accuracy, that can\nbe obtained from a specific dataset in a binary classification problem with\ncategorical features {\\sl regardless} of the model used. This limit, namely the\nBayes error, is completely independent of any model used and describes an\nintrinsic property of the dataset. The ILD algorithm thus provides important\ninformation regarding the prediction limits of any binary classification\nalgorithm when applied to the considered dataset. In this paper the algorithm\nis described in detail, its entire mathematical framework is presented and the\npseudocode is given to facilitate its implementation. Finally, an example with\na real dataset is given.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 13:55:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Michelucci", "Umberto", ""], ["Sperti", "Michela", ""], ["Piga", "Dario", ""], ["Venturini", "Francesca", ""], ["Deriu", "Marco A.", ""]]}, {"id": "2107.11630", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er", "title": "Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them", "comments": "ICML 2021 Workshop on the Prospects and Perils of Adversarial Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making classifiers robust to adversarial examples is hard. Thus, many\ndefenses tackle the seemingly easier task of detecting perturbed inputs. We\nshow a barrier towards this goal. We prove a general hardness reduction between\ndetection and classification of adversarial examples: given a robust detector\nfor attacks at distance {\\epsilon} (in some metric), we can build a similarly\nrobust (but inefficient) classifier for attacks at distance {\\epsilon}/2. Our\nreduction is computationally inefficient, and thus cannot be used to build\npractical classifiers. Instead, it is a useful sanity check to test whether\nempirical detection results imply something much stronger than the authors\npresumably anticipated. To illustrate, we revisit 13 detector defenses. For\n11/13 cases, we show that the claimed detection results would imply an\ninefficient classifier with robustness far beyond the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 15:14:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tram\u00e8r", "Florian", ""]]}, {"id": "2107.11658", "submitter": "Nikolaos Dionelis", "authors": "Nikolaos Dionelis", "title": "Tail of Distribution GAN (TailGAN): Generative-\n  Adversarial-Network-Based Boundary Formation", "comments": "5 pages, 2020 Sensor Signal Processing for Defence Conference (SSPD)", "journal-ref": "2020 Sensor Signal Processing for Defence Conference (SSPD)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GAN) are a powerful methodology and can be\nused for unsupervised anomaly detection, where current techniques have\nlimitations such as the accurate detection of anomalies near the tail of a\ndistribution. GANs generally do not guarantee the existence of a probability\ndensity and are susceptible to mode collapse, while few GANs use likelihood to\nreduce mode collapse. In this paper, we create a GAN-based tail formation model\nfor anomaly detection, the Tail of distribution GAN (TailGAN), to generate\nsamples on the tail of the data distribution and detect anomalies near the\nsupport boundary. Using TailGAN, we leverage GANs for anomaly detection and use\nmaximum entropy regularization. Using GANs that learn the probability of the\nunderlying distribution has advantages in improving the anomaly detection\nmethodology by allowing us to devise a generator for boundary samples, and use\nthis model to characterize anomalies. TailGAN addresses supports with disjoint\ncomponents and achieves competitive performance on images. We evaluate TailGAN\nfor identifying Out-of-Distribution (OoD) data and its performance evaluated on\nMNIST, CIFAR-10, Baggage X-Ray, and OoD data shows competitiveness compared to\nmethods from the literature.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 17:29:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Dionelis", "Nikolaos", ""]]}, {"id": "2107.11662", "submitter": "Rahul Singh", "authors": "Rahul Singh, Yongxin Chen", "title": "Inference of collective Gaussian hidden Markov models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider inference problems for a class of continuous state collective\nhidden Markov models, where the data is recorded in aggregate (collective) form\ngenerated by a large population of individuals following the same dynamics. We\npropose an aggregate inference algorithm called collective Gaussian\nforward-backward algorithm, extending recently proposed Sinkhorn belief\npropagation algorithm to models characterized by Gaussian densities. Our\nalgorithm enjoys convergence guarantee. In addition, it reduces to the standard\nKalman filter when the observations are generated by a single individual. The\nefficacy of the proposed algorithm is demonstrated through multiple\nexperiments.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 17:49:01 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Singh", "Rahul", ""], ["Chen", "Yongxin", ""]]}, {"id": "2107.11712", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Sutanu Gayen, Saravanan Kandasamy, Vedant Raval,\n  N. V. Vinodchandran", "title": "Efficient inference of interventional distributions", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of efficiently inferring interventional distributions\nin a causal Bayesian network from a finite number of observations. Let\n$\\mathcal{P}$ be a causal model on a set $\\mathbf{V}$ of observable variables\non a given causal graph $G$. For sets $\\mathbf{X},\\mathbf{Y}\\subseteq\n\\mathbf{V}$, and setting ${\\bf x}$ to $\\mathbf{X}$, let $P_{\\bf x}(\\mathbf{Y})$\ndenote the interventional distribution on $\\mathbf{Y}$ with respect to an\nintervention ${\\bf x}$ to variables ${\\bf x}$. Shpitser and Pearl (AAAI 2006),\nbuilding on the work of Tian and Pearl (AAAI 2001), gave an exact\ncharacterization of the class of causal graphs for which the interventional\ndistribution $P_{\\bf x}({\\mathbf{Y}})$ can be uniquely determined. We give the\nfirst efficient version of the Shpitser-Pearl algorithm. In particular, under\nnatural assumptions, we give a polynomial-time algorithm that on input a causal\ngraph $G$ on observable variables $\\mathbf{V}$, a setting ${\\bf x}$ of a set\n$\\mathbf{X} \\subseteq \\mathbf{V}$ of bounded size, outputs succinct\ndescriptions of both an evaluator and a generator for a distribution $\\hat{P}$\nthat is $\\varepsilon$-close (in total variation distance) to $P_{\\bf\nx}({\\mathbf{Y}})$ where $Y=\\mathbf{V}\\setminus \\mathbf{X}$, if $P_{\\bf\nx}(\\mathbf{Y})$ is identifiable. We also show that when $\\mathbf{Y}$ is an\narbitrary set, there is no efficient algorithm that outputs an evaluator of a\ndistribution that is $\\varepsilon$-close to $P_{\\bf x}({\\mathbf{Y}})$ unless\nall problems that have statistical zero-knowledge proofs, including the Graph\nIsomorphism problem, have efficient randomized algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 02:40:01 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 15:14:09 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Gayen", "Sutanu", ""], ["Kandasamy", "Saravanan", ""], ["Raval", "Vedant", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "2107.11717", "submitter": "Avik Roy", "authors": "Chandrajit Bajaj, Avik Roy, Haoran Zhang", "title": "Invariance-based Multi-Clustering of Latent Space Embeddings for\n  Equivariant Learning", "comments": "The codebase for MCEVAE is available at\n  https://github.com/CVC-Lab/MCE-VAE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) have been shown to be remarkably effective in\nrecovering model latent spaces for several computer vision tasks. However,\ncurrently trained VAEs, for a number of reasons, seem to fall short in learning\ninvariant and equivariant clusters in latent space. Our work focuses on\nproviding solutions to this problem and presents an approach to disentangle\nequivariance feature maps in a Lie group manifold by enforcing deep,\ngroup-invariant learning. Simultaneously implementing a novel separation of\nsemantic and equivariant variables of the latent space representation, we\nformulate a modified Evidence Lower BOund (ELBO) by using a mixture model pdf\nlike Gaussian mixtures for invariant cluster embeddings that allows superior\nunsupervised variational clustering. Our experiments show that this model\neffectively learns to disentangle the invariant and equivariant representations\nwith significant improvements in the learning rate and an observably superior\nimage recognition and canonical state reconstruction compared to the currently\nbest deep learning models.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 03:27:47 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Bajaj", "Chandrajit", ""], ["Roy", "Avik", ""], ["Zhang", "Haoran", ""]]}, {"id": "2107.11774", "submitter": "Liu Ziyin", "authors": "Liu Ziyin, Botao Li, Masahito Ueda", "title": "SGD May Never Escape Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) has been deployed to solve highly\nnon-linear and non-convex machine learning problems such as the training of\ndeep neural networks. However, previous works on SGD often rely on highly\nrestrictive and unrealistic assumptions about the nature of noise in SGD. In\nthis work, we mathematically construct examples that defy previous\nunderstandings of SGD. For example, our constructions show that: (1) SGD may\nconverge to a local maximum; (2) SGD may escape a saddle point arbitrarily\nslowly; (3) SGD may prefer sharp minima over the flat ones; and (4) AMSGrad may\nconverge to a local maximum. Our result suggests that the noise structure of\nSGD might be more important than the loss landscape in neural network training\nand that future research should focus on deriving the actual noise structure in\ndeep learning.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 10:12:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ziyin", "Liu", ""], ["Li", "Botao", ""], ["Ueda", "Masahito", ""]]}, {"id": "2107.11858", "submitter": "Kevin O'Connor", "authors": "Kevin O'Connor, Kevin McGoff, Andrew B Nobel", "title": "Estimation of Stationary Optimal Transport Plans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study optimal transport problems in which finite-valued quantities of\ninterest evolve dynamically over time in a stationary fashion. Mathematically,\nthis is a special case of the general optimal transport problem in which the\ndistributions under study represent stationary processes and the cost depends\non a finite number of time points. In this setting, we argue that one should\nrestrict attention to stationary couplings, also known as joinings, which have\nclose connections with long run average cost. We introduce estimators of both\noptimal joinings and the optimal joining cost, and we establish their\nconsistency under mild conditions. Under stronger mixing assumptions we\nestablish finite-sample error rates for the same estimators that extend the\nbest known results in the iid case. Finally, we extend the consistency and rate\nanalysis to an entropy-penalized version of the optimal joining problem.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 17:46:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["O'Connor", "Kevin", ""], ["McGoff", "Kevin", ""], ["Nobel", "Andrew B", ""]]}, {"id": "2107.11869", "submitter": "Timothy Christensen", "authors": "Xiaohong Chen, Timothy Christensen, Sid Kankanala", "title": "Adaptive Estimation and Uniform Confidence Bands for Nonparametric IV", "comments": "The data-driven choice of sieve dimension in this paper is based on\n  and supersedes Section 3 of the preprint arXiv:1508.03365v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce computationally simple, data-driven procedures for estimation\nand inference on a structural function $h_0$ and its derivatives in\nnonparametric models using instrumental variables. Our first procedure is a\nbootstrap-based, data-driven choice of sieve dimension for sieve nonparametric\ninstrumental variables (NPIV) estimators. When implemented with this\ndata-driven choice, sieve NPIV estimators of $h_0$ and its derivatives are\nadaptive: they converge at the best possible (i.e., minimax) sup-norm rate,\nwithout having to know the smoothness of $h_0$, degree of endogeneity of the\nregressors, or instrument strength. Our second procedure is a data-driven\napproach for constructing honest and adaptive uniform confidence bands (UCBs)\nfor $h_0$ and its derivatives. Our data-driven UCBs guarantee coverage for\n$h_0$ and its derivatives uniformly over a generic class of data-generating\nprocesses (honesty) and contract at, or within a logarithmic factor of, the\nminimax sup-norm rate (adaptivity). As such, our data-driven UCBs deliver\nasymptotic efficiency gains relative to UCBs constructed via the usual approach\nof undersmoothing. In addition, both our procedures apply to nonparametric\nregression as a special case. We use our procedures to estimate and perform\ninference on a nonparametric gravity equation for the intensive margin of firm\nexports and find evidence against common parameterizations of the distribution\nof unobserved firm productivity.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 18:46:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chen", "Xiaohong", ""], ["Christensen", "Timothy", ""], ["Kankanala", "Sid", ""]]}, {"id": "2107.11892", "submitter": "Mengwu Guo", "authors": "Mengwu Guo", "title": "A brief note on understanding neural networks as Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a generalization of the work in [Lee et al., 2017], this note briefly\ndiscusses when the prior of a neural network output follows a Gaussian process,\nand how a neural-network-induced Gaussian process is formulated. The posterior\nmean functions of such a Gaussian process regression lie in the reproducing\nkernel Hilbert space defined by the neural-network-induced kernel. In the case\nof two-layer neural networks, the induced Gaussian processes provide an\ninterpretation of the reproducing kernel Hilbert spaces whose union forms a\nBarron space.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 21:06:58 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guo", "Mengwu", ""]]}, {"id": "2107.12034", "submitter": "Dirk Alexander Molitor", "authors": "Dirk Alexander Molitor and Christian Kubik and Ruben Helmut Hetfleisch\n  and Peter Groche", "title": "Workpiece Image-based Tool Wear Classification in Blanking Processes\n  Using Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blanking processes belong to the most widely used manufacturing techniques\ndue to their economic efficiency. Their economic viability depends to a large\nextent on the resulting product quality and the associated customer\nsatisfaction as well as on possible downtimes. In particular, the occurrence of\nincreased tool wear reduces the product quality and leads to downtimes, which\nis why considerable research has been carried out in recent years with regard\nto wear detection. While processes have widely been monitored based on force\nand acceleration signals, a new approach is pursued in this paper. Blanked\nworkpieces manufactured by punches with 16 different wear states are\nphotographed and then used as inputs for Deep Convolutional Neural Networks to\nclassify wear states. The results show that wear states can be predicted with\nsurprisingly high accuracy, opening up new possibilities and research\nopportunities for tool wear monitoring of blanking processes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:49:08 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Molitor", "Dirk Alexander", ""], ["Kubik", "Christian", ""], ["Hetfleisch", "Ruben Helmut", ""], ["Groche", "Peter", ""]]}, {"id": "2107.12100", "submitter": "Christoph Gote", "authors": "Christoph Gote and Vincenzo Perri and Ingo Scholtes", "title": "Predicting Influential Higher-Order Patterns in Temporal Network Data", "comments": "28 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IT cs.LG math.IT physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are frequently used to model complex systems comprised of\ninteracting elements. While links capture the topology of direct interactions,\nthe true complexity of many systems originates from higher-order patterns in\npaths by which nodes can indirectly influence each other. Path data,\nrepresenting ordered sequences of consecutive direct interactions, can be used\nto model these patterns. However, to avoid overfitting, such models should only\nconsider those higher-order patterns for which the data provide sufficient\nstatistical evidence. On the other hand, we hypothesise that network models,\nwhich capture only direct interactions, underfit higher-order patterns present\nin data. Consequently, both approaches are likely to misidentify influential\nnodes in complex networks. We contribute to this issue by proposing eight\ncentrality measures based on MOGen, a multi-order generative model that\naccounts for all paths up to a maximum distance but disregards paths at higher\ndistances. We compare MOGen-based centralities to equivalent measures for\nnetwork models and path data in a prediction experiment where we aim to\nidentify influential nodes in out-of-sample data. Our results show strong\nevidence supporting our hypothesis. MOGen consistently outperforms both the\nnetwork model and path-based prediction. We further show that the performance\ndifference between MOGen and the path-based approach disappears if we have\nsufficient observations, confirming that the error is due to overfitting.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 10:44:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gote", "Christoph", ""], ["Perri", "Vincenzo", ""], ["Scholtes", "Ingo", ""]]}, {"id": "2107.12248", "submitter": "Christian Henning", "authors": "Christian Henning, Francesco D'Angelo, Benjamin F. Grewe", "title": "Are Bayesian neural networks intrinsically good at out-of-distribution\n  detection?", "comments": "Published at UDL Workshop, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to avoid confident predictions on unfamiliar data has sparked\ninterest in out-of-distribution (OOD) detection. It is widely assumed that\nBayesian neural networks (BNN) are well suited for this task, as the endowed\nepistemic uncertainty should lead to disagreement in predictions on outliers.\nIn this paper, we question this assumption and provide empirical evidence that\nproper Bayesian inference with common neural network architectures does not\nnecessarily lead to good OOD detection. To circumvent the use of approximate\ninference, we start by studying the infinite-width case, where Bayesian\ninference can be exact considering the corresponding Gaussian process.\nStrikingly, the kernels induced under common architectural choices lead to\nuncertainties that do not reflect the underlying data generating process and\nare therefore unsuited for OOD detection. Finally, we study finite-width\nnetworks using HMC, and observe OOD behavior that is consistent with the\ninfinite-width case. Overall, our study discloses fundamental problems when\nnaively using BNNs for OOD detection and opens interesting avenues for future\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:53:14 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Henning", "Christian", ""], ["D'Angelo", "Francesco", ""], ["Grewe", "Benjamin F.", ""]]}, {"id": "2107.12250", "submitter": "Zhiliang Wu", "authors": "Zhiliang Wu, Yinchong Yang, Peter A. Fasching, Volker Tresp", "title": "Uncertainty-Aware Time-to-Event Prediction using Deep Kernel Accelerated\n  Failure Time Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network based solutions are increasingly being used in the\nanalysis of longitudinal Electronic Health Record data. However, most works\nfocus on prediction accuracy and neglect prediction uncertainty. We propose\nDeep Kernel Accelerated Failure Time models for the time-to-event prediction\ntask, enabling uncertainty-awareness of the prediction by a pipeline of a\nrecurrent neural network and a sparse Gaussian Process. Furthermore, a deep\nmetric learning based pre-training step is adapted to enhance the proposed\nmodel. Our model shows better point estimate performance than recurrent neural\nnetwork based baselines in experiments on two real-world datasets. More\nimportantly, the predictive variance from our model can be used to quantify the\nuncertainty estimates of the time-to-event prediction: Our model delivers\nbetter performance when it is more confident in its prediction. Compared to\nrelated methods, such as Monte Carlo Dropout, our model offers better\nuncertainty estimates by leveraging an analytical solution and is more\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:55:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wu", "Zhiliang", ""], ["Yang", "Yinchong", ""], ["Fasching", "Peter A.", ""], ["Tresp", "Volker", ""]]}, {"id": "2107.12364", "submitter": "Tudor Manole", "authors": "Tudor Manole, Sivaraman Balakrishnan, Jonathan Niles-Weed, Larry\n  Wasserman", "title": "Plugin Estimation of Smooth Optimal Transport Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a number of natural estimators for the optimal transport map\nbetween two distributions and show that they are minimax optimal. We adopt the\nplugin approach: our estimators are simply optimal couplings between measures\nderived from our observations, appropriately extended so that they define\nfunctions on $\\mathbb{R}^d$. When the underlying map is assumed to be\nLipschitz, we show that computing the optimal coupling between the empirical\nmeasures, and extending it using linear smoothers, already gives a minimax\noptimal estimator. When the underlying map enjoys higher regularity, we show\nthat the optimal coupling between appropriate nonparametric density estimates\nyields faster rates. Our work also provides new bounds on the risk of\ncorresponding plugin estimators for the quadratic Wasserstein distance, and we\nshow how this problem relates to that of estimating optimal transport maps\nusing stability arguments for smooth and strongly convex Brenier potentials. As\nan application of our results, we derive a central limit theorem for a density\nplugin estimator of the squared Wasserstein distance, which is centered at its\npopulation counterpart when the underlying distributions have sufficiently\nsmooth densities. In contrast to known central limit theorems for empirical\nestimators, this result easily lends itself to statistical inference for\nWasserstein distances.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:58:48 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Manole", "Tudor", ""], ["Balakrishnan", "Sivaraman", ""], ["Niles-Weed", "Jonathan", ""], ["Wasserman", "Larry", ""]]}, {"id": "2107.12365", "submitter": "Yuling Yan", "authors": "Yuling Yan, Yuxin Chen, Jianqing Fan", "title": "Inference for Heteroskedastic PCA with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to construct confidence regions for principal\ncomponent analysis (PCA) in high dimension, a problem that has been vastly\nunder-explored. While computing measures of uncertainty for nonlinear/nonconvex\nestimators is in general difficult in high dimension, the challenge is further\ncompounded by the prevalent presence of missing data and heteroskedastic noise.\nWe propose a suite of solutions to perform valid inference on the principal\nsubspace based on two estimators: a vanilla SVD-based approach, and a more\nrefined iterative scheme called $\\textsf{HeteroPCA}$ (Zhang et al., 2018). We\ndevelop non-asymptotic distributional guarantees for both estimators, and\ndemonstrate how these can be invoked to compute both confidence regions for the\nprincipal subspace and entrywise confidence intervals for the spiked covariance\nmatrix. Particularly worth highlighting is the inference procedure built on top\nof $\\textsf{HeteroPCA}$, which is not only valid but also statistically\nefficient for broader scenarios (e.g., it covers a wider range of missing rates\nand signal-to-noise ratios). Our solutions are fully data-driven and adaptive\nto heteroskedastic random noise, without requiring prior knowledge about the\nnoise levels and noise distributions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:59:01 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yan", "Yuling", ""], ["Chen", "Yuxin", ""], ["Fan", "Jianqing", ""]]}, {"id": "2107.12438", "submitter": "Michael Huang", "authors": "Vishal Gupta, Michael Huang, Paat Rusmevichientong", "title": "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the poor performance of cross-validation in settings where data\nare scarce, we propose a novel estimator of the out-of-sample performance of a\npolicy in data-driven optimization.Our approach exploits the optimization\nproblem's sensitivity analysis to estimate the gradient of the optimal\nobjective value with respect to the amount of noise in the data and uses the\nestimated gradient to debias the policy's in-sample performance. Unlike\ncross-validation techniques, our approach avoids sacrificing data for a test\nset, utilizes all data when training and, hence, is well-suited to settings\nwhere data are scarce. We prove bounds on the bias and variance of our\nestimator for optimization problems with uncertain linear objectives but known,\npotentially non-convex, feasible regions. For more specialized optimization\nproblems where the feasible region is \"weakly-coupled\" in a certain sense, we\nprove stronger results. Specifically, we provide explicit high-probability\nbounds on the error of our estimator that hold uniformly over a policy class\nand depends on the problem's dimension and policy class's complexity. Our\nbounds show that under mild conditions, the error of our estimator vanishes as\nthe dimension of the optimization problem grows, even if the amount of\navailable data remains small and constant. Said differently, we prove our\nestimator performs well in the small-data, large-scale regime. Finally, we\nnumerically compare our proposed method to state-of-the-art approaches through\na case-study on dispatching emergency medical response services using real\ndata. Our method provides more accurate estimates of out-of-sample performance\nand learns better-performing policies.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 19:00:51 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 15:39:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Gupta", "Vishal", ""], ["Huang", "Michael", ""], ["Rusmevichientong", "Paat", ""]]}, {"id": "2107.12521", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Restricted Boltzmann Machine and Deep Belief Network: Tutorial and\n  Survey", "comments": "To appear as a part of an upcoming textbook on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a tutorial and survey paper on Boltzmann Machine (BM), Restricted\nBoltzmann Machine (RBM), and Deep Belief Network (DBN). We start with the\nrequired background on probabilistic graphical models, Markov random field,\nGibbs sampling, statistical physics, Ising model, and the Hopfield network.\nThen, we introduce the structures of BM and RBM. The conditional distributions\nof visible and hidden variables, Gibbs sampling in RBM for generating\nvariables, training BM and RBM by maximum likelihood estimation, and\ncontrastive divergence are explained. Then, we discuss different possible\ndiscrete and continuous distributions for the variables. We introduce\nconditional RBM and how it is trained. Finally, we explain deep belief network\nas a stack of RBM models. This paper on Boltzmann machines can be useful in\nvarious fields including data science, statistics, neural computation, and\nstatistical physics.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 23:59:12 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2107.12525", "submitter": "Daniel Kang", "authors": "Daniel Kang, John Guibas, Peter Bailis, Tatsunori Hashimoto, Yi Sun,\n  Matei Zaharia", "title": "Proof: Accelerating Approximate Aggregation Queries with Expensive\n  Predicates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DB cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset $\\mathcal{D}$, we are interested in computing the mean of a\nsubset of $\\mathcal{D}$ which matches a predicate. ABae leverages stratified\nsampling and proxy models to efficiently compute this statistic given a\nsampling budget $N$. In this document, we theoretically analyze ABae and show\nthat the MSE of the estimate decays at rate $O(N_1^{-1} + N_2^{-1} +\nN_1^{1/2}N_2^{-3/2})$, where $N=K \\cdot N_1+N_2$ for some integer constant $K$\nand $K \\cdot N_1$ and $N_2$ represent the number of samples used in Stage 1 and\nStage 2 of ABae respectively. Hence, if a constant fraction of the total sample\nbudget $N$ is allocated to each stage, we will achieve a mean squared error of\n$O(N^{-1})$ which matches the rate of mean squared error of the optimal\nstratified sampling algorithm given a priori knowledge of the predicate\npositive rate and standard deviation per stratum.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 00:18:21 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 18:29:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kang", "Daniel", ""], ["Guibas", "John", ""], ["Bailis", "Peter", ""], ["Hashimoto", "Tatsunori", ""], ["Sun", "Yi", ""], ["Zaharia", "Matei", ""]]}, {"id": "2107.12580", "submitter": "Maithra Raghu", "authors": "Chiyuan Zhang, Maithra Raghu, Jon Kleinberg, Samy Bengio", "title": "Pointer Value Retrieval: A new benchmark for understanding the limits of\n  neural network generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successes of deep learning critically rely on the ability of neural\nnetworks to output meaningful predictions on unseen data -- generalization. Yet\ndespite its criticality, there remain fundamental open questions on how neural\nnetworks generalize. How much do neural networks rely on memorization -- seeing\nhighly similar training examples -- and how much are they capable of\nhuman-intelligence styled reasoning -- identifying abstract rules underlying\nthe data? In this paper we introduce a novel benchmark, Pointer Value Retrieval\n(PVR) tasks, that explore the limits of neural network generalization. While\nPVR tasks can consist of visual as well as symbolic inputs, each with varying\nlevels of difficulty, they all have a simple underlying rule. One part of the\nPVR task input acts as a pointer, giving the location of a different part of\nthe input, which forms the value (and output). We demonstrate that this task\nstructure provides a rich testbed for understanding generalization, with our\nempirical study showing large variations in neural network performance based on\ndataset size, task complexity and model architecture. The interaction of\nposition, values and the pointer rule also allow the development of nuanced\ntests of generalization, by introducing distribution shift and increasing\nfunctional complexity. These reveal both subtle failures and surprising\nsuccesses, suggesting many promising directions of exploration on this\nbenchmark.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 03:50:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Raghu", "Maithra", ""], ["Kleinberg", "Jon", ""], ["Bengio", "Samy", ""]]}, {"id": "2107.12685", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Csaba Szepesv\\'ari, Omar Rivasplata, Amal\n  Rannen-Triki, Razvan Pascanu", "title": "On the Role of Optimization in Double Descent: A Least Squares Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirically it has been observed that the performance of deep neural networks\nsteadily improves as we increase model size, contradicting the classical view\non overfitting and generalization. Recently, the double descent phenomena has\nbeen proposed to reconcile this observation with theory, suggesting that the\ntest error has a second descent when the model becomes sufficiently\noverparameterized, as the model size itself acts as an implicit regularizer. In\nthis paper we add to the growing body of work in this space, providing a\ncareful study of learning dynamics as a function of model size for the least\nsquares scenario. We show an excess risk bound for the gradient descent\nsolution of the least squares objective. The bound depends on the smallest\nnon-zero eigenvalue of the covariance matrix of the input features, via a\nfunctional form that has the double descent behavior. This gives a new\nperspective on the double descent curves reported in the literature. Our\nanalysis of the excess risk allows to decouple the effect of optimization and\ngeneralization error. In particular, we find that in case of noiseless\nregression, double descent is explained solely by optimization-related\nquantities, which was missed in studies focusing on the Moore-Penrose\npseudoinverse solution. We believe that our derivation provides an alternative\nview compared to existing work, shedding some light on a possible cause of this\nphenomena, at least in the considered least squares setting. We empirically\nexplore if our predictions hold for neural networks, in particular whether the\ncovariance of intermediary hidden activations has a similar behavior as the one\npredicted by our derivations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 09:13:11 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Rivasplata", "Omar", ""], ["Rannen-Triki", "Amal", ""], ["Pascanu", "Razvan", ""]]}, {"id": "2107.12723", "submitter": "Dominic Richards", "authors": "Dominic Richards, Ilja Kuzborskij", "title": "Stability & Generalisation of Gradient Descent for Shallow Neural\n  Networks without the Neural Tangent Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit on-average algorithmic stability of Gradient Descent (GD) for\ntraining overparameterised shallow neural networks and prove new generalisation\nand excess risk bounds without the Neural Tangent Kernel (NTK) or\nPolyak-{\\L}ojasiewicz (PL) assumptions. In particular, we show oracle type\nbounds which reveal that the generalisation and excess risk of GD is controlled\nby an interpolating network with the shortest GD path from initialisation (in a\nsense, an interpolating network with the smallest relative norm). While this\nwas known for kernelised interpolants, our proof applies directly to networks\ntrained by GD without intermediate kernelisation. At the same time, by relaxing\noracle inequalities developed here we recover existing NTK-based risk bounds in\na straightforward way, which demonstrates that our analysis is tighter.\nFinally, unlike most of the NTK-based analyses we focus on regression with\nlabel noise and show that GD with early stopping is consistent.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 10:53:15 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Richards", "Dominic", ""], ["Kuzborskij", "Ilja", ""]]}, {"id": "2107.12783", "submitter": "Drona Khurana", "authors": "Drona Khurana, Srinivasan Ravichandran, Sparsh Jain, Narayanan Unny\n  Edakunni", "title": "Statistical Guarantees for Fairness Aware Plug-In Algorithms", "comments": "This paper was accepted at the workshop on Socially Responsible\n  Machine Learning, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plug-in algorithm to estimate Bayes Optimal Classifiers for fairness-aware\nbinary classification has been proposed in (Menon & Williamson, 2018). However,\nthe statistical efficacy of their approach has not been established. We prove\nthat the plug-in algorithm is statistically consistent. We also derive finite\nsample guarantees associated with learning the Bayes Optimal Classifiers via\nthe plug-in algorithm. Finally, we propose a protocol that modifies the plug-in\napproach, so as to simultaneously guarantee fairness and differential privacy\nwith respect to a binary feature deemed sensitive.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 12:51:33 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Khurana", "Drona", ""], ["Ravichandran", "Srinivasan", ""], ["Jain", "Sparsh", ""], ["Edakunni", "Narayanan Unny", ""]]}, {"id": "2107.12797", "submitter": "Michael Kepler Jr", "authors": "Michael E. Kepler, Alec Koppel, Amrit Singh Bedi, and Daniel J.\n  Stilwell", "title": "Wasserstein-Splitting Gaussian Process Regression for Heterogeneous\n  Online Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian processes (GPs) are a well-known nonparametric Bayesian inference\ntechnique, but they suffer from scalability problems for large sample sizes,\nand their performance can degrade for non-stationary or spatially heterogeneous\ndata. In this work, we seek to overcome these issues through (i) employing\nvariational free energy approximations of GPs operating in tandem with online\nexpectation propagation steps; and (ii) introducing a local splitting step\nwhich instantiates a new GP whenever the posterior distribution changes\nsignificantly as quantified by the Wasserstein metric over posterior\ndistributions. Over time, then, this yields an ensemble of sparse GPs which may\nbe updated incrementally, and adapts to locality, heterogeneity, and\nnon-stationarity in training data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:52:46 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kepler", "Michael E.", ""], ["Koppel", "Alec", ""], ["Bedi", "Amrit Singh", ""], ["Stilwell", "Daniel J.", ""]]}, {"id": "2107.12825", "submitter": "Guillaume Ausset", "authors": "Guillaume Ausset, Tom Ciffreo, Francois Portier, Stephan\n  Cl\\'emen\\c{c}on, Timoth\\'ee Papin", "title": "Individual Survival Curves with Conditional Normalizing Flows", "comments": "IEEE DSAA '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Survival analysis, or time-to-event modelling, is a classical statistical\nproblem that has garnered a lot of interest for its practical use in\nepidemiology, demographics or actuarial sciences. Recent advances on the\nsubject from the point of view of machine learning have been concerned with\nprecise per-individual predictions instead of population studies, driven by the\nrise of individualized medicine. We introduce here a conditional normalizing\nflow based estimate of the time-to-event density as a way to model highly\nflexible and individualized conditional survival distributions. We use a novel\nhierarchical formulation of normalizing flows to enable efficient fitting of\nflexible conditional distributions without overfitting and show how the\nnormalizing flow formulation can be efficiently adapted to the censored\nsetting. We experimentally validate the proposed approach on a synthetic\ndataset as well as four open medical datasets and an example of a common\nfinancial problem.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:45:12 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ausset", "Guillaume", ""], ["Ciffreo", "Tom", ""], ["Portier", "Francois", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""], ["Papin", "Timoth\u00e9e", ""]]}, {"id": "2107.12890", "submitter": "Daniel Kowal", "authors": "Daniel R. Kowal", "title": "Subset selection for linear mixed models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linear mixed models (LMMs) are instrumental for regression analysis with\nstructured dependence, such as grouped, clustered, or multilevel data. However,\nselection among the covariates--while accounting for this structured\ndependence--remains a challenge. We introduce a Bayesian decision analysis for\nsubset selection with LMMs. Using a Mahalanobis loss function that incorporates\nthe structured dependence, we derive optimal linear actions for any subset of\ncovariates and under any Bayesian LMM. Crucially, these actions inherit\nshrinkage or regularization and uncertainty quantification from the underlying\nBayesian LMM. Rather than selecting a single \"best\" subset, which is often\nunstable and limited in its information content, we collect the acceptable\nfamily of subsets that nearly match the predictive ability of the \"best\"\nsubset. The acceptable family is summarized by its smallest member and key\nvariable importance metrics. Customized subset search and out-of-sample\napproximation algorithms are provided for more scalable computing. These tools\nare applied to simulated data and a longitudinal physical activity dataset, and\nin both cases demonstrate excellent prediction, estimation, and selection\nability.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 15:47:44 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kowal", "Daniel R.", ""]]}, {"id": "2107.12940", "submitter": "Mark Koren", "authors": "Mark Koren and Ahmed Nassar and Mykel J. Kochenderfer", "title": "Finding Failures in High-Fidelity Simulation using Adaptive Stress\n  Testing and the Backward Algorithm", "comments": "Accepted to IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Validating the safety of autonomous systems generally requires the use of\nhigh-fidelity simulators that adequately capture the variability of real-world\nscenarios. However, it is generally not feasible to exhaustively search the\nspace of simulation scenarios for failures. Adaptive stress testing (AST) is a\nmethod that uses reinforcement learning to find the most likely failure of a\nsystem. AST with a deep reinforcement learning solver has been shown to be\neffective in finding failures across a range of different systems. This\napproach generally involves running many simulations, which can be very\nexpensive when using a high-fidelity simulator. To improve efficiency, we\npresent a method that first finds failures in a low-fidelity simulator. It then\nuses the backward algorithm, which trains a deep neural network policy using a\nsingle expert demonstration, to adapt the low-fidelity failures to\nhigh-fidelity. We have created a series of autonomous vehicle validation case\nstudies that represent some of the ways low-fidelity and high-fidelity\nsimulators can differ, such as time discretization. We demonstrate in a variety\nof case studies that this new AST approach is able to find failures with\nsignificantly fewer high-fidelity simulation steps than are needed when just\nrunning AST directly in high-fidelity. As a proof of concept, we also\ndemonstrate AST on NVIDIA's DriveSim simulator, an industry state-of-the-art\nhigh-fidelity simulator for finding failures in autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:54:04 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Koren", "Mark", ""], ["Nassar", "Ahmed", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2107.12972", "submitter": "Sarath Shekkizhar", "authors": "David Bonet, Antonio Ortega, Javier Ruiz-Hidalgo, Sarath Shekkizhar", "title": "Channel-Wise Early Stopping without a Validation Set via NNK Polytope\n  Interpolation", "comments": "Submitted to APSIPA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural network architectures continue to scale in size and\ndeliver impressive generalization results, although this comes at the expense\nof limited interpretability. In particular, a key challenge is to determine\nwhen to stop training the model, as this has a significant impact on\ngeneralization. Convolutional neural networks (ConvNets) comprise\nhigh-dimensional feature spaces formed by the aggregation of multiple channels,\nwhere analyzing intermediate data representations and the model's evolution can\nbe challenging owing to the curse of dimensionality. We present channel-wise\nDeepNNK (CW-DeepNNK), a novel channel-wise generalization estimate based on\nnon-negative kernel regression (NNK) graphs with which we perform local\npolytope interpolation on low-dimensional channels. This method leads to\ninstance-based interpretability of both the learned data representations and\nthe relationship between channels. Motivated by our observations, we use\nCW-DeepNNK to propose a novel early stopping criterion that (i) does not\nrequire a validation set, (ii) is based on a task performance metric, and (iii)\nallows stopping to be reached at different points for each channel. Our\nexperiments demonstrate that our proposed method has advantages as compared to\nthe standard criterion based on validation set performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:33:30 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bonet", "David", ""], ["Ortega", "Antonio", ""], ["Ruiz-Hidalgo", "Javier", ""], ["Shekkizhar", "Sarath", ""]]}, {"id": "2107.13059", "submitter": "Yu Wang", "authors": "Yu Wang, Yuesong Shen, Daniel Cremers", "title": "Explicit Pairwise Factorized Graph Neural Network for Semi-Supervised\n  Node Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node features and structural information of a graph are both crucial for\nsemi-supervised node classification problems. A variety of graph neural network\n(GNN) based approaches have been proposed to tackle these problems, which\ntypically determine output labels through feature aggregation. This can be\nproblematic, as it implies conditional independence of output nodes given\nhidden representations, despite their direct connections in the graph. To learn\nthe direct influence among output nodes in a graph, we propose the Explicit\nPairwise Factorized Graph Neural Network (EPFGNN), which models the whole graph\nas a partially observed Markov Random Field. It contains explicit pairwise\nfactors to model output-output relations and uses a GNN backbone to model\ninput-output relations. To balance model complexity and expressivity, the\npairwise factors have a shared component and a separate scaling coefficient for\neach edge. We apply the EM algorithm to train our model, and utilize a\nstar-shaped piecewise likelihood for the tractable surrogate objective. We\nconduct experiments on various datasets, which shows that our model can\neffectively improve the performance for semi-supervised node classification on\ngraphs.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:47:53 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Yu", ""], ["Shen", "Yuesong", ""], ["Cremers", "Daniel", ""]]}, {"id": "2107.13068", "submitter": "Mohammad Taha Bahadori", "authors": "Mohammad Taha Bahadori and Eric Tchetgen Tchetgen and David E.\n  Heckerman", "title": "End-to-End Balancing for Causal Continuous Treatment-Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of observational causal inference with continuous\ntreatment. We focus on the challenge of estimating the causal response curve\nfor infrequently-observed treatment values. We design a new algorithm based on\nthe framework of entropy balancing which learns weights that directly maximize\ncausal inference accuracy using end-to-end optimization. Our weights can be\ncustomized for different datasets and causal inference algorithms. We propose a\nnew theory for consistency of entropy balancing for continuous treatments.\nUsing synthetic and real-world data, we show that our proposed algorithm\noutperforms the entropy balancing in terms of causal inference accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 20:04:59 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Bahadori", "Mohammad Taha", ""], ["Tchetgen", "Eric Tchetgen", ""], ["Heckerman", "David E.", ""]]}, {"id": "2107.13090", "submitter": "Renyuan Xu", "authors": "Ben Hambly, Renyuan Xu and Huining Yang", "title": "Policy Gradient Methods Find the Nash Equilibrium in N-player\n  General-sum Linear-quadratic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general-sum N-player linear-quadratic game with stochastic\ndynamics over a finite horizon and prove the global convergence of the natural\npolicy gradient method to the Nash equilibrium. In order to prove the\nconvergence of the method, we require a certain amount of noise in the system.\nWe give a condition, essentially a lower bound on the covariance of the noise\nin terms of the model parameters, in order to guarantee convergence. We\nillustrate our results with numerical experiments to show that even in\nsituations where the policy gradient method may not converge in the\ndeterministic setting, the addition of noise leads to convergence.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 22:08:41 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Hambly", "Ben", ""], ["Xu", "Renyuan", ""], ["Yang", "Huining", ""]]}, {"id": "2107.13163", "submitter": "Colin Wei", "authors": "Colin Wei, Yining Chen, Tengyu Ma", "title": "Statistically Meaningful Approximation: a Case Study on Approximating\n  Turing Machines with Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common lens to theoretically study neural net architectures is to analyze\nthe functions they can approximate. However, the constructions from\napproximation theory often have unrealistic aspects, for example, reliance on\ninfinite precision to memorize target function values, which make these results\npotentially less meaningful. To address these issues, this work proposes a\nformal definition of statistically meaningful approximation which requires the\napproximating network to exhibit good statistical learnability. We present case\nstudies on statistically meaningful approximation for two classes of functions:\nboolean circuits and Turing machines. We show that overparameterized\nfeedforward neural nets can statistically meaningfully approximate boolean\ncircuits with sample complexity depending only polynomially on the circuit\nsize, not the size of the approximating network. In addition, we show that\ntransformers can statistically meaningfully approximate Turing machines with\ncomputation time bounded by $T$, requiring sample complexity polynomial in the\nalphabet size, state space size, and $\\log (T)$. Our analysis introduces new\ntools for generalization bounds that provide much tighter sample complexity\nguarantees than the typical VC-dimension or norm-based bounds, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 04:28:55 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wei", "Colin", ""], ["Chen", "Yining", ""], ["Ma", "Tengyu", ""]]}, {"id": "2107.13304", "submitter": "Bang Xiang Yong", "authors": "Bang Xiang Yong, Tim Pearce, Alexandra Brintrup", "title": "Bayesian Autoencoders: Analysing and Fixing the Bernoulli likelihood for\n  Out-of-Distribution Detection", "comments": "Presented at the ICML 2020 Workshop on Uncertainty and Ro-bustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  After an autoencoder (AE) has learnt to reconstruct one dataset, it might be\nexpected that the likelihood on an out-of-distribution (OOD) input would be\nlow. This has been studied as an approach to detect OOD inputs. Recent work\nshowed this intuitive approach can fail for the dataset pairs FashionMNIST vs\nMNIST. This paper suggests this is due to the use of Bernoulli likelihood and\nanalyses why this is the case, proposing two fixes: 1) Compute the uncertainty\nof likelihood estimate by using a Bayesian version of the AE. 2) Use\nalternative distributions to model the likelihood.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:51:35 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Yong", "Bang Xiang", ""], ["Pearce", "Tim", ""], ["Brintrup", "Alexandra", ""]]}, {"id": "2107.13430", "submitter": "Kiheiji Nishida", "authors": "Kiheiji Nishida and Kanta Naito", "title": "Kernel Density Estimation by Stagewise Algorithm with a Simple\n  Dictionary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies kernel density estimation by stagewise minimization\nalgorithm with a simple dictionary on U-divergence. We randomly split an i.i.d.\nsample into the two disjoint sets, one to be used for constructing the kernels\nin the dictionary and the other for evaluating the estimator, and implement the\nalgorithm. The resulting estimator brings us data-adaptive weighting parameters\nand bandwidth matrices, and realizes a sparse representation of kernel density\nestimation. We present the non-asymptotic error bounds of our estimator and\nconfirm its performance by simulations compared with the direct plug-in\nbandwidth matrices and the reduced set density estimator.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:05:06 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Nishida", "Kiheiji", ""], ["Naito", "Kanta", ""]]}, {"id": "2107.13494", "submitter": "Ziv Goldfeld", "authors": "Ritwik Sadhu and Ziv Goldfeld and Kengo Kato", "title": "Limit Distribution Theory for the Smooth 1-Wasserstein Distance with\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The smooth 1-Wasserstein distance (SWD) $W_1^\\sigma$ was recently proposed as\na means to mitigate the curse of dimensionality in empirical approximation\nwhile preserving the Wasserstein structure. Indeed, SWD exhibits parametric\nconvergence rates and inherits the metric and topological structure of the\nclassic Wasserstein distance. Motivated by the above, this work conducts a\nthorough statistical study of the SWD, including a high-dimensional limit\ndistribution result for empirical $W_1^\\sigma$, bootstrap consistency,\nconcentration inequalities, and Berry-Esseen type bounds. The derived\nnondegenerate limit stands in sharp contrast with the classic empirical $W_1$,\nfor which a similar result is known only in the one-dimensional case. We also\nexplore asymptotics and characterize the limit distribution when the smoothing\nparameter $\\sigma$ is scaled with $n$, converging to $0$ at a sufficiently slow\nrate. The dimensionality of the sampled distribution enters empirical SWD\nconvergence bounds only through the prefactor (i.e., the constant). We provide\na sharp characterization of this prefactor's dependence on the smoothing\nparameter and the intrinsic dimension. This result is then used to derive new\nempirical convergence rates for classic $W_1$ in terms of the intrinsic\ndimension. As applications of the limit distribution theory, we study\ntwo-sample testing and minimum distance estimation (MDE) under $W_1^\\sigma$. We\nestablish asymptotic validity of SWD testing, while for MDE, we prove\nmeasurability, almost sure convergence, and limit distributions for optimal\nestimators and their corresponding $W_1^\\sigma$ error. Our results suggest that\nthe SWD is well suited for high-dimensional statistical learning and inference.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:02:24 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 13:39:02 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Sadhu", "Ritwik", ""], ["Goldfeld", "Ziv", ""], ["Kato", "Kengo", ""]]}, {"id": "2107.13610", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Pengfei He, Chenghui Li", "title": "Large sample spectral analysis of graph-based multi-manifold clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DG math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study statistical properties of graph-based algorithms for\nmulti-manifold clustering (MMC). In MMC the goal is to retrieve the\nmulti-manifold structure underlying a given Euclidean data set when this one is\nassumed to be obtained by sampling a distribution on a union of manifolds\n$\\mathcal{M} = \\mathcal{M}_1 \\cup\\dots \\cup \\mathcal{M}_N$ that may intersect\nwith each other and that may have different dimensions. We investigate\nsufficient conditions that similarity graphs on data sets must satisfy in order\nfor their corresponding graph Laplacians to capture the right geometric\ninformation to solve the MMC problem. Precisely, we provide high probability\nerror bounds for the spectral approximation of a tensorized Laplacian on\n$\\mathcal{M}$ with a suitable graph Laplacian built from the observations; the\nrecovered tensorized Laplacian contains all geometric information of all the\nindividual underlying manifolds. We provide an example of a family of\nsimilarity graphs, which we call annular proximity graphs with angle\nconstraints, satisfying these sufficient conditions. We contrast our family of\ngraphs with other constructions in the literature based on the alignment of\ntangent planes. Extensive numerical experiments expand the insights that our\ntheory provides on the MMC problem.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:39:12 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["He", "Pengfei", ""], ["Li", "Chenghui", ""]]}, {"id": "2107.13656", "submitter": "Gholamali Aminian", "authors": "Gholamali Aminian, Yuheng Bu, Laura Toni, Miguel R. D. Rodrigues and\n  Gregory Wornell", "title": "Characterizing the Generalization Error of Gibbs Algorithm with\n  Symmetrized KL information", "comments": "The first and second author have contributed equally to the paper.\n  This paper is accepted in the ICML-21 Workshop on Information-Theoretic\n  Methods for Rigorous, Responsible, and Reliable Machine Learning:\n  https://sites.google.com/view/itr3/schedule", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bounding the generalization error of a supervised learning algorithm is one\nof the most important problems in learning theory, and various approaches have\nbeen developed. However, existing bounds are often loose and lack of\nguarantees. As a result, they may fail to characterize the exact generalization\nability of a learning algorithm. Our main contribution is an exact\ncharacterization of the expected generalization error of the well-known Gibbs\nalgorithm in terms of symmetrized KL information between the input training\nsamples and the output hypothesis. Such a result can be applied to tighten\nexisting expected generalization error bound. Our analysis provides more\ninsight on the fundamental role the symmetrized KL information plays in\ncontrolling the generalization error of the Gibbs algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 22:20:34 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Aminian", "Gholamali", ""], ["Bu", "Yuheng", ""], ["Toni", "Laura", ""], ["Rodrigues", "Miguel R. D.", ""], ["Wornell", "Gregory", ""]]}, {"id": "2107.13721", "submitter": "Bayan Saparbayeva", "authors": "Zhengwu Zhang and Bayan Saparbayeva", "title": "Amplitude Mean of Functional Data on $\\mathbb{S}^2$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mainfold-valued functional data analysis (FDA) recently becomes an active\narea of research motivated by the raising availability of trajectories or\nlongitudinal data observed on non-linear manifolds. The challenges of analyzing\nsuch data comes from many aspects, including infinite dimensionality and\nnonlinearity, as well as time domain or phase variability. In this paper, we\nstudy the amplitude part of manifold-valued functions on $\\S^2$, which is\ninvariant to random time warping or re-parameterization of the function.\nUtilizing the nice geometry of $\\S^2$, we develop a set of efficient and\naccurate tools for temporal alignment of functions, geodesic and sample mean\ncalculation. At the heart of these tools, they rely on gradient descent\nalgorithms with carefully derived gradients. We show the advantages of these\nnewly developed tools over its competitors with extensive simulations and real\ndata, and demonstrate the importance of considering the amplitude part of\nfunctions instead of mixing it with phase variability in mainfold-valued FDA.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 03:11:26 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zhang", "Zhengwu", ""], ["Saparbayeva", "Bayan", ""]]}, {"id": "2107.13735", "submitter": "Yubin Lu", "authors": "Yubin Lu, Romit Maulik, Ting Gao, Felix Dietrich, Ioannis G.\n  Kevrekidis, Jinqiao Duan", "title": "Learning the temporal evolution of multivariate densities via\n  normalizing flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a method to learn probability distributions using\nsample path data from stochastic differential equations. Specifically, we\nconsider temporally evolving probability distributions (e.g., those produced by\nintegrating local or nonlocal Fokker-Planck equations). We analyze this\nevolution through machine learning assisted construction of a time-dependent\nmapping that takes a reference distribution (say, a Gaussian) to each and every\ninstance of our evolving distribution. If the reference distribution is the\ninitial condition of a Fokker-Planck equation, what we learn is the time-T map\nof the corresponding solution. Specifically, the learned map is a normalizing\nflow that deforms the support of the reference density to the support of each\nand every density snapshot in time. We demonstrate that this approach can learn\nsolutions to non-local Fokker-Planck equations, such as those arising in\nsystems driven by both Brownian and L\\'evy noise. We present examples with two-\nand three-dimensional, uni- and multimodal distributions to validate the\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 04:05:02 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lu", "Yubin", ""], ["Maulik", "Romit", ""], ["Gao", "Ting", ""], ["Dietrich", "Felix", ""], ["Kevrekidis", "Ioannis G.", ""], ["Duan", "Jinqiao", ""]]}, {"id": "2107.13772", "submitter": "Dorina Weichert", "authors": "Dorina Weichert, Alexander Kister", "title": "Bayesian Optimization for Min Max Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A solution that is only reliable under favourable conditions is hardly a safe\nsolution. Min Max Optimization is an approach that returns optima that are\nrobust against worst case conditions. We propose algorithms that perform Min\nMax Optimization in a setting where the function that should be optimized is\nnot known a priori and hence has to be learned by experiments. Therefore we\nextend the Bayesian Optimization setting, which is tailored to maximization\nproblems, to Min Max Optimization problems. While related work extends the two\nacquisition functions Expected Improvement and Gaussian Process Upper\nConfidence Bound; we extend the two acquisition functions Entropy Search and\nKnowledge Gradient. These acquisition functions are able to gain knowledge\nabout the optimum instead of just looking for points that are supposed to be\noptimal. In our evaluation we show that these acquisition functions allow for\nbetter solutions - converging faster to the optimum than the benchmark\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 06:49:34 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Weichert", "Dorina", ""], ["Kister", "Alexander", ""]]}, {"id": "2107.13944", "submitter": "Ashkan Bagheri Jeddi", "authors": "Ashkan B. Jeddi, Nariman L. Dehghani, Abdollah Shafieezadeh", "title": "Lyapunov-based uncertainty-aware safe reinforcement learning", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has shown a promising performance in learning\noptimal policies for a variety of sequential decision-making tasks. However, in\nmany real-world RL problems, besides optimizing the main objectives, the agent\nis expected to satisfy a certain level of safety (e.g., avoiding collisions in\nautonomous driving). While RL problems are commonly formalized as Markov\ndecision processes (MDPs), safety constraints are incorporated via constrained\nMarkov decision processes (CMDPs). Although recent advances in safe RL have\nenabled learning safe policies in CMDPs, these safety requirements should be\nsatisfied during both training and in the deployment process. Furthermore, it\nis shown that in memory-based and partially observable environments, these\nmethods fail to maintain safety over unseen out-of-distribution observations.\nTo address these limitations, we propose a Lyapunov-based uncertainty-aware\nsafe RL model. The introduced model adopts a Lyapunov function that converts\ntrajectory-based constraints to a set of local linear constraints. Furthermore,\nto ensure the safety of the agent in highly uncertain environments, an\nuncertainty quantification method is developed that enables identifying\nrisk-averse actions through estimating the probability of constraint\nviolations. Moreover, a Transformers model is integrated to provide the agent\nwith memory to process long time horizons of information via the self-attention\nmechanism. The proposed model is evaluated in grid-world navigation tasks where\nsafety is defined as avoiding static and dynamic obstacles in fully and\npartially observable environments. The results of these experiments show a\nsignificant improvement in the performance of the agent both in achieving\noptimality and satisfying safety constraints.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 13:08:15 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Jeddi", "Ashkan B.", ""], ["Dehghani", "Nariman L.", ""], ["Shafieezadeh", "Abdollah", ""]]}, {"id": "2107.14151", "submitter": "Aniruddha Rajendra Rao", "authors": "Aniruddha Rajendra Rao, Matthew Reimherr", "title": "Modern Non-Linear Function-on-Function Regression", "comments": "6 figures, 5 tables (including supplementary material), 16 pages\n  (including supplementary material). arXiv admin note: text overlap with\n  arXiv:2104.09371", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new class of non-linear function-on-function regression models\nfor functional data using neural networks. We propose a framework using a\nhidden layer consisting of continuous neurons, called a continuous hidden\nlayer, for functional response modeling and give two model fitting strategies,\nFunctional Direct Neural Network (FDNN) and Functional Basis Neural Network\n(FBNN). Both are designed explicitly to exploit the structure inherent in\nfunctional data and capture the complex relations existing between the\nfunctional predictors and the functional response. We fit these models by\nderiving functional gradients and implement regularization techniques for more\nparsimonious results. We demonstrate the power and flexibility of our proposed\nmethod in handling complex functional models through extensive simulation\nstudies as well as real data examples.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 16:19:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Rao", "Aniruddha Rajendra", ""], ["Reimherr", "Matthew", ""]]}, {"id": "2107.14203", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen, Tracy Cai, Matei Zaharia, James Zou", "title": "Did the Model Change? Efficiently Assessing Machine Learning API Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) prediction APIs are increasingly widely used. An ML API\ncan change over time due to model updates or retraining. This presents a key\nchallenge in the usage of the API because it is often not clear to the user if\nand how the ML model has changed. Model shifts can affect downstream\napplication performance and also create oversight issues (e.g. if consistency\nis desired). In this paper, we initiate a systematic investigation of ML API\nshifts. We first quantify the performance shifts from 2020 to 2021 of popular\nML APIs from Google, Microsoft, Amazon, and others on a variety of datasets. We\nidentified significant model shifts in 12 out of 36 cases we investigated.\nInterestingly, we found several datasets where the API's predictions became\nsignificantly worse over time. This motivated us to formulate the API shift\nassessment problem at a more fine-grained level as estimating how the API\nmodel's confusion matrix changes over time when the data distribution is\nconstant. Monitoring confusion matrix shifts using standard random sampling can\nrequire a large number of samples, which is expensive as each API call costs a\nfee. We propose a principled adaptive sampling algorithm, MASA, to efficiently\nestimate confusion matrix shifts. MASA can accurately estimate the confusion\nmatrix shifts in commercial ML APIs using up to 90% fewer samples compared to\nrandom sampling. This work establishes ML API shifts as an important problem to\nstudy and provides a cost-effective approach to monitor such shifts.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:41:53 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Lingjiao", ""], ["Cai", "Tracy", ""], ["Zaharia", "Matei", ""], ["Zou", "James", ""]]}, {"id": "2107.14226", "submitter": "Dj Strouse", "authors": "DJ Strouse, Kate Baumli, David Warde-Farley, Vlad Mnih, Steven Hansen", "title": "Learning more skills through optimistic exploration", "comments": "Steven Hansen and DJ Strouse contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised skill learning objectives (Gregor et al., 2016, Eysenbach et\nal., 2018) allow agents to learn rich repertoires of behavior in the absence of\nextrinsic rewards. They work by simultaneously training a policy to produce\ndistinguishable latent-conditioned trajectories, and a discriminator to\nevaluate distinguishability by trying to infer latents from trajectories. The\nhope is for the agent to explore and master the environment by encouraging each\nskill (latent) to reliably reach different states. However, an inherent\nexploration problem lingers: when a novel state is actually encountered, the\ndiscriminator will necessarily not have seen enough training data to produce\naccurate and confident skill classifications, leading to low intrinsic reward\nfor the agent and effective penalization of the sort of exploration needed to\nactually maximize the objective. To combat this inherent pessimism towards\nexploration, we derive an information gain auxiliary objective that involves\ntraining an ensemble of discriminators and rewarding the policy for their\ndisagreement. Our objective directly estimates the epistemic uncertainty that\ncomes from the discriminator not having seen enough training examples, thus\nproviding an intrinsic reward more tailored to the true objective compared to\npseudocount-based methods (Burda et al., 2019). We call this exploration bonus\ndiscriminator disagreement intrinsic reward, or DISDAIN. We demonstrate\nempirically that DISDAIN improves skill learning both in a tabular grid world\n(Four Rooms) and the 57 games of the Atari Suite (from pixels). Thus, we\nencourage researchers to treat pessimism with DISDAIN.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:58:04 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Strouse", "DJ", ""], ["Baumli", "Kate", ""], ["Warde-Farley", "David", ""], ["Mnih", "Vlad", ""], ["Hansen", "Steven", ""]]}]