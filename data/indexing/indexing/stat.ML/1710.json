[{"id": "1710.00002", "submitter": "Andrew Wagenmaker", "authors": "Andrew J. Wagenmaker, Brian E. Moore, Raj Rao Nadakuditi", "title": "Robust Photometric Stereo Using Learned Image and Gradient Dictionaries", "comments": "ICIP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photometric stereo is a method for estimating the normal vectors of an object\nfrom images of the object under varying lighting conditions. Motivated by\nseveral recent works that extend photometric stereo to more general objects and\nlighting conditions, we study a new robust approach to photometric stereo that\nutilizes dictionary learning. Specifically, we propose and analyze two\napproaches to adaptive dictionary regularization for the photometric stereo\nproblem. First, we propose an image preprocessing step that utilizes an\nadaptive dictionary learning model to remove noise and other non-idealities\nfrom the image dataset before estimating the normal vectors. We also propose an\nalternative model where we directly apply the adaptive dictionary\nregularization to the normal vectors themselves during estimation. We study the\npractical performance of both methods through extensive simulations, which\ndemonstrate the state-of-the-art performance of both methods in the presence of\nnoise.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 17:22:55 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Wagenmaker", "Andrew J.", ""], ["Moore", "Brian E.", ""], ["Nadakuditi", "Raj Rao", ""]]}, {"id": "1710.00017", "submitter": "Nicholas Lubbers", "authors": "Nicholas Lubbers, Justin S. Smith, Kipton Barros", "title": "Hierarchical modeling of molecular energies using a deep neural network", "comments": null, "journal-ref": null, "doi": "10.1063/1.5011181", "report-no": null, "categories": "stat.ML physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Hierarchically Interacting Particle Neural Network (HIP-NN)\nto model molecular properties from datasets of quantum calculations. Inspired\nby a many-body expansion, HIP-NN decomposes properties, such as energy, as a\nsum over hierarchical terms. These terms are generated from a neural network--a\ncomposition of many nonlinear transformations--acting on a representation of\nthe molecule. HIP-NN achieves state-of-the-art performance on a dataset of 131k\nground state organic molecules, and predicts energies with 0.26 kcal/mol mean\nabsolute error. With minimal tuning, our model is also competitive on a dataset\nof molecular dynamics trajectories. In addition to enabling accurate energy\npredictions, the hierarchical structure of HIP-NN helps to identify regions of\nmodel uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 18:12:29 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Lubbers", "Nicholas", ""], ["Smith", "Justin S.", ""], ["Barros", "Kipton", ""]]}, {"id": "1710.00018", "submitter": "Vladimir Pavlovic", "authors": "Cuong D. Tran and Ognjen Rudovic and Vladimir Pavlovic", "title": "Unsupervised Domain Adaptation with Copula Models", "comments": "IEEE International Workshop On Machine Learning for Signal Processing\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of unsupervised domain adaptation, where no labeled data\nfrom the target domain is provided during training time. To deal with the\npotential discrepancy between the source and target distributions, both in\nfeatures and labels, we exploit a copula-based regression framework. The\nbenefits of this approach are two-fold: (a) it allows us to model a broader\nrange of conditional predictive densities beyond the common exponential family,\n(b) we show how to leverage Sklar's theorem, the essence of the copula\nformulation relating the joint density to the copula dependency functions, to\nfind effective feature mappings that mitigate the domain mismatch. By\ntransforming the data to a copula domain, we show on a number of benchmark\ndatasets (including human emotion estimation), and using different regression\nmodels for prediction, that we can achieve a more robust and accurate\nestimation of target labels, compared to recently proposed feature\ntransformation (adaptation) methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 18:14:55 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Tran", "Cuong D.", ""], ["Rudovic", "Ognjen", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1710.00085", "submitter": "Niko Br\\\"ummer", "authors": "Niko Br\\\"ummer and Albert Swart", "title": "Language-depedent I-Vectors for LRE15", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard recipe for spoken language recognition is to apply a Gaussian\nback-end to i-vectors. This ignores the uncertainty in the i-vector extraction,\nwhich could be important especially for short utterances. A recent paper by\nCumani, Plchot and Fer proposes a solution to propagate that uncertainty into\nthe backend. We propose an alternative method of propagating the uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 20:43:24 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Br\u00fcmmer", "Niko", ""], ["Swart", "Albert", ""]]}, {"id": "1710.00095", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan and Avetik G. Karagulyan", "title": "User-friendly guarantees for the Langevin Monte Carlo with inaccurate\n  gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of sampling from a given probability\ndensity function that is known to be smooth and strongly log-concave. We\nanalyze several methods of approximate sampling based on discretizations of the\n(highly overdamped) Langevin diffusion and establish guarantees on its error\nmeasured in the Wasserstein-2 distance. Our guarantees improve or extend the\nstate-of-the-art results in three directions. First, we provide an upper bound\non the error of the first-order Langevin Monte Carlo (LMC) algorithm with\noptimized varying step-size. This result has the advantage of being horizon\nfree (we do not need to know in advance the target precision) and to improve by\na logarithmic factor the corresponding result for the constant step-size.\nSecond, we study the case where accurate evaluations of the gradient of the\nlog-density are unavailable, but one can have access to approximations of the\naforementioned gradient. In such a situation, we consider both deterministic\nand stochastic approximations of the gradient and provide an upper bound on the\nsampling error of the first-order LMC that quantifies the impact of the\ngradient evaluation inaccuracies. Third, we establish upper bounds for two\nversions of the second-order LMC, which leverage the Hessian of the\nlog-density. We nonasymptotic guarantees on the sampling error of these\nsecond-order LMCs. These guarantees reveal that the second-order LMC algorithms\nimprove on the first-order LMC in ill-conditioned settings.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 21:15:03 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 21:01:23 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 11:46:52 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Karagulyan", "Avetik G.", ""]]}, {"id": "1710.00109", "submitter": "Viraj Jayminkumar Shah", "authors": "Viraj Shah, Mohammadreza Soltani, Chinmay Hegde", "title": "Reconstruction from Periodic Nonlinearities, With Applications to HDR\n  Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing signals and images from periodic\nnonlinearities. For such problems, we design a measurement scheme that supports\nefficient reconstruction; moreover, our method can be adapted to extend to\ncompressive sensing-based signal and image acquisition systems. Our techniques\ncan be potentially useful for reducing the measurement complexity of high\ndynamic range (HDR) imaging systems, with little loss in reconstruction\nquality. Several numerical experiments on real data demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 22:07:35 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Shah", "Viraj", ""], ["Soltani", "Mohammadreza", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1710.00112", "submitter": "Sayed Hadi Hashemi", "authors": "Faraz Faghri, Sayed Hadi Hashemi, Mohammad Babaeizadeh, Mike A. Nalls,\n  Saurabh Sinha, Roy H. Campbell", "title": "Toward Scalable Machine Learning and Data Mining: the Bioinformatics\n  Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an effort to overcome the data deluge in computational biology and\nbioinformatics and to facilitate bioinformatics research in the era of big\ndata, we identify some of the most influential algorithms that have been widely\nused in the bioinformatics community. These top data mining and machine\nlearning algorithms cover classification, clustering, regression, graphical\nmodel-based learning, and dimensionality reduction. The goal of this study is\nto guide the focus of scalable computing experts in the endeavor of applying\nnew storage and scalable computation designs to bioinformatics algorithms that\nmerit their attention most, following the engineering maxim of \"optimize the\ncommon case\".\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 22:29:19 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Faghri", "Faraz", ""], ["Hashemi", "Sayed Hadi", ""], ["Babaeizadeh", "Mohammad", ""], ["Nalls", "Mike A.", ""], ["Sinha", "Saurabh", ""], ["Campbell", "Roy H.", ""]]}, {"id": "1710.00210", "submitter": "Herbert Weisberg", "authors": "Herbert Weisberg, Victor Pontes, and Mathis Thoma", "title": "Testing for Feature Relevance: The HARVEST Algorithm", "comments": "22 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection with high-dimensional data and a very small proportion of\nrelevant features poses a severe challenge to standard statistical methods. We\nhave developed a new approach (HARVEST) that is straightforward to apply,\nalbeit somewhat computer-intensive. This algorithm can be used to pre-screen a\nlarge number of features to identify those that are potentially useful. The\nbasic idea is to evaluate each feature in the context of many random subsets of\nother features. HARVEST is predicated on the assumption that an irrelevant\nfeature can add no real predictive value, regardless of which other features\nare included in the subset. Motivated by this idea, we have derived a simple\nstatistical test for feature relevance. Empirical analyses and simulations\nproduced so far indicate that the HARVEST algorithm is highly effective in\npredictive analytics, both in science and business.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 14:53:51 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 21:44:12 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Weisberg", "Herbert", ""], ["Pontes", "Victor", ""], ["Thoma", "Mathis", ""]]}, {"id": "1710.00211", "submitter": "Bing Yu", "authors": "Weinan E, Bing Yu", "title": "The Deep Ritz method: A deep learning-based numerical algorithm for\n  solving variational problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep learning based method, the Deep Ritz Method, for\nnumerically solving variational problems, particularly the ones that arise from\npartial differential equations. The Deep Ritz method is naturally nonlinear,\nnaturally adaptive and has the potential to work in rather high dimensions. The\nframework is quite simple and fits well with the stochastic gradient descent\nmethod used in deep learning. We illustrate the method on several problems\nincluding some eigenvalue problems.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 15:06:14 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["E", "Weinan", ""], ["Yu", "Bing", ""]]}, {"id": "1710.00230", "submitter": "Andrew Wagenmaker", "authors": "Andrew J. Wagenmaker, Brian E. Moore, Raj Rao Nadakuditi", "title": "Robust Surface Reconstruction from Gradients via Adaptive Dictionary\n  Regularization", "comments": "ICIP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel approach to robust surface reconstruction from\nphotometric stereo normal vector maps that is particularly well-suited for\nreconstructing surfaces from noisy gradients. Specifically, we propose an\nadaptive dictionary learning based approach that attempts to simultaneously\nintegrate the gradient fields while sparsely representing the spatial patches\nof the reconstructed surface in an adaptive dictionary domain. We show that our\nformulation learns the underlying structure of the surface, effectively acting\nas an adaptive regularizer that enforces a smoothness constraint on the\nreconstructed surface. Our method is general and may be coupled with many\nexisting approaches in the literature to improve the integrity of the\nreconstructed surfaces. We demonstrate the performance of our method on\nsynthetic data as well as real photometric stereo data and evaluate its\nrobustness to noise.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 17:23:10 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Wagenmaker", "Andrew J.", ""], ["Moore", "Brian E.", ""], ["Nadakuditi", "Raj Rao", ""]]}, {"id": "1710.00264", "submitter": "Samuel Hopkins", "authors": "Samuel B. Hopkins and David Steurer", "title": "Bayesian estimation from few samples: community detection and related\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient meta-algorithm for Bayesian estimation problems that\nis based on low-degree polynomials, semidefinite programming, and tensor\ndecomposition. The algorithm is inspired by recent lower bound constructions\nfor sum-of-squares and related to the method of moments. Our focus is on sample\ncomplexity bounds that are as tight as possible (up to additive lower-order\nterms) and often achieve statistical thresholds or conjectured computational\nthresholds.\n  Our algorithm recovers the best known bounds for community detection in the\nsparse stochastic block model, a widely-studied class of estimation problems\nfor community detection in graphs. We obtain the first recovery guarantees for\nthe mixed-membership stochastic block model (Airoldi et el.) in constant\naverage degree graphs---up to what we conjecture to be the computational\nthreshold for this model. We show that our algorithm exhibits a sharp\ncomputational threshold for the stochastic block model with multiple\ncommunities beyond the Kesten--Stigum bound---giving evidence that this task\nmay require exponential time.\n  The basic strategy of our algorithm is strikingly simple: we compute the\nbest-possible low-degree approximation for the moments of the posterior\ndistribution of the parameters and use a robust tensor decomposition algorithm\nto recover the parameters from these approximate posterior moments.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 21:58:34 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Hopkins", "Samuel B.", ""], ["Steurer", "David", ""]]}, {"id": "1710.00283", "submitter": "Ding Zhao", "authors": "Zhiyuan Huang, Yaohui Guo, Henry Lam, Ding Zhao", "title": "A Versatile Approach to Evaluating and Testing Automated Vehicles based\n  on Kernel Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation and validation of complicated control systems are crucial to\nguarantee usability and safety. Usually, failure happens in some very rarely\nencountered situations, but once triggered, the consequence is disastrous.\nAccelerated Evaluation is a methodology that efficiently tests those\nrarely-occurring yet critical failures via smartly-sampled test cases. The\ndistribution used in sampling is pivotal to the performance of the method, but\nbuilding a suitable distribution requires case-by-case analysis. This paper\nproposes a versatile approach for constructing sampling distribution using\nkernel method. The approach uses statistical learning tools to approximate the\ncritical event sets and constructs distributions based on the unique properties\nof Gaussian distributions. We applied the method to evaluate the automated\nvehicles. Numerical experiments show proposed approach can robustly identify\nthe rare failures and significantly reduce the evaluation time.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 03:36:21 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Huang", "Zhiyuan", ""], ["Guo", "Yaohui", ""], ["Lam", "Henry", ""], ["Zhao", "Ding", ""]]}, {"id": "1710.00387", "submitter": "Tomohiko Mizutani", "authors": "Tomohiko Mizutani and Mirai Tanaka", "title": "Efficient Preconditioning for Noisy Separable NMFs by Successive\n  Projection Based Low-Rank Approximations", "comments": "32 pages, 4 figures", "journal-ref": "Machine Learning, 107(4), pages 643-673, 2018", "doi": null, "report-no": null, "categories": "cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successive projection algorithm (SPA) can quickly solve a nonnegative\nmatrix factorization problem under a separability assumption. Even if noise is\nadded to the problem, SPA is robust as long as the perturbations caused by the\nnoise are small. In particular, robustness against noise should be high when\nhandling the problems arising from real applications. The preconditioner\nproposed by Gillis and Vavasis (2015) makes it possible to enhance the noise\nrobustness of SPA. Meanwhile, an additional computational cost is required. The\nconstruction of the preconditioner contains a step to compute the top-$k$\ntruncated singular value decomposition of an input matrix. It is known that the\ndecomposition provides the best rank-$k$ approximation to the input matrix; in\nother words, a matrix with the smallest approximation error among all matrices\nof rank less than $k$. This step is an obstacle to an efficient implementation\nof the preconditioned SPA.\n  To address the cost issue, we propose a modification of the algorithm for\nconstructing the preconditioner. Although the original algorithm uses the best\nrank-$k$ approximation, instead of it, our modification uses an alternative.\nIdeally, this alternative should have high approximation accuracy and low\ncomputational cost. To ensure this, our modification employs a rank-$k$\napproximation produced by an SPA based algorithm. We analyze the accuracy of\nthe approximation and evaluate the computational cost of the algorithm. We then\npresent an empirical study revealing the actual performance of the SPA based\nrank-$k$ approximation algorithm and the modified preconditioned SPA.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 18:20:57 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Mizutani", "Tomohiko", ""], ["Tanaka", "Mirai", ""]]}, {"id": "1710.00482", "submitter": "Hung-Hsuan Chen", "authors": "Hung-Hsuan Chen", "title": "Weighted-SVD: Matrix Factorization with Weights on the Latent Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Matrix Factorization models, sometimes called the latent factor models,\nare a family of methods in the recommender system research area to (1) generate\nthe latent factors for the users and the items and (2) predict users' ratings\non items based on their latent factors. However, current Matrix Factorization\nmodels presume that all the latent factors are equally weighted, which may not\nalways be a reasonable assumption in practice. In this paper, we propose a new\nmodel, called Weighted-SVD, to integrate the linear regression model with the\nSVD model such that each latent factor accompanies with a corresponding weight\nparameter. This mechanism allows the latent factors have different weights to\ninfluence the final ratings. The complexity of the Weighted-SVD model is\nslightly larger than the SVD model but much smaller than the SVD++ model. We\ncompared the Weighted-SVD model with several latent factor models on five\npublic datasets based on the Root-Mean-Squared-Errors (RMSEs). The results show\nthat the Weighted-SVD model outperforms the baseline methods in all the\nexperimental datasets under almost all settings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 04:56:09 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Chen", "Hung-Hsuan", ""]]}, {"id": "1710.00486", "submitter": "Divya Gopinath", "authors": "Divya Gopinath, Guy Katz, Corina S. Pasareanu, Clark Barrett", "title": "DeepSafe: A Data-driven Approach for Checking Adversarial Robustness in\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have become widely used, obtaining remarkable results in\ndomains such as computer vision, speech recognition, natural language\nprocessing, audio recognition, social network filtering, machine translation,\nand bio-informatics, where they have produced results comparable to human\nexperts. However, these networks can be easily fooled by adversarial\nperturbations: minimal changes to correctly-classified inputs, that cause the\nnetwork to mis-classify them. This phenomenon represents a concern for both\nsafety and security, but it is currently unclear how to measure a network's\nrobustness against such perturbations. Existing techniques are limited to\nchecking robustness around a few individual input points, providing only very\nlimited guarantees. We propose a novel approach for automatically identifying\nsafe regions of the input space, within which the network is robust against\nadversarial perturbations. The approach is data-guided, relying on clustering\nto identify well-defined geometric regions as candidate safe regions. We then\nutilize verification techniques to confirm that these regions are safe or to\nprovide counter-examples showing that they are not safe. We also introduce the\nnotion of targeted robustness which, for a given target label and region,\nensures that a NN does not map any input in the region to the target label. We\nevaluated our technique on the MNIST dataset and on a neural network\nimplementation of a controller for the next-generation Airborne Collision\nAvoidance System for unmanned aircraft (ACAS Xu). For these networks, our\napproach identified multiple regions which were completely safe as well as some\nwhich were only safe for specific labels. It also discovered several\nadversarial perturbations of interest.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 05:09:52 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:29:12 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Gopinath", "Divya", ""], ["Katz", "Guy", ""], ["Pasareanu", "Corina S.", ""], ["Barrett", "Clark", ""]]}, {"id": "1710.00499", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Fanny Yang, Martin J. Wainwright, Michael I. Jordan", "title": "Online control of the false discovery rate with decaying memory", "comments": "20 pages, 4 figures. Published in the proceedings of NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online multiple testing problem, p-values corresponding to different\nnull hypotheses are observed one by one, and the decision of whether or not to\nreject the current hypothesis must be made immediately, after which the next\np-value is observed. Alpha-investing algorithms to control the false discovery\nrate (FDR), formulated by Foster and Stine, have been generalized and applied\nto many settings, including quality-preserving databases in science and\nmultiple A/B or multi-armed bandit tests for internet commerce. This paper\nimproves the class of generalized alpha-investing algorithms (GAI) in four\nways: (a) we show how to uniformly improve the power of the entire class of\nmonotone GAI procedures by awarding more alpha-wealth for each rejection,\ngiving a win-win resolution to a recent dilemma raised by Javanmard and\nMontanari, (b) we demonstrate how to incorporate prior weights to indicate\ndomain knowledge of which hypotheses are likely to be non-null, (c) we allow\nfor differing penalties for false discoveries to indicate that some hypotheses\nmay be more important than others, (d) we define a new quantity called the\ndecaying memory false discovery rate (mem-FDR) that may be more meaningful for\ntruly temporal applications, and which alleviates problems that we describe and\nrefer to as \"piggybacking\" and \"alpha-death\". Our GAI++ algorithms incorporate\nall four generalizations simultaneously, and reduce to more powerful variants\nof earlier algorithms when the weights and decay are all set to unity. Finally,\nwe also describe a simple method to derive new online FDR rules based on an\nestimated false discovery proportion.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 06:13:37 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Yang", "Fanny", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1710.00569", "submitter": "Magda Gregorova", "authors": "Magda Gregorova, Alexandros Kalousis, Stephane Marchand-Maillet", "title": "Learning Predictive Leading Indicators for Forecasting Time Series\n  Systems with Unknown Clusters of Forecast Tasks", "comments": "Accepted for ACML2017; includes appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new method for forecasting systems of multiple interrelated time\nseries. The method learns the forecast models together with discovering leading\nindicators from within the system that serve as good predictors improving the\nforecast accuracy and a cluster structure of the predictive tasks around these.\nThe method is based on the classical linear vector autoregressive model (VAR)\nand links the discovery of the leading indicators to inferring sparse graphs of\nGranger causality. We formulate a new constrained optimisation problem to\npromote the desired sparse structures across the models and the sharing of\ninformation amongst the learning tasks in a multi-task manner. We propose an\nalgorithm for solving the problem and document on a battery of synthetic and\nreal-data experiments the advantages of our new method over baseline VAR models\nas well as the state-of-the-art sparse VAR learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 10:15:59 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Gregorova", "Magda", ""], ["Kalousis", "Alexandros", ""], ["Marchand-Maillet", "Stephane", ""]]}, {"id": "1710.00575", "submitter": "Pablo Morales-\\'Alvarez", "authors": "Pablo Morales-Alvarez and Adrian Perez-Suay and Rafael Molina and\n  Gustau Camps-Valls", "title": "Remote Sensing Image Classification with Large Scale Gaussian Processes", "comments": "11 pages, 6 figures, Accepted for publication in IEEE Transactions on\n  Geoscience and Remote Sensing; added the IEEE copyright statement", "journal-ref": null, "doi": "10.1109/TGRS.2017.2758922", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current remote sensing image classification problems have to deal with an\nunprecedented amount of heterogeneous and complex data sources. Upcoming\nmissions will soon provide large data streams that will make land cover/use\nclassification difficult. Machine learning classifiers can help at this, and\nmany methods are currently available. A popular kernel classifier is the\nGaussian process classifier (GPC), since it approaches the classification\nproblem with a solid probabilistic treatment, thus yielding confidence\nintervals for the predictions as well as very competitive results to\nstate-of-the-art neural networks and support vector machines. However, its\ncomputational cost is prohibitive for large scale applications, and constitutes\nthe main obstacle precluding wide adoption. This paper tackles this problem by\nintroducing two novel efficient methodologies for Gaussian Process (GP)\nclassification. We first include the standard random Fourier features\napproximation into GPC, which largely decreases its computational cost and\npermits large scale remote sensing image classification. In addition, we\npropose a model which avoids randomly sampling a number of Fourier frequencies,\nand alternatively learns the optimal ones within a variational Bayes approach.\nThe performance of the proposed methods is illustrated in complex problems of\ncloud detection from multispectral imagery and infrared sounding data.\nExcellent empirical results support the proposal in both computational cost and\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 10:51:47 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 10:40:11 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Morales-Alvarez", "Pablo", ""], ["Perez-Suay", "Adrian", ""], ["Molina", "Rafael", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "1710.00578", "submitter": "Jack Baker", "authors": "Jack Baker, Paul Fearnhead, Emily B. Fox, Christopher Nemeth", "title": "sgmcmc: An R Package for Stochastic Gradient Markov Chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the R package sgmcmc; which can be used for Bayesian\ninference on problems with large datasets using stochastic gradient Markov\nchain Monte Carlo (SGMCMC). Traditional Markov chain Monte Carlo (MCMC)\nmethods, such as Metropolis-Hastings, are known to run prohibitively slowly as\nthe dataset size increases. SGMCMC solves this issue by only using a subset of\ndata at each iteration. SGMCMC requires calculating gradients of the log\nlikelihood and log priors, which can be time consuming and error prone to\nperform by hand. The sgmcmc package calculates these gradients itself using\nautomatic differentiation, making the implementation of these methods much\neasier. To do this, the package uses the software library TensorFlow, which has\na variety of statistical distributions and mathematical operations as standard,\nmeaning a wide class of models can be built using this framework. SGMCMC has\nbecome widely adopted in the machine learning literature, but less so in the\nstatistics community. We believe this may be partly due to lack of software;\nthis package aims to bridge this gap.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 11:01:53 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 10:13:42 GMT"}, {"version": "v3", "created": "Fri, 13 Apr 2018 12:01:23 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Baker", "Jack", ""], ["Fearnhead", "Paul", ""], ["Fox", "Emily B.", ""], ["Nemeth", "Christopher", ""]]}, {"id": "1710.00598", "submitter": "Antonio Horta Ribeiro", "authors": "Ant\\^onio H. Ribeiro and Luis A. Aguirre", "title": "Lasso Regularization Paths for NARMAX Models via Coordinate Descent", "comments": "2018 American Control Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm for estimating NARMAX models with $L_1$\nregularization for models represented as a linear combination of basis\nfunctions. Due to the $L_1$-norm penalty the Lasso estimation tends to produce\nsome coefficients that are exactly zero and hence gives interpretable models.\nThe novelty of the contribution is the inclusion of error regressors in the\nLasso estimation (which yields a nonlinear regression problem). The proposed\nalgorithm uses cyclical coordinate descent to compute the parameters of the\nNARMAX models for the entire regularization path. It deals with the error terms\nby updating the regressor matrix along with the parameter vector. In\ncomparative timings we find that the modification does not reduce the\ncomputational efficiency of the original algorithm and can provide the most\nimportant regressors in very few inexpensive iterations. The method is\nillustrated for linear and polynomial models by means of two examples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 12:05:37 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 18:53:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Ribeiro", "Ant\u00f4nio H.", ""], ["Aguirre", "Luis A.", ""]]}, {"id": "1710.00629", "submitter": "Albert Vilamala", "authors": "Albert Vilamala, Kristoffer Hougaard Madsen and Lars Kai Hansen", "title": "Adaptive Smoothing in fMRI Data Processing Neural Networks", "comments": "4 pages, 3 figures, 1 table, IEEE 2017 International Workshop on\n  Pattern Recognition in Neuroimaging (PRNI)", "journal-ref": null, "doi": "10.1109/PRNI.2017.7981499", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional Magnetic Resonance Imaging (fMRI) relies on multi-step data\nprocessing pipelines to accurately determine brain activity; among them, the\ncrucial step of spatial smoothing. These pipelines are commonly suboptimal,\ngiven the local optimisation strategy they use, treating each step in\nisolation. With the advent of new tools for deep learning, recent work has\nproposed to turn these pipelines into end-to-end learning networks. This change\nof paradigm offers new avenues to improvement as it allows for a global\noptimisation. The current work aims at benefitting from this paradigm shift by\ndefining a smoothing step as a layer in these networks able to adaptively\nmodulate the degree of smoothing required by each brain volume to better\naccomplish a given data analysis task. The viability is evaluated on real fMRI\ndata where subjects did alternate between left and right finger tapping tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 13:29:27 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Vilamala", "Albert", ""], ["Madsen", "Kristoffer Hougaard", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1710.00633", "submitter": "Albert Vilamala", "authors": "Albert Vilamala, Kristoffer H. Madsen and Lars K. Hansen", "title": "Deep Convolutional Neural Networks for Interpretable Analysis of EEG\n  Sleep Stage Scoring", "comments": "8 pages, 1 figure, 2 tables, IEEE 2017 International Workshop on\n  Machine Learning for Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep studies are important for diagnosing sleep disorders such as insomnia,\nnarcolepsy or sleep apnea. They rely on manual scoring of sleep stages from raw\npolisomnography signals, which is a tedious visual task requiring the workload\nof highly trained professionals. Consequently, research efforts to purse for an\nautomatic stage scoring based on machine learning techniques have been carried\nout over the last years. In this work, we resort to multitaper spectral\nanalysis to create visually interpretable images of sleep patterns from EEG\nsignals as inputs to a deep convolutional network trained to solve visual\nrecognition tasks. As a working example of transfer learning, a system able to\naccurately classify sleep stages in new unseen patients is presented.\nEvaluations in a widely-used publicly available dataset favourably compare to\nstate-of-the-art results, while providing a framework for visual interpretation\nof outcomes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 13:36:29 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Vilamala", "Albert", ""], ["Madsen", "Kristoffer H.", ""], ["Hansen", "Lars K.", ""]]}, {"id": "1710.00725", "submitter": "Andrea Rocchetto", "authors": "Andrea Rocchetto, Edward Grant, Sergii Strelchuk, Giuseppe Carleo,\n  Simone Severini", "title": "Learning hard quantum distributions with variational autoencoders", "comments": "v2: 9 pages, 3 figures, journal version with major edits with respect\n  to v1 (rewriting of section \"hard and easy quantum states\", extended\n  discussion on comparison with tensor networks)", "journal-ref": "npj Quantum Information, Volume 4, Article number: 28 (2018)", "doi": "10.1038/s41534-018-0077-z", "report-no": null, "categories": "quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying general quantum many-body systems is one of the major challenges in\nmodern physics because it requires an amount of computational resources that\nscales exponentially with the size of the system.Simulating the evolution of a\nstate, or even storing its description, rapidly becomes intractable for exact\nclassical algorithms. Recently, machine learning techniques, in the form of\nrestricted Boltzmann machines, have been proposed as a way to efficiently\nrepresent certain quantum states with applications in state tomography and\nground state estimation. Here, we introduce a new representation of states\nbased on variational autoencoders. Variational autoencoders are a type of\ngenerative model in the form of a neural network. We probe the power of this\nrepresentation by encoding probability distributions associated with states\nfrom different classes. Our simulations show that deep networks give a better\nrepresentation for states that are hard to sample from, while providing no\nbenefit for random states. This suggests that the probability distributions\nassociated to hard quantum states might have a compositional structure that can\nbe exploited by layered neural networks. Specifically, we consider the\nlearnability of a class of quantum states introduced by Fefferman and Umans.\nSuch states are provably hard to sample for classical computers, but not for\nquantum ones, under plausible computational complexity assumptions. The good\nlevel of compression achieved for hard states suggests these methods can be\nsuitable for characterising states of the size expected in first generation\nquantum hardware.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 15:34:19 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 14:55:04 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Rocchetto", "Andrea", ""], ["Grant", "Edward", ""], ["Strelchuk", "Sergii", ""], ["Carleo", "Giuseppe", ""], ["Severini", "Simone", ""]]}, {"id": "1710.00811", "submitter": "Aaron Tuor", "authors": "Aaron Tuor, Samuel Kaplan, Brian Hutchinson, Nicole Nichols, Sean\n  Robinson", "title": "Deep Learning for Unsupervised Insider Threat Detection in Structured\n  Cybersecurity Data Streams", "comments": "Proceedings of AI for Cyber Security Workshop at AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of an organization's computer network activity is a key component of\nearly detection and mitigation of insider threat, a growing concern for many\norganizations. Raw system logs are a prototypical example of streaming data\nthat can quickly scale beyond the cognitive power of a human analyst. As a\nprospective filter for the human analyst, we present an online unsupervised\ndeep learning approach to detect anomalous network activity from system logs in\nreal time. Our models decompose anomaly scores into the contributions of\nindividual user behavior features for increased interpretability to aid\nanalysts reviewing potential cases of insider threat. Using the CERT Insider\nThreat Dataset v6.2 and threat detection recall as our performance metric, our\nnovel deep and recurrent neural network models outperform Principal Component\nAnalysis, Support Vector Machine and Isolation Forest based anomaly detection\nbaselines. For our best model, the events labeled as insider threat activity in\nour dataset had an average anomaly score in the 95.53 percentile, demonstrating\nour approach's potential to greatly reduce analyst workloads.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 17:54:28 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 20:53:03 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Tuor", "Aaron", ""], ["Kaplan", "Samuel", ""], ["Hutchinson", "Brian", ""], ["Nichols", "Nicole", ""], ["Robinson", "Sean", ""]]}, {"id": "1710.00889", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Jos\\'e Bento", "title": "How is Distributed ADMM Affected by Network Topology?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When solving consensus optimization problems over a graph, there is often an\nexplicit characterization of the convergence rate of Gradient Descent (GD)\nusing the spectrum of the graph Laplacian. The same type of problems under the\nAlternating Direction Method of Multipliers (ADMM) are, however, poorly\nunderstood. For instance, simple but important non-strongly-convex consensus\nproblems have not yet being analyzed, especially concerning the dependency of\nthe convergence rate on the graph topology. Recently, for a non-strongly-convex\nconsensus problem, a connection between distributed ADMM and lifted Markov\nchains was proposed, followed by a conjecture that ADMM is faster than GD by a\nsquare root factor in its convergence time, in close analogy to the mixing\nspeedup achieved by lifting several Markov chains. Nevertheless, a proof of\nsuch a claim is is still lacking. Here we provide a full characterization of\nthe convergence of distributed over-relaxed ADMM for the same type of consensus\nproblem in terms of the topology of the underlying graph. Our results provide\nexplicit formulas for optimal parameter selection in terms of the second\nlargest eigenvalue of the transition matrix of the graph's random walk. Another\nconsequence of our results is a proof of the aforementioned conjecture, which\ninterestingly, we show it is valid for any graph, even the ones whose random\nwalks cannot be accelerated via Markov chain lifting.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 20:11:25 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "1710.00904", "submitter": "Xuchao Zhang", "authors": "Xuchao Zhang, Liang Zhao, Arnold P. Boedihardjo, Chang-Tien Lu", "title": "Online and Distributed Robust Regressions under Adversarial Data\n  Corruption", "comments": "Accepted by ICDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's era of big data, robust least-squares regression becomes a more\nchallenging problem when considering the adversarial corruption along with\nexplosive growth of datasets. Traditional robust methods can handle the noise\nbut suffer from several challenges when applied in huge dataset including 1)\ncomputational infeasibility of handling an entire dataset at once, 2) existence\nof heterogeneously distributed corruption, and 3) difficulty in corruption\nestimation when data cannot be entirely loaded. This paper proposes online and\ndistributed robust regression approaches, both of which can concurrently\naddress all the above challenges. Specifically, the distributed algorithm\noptimizes the regression coefficients of each data block via heuristic hard\nthresholding and combines all the estimates in a distributed robust\nconsolidation. Furthermore, an online version of the distributed algorithm is\nproposed to incrementally update the existing estimates with new incoming data.\nWe also prove that our algorithms benefit from strong robustness guarantees in\nterms of regression coefficient recovery with a constant upper bound on the\nerror of state-of-the-art batch methods. Extensive experiments on synthetic and\nreal datasets demonstrate that our approaches are superior to those of existing\nmethods in effectiveness, with competitive efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 20:55:39 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Zhang", "Xuchao", ""], ["Zhao", "Liang", ""], ["Boedihardjo", "Arnold P.", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1710.00956", "submitter": "Soledad Villar", "authors": "Dustin G. Mixon and Soledad Villar", "title": "Monte Carlo approximation certificates for k-means clustering", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient algorithms for $k$-means clustering frequently converge to\nsuboptimal partitions, and given a partition, it is difficult to detect\n$k$-means optimality. In this paper, we develop an a posteriori certifier of\napproximate optimality for $k$-means clustering. The certifier is a sub-linear\nMonte Carlo algorithm based on Peng and Wei's semidefinite relaxation of\n$k$-means. In particular, solving the relaxation for small random samples of\nthe dataset produces a high-confidence lower bound on the $k$-means objective,\nand being sub-linear, our algorithm is faster than $k$-means++ when the number\nof data points is large. We illustrate the performance of our algorithm with\nboth numerical experiments and a performance guarantee: If the data points are\ndrawn independently from any mixture of two Gaussians over $\\mathbb{R}^m$ with\nidentity covariance, then with probability $1-O(1/m)$, our\n$\\operatorname{poly}(m)$-time algorithm produces a 3-approximation certificate\nwith 99% confidence.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 02:02:17 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Mixon", "Dustin G.", ""], ["Villar", "Soledad", ""]]}, {"id": "1710.00977", "submitter": "Naimish Agarwal", "authors": "Naimish Agarwal, Artus Krohn-Grimberghe, Ranjana Vyas", "title": "Facial Key Points Detection using Deep Convolutional Neural Network -\n  NaimishNet", "comments": "7 pages, 21 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial Key Points (FKPs) Detection is an important and challenging problem in\nthe fields of computer vision and machine learning. It involves predicting the\nco-ordinates of the FKPs, e.g. nose tip, center of eyes, etc, for a given face.\nIn this paper, we propose a LeNet adapted Deep CNN model - NaimishNet, to\noperate on facial key points data and compare our model's performance against\nexisting state of the art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 04:23:08 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Agarwal", "Naimish", ""], ["Krohn-Grimberghe", "Artus", ""], ["Vyas", "Ranjana", ""]]}, {"id": "1710.01013", "submitter": "Emanuele Sansone", "authors": "Emanuele Sansone, Francesco G.B. De Natale", "title": "Training Feedforward Neural Networks with Standard Logistic Activations\n  is Feasible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training feedforward neural networks with standard logistic activations is\nconsidered difficult because of the intrinsic properties of these sigmoidal\nfunctions. This work aims at showing that these networks can be trained to\nachieve generalization performance comparable to those based on hyperbolic\ntangent activations. The solution consists on applying a set of conditions in\nparameter initialization, which have been derived from the study of the\nproperties of a single neuron from an information-theoretic perspective. The\nproposed initialization is validated through an extensive experimental\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 07:21:03 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Sansone", "Emanuele", ""], ["De Natale", "Francesco G. B.", ""]]}, {"id": "1710.01163", "submitter": "Kinjal Basu", "authors": "Kinjal Basu, Ankan Saha, Shaunak Chatterjee", "title": "Large-Scale Quadratically Constrained Quadratic Program via\n  Low-Discrepancy Sequences", "comments": "Accepted at NIPS 2017. arXiv admin note: substantial text overlap\n  with arXiv:1602.04391", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of solving a large-scale Quadratically Constrained\nQuadratic Program. Such problems occur naturally in many scientific and web\napplications. Although there are efficient methods which tackle this problem,\nthey are mostly not scalable. In this paper, we develop a method that\ntransforms the quadratic constraint into a linear form by sampling a set of\nlow-discrepancy points. The transformed problem can then be solved by applying\nany state-of-the-art large-scale quadratic programming solvers. We show the\nconvergence of our approximate solution to the true solution as well as some\nfinite sample error bounds. Experimental results are also shown to prove\nscalability as well as improved quality of approximation in practice.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 02:38:37 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Basu", "Kinjal", ""], ["Saha", "Ankan", ""], ["Chatterjee", "Shaunak", ""]]}, {"id": "1710.01167", "submitter": "Julian Katz-Samuels", "authors": "Julian Katz-Samuels, Gilles Blanchard, and Clayton Scott", "title": "Decontamination of Mutual Contamination Models", "comments": "Published in JMLR. Subsumes arXiv:1602.06235", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems can be characterized by mutual contamination\nmodels. In these problems, one observes several random samples from different\nconvex combinations of a set of unknown base distributions and the goal is to\ninfer these base distributions. This paper considers the general setting where\nthe base distributions are defined on arbitrary probability spaces. We examine\nthree popular machine learning problems that arise in this general setting:\nmulticlass classification with label noise, demixing of mixed membership\nmodels, and classification with partial labels. In each case, we give\nsufficient conditions for identifiability and present algorithms for the\ninfinite and finite sample settings, with associated performance guarantees.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 17:10:02 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 15:34:16 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Katz-Samuels", "Julian", ""], ["Blanchard", "Gilles", ""], ["Scott", "Clayton", ""]]}, {"id": "1710.01278", "submitter": "Ankit Gupta", "authors": "Ankit Gupta, Alexander M. Rush", "title": "Dilated Convolutions for Modeling Long-Distance Genomic Dependencies", "comments": "Presented at the ICML Workshop on Computational Biology in Sydney,\n  Australia in August 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of detecting regulatory elements in the human genome\ndirectly from raw DNA. Past work has focused on small snippets of DNA, making\nit difficult to model long-distance dependencies that arise from DNA's\n3-dimensional conformation. In order to study long-distance dependencies, we\ndevelop and release a novel dataset for a larger-context modeling task. Using\nthis new data set we model long-distance interactions using dilated\nconvolutional neural networks, and compare them to standard convolutions and\nrecurrent neural networks. We show that dilated convolutions are effective at\nmodeling the locations of regulatory markers in the human genome, such as\ntranscription factor binding sites, histone modifications, and DNAse\nhypersensitivity sites.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 17:21:15 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Gupta", "Ankit", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1710.01406", "submitter": "Jeremiah Zhe Liu", "authors": "Jeremiah Zhe Liu, Brent Coull", "title": "Robust Hypothesis Test for Nonlinear Effect with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work constructs a hypothesis test for detecting whether an\ndata-generating function $h: R^p \\rightarrow R$ belongs to a specific\nreproducing kernel Hilbert space $\\mathcal{H}_0$ , where the structure of\n$\\mathcal{H}_0$ is only partially known. Utilizing the theory of reproducing\nkernels, we reduce this hypothesis to a simple one-sided score test for a\nscalar parameter, develop a testing procedure that is robust against the\nmis-specification of kernel functions, and also propose an ensemble-based\nestimator for the null model to guarantee test performance in small samples. To\ndemonstrate the utility of the proposed method, we apply our test to the\nproblem of detecting nonlinear interaction between groups of continuous\nfeatures. We evaluate the finite-sample performance of our test under different\ndata-generating functions and estimation strategies for the null model. Our\nresults reveal interesting connections between notions in machine learning\n(model underfit/overfit) and those in statistical inference (i.e. Type I\nerror/power of hypothesis test), and also highlight unexpected consequences of\ncommon model estimating strategies (e.g. estimating kernel hyperparameters\nusing maximum likelihood estimation) on model inference.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 22:24:32 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 21:28:26 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Liu", "Jeremiah Zhe", ""], ["Coull", "Brent", ""]]}, {"id": "1710.01408", "submitter": "Mohammed Yousefhussien", "authors": "Mohammed Yousefhussien, David J. Kelbe, Emmett J. Ientilucci and Carl\n  Salvaggio", "title": "A Fully Convolutional Network for Semantic Labeling of 3D Point Clouds", "comments": null, "journal-ref": "ISPRS Journal of Photogrammetry and Remote Sensing, 2018", "doi": "10.1016/j.isprsjprs.2018.03.018", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When classifying point clouds, a large amount of time is devoted to the\nprocess of engineering a reliable set of features which are then passed to a\nclassifier of choice. Generally, such features - usually derived from the\n3D-covariance matrix - are computed using the surrounding neighborhood of\npoints. While these features capture local information, the process is usually\ntime-consuming, and requires the application at multiple scales combined with\ncontextual methods in order to adequately describe the diversity of objects\nwithin a scene. In this paper we present a 1D-fully convolutional network that\nconsumes terrain-normalized points directly with the corresponding spectral\ndata,if available, to generate point-wise labeling while implicitly learning\ncontextual features in an end-to-end fashion. Our method uses only the\n3D-coordinates and three corresponding spectral features for each point.\nSpectral features may either be extracted from 2D-georeferenced images, as\nshown here for Light Detection and Ranging (LiDAR) point clouds, or extracted\ndirectly for passive-derived point clouds,i.e. from muliple-view imagery. We\ntrain our network by splitting the data into square regions, and use a pooling\nlayer that respects the permutation-invariance of the input points. Evaluated\nusing the ISPRS 3D Semantic Labeling Contest, our method scored second place\nwith an overall accuracy of 81.6%. We ranked third place with a mean F1-score\nof 63.32%, surpassing the F1-score of the method with highest accuracy by\n1.69%. In addition to labeling 3D-point clouds, we also show that our method\ncan be easily extended to 2D-semantic segmentation tasks, with promising\ninitial results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 22:35:25 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Yousefhussien", "Mohammed", ""], ["Kelbe", "David J.", ""], ["Ientilucci", "Emmett J.", ""], ["Salvaggio", "Carl", ""]]}, {"id": "1710.01410", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Lawrence Carin, Hongyuan Zha", "title": "Learning Registered Point Processes from Idiosyncratic Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parametric point process model is developed, with modeling based on the\nassumption that sequential observations often share latent phenomena, while\nalso possessing idiosyncratic effects. An alternating optimization method is\nproposed to learn a \"registered\" point process that accounts for shared\nstructure, as well as \"warping\" functions that characterize idiosyncratic\naspects of each observed sequence. Under reasonable constraints, in each\niteration we update the sample-specific warping functions by solving a set of\nconstrained nonlinear programming problems in parallel, and update the model by\nmaximum likelihood estimation. The justifiability, complexity and robustness of\nthe proposed method are investigated in detail, and the influence of sequence\nstitching on the learning results is examined empirically. Experiments on both\nsynthetic and real-world data demonstrate that the method yields explainable\npoint process models, achieving encouraging results compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 22:39:22 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 20:12:24 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 16:24:28 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Xu", "Hongteng", ""], ["Carin", "Lawrence", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1710.01416", "submitter": "Saed Khawaldeh", "authors": "Vu Hoang Minh, Tajwar Abrar Aleef, Usama Pervaiz, Yeman Brhane Hagos,\n  Saed Khawaldeh", "title": "Smoothness-based Edge Detection using Low-SNR Camera for Robot\n  Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the emerging advancement in the branch of autonomous robotics, the ability\nof a robot to efficiently localize and construct maps of its surrounding is\ncrucial. This paper deals with utilizing thermal-infrared cameras, as opposed\nto conventional cameras as the primary sensor to capture images of the robot's\nsurroundings. For localization, the images need to be further processed before\nfeeding them to a navigational system. The main motivation of this paper was to\ndevelop an edge detection methodology capable of utilizing the low-SNR poor\noutput from such a thermal camera and effectively detect smooth edges of the\nsurrounding environment. The enhanced edge detector proposed in this paper\ntakes the raw image from the thermal sensor, denoises the images, applies Canny\nedge detection followed by CSS method. The edges are ranked to remove any noise\nand only edges of the highest rank are kept. Then, the broken edges are linked\nby computing edge metrics and a smooth edge of the surrounding is displayed in\na binary image. Several comparisons are also made in the paper between the\nproposed technique and the existing techniques.\n", "versions": [{"version": "v1", "created": "Tue, 3 Oct 2017 22:48:41 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Minh", "Vu Hoang", ""], ["Aleef", "Tajwar Abrar", ""], ["Pervaiz", "Usama", ""], ["Hagos", "Yeman Brhane", ""], ["Khawaldeh", "Saed", ""]]}, {"id": "1710.01437", "submitter": "Elina Robeva Massachusetts Institute of Technology", "authors": "Elina Robeva and Anna Seigal", "title": "Duality of Graphical Models and Tensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI quant-ph stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we show the duality between tensor networks and undirected\ngraphical models with discrete variables. We study tensor networks on\nhypergraphs, which we call tensor hypernetworks. We show that the tensor\nhypernetwork on a hypergraph exactly corresponds to the graphical model given\nby the dual hypergraph. We translate various notions under duality. For\nexample, marginalization in a graphical model is dual to contraction in the\ntensor network. Algorithms also translate under duality. We show that belief\npropagation corresponds to a known algorithm for tensor network contraction.\nThis article is a reminder that the research areas of graphical models and\ntensor networks can benefit from interaction.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 01:55:05 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Robeva", "Elina", ""], ["Seigal", "Anna", ""]]}, {"id": "1710.01467", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Mechanisms of dimensionality reduction and decorrelation in deep neural\n  networks", "comments": "11 pages, 5 figures, a physics explanation of decorrelation and\n  dimensionality reduction is added; to be published by Phys Rev E (2018)", "journal-ref": "Phys. Rev. E 98, 062313 (2018)", "doi": "10.1103/PhysRevE.98.062313", "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used in various domains. However, the nature\nof computations at each layer of the deep networks is far from being well\nunderstood. Increasing the interpretability of deep neural networks is thus\nimportant. Here, we construct a mean-field framework to understand how compact\nrepresentations are developed across layers, not only in deterministic deep\nnetworks with random weights but also in generative deep networks where an\nunsupervised learning is carried out. Our theory shows that the deep\ncomputation implements a dimensionality reduction while maintaining a finite\nlevel of weak correlations between neurons for possible feature extraction.\nMechanisms of dimensionality reduction and decorrelation are unified in the\nsame framework. This work may pave the way for understanding how a sensory\nhierarchy works.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 05:38:50 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 04:59:06 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 02:52:24 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1710.01490", "submitter": "Mohamed Laib", "authors": "Mohamed Laib, Jean Golay, Luciano Telesca, Mikhail Kanevski", "title": "Multifractal analysis of the time series of daily means of wind speed in\n  complex regions", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2018.02.024", "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we applied the multifractal detrended fluctuation analysis to\nthe daily means of wind speed measured by 119 weather stations distributed over\nthe territory of Switzerland. The analysis was focused on the inner time\nfluctuations of wind speed, which could be more linked with the local\nconditions of the highly varying topography of Switzerland. Our findings point\nout to a persistent behaviour of all the measured wind speed series (indicated\nby a Hurst exponent significantly larger than 0.5), and to a high\nmultifractality degree indicating a relative dominance of the large\nfluctuations in the dynamics of wind speed, especially in the Swiss plateau,\nwhich is comprised between the Jura and Alp mountain ranges. The study\nrepresents a contribution to the understanding of the dynamical mechanisms of\nwind speed variability in mountainous regions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 07:46:53 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Laib", "Mohamed", ""], ["Golay", "Jean", ""], ["Telesca", "Luciano", ""], ["Kanevski", "Mikhail", ""]]}, {"id": "1710.01494", "submitter": "Klemen Grm", "authors": "Klemen Grm, Vitomir \\v{S}truc, Anais Artiges, Matthieu Caron, Hazim\n  Kemal Ekenel", "title": "Strengths and Weaknesses of Deep Learning Models for Face Recognition\n  Against Image Degradations", "comments": null, "journal-ref": null, "doi": "10.1049/iet-bmt.2017.0083", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) based approaches are the\nstate-of-the-art in various computer vision tasks, including face recognition.\nConsiderable research effort is currently being directed towards further\nimproving deep CNNs by focusing on more powerful model architectures and better\nlearning techniques. However, studies systematically exploring the strengths\nand weaknesses of existing deep models for face recognition are still\nrelatively scarce in the literature. In this paper, we try to fill this gap and\nstudy the effects of different covariates on the verification performance of\nfour recent deep CNN models using the Labeled Faces in the Wild (LFW) dataset.\nSpecifically, we investigate the influence of covariates related to: image\nquality -- blur, JPEG compression, occlusion, noise, image brightness,\ncontrast, missing pixels; and model characteristics -- CNN architecture, color\ninformation, descriptor computation; and analyze their impact on the face\nverification performance of AlexNet, VGG-Face, GoogLeNet, and SqueezeNet. Based\non comprehensive and rigorous experimentation, we identify the strengths and\nweaknesses of the deep learning models, and present key areas for potential\nfuture research. Our results indicate that high levels of noise, blur, missing\npixels, and brightness have a detrimental effect on the verification\nperformance of all models, whereas the impact of contrast changes and\ncompression artifacts is limited. It has been found that the descriptor\ncomputation strategy and color information does not have a significant\ninfluence on performance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 08:03:41 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Grm", "Klemen", ""], ["\u0160truc", "Vitomir", ""], ["Artiges", "Anais", ""], ["Caron", "Matthieu", ""], ["Ekenel", "Hazim Kemal", ""]]}, {"id": "1710.01592", "submitter": "Pan Zhang", "authors": "Pan Zhang", "title": "Spectral estimation of the percolation transition in clustered networks", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.96.042303", "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been several spectral bounds for the percolation transition in\nnetworks, using spectrum of matrices associated with the network such as the\nadjacency matrix and the non-backtracking matrix. However they are far from\nbeing tight when the network is sparse and displays clustering or transitivity,\nwhich is represented by existence of short loops e.g. triangles. In this work,\nfor the bond percolation, we first propose a message passing algorithm for\ncalculating size of percolating clusters considering effects of triangles, then\nrelate the percolation transition to the leading eigenvalue of a matrix that we\nname the triangle-non-backtracking matrix, by analyzing stability of the\nmessage passing equations. We establish that our method gives a tighter\nlower-bound to the bond percolation transition than previous spectral bounds,\nand it becomes exact for an infinite network with no loops longer than 3. We\nevaluate numerically our methods on synthetic and real-world networks, and\ndiscuss further generalizations of our approach to include higher-order\nsub-structures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 13:25:41 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Zhang", "Pan", ""]]}, {"id": "1710.01614", "submitter": "Zhiguo Zhou", "authors": "Zhiguo Zhou, Zhi-Jie Zhou, Hongxia Hao, Shulong Li, Xi Chen, You\n  Zhang, Michael Folkert, and Jing Wang", "title": "Constructing multi-modality and multi-classifier radiomics predictive\n  models through reliable classifier fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiomics aims to extract and analyze large numbers of quantitative features\nfrom medical images and is highly promising in staging, diagnosing, and\npredicting outcomes of cancer treatments. Nevertheless, several challenges need\nto be addressed to construct an optimal radiomics predictive model. First, the\npredictive performance of the model may be reduced when features extracted from\nan individual imaging modality are blindly combined into a single predictive\nmodel. Second, because many different types of classifiers are available to\nconstruct a predictive model, selecting an optimal classifier for a particular\napplication is still challenging. In this work, we developed multi-modality and\nmulti-classifier radiomics predictive models that address the aforementioned\nissues in currently available models. Specifically, a new reliable classifier\nfusion strategy was proposed to optimally combine output from different\nmodalities and classifiers. In this strategy, modality-specific classifiers\nwere first trained, and an analytic evidential reasoning (ER) rule was\ndeveloped to fuse the output score from each modality to construct an optimal\npredictive model. One public data set and two clinical case studies were\nperformed to validate model performance. The experimental results indicated\nthat the proposed ER rule based radiomics models outperformed the traditional\nmodels that rely on a single classifier or simply use combined features from\ndifferent modalities.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 14:23:04 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 20:52:35 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Zhou", "Zhiguo", ""], ["Zhou", "Zhi-Jie", ""], ["Hao", "Hongxia", ""], ["Li", "Shulong", ""], ["Chen", "Xi", ""], ["Zhang", "You", ""], ["Folkert", "Michael", ""], ["Wang", "Jing", ""]]}, {"id": "1710.01641", "submitter": "Matej Balog", "authors": "Matej Balog, Ilya Tolstikhin, Bernhard Sch\\\"olkopf", "title": "Differentially Private Database Release via Kernel Mean Embeddings", "comments": "35th International Conference on Machine Learning (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We lay theoretical foundations for new database release mechanisms that allow\nthird-parties to construct consistent estimators of population statistics,\nwhile ensuring that the privacy of each individual contributing to the database\nis protected. The proposed framework rests on two main ideas. First, releasing\n(an estimate of) the kernel mean embedding of the data generating random\nvariable instead of the database itself still allows third-parties to construct\nconsistent estimators of a wide class of population statistics. Second, the\nalgorithm can satisfy the definition of differential privacy by basing the\nreleased kernel mean embedding on entirely synthetic data points, while\ncontrolling accuracy through the metric available in a Reproducing Kernel\nHilbert Space. We describe two instantiations of the proposed framework,\nsuitable under different scenarios, and prove theoretical results guaranteeing\ndifferential privacy of the resulting algorithms and the consistency of\nestimators constructed from their outputs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 14:57:43 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 16:38:01 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Balog", "Matej", ""], ["Tolstikhin", "Ilya", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1710.01688", "submitter": "Stephen Tu", "authors": "Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht and Stephen Tu", "title": "On the Sample Complexity of the Linear Quadratic Regulator", "comments": "Contains a new analysis of finite-dimensional truncation, a new\n  data-dependent estimation bound, and an expanded exposition on necessary\n  background in control theory and System Level Synthesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the optimal control problem known as the Linear\nQuadratic Regulator in the case when the dynamics are unknown. We propose a\nmulti-stage procedure, called Coarse-ID control, that estimates a model from a\nfew experimental trials, estimates the error in that model with respect to the\ntruth, and then designs a controller using both the model and uncertainty\nestimate. Our technique uses contemporary tools from random matrix theory to\nbound the error in the estimation procedure. We also employ a recently\ndeveloped approach to control synthesis called System Level Synthesis that\nenables robust control design by solving a convex optimization problem. We\nprovide end-to-end bounds on the relative error in control cost that are nearly\noptimal in the number of parameters and that highlight salient properties of\nthe system to be controlled such as closed-loop sensitivity and optimal control\nmagnitude. We show experimentally that the Coarse-ID approach enables efficient\ncomputation of a stabilizing controller in regimes where simple control schemes\nthat do not take the model uncertainty into account fail to stabilize the true\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 16:46:38 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 08:39:54 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 20:38:30 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Dean", "Sarah", ""], ["Mania", "Horia", ""], ["Matni", "Nikolai", ""], ["Recht", "Benjamin", ""], ["Tu", "Stephen", ""]]}, {"id": "1710.01691", "submitter": "Kun Ho Kim", "authors": "Kun Ho Kim, Oisin Mac Aodha, Pietro Perona", "title": "Context Embedding Networks", "comments": "CVPR 2018 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low dimensional embeddings that capture the main variations of interest in\ncollections of data are important for many applications. One way to construct\nthese embeddings is to acquire estimates of similarity from the crowd. However,\nsimilarity is a multi-dimensional concept that varies from individual to\nindividual. Existing models for learning embeddings from the crowd typically\nmake simplifying assumptions such as all individuals estimate similarity using\nthe same criteria, the list of criteria is known in advance, or that the crowd\nworkers are not influenced by the data that they see. To overcome these\nlimitations we introduce Context Embedding Networks (CENs). In addition to\nlearning interpretable embeddings from images, CENs also model worker biases\nfor different attributes along with the visual context i.e. the visual\nattributes highlighted by a set of images. Experiments on two noisy crowd\nannotated datasets show that modeling both worker bias and visual context\nresults in more interpretable embeddings compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 18:46:40 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 22:47:50 GMT"}, {"version": "v3", "created": "Thu, 29 Mar 2018 16:32:35 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Kim", "Kun Ho", ""], ["Mac Aodha", "Oisin", ""], ["Perona", "Pietro", ""]]}, {"id": "1710.01720", "submitter": "Kostas Hatalis", "authors": "Kostas Hatalis, Alberto J. Lamadrid, Katya Scheinberg, Shalinee\n  Kishore", "title": "Smooth Pinball Neural Network for Probabilistic Forecasting of Wind\n  Power", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty analysis in the form of probabilistic forecasting can\nsignificantly improve decision making processes in the smart power grid for\nbetter integrating renewable energy sources such as wind. Whereas point\nforecasting provides a single expected value, probabilistic forecasts provide\nmore information in the form of quantiles, prediction intervals, or full\npredictive densities. This paper analyzes the effectiveness of a novel approach\nfor nonparametric probabilistic forecasting of wind power that combines a\nsmooth approximation of the pinball loss function with a neural network\narchitecture and a weighting initialization scheme to prevent the quantile\ncross over problem. A numerical case study is conducted using publicly\navailable wind data from the Global Energy Forecasting Competition 2014.\nMultiple quantiles are estimated to form 10%, to 90% prediction intervals which\nare evaluated using a quantile score and reliability measures. Benchmark models\nsuch as the persistence and climatology distributions, multiple quantile\nregression, and support vector quantile regression are used for comparison\nwhere results demonstrate the proposed approach leads to improved performance\nwhile preventing the problem of overlapping quantile estimates.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 17:48:10 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Hatalis", "Kostas", ""], ["Lamadrid", "Alberto J.", ""], ["Scheinberg", "Katya", ""], ["Kishore", "Shalinee", ""]]}, {"id": "1710.01788", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Ming Yu and Addie M. Thompson and Karthikeyan Natesan Ramamurthy and\n  Eunho Yang and Aur\\'elie C. Lozano", "title": "Multitask Learning using Task Clustering with Applications to Predictive\n  Modeling and GWAS of Plant Varieties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring predictive maps between multiple input and multiple output\nvariables or tasks has innumerable applications in data science. Multi-task\nlearning attempts to learn the maps to several output tasks simultaneously with\ninformation sharing between them. We propose a novel multi-task learning\nframework for sparse linear regression, where a full task hierarchy is\nautomatically inferred from the data, with the assumption that the task\nparameters follow a hierarchical tree structure. The leaves of the tree are the\nparameters for individual tasks, and the root is the global model that\napproximates all the tasks. We apply the proposed approach to develop and\nevaluate: (a) predictive models of plant traits using large-scale and automated\nremote sensing data, and (b) GWAS methodologies mapping such derived phenotypes\nin lieu of hand-measured traits. We demonstrate the superior performance of our\napproach compared to other methods, as well as the usefulness of discovering\nhierarchical groupings between tasks. Our results suggest that richer genetic\nmapping can indeed be obtained from the remote sensing data. In addition, our\ndiscovered groupings reveal interesting insights from a plant science\nperspective.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 20:13:21 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Yu", "Ming", ""], ["Thompson", "Addie M.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Yang", "Eunho", ""], ["Lozano", "Aur\u00e9lie C.", ""]]}, {"id": "1710.01878", "submitter": "Michael Zhu", "authors": "Michael Zhu, Suyog Gupta", "title": "To prune, or not to prune: exploring the efficacy of pruning for model\n  compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model pruning seeks to induce sparsity in a deep neural network's various\nconnection matrices, thereby reducing the number of nonzero-valued parameters\nin the model. Recent reports (Han et al., 2015; Narang et al., 2017) prune deep\nnetworks at the cost of only a marginal loss in accuracy and achieve a sizable\nreduction in model size. This hints at the possibility that the baseline models\nin these experiments are perhaps severely over-parameterized at the outset and\na viable alternative for model compression might be to simply reduce the number\nof hidden units while maintaining the model's dense connection structure,\nexposing a similar trade-off in model size and accuracy. We investigate these\ntwo distinct paths for model compression within the context of energy-efficient\ninference in resource-constrained environments and propose a new gradual\npruning technique that is simple and straightforward to apply across a variety\nof models/datasets with minimal tuning and can be seamlessly incorporated\nwithin the training process. We compare the accuracy of large, but pruned\nmodels (large-sparse) and their smaller, but dense (small-dense) counterparts\nwith identical memory footprint. Across a broad range of neural network\narchitectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we find\nlarge-sparse models to consistently outperform small-dense models and achieve\nup to 10x reduction in number of non-zero parameters with minimal loss in\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 04:26:49 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 18:40:16 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Zhu", "Michael", ""], ["Gupta", "Suyog", ""]]}, {"id": "1710.01931", "submitter": "Anna Guitart Atienza", "authors": "Anna Guitart, Pei Pei Chen, Paul Bertens and \\'Africa Peri\\'a\\~nez", "title": "Forecasting Player Behavioral Data and Simulating in-Game Events", "comments": null, "journal-ref": "In: Arai K., Kapoor S., Bhatia R. (eds) Advances in Information\n  and Communication Networks. FICC 2018. Advances in Intelligent Systems and\n  Computing, vol 886. Springer, Cham", "doi": "10.1007/978-3-030-03402-3_19", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding player behavior is fundamental in game data science. Video\ngames evolve as players interact with the game, so being able to foresee player\nexperience would help to ensure a successful game development. In particular,\ngame developers need to evaluate beforehand the impact of in-game events.\nSimulation optimization of these events is crucial to increase player\nengagement and maximize monetization. We present an experimental analysis of\nseveral methods to forecast game-related variables, with two main aims: to\nobtain accurate predictions of in-app purchases and playtime in an operational\nproduction environment, and to perform simulations of in-game events in order\nto maximize sales and playtime. Our ultimate purpose is to take a step towards\nthe data-driven development of games. The results suggest that, even though the\nperformance of traditional approaches such as ARIMA is still better, the\noutcomes of state-of-the-art techniques like deep learning are promising. Deep\nlearning comes up as a well-suited general model that could be used to forecast\na variety of time series with different dynamic behaviors.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 09:17:22 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Guitart", "Anna", ""], ["Chen", "Pei Pei", ""], ["Bertens", "Paul", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1710.02030", "submitter": "Ali Pesaranghader", "authors": "Ali Pesaranghader, Herna Viktor, Eric Paquet", "title": "McDiarmid Drift Detection Methods for Evolving Data Streams", "comments": "9 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly, Internet of Things (IoT) domains, such as sensor networks,\nsmart cities, and social networks, generate vast amounts of data. Such data are\nnot only unbounded and rapidly evolving. Rather, the content thereof\ndynamically evolves over time, often in unforeseen ways. These variations are\ndue to so-called concept drifts, caused by changes in the underlying data\ngeneration mechanisms. In a classification setting, concept drift causes the\npreviously learned models to become inaccurate, unsafe and even unusable.\nAccordingly, concept drifts need to be detected, and handled, as soon as\npossible. In medical applications and emergency response settings, for example,\nchange in behaviours should be detected in near real-time, to avoid potential\nloss of life. To this end, we introduce the McDiarmid Drift Detection Method\n(MDDM), which utilizes McDiarmid's inequality in order to detect concept drift.\nThe MDDM approach proceeds by sliding a window over prediction results, and\nassociate window entries with weights. Higher weights are assigned to the most\nrecent entries, in order to emphasize their importance. As instances are\nprocessed, the detection algorithm compares a weighted mean of elements inside\nthe sliding window with the maximum weighted mean observed so far. A\nsignificant difference between the two weighted means, upper-bounded by the\nMcDiarmid inequality, implies a concept drift. Our extensive experimentation\nagainst synthetic and real-world data streams show that our novel method\noutperforms the state-of-the-art. Specifically, MDDM yields shorter detection\ndelays as well as lower false negative rates, while maintaining high\nclassification accuracies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 14:02:28 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 19:03:06 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Pesaranghader", "Ali", ""], ["Viktor", "Herna", ""], ["Paquet", "Eric", ""]]}, {"id": "1710.02101", "submitter": "Amir Najafi", "authors": "Amir Najafi, Abolfazl Motahari, Hamid R. Rabiee", "title": "Reliable Clustering of Bernoulli Mixture Models", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bernoulli Mixture Model (BMM) is a finite mixture of random binary vectors\nwith independent dimensions. The problem of clustering BMM data arises in a\nvariety of real-world applications, ranging from population genetics to\nactivity analysis in social networks. In this paper, we analyze the\nclusterability of BMMs from a theoretical perspective, when the number of\nclusters is unknown. In particular, we stipulate a set of conditions on the\nsample complexity and dimension of the model in order to guarantee the Probably\nApproximately Correct (PAC)-clusterability of a dataset. To the best of our\nknowledge, these findings are the first non-asymptotic bounds on the sample\ncomplexity of learning or clustering BMMs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:22:27 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 19:35:33 GMT"}, {"version": "v3", "created": "Sun, 16 Jun 2019 04:55:27 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Najafi", "Amir", ""], ["Motahari", "Abolfazl", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1710.02103", "submitter": "Yu Zhang", "authors": "Yu Zhang, Srikanta Tirthapura, Graham Cormode", "title": "Learning Graphical Models from a Distributed Stream", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A current challenge for data management systems is to support the\nconstruction and maintenance of machine learning models over data that is\nlarge, multi-dimensional, and evolving. While systems that could support these\ntasks are emerging, the need to scale to distributed, streaming data requires\nnew models and algorithms. In this setting, as well as computational\nscalability and model accuracy, we also need to minimize the amount of\ncommunication between distributed processors, which is the chief component of\nlatency. We study Bayesian networks, the workhorse of graphical models, and\npresent a communication-efficient method for continuously learning and\nmaintaining a Bayesian network model over data that is arriving as a\ndistributed stream partitioned across multiple processors. We show a strategy\nfor maintaining model parameters that leads to an exponential reduction in\ncommunication when compared with baseline approaches to maintain the exact MLE\n(maximum likelihood estimation). Meanwhile, our strategy provides similar\nprediction errors for the target distribution and for classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:30:33 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Zhang", "Yu", ""], ["Tirthapura", "Srikanta", ""], ["Cormode", "Graham", ""]]}, {"id": "1710.02113", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad and Daoqiang Zhang", "title": "Anatomical Pattern Analysis for decoding visual stimuli in human brains", "comments": "Published in Cognitive Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: A universal unanswered question in neuroscience and machine\nlearning is whether computers can decode the patterns of the human brain.\nMulti-Voxels Pattern Analysis (MVPA) is a critical tool for addressing this\nquestion. However, there are two challenges in the previous MVPA methods, which\ninclude decreasing sparsity and noise in the extracted features and increasing\nthe performance of prediction.\n  Methods: In overcoming mentioned challenges, this paper proposes Anatomical\nPattern Analysis (APA) for decoding visual stimuli in the human brain. This\nframework develops a novel anatomical feature extraction method and a new\nimbalance AdaBoost algorithm for binary classification. Further, it utilizes an\nError-Correcting Output Codes (ECOC) method for multiclass prediction. APA can\nautomatically detect active regions for each category of the visual stimuli.\nMoreover, it enables us to combine homogeneous datasets for applying advanced\nclassification.\n  Results and Conclusions: Experimental studies on 4 visual categories (words,\nconsonants, objects and scrambled photos) demonstrate that the proposed\napproach achieves superior performance to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 16:57:21 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1710.02196", "submitter": "Soheil Feizi", "authors": "Soheil Feizi, Hamid Javadi, Jesse Zhang and David Tse", "title": "Porcupine Neural Networks: (Almost) All Local Optima are Global", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been used prominently in several machine learning and\nstatistics applications. In general, the underlying optimization of neural\nnetworks is non-convex which makes their performance analysis challenging. In\nthis paper, we take a novel approach to this problem by asking whether one can\nconstrain neural network weights to make its optimization landscape have good\ntheoretical properties while at the same time, be a good approximation for the\nunconstrained one. For two-layer neural networks, we provide affirmative\nanswers to these questions by introducing Porcupine Neural Networks (PNNs)\nwhose weight vectors are constrained to lie over a finite set of lines. We show\nthat most local optima of PNN optimizations are global while we have a\ncharacterization of regions where bad local optimizers may exist. Moreover, our\ntheoretical and empirical results suggest that an unconstrained neural network\ncan be approximated using a polynomially-large PNN.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 20:04:10 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Feizi", "Soheil", ""], ["Javadi", "Hamid", ""], ["Zhang", "Jesse", ""], ["Tse", "David", ""]]}, {"id": "1710.02221", "submitter": "Ondrej Kuzelka", "authors": "Gustav Sourek, Martin Svatos, Filip Zelezny, Steven Schockaert, Ondrej\n  Kuzelka", "title": "Stacked Structure Learning for Lifted Relational Neural Networks", "comments": "Presented at ILP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifted Relational Neural Networks (LRNNs) describe relational domains using\nweighted first-order rules which act as templates for constructing feed-forward\nneural networks. While previous work has shown that using LRNNs can lead to\nstate-of-the-art results in various ILP tasks, these results depended on\nhand-crafted rules. In this paper, we extend the framework of LRNNs with\nstructure learning, thus enabling a fully automated learning process. Similarly\nto many ILP methods, our structure learning algorithm proceeds in an iterative\nfashion by top-down searching through the hypothesis space of all possible Horn\nclauses, considering the predicates that occur in the training examples as well\nas invented soft concepts entailed by the best weighted rules found so far. In\nthe experiments, we demonstrate the ability to automatically induce useful\nhierarchical soft concepts leading to deep LRNNs with a competitive predictive\npower.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 21:15:45 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Sourek", "Gustav", ""], ["Svatos", "Martin", ""], ["Zelezny", "Filip", ""], ["Schockaert", "Steven", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "1710.02236", "submitter": "Shiqian Ma", "authors": "Junyu Zhang, Shiqian Ma, Shuzhong Zhang", "title": "Primal-Dual Optimization Algorithms over Riemannian Manifolds: an\n  Iteration Complexity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study nonconvex and nonsmooth multi-block optimization over\nRiemannian manifolds with coupled linear constraints. Such optimization\nproblems naturally arise from machine learning, statistical learning,\ncompressive sensing, image processing, and tensor PCA, among others. We develop\nan ADMM-like primal-dual approach based on decoupled solvable subroutines such\nas linearized proximal mappings. First, we introduce the optimality conditions\nfor the afore-mentioned optimization models. Then, the notion of\n$\\epsilon$-stationary solutions is introduced as a result. The main part of the\npaper is to show that the proposed algorithms enjoy an iteration complexity of\n$O(1/\\epsilon^2)$ to reach an $\\epsilon$-stationary solution. For prohibitively\nlarge-size tensor or machine learning models, we present a sampling-based\nstochastic algorithm with the same iteration complexity bound in expectation.\nIn case the subproblems are not analytically solvable, a feasible curvilinear\nline-search variant of the algorithm based on retraction operators is proposed.\nFinally, we show specifically how the algorithms can be implemented to solve a\nvariety of practical problems such as the NP-hard maximum bisection problem,\nthe $\\ell_q$ regularized sparse tensor principal component analysis and the\ncommunity detection problem. Our preliminary numerical results show great\npotentials of the proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 23:21:11 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Zhang", "Junyu", ""], ["Ma", "Shiqian", ""], ["Zhang", "Shuzhong", ""]]}, {"id": "1710.02238", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Charles Siegel, Abhinav Vishnu, Nathan O. Hodas,\n  Nathan Baker", "title": "How Much Chemistry Does a Deep Neural Network Need to Know to Make\n  Accurate Predictions?", "comments": "In Proceedings of 2018 IEEE Winter Conference on Applications of\n  Computer Vision (WACV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The meteoric rise of deep learning models in computer vision research, having\nachieved human-level accuracy in image recognition tasks is firm evidence of\nthe impact of representation learning of deep neural networks. In the chemistry\ndomain, recent advances have also led to the development of similar CNN models,\nsuch as Chemception, that is trained to predict chemical properties using\nimages of molecular drawings. In this work, we investigate the effects of\nsystematically removing and adding localized domain-specific information to the\nimage channels of the training data. By augmenting images with only 3\nadditional basic information, and without introducing any architectural\nchanges, we demonstrate that an augmented Chemception (AugChemception)\noutperforms the original model in the prediction of toxicity, activity, and\nsolvation free energy. Then, by altering the information content in the images,\nand examining the resulting model's performance, we also identify two distinct\nlearning patterns in predicting toxicity/activity as compared to solvation free\nenergy. These patterns suggest that Chemception is learning about its tasks in\nthe manner that is consistent with established knowledge. Thus, our work\ndemonstrates that advanced chemical knowledge is not a pre-requisite for deep\nlearning models to accurately predict complex chemical properties.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 23:53:59 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 14:03:12 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Goh", "Garrett B.", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""], ["Hodas", "Nathan O.", ""], ["Baker", "Nathan", ""]]}, {"id": "1710.02245", "submitter": "Son Tran", "authors": "Son N. Tran, Srikanth Cherla, Artur Garcez, Tillman Weyde", "title": "Linear-Time Sequence Classification using Restricted Boltzmann Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Classification of sequence data is the topic of interest for dynamic Bayesian\nmodels and Recurrent Neural Networks (RNNs). While the former can explicitly\nmodel the temporal dependencies between class variables, the latter have a\ncapability of learning representations. Several attempts have been made to\nimprove performance by combining these two approaches or increasing the\nprocessing capability of the hidden units in RNNs. This often results in\ncomplex models with a large number of learning parameters. In this paper, a\ncompact model is proposed which offers both representation learning and\ntemporal inference of class variables by rolling Restricted Boltzmann Machines\n(RBMs) and class variables over time. We address the key issue of\nintractability in this variant of RBMs by optimising a conditional\ndistribution, instead of a joint distribution. Experiments reported in the\npaper on melody modelling and optical character recognition show that the\nproposed model can outperform the state-of-the-art. Also, the experimental\nresults on optical character recognition, part-of-speech tagging and text\nchunking demonstrate that our model is comparable to recurrent neural networks\nwith complex memory gates while requiring far fewer parameters.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 00:29:30 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 22:38:07 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 23:55:15 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Tran", "Son N.", ""], ["Cherla", "Srikanth", ""], ["Garcez", "Artur", ""], ["Weyde", "Tillman", ""]]}, {"id": "1710.02248", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, Ahmed Touati, Laurent Dinh, Michal Drozdzal, Mohammad\n  Havaei, Laurent Charlin, Aaron Courville", "title": "Learnable Explicit Density for Continuous Latent Space and Variational\n  Inference", "comments": "2 figures, 5 pages, submitted to ICML Principled Approaches to Deep\n  Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study two aspects of the variational autoencoder (VAE): the\nprior distribution over the latent variables and its corresponding posterior.\nFirst, we decompose the learning of VAEs into layerwise density estimation, and\nargue that having a flexible prior is beneficial to both sample generation and\ninference. Second, we analyze the family of inverse autoregressive flows\n(inverse AF) and show that with further improvement, inverse AF could be used\nas universal approximation to any complicated posterior. Our analysis results\nin a unified approach to parameterizing a VAE, without the need to restrict\nourselves to use factorial Gaussians in the latent real space.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 00:51:03 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Touati", "Ahmed", ""], ["Dinh", "Laurent", ""], ["Drozdzal", "Michal", ""], ["Havaei", "Mohammad", ""], ["Charlin", "Laurent", ""], ["Courville", "Aaron", ""]]}, {"id": "1710.02262", "submitter": "Anna Guitart Atienza", "authors": "Paul Bertens, Anna Guitart and \\'Africa Peri\\'a\\~nez", "title": "Games and Big Data: A Scalable Multi-Dimensional Churn Prediction Model", "comments": null, "journal-ref": "IEEE Conference on Computational Intelligence and Games (CIG),\n  33--36, 2017", "doi": "10.1109/CIG.2017.8080412", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of mobile games has caused a paradigm shift in the video-game\nindustry. Game developers now have at their disposal a plethora of information\non their players, and thus can take advantage of reliable models that can\naccurately predict player behavior and scale to huge datasets. Churn\nprediction, a challenge common to a variety of sectors, is particularly\nrelevant for the mobile game industry, as player retention is crucial for the\nsuccessful monetization of a game. In this article, we present an approach to\npredicting game abandon based on survival ensembles. Our method provides\naccurate predictions on both the level at which each player will leave the game\nand their accumulated playtime until that moment. Further, it is robust to\ndifferent data distributions and applicable to a wide range of response\nvariables, while also allowing for efficient parallelization of the algorithm.\nThis makes our model well suited to perform real-time analyses of churners,\neven for games with millions of daily active users.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 03:01:52 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Bertens", "Paul", ""], ["Guitart", "Anna", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1710.02264", "submitter": "Anna Guitart Atienza", "authors": "\\'Africa Peri\\'a\\~nez, Alain Saas, Anna Guitart and Colin Magne", "title": "Churn Prediction in Mobile Social Games: Towards a Complete Assessment\n  Using Survival Ensembles", "comments": null, "journal-ref": "IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA), 564--573, 2016", "doi": "10.1109/DSAA.2016.84", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing user attrition, i.e. churn, is a broad challenge faced by several\nindustries. In mobile social games, decreasing churn is decisive to increase\nplayer retention and rise revenues. Churn prediction models allow to understand\nplayer loyalty and to anticipate when they will stop playing a game. Thanks to\nthese predictions, several initiatives can be taken to retain those players who\nare more likely to churn.\n  Survival analysis focuses on predicting the time of occurrence of a certain\nevent, churn in our case. Classical methods, like regressions, could be applied\nonly when all players have left the game. The challenge arises for datasets\nwith incomplete churning information for all players, as most of them still\nconnect to the game. This is called a censored data problem and is in the\nnature of churn. Censoring is commonly dealt with survival analysis techniques,\nbut due to the inflexibility of the survival statistical algorithms, the\naccuracy achieved is often poor. In contrast, novel ensemble learning\ntechniques, increasingly popular in a variety of scientific fields, provide\nhigh-class prediction results.\n  In this work, we develop, for the first time in the social games domain, a\nsurvival ensemble model which provides a comprehensive analysis together with\nan accurate prediction of churn. For each player, we predict the probability of\nchurning as function of time, which permits to distinguish various levels of\nloyalty profiles. Additionally, we assess the risk factors that explain the\npredicted player survival times. Our results show that churn prediction by\nsurvival ensembles significantly improves the accuracy and robustness of\ntraditional analyses, like Cox regression.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 03:19:55 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Peri\u00e1\u00f1ez", "\u00c1frica", ""], ["Saas", "Alain", ""], ["Guitart", "Anna", ""], ["Magne", "Colin", ""]]}, {"id": "1710.02268", "submitter": "Anna Guitart Atienza", "authors": "Alain Saas, Anna Guitart and \\'Africa Peri\\'a\\~nez", "title": "Discovering Playing Patterns: Time Series Clustering of Free-To-Play\n  Game Data", "comments": null, "journal-ref": "IEEE Conference on Computational Intelligence and Games (CIG),\n  20-23, 2016", "doi": "10.1109/CIG.2016.7860442", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of time series data is a challenge common to all\ndata-driven fields. However, there is no agreement about which are the most\nefficient techniques to group unlabeled time-ordered data. This is because a\nsuccessful classification of time series patterns depends on the goal and the\ndomain of interest, i.e. it is application-dependent.\n  In this article, we study free-to-play game data. In this domain, clustering\nsimilar time series information is increasingly important due to the large\namount of data collected by current mobile and web applications. We evaluate\nwhich methods cluster accurately time series of mobile games, focusing on\nplayer behavior data. We identify and validate several aspects of the\nclustering: the similarity measures and the representation techniques to reduce\nthe high dimensionality of time series. As a robustness test, we compare\nvarious temporal datasets of player activity from two free-to-play video-games.\n  With these techniques we extract temporal patterns of player behavior\nrelevant for the evaluation of game events and game-business diagnosis. Our\nexperiments provide intuitive visualizations to validate the results of the\nclustering and to determine the optimal number of clusters. Additionally, we\nassess the common characteristics of the players belonging to the same group.\nThis study allows us to improve the understanding of player dynamics and churn\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 03:39:33 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Saas", "Alain", ""], ["Guitart", "Anna", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1710.02277", "submitter": "Donghyun Yoo", "authors": "Donghyun Yoo, Haoqi Fan, Vishnu Naresh Boddeti, Kris M. Kitani", "title": "Efficient K-Shot Learning with Regularized Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature representations from pre-trained deep neural networks have been known\nto exhibit excellent generalization and utility across a variety of related\ntasks. Fine-tuning is by far the simplest and most widely used approach that\nseeks to exploit and adapt these feature representations to novel tasks with\nlimited data. Despite the effectiveness of fine-tuning, itis often sub-optimal\nand requires very careful optimization to prevent severe over-fitting to small\ndatasets. The problem of sub-optimality and over-fitting, is due in part to the\nlarge number of parameters used in a typical deep convolutional neural network.\nTo address these problems, we propose a simple yet effective regularization\nmethod for fine-tuning pre-trained deep networks for the task of k-shot\nlearning. To prevent overfitting, our key strategy is to cluster the model\nparameters while ensuring intra-cluster similarity and inter-cluster diversity\nof the parameters, effectively regularizing the dimensionality of the parameter\nsearch space. In particular, we identify groups of neurons within each layer of\na deep network that shares similar activation patterns. When the network is to\nbe fine-tuned for a classification task using only k examples, we propagate a\nsingle gradient to all of the neuron parameters that belong to the same group.\nThe grouping of neurons is non-trivial as neuron activations depend on the\ndistribution of the input data. To efficiently search for optimal groupings\nconditioned on the input data, we propose a reinforcement learning search\nstrategy using recurrent networks to learn the optimal group assignments for\neach network layer. Experimental results show that our method can be easily\napplied to several popular convolutional neural networks and improve upon other\nstate-of-the-art fine-tuning based k-shot learning strategies by more than10%\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 05:07:28 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Yoo", "Donghyun", ""], ["Fan", "Haoqi", ""], ["Boddeti", "Vishnu Naresh", ""], ["Kitani", "Kris M.", ""]]}, {"id": "1710.02368", "submitter": "Joeri Hermans", "authors": "Joeri Hermans, Gerasimos Spanakis and Rico M\\\"ockel", "title": "Accumulated Gradient Normalization", "comments": "16 pages, 12 figures, ACML2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work addresses the instability in asynchronous data parallel\noptimization. It does so by introducing a novel distributed optimizer which is\nable to efficiently optimize a centralized model under communication\nconstraints. The optimizer achieves this by pushing a normalized sequence of\nfirst-order gradients to a parameter server. This implies that the magnitude of\na worker delta is smaller compared to an accumulated gradient, and provides a\nbetter direction towards a minimum compared to first-order gradients, which in\nturn also forces possible implicit momentum fluctuations to be more aligned\nsince we make the assumption that all workers contribute towards a single\nminima. As a result, our approach mitigates the parameter staleness problem\nmore effectively since staleness in asynchrony induces (implicit) momentum, and\nachieves a better convergence rate compared to other optimizers such as\nasynchronous EASGD and DynSGD, which we show empirically.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 12:32:16 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Hermans", "Joeri", ""], ["Spanakis", "Gerasimos", ""], ["M\u00f6ckel", "Rico", ""]]}, {"id": "1710.02441", "submitter": "Gopal Nataraj", "authors": "Gopal Nataraj, Jon-Fredrik Nielsen, Clayton Scott, and Jeffrey A.\n  Fessler", "title": "Dictionary-Free MRI PERK: Parameter Estimation via Regression with\n  Kernels", "comments": "submitted to IEEE Transactions on Medical Imaging", "journal-ref": "IEEE Transactions on Medical Imaging 37(9):2103-14 Sep 2018", "doi": "10.1109/TMI.2018.2817547", "report-no": null, "categories": "stat.ML eess.SP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a fast, general method for dictionary-free parameter\nestimation in quantitative magnetic resonance imaging (QMRI) via regression\nwith kernels (PERK). PERK first uses prior distributions and the nonlinear MR\nsignal model to simulate many parameter-measurement pairs. Inspired by machine\nlearning, PERK then takes these parameter-measurement pairs as labeled training\npoints and learns from them a nonlinear regression function using kernel\nfunctions and convex optimization. PERK admits a simple implementation as\nper-voxel nonlinear lifting of MRI measurements followed by linear minimum\nmean-squared error regression. We demonstrate PERK for $T_1,T_2$ estimation, a\nwell-studied application where it is simple to compare PERK estimates against\ndictionary-based grid search estimates. Numerical simulations as well as\nsingle-slice phantom and in vivo experiments demonstrate that PERK and grid\nsearch produce comparable $T_1,T_2$ estimates in white and gray matter, but\nPERK is consistently at least $23\\times$ faster. This acceleration factor will\nincrease by several orders of magnitude for full-volume QMRI estimation\nproblems involving more latent parameters per voxel.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 15:05:19 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Nataraj", "Gopal", ""], ["Nielsen", "Jon-Fredrik", ""], ["Scott", "Clayton", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1710.02458", "submitter": "Daniel B. Neill", "authors": "Daniel B. Neill (1), William Herlands (1) ((1) Carnegie Mellon\n  University)", "title": "Machine Learning for Drug Overdose Surveillance", "comments": "Presented at the Data For Good Exchange 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two recently proposed machine learning approaches for discovering\nemerging trends in fatal accidental drug overdoses. The Gaussian Process Subset\nScan enables early detection of emerging patterns in spatio-temporal data,\naccounting for both the non-iid nature of the data and the fact that detecting\nsubtle patterns requires integration of information across multiple spatial\nareas and multiple time steps. We apply this approach to 17 years of\ncounty-aggregated data for monthly opioid overdose deaths in the New York City\nmetropolitan area, showing clear advantages in the utility of discovered\npatterns as compared to typical anomaly detection approaches.\n  To detect and characterize emerging overdose patterns that differentially\naffect a subpopulation of the data, including geographic, demographic, and\nbehavioral patterns (e.g., which combinations of drugs are involved), we apply\nthe Multidimensional Tensor Scan to 8 years of case-level overdose data from\nAllegheny County, PA. We discover previously unidentified overdose patterns\nwhich reveal unusual demographic clusters, show impacts of drug legislation,\nand demonstrate potential for early detection and targeted intervention. These\napproaches to early detection of overdose patterns can inform prevention and\nresponse efforts, as well as understanding the effects of policy changes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 15:43:44 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Neill", "Daniel B.", ""], ["Herlands", "William", ""]]}, {"id": "1710.02546", "submitter": "Xuemei Xie", "authors": "Xuemei Xie, Chenye Wang, Shu Chen, Guangming Shi, Zhifu Zhao", "title": "Real-Time Illegal Parking Detection System Based on Deep Learning", "comments": "5pages,6figures", "journal-ref": null, "doi": "10.1145/3094243.3094261", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing illegal parking has become more and more serious. Nowadays the\nmethods of detecting illegally parked vehicles are based on background\nsegmentation. However, this method is weakly robust and sensitive to\nenvironment. Benefitting from deep learning, this paper proposes a novel\nillegal vehicle parking detection system. Illegal vehicles captured by camera\nare firstly located and classified by the famous Single Shot MultiBox Detector\n(SSD) algorithm. To improve the performance, we propose to optimize SSD by\nadjusting the aspect ratio of default box to accommodate with our dataset\nbetter. After that, a tracking and analysis of movement is adopted to judge the\nillegal vehicles in the region of interest (ROI). Experiments show that the\nsystem can achieve a 99% accuracy and real-time (25FPS) detection with strong\nrobustness in complex environments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 07:57:29 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Xie", "Xuemei", ""], ["Wang", "Chenye", ""], ["Chen", "Shu", ""], ["Shi", "Guangming", ""], ["Zhao", "Zhifu", ""]]}, {"id": "1710.02619", "submitter": "Yijie Peng", "authors": "Yijie Peng, Edwin K. P. Chong, Chun-Hung Chen and Michael C. Fu", "title": "Ranking and Selection as Stochastic Control", "comments": "15 pages, 8 figures, to appear in IEEE Transactions on Automatic\n  Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under a Bayesian framework, we formulate the fully sequential sampling and\nselection decision in statistical ranking and selection as a stochastic control\nproblem, and derive the associated Bellman equation. Using value function\napproximation, we derive an approximately optimal allocation policy. We show\nthat this policy is not only computationally efficient but also possesses both\none-step-ahead and asymptotic optimality for independent normal sampling\ndistributions. Moreover, the proposed allocation policy is easily generalizable\nin the approximate dynamic programming paradigm.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 01:53:54 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Peng", "Yijie", ""], ["Chong", "Edwin K. P.", ""], ["Chen", "Chun-Hung", ""], ["Fu", "Michael C.", ""]]}, {"id": "1710.02642", "submitter": "Haihui Shen", "authors": "Haihui Shen, L. Jeff Hong, Xiaowei Zhang", "title": "Ranking and Selection with Covariates for Personalized Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of ranking and selection via simulation in the context\nof personalized decision making, where the best alternative is not universal\nbut varies as a function of some observable covariates. The goal of ranking and\nselection with covariates (R&S-C) is to use simulation samples to obtain a\nselection policy that specifies the best alternative with certain statistical\nguarantee for subsequent individuals upon observing their covariates. A linear\nmodel is proposed to capture the relationship between the mean performance of\nan alternative and the covariates. Under the indifference-zone formulation, we\ndevelop two-stage procedures for both homoscedastic and heteroscedastic\nsimulation errors, respectively, and prove their statistical validity in terms\nof average probability of correct selection. We also generalize the well-known\nslippage configuration, and prove that the generalized slippage configuration\nis the least favorable configuration for our procedures. Extensive numerical\nexperiments are conducted to investigate the performance of the proposed\nprocedures, the experimental design issue, and the robustness to the linearity\nassumption. Finally, we demonstrate the usefulness of R&S-C via a case study of\nselecting the best treatment regimen in the prevention of esophageal cancer. We\nfind that by leveraging disease-related personal information, R&S-C can\nsubstantially improve patients' expected quality-adjusted life years by\nproviding patient-specific treatment regimen.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 06:58:45 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 09:23:48 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Shen", "Haihui", ""], ["Hong", "L. Jeff", ""], ["Zhang", "Xiaowei", ""]]}, {"id": "1710.02704", "submitter": "Zemin Zheng", "authors": "Zemin Zheng, Jinchi Lv and Wei Lin", "title": "Nonsparse learning with latent variables", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a popular tool for producing meaningful and interpretable models,\nlarge-scale sparse learning works efficiently when the underlying structures\nare indeed or close to sparse. However, naively applying the existing\nregularization methods can result in misleading outcomes due to model\nmisspecification. In particular, the direct sparsity assumption on coefficient\nvectors has been questioned in real applications. Therefore, we consider\nnonsparse learning with the conditional sparsity structure that the coefficient\nvector becomes sparse after taking out the impacts of certain unobservable\nlatent variables. A new methodology of nonsparse learning with latent variables\n(NSL) is proposed to simultaneously recover the significant observable\npredictors and latent factors as well as their effects. We explore a common\nlatent family incorporating population principal components and derive the\nconvergence rates of both sample principal components and their score vectors\nthat hold for a wide class of distributions. With the properly estimated latent\nvariables, properties including model selection consistency and oracle\ninequalities under various prediction and estimation losses are established for\nthe proposed methodology. Our new methodology and results are evidenced by\nsimulation and real data examples.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 16:14:08 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Zheng", "Zemin", ""], ["Lv", "Jinchi", ""], ["Lin", "Wei", ""]]}, {"id": "1710.02736", "submitter": "Holden Lee", "authors": "Rong Ge, Holden Lee, Andrej Risteski", "title": "Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal\n  Distributions using Simulated Tempering Langevin Monte Carlo", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key task in Bayesian statistics is sampling from distributions that are\nonly specified up to a partition function (i.e., constant of proportionality).\nHowever, without any assumptions, sampling (even approximately) can be #P-hard,\nand few works have provided \"beyond worst-case\" guarantees for such settings.\n  For log-concave distributions, classical results going back to Bakry and\n\\'Emery (1985) show that natural continuous-time Markov chains called Langevin\ndiffusions mix in polynomial time. The most salient feature of log-concavity\nviolated in practice is uni-modality: commonly, the distributions we wish to\nsample from are multi-modal. In the presence of multiple deep and\nwell-separated modes, Langevin diffusion suffers from torpid mixing.\n  We address this problem by combining Langevin diffusion with simulated\ntempering. The result is a Markov chain that mixes more rapidly by\ntransitioning between different temperatures of the distribution. We analyze\nthis Markov chain for the canonical multi-modal distribution: a mixture of\ngaussians (of equal variance). The algorithm based on our Markov chain provably\nsamples from distributions that are close to mixtures of gaussians, given\naccess to the gradient of the log-pdf. For the analysis, we use a spectral\ndecomposition theorem for graphs (Gharan and Trevisan, 2014) and a Markov chain\ndecomposition technique (Madras and Randall, 2002).\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 19:55:51 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 01:49:53 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Holden", ""], ["Risteski", "Andrej", ""]]}, {"id": "1710.02766", "submitter": "Markus Kaiser", "authors": "Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Henrik Ek", "title": "Bayesian Alignments of Warped Multi-Output Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian approach to modelling nonlinear alignments of\ntime series based on latent shared information. We apply the method to the\nreal-world problem of finding common structure in the sensor data of wind\nturbines introduced by the underlying latent and turbulent wind field. The\nproposed model allows for both arbitrary alignments of the inputs and\nnon-parametric output warpings to transform the observations. This gives rise\nto multiple deep Gaussian process models connected via latent generating\nprocesses. We present an efficient variational approximation based on nested\nvariational compression and show how the model can be used to extract shared\ninformation between dependent time series, recovering an interpretable\nfunctional decomposition of the learning problem. We show results for an\nartificial data set and real-world data of two wind turbines.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 01:42:39 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 12:04:08 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 13:07:53 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Kaiser", "Markus", ""], ["Otte", "Clemens", ""], ["Runkler", "Thomas", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1710.02823", "submitter": "Markku Hinkka", "authors": "Markku Hinkka, Teemu Lehto, Keijo Heljanko, Alexander Jung", "title": "Structural Feature Selection for Event Logs", "comments": "Extended version of a paper published in the proceedings of the BPM\n  2017 workshops", "journal-ref": null, "doi": "10.1007/978-3-319-74030-0_2", "report-no": null, "categories": "cs.LG cs.DB cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of classifying business process instances based on\nstructural features derived from event logs. The main motivation is to provide\nmachine learning based techniques with quick response times for interactive\ncomputer assisted root cause analysis. In particular, we create structural\nfeatures from process mining such as activity and transition occurrence counts,\nand ordering of activities to be evaluated as potential features for\nclassification. We show that adding such structural features increases the\namount of information thus potentially increasing classification accuracy.\nHowever, there is an inherent trade-off as using too many features leads to too\nlong run-times for machine learning classification models. One way to improve\nthe machine learning algorithms' run-time is to only select a small number of\nfeatures by a feature selection algorithm. However, the run-time required by\nthe feature selection algorithm must also be taken into account. Also, the\nclassification accuracy should not suffer too much from the feature selection.\nThe main contributions of this paper are as follows: First, we propose and\ncompare six different feature selection algorithms by means of an experimental\nsetup comparing their classification accuracy and achievable response times.\nSecond, we discuss the potential use of feature selection results for computer\nassisted root cause analysis as well as the properties of different types of\nstructural features in the context of feature selection.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 11:38:37 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 08:54:22 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Hinkka", "Markku", ""], ["Lehto", "Teemu", ""], ["Heljanko", "Keijo", ""], ["Jung", "Alexander", ""]]}, {"id": "1710.02844", "submitter": "Zeng Yu", "authors": "Zeng Yu, Tianrui Li, Ning Yu, Yi Pan, Hongmei Chen, Bing Liu", "title": "Reconstruction of Hidden Representation for Robust Feature Extraction", "comments": "This article has been accepted for publication in a future issue of\n  ACM Transactions on Intelligent Systems and Technology", "journal-ref": null, "doi": "10.1145/3284174", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to develop a new and robust approach to feature\nrepresentation. Motivated by the success of Auto-Encoders, we first theoretical\nsummarize the general properties of all algorithms that are based on\ntraditional Auto-Encoders: 1) The reconstruction error of the input can not be\nlower than a lower bound, which can be viewed as a guiding principle for\nreconstructing the input. Additionally, when the input is corrupted with\nnoises, the reconstruction error of the corrupted input also can not be lower\nthan a lower bound. 2) The reconstruction of a hidden representation achieving\nits ideal situation is the necessary condition for the reconstruction of the\ninput to reach the ideal state. 3) Minimizing the Frobenius norm of the\nJacobian matrix of the hidden representation has a deficiency and may result in\na much worse local optimum value. We believe that minimizing the reconstruction\nerror of the hidden representation is more robust than minimizing the Frobenius\nnorm of the Jacobian matrix of the hidden representation. Based on the above\nanalysis, we propose a new model termed Double Denoising Auto-Encoders (DDAEs),\nwhich uses corruption and reconstruction on both the input and the hidden\nrepresentation. We demonstrate that the proposed model is highly flexible and\nextensible and has a potentially better capability to learn invariant and\nrobust feature representations. We also show that our model is more robust than\nDenoising Auto-Encoders (DAEs) for dealing with noises or inessential features.\nFurthermore, we detail how to train DDAEs with two different pre-training\nmethods by optimizing the objective function in a combined and separate manner,\nrespectively. Comparative experiments illustrate that the proposed model is\nsignificantly better for representation learning than the state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 15:48:37 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 15:51:57 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Yu", "Zeng", ""], ["Li", "Tianrui", ""], ["Yu", "Ning", ""], ["Pan", "Yi", ""], ["Chen", "Hongmei", ""], ["Liu", "Bing", ""]]}, {"id": "1710.02869", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge, Jose C. Principe", "title": "An Analysis of the Value of Information when Exploring Stochastic,\n  Discrete Multi-Armed Bandits", "comments": "Entropy", "journal-ref": null, "doi": "10.3390/e20030155", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an information-theoretic exploration strategy for\nstochastic, discrete multi-armed bandits that achieves optimal regret. Our\nstrategy is based on the value of information criterion. This criterion\nmeasures the trade-off between policy information and obtainable rewards. High\namounts of policy information are associated with exploration-dominant searches\nof the space and yield high rewards. Low amounts of policy information favor\nthe exploitation of existing knowledge. Information, in this criterion, is\nquantified by a parameter that can be varied during search. We demonstrate that\na simulated-annealing-like update of this parameter, with a sufficiently fast\ncooling schedule, leads to an optimal regret that is logarithmic with respect\nto the number of episodes.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 18:48:48 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2018 21:01:57 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Principe", "Jose C.", ""]]}, {"id": "1710.02901", "submitter": "Amir Ali Ahmadi", "authors": "Amir Ali Ahmadi, Anirudha Majumdar", "title": "Response to \"Counterexample to global convergence of DSOS and SDSOS\n  hierarchies\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent note [8], the author provides a counterexample to the global\nconvergence of what his work refers to as \"the DSOS and SDSOS hierarchies\" for\npolynomial optimization problems (POPs) and purports that this refutes claims\nin our extended abstract [4] and slides in [3]. The goal of this paper is to\nclarify that neither [4], nor [3], and certainly not our full paper [5], ever\ndefined DSOS or SDSOS hierarchies as it is done in [8]. It goes without saying\nthat no claims about convergence properties of the hierarchies in [8] were ever\nmade as a consequence. What was stated in [4,3] was completely different: we\nstated that there exist hierarchies based on DSOS and SDSOS optimization that\nconverge. This is indeed true as we discuss in this response. We also emphasize\nthat we were well aware that some (S)DSOS hierarchies do not converge even if\ntheir natural SOS counterparts do. This is readily implied by an example in our\nprior work [5], which makes the counterexample in [8] superfluous. Finally, we\nprovide concrete counterarguments to claims made in [8] that aim to challenge\nthe scalability improvements obtained by DSOS and SDSOS optimization as\ncompared to sum of squares (SOS) optimization.\n  [3] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS: More tractable alternatives\nto SOS. Slides at the meeting on Geometry and Algebra of Linear Matrix\nInequalities, CIRM, Marseille, 2013. [4] A. A. Ahmadi and A. Majumdar. DSOS and\nSDSOS optimization: LP and SOCP-based alternatives to sum of squares\noptimization. In proceedings of the 48th annual IEEE Conference on Information\nSciences and Systems, 2014. [5] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS\noptimization: more tractable alternatives to sum of squares and semidefinite\noptimization. arXiv:1706.02586, 2017. [8] C. Josz. Counterexample to global\nconvergence of DSOS and SDSOS hierarchies. arXiv:1707.02964, 2017.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 00:22:00 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "1710.02924", "submitter": "Chuanhou Gao", "authors": "Shaohan Chen, Chuanhou Gao, and Ping Zhang", "title": "Enhancing Interpretability of Black-box Soft-margin SVM by Integrating\n  Data-based Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability often makes black-box models difficult to be\napplied to many practical domains. For this reason, the current work, from the\nblack-box model input port, proposes to incorporate data-based prior\ninformation into the black-box soft-margin SVM model to enhance its\ninterpretability. The concept and incorporation mechanism of data-based prior\ninformation are successively developed, based on which the interpretable or\npartly interpretable SVM optimization model is designed and then solved through\nhandily rewriting the optimization problem as a nonlinear quadratic programming\nproblem. An algorithm for mining data-based linear prior information from data\nset is also proposed, which generates a linear expression with respect to two\nappropriate inputs identified from all inputs of system. At last, the proposed\ninterpretability enhancement strategy is applied to eight benchmark examples\nfor effectiveness exhibition.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 03:06:32 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 13:53:29 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Chen", "Shaohan", ""], ["Gao", "Chuanhou", ""], ["Zhang", "Ping", ""]]}, {"id": "1710.02950", "submitter": "Rui Zhuang", "authors": "Rui Zhuang and Johannes Lederer", "title": "Maximum Regularized Likelihood Estimators: A General Prediction Theory\n  and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum regularized likelihood estimators (MRLEs) are arguably the most\nestablished class of estimators in high-dimensional statistics. In this paper,\nwe derive guarantees for MRLEs in Kullback-Leibler divergence, a general\nmeasure of prediction accuracy. We assume only that the densities have a convex\nparametrization and that the regularization is definite and positive\nhomogenous. The results thus apply to a very large variety of models and\nestimators, such as tensor regression and graphical models with convex and\nnon-convex regularized methods. A main conclusion is that MRLEs are broadly\nconsistent in prediction - regardless of whether restricted eigenvalues or\nsimilar conditions hold.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 06:16:50 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 05:13:06 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Zhuang", "Rui", ""], ["Lederer", "Johannes", ""]]}, {"id": "1710.02952", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Aritra Guha and XuanLong Nguyen", "title": "Conic Scan-and-Cover algorithms for nonparametric topic modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new algorithms for topic modeling when the number of topics is\nunknown. Our approach relies on an analysis of the concentration of mass and\nangular geometry of the topic simplex, a convex polytope constructed by taking\nthe convex hull of vertices representing the latent topics. Our algorithms are\nshown in practice to have accuracy comparable to a Gibbs sampler in terms of\ntopic estimation, which requires the number of topics be given. Moreover, they\nare one of the fastest among several state of the art parametric techniques.\nStatistical consistency of our estimator is established under some conditions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 06:28:03 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Guha", "Aritra", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1710.02971", "submitter": "Jiezhong Qiu", "authors": "Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, Jie Tang", "title": "Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE,\n  and node2vec", "comments": "9 pages, published in WSDM 2018 proceedings", "journal-ref": null, "doi": "10.1145/3159652.3159706", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the invention of word2vec, the skip-gram model has significantly\nadvanced the research of network embedding, such as the recent emergence of the\nDeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of\nthe aforementioned models with negative sampling can be unified into the matrix\nfactorization framework with closed forms. Our analysis and proofs reveal that:\n(1) DeepWalk empirically produces a low-rank transformation of a network's\nnormalized Laplacian matrix; (2) LINE, in theory, is a special case of DeepWalk\nwhen the size of vertices' context is set to one; (3) As an extension of LINE,\nPTE can be viewed as the joint factorization of multiple networks' Laplacians;\n(4) node2vec is factorizing a matrix related to the stationary distribution and\ntransition probability tensor of a 2nd-order random walk. We further provide\nthe theoretical connections between skip-gram based network embedding\nalgorithms and the theory of graph Laplacian. Finally, we present the NetMF\nmethod as well as its approximation algorithm for computing network embedding.\nOur method offers significant improvements over DeepWalk and LINE for\nconventional network mining tasks. This work lays the theoretical foundation\nfor skip-gram based network embedding methods, leading to a better\nunderstanding of latent network representation learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 07:28:46 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 02:38:00 GMT"}, {"version": "v3", "created": "Tue, 12 Dec 2017 06:33:35 GMT"}, {"version": "v4", "created": "Thu, 8 Feb 2018 09:51:03 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Qiu", "Jiezhong", ""], ["Dong", "Yuxiao", ""], ["Ma", "Hao", ""], ["Li", "Jian", ""], ["Wang", "Kuansan", ""], ["Tang", "Jie", ""]]}, {"id": "1710.03013", "submitter": "Marco Jacopo Ferrarotti", "authors": "Marco Jacopo Ferrarotti, Sergio Decherchi and Walter Rocchia", "title": "Distributed Kernel K-Means for Large Scale Clustering", "comments": "Conference paper", "journal-ref": "3rd International Conference on Artificial Intelligence and Soft\n  Computing, Computer Science & Information Technology, AIRCC, Vol 7, Number\n  10, August 2017", "doi": "10.5121/csit.2017.71015", "report-no": null, "categories": "cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering samples according to an effective metric and/or vector space\nrepresentation is a challenging unsupervised learning task with a wide spectrum\nof applications. Among several clustering algorithms, k-means and its\nkernelized version have still a wide audience because of their conceptual\nsimplicity and efficacy. However, the systematic application of the kernelized\nversion of k-means is hampered by its inherent square scaling in memory with\nthe number of samples. In this contribution, we devise an approximate strategy\nto minimize the kernel k-means cost function in which the trade-off between\naccuracy and velocity is automatically ruled by the available system memory.\nMoreover, we define an ad-hoc parallelization scheme well suited for hybrid\ncpu-gpu state-of-the-art parallel architectures. We proved the effectiveness\nboth of the approximation scheme and of the parallelization method on standard\nUCI datasets and on molecular dynamics (MD) data in the realm of computational\nchemistry. In this applicative domain, clustering can play a key role for both\nquantitively estimating kinetics rates via Markov State Models or to give\nqualitatively a human compatible summarization of the underlying chemical\nphenomenon under study. For these reasons, we selected it as a valuable\nreal-world application scenario.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 09:55:24 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Ferrarotti", "Marco Jacopo", ""], ["Decherchi", "Sergio", ""], ["Rocchia", "Walter", ""]]}, {"id": "1710.03035", "submitter": "Wenzhe Li", "authors": "Wenzhe Li, Dong Guo, Greg Ver Steeg, Aram Galstyan", "title": "Unifying Local and Global Change Detection in Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world networks are complex dynamical systems, where both local\n(e.g., changing node attributes) and global (e.g., changing network topology)\nprocesses unfold over time. Local dynamics may provoke global changes in the\nnetwork, and the ability to detect such effects could have profound\nimplications for a number of real-world problems. Most existing techniques\nfocus individually on either local or global aspects of the problem or treat\nthe two in isolation from each other. In this paper we propose a novel network\nmodel that simultaneously accounts for both local and global dynamics. To the\nbest of our knowledge, this is the first attempt at modeling and detecting\nlocal and global change points on dynamic networks via a unified generative\nframework. Our model is built upon the popular mixed membership stochastic\nblockmodels (MMSB) with sparse co-evolving patterns. We derive an efficient\nstochastic gradient Langevin dynamics (SGLD) sampler for our proposed model,\nwhich allows it to scale to potentially very large networks. Finally, we\nvalidate our model on both synthetic and real-world data and demonstrate its\nsuperiority over several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 11:34:29 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Li", "Wenzhe", ""], ["Guo", "Dong", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1710.03070", "submitter": "Brian DePasquale", "authors": "Brian DePasquale, Christopher J. Cueva, Kanaka Rajan, G. Sean Escola,\n  L.F. Abbott", "title": "full-FORCE: A Target-Based Method for Training Recurrent Networks", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0191527", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trained recurrent networks are powerful tools for modeling dynamic neural\ncomputations. We present a target-based method for modifying the full\nconnectivity matrix of a recurrent network to train it to perform tasks\ninvolving temporally complex input/output transformations. The method\nintroduces a second network during training to provide suitable \"target\"\ndynamics useful for performing the task. Because it exploits the full recurrent\nconnectivity, the method produces networks that perform tasks with fewer\nneurons and greater noise robustness than traditional least-squares (FORCE)\napproaches. In addition, we show how introducing additional input signals into\nthe target-generating network, which act as task hints, greatly extends the\nrange of tasks that can be learned and provides control over the complexity and\nnature of the dynamics of the trained, task-performing network.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 13:00:08 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["DePasquale", "Brian", ""], ["Cueva", "Christopher J.", ""], ["Rajan", "Kanaka", ""], ["Escola", "G. Sean", ""], ["Abbott", "L. F.", ""]]}, {"id": "1710.03184", "submitter": "Pratik Gajane", "authors": "Pratik Gajane and Mykola Pechenizkiy", "title": "On Formalizing Fairness in Prediction with Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms for prediction are increasingly being used in\ncritical decisions affecting human lives. Various fairness formalizations, with\nno firm consensus yet, are employed to prevent such algorithms from\nsystematically discriminating against people based on certain attributes\nprotected by law. The aim of this article is to survey how fairness is\nformalized in the machine learning literature for the task of prediction and\npresent these formalizations with their corresponding notions of distributive\njustice from the social sciences literature. We provide theoretical as well as\nempirical critiques of these notions from the social sciences literature and\nexplain how these critiques limit the suitability of the corresponding fairness\nformalizations to certain domains. We also suggest two notions of distributive\njustice which address some of these critiques and discuss avenues for\nprospective fairness formalizations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 16:39:31 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 10:12:23 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 08:22:01 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Gajane", "Pratik", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1710.03222", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Christoph Bergmeir, Slawek Smyl", "title": "Forecasting Across Time Series Databases using Recurrent Neural Networks\n  on Groups of Similar Series: A Clustering Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Big Data, nowadays in many applications databases\ncontaining large quantities of similar time series are available. Forecasting\ntime series in these domains with traditional univariate forecasting procedures\nleaves great potentials for producing accurate forecasts untapped. Recurrent\nneural networks (RNNs), and in particular Long Short-Term Memory (LSTM)\nnetworks, have proven recently that they are able to outperform\nstate-of-the-art univariate time series forecasting methods in this context\nwhen trained across all available time series. However, if the time series\ndatabase is heterogeneous, accuracy may degenerate, so that on the way towards\nfully automatic forecasting methods in this space, a notion of similarity\nbetween the time series needs to be built into the methods. To this end, we\npresent a prediction model that can be used with different types of RNN models\non subgroups of similar time series, which are identified by time series\nclustering techniques. We assess our proposed methodology using LSTM networks,\na widely popular RNN variant. Our method achieves competitive results on\nbenchmarking datasets under competition evaluation procedures. In particular,\nin terms of mean sMAPE accuracy, it consistently outperforms the baseline LSTM\nmodel and outperforms all other methods on the CIF2016 forecasting competition\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 04:08:15 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 08:03:34 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Bandara", "Kasun", ""], ["Bergmeir", "Christoph", ""], ["Smyl", "Slawek", ""]]}, {"id": "1710.03263", "submitter": "Oren Elisha", "authors": "Oren Elisha and Shai Dekel", "title": "Function space analysis of deep learning representation layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a function space approach to Representation Learning\nand the analysis of the representation layers in deep learning architectures.\nWe show how to compute a weak-type Besov smoothness index that quantifies the\ngeometry of the clustering in the feature space. This approach was already\napplied successfully to improve the performance of machine learning algorithms\nsuch as the Random Forest and tree-based Gradient Boosting. Our experiments\ndemonstrate that in well-known and well-performing trained networks, the Besov\nsmoothness of the training set, measured in the corresponding hidden layer\nfeature map representation, increases from layer to layer. We also contribute\nto the understanding of generalization by showing how the Besov smoothness of\nthe representations, decreases as we add more mis-labeling to the training\ndata. We hope this approach will contribute to the de-mystification of some\naspects of deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 18:52:42 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Elisha", "Oren", ""], ["Dekel", "Shai", ""]]}, {"id": "1710.03266", "submitter": "Yun Yang", "authors": "Yun Yang and Debdeep Pati and Anirban Bhattacharya", "title": "$\\alpha$-Variational Inference with Statistical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of variational approximations to Bayesian posterior\ndistributions, called $\\alpha$-VB, with provable statistical guarantees. The\nstandard variational approximation is a special case of $\\alpha$-VB with\n$\\alpha=1$. When $\\alpha \\in(0,1]$, a novel class of variational inequalities\nare developed for linking the Bayes risk under the variational approximation to\nthe objective function in the variational optimization problem, implying that\nmaximizing the evidence lower bound in variational inference has the effect of\nminimizing the Bayes risk within the variational density family. Operating in a\nfrequentist setup, the variational inequalities imply that point estimates\nconstructed from the $\\alpha$-VB procedure converge at an optimal rate to the\ntrue parameter in a wide range of problems. We illustrate our general theory\nwith a number of examples, including the mean-field variational approximation\nto (low)-high-dimensional Bayesian linear regression with spike and slab\npriors, mixture of Gaussian models, latent Dirichlet allocation, and (mixture\nof) Gaussian variational approximation in regular parametric models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 19:10:14 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 20:00:48 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Yang", "Yun", ""], ["Pati", "Debdeep", ""], ["Bhattacharya", "Anirban", ""]]}, {"id": "1710.03268", "submitter": "Matthew K. Breitenstein Ph.D.", "authors": "Alena Orlenko, Jason H. Moore, Patryk Orzechowski, Randal S. Olson,\n  Junmei Cairns, Pedro J. Caraballo, Richard M. Weinshilboum, Liewei Wang,\n  Matthew K. Breitenstein", "title": "Considerations of automated machine learning in clinical metabolic\n  profiling: Altered homocysteine plasma concentration associated with\n  metformin exposure", "comments": "Manuscript - containing supplementary information - accepted\n  (9/15/2017) for publication within Pacific Symposium on Biocomputing 2018\n  <https://psb.stanford.edu/psb-online>. Original supplementary information\n  includes an additional 6 pages of content (18 pages total) and 8 figures (13\n  figures total)", "journal-ref": "Pacific Symposium on Biocomputing, 2018 (Vol. 23)", "doi": null, "report-no": null, "categories": "q-bio.MN q-bio.PE q-bio.QM stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the maturation of metabolomics science and proliferation of biobanks,\nclinical metabolic profiling is an increasingly opportunistic frontier for\nadvancing translational clinical research. Automated Machine Learning (AutoML)\napproaches provide exciting opportunity to guide feature selection in agnostic\nmetabolic profiling endeavors, where potentially thousands of independent data\npoints must be evaluated. In previous research, AutoML using high-dimensional\ndata of varying types has been demonstrably robust, outperforming traditional\napproaches. However, considerations for application in clinical metabolic\nprofiling remain to be evaluated. Particularly, regarding the robustness of\nAutoML to identify and adjust for common clinical confounders. In this study,\nwe present a focused case study regarding AutoML considerations for using the\nTree-Based Optimization Tool (TPOT) in metabolic profiling of exposure to\nmetformin in a biobank cohort. First, we propose a tandem rank-accuracy measure\nto guide agnostic feature selection and corresponding threshold determination\nin clinical metabolic profiling endeavors. Second, while AutoML, using default\nparameters, demonstrated potential to lack sensitivity to low-effect\nconfounding clinical covariates, we demonstrated residual training and\nadjustment of metabolite features as an easily applicable approach to ensure\nAutoML adjustment for potential confounding characteristics. Finally, we\npresent increased homocysteine with long-term exposure to metformin as a\npotentially novel, non-replicated metabolite association suggested by TPOT; an\nassociation not identified in parallel clinical metabolic profiling endeavors.\nWhile considerations are recommended, including adjustment approaches for\nclinical confounders, AutoML presents an exciting tool to enhance clinical\nmetabolic profiling and advance translational research endeavors.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 19:19:57 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Orlenko", "Alena", ""], ["Moore", "Jason H.", ""], ["Orzechowski", "Patryk", ""], ["Olson", "Randal S.", ""], ["Cairns", "Junmei", ""], ["Caraballo", "Pedro J.", ""], ["Weinshilboum", "Richard M.", ""], ["Wang", "Liewei", ""], ["Breitenstein", "Matthew K.", ""]]}, {"id": "1710.03276", "submitter": "Linh Nghiem", "authors": "Michael Byrd, Linh Nghiem and Jing Cao", "title": "Lagged Exact Bayesian Online Changepoint Detection with Parameter\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying changes in the generative process of sequential data, known as\nchangepoint detection, has become an increasingly important topic for a wide\nvariety of fields. A recently developed approach, which we call EXact Online\nBayesian Changepoint Detection (EXO), has shown reasonable results with\nefficient computation for real time updates. The method is based on a\n\\textit{forward} recursive message-passing algorithm. However, the detected\nchangepoints from these methods are unstable. We propose a new algorithm called\nLagged EXact Online Bayesian Changepoint Detection (LEXO) that improves the\naccuracy and stability of the detection by incorporating $\\ell$-time lags to\nthe inference. The new algorithm adds a recursive \\textit{backward} step to the\nforward EXO and has computational complexity linear in the number of added\nlags. Estimation of parameters associated with regimes is also developed.\nSimulation studies with three common changepoint models show that the detected\nchangepoints from LEXO are much more stable and parameter estimates from LEXO\nhave considerably lower MSE than EXO. We illustrate applicability of the\nmethods with two real world data examples comparing the EXO and LEXO.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 19:34:25 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 03:44:55 GMT"}, {"version": "v3", "created": "Sat, 13 Oct 2018 06:49:57 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Byrd", "Michael", ""], ["Nghiem", "Linh", ""], ["Cao", "Jing", ""]]}, {"id": "1710.03285", "submitter": "Alejandro Molina", "authors": "Alejandro Molina, Alexander Munteanu, Kristian Kersting", "title": "Coresets for Dependency Networks", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications infer the structure of a probabilistic graphical model from\ndata to elucidate the relationships between variables. But how can we train\ngraphical models on a massive data set? In this paper, we show how to construct\ncoresets -compressed data sets which can be used as proxy for the original data\nand have provably bounded worst case error- for Gaussian dependency networks\n(DNs), i.e., cyclic directed graphical models over Gaussians, where the parents\nof each variable are its Markov blanket. Specifically, we prove that Gaussian\nDNs admit coresets of size independent of the size of the data set.\nUnfortunately, this does not extend to DNs over members of the exponential\nfamily in general. As we will prove, Poisson DNs do not admit small coresets.\nDespite this worst-case result, we will provide an argument why our coreset\nconstruction for DNs can still work well in practice on count data. To\ncorroborate our theoretical results, we empirically evaluated the resulting\nCore DNs on real data sets. The results\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 19:49:11 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 08:45:43 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Molina", "Alejandro", ""], ["Munteanu", "Alexander", ""], ["Kersting", "Kristian", ""]]}, {"id": "1710.03297", "submitter": "Alejandro Molina", "authors": "Alejandro Molina, Antonio Vergari, Nicola Di Mauro, Sriraam Natarajan,\n  Floriana Esposito, Kristian Kersting", "title": "Sum-Product Networks for Hybrid Domains", "comments": "16 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While all kinds of mixed data -from personal data, over panel and scientific\ndata, to public and commercial data- are collected and stored, building\nprobabilistic graphical models for these hybrid domains becomes more difficult.\nUsers spend significant amounts of time in identifying the parametric form of\nthe random variables (Gaussian, Poisson, Logit, etc.) involved and learning the\nmixed models. To make this difficult task easier, we propose the first\ntrainable probabilistic deep architecture for hybrid domains that features\ntractable queries. It is based on Sum-Product Networks (SPNs) with piecewise\npolynomial leave distributions together with novel nonparametric decomposition\nand conditioning steps using the Hirschfeld-Gebelein-R\\'enyi Maximum\nCorrelation Coefficient. This relieves the user from deciding a-priori the\nparametric form of the random variables but is still expressive enough to\neffectively approximate any continuous distribution and permits efficient\nlearning and inference. Our empirical evidence shows that the architecture,\ncalled Mixed SPNs, can indeed capture complex distributions across a wide range\nof hybrid domains.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 20:13:21 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 08:40:57 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 09:39:01 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Molina", "Alejandro", ""], ["Vergari", "Antonio", ""], ["Di Mauro", "Nicola", ""], ["Natarajan", "Sriraam", ""], ["Esposito", "Floriana", ""], ["Kersting", "Kristian", ""]]}, {"id": "1710.03344", "submitter": "Kuang Gong", "authors": "Kuang Gong, Jiahui Guan, Kyungsang Kim, Xuezhu Zhang, Georges El\n  Fakhri, Jinyi Qi, Quanzheng Li", "title": "Iterative PET Image Reconstruction Using Convolutional Neural Network\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PET image reconstruction is challenging due to the ill-poseness of the\ninverse problem and limited number of detected photons. Recently deep neural\nnetworks have been widely and successfully used in computer vision tasks and\nattracted growing interests in medical imaging. In this work, we trained a deep\nresidual convolutional neural network to improve PET image quality by using the\nexisting inter-patient information. An innovative feature of the proposed\nmethod is that we embed the neural network in the iterative reconstruction\nframework for image representation, rather than using it as a post-processing\ntool. We formulate the objective function as a constraint optimization problem\nand solve it using the alternating direction method of multipliers (ADMM)\nalgorithm. Both simulation data and hybrid real data are used to evaluate the\nproposed method. Quantification results show that our proposed iterative neural\nnetwork method can outperform the neural network denoising and conventional\npenalized maximum likelihood methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 22:51:28 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Gong", "Kuang", ""], ["Guan", "Jiahui", ""], ["Kim", "Kyungsang", ""], ["Zhang", "Xuezhu", ""], ["Fakhri", "Georges El", ""], ["Qi", "Jinyi", ""], ["Li", "Quanzheng", ""]]}, {"id": "1710.03442", "submitter": "Ryo Iwaki", "authors": "Ryo Iwaki and Minoru Asada", "title": "On- and Off-Policy Monotonic Policy Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonic policy improvement and off-policy learning are two main desirable\nproperties for reinforcement learning algorithms. In this paper, by lower\nbounding the performance difference of two policies, we show that the monotonic\npolicy improvement is guaranteed from on- and off-policy mixture samples. An\noptimization procedure which applies the proposed bound can be regarded as an\noff-policy natural policy gradient method. In order to support the theoretical\nresult, we provide a trust region policy optimization method using experience\nreplay as a naive application of our bound, and evaluate its performance in two\nclassical benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 08:18:24 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 08:37:34 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Iwaki", "Ryo", ""], ["Asada", "Minoru", ""]]}, {"id": "1710.03444", "submitter": "Martin Trapp", "authors": "Martin Trapp, Tamas Madl, Robert Peharz, Franz Pernkopf, Robert Trappl", "title": "Safe Semi-Supervised Learning of Sum-Product Networks", "comments": "Conference on Uncertainty in Artificial Intelligence (UAI), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several domains obtaining class annotations is expensive while at the same\ntime unlabelled data are abundant. While most semi-supervised approaches\nenforce restrictive assumptions on the data distribution, recent work has\nmanaged to learn semi-supervised models in a non-restrictive regime. However,\nso far such approaches have only been proposed for linear models. In this work,\nwe introduce semi-supervised parameter learning for Sum-Product Networks\n(SPNs). SPNs are deep probabilistic models admitting inference in linear time\nin number of network edges. Our approach has several advantages, as it (1)\nallows generative and discriminative semi-supervised learning, (2) guarantees\nthat adding unlabelled data can increase, but not degrade, the performance\n(safe), and (3) is computationally efficient and does not enforce restrictive\nassumptions on the data distribution. We show on a variety of data sets that\nsafe semi-supervised learning with SPNs is competitive compared to\nstate-of-the-art and can lead to a better generative and discriminative\nobjective value than a purely supervised approach.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 08:27:42 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Trapp", "Martin", ""], ["Madl", "Tamas", ""], ["Peharz", "Robert", ""], ["Pernkopf", "Franz", ""], ["Trappl", "Robert", ""]]}, {"id": "1710.03487", "submitter": "Jacopo Cavazza", "authors": "Jacopo Cavazza, Connor Lane, Benjamin D. Haeffele, Vittorio Murino,\n  Ren\\'e Vidal", "title": "An Analysis of Dropout for Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a simple yet effective algorithm for regularizing neural networks\nby randomly dropping out units through Bernoulli multiplicative noise, and for\nsome restricted problem classes, such as linear or logistic regression, several\ntheoretical studies have demonstrated the equivalence between dropout and a\nfully deterministic optimization problem with data-dependent Tikhonov\nregularization. This work presents a theoretical analysis of dropout for matrix\nfactorization, where Bernoulli random variables are used to drop a factor,\nthereby attempting to control the size of the factorization. While recent work\nhas demonstrated the empirical effectiveness of dropout for matrix\nfactorization, a theoretical understanding of the regularization properties of\ndropout in this context remains elusive. This work demonstrates the equivalence\nbetween dropout and a fully deterministic model for matrix factorization in\nwhich the factors are regularized by the sum of the product of the norms of the\ncolumns. While the resulting regularizer is closely related to a variational\nform of the nuclear norm, suggesting that dropout may limit the size of the\nfactorization, we show that it is possible to trivially lower the objective\nvalue by doubling the size of the factorization. We show that this problem is\ncaused by the use of a fixed dropout rate, which motivates the use of a rate\nthat increases with the size of the factorization. Synthetic experiments\nvalidate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 10:03:43 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Cavazza", "Jacopo", ""], ["Lane", "Connor", ""], ["Haeffele", "Benjamin D.", ""], ["Murino", "Vittorio", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1710.03600", "submitter": "Zheng-Chu Guo", "authors": "Zheng-Chu Guo and Lei Shi", "title": "Fast and Strong Convergence of Online Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the online learning algorithm without explicit\nregularization terms. This algorithm is essentially a stochastic gradient\ndescent scheme in a reproducing kernel Hilbert space (RKHS). The polynomially\ndecaying step size in each iteration can play a role of regularization to\nensure the generalization ability of online learning algorithm. We develop a\nnovel capacity dependent analysis on the performance of the last iterate of\nonline learning algorithm. The contribution of this paper is two-fold. First,\nour nice analysis can lead to the convergence rate in the standard mean square\ndistance which is the best so far. Second, we establish, for the first time,\nthe strong convergence of the last iterate with polynomially decaying step\nsizes in the RKHS norm. We demonstrate that the theoretical analysis\nestablished in this paper fully exploits the fine structure of the underlying\nRKHS, and thus can lead to sharp error estimates of online learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 13:53:45 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Guo", "Zheng-Chu", ""], ["Shi", "Lei", ""]]}, {"id": "1710.03608", "submitter": "Jungwoo Lee", "authors": "Jungwoo Lee, Dongjin Choi, and Lee Sael", "title": "CTD: Fast, Accurate, and Interpretable Method for Static and Dynamic\n  Tensor Decompositions", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0200579", "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we find patterns and anomalies in a tensor, or multi-dimensional\narray, in an efficient and directly interpretable way? How can we do this in an\nonline environment, where a new tensor arrives each time step? Finding patterns\nand anomalies in a tensor is a crucial problem with many applications,\nincluding building safety monitoring, patient health monitoring, cyber\nsecurity, terrorist detection, and fake user detection in social networks.\nStandard PARAFAC and Tucker decomposition results are not directly\ninterpretable. Although a few sampling-based methods have previously been\nproposed towards better interpretability, they need to be made faster, more\nmemory efficient, and more accurate.\n  In this paper, we propose CTD, a fast, accurate, and directly interpretable\ntensor decomposition method based on sampling. CTD-S, the static version of\nCTD, provably guarantees a high accuracy that is 17 ~ 83x more accurate than\nthat of the state-of-the-art method. Also, CTD-S is made 5 ~ 86x faster, and 7\n~ 12x more memory-efficient than the state-of-the-art method by removing\nredundancy. CTD-D, the dynamic version of CTD, is the first interpretable\ndynamic tensor decomposition method ever proposed. Also, it is made 2 ~ 3x\nfaster than already fast CTD-S by exploiting factors at previous time step and\nby reordering operations. With CTD, we demonstrate how the results can be\neffectively interpreted in the online distributed denial of service (DDoS)\nattack detection.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 09:44:41 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Lee", "Jungwoo", ""], ["Choi", "Dongjin", ""], ["Sael", "Lee", ""]]}, {"id": "1710.03627", "submitter": "Olivier Colliot", "authors": "Pascal Lu, Olivier Colliot", "title": "Multilevel Modeling with Structured Penalties for Classification from\n  Imaging Genetics data", "comments": null, "journal-ref": "3rd MICCAI Workshop on Imaging Genetics (MICGen 2017), Graphs in\n  Biomedical Image Analysis, Computational Anatomy and Imaging Genetics,\n  Lecture Notes in Computer Science, 1 (21), pp.230-240, Qu\\'ebec City, Canada.\n  Springer, 2017", "doi": "10.1007/978-3-319-67675-3_21", "report-no": null, "categories": "stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a framework for automatic classification of\npatients from multimodal genetic and brain imaging data by optimally combining\nthem. Additive models with unadapted penalties (such as the classical group\nlasso penalty or $L_1$-multiple kernel learning) treat all modalities in the\nsame manner and can result in undesirable elimination of specific modalities\nwhen their contributions are unbalanced. To overcome this limitation, we\nintroduce a multilevel model that combines imaging and genetics and that\nconsiders joint effects between these two modalities for diagnosis prediction.\nFurthermore, we propose a framework allowing to combine several penalties\ntaking into account the structure of the different types of data, such as a\ngroup lasso penalty over the genetic modality and a $L_2$-penalty on imaging\nmodalities. Finally , we propose a fast optimization algorithm, based on a\nproximal gradient method. The model has been evaluated on genetic (single\nnucleotide polymorphisms-SNP) and imaging (anatomical MRI measures) data from\nthe ADNI database, and compared to additive models. It exhibits good\nperformances in AD diagnosis; and at the same time, reveals relationships\nbetween genes, brain regions and the disease status.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 14:39:18 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Lu", "Pascal", ""], ["Colliot", "Olivier", ""]]}, {"id": "1710.03634", "submitter": "Laurent De Vito", "authors": "Laurent de Vito", "title": "LinXGBoost: Extension of XGBoost to Generalized Local Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XGBoost is often presented as the algorithm that wins every ML competition.\nSurprisingly, this is true even though predictions are piecewise constant. This\nmight be justified in high dimensional input spaces, but when the number of\nfeatures is low, a piecewise linear model is likely to perform better. XGBoost\nwas extended into LinXGBoost that stores at each leaf a linear model. This\nextension, equivalent to piecewise regularized least-squares, is particularly\nattractive for regression of functions that exhibits jumps or discontinuities.\nThose functions are notoriously hard to regress. Our extension is compared to\nthe vanilla XGBoost and Random Forest in experiments on both synthetic and\nreal-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 14:52:47 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["de Vito", "Laurent", ""]]}, {"id": "1710.03667", "submitter": "Madhu Advani", "authors": "Madhu S. Advani, Andrew M. Saxe", "title": "High-dimensional dynamics of generalization error in neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform an average case analysis of the generalization dynamics of large\nneural networks trained using gradient descent. We study the\npractically-relevant \"high-dimensional\" regime where the number of free\nparameters in the network is on the order of or even larger than the number of\nexamples in the dataset. Using random matrix theory and exact solutions in\nlinear models, we derive the generalization error and training error dynamics\nof learning and analyze how they depend on the dimensionality of data and\nsignal to noise ratio of the learning problem. We find that the dynamics of\ngradient descent learning naturally protect against overtraining and\noverfitting in large networks. Overtraining is worst at intermediate network\nsizes, when the effective number of free parameters equals the number of\nsamples, and thus can be reduced by making a network smaller or larger.\nAdditionally, in the high-dimensional regime, low generalization error requires\nstarting with small initial weights. We then turn to non-linear neural\nnetworks, and show that making networks very large does not harm their\ngeneralization performance. On the contrary, it can in fact reduce\novertraining, even without early stopping or regularization of any sort. We\nidentify two novel phenomena underlying this behavior in overcomplete models:\nfirst, there is a frozen subspace of the weights in which no learning occurs\nunder gradient descent; and second, the statistical properties of the\nhigh-dimensional regime yield better-conditioned input correlations which\nprotect against overtraining. We demonstrate that naive application of\nworst-case theories such as Rademacher complexity are inaccurate in predicting\nthe generalization performance of deep neural networks, and derive an\nalternative bound which incorporates the frozen subspace and conditioning\neffects and qualitatively matches the behavior observed in simulation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 15:48:12 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Advani", "Madhu S.", ""], ["Saxe", "Andrew M.", ""]]}, {"id": "1710.03740", "submitter": "Sharan Narang", "authors": "Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos,\n  Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev,\n  Ganesh Venkatesh, Hao Wu", "title": "Mixed Precision Training", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have enabled progress in a wide variety of applications.\nGrowing the size of the neural network typically results in improved accuracy.\nAs model sizes grow, the memory and compute requirements for training these\nmodels also increases. We introduce a technique to train deep neural networks\nusing half precision floating point numbers. In our technique, weights,\nactivations and gradients are stored in IEEE half-precision format.\nHalf-precision floating numbers have limited numerical range compared to\nsingle-precision numbers. We propose two techniques to handle this loss of\ninformation. Firstly, we recommend maintaining a single-precision copy of the\nweights that accumulates the gradients after each optimizer step. This\nsingle-precision copy is rounded to half-precision format during training.\nSecondly, we propose scaling the loss appropriately to handle the loss of\ninformation with half-precision gradients. We demonstrate that this approach\nworks for a wide variety of models including convolution neural networks,\nrecurrent neural networks and generative adversarial networks. This technique\nworks for large scale models with more than 100 million parameters trained on\nlarge datasets. Using this approach, we can reduce the memory consumption of\ndeep learning models by nearly 2x. In future processors, we can also expect a\nsignificant computation speedup using half-precision hardware units.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 17:42:04 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 19:09:05 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 20:04:02 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Micikevicius", "Paulius", ""], ["Narang", "Sharan", ""], ["Alben", "Jonah", ""], ["Diamos", "Gregory", ""], ["Elsen", "Erich", ""], ["Garcia", "David", ""], ["Ginsburg", "Boris", ""], ["Houston", "Michael", ""], ["Kuchaiev", "Oleksii", ""], ["Venkatesh", "Ganesh", ""], ["Wu", "Hao", ""]]}, {"id": "1710.03850", "submitter": "David Isele", "authors": "David Isele, Mohammad Rostami, Eric Eaton", "title": "Using Task Descriptions in Lifelong Machine Learning for Improved\n  Performance and Zero-Shot Transfer", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge transfer between tasks can improve the performance of learned\nmodels, but requires an accurate estimate of the inter-task relationships to\nidentify the relevant knowledge to transfer. These inter-task relationships are\ntypically estimated based on training data for each task, which is inefficient\nin lifelong learning settings where the goal is to learn each consecutive task\nrapidly from as little data as possible. To reduce this burden, we develop a\nlifelong learning method based on coupled dictionary learning that utilizes\nhigh-level task descriptions to model the inter-task relationships. We show\nthat using task descriptors improves the performance of the learned task\npolicies, providing both theoretical justification for the benefit and\nempirical demonstration of the improvement across a variety of learning\nproblems. Given only the descriptor for a new task, the lifelong learner is\nalso able to accurately predict a model for the new task through zero-shot\nlearning using the coupled dictionary, eliminating the need to gather training\ndata before addressing the task.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 22:57:43 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Isele", "David", ""], ["Rostami", "Mohammad", ""], ["Eaton", "Eric", ""]]}, {"id": "1710.03923", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad and Daoqiang Zhang", "title": "Deep Hyperalignment", "comments": "31st Conference on Neural Information Processing Systems (NIPS 2017),\n  Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Deep Hyperalignment (DHA) as a regularized, deep\nextension, scalable Hyperalignment (HA) method, which is well-suited for\napplying functional alignment to fMRI datasets with nonlinearity,\nhigh-dimensionality (broad ROI), and a large number of subjects. Unlink\nprevious methods, DHA is not limited by a restricted fixed kernel function.\nFurther, it uses a parametric approach, rank-$m$ Singular Value Decomposition\n(SVD), and stochastic gradient descent for optimization. Therefore, DHA has a\nsuitable time complexity for large datasets, and DHA does not require the\ntraining data when it computes the functional alignment for a new subject.\nExperimental studies on multi-subject fMRI analysis confirm that the DHA method\nachieves superior performance to other state-of-the-art HA algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 06:21:45 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1710.03924", "submitter": "Yen-Chi Chen", "authors": "Ruqian Chen, Yen-Chi Chen, Wei Guo, Ashis G. Banerjee", "title": "A Note on Community Trees in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of community trees that summarizes topological\nstructures within a network. A community tree is a tree structure representing\nclique communities from the clique percolation method (CPM). The community tree\nalso generates a persistent diagram. Community trees and persistent diagrams\nreveal topological structures of the underlying networks and can be used as\nvisualization tools. We study the stability of community trees and derive a\nquantity called the total star number (TSN) that presents an upper bound on the\nchange of community trees. Our findings provide a topological interpretation\nfor the stability of communities generated by the CPM.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 06:23:55 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Chen", "Ruqian", ""], ["Chen", "Yen-Chi", ""], ["Guo", "Wei", ""], ["Banerjee", "Ashis G.", ""]]}, {"id": "1710.03971", "submitter": "Markus Grasmair", "authors": "Markus Grasmair, Timo Klock, and Valeriya Naumova", "title": "Adaptive multi-penalty regularization based on a generalized Lasso path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many algorithms, parameter tuning remains a challenging and critical\ntask, which becomes tedious and infeasible in a multi-parameter setting.\nMulti-penalty regularization, successfully used for solving undetermined sparse\nregression of problems of unmixing type where signal and noise are additively\nmixed, is one of such examples. In this paper, we propose a novel algorithmic\nframework for an adaptive parameter choice in multi-penalty regularization with\na focus on the correct support recovery. Building upon the theory of\nregularization paths and algorithms for single-penalty functionals, we extend\nthese ideas to a multi-penalty framework by providing an efficient procedure\nfor the construction of regions containing structurally similar solutions,\ni.e., solutions with the same sparsity and sign pattern, over the whole range\nof parameters. Combining this with a model selection criterion, we can choose\nregularization parameters in a data-adaptive manner. Another advantage of our\nalgorithm is that it provides an overview on the solution stability over the\nwhole range of parameters. This can be further exploited to obtain additional\ninsights into the problem of interest. We provide a numerical analysis of our\nmethod and compare it to the state-of-the-art single-penalty algorithms for\ncompressed sensing problems in order to demonstrate the robustness and power of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 09:12:45 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Grasmair", "Markus", ""], ["Klock", "Timo", ""], ["Naumova", "Valeriya", ""]]}, {"id": "1710.04008", "submitter": "Yin Cheng Ng", "authors": "Yin Cheng Ng, Ricardo Silva", "title": "A Dynamic Edge Exchangeable Model for Sparse Temporal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic edge exchangeable network model that can capture sparse\nconnections observed in real temporal networks, in contrast to existing models\nwhich are dense. The model achieved superior link prediction accuracy on\nmultiple data sets when compared to a dynamic variant of the blockmodel, and is\nable to extract interpretable time-varying community structures from the data.\nIn addition to sparsity, the model accounts for the effect of social influence\non vertices' future behaviours. Compared to the dynamic blockmodels, our model\nhas a smaller latent space. The compact latent space requires a smaller number\nof parameters to be estimated in variational inference and results in a\ncomputationally friendly inference algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 11:20:40 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Ng", "Yin Cheng", ""], ["Silva", "Ricardo", ""]]}, {"id": "1710.04019", "submitter": "Bertrand Michel", "authors": "Fr\\'ed\\'eric Chazal (1), Bertrand Michel (2) ((1) DATASHAPE, (2) LSTA)", "title": "An introduction to Topological Data Analysis: fundamental and practical\n  aspects for data scientists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.AT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis is a recent and fast growing field providing a set\nof new topological and geometric tools to infer relevant features for possibly\ncomplex data. This paper is a brief introduction, through a few selected\ntopics, to basic fundamental and practical aspects of \\tda\\ for non experts.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 11:53:32 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 08:31:59 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Chazal", "Fr\u00e9d\u00e9ric", "", "DATASHAPE"], ["Michel", "Bertrand", "", "LSTA"]]}, {"id": "1710.04045", "submitter": "Ivan Glasser", "authors": "Ivan Glasser, Nicola Pancotti, Moritz August, Ivan D. Rodriguez, J.\n  Ignacio Cirac", "title": "Neural-Network Quantum States, String-Bond States, and Chiral\n  Topological States", "comments": "15 pages, 7 figures", "journal-ref": "Phys. Rev. X 8, 011006 (2018)", "doi": "10.1103/PhysRevX.8.011006", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cond-mat.str-el stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-Network Quantum States have been recently introduced as an Ansatz for\ndescribing the wave function of quantum many-body systems. We show that there\nare strong connections between Neural-Network Quantum States in the form of\nRestricted Boltzmann Machines and some classes of Tensor-Network states in\narbitrary dimensions. In particular we demonstrate that short-range Restricted\nBoltzmann Machines are Entangled Plaquette States, while fully connected\nRestricted Boltzmann Machines are String-Bond States with a nonlocal geometry\nand low bond dimension. These results shed light on the underlying architecture\nof Restricted Boltzmann Machines and their efficiency at representing many-body\nquantum states. String-Bond States also provide a generic way of enhancing the\npower of Neural-Network Quantum States and a natural generalization to systems\nwith larger local Hilbert space. We compare the advantages and drawbacks of\nthese different classes of states and present a method to combine them\ntogether. This allows us to benefit from both the entanglement structure of\nTensor Networks and the efficiency of Neural-Network Quantum States into a\nsingle Ansatz capable of targeting the wave function of strongly correlated\nsystems. While it remains a challenge to describe states with chiral\ntopological order using traditional Tensor Networks, we show that\nNeural-Network Quantum States and their String-Bond States extension can\ndescribe a lattice Fractional Quantum Hall state exactly. In addition, we\nprovide numerical evidence that Neural-Network Quantum States can approximate a\nchiral spin liquid with better accuracy than Entangled Plaquette States and\nlocal String-Bond States. Our results demonstrate the efficiency of neural\nnetworks to describe complex quantum wave functions and pave the way towards\nthe use of String-Bond States as a tool in more traditional machine-learning\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 13:03:19 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 14:42:54 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2018 10:38:50 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Glasser", "Ivan", ""], ["Pancotti", "Nicola", ""], ["August", "Moritz", ""], ["Rodriguez", "Ivan D.", ""], ["Cirac", "J. Ignacio", ""]]}, {"id": "1710.04062", "submitter": "Alec Koppel", "authors": "Alec Koppel, Santiago Paternain, Cedric Richard, Alejandro Ribeiro", "title": "Decentralized Online Learning with Kernels", "comments": "Submitted to IEEE TSP. Partial results appear in 2017 IEEE GlobalSIP.\n  arXiv admin note: text overlap with arXiv:1612.04111", "journal-ref": null, "doi": "10.1109/TSP.2018.2830299", "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-agent stochastic optimization problems over reproducing\nkernel Hilbert spaces (RKHS). In this setting, a network of interconnected\nagents aims to learn decision functions, i.e., nonlinear statistical models,\nthat are optimal in terms of a global convex functional that aggregates data\nacross the network, with only access to locally and sequentially observed\nsamples. We propose solving this problem by allowing each agent to learn a\nlocal regression function while enforcing consensus constraints. We use a\npenalized variant of functional stochastic gradient descent operating\nsimultaneously with low-dimensional subspace projections. These subspaces are\nconstructed greedily by applying orthogonal matching pursuit to the sequence of\nkernel dictionaries and weights. By tuning the projection-induced bias, we\npropose an algorithm that allows for each individual agent to learn, based upon\nits locally observed data stream and message passing with its neighbors only, a\nregression function that is close to the globally optimal regression function.\nThat is, we establish that with constant step-size selections agents' functions\nconverge to a neighborhood of the globally optimal one while satisfying the\nconsensus constraints as the penalty parameter is increased. Moreover, the\ncomplexity of the learned regression functions is guaranteed to remain finite.\nOn both multi-class kernel logistic regression and multi-class kernel support\nvector classification with data generated from class-dependent Gaussian mixture\nmodels, we observe stable function estimation and state of the art performance\nfor distributed online multi-class classification. Experiments on the Brodatz\ntextures further substantiate the empirical validity of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 13:49:28 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Koppel", "Alec", ""], ["Paternain", "Santiago", ""], ["Richard", "Cedric", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1710.04073", "submitter": "Matthieu Latapy", "authors": "Matthieu Latapy, Tiphaine Viard, Cl\\'emence Magnien", "title": "Stream Graphs and Link Streams for the Modeling of Interactions over\n  Time", "comments": "Keywords: stream graphs, link streams, temporal networks,\n  time-varying graphs, dynamic graphs, dynamic networks, longitudinal networks,\n  interactions, time, graphs, networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DM cs.DS physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph theory provides a language for studying the structure of relations, and\nit is often used to study interactions over time too. However, it poorly\ncaptures the both temporal and structural nature of interactions, that calls\nfor a dedicated formalism. In this paper, we generalize graph concepts in order\nto cope with both aspects in a consistent way. We start with elementary\nconcepts like density, clusters, or paths, and derive from them more advanced\nconcepts like cliques, degrees, clustering coefficients, or connected\ncomponents. We obtain a language to directly deal with interactions over time,\nsimilar to the language provided by graphs to deal with relations. This\nformalism is self-consistent: usual relations between different concepts are\npreserved. It is also consistent with graph theory: graph concepts are special\ncases of the ones we introduce. This makes it easy to generalize higher-level\nobjects such as quotient graphs, line graphs, k-cores, and centralities. This\npaper also considers discrete versus continuous time assumptions, instantaneous\nlinks, and extensions to more complex cases.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:03:40 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Latapy", "Matthieu", ""], ["Viard", "Tiphaine", ""], ["Magnien", "Cl\u00e9mence", ""]]}, {"id": "1710.04089", "submitter": "Badong Chen", "authors": "Badong Chen, Lei Xing, Nanning Zheng, Jose C. Pr\\'incipe", "title": "Quantized Minimum Error Entropy Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing with traditional learning criteria, such as mean square error\n(MSE), the minimum error entropy (MEE) criterion is superior in nonlinear and\nnon-Gaussian signal processing and machine learning. The argument of the\nlogarithm in Renyis entropy estimator, called information potential (IP), is a\npopular MEE cost in information theoretic learning (ITL). The computational\ncomplexity of IP is however quadratic in terms of sample number due to double\nsummation. This creates computational bottlenecks especially for large-scale\ndatasets. To address this problem, in this work we propose an efficient\nquantization approach to reduce the computational burden of IP, which decreases\nthe complexity from O(N*N) to O (MN) with M << N. The new learning criterion is\ncalled the quantized MEE (QMEE). Some basic properties of QMEE are presented.\nIllustrative examples are provided to verify the excellent performance of QMEE.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:30:29 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 09:15:41 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Chen", "Badong", ""], ["Xing", "Lei", ""], ["Zheng", "Nanning", ""], ["Pr\u00edncipe", "Jose C.", ""]]}, {"id": "1710.04099", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn {\\AA}rup Nielsen", "title": "Wembedder: Wikidata entity embedding web service", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I present a web service for querying an embedding of entities in the Wikidata\nknowledge graph. The embedding is trained on the Wikidata dump using Gensim's\nWord2Vec implementation and a simple graph walk. A REST API is implemented.\nTogether with the Wikidata API the web service exposes a multilingual resource\nfor over 600'000 Wikidata items and properties.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:56:27 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Nielsen", "Finn \u00c5rup", ""]]}, {"id": "1710.04170", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis, Nishanth Dikkala, Gautam Kamath", "title": "Concentration of Multilinear Functions of the Ising Model with\n  Applications to Network Data", "comments": "To appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math-ph math.MP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove near-tight concentration of measure for polynomial functions of the\nIsing model under high temperature. For any degree $d$, we show that a\ndegree-$d$ polynomial of a $n$-spin Ising model exhibits exponential tails that\nscale as $\\exp(-r^{2/d})$ at radius $r=\\tilde{\\Omega}_d(n^{d/2})$. Our\nconcentration radius is optimal up to logarithmic factors for constant $d$,\nimproving known results by polynomial factors in the number of spins. We\ndemonstrate the efficacy of polynomial functions as statistics for testing the\nstrength of interactions in social networks in both synthetic and real world\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 16:55:14 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Kamath", "Gautam", ""]]}, {"id": "1710.04177", "submitter": "Heather Mattie", "authors": "Heather Mattie, Kenth Eng{\\o}-Monsen, Rich Ling, Jukka-Pekka Onnela", "title": "The Social Bow Tie", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding tie strength in social networks, and the factors that influence\nit, have received much attention in a myriad of disciplines for decades.\nSeveral models incorporating indicators of tie strength have been proposed and\nused to quantify relationships in social networks, and a standard set of\nstructural network metrics have been applied to predominantly online social\nmedia sites to predict tie strength. Here, we introduce the concept of the\n\"social bow tie\" framework, a small subgraph of the network that consists of a\ncollection of nodes and ties that surround a tie of interest, forming a\ntopological structure that resembles a bow tie. We also define several\nintuitive and interpretable metrics that quantify properties of the bow tie. We\nuse random forests and regression models to predict categorical and continuous\nmeasures of tie strength from different properties of the bow tie, including\nnodal attributes. We also investigate what aspects of the bow tie are most\npredictive of tie strength in two distinct social networks: a collection of 75\nrural villages in India and a nationwide call network of European mobile phone\nusers. Our results indicate several of the bow tie metrics are highly\npredictive of tie strength, and we find the more the social circles of two\nindividuals overlap, the stronger their tie, consistent with previous findings.\nHowever, we also find that the more tightly-knit their non-overlapping social\ncircles, the weaker the tie. This new finding complements our current\nunderstanding of what drives the strength of ties in social networks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 17:12:05 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 12:10:30 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Mattie", "Heather", ""], ["Eng\u00f8-Monsen", "Kenth", ""], ["Ling", "Rich", ""], ["Onnela", "Jukka-Pekka", ""]]}, {"id": "1710.04211", "submitter": "Biswa Sengupta", "authors": "Alessandro Bay, Biswa Sengupta", "title": "StackSeq2Seq: Dual Encoder Seq2Seq Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widely studied non-deterministic polynomial time (NP) hard problem lies in\nfinding a route between the two nodes of a graph. Often meta-heuristics\nalgorithms such as $A^{*}$ are employed on graphs with a large number of nodes.\nHere, we propose a deep recurrent neural network architecture based on the\nSequence-2-Sequence (Seq2Seq) model, widely used, for instance in text\ntranslation. Particularly, we illustrate that utilising a context vector that\nhas been learned from two different recurrent networks enables increased\naccuracies in learning the shortest route of a graph. Additionally, we show\nthat one can boost the performance of the Seq2Seq network by smoothing the loss\nfunction using a homotopy continuation of the decoder's loss function.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 11:22:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 21:47:46 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Bay", "Alessandro", ""], ["Sengupta", "Biswa", ""]]}, {"id": "1710.04234", "submitter": "Alexandre Drouin", "authors": "Alexandre Drouin, Toby Dylan Hocking, Fran\\c{c}ois Laviolette", "title": "Maximum Margin Interval Trees", "comments": "Accepted for presentation at the 31st Conference on Neural\n  Information Processing Systems (NIPS 2017), Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a regression function using censored or interval-valued output data\nis an important problem in fields such as genomics and medicine. The goal is to\nlearn a real-valued prediction function, and the training output labels\nindicate an interval of possible values. Whereas most existing algorithms for\nthis task are linear models, in this paper we investigate learning nonlinear\ntree models. We propose to learn a tree by minimizing a margin-based\ndiscriminative objective function, and we provide a dynamic programming\nalgorithm for computing the optimal solution in log-linear time. We show\nempirically that this algorithm achieves state-of-the-art speed and prediction\naccuracy in a benchmark of several data sets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 18:02:38 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 16:48:57 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Drouin", "Alexandre", ""], ["Hocking", "Toby Dylan", ""], ["Laviolette", "Fran\u00e7ois", ""]]}, {"id": "1710.04248", "submitter": "Christian Grussler", "authors": "Christian Grussler and Pontus Giselsson", "title": "Local Convergence of Proximal Splitting Methods for Rank Constrained\n  Problems", "comments": "To be presented at the 56th IEEE Conference on Decision and Control,\n  Melbourne, Dec 2017", "journal-ref": null, "doi": "10.1109/CDC.2017.8263743", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the local convergence of proximal splitting algorithms to solve\noptimization problems that are convex besides a rank constraint. For this, we\nshow conditions under which the proximal operator of a function involving the\nrank constraint is locally identical to the proximal operator of its convex\nenvelope, hence implying local convergence. The conditions imply that the\nnon-convex algorithms locally converge to a solution whenever a convex\nrelaxation involving the convex envelope can be expected to solve the\nnon-convex problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 18:35:21 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Grussler", "Christian", ""], ["Giselsson", "Pontus", ""]]}, {"id": "1710.04273", "submitter": "Konstantinos Spiliopoulos", "authors": "Justin Sirignano, Konstantinos Spiliopoulos", "title": "Stochastic Gradient Descent in Continuous Time: A Central Limit Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.CP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent in continuous time (SGDCT) provides a\ncomputationally efficient method for the statistical learning of\ncontinuous-time models, which are widely used in science, engineering, and\nfinance. The SGDCT algorithm follows a (noisy) descent direction along a\ncontinuous stream of data. The parameter updates occur in continuous time and\nsatisfy a stochastic differential equation. This paper analyzes the asymptotic\nconvergence rate of the SGDCT algorithm by proving a central limit theorem\n(CLT) for strongly convex objective functions and, under slightly stronger\nconditions, for non-convex objective functions as well. An $L^{p}$ convergence\nrate is also proven for the algorithm in the strongly convex case. The\nmathematical analysis lies at the intersection of stochastic analysis and\nstatistical learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 19:41:36 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 17:26:15 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 18:42:25 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 06:52:10 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sirignano", "Justin", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1710.04325", "submitter": "Wai Ming Tai", "authors": "Jeff M. Phillips, Wai Ming Tai", "title": "Improved Coresets for Kernel Density Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the construction of coresets for kernel density estimates. That is\nwe show how to approximate the kernel density estimate described by a large\npoint set with another kernel density estimate with a much smaller point set.\nFor characteristic kernels (including Gaussian and Laplace kernels), our\napproximation preserves the $L_\\infty$ error between kernel density estimates\nwithin error $\\epsilon$, with coreset size $2/\\epsilon^2$, but no other aspects\nof the data, including the dimension, the diameter of the point set, or the\nbandwidth of the kernel common to other approximations. When the dimension is\nunrestricted, we show this bound is tight for these kernels as well as a much\nbroader set.\n  This work provides a careful analysis of the iterative Frank-Wolfe algorithm\nadapted to this context, an algorithm called \\emph{kernel herding}. This\nanalysis unites a broad line of work that spans statistics, machine learning,\nand geometry.\n  When the dimension $d$ is constant, we demonstrate much tighter bounds on the\nsize of the coreset specifically for Gaussian kernels, showing that it is\nbounded by the size of the coreset for axis-aligned rectangles. Currently the\nbest known constructive bound is $O(\\frac{1}{\\epsilon} \\log^d\n\\frac{1}{\\epsilon})$, and non-constructively, this can be improved by\n$\\sqrt{\\log \\frac{1}{\\epsilon}}$. This improves the best constant dimension\nbounds polynomially for $d \\geq 3$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 22:35:29 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Phillips", "Jeff M.", ""], ["Tai", "Wai Ming", ""]]}, {"id": "1710.04328", "submitter": "Oh-Hyun Kwon", "authors": "Oh-Hyun Kwon, Tarik Crnovrsanin, Kwan-Liu Ma", "title": "What Would a Graph Look Like in This Layout? A Machine Learning Approach\n  to Large Graph Visualization", "comments": "Presented at IEEE InfoVis 2017. To appear in IEEE Transactions on\n  Visualization and Computer Graphics", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics (2018)", "doi": "10.1109/TVCG.2017.2743858", "report-no": null, "categories": "cs.SI cs.CG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using different methods for laying out a graph can lead to very different\nvisual appearances, with which the viewer perceives different information.\nSelecting a \"good\" layout method is thus important for visualizing a graph. The\nselection can be highly subjective and dependent on the given task. A common\napproach to selecting a good layout is to use aesthetic criteria and visual\ninspection. However, fully calculating various layouts and their associated\naesthetic metrics is computationally expensive. In this paper, we present a\nmachine learning approach to large graph visualization based on computing the\ntopological similarity of graphs using graph kernels. For a given graph, our\napproach can show what the graph would look like in different layouts and\nestimate their corresponding aesthetic metrics. An important contribution of\nour work is the development of a new framework to design graph kernels. Our\nexperimental study shows that our estimation calculation is considerably faster\nthan computing the actual layouts and their aesthetic metrics. Also, our graph\nkernels outperform the state-of-the-art ones in both time and accuracy. In\naddition, we conducted a user study to demonstrate that the topological\nsimilarity computed with our graph kernel matches perceptual similarity\nassessed by human users.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 23:00:14 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Kwon", "Oh-Hyun", ""], ["Crnovrsanin", "Tarik", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "1710.04329", "submitter": "Youzuo Lin", "authors": "Youzuo Lin, Shusen Wang, Jayaraman Thiagarajan, George Guthrie, David\n  Coblentz", "title": "Efficient Data-Driven Geologic Feature Detection from Pre-stack Seismic\n  Measurements using Randomized Machine-Learning Algorithm", "comments": null, "journal-ref": null, "doi": "10.1093/gji/ggy385", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional seismic techniques for detecting the subsurface geologic\nfeatures are challenged by limited data coverage, computational inefficiency,\nand subjective human factors. We developed a novel data-driven geological\nfeature detection approach based on pre-stack seismic measurements. Our\ndetection method employs an efficient and accurate machine-learning detection\napproach to extract useful subsurface geologic features automatically.\nSpecifically, our method is based on kernel ridge regression model. The\nconventional kernel ridge regression can be computationally prohibited because\nof the large volume of seismic measurements. We employ a data reduction\ntechnique in combination with the conventional kernel ridge regression method\nto improve the computational efficiency and reduce memory usage. In particular,\nwe utilize a randomized numerical linear algebra technique, named Nystr\\\"om\nmethod, to effectively reduce the dimensionality of the feature space without\ncompromising the information content required for accurate detection. We\nprovide thorough computational cost analysis to show efficiency of our new\ngeological feature detection methods. We further validate the performance of\nour new subsurface geologic feature detection method using synthetic surface\nseismic data for 2D acoustic and elastic velocity models. Our numerical\nexamples demonstrate that our new detection method significantly improves the\ncomputational efficiency while maintaining comparable accuracy. Interestingly,\nwe show that our method yields a speed-up ratio on the order of $\\sim10^2$ to\n$\\sim 10^3$ in a multi-core computational environment.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 23:04:49 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Lin", "Youzuo", ""], ["Wang", "Shusen", ""], ["Thiagarajan", "Jayaraman", ""], ["Guthrie", "George", ""], ["Coblentz", "David", ""]]}, {"id": "1710.04340", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi, Yoshinobu Kawahara, Takehisa Yairi", "title": "Learning Koopman Invariant Subspaces for Dynamic Mode Decomposition", "comments": "18 pages, 7 figures, presented in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral decomposition of the Koopman operator is attracting attention as a\ntool for the analysis of nonlinear dynamical systems. Dynamic mode\ndecomposition is a popular numerical algorithm for Koopman spectral analysis;\nhowever, we often need to prepare nonlinear observables manually according to\nthe underlying dynamics, which is not always possible since we may not have any\na priori knowledge about them. In this paper, we propose a fully data-driven\nmethod for Koopman spectral analysis based on the principle of learning Koopman\ninvariant subspaces from observed data. To this end, we propose minimization of\nthe residual sum of squares of linear least-squares regression to estimate a\nset of functions that transforms data into a form in which the linear\nregression fits well. We introduce an implementation with neural networks and\nevaluate performance empirically using nonlinear dynamical systems and\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 01:37:46 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 08:06:25 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Takeishi", "Naoya", ""], ["Kawahara", "Yoshinobu", ""], ["Yairi", "Takehisa", ""]]}, {"id": "1710.04350", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Tony (Zhiwei) Qin, Xuewen Chen, Matthew Nokleby and\n  Jieping Ye", "title": "A Unified Neural Network Approach for Estimating Travel Time and\n  Distance for a Taxi Trip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In building intelligent transportation systems such as taxi or rideshare\nservices, accurate prediction of travel time and distance is crucial for\ncustomer experience and resource management. Using the NYC taxi dataset, which\ncontains taxi trips data collected from GPS-enabled taxis [23], this paper\ninvestigates the use of deep neural networks to jointly predict taxi trip time\nand distance. We propose a model, called ST-NN (Spatio-Temporal Neural\nNetwork), which first predicts the travel distance between an origin and a\ndestination GPS coordinate, then combines this prediction with the time of day\nto predict the travel time. The beauty of ST-NN is that it uses only the raw\ntrips data without requiring further feature engineering and provides a joint\nestimate of travel time and distance. We compare the performance of ST-NN to\nthat of state-of-the-art travel time estimation methods, and we observe that\nthe proposed approach generalizes better than state-of-the-art methods. We show\nthat ST-NN approach significantly reduces the mean absolute error for both\npredicted travel time and distance, about 17% for travel time prediction. We\nalso observe that the proposed approach is more robust to outliers present in\nthe dataset by testing the performance of ST-NN on the datasets with and\nwithout outliers.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 03:21:16 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Jindal", "Ishan", "", "Zhiwei"], ["Tony", "", "", "Zhiwei"], ["Qin", "", ""], ["Chen", "Xuewen", ""], ["Nokleby", "Matthew", ""], ["Ye", "Jieping", ""]]}, {"id": "1710.04373", "submitter": "Chuanyun Zang", "authors": "Chuanyun Zang", "title": "Deep Learning in Multiple Multistep Time Series Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The project aims to research on combining deep learning specifically\nLong-Short Memory (LSTM) and basic statistics in multiple multistep time series\nprediction. LSTM can dive into all the pages and learn the general trends of\nvariation in a large scope, while the well selected medians for each page can\nkeep the special seasonality of different pages so that the future trend will\nnot fluctuate too much from the reality. A recent Kaggle competition on 145K\nWeb Traffic Time Series Forecasting [1] is used to thoroughly illustrate and\ntest this idea.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 05:28:05 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Zang", "Chuanyun", ""]]}, {"id": "1710.04382", "submitter": "Richard Everitt", "authors": "Richard G. Everitt and Dennis Prangle and Philip Maybank and Mark Bell", "title": "Marginal sequential Monte Carlo for doubly intractable models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI physics.data-an stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference for models that have an intractable partition function is\nknown as a doubly intractable problem, where standard Monte Carlo methods are\nnot applicable. The past decade has seen the development of auxiliary variable\nMonte Carlo techniques (M{\\o}ller et al., 2006; Murray et al., 2006) for\ntackling this problem; these approaches being members of the more general class\nof pseudo-marginal, or exact-approximate, Monte Carlo algorithms (Andrieu and\nRoberts, 2009), which make use of unbiased estimates of intractable posteriors.\nEveritt et al. (2017) investigated the use of exact-approximate importance\nsampling (IS) and sequential Monte Carlo (SMC) in doubly intractable problems,\nbut focussed only on SMC algorithms that used data-point tempering. This paper\ndescribes SMC samplers that may use alternative sequences of distributions, and\ndescribes ways in which likelihood estimates may be improved adaptively as the\nalgorithm progresses, building on ideas from Moores et al. (2015). This\napproach is compared with a number of alternative algorithms for doubly\nintractable problems, including approximate Bayesian computation (ABC), which\nwe show is closely related to the method of M{\\o}ller et al. (2006).\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 06:36:14 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Everitt", "Richard G.", ""], ["Prangle", "Dennis", ""], ["Maybank", "Philip", ""], ["Bell", "Mark", ""]]}, {"id": "1710.04404", "submitter": "Or Sharir", "authors": "Or Sharir and Amnon Shashua", "title": "Sum-Product-Quotient Networks", "comments": "Published as a conference paper at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel tractable generative model that extends Sum-Product\nNetworks (SPNs) and significantly boosts their power. We call it\nSum-Product-Quotient Networks (SPQNs), whose core concept is to incorporate\nconditional distributions into the model by direct computation using quotient\nnodes, e.g. $P(A|B) = \\frac{P(A,B)}{P(B)}$. We provide sufficient conditions\nfor the tractability of SPQNs that generalize and relax the decomposable and\ncomplete tractability conditions of SPNs. These relaxed conditions give rise to\nan exponential boost to the expressive efficiency of our model, i.e. we prove\nthat there are distributions which SPQNs can compute efficiently but require\nSPNs to be of exponential size. Thus, we narrow the gap in expressivity between\ntractable graphical models and other Neural Network-based generative models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 08:18:07 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 16:11:53 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 23:34:53 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Sharir", "Or", ""], ["Shashua", "Amnon", ""]]}, {"id": "1710.04450", "submitter": "Parvin Razzaghi", "authors": "Parvin Razzaghi", "title": "Self-Taught Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new approach for classification of target task using limited\nlabeled target data as well as enormous unlabeled source data is proposed which\nis called self-taught learning. The target and source data can be drawn from\ndifferent distributions. In the previous approaches, covariate shift assumption\nis considered where the marginal distributions p(x) change over domains and the\nconditional distributions p(y|x) remain the same. In our approach, we propose a\nnew objective function which simultaneously learns a common space T(.) where\nthe conditional distributions over domains p(T(x)|y) remain the same and learns\nrobust SVM classifiers for target task using both source and target data in the\nnew representation. Hence, in the proposed objective function, the hidden label\nof the source data is also incorporated. We applied the proposed approach on\nCaltech-256, MSRC+LMO datasets and compared the performance of our algorithm to\nthe available competing methods. Our method has a superior performance to the\nsuccessful existing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 11:12:30 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Razzaghi", "Parvin", ""]]}, {"id": "1710.04461", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, Muhammad Ashad Kabir, Alan Colman, Jun Han", "title": "An Improved Naive Bayes Classifier-based Noise Detection Technique for\n  Classifying User Phone Call Behavior", "comments": "The 15th Australasian Data Mining Conference (AusDM 2017), Melbourne,\n  Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of noisy instances in mobile phone data is a fundamental issue\nfor classifying user phone call behavior (i.e., accept, reject, missed and\noutgoing), with many potential negative consequences. The classification\naccuracy may decrease and the complexity of the classifiers may increase due to\nthe number of redundant training samples. To detect such noisy instances from a\ntraining dataset, researchers use naive Bayes classifier (NBC) as it identifies\nmisclassified instances by taking into account independence assumption and\nconditional probabilities of the attributes. However, some of these\nmisclassified instances might indicate usages behavioral patterns of individual\nmobile phone users. Existing naive Bayes classifier based noise detection\ntechniques have not considered this issue and, thus, are lacking in\nclassification accuracy. In this paper, we propose an improved noise detection\ntechnique based on naive Bayes classifier for effectively classifying users'\nphone call behaviors. In order to improve the classification accuracy, we\neffectively identify noisy instances from the training dataset by analyzing the\nbehavioral patterns of individuals. We dynamically determine a noise threshold\naccording to individual's unique behavioral patterns by using both the naive\nBayes classifier and Laplace estimator. We use this noise threshold to identify\nnoisy instances. To measure the effectiveness of our technique in classifying\nuser phone call behavior, we employ the most popular classification algorithm\n(e.g., decision tree). Experimental results on the real phone call log dataset\nshow that our proposed technique more accurately identifies the noisy instances\nfrom the training datasets that leads to better classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 11:37:21 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 01:19:03 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Kabir", "Muhammad Ashad", ""], ["Colman", "Alan", ""], ["Han", "Jun", ""]]}, {"id": "1710.04462", "submitter": "Ehsan Arbabi", "authors": "Ali Saeedi and Ehsan Arbabi", "title": "Effects of Images with Different Levels of Familiarity on EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating human brain potentials during watching different images can be\nused for memory evaluation, information retrieving, guilty-innocent\nidentification and examining the brain response. In this study, the effects of\nwatching images, with different levels of familiarity, on subjects'\nElectroencephalogram (EEG) have been studied. Three different groups of images\nwith three familiarity levels of \"unfamiliar\", \"familiar\" and \"very familiar\"\nhave been considered for this study. EEG signals of 21 subjects (14 men) were\nrecorded. After signal acquisition, pre-processing, including noise and\nartifact removal, were performed on epochs of data. Features, including\nspatial-statistical, wavelet, frequency and harmonic parameters, and also\ncorrelation between recording channels, were extracted from the data. Then, we\nevaluated the efficiency of the extracted features by using p-value and also an\northogonal feature selection method (combination of Gram-Schmitt method and\nFisher discriminant ratio) for feature dimensional reduction. As the final step\nof feature selection, we used 'add-r take-away l' method for choosing the most\ndiscriminative features. For data classification, including all two-class and\nthree-class cases, we applied Support Vector Machine (SVM) on the extracted\nfeatures. The correct classification rates (CCR) for \"unfamiliar-familiar\",\n\"unfamiliar-very familiar\" and \"familiar-very familiar\" cases were 85.6%,\n92.6%, and 70.6%, respectively. The best results of classifications were\nobtained in pre-frontal and frontal regions of brain. Also, wavelet, frequency\nand harmonic features were among the most discriminative features. Finally, in\nthree-class case, the best CCR was 86.8%.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 11:39:48 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Saeedi", "Ali", ""], ["Arbabi", "Ehsan", ""]]}, {"id": "1710.04484", "submitter": "Colleen Farrelly", "authors": "Colleen M. Farrelly", "title": "Dimensionality Reduction Ensembles", "comments": "12 pages, 1 table, 8 figures; under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning has had many successes in supervised learning, but it has\nbeen rare in unsupervised learning and dimensionality reduction. This study\nexplores dimensionality reduction ensembles, using principal component analysis\nand manifold learning techniques to capture linear, nonlinear, local, and\nglobal features in the original dataset. Dimensionality reduction ensembles are\ntested first on simulation data and then on two real medical datasets using\nrandom forest classifiers; results suggest the efficacy of this approach, with\naccuracies approaching that of the full dataset. Limitations include\ncomputational cost of some algorithms with strong performance, which may be\nameliorated through distributed computing and the development of more efficient\nversions of these algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 14:38:47 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Farrelly", "Colleen M.", ""]]}, {"id": "1710.04486", "submitter": "Dominique Vaufreydaz", "authors": "Thomas Guntz (LIG), Raffaella Balzarini (LIG), Dominique Vaufreydaz\n  (LIG, UGA), James L. Crowley (Grenoble INP, LIG)", "title": "Multimodal Observation and Interpretation of Subjects Engaged in Problem\n  Solving", "comments": null, "journal-ref": "1st Workshop on \"Behavior, Emotion and Representation: Building\n  Blocks of Interaction'', Oct 2017, Bielefeld, Germany. 2017", "doi": null, "report-no": null, "categories": "cs.HC cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the first results of a pilot experiment in the\ncapture and interpretation of multimodal signals of human experts engaged in\nsolving challenging chess problems. Our goal is to investigate the extent to\nwhich observations of eye-gaze, posture, emotion and other physiological\nsignals can be used to model the cognitive state of subjects, and to explore\nthe integration of multiple sensor modalities to improve the reliability of\ndetection of human displays of awareness and emotion. We observed chess players\nengaged in problems of increasing difficulty while recording their behavior.\nSuch recordings can be used to estimate a participant's awareness of the\ncurrent situation and to predict ability to respond effectively to challenging\nsituations. Results show that a multimodal approach is more accurate than a\nunimodal one. By combining body posture, visual attention and emotion, the\nmultimodal approach can reach up to 93% of accuracy when determining player's\nchess expertise while unimodal approach reaches 86%. Finally this experiment\nvalidates the use of our equipment as a general and reproducible tool for the\nstudy of participants engaged in screen-based interaction and/or problem\nsolving.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 12:59:42 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Guntz", "Thomas", "", "LIG"], ["Balzarini", "Raffaella", "", "LIG"], ["Vaufreydaz", "Dominique", "", "LIG, UGA"], ["Crowley", "James L.", "", "Grenoble INP, LIG"]]}, {"id": "1710.04521", "submitter": "Jefrey Lijffijt", "authors": "Jefrey Lijffijt, Bo Kang, Wouter Duivesteijn, Kai Puolam\\\"aki, Emilia\n  Oikarinen, Tijl De Bie", "title": "Subjectively Interesting Subgroup Discovery on Real-valued Targets", "comments": "12 pages, 10 figures, 2 tables, conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deriving insights from high-dimensional data is one of the core problems in\ndata mining. The difficulty mainly stems from the fact that there are\nexponentially many variable combinations to potentially consider, and there are\ninfinitely many if we consider weighted combinations, even for linear\ncombinations. Hence, an obvious question is whether we can automate the search\nfor interesting patterns and visualizations. In this paper, we consider the\nsetting where a user wants to learn as efficiently as possible about\nreal-valued attributes. For example, to understand the distribution of crime\nrates in different geographic areas in terms of other (numerical, ordinal\nand/or categorical) variables that describe the areas. We introduce a method to\nfind subgroups in the data that are maximally informative (in the formal\nInformation Theoretic sense) with respect to a single or set of real-valued\ntarget attributes. The subgroup descriptions are in terms of a succinct set of\narbitrarily-typed other attributes. The approach is based on the Subjective\nInterestingness framework FORSIED to enable the use of prior knowledge when\nfinding most informative non-redundant patterns, and hence the method also\nsupports iterative data mining.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 14:04:19 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Lijffijt", "Jefrey", ""], ["Kang", "Bo", ""], ["Duivesteijn", "Wouter", ""], ["Puolam\u00e4ki", "Kai", ""], ["Oikarinen", "Emilia", ""], ["De Bie", "Tijl", ""]]}, {"id": "1710.04556", "submitter": "Alain Celisse", "authors": "Alain Celisse (LPP, MODAL), Guillemette Marot (MODAL, CERIM), Morgane\n  Pierre-Jean (LaMME), Guillem Rigaill (URGV)", "title": "New efficient algorithms for multiple change-point detection with\n  kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several statistical approaches based on reproducing kernels have been\nproposed to detect abrupt changes arising in the full distribution of the\nobservations and not only in the mean or variance. Some of these approaches\nenjoy good statistical properties (oracle inequality, \\ldots). Nonetheless,\nthey have a high computational cost both in terms of time and memory. This\nmakes their application difficult even for small and medium sample sizes ($n<\n10^4$). This computational issue is addressed by first describing a new\nefficient and exact algorithm for kernel multiple change-point detection with\nan improved worst-case complexity that is quadratic in time and linear in\nspace. It allows dealing with medium size signals (up to $n \\approx 10^5$).\nSecond, a faster but approximation algorithm is described. It is based on a\nlow-rank approximation to the Gram matrix. It is linear in time and space. This\napproximation algorithm can be applied to large-scale signals ($n \\geq 10^6$).\nThese exact and approximation algorithms have been implemented in \\texttt{R}\nand \\texttt{C} for various kernels. The computational and statistical\nperformances of these new algorithms have been assessed through empirical\nexperiments. The runtime of the new algorithms is observed to be faster than\nthat of other considered procedures. Finally, simulations confirmed the higher\nstatistical accuracy of kernel-based approaches to detect changes that are not\nonly in the mean. These simulations also illustrate the flexibility of\nkernel-based approaches to analyze complex biological profiles made of DNA copy\nnumber and allele B frequencies. An R package implementing the approach will be\nmade available on github.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 15:08:52 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Celisse", "Alain", "", "LPP, MODAL"], ["Marot", "Guillemette", "", "MODAL, CERIM"], ["Pierre-Jean", "Morgane", "", "LaMME"], ["Rigaill", "Guillem", "", "URGV"]]}, {"id": "1710.04580", "submitter": "Galen Reeves", "authors": "Galen Reeves", "title": "Additivity of Information in Multilayer Networks via Additive Gaussian\n  Noise Transforms", "comments": "Presented at the 55th Annual Allerton Conference on Communication,\n  Control, and Computing, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer (or deep) networks are powerful probabilistic models based on\nmultiple stages of a linear transform followed by a non-linear (possibly\nrandom) function. In general, the linear transforms are defined by matrices and\nthe non-linear functions are defined by information channels. These models have\ngained great popularity due to their ability to characterize complex\nprobabilistic relationships arising in a wide variety of inference problems.\nThe contribution of this paper is a new method for analyzing the fundamental\nlimits of statistical inference in settings where the model is known. The\nvalidity of our method can be established in a number of settings and is\nconjectured to hold more generally. A key assumption made throughout is that\nthe matrices are drawn randomly from orthogonally invariant distributions.\n  Our method yields explicit formulas for 1) the mutual information; 2) the\nminimum mean-squared error (MMSE); 3) the existence and locations of certain\nphase-transitions with respect to the problem parameters; and 4) the stationary\npoints for the state evolution of approximate message passing algorithms. When\napplied to the special case of models with multivariate Gaussian channels our\nmethod is rigorous and has close connections to free probability theory for\nrandom matrices. When applied to the general case of non-Gaussian channels, our\nmethod provides a simple alternative to the replica method from statistical\nphysics. A key observation is that the combined effects of the individual\ncomponents in the model (namely the matrices and the channels) are additive\nwhen viewed in a certain transform domain.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 16:02:19 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Reeves", "Galen", ""]]}, {"id": "1710.04582", "submitter": "Eleni Vasilaki D.Phil.", "authors": "Eleni Vasilaki", "title": "Is Epicurus the father of Reinforcement Learning?", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Epicurean Philosophy is commonly thought as simplistic and hedonistic.\nHere I discuss how this is a misconception and explore its link to\nReinforcement Learning. Based on the letters of Epicurus, I construct an\nobjective function for hedonism which turns out to be equivalent of the\nReinforcement Learning objective function when omitting the discount factor. I\nthen discuss how Plato and Aristotle 's views that can be also loosely linked\nto Reinforcement Learning, as well as their weaknesses in relationship to it.\nFinally, I emphasise the close affinity of the Epicurean views and the Bellman\nequation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 16:07:18 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Vasilaki", "Eleni", ""]]}, {"id": "1710.04584", "submitter": "Yongyu Wang", "authors": "Yongyu Wang, Zhuo Feng", "title": "Towards Scalable Spectral Clustering via Spectrum-Preserving\n  Sparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The eigendeomposition of nearest-neighbor (NN) graph Laplacian matrices is\nthe main computational bottleneck in spectral clustering. In this work, we\nintroduce a highly-scalable, spectrum-preserving graph sparsification algorithm\nthat enables to build ultra-sparse NN (u-NN) graphs with guaranteed\npreservation of the original graph spectrums, such as the first few\neigenvectors of the original graph Laplacian. Our approach can immediately lead\nto scalable spectral clustering of large data networks without sacrificing\nsolution quality. The proposed method starts from constructing low-stretch\nspanning trees (LSSTs) from the original graphs, which is followed by\niteratively recovering small portions of \"spectrally critical\" off-tree edges\nto the LSSTs by leveraging a spectral off-tree embedding scheme. To determine\nthe suitable amount of off-tree edges to be recovered to the LSSTs, an\neigenvalue stability checking scheme is proposed, which enables to robustly\npreserve the first few Laplacian eigenvectors within the sparsified graph.\nAdditionally, an incremental graph densification scheme is proposed for\nidentifying extra edges that have been missing in the original NN graphs but\ncan still play important roles in spectral clustering tasks. Our experimental\nresults for a variety of well-known data sets show that the proposed method can\ndramatically reduce the complexity of NN graphs, leading to significant\nspeedups in spectral clustering.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 16:09:29 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 00:51:54 GMT"}, {"version": "v3", "created": "Thu, 16 Nov 2017 01:04:10 GMT"}, {"version": "v4", "created": "Thu, 11 Oct 2018 17:59:49 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Wang", "Yongyu", ""], ["Feng", "Zhuo", ""]]}, {"id": "1710.04677", "submitter": "Rui Zhang", "authors": "Rui Zhang, Quanyan Zhu", "title": "Game-Theoretic Design of Secure and Resilient Distributed Support Vector\n  Machines with Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a large number of sensors and control units in networked systems,\ndistributed support vector machines (DSVMs) play a fundamental role in scalable\nand efficient multi-sensor classification and prediction tasks. However, DSVMs\nare vulnerable to adversaries who can modify and generate data to deceive the\nsystem to misclassification and misprediction. This work aims to design defense\nstrategies for DSVM learner against a potential adversary. We establish a\ngame-theoretic framework to capture the conflicting interests between the DSVM\nlearner and the attacker. The Nash equilibrium of the game allows predicting\nthe outcome of learning algorithms in adversarial environments, and enhancing\nthe resilience of the machine learning through dynamic distributed learning\nalgorithms. We show that the DSVM learner is less vulnerable when he uses a\nbalanced network with fewer nodes and higher degree. We also show that adding\nmore training samples is an efficient defense strategy against an attacker. We\npresent secure and resilient DSVM algorithms with verification method and\nrejection method, and show their resiliency against adversary with numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 18:10:14 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Zhang", "Rui", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1710.04725", "submitter": "Jan N. Van Rijn PhD", "authors": "J. N. van Rijn and F. Hutter", "title": "Hyperparameter Importance Across Datasets", "comments": "\\c{opyright} 2018. Copyright is held by the owner/author(s).\n  Publication rights licensed to ACM. This is the author's version of the work.\n  It is posted here for your personal use, not for redistribution. The\n  definitive Version of Record was published in Proceedings of the 24th ACM\n  SIGKDD International Conference on Knowledge Discovery & Data Mining", "journal-ref": null, "doi": "10.1145/3219819.3220058", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of automated machine learning, automated hyperparameter\noptimization methods are by now routinely used in data mining. However, this\nprogress is not yet matched by equal progress on automatic analyses that yield\ninformation beyond performance-optimizing hyperparameter settings. In this\nwork, we aim to answer the following two questions: Given an algorithm, what\nare generally its most important hyperparameters, and what are typically good\nvalues for these? We present methodology and a framework to answer these\nquestions based on meta-learning across many datasets. We apply this\nmethodology using the experimental meta-data available on OpenML to determine\nthe most important hyperparameters of support vector machines, random forests\nand Adaboost, and to infer priors for all their hyperparameters. The results,\nobtained fully automatically, provide a quantitative basis to focus efforts in\nboth manual algorithm design and in automated hyperparameter optimization. The\nconducted experiments confirm that the hyperparameters selected by the proposed\nmethod are indeed the most important ones and that the obtained priors also\nlead to statistically significant improvements in hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 21:27:38 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 14:43:53 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["van Rijn", "J. N.", ""], ["Hutter", "F.", ""]]}, {"id": "1710.04735", "submitter": "Dhruv Choudhary", "authors": "Dhruv Choudhary, Arun Kejariwal, Francois Orsini", "title": "On the Runtime-Efficacy Trade-off of Anomaly Detection Techniques for\n  Real-Time Streaming Data", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever growing volume and velocity of data coupled with decreasing attention\nspan of end users underscore the critical need for real-time analytics. In this\nregard, anomaly detection plays a key role as an application as well as a means\nto verify data fidelity. Although the subject of anomaly detection has been\nresearched for over 100 years in a multitude of disciplines such as, but not\nlimited to, astronomy, statistics, manufacturing, econometrics, marketing, most\nof the existing techniques cannot be used as is on real-time data streams.\nFurther, the lack of characterization of performance -- both with respect to\nreal-timeliness and accuracy -- on production data sets makes model selection\nvery challenging. To this end, we present an in-depth analysis, geared towards\nreal-time streaming data, of anomaly detection techniques. Given the\nrequirements with respect to real-timeliness and accuracy, the analysis\npresented in this paper should serve as a guide for selection of the \"best\"\nanomaly detection technique. To the best of our knowledge, this is the first\ncharacterization of anomaly detection techniques proposed in very diverse set\nof fields, using production data sets corresponding to a wide set of\napplication domains.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 21:57:55 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Choudhary", "Dhruv", ""], ["Kejariwal", "Arun", ""], ["Orsini", "Francois", ""]]}, {"id": "1710.04749", "submitter": "Vijay Manikandan Janakiraman", "authors": "Vijay Manikandan Janakiraman", "title": "Explaining Aviation Safety Incidents Using Deep Temporal Multiple\n  Instance Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although aviation accidents are rare, safety incidents occur more frequently\nand require a careful analysis to detect and mitigate risks in a timely manner.\nAnalyzing safety incidents using operational data and producing event-based\nexplanations is invaluable to airline companies as well as to governing\norganizations such as the Federal Aviation Administration (FAA) in the United\nStates. However, this task is challenging because of the complexity involved in\nmining multi-dimensional heterogeneous time series data, the lack of\ntime-step-wise annotation of events in a flight, and the lack of scalable tools\nto perform analysis over a large number of events. In this work, we propose a\nprecursor mining algorithm that identifies events in the multidimensional time\nseries that are correlated with the safety incident. Precursors are valuable to\nsystems health and safety monitoring and in explaining and forecasting safety\nincidents. Current methods suffer from poor scalability to high dimensional\ntime series data and are inefficient in capturing temporal behavior. We propose\nan approach by combining multiple-instance learning (MIL) and deep recurrent\nneural networks (DRNN) to take advantage of MIL's ability to learn using weakly\nsupervised data and DRNN's ability to model temporal behavior. We describe the\nalgorithm, the data, the intuition behind taking a MIL approach, and a\ncomparative analysis of the proposed algorithm with baseline models. We also\ndiscuss the application to a real-world aviation safety problem using data from\na commercial airline company and discuss the model's abilities and\nshortcomings, with some final remarks about possible deployment directions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 23:42:00 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 05:16:08 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Janakiraman", "Vijay Manikandan", ""]]}, {"id": "1710.04759", "submitter": "David Krueger", "authors": "David Krueger, Chin-Wei Huang, Riashat Islam, Ryan Turner, Alexandre\n  Lacoste, Aaron Courville", "title": "Bayesian Hypernetworks", "comments": "David Krueger and Chin-Wei Huang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Bayesian hypernetworks: a framework for approximate Bayesian\ninference in neural networks. A Bayesian hypernetwork $\\h$ is a neural network\nwhich learns to transform a simple noise distribution, $p(\\vec\\epsilon) =\n\\N(\\vec 0,\\mat I)$, to a distribution $q(\\pp) := q(h(\\vec\\epsilon))$ over the\nparameters $\\pp$ of another neural network (the \"primary network\")\\@. We train\n$q$ with variational inference, using an invertible $\\h$ to enable efficient\nestimation of the variational lower bound on the posterior $p(\\pp | \\D)$ via\nsampling. In contrast to most methods for Bayesian deep learning, Bayesian\nhypernets can represent a complex multimodal approximate posterior with\ncorrelations between parameters, while enabling cheap iid sampling of~$q(\\pp)$.\nIn practice, Bayesian hypernets can provide a better defense against\nadversarial examples than dropout, and also exhibit competitive performance on\na suite of tasks which evaluate model uncertainty, including regularization,\nactive learning, and anomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 00:27:57 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 20:36:16 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Krueger", "David", ""], ["Huang", "Chin-Wei", ""], ["Islam", "Riashat", ""], ["Turner", "Ryan", ""], ["Lacoste", "Alexandre", ""], ["Courville", "Aaron", ""]]}, {"id": "1710.04792", "submitter": "Shihua Zhang", "authors": "Wenwen Min, Juan Liu and Shihua Zhang", "title": "Sparse Weighted Canonical Correlation Analysis", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two data matrices $X$ and $Y$, sparse canonical correlation analysis\n(SCCA) is to seek two sparse canonical vectors $u$ and $v$ to maximize the\ncorrelation between $Xu$ and $Yv$. However, classical and sparse CCA models\nconsider the contribution of all the samples of data matrices and thus cannot\nidentify an underlying specific subset of samples. To this end, we propose a\nnovel sparse weighted canonical correlation analysis (SWCCA), where weights are\nused for regularizing different samples. We solve the $L_0$-regularized SWCCA\n($L_0$-SWCCA) using an alternating iterative algorithm. We apply $L_0$-SWCCA to\nsynthetic data and real-world data to demonstrate its effectiveness and\nsuperiority compared to related methods. Lastly, we consider also SWCCA with\ndifferent penalties like LASSO (Least absolute shrinkage and selection\noperator) and Group LASSO, and extend it for integrating more than three data\nmatrices.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 03:42:39 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Min", "Wenwen", ""], ["Liu", "Juan", ""], ["Zhang", "Shihua", ""]]}, {"id": "1710.04806", "submitter": "Oscar Li", "authors": "Oscar Li, Hao Liu, Chaofan Chen, and Cynthia Rudin", "title": "Deep Learning for Case-Based Reasoning through Prototypes: A Neural\n  Network that Explains Its Predictions", "comments": "The first two authors contributed equally, 8 pages, accepted in AAAI\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are widely used for classification. These deep models\noften suffer from a lack of interpretability -- they are particularly difficult\nto understand because of their non-linear nature. As a result, neural networks\nare often treated as \"black box\" models, and in the past, have been trained\npurely to optimize the accuracy of predictions. In this work, we create a novel\nnetwork architecture for deep learning that naturally explains its own\nreasoning for each prediction. This architecture contains an autoencoder and a\nspecial prototype layer, where each unit of that layer stores a weight vector\nthat resembles an encoded training input. The encoder of the autoencoder allows\nus to do comparisons within the latent space, while the decoder allows us to\nvisualize the learned prototypes. The training objective has four terms: an\naccuracy term, a term that encourages every prototype to be similar to at least\none encoded input, a term that encourages every encoded input to be close to at\nleast one prototype, and a term that encourages faithful reconstruction by the\nautoencoder. The distances computed in the prototype layer are used as part of\nthe classification process. Since the prototypes are learned during training,\nthe learned network naturally comes with explanations for each prediction, and\nthe explanations are loyal to what the network actually computes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 05:12:03 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 06:43:01 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Li", "Oscar", ""], ["Liu", "Hao", ""], ["Chen", "Chaofan", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1710.04833", "submitter": "Shi-Ju Ran", "authors": "Ding Liu, Shi-Ju Ran, Peter Wittek, Cheng Peng, Raul Bl\\'azquez\n  Garc\\'ia, Gang Su, and Maciej Lewenstein", "title": "Machine Learning by Unitary Tensor Network of Hierarchical Tree\n  Structure", "comments": "6 pages, 4 figures", "journal-ref": "New Journal of Physics, 21, 073059 (2019)", "doi": "10.1088/1367-2630/ab31ef", "report-no": null, "categories": "stat.ML cond-mat.str-el physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The resemblance between the methods used in quantum-many body physics and in\nmachine learning has drawn considerable attention. In particular, tensor\nnetworks (TNs) and deep learning architectures bear striking similarities to\nthe extent that TNs can be used for machine learning. Previous results used\none-dimensional TNs in image recognition, showing limited scalability and\nflexibilities. In this work, we train two-dimensional hierarchical TNs to solve\nimage recognition problems, using a training algorithm derived from the\nmulti-scale entanglement renormalization ansatz. This approach introduces\nmathematical connections among quantum many-body physics, quantum information\ntheory, and machine learning. While keeping the TN unitary in the training\nphase, TN states are defined, which encode classes of images into quantum\nmany-body states. We study the quantum features of the TN states, including\nquantum entanglement and fidelity. We find these quantities could be properties\nthat characterize the image classes, as well as the machine learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 08:24:09 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 20:32:46 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 06:35:59 GMT"}, {"version": "v4", "created": "Sun, 10 Mar 2019 13:11:46 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Liu", "Ding", ""], ["Ran", "Shi-Ju", ""], ["Wittek", "Peter", ""], ["Peng", "Cheng", ""], ["Garc\u00eda", "Raul Bl\u00e1zquez", ""], ["Su", "Gang", ""], ["Lewenstein", "Maciej", ""]]}, {"id": "1710.04837", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Tao Xiang, Yu-Gang Jiang, Xiangyang Xue, Leonid Sigal, and\n  Shaogang Gong", "title": "Recent Advances in Zero-shot Recognition", "comments": "accepted by IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent renaissance of deep convolution neural networks, encouraging\nbreakthroughs have been achieved on the supervised recognition tasks, where\neach class has sufficient training data and fully annotated training data.\nHowever, to scale the recognition to a large number of classes with few or now\ntraining samples for each class remains an unsolved problem. One approach to\nscaling up the recognition is to develop models capable of recognizing unseen\ncategories without any training instances, or zero-shot recognition/ learning.\nThis article provides a comprehensive review of existing zero-shot recognition\ntechniques covering various aspects ranging from representations of models, and\nfrom datasets and evaluation settings. We also overview related recognition\ntasks including one-shot and open set recognition which can be used as natural\nextensions of zero-shot recognition when limited number of class samples become\navailable or when zero-shot recognition is implemented in a real-world setting.\nImportantly, we highlight the limitations of existing approaches and point out\nfuture research directions in this existing new research area.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 08:29:29 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Fu", "Yanwei", ""], ["Xiang", "Tao", ""], ["Jiang", "Yu-Gang", ""], ["Xue", "Xiangyang", ""], ["Sigal", "Leonid", ""], ["Gong", "Shaogang", ""]]}, {"id": "1710.04872", "submitter": "Abhishake Rastogi", "authors": "Abhishake Rastogi and Sivananthan Sampath", "title": "Manifold regularization based on Nystr{\\\"o}m type subsampling", "comments": null, "journal-ref": null, "doi": "10.1016/j.acha.2018.12.002", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the Nystr{\\\"o}m type subsampling for large scale\nkernel methods to reduce the computational complexities of big data. We discuss\nthe multi-penalty regularization scheme based on Nystr{\\\"o}m type subsampling\nwhich is motivated from well-studied manifold regularization schemes. We\ndevelop a theoretical analysis of multi-penalty least-square regularization\nscheme under the general source condition in vector-valued function setting,\ntherefore the results can also be applied to multi-task learning problems. We\nachieve the optimal minimax convergence rates of multi-penalty regularization\nusing the concept of effective dimension for the appropriate subsampling size.\nWe discuss an aggregation approach based on linear function strategy to combine\nvarious Nystr{\\\"o}m approximants. Finally, we demonstrate the performance of\nmulti-penalty regularization based on Nystr{\\\"o}m type subsampling on\nCaltech-101 data set for multi-class image classification and NSL-KDD benchmark\ndata set for intrusion detection problem.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 11:13:38 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Rastogi", "Abhishake", ""], ["Sampath", "Sivananthan", ""]]}, {"id": "1710.04874", "submitter": "Gregorz Dudek", "authors": "Grzegorz Dudek", "title": "A Method of Generating Random Weights and Biases in Feedforward Neural\n  Networks with Random Hidden Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with random hidden nodes have gained increasing interest from\nresearchers and practical applications. This is due to their unique features\nsuch as very fast training and universal approximation property. In these\nnetworks the weights and biases of hidden nodes determining the nonlinear\nfeature mapping are set randomly and are not learned. Appropriate selection of\nthe intervals from which weights and biases are selected is extremely\nimportant. This topic has not yet been sufficiently explored in the literature.\nIn this work a method of generating random weights and biases is proposed. This\nmethod generates the parameters of the hidden nodes in such a way that\nnonlinear fragments of the activation functions are located in the input space\nregions with data and can be used to construct the surface approximating a\nnonlinear target function. The weights and biases are dependent on the input\ndata range and activation function type. The proposed methods allows us to\ncontrol the generalization degree of the model. These all lead to improvement\nin approximation performance of the network. Several experiments show very\npromising results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 11:23:18 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1710.04881", "submitter": "Pedram Daee", "authors": "Pedram Daee, Tomi Peltola, Aki Vehtari, Samuel Kaski", "title": "User Modelling for Avoiding Overfitting in Interactive Knowledge\n  Elicitation for Prediction", "comments": "9 pages, 2 figures. The paper is published in the proceedings of IUI\n  2018. Codes and data available at\n  https://github.com/HIIT/human-overfitting-in-IML", "journal-ref": null, "doi": "10.1145/3172944.3172989", "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human-in-the-loop machine learning, the user provides information beyond\nthat in the training data. Many algorithms and user interfaces have been\ndesigned to optimize and facilitate this human--machine interaction; however,\nfewer studies have addressed the potential defects the designs can cause.\nEffective interaction often requires exposing the user to the training data or\nits statistics. The design of the system is then critical, as this can lead to\ndouble use of data and overfitting, if the user reinforces noisy patterns in\nthe data. We propose a user modelling methodology, by assuming simple rational\nbehaviour, to correct the problem. We show, in a user study with 48\nparticipants, that the method improves predictive performance in a sparse\nlinear regression sentiment analysis task, where graded user knowledge on\nfeature relevance is elicited. We believe that the key idea of inferring user\nknowledge with probabilistic user models has general applicability in guarding\nagainst overfitting and improving interactive machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 11:52:19 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 02:06:27 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Daee", "Pedram", ""], ["Peltola", "Tomi", ""], ["Vehtari", "Aki", ""], ["Kaski", "Samuel", ""]]}, {"id": "1710.04908", "submitter": "Meihao Chen", "authors": "Meihao Chen, Zhuoru Lin, Kyunghyun Cho", "title": "Graph Convolutional Networks for Classification with a Structured Label\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a usual practice to ignore any structural information underlying\nclasses in multi-class classification. In this paper, we propose a graph\nconvolutional network (GCN) augmented neural network classifier to exploit a\nknown, underlying graph structure of labels. The proposed approach resembles an\n(approximate) inference procedure in, for instance, a conditional random field\n(CRF). We evaluate the proposed approach on document classification and object\nrecognition and report both accuracies and graph-theoretic metrics that\ncorrespond to the consistency of the model's prediction. The experiment results\nreveal that the proposed model outperforms a baseline method which ignores the\ngraph structures of a label space in terms of graph-theoretic metrics.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 02:39:18 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 07:21:29 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Chen", "Meihao", ""], ["Lin", "Zhuoru", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1710.04924", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama and Hajime Shimao", "title": "Two-stage Algorithm for Fairness-aware Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic decision making process now affects many aspects of our lives.\nStandard tools for machine learning, such as classification and regression, are\nsubject to the bias in data, and thus direct application of such off-the-shelf\ntools could lead to a specific group being unfairly discriminated. Removing\nsensitive attributes of data does not solve this problem because a\n\\textit{disparate impact} can arise when non-sensitive attributes and sensitive\nattributes are correlated. Here, we study a fair machine learning algorithm\nthat avoids such a disparate impact when making a decision. Inspired by the\ntwo-stage least squares method that is widely used in the field of economics,\nwe propose a two-stage algorithm that removes bias in the training data. The\nproposed algorithm is conceptually simple. Unlike most of existing fair\nalgorithms that are designed for classification tasks, the proposed method is\nable to (i) deal with regression tasks, (ii) combine explanatory attributes to\nremove reverse discrimination, and (iii) deal with numerical sensitive\nattributes. The performance and fairness of the proposed algorithm are\nevaluated in simulations with synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 13:58:42 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Komiyama", "Junpei", ""], ["Shimao", "Hajime", ""]]}, {"id": "1710.04934", "submitter": "Muktabh Mayank Srivastava", "authors": "Monika Grewal, Muktabh Mayank Srivastava, Pulkit Kumar, Srikrishna\n  Varadarajan", "title": "RADNET: Radiologist Level Accuracy using Deep Learning for HEMORRHAGE\n  detection in CT Scans", "comments": "Accepted at IEEE Symposium on Biomedical Imaging (ISBI) 2018 as\n  conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe a deep learning approach for automated brain hemorrhage detection\nfrom computed tomography (CT) scans. Our model emulates the procedure followed\nby radiologists to analyse a 3D CT scan in real-world. Similar to radiologists,\nthe model sifts through 2D cross-sectional slices while paying close attention\nto potential hemorrhagic regions. Further, the model utilizes 3D context from\nneighboring slices to improve predictions at each slice and subsequently,\naggregates the slice-level predictions to provide diagnosis at CT level. We\nrefer to our proposed approach as Recurrent Attention DenseNet (RADnet) as it\nemploys original DenseNet architecture along with adding the components of\nattention for slice level predictions and recurrent neural network layer for\nincorporating 3D context. The real-world performance of RADnet has been\nbenchmarked against independent analysis performed by three senior radiologists\nfor 77 brain CTs. RADnet demonstrates 81.82% hemorrhage prediction accuracy at\nCT level that is comparable to radiologists. Further, RADnet achieves higher\nrecall than two of the three radiologists, which is remarkable.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 14:14:39 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 12:05:54 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Grewal", "Monika", ""], ["Srivastava", "Muktabh Mayank", ""], ["Kumar", "Pulkit", ""], ["Varadarajan", "Srikrishna", ""]]}, {"id": "1710.05012", "submitter": "Sreeram Kannan", "authors": "Arman Rahimzamani and Sreeram Kannan", "title": "Potential Conditional Mutual Information: Estimators, Properties and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional mutual information I(X;Y|Z) measures the average information\nthat X and Y contain about each other given Z. This is an important primitive\nin many learning problems including conditional independence testing, graphical\nmodel inference, causal strength estimation and time-series problems. In\nseveral applications, it is desirable to have a functional purely of the\nconditional distribution p_{Y|X,Z} rather than of the joint distribution\np_{X,Y,Z}. We define the potential conditional mutual information as the\nconditional mutual information calculated with a modified joint distribution\np_{Y|X,Z} q_{X,Z}, where q_{X,Z} is a potential distribution, fixed airport. We\ndevelop K nearest neighbor based estimators for this functional, employing\nimportance sampling, and a coupling trick, and prove the finite k consistency\nof such an estimator. We demonstrate that the estimator has excellent practical\nperformance and show an application in dynamical system inference.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 17:26:18 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Rahimzamani", "Arman", ""], ["Kannan", "Sreeram", ""]]}, {"id": "1710.05050", "submitter": "Phil\\'emon Brakel", "authors": "Philemon Brakel and Yoshua Bengio", "title": "Learning Independent Features with Adversarial Nets for Non-linear ICA", "comments": "A preliminary version of this work was presented at the ICML 2017\n  workshop on implicit models", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable measures of statistical dependence could be useful tools for\nlearning independent features and performing tasks like source separation using\nIndependent Component Analysis (ICA). Unfortunately, many of such measures,\nlike the mutual information, are hard to estimate and optimize directly. We\npropose to learn independent features with adversarial objectives which\noptimize such measures implicitly. These objectives compare samples from the\njoint distribution and the product of the marginals without the need to compute\nany probability densities. We also propose two methods for obtaining samples\nfrom the product of the marginals using either a simple resampling trick or a\nseparate parametric distribution. Our experiments show that this strategy can\neasily be applied to different types of model architectures and solve both\nlinear and non-linear ICA problems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 18:29:56 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Brakel", "Philemon", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1710.05053", "submitter": "Trevor Campbell", "authors": "Trevor Campbell, Tamara Broderick", "title": "Automated Scalable Bayesian Inference via Hilbert Coresets", "comments": null, "journal-ref": "Journal of Machine Learning Research 20(15):1-38, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automation of posterior inference in Bayesian data analysis has enabled\nexperts and nonexperts alike to use more sophisticated models, engage in faster\nexploratory modeling and analysis, and ensure experimental reproducibility.\nHowever, standard automated posterior inference algorithms are not tractable at\nthe scale of massive modern datasets, and modifications to make them so are\ntypically model-specific, require expert tuning, and can break theoretical\nguarantees on inferential quality. Building on the Bayesian coresets framework,\nthis work instead takes advantage of data redundancy to shrink the dataset\nitself as a preprocessing step, providing fully-automated, scalable Bayesian\ninference with theoretical guarantees. We begin with an intuitive reformulation\nof Bayesian coreset construction as sparse vector sum approximation, and\ndemonstrate that its automation and performance-based shortcomings arise from\nthe use of the supremum norm. To address these shortcomings we develop Hilbert\ncoresets, i.e., Bayesian coresets constructed under a norm induced by an\ninner-product on the log-likelihood function space. We propose two Hilbert\ncoreset construction algorithms---one based on importance sampling, and one\nbased on the Frank-Wolfe algorithm---along with theoretical guarantees on\napproximation quality as a function of coreset size. Since the exact\ncomputation of the proposed inner-products is model-specific, we automate the\nconstruction with a random finite-dimensional projection of the log-likelihood\nfunctions. The resulting automated coreset construction algorithm is simple to\nimplement, and experiments on a variety of models with real and synthetic\ndatasets show that it provides high-quality posterior approximations and a\nsignificant reduction in the computational cost of inference.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 19:13:40 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 08:59:59 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Campbell", "Trevor", ""], ["Broderick", "Tamara", ""]]}, {"id": "1710.05080", "submitter": "Lin Xiao", "authors": "Lin Xiao, Adams Wei Yu, Qihang Lin, Weizhu Chen", "title": "DSCOVR: Randomized Primal-Dual Block Coordinate Algorithms for\n  Asynchronous Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning with big data often involves large optimization models. For\ndistributed optimization over a cluster of machines, frequent communication and\nsynchronization of all model parameters (optimization variables) can be very\ncostly. A promising solution is to use parameter servers to store different\nsubsets of the model parameters, and update them asynchronously at different\nmachines using local datasets. In this paper, we focus on distributed\noptimization of large linear models with convex loss functions, and propose a\nfamily of randomized primal-dual block coordinate algorithms that are\nespecially suitable for asynchronous distributed implementation with parameter\nservers. In particular, we work with the saddle-point formulation of such\nproblems which allows simultaneous data and model partitioning, and exploit its\nstructure by doubly stochastic coordinate optimization with variance reduction\n(DSCOVR). Compared with other first-order distributed algorithms, we show that\nDSCOVR may require less amount of overall computation and communication, and\nless or no synchronization. We discuss the implementation details of the DSCOVR\nalgorithms, and present numerical experiments on an industrial distributed\ncomputing system.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 21:19:01 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Xiao", "Lin", ""], ["Yu", "Adams Wei", ""], ["Lin", "Qihang", ""], ["Chen", "Weizhu", ""]]}, {"id": "1710.05086", "submitter": "Romain Lopez", "authors": "Romain Lopez, Jeffrey Regier, Michael Cole, Michael Jordan and Nir\n  Yosef", "title": "A deep generative model for single-cell RNA sequencing with application\n  to detecting differentially expressed genes", "comments": "Updated a previous submission instead. See arXiv:1709.02082", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic model for interpreting gene expression levels that\nare observed through single-cell RNA sequencing. In the model, each cell has a\nlow-dimensional latent representation. Additional latent variables account for\ntechnical effects that may erroneously set some observations of gene expression\nlevels to zero. Conditional distributions are specified by neural networks,\ngiving the proposed model enough flexibility to fit the data well. We use\nvariational inference and stochastic optimization to approximate the posterior\ndistribution. The inference procedure scales to over one million cells, whereas\ncompeting algorithms do not. Even for smaller datasets, for several tasks, the\nproposed procedure outperforms state-of-the-art methods like ZIFA and\nZINB-WaVE. We also extend our framework to take into account batch effects and\nother confounding factors and propose a natural Bayesian hypothesis framework\nfor differential expression that outperforms tradition DESeq2.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 21:47:48 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 01:42:35 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Lopez", "Romain", ""], ["Regier", "Jeffrey", ""], ["Cole", "Michael", ""], ["Jordan", "Michael", ""], ["Yosef", "Nir", ""]]}, {"id": "1710.05090", "submitter": "Alex Kuefler", "authors": "Alex Kuefler, Mykel J. Kochenderfer", "title": "Burn-In Demonstrations for Multi-Modal Imitation Learning", "comments": "1st Conference on Robotic Learning, Non-archival Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on imitation learning has generated policies that reproduce\nexpert behavior from multi-modal data. However, past approaches have focused\nonly on recreating a small number of distinct, expert maneuvers, or have relied\non supervised learning techniques that produce unstable policies. This work\nextends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce\nbehavior over an extended period of time. Our approach involves reformulating\nthe typical imitation learning setting to include \"burn-in demonstrations\" upon\nwhich policies are conditioned at test time. We demonstrate that our approach\noutperforms standard InfoGAIL in maximizing the mutual information between\npredicted and unseen style labels in road scene simulations, and we show that\nour method leads to policies that imitate expert autonomous driving systems\nover long time horizons.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 22:29:51 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Kuefler", "Alex", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1710.05091", "submitter": "Gourab Mitra", "authors": "Gourab Mitra, Shashidhar Sundareisan and Bikash Kanti Sarkar", "title": "A simple data discretizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data discretization is an important step in the process of machine learning,\nsince it is easier for classifiers to deal with discrete attributes rather than\ncontinuous attributes. Over the years, several methods of performing\ndiscretization such as Boolean Reasoning, Equal Frequency Binning, Entropy have\nbeen proposed, explored, and implemented. In this article, a simple supervised\ndiscretization approach is introduced. The prime goal of MIL is to maximize\nclassification accuracy of classifier, minimizing loss of information while\ndiscretization of continuous attributes. The performance of the suggested\napproach is compared with the supervised discretization algorithm Minimum\nInformation Loss (MIL), using the state-of-the-art rule inductive algorithms-\nJ48 (Java implementation of C4.5 classifier). The presented approach is,\nindeed, the modified version of MIL. The empirical results show that the\nmodified approach performs better in several cases in comparison to the\noriginal MIL algorithm and Minimum Description Length Principle (MDLP) .\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 22:45:11 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Mitra", "Gourab", ""], ["Sundareisan", "Shashidhar", ""], ["Sarkar", "Bikash Kanti", ""]]}, {"id": "1710.05092", "submitter": "Jacopo Cavazza", "authors": "Jacopo Cavazza, Pietro Morerio, Benjamin Haeffele, Connor Lane,\n  Vittorio Murino, Rene Vidal", "title": "Dropout as a Low-Rank Regularizer for Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization for matrix factorization (MF) and approximation problems has\nbeen carried out in many different ways. Due to its popularity in deep\nlearning, dropout has been applied also for this class of problems. Despite its\nsolid empirical performance, the theoretical properties of dropout as a\nregularizer remain quite elusive for this class of problems. In this paper, we\npresent a theoretical analysis of dropout for MF, where Bernoulli random\nvariables are used to drop columns of the factors. We demonstrate the\nequivalence between dropout and a fully deterministic model for MF in which the\nfactors are regularized by the sum of the product of squared Euclidean norms of\nthe columns. Additionally, we inspect the case of a variable sized\nfactorization and we prove that dropout achieves the global minimum of a convex\napproximation problem with (squared) nuclear norm regularization. As a result,\nwe conclude that dropout can be used as a low-rank regularizer with data\ndependent singular-value thresholding.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 22:47:19 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Cavazza", "Jacopo", ""], ["Morerio", "Pietro", ""], ["Haeffele", "Benjamin", ""], ["Lane", "Connor", ""], ["Murino", "Vittorio", ""], ["Vidal", "Rene", ""]]}, {"id": "1710.05101", "submitter": "Maximilian Karl", "authors": "Maximilian Karl, Maximilian Soelch, Philip Becker-Ehmck, Djalel\n  Benbouzid, Patrick van der Smagt, Justin Bayer", "title": "Unsupervised Real-Time Control through Variational Empowerment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a methodology for efficiently computing a lower bound to\nempowerment, allowing it to be used as an unsupervised cost function for policy\nlearning in real-time control. Empowerment, being the channel capacity between\nactions and states, maximises the influence of an agent on its near future. It\nhas been shown to be a good model of biological behaviour in the absence of an\nextrinsic goal. But empowerment is also prohibitively hard to compute,\nespecially in nonlinear continuous spaces. We introduce an efficient, amortised\nmethod for learning empowerment-maximising policies. We demonstrate that our\nalgorithm can reliably handle continuous dynamical systems using system\ndynamics learned from raw data. The resulting policies consistently drive the\nagents into states where they can use their full potential.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 23:51:38 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Karl", "Maximilian", ""], ["Soelch", "Maximilian", ""], ["Becker-Ehmck", "Philip", ""], ["Benbouzid", "Djalel", ""], ["van der Smagt", "Patrick", ""], ["Bayer", "Justin", ""]]}, {"id": "1710.05114", "submitter": "Anastasis Kratsios", "authors": "Anastasis Kratsios and Cody B. Hyndman", "title": "Deep Learning in a Generalized HJM-type Framework Through Arbitrage-Free\n  Regularization", "comments": "23 Pages + References", "journal-ref": null, "doi": "10.3390/risks8020040", "report-no": null, "categories": "q-fin.MF math.PR q-fin.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a regularization approach to arbitrage-free factor-model\nselection. The considered model selection problem seeks to learn the closest\narbitrage-free HJM-type model to any prespecified factor-model. An asymptotic\nsolution to this, a priori computationally intractable, problem is represented\nas the limit of a 1-parameter family of optimizers to computationally tractable\nmodel selection tasks. Each of these simplified model-selection tasks seeks to\nlearn the most similar model, to the prescribed factor-model, subject to a\npenalty detecting when the reference measure is a local martingale-measure for\nthe entire underlying financial market. A simple expression for the penalty\nterms is obtained in the bond market withing the affine-term structure setting,\nand it is used to formulate a deep-learning approach to arbitrage-free affine\nterm-structure modelling. Numerical implementations are also performed to\nevaluate the performance in the bond market.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 00:51:18 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 00:43:59 GMT"}, {"version": "v3", "created": "Sun, 12 Aug 2018 16:45:06 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 16:07:18 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Kratsios", "Anastasis", ""], ["Hyndman", "Cody B.", ""]]}, {"id": "1710.05115", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Dixin Luo, Xu Chen, Lawrence Carin", "title": "Benefits from Superposed Hawkes Processes", "comments": null, "journal-ref": "AISTATS 2018", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The superposition of temporal point processes has been studied for many\nyears, although the usefulness of such models for practical applications has\nnot be fully developed. We investigate superposed Hawkes process as an\nimportant class of such models, with properties studied in the framework of\nleast squares estimation. The superposition of Hawkes processes is demonstrated\nto be beneficial for tightening the upper bound of excess risk under certain\nconditions, and we show the feasibility of the benefit in typical situations.\nThe usefulness of superposed Hawkes processes is verified on synthetic data,\nand its potential to solve the cold-start problem of recommendation systems is\ndemonstrated on real-world data.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 00:53:42 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 16:05:47 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 16:26:53 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Xu", "Hongteng", ""], ["Luo", "Dixin", ""], ["Chen", "Xu", ""], ["Carin", "Lawrence", ""]]}, {"id": "1710.05135", "submitter": "Lin Wu", "authors": "Tong Chen, Lin Wu, Yang Wang, Jun Zhang, Hongxu Chen, Xue Li", "title": "When Point Process Meets RNNs: Predicting Fine-Grained User Interests\n  with Mutual Behavioral Infectivity", "comments": "Several existing references are missing and not discussed explicitly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting fine-grained interests of users with temporal behavior is\nimportant to personalization and information filtering applications. However,\nexisting interest prediction methods are incapable of capturing the subtle\ndegreed user interests towards particular items, and the internal time-varying\ndrifting attention of individuals is not studied yet. Moreover, the prediction\nprocess can also be affected by inter-personal influence, known as behavioral\nmutual infectivity. Inspired by point process in modeling temporal point\nprocess, in this paper we present a deep prediction method based on two\nrecurrent neural networks (RNNs) to jointly model each user's continuous\nbrowsing history and asynchronous event sequences in the context of inter-user\nbehavioral mutual infectivity. Our model is able to predict the fine-grained\ninterest from a user regarding a particular item and corresponding timestamps\nwhen an occurrence of event takes place. The proposed approach is more flexible\nto capture the dynamic characteristic of event sequences by using the temporal\npoint process to model event data and timely update its intensity function by\nRNNs. Furthermore, to improve the interpretability of the model, the attention\nmechanism is introduced to emphasize both intra-personal and inter-personal\nbehavior influence over time. Experiments on real datasets demonstrate that our\nmodel outperforms the state-of-the-art methods in fine-grained user interest\nprediction.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 05:37:55 GMT"}, {"version": "v2", "created": "Sun, 22 Oct 2017 00:12:38 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Chen", "Tong", ""], ["Wu", "Lin", ""], ["Wang", "Yang", ""], ["Zhang", "Jun", ""], ["Chen", "Hongxu", ""], ["Li", "Xue", ""]]}, {"id": "1710.05163", "submitter": "Xinwei Deng", "authors": "Xiaoning Kang and Xinwei Deng", "title": "An Improved Modified Cholesky Decomposition Method for Precision Matrix\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modified Cholesky decomposition is commonly used for precision matrix\nestimation given a specified order of random variables. However, the order of\nvariables is often not available or cannot be pre-determined. In this work, we\npropose to address the variable order issue in the modified Cholesky\ndecomposition for sparse precision matrix estimation. The key idea is to\neffectively combine a set of estimates obtained from multiple permutations of\nvariable orders, and to efficiently encourage the sparse structure for the\nresultant estimate by the thresholding technique on the ensemble Cholesky\nfactor matrix. The consistent property of the proposed estimate is established\nunder some weak regularity conditions. Simulation studies are conducted to\nevaluate the performance of the proposed method in comparison with several\nexisting approaches. The proposed method is also applied into linear\ndiscriminant analysis of real data for classification.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 11:14:26 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 01:19:34 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kang", "Xiaoning", ""], ["Deng", "Xinwei", ""]]}, {"id": "1710.05213", "submitter": "Maxim Panov", "authors": "Nikita Mokrov, Maxim Panov, Boris A. Gutman, Joshua I. Faskowitz, Neda\n  Jahanshad and Paul M. Thompson", "title": "Simultaneous Matrix Diagonalization for Structural Brain Networks\n  Classification", "comments": null, "journal-ref": "Complex Networks & Their Applications VI. COMPLEX NETWORKS 2017.\n  Studies in Computational Intelligence, vol 689", "doi": "10.1007/978-3-319-72150-7_102", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of brain disease classification based on\nconnectome data. A connectome is a network representation of a human brain. The\ntypical connectome classification problem is very challenging because of the\nsmall sample size and high dimensionality of the data. We propose to use\nsimultaneous approximate diagonalization of adjacency matrices in order to\ncompute their eigenstructures in more stable way. The obtained approximate\neigenvalues are further used as features for classification. The proposed\napproach is demonstrated to be efficient for detection of Alzheimer's disease,\noutperforming simple baselines and competing with state-of-the-art approaches\nto brain disease classification.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 17:12:42 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Mokrov", "Nikita", ""], ["Panov", "Maxim", ""], ["Gutman", "Boris A.", ""], ["Faskowitz", "Joshua I.", ""], ["Jahanshad", "Neda", ""], ["Thompson", "Paul M.", ""]]}, {"id": "1710.05241", "submitter": "Qunwei Li", "authors": "Qunwei Li, Bhavya Kailkhura, Ryan Goldhahn, Priyadip Ray, Pramod K.\n  Varshney", "title": "Robust Decentralized Learning Using ADMM with Unreliable Agents", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems can be formulated as consensus optimization\nproblems which can be solved efficiently via a cooperative multi-agent system.\nHowever, the agents in the system can be unreliable due to a variety of\nreasons: noise, faults and attacks. Providing erroneous updates leads the\noptimization process in a wrong direction, and degrades the performance of\ndistributed machine learning algorithms. This paper considers the problem of\ndecentralized learning using ADMM in the presence of unreliable agents. First,\nwe rigorously analyze the effect of erroneous updates (in ADMM learning\niterations) on the convergence behavior of multi-agent system. We show that the\nalgorithm linearly converges to a neighborhood of the optimal solution under\ncertain conditions and characterize the neighborhood size analytically. Next,\nwe provide guidelines for network design to achieve a faster convergence. We\nalso provide conditions on the erroneous updates for exact convergence to the\noptimal solution. Finally, to mitigate the influence of unreliable agents, we\npropose \\textsf{ROAD}, a robust variant of ADMM, and show its resilience to\nunreliable agents with an exact convergence to the optimum.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 21:44:32 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 21:08:41 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 19:10:13 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Li", "Qunwei", ""], ["Kailkhura", "Bhavya", ""], ["Goldhahn", "Ryan", ""], ["Ray", "Priyadip", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1710.05270", "submitter": "Wei Ping", "authors": "Wei Ping, Qiang Liu, Alexander Ihler", "title": "Learning Infinite RBMs with Frank-Wolfe", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an infinite restricted Boltzmann machine~(RBM),\nwhose maximum likelihood estimation~(MLE) corresponds to a constrained convex\noptimization. We consider the Frank-Wolfe algorithm to solve the program, which\nprovides a sparse solution that can be interpreted as inserting a hidden unit\nat each iteration, so that the optimization process takes the form of a\nsequence of finite models of increasing complexity. As a side benefit, this can\nbe used to easily and efficiently identify an appropriate number of hidden\nunits during the optimization. The resulting model can also be used as an\ninitialization for typical state-of-the-art RBM training algorithms such as\ncontrastive divergence, leading to models with consistently higher test\nlikelihood than random initialization.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 03:38:32 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Ping", "Wei", ""], ["Liu", "Qiang", ""], ["Ihler", "Alexander", ""]]}, {"id": "1710.05279", "submitter": "Shenghao Shi", "authors": "Shenghao Shi", "title": "Facial Keypoints Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Detect facial keypoints is a critical element in face recognition. However,\nthere is difficulty to catch keypoints on the face due to complex influences\nfrom original images, and there is no guidance to suitable algorithms. In this\npaper, we study different algorithms that can be applied to locate keyponits.\nSpecifically: our framework (1)prepare the data for further investigation\n(2)Using PCA and LBP to process the data (3) Apply different algorithms to\nanalysis data, including linear regression models, tree based model, neural\nnetwork and convolutional neural network, etc. Finally we will give our\nconclusion and further research topic. A comprehensive set of experiments on\ndataset demonstrates the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 05:38:16 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Shi", "Shenghao", ""]]}, {"id": "1710.05338", "submitter": "Tsz Kit Lau", "authors": "Tsz Kit Lau and Yuan Yao", "title": "Accelerated Block Coordinate Proximal Gradients with Applications in\n  High Dimensional Statistics", "comments": "10th NIPS Workshop on Optimization for Machine Learning (NIPS 2017).\n  8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex optimization problems arise in different research fields and arouse\nlots of attention in signal processing, statistics and machine learning. In\nthis work, we explore the accelerated proximal gradient method and some of its\nvariants which have been shown to converge under nonconvex context recently. We\nshow that a novel variant proposed here, which exploits adaptive momentum and\nblock coordinate update with specific update rules, further improves the\nperformance of a broad class of nonconvex problems. In applications to sparse\nlinear regression with regularizations like Lasso, grouped Lasso, capped\n$\\ell_1$ and SCAP, the proposed scheme enjoys provable local linear\nconvergence, with experimental justification.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 14:07:32 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 11:21:32 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2017 06:31:38 GMT"}, {"version": "v4", "created": "Mon, 30 Oct 2017 15:16:24 GMT"}, {"version": "v5", "created": "Tue, 31 Oct 2017 11:40:24 GMT"}, {"version": "v6", "created": "Sat, 18 Nov 2017 09:26:25 GMT"}, {"version": "v7", "created": "Sun, 3 Dec 2017 11:21:03 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Lau", "Tsz Kit", ""], ["Yao", "Yuan", ""]]}, {"id": "1710.05359", "submitter": "Tomoya Sakai", "authors": "Tomoya Sakai and Gang Niu and Masashi Sugiyama", "title": "Information-Theoretic Representation Learning for Positive-Unlabeled\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in weakly supervised classification allow us to train a\nclassifier only from positive and unlabeled (PU) data. However, existing PU\nclassification methods typically require an accurate estimate of the\nclass-prior probability, which is a critical bottleneck particularly for\nhigh-dimensional data. This problem has been commonly addressed by applying\nprincipal component analysis in advance, but such unsupervised dimension\nreduction can collapse underlying class structure. In this paper, we propose a\nnovel representation learning method from PU data based on the\ninformation-maximization principle. Our method does not require class-prior\nestimation and thus can be used as a preprocessing method for PU\nclassification. Through experiments, we demonstrate that our method combined\nwith deep neural networks highly improves the accuracy of PU class-prior\nestimation, leading to state-of-the-art PU classification performance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 16:19:37 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 10:50:54 GMT"}, {"version": "v3", "created": "Mon, 12 Feb 2018 06:45:53 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Sakai", "Tomoya", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1710.05381", "submitter": "Mateusz Buda", "authors": "Mateusz Buda, Atsuto Maki, Maciej A. Mazurowski", "title": "A systematic study of the class imbalance problem in convolutional\n  neural networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2018.07.011", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we systematically investigate the impact of class imbalance on\nclassification performance of convolutional neural networks (CNNs) and compare\nfrequently used methods to address the issue. Class imbalance is a common\nproblem that has been comprehensively studied in classical machine learning,\nyet very limited systematic research is available in the context of deep\nlearning. In our study, we use three benchmark datasets of increasing\ncomplexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of\nimbalance on classification and perform an extensive comparison of several\nmethods to address the issue: oversampling, undersampling, two-phase training,\nand thresholding that compensates for prior class probabilities. Our main\nevaluation metric is area under the receiver operating characteristic curve\n(ROC AUC) adjusted to multi-class tasks since overall accuracy metric is\nassociated with notable difficulties in the context of imbalanced data. Based\non results from our experiments we conclude that (i) the effect of class\nimbalance on classification performance is detrimental; (ii) the method of\naddressing class imbalance that emerged as dominant in almost all analyzed\nscenarios was oversampling; (iii) oversampling should be applied to the level\nthat completely eliminates the imbalance, whereas the optimal undersampling\nratio depends on the extent of imbalance; (iv) as opposed to some classical\nmachine learning models, oversampling does not cause overfitting of CNNs; (v)\nthresholding should be applied to compensate for prior class probabilities when\noverall number of properly classified cases is of interest.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 19:01:43 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2018 02:02:17 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Buda", "Mateusz", ""], ["Maki", "Atsuto", ""], ["Mazurowski", "Maciej A.", ""]]}, {"id": "1710.05384", "submitter": "Chuang Wang", "authors": "Chuang Wang and Yue M. Lu", "title": "The Scaling Limit of High-Dimensional Online Independent Component\n  Analysis", "comments": "10 pages, 3 figures, 31st Conference on Neural Information Processing\n  Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the dynamics of an online algorithm for independent component\nanalysis in the high-dimensional scaling limit. As the ambient dimension tends\nto infinity, and with proper time scaling, we show that the time-varying joint\nempirical measure of the target feature vector and the estimates provided by\nthe algorithm will converge weakly to a deterministic measured-valued process\nthat can be characterized as the unique solution of a nonlinear PDE. Numerical\nsolutions of this PDE, which involves two spatial variables and one time\nvariable, can be efficiently obtained. These solutions provide detailed\ninformation about the performance of the ICA algorithm, as many practical\nperformance metrics are functionals of the joint empirical measures. Numerical\nsimulations show that our asymptotic analysis is accurate even for moderate\ndimensions. In addition to providing a tool for understanding the performance\nof the algorithm, our PDE analysis also provides useful insight. In particular,\nin the high-dimensional limit, the original coupled dynamics associated with\nthe algorithm will be asymptotically \"decoupled\", with each coordinate\nindependently solving a 1-D effective minimization problem via stochastic\ngradient descent. Exploiting this insight to design new algorithms for\nachieving optimal trade-offs between computational and statistical efficiency\nmay prove an interesting line of future research.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 19:14:26 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 02:48:03 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Wang", "Chuang", ""], ["Lu", "Yue M.", ""]]}, {"id": "1710.05387", "submitter": "Xinyan Yan", "authors": "Xinyan Yan, Krzysztof Choromanski, Byron Boots, Vikas Sindhwani", "title": "Manifold Regularization for Kernelized LSTD", "comments": "6 pages, CoRL 2017 non-archival track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation or value function or Q-function approximation is a key\nprocedure in reinforcement learning (RL). It is a necessary component of policy\niteration and can be used for variance reduction in policy gradient methods.\nTherefore its quality has a significant impact on most RL algorithms. Motivated\nby manifold regularized learning, we propose a novel kernelized policy\nevaluation method that takes advantage of the intrinsic geometry of the state\nspace learned from data, in order to achieve better sample efficiency and\nhigher accuracy in Q-function approximation. Applying the proposed method in\nthe Least-Squares Policy Iteration (LSPI) framework, we observe superior\nperformance compared to widely used parametric basis functions on two standard\nbenchmarks in terms of policy quality.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 19:59:13 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Yan", "Xinyan", ""], ["Choromanski", "Krzysztof", ""], ["Boots", "Byron", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1710.05420", "submitter": "Ermao Cai", "authors": "Ermao Cai, Da-Cheng Juan, Dimitrios Stamoulis, Diana Marculescu", "title": "NeuralPower: Predict and Deploy Energy-Efficient Convolutional Neural\n  Networks", "comments": "Accepted as a conference paper at ACML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"How much energy is consumed for an inference made by a convolutional neural\nnetwork (CNN)?\" With the increased popularity of CNNs deployed on the\nwide-spectrum of platforms (from mobile devices to workstations), the answer to\nthis question has drawn significant attention. From lengthening battery life of\nmobile devices to reducing the energy bill of a datacenter, it is important to\nunderstand the energy efficiency of CNNs during serving for making an\ninference, before actually training the model. In this work, we propose\nNeuralPower: a layer-wise predictive framework based on sparse polynomial\nregression, for predicting the serving energy consumption of a CNN deployed on\nany GPU platform. Given the architecture of a CNN, NeuralPower provides an\naccurate prediction and breakdown for power and runtime across all layers in\nthe whole network, helping machine learners quickly identify the power,\nruntime, or energy bottlenecks. We also propose the \"energy-precision ratio\"\n(EPR) metric to guide machine learners in selecting an energy-efficient CNN\narchitecture that better trades off the energy consumption and prediction\naccuracy. The experimental results show that the prediction accuracy of the\nproposed NeuralPower outperforms the best published model to date, yielding an\nimprovement in accuracy of up to 68.5%. We also assess the accuracy of\npredictions at the network level, by predicting the runtime, power, and energy\nof state-of-the-art CNN architectures, achieving an average accuracy of 88.24%\nin runtime, 88.34% in power, and 97.21% in energy. We comprehensively\ncorroborate the effectiveness of NeuralPower as a powerful framework for\nmachine learners by testing it on different GPU platforms and Deep Learning\nsoftware tools.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 23:39:29 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Cai", "Ermao", ""], ["Juan", "Da-Cheng", ""], ["Stamoulis", "Dimitrios", ""], ["Marculescu", "Diana", ""]]}, {"id": "1710.05468", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Leslie Pack Kaelbling, Yoshua Bengio", "title": "Generalization in Deep Learning", "comments": "To appear in Mathematics of Deep Learning, Cambridge University\n  Press. All previous results remain unchanged", "journal-ref": null, "doi": null, "report-no": "Massachusetts Institute of Technology (MIT), MIT-CSAIL-TR-2018-014", "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides theoretical insights into why and how deep learning can\ngeneralize well, despite its large capacity, complexity, possible algorithmic\ninstability, nonrobustness, and sharp minima, responding to an open question in\nthe literature. We also discuss approaches to provide non-vacuous\ngeneralization guarantees for deep learning. Based on theoretical observations,\nwe propose new open problems and discuss the limitations of our results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 02:21:24 GMT"}, {"version": "v2", "created": "Sun, 24 Dec 2017 19:44:43 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 23:39:50 GMT"}, {"version": "v4", "created": "Tue, 1 Jan 2019 00:07:45 GMT"}, {"version": "v5", "created": "Fri, 10 May 2019 18:41:13 GMT"}, {"version": "v6", "created": "Mon, 27 Jul 2020 23:01:04 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Kaelbling", "Leslie Pack", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1710.05476", "submitter": "Haozhen Wu", "authors": "Haozhen Wu", "title": "Calibrated Boosting-Forest", "comments": "9 pages, 3 figures, 4 tables, NIPS 2017 Workshop on Machine Learning\n  for Molecules and Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excellent ranking power along with well calibrated probability estimates are\nneeded in many classification tasks. In this paper, we introduce a technique,\nCalibrated Boosting-Forest that captures both. This novel technique is an\nensemble of gradient boosting machines that can support both continuous and\nbinary labels. While offering superior ranking power over any individual\nregression or classification model, Calibrated Boosting-Forest is able to\npreserve well calibrated posterior probabilities. Along with these benefits, we\nprovide an alternative to the tedious step of tuning gradient boosting\nmachines. We demonstrate that tuning Calibrated Boosting-Forest can be reduced\nto a simple hyper-parameter selection. We further establish that increasing\nthis hyper-parameter improves the ranking performance under a diminishing\nreturn. We examine the effectiveness of Calibrated Boosting-Forest on\nligand-based virtual screening where both continuous and binary labels are\navailable and compare the performance of Calibrated Boosting-Forest with\nlogistic regression, gradient boosting machine and deep learning. Calibrated\nBoosting-Forest achieved an approximately 48% improvement compared to a\nstate-of-art deep learning model. Moreover, it achieved around 95% improvement\non probability quality measurement compared to the best individual gradient\nboosting machine. Calibrated Boosting-Forest offers a benchmark demonstration\nthat in the field of ligand-based virtual screening, deep learning is not the\nuniversally dominant machine learning model and good calibrated probabilities\ncan better facilitate virtual screening process.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 02:49:07 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 02:45:46 GMT"}, {"version": "v3", "created": "Mon, 13 Nov 2017 19:01:55 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Wu", "Haozhen", ""]]}, {"id": "1710.05488", "submitter": "Na Lei", "authors": "Na Lei, Kehua Su, Li Cui, Shing-Tung Yau, David Xianfeng Gu", "title": "A Geometric View of Optimal Transportation and Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we show the intrinsic relations between optimal transportation\nand convex geometry, especially the variational approach to solve Alexandrov\nproblem: constructing a convex polytope with prescribed face normals and\nvolumes. This leads to a geometric interpretation to generative models, and\nleads to a novel framework for generative models. By using the optimal\ntransportation view of GAN model, we show that the discriminator computes the\nKantorovich potential, the generator calculates the transportation map. For a\nlarge class of transportation costs, the Kantorovich potential can give the\noptimal transportation map by a close-form formula. Therefore, it is sufficient\nto solely optimize the discriminator. This shows the adversarial competition\ncan be avoided, and the computational architecture can be simplified.\nPreliminary experimental results show the geometric method outperforms WGAN for\napproximating probability measures with multiple clusters in low dimensional\nspace.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 03:30:09 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 04:28:31 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Lei", "Na", ""], ["Su", "Kehua", ""], ["Cui", "Li", ""], ["Yau", "Shing-Tung", ""], ["Gu", "David Xianfeng", ""]]}, {"id": "1710.05512", "submitter": "Roberto Calandra", "authors": "Roberto Calandra, Andrew Owens, Manu Upadhyaya, Wenzhen Yuan, Justin\n  Lin, Edward H. Adelson, Sergey Levine", "title": "The Feeling of Success: Does Touch Sensing Help Predict Grasp Outcomes?", "comments": "10 pages, accepted at the 1st Annual Conference on Robot Learning\n  (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A successful grasp requires careful balancing of the contact forces. Deducing\nwhether a particular grasp will be successful from indirect measurements, such\nas vision, is therefore quite challenging, and direct sensing of contacts\nthrough touch sensing provides an appealing avenue toward more successful and\nconsistent robotic grasping. However, in order to fully evaluate the value of\ntouch sensing for grasp outcome prediction, we must understand how touch\nsensing can influence outcome prediction accuracy when combined with other\nmodalities. Doing so using conventional model-based techniques is exceptionally\ndifficult. In this work, we investigate the question of whether touch sensing\naids in predicting grasp outcomes within a multimodal sensing framework that\ncombines vision and touch. To that end, we collected more than 9,000 grasping\ntrials using a two-finger gripper equipped with GelSight high-resolution\ntactile sensors on each finger, and evaluated visuo-tactile deep neural network\nmodels to directly predict grasp outcomes from either modality individually,\nand from both modalities together. Our experimental results indicate that\nincorporating tactile readings substantially improve grasping performance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 05:32:38 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Calandra", "Roberto", ""], ["Owens", "Andrew", ""], ["Upadhyaya", "Manu", ""], ["Yuan", "Wenzhen", ""], ["Lin", "Justin", ""], ["Adelson", "Edward H.", ""], ["Levine", "Sergey", ""]]}, {"id": "1710.05513", "submitter": "Ziping Zhao", "authors": "Ziping Zhao and Daniel P. Palomar", "title": "Robust Maximum Likelihood Estimation of Sparse Vector Error Correction\n  Model", "comments": "5 pages, 3 figures, to appear in Proc. of the 2017 5th IEEE Global\n  Conference on Signal and Information Processing (GlobalSIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NA q-fin.ST stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In econometrics and finance, the vector error correction model (VECM) is an\nimportant time series model for cointegration analysis, which is used to\nestimate the long-run equilibrium variable relationships. The traditional\nanalysis and estimation methodologies assume the underlying Gaussian\ndistribution but, in practice, heavy-tailed data and outliers can lead to the\ninapplicability of these methods. In this paper, we propose a robust model\nestimation method based on the Cauchy distribution to tackle this issue. In\naddition, sparse cointegration relations are considered to realize feature\nselection and dimension reduction. An efficient algorithm based on the\nmajorization-minimization (MM) method is applied to solve the proposed\nnonconvex problem. The performance of this algorithm is shown through numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 05:38:27 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Zhao", "Ziping", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "1710.05552", "submitter": "Liyuan Xu", "authors": "Liyuan Xu, Junya Honda, Masashi Sugiyama", "title": "Fully adaptive algorithm for pure exploration in linear bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first fully-adaptive algorithm for pure exploration in linear\nbandits---the task to find the arm with the largest expected reward, which\ndepends on an unknown parameter linearly. While existing methods partially or\nentirely fix sequences of arm selections before observing rewards, our method\nadaptively changes the arm selection strategy based on past observations at\neach round. We show our sample complexity matches the achievable lower bound up\nto a constant factor in an extreme case. Furthermore, we evaluate the\nperformance of the methods by simulations based on both synthetic setting and\nreal-world data, in which our method shows vast improvement over existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 08:16:50 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Xu", "Liyuan", ""], ["Honda", "Junya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1710.05578", "submitter": "Adrian Perez-Suay", "authors": "Adri\\'an P\\'erez-Suay, Valero Laparra, Gonzalo Mateo-Garc\\'ia, Jordi\n  Mu\\~noz-Mar\\'i, Luis G\\'omez-Chova, and Gustau Camps-Valls", "title": "Fair Kernel Learning", "comments": "Work published on ECML'17,\n  http://ecmlpkdd2017.ijs.si/papers/paperID275.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New social and economic activities massively exploit big data and machine\nlearning algorithms to do inference on people's lives. Applications include\nautomatic curricula evaluation, wage determination, and risk assessment for\ncredits and loans. Recently, many governments and institutions have raised\nconcerns about the lack of fairness, equity and ethics in machine learning to\ntreat these problems. It has been shown that not including sensitive features\nthat bias fairness, such as gender or race, is not enough to mitigate the\ndiscrimination when other related features are included. Instead, including\nfairness in the objective function has been shown to be more efficient.\n  We present novel fair regression and dimensionality reduction methods built\non a previously proposed fair classification framework. Both methods rely on\nusing the Hilbert Schmidt independence criterion as the fairness term. Unlike\nprevious approaches, this allows us to simplify the problem and to use multiple\nsensitive variables simultaneously. Replacing the linear formulation by kernel\nfunctions allows the methods to deal with nonlinear problems. For both linear\nand nonlinear formulations the solution reduces to solving simple matrix\ninversions or generalized eigenvalue problems. This simplifies the evaluation\nof the solutions for different trade-off values between the predictive error\nand fairness terms. We illustrate the usefulness of the proposed methods in toy\nexamples, and evaluate their performance on real world datasets to predict\nincome using gender and/or race discrimination as sensitive variables, and\ncontraceptive method prediction under demographic and socio-economic sensitive\ndescriptors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 09:19:56 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["P\u00e9rez-Suay", "Adri\u00e1n", ""], ["Laparra", "Valero", ""], ["Mateo-Garc\u00eda", "Gonzalo", ""], ["Mu\u00f1oz-Mar\u00ed", "Jordi", ""], ["G\u00f3mez-Chova", "Luis", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "1710.05613", "submitter": "Nino Antulov-Fantulin", "authors": "Vaibhav Krishna and Tian Guo and Nino Antulov-Fantulin", "title": "Is Simple Better? Revisiting Non-linear Matrix Factorization for\n  Learning Incomplete Ratings", "comments": "version 3", "journal-ref": null, "doi": "10.1109/ICDMW.2018.00183", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization techniques have been widely used as a method for\ncollaborative filtering for recommender systems. In recent times, different\nvariants of deep learning algorithms have been explored in this setting to\nimprove the task of making a personalized recommendation with user-item\ninteraction data. The idea that the mapping between the latent user or item\nfactors and the original features is highly nonlinear suggest that classical\nmatrix factorization techniques are no longer sufficient. In this paper, we\npropose a multilayer nonlinear semi-nonnegative matrix factorization method,\nwith the motivation that user-item interactions can be modeled more accurately\nusing a linear combination of non-linear item features. Firstly, we learn\nlatent factors for representations of users and items from the designed\nmultilayer nonlinear Semi-NMF approach using explicit ratings. Secondly, the\narchitecture built is compared with deep-learning algorithms like Restricted\nBoltzmann Machine and state-of-the-art Deep Matrix factorization techniques. By\nusing both supervised rate prediction task and unsupervised clustering in\nlatent item space, we demonstrate that our proposed approach achieves better\ngeneralization ability in prediction as well as comparable representation\nability as deep matrix factorization in the clustering task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 10:46:41 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 12:58:31 GMT"}, {"version": "v3", "created": "Fri, 21 Sep 2018 09:36:35 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Krishna", "Vaibhav", ""], ["Guo", "Tian", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "1710.05654", "submitter": "Nathanael Perraudin N. P.", "authors": "Vassilis Kalofolias, Nathana\\\"el Perraudin", "title": "Large Scale Graph Learning from Smooth Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are a prevalent tool in data science, as they model the inherent\nstructure of the data. They have been used successfully in unsupervised and\nsemi-supervised learning. Typically they are constructed either by connecting\nnearest samples, or by learning them from data, solving an optimization\nproblem. While graph learning does achieve a better quality, it also comes with\na higher computational cost. In particular, the current state-of-the-art model\ncost is $\\mathcal{O}(n^2)$ for $n$ samples. In this paper, we show how to scale\nit, obtaining an approximation with leading cost of $\\mathcal{O}(n\\log(n))$,\nwith quality that approaches the exact graph learning model. Our algorithm uses\nknown approximate nearest neighbor techniques to reduce the number of\nvariables, and automatically selects the correct parameters of the model,\nrequiring a single intuitive input: the desired edge density.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 12:42:15 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 12:30:44 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Kalofolias", "Vassilis", ""], ["Perraudin", "Nathana\u00ebl", ""]]}, {"id": "1710.05739", "submitter": "Gergely Neu", "authors": "G\\'abor Lugosi, Mihalis G. Markakis, Gergely Neu", "title": "On the Hardness of Inventory Management with Censored Demand Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a repeated newsvendor problem where the inventory manager has no\nprior information about the demand, and can access only censored/sales data. In\nanalogy to multi-armed bandit problems, the manager needs to simultaneously\n\"explore\" and \"exploit\" with her inventory decisions, in order to minimize the\ncumulative cost. We make no probabilistic assumptions---importantly,\nindependence or time stationarity---regarding the mechanism that creates the\ndemand sequence. Our goal is to shed light on the hardness of the problem, and\nto develop policies that perform well with respect to the regret criterion,\nthat is, the difference between the cumulative cost of a policy and that of the\nbest fixed action/static inventory decision in hindsight, uniformly over all\nfeasible demand sequences. We show that a simple randomized policy, termed the\nExponentially Weighted Forecaster, combined with a carefully designed cost\nestimator, achieves optimal scaling of the expected regret (up to logarithmic\nfactors) with respect to all three key primitives: the number of time periods,\nthe number of inventory decisions available, and the demand support. Through\nthis result, we derive an important insight: the benefit from \"information\nstalking\" as well as the cost of censoring are both negligible in this dynamic\nlearning problem, at least with respect to the regret criterion. Furthermore,\nwe modify the proposed policy in order to perform well in terms of the tracking\nregret, that is, using as benchmark the best sequence of inventory decisions\nthat switches a limited number of times. Numerical experiments suggest that the\nproposed approach outperforms existing ones (that are tailored to, or\nfacilitated by, time stationarity) on nonstationary demand models. Finally, we\nextend the proposed approach and its analysis to a \"combinatorial\" version of\nthe repeated newsvendor problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 14:33:59 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Lugosi", "G\u00e1bor", ""], ["Markakis", "Mihalis G.", ""], ["Neu", "Gergely", ""]]}, {"id": "1710.05741", "submitter": "Marco Fraccaro", "authors": "Marco Fraccaro, Simon Kamronn, Ulrich Paquet, Ole Winther", "title": "A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised\n  Learning", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper takes a step towards temporal reasoning in a dynamically changing\nvideo, not in the pixel space that constitutes its frames, but in a latent\nspace that describes the non-linear dynamics of the objects in its world. We\nintroduce the Kalman variational auto-encoder, a framework for unsupervised\nlearning of sequential data that disentangles two latent representations: an\nobject's representation, coming from a recognition model, and a latent state\ndescribing its dynamics. As a result, the evolution of the world can be\nimagined and missing data imputed, both without the need to generate high\ndimensional frames at each time step. The model is trained end-to-end on videos\nof a variety of simulated physical systems, and outperforms competing methods\nin generative and missing data imputation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 14:34:24 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 09:34:32 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Fraccaro", "Marco", ""], ["Kamronn", "Simon", ""], ["Paquet", "Ulrich", ""], ["Winther", "Ole", ""]]}, {"id": "1710.05751", "submitter": "Aaron Elliot", "authors": "Aaron Elliot, Cheng Hua Hsu", "title": "Time Series Prediction : Predicting Stock Price", "comments": "Under advisement of Dr. Sang Kim, for his class CS542. Additional\n  author unnamed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is widely used in a multitude of domains. In this\npaper, we present four models to predict the stock price using the SPX index as\ninput time series data. The martingale and ordinary linear models require the\nstrongest assumption in stationarity which we use as baseline models. The\ngeneralized linear model requires lesser assumptions but is unable to\noutperform the martingale. In empirical testing, the RNN model performs the\nbest comparing to other two models, because it will update the input through\nLSTM instantaneously, but also does not beat the martingale. In addition, we\nintroduce an online to batch algorithm and discrepancy measure to inform\nreaders the newest research in time series predicting method, which doesn't\nrequire any stationarity or non mixing assumptions in time series data.\nFinally, to apply these forecasting to practice, we introduce basic trading\nstrategies that can create Win win and Zero sum situations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 14:39:38 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 18:09:42 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Elliot", "Aaron", ""], ["Hsu", "Cheng Hua", ""]]}, {"id": "1710.05758", "submitter": "Dominik Marek Loroch", "authors": "Dominik Marek Loroch, Norbert Wehn, Franz-Josef Pfreundt, Janis Keuper", "title": "TensorQuant - A Simulation Toolbox for Deep Neural Network Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research implies that training and inference of deep neural networks\n(DNN) can be computed with low precision numerical representations of the\ntraining/test data, weights and gradients without a general loss in accuracy.\nThe benefit of such compact representations is twofold: they allow a\nsignificant reduction of the communication bottleneck in distributed DNN\ntraining and faster neural network implementations on hardware accelerators\nlike FPGAs. Several quantization methods have been proposed to map the original\n32-bit floating point problem to low-bit representations. While most related\npublications validate the proposed approach on a single DNN topology, it\nappears to be evident, that the optimal choice of the quantization method and\nnumber of coding bits is topology dependent. To this end, there is no general\ntheory available, which would allow users to derive the optimal quantization\nduring the design of a DNN topology. In this paper, we present a quantization\ntool box for the TensorFlow framework. TensorQuant allows a transparent\nquantization simulation of existing DNN topologies during training and\ninference. TensorQuant supports generic quantization methods and allows\nexperimental evaluation of the impact of the quantization on single layers as\nwell as on the full topology. In a first series of experiments with\nTensorQuant, we show an analysis of fix-point quantizations of popular CNN\ntopologies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 10:15:27 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Loroch", "Dominik Marek", ""], ["Wehn", "Norbert", ""], ["Pfreundt", "Franz-Josef", ""], ["Keuper", "Janis", ""]]}, {"id": "1710.05776", "submitter": "Edward Cheung", "authors": "Edward Cheung and Yuying Li", "title": "Nonsmooth Frank-Wolfe using Uniform Affine Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frank-Wolfe methods (FW) have gained significant interest in the machine\nlearning community due to its ability to efficiently solve large problems that\nadmit a sparse structure (e.g. sparse vectors and low-rank matrices). However\nthe performance of the existing FW method hinges on the quality of the linear\napproximation. This typically restricts FW to smooth functions for which the\napproximation quality, indicated by a global curvature measure, is reasonably\ngood.\n  In this paper, we propose a modified FW algorithm amenable to nonsmooth\nfunctions by optimizing for approximation quality over all affine\napproximations given a neighborhood of interest. We analyze theoretical\nproperties of the proposed algorithm and demonstrate that it overcomes many\nissues associated with existing methods in the context of nonsmooth low-rank\nmatrix estimation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 15:16:20 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 21:38:37 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Cheung", "Edward", ""], ["Li", "Yuying", ""]]}, {"id": "1710.05778", "submitter": "Ting Kei Pong", "authors": "Tianxiang Liu, Ting Kei Pong, Akiko Takeda", "title": "A successive difference-of-convex approximation method for a class of\n  nonconvex nonsmooth optimization problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of nonconvex nonsmooth optimization problems whose\nobjective is the sum of a smooth function and a finite number of nonnegative\nproper closed possibly nonsmooth functions (whose proximal mappings are easy to\ncompute), some of which are further composed with linear maps. This kind of\nproblems arises naturally in various applications when different regularizers\nare introduced for inducing simultaneous structures in the solutions. Solving\nthese problems, however, can be challenging because of the coupled nonsmooth\nfunctions: the corresponding proximal mapping can be hard to compute so that\nstandard first-order methods such as the proximal gradient algorithm cannot be\napplied efficiently. In this paper, we propose a successive\ndifference-of-convex approximation method for solving this kind of problems. In\nthis algorithm, we approximate the nonsmooth functions by their Moreau\nenvelopes in each iteration. Making use of the simple observation that Moreau\nenvelopes of nonnegative proper closed functions are continuous {\\em\ndifference-of-convex} functions, we can then approximately minimize the\napproximation function by first-order methods with suitable majorization\ntechniques. These first-order methods can be implemented efficiently thanks to\nthe fact that the proximal mapping of {\\em each} nonsmooth function is easy to\ncompute. Under suitable assumptions, we prove that the sequence generated by\nour method is bounded and any accumulation point is a stationary point of the\nobjective. We also discuss how our method can be applied to concrete\napplications such as nonconvex fused regularized optimization problems and\nsimultaneously structured matrix optimization problems, and illustrate the\nperformance numerically for these two specific applications.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 15:18:28 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 13:40:34 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Liu", "Tianxiang", ""], ["Pong", "Ting Kei", ""], ["Takeda", "Akiko", ""]]}, {"id": "1710.05817", "submitter": "Jonathan Rubin", "authors": "Jonathan Rubin, Saman Parvaneh, Asif Rahman, Bryan Conroy and Saeed\n  Babaeizadeh", "title": "Densely Connected Convolutional Networks and Signal Quality Analysis to\n  Detect Atrial Fibrillation Using Short Single-Lead ECG Recordings", "comments": "Computing in Cardiology 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of new technology such as wearables that record high-quality\nsingle channel ECG, provides an opportunity for ECG screening in a larger\npopulation, especially for atrial fibrillation screening. The main goal of this\nstudy is to develop an automatic classification algorithm for normal sinus\nrhythm (NSR), atrial fibrillation (AF), other rhythms (O), and noise from a\nsingle channel short ECG segment (9-60 seconds). For this purpose, signal\nquality index (SQI) along with dense convolutional neural networks was used.\nTwo convolutional neural network (CNN) models (main model that accepts 15\nseconds ECG and secondary model that processes 9 seconds shorter ECG) were\ntrained using the training data set. If the recording is determined to be of\nlow quality by SQI, it is immediately classified as noisy. Otherwise, it is\ntransformed to a time-frequency representation and classified with the CNN as\nNSR, AF, O, or noise. At the final step, a feature-based post-processing\nalgorithm classifies the rhythm as either NSR or O in case the CNN model's\ndiscrimination between the two is indeterminate. The best result achieved at\nthe official phase of the PhysioNet/CinC challenge on the blind test set was\n0.80 (F1 for NSR, AF, and O were 0.90, 0.80, and 0.70, respectively).\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 18:58:45 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Rubin", "Jonathan", ""], ["Parvaneh", "Saman", ""], ["Rahman", "Asif", ""], ["Conroy", "Bryan", ""], ["Babaeizadeh", "Saeed", ""]]}, {"id": "1710.05829", "submitter": "Cody Hyndman", "authors": "Anastasis Kratsios and Cody B. Hyndman", "title": "Non-Euclidean Conditional Expectation and Filtering", "comments": "This updated version focuses on non Euclidean filtering applications.\n  The content on geometric learning from version one separated and expanded in\n  our paper \"The NEU Meta-Algorithm for Geometric Learning with Applications in\n  Finance\" [arXiv:1809.00082]", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF math.PR q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A non-Euclidean generalization of conditional expectation is introduced and\ncharacterized as the minimizer of expected intrinsic squared-distance from a\nmanifold-valued target. The computational tractable formulation expresses the\nnon-convex optimization problem as transformations of Euclidean conditional\nexpectation. This gives computationally tractable filtering equations for the\ndynamics of the intrinsic conditional expectation of a manifold-valued signal\nand is used to obtain accurate numerical forecasts of efficient portfolios by\nincorporating their geometric structure into the estimates.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 16:51:27 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 00:45:39 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2018 16:38:56 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Kratsios", "Anastasis", ""], ["Hyndman", "Cody B.", ""]]}, {"id": "1710.05895", "submitter": "Anil Aswani", "authors": "Matt Olfat, Anil Aswani", "title": "Spectral Algorithms for Computing Fair Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers and rating scores are prone to implicitly codifying biases, which\nmay be present in the training data, against protected classes (i.e., age,\ngender, or race). So it is important to understand how to design classifiers\nand scores that prevent discrimination in predictions. This paper develops\ncomputationally tractable algorithms for designing accurate but fair support\nvector machines (SVM's). Our approach imposes a constraint on the covariance\nmatrices conditioned on each protected class, which leads to a nonconvex\nquadratic constraint in the SVM formulation. We develop iterative algorithms to\ncompute fair linear and kernel SVM's, which solve a sequence of relaxations\nconstructed using a spectral decomposition of the nonconvex constraint. Its\neffectiveness in achieving high prediction accuracy while ensuring fairness is\nshown through numerical experiments on several data sets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 17:48:23 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Olfat", "Matt", ""], ["Aswani", "Anil", ""]]}, {"id": "1710.05918", "submitter": "Giuseppe Jurman", "authors": "Giuseppe Jurman and Valerio Maggio and Diego Fioravanti and Ylenia\n  Giarratano and Isotta Landi and Margherita Francescatto and Claudio\n  Agostinelli and Marco Chierici and Manlio De Domenico and Cesare Furlanello", "title": "Convolutional neural networks for structured omics: OmicsCNN and the\n  OmicsConv layer", "comments": "7 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1709.02268", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are a popular deep learning architecture\nwidely applied in different domains, in particular in classifying over images,\nfor which the concept of convolution with a filter comes naturally.\nUnfortunately, the requirement of a distance (or, at least, of a neighbourhood\nfunction) in the input feature space has so far prevented its direct use on\ndata types such as omics data. However, a number of omics data are metrizable,\ni.e., they can be endowed with a metric structure, enabling to adopt a\nconvolutional based deep learning framework, e.g., for prediction. We propose a\ngeneralized solution for CNNs on omics data, implemented through a dedicated\nKeras layer. In particular, for metagenomics data, a metric can be derived from\nthe patristic distance on the phylogenetic tree. For transcriptomics data, we\ncombine Gene Ontology semantic similarity and gene co-expression to define a\ndistance; the function is defined through a multilayer network where 3 layers\nare defined by the GO mutual semantic similarity while the fourth one by gene\nco-expression. As a general tool, feature distance on omics data is enabled by\nOmicsConv, a novel Keras layer, obtaining OmicsCNN, a dedicated deep learning\nframework. Here we demonstrate OmicsCNN on gut microbiota sequencing data, for\nInflammatory Bowel Disease (IBD) 16S data, first on synthetic data and then a\nmetagenomics collection of gut microbiota of 222 IBD patients.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 13:58:08 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Jurman", "Giuseppe", ""], ["Maggio", "Valerio", ""], ["Fioravanti", "Diego", ""], ["Giarratano", "Ylenia", ""], ["Landi", "Isotta", ""], ["Francescatto", "Margherita", ""], ["Agostinelli", "Claudio", ""], ["Chierici", "Marco", ""], ["De Domenico", "Manlio", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1710.05989", "submitter": "Sheng Chen", "authors": "Sheng Chen and Arindam Banerjee", "title": "Sparse Linear Isotonic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning and data mining, linear models have been widely used to\nmodel the response as parametric linear functions of the predictors. To relax\nsuch stringent assumptions made by parametric linear models, additive models\nconsider the response to be a summation of unknown transformations applied on\nthe predictors; in particular, additive isotonic models (AIMs) assume the\nunknown transformations to be monotone. In this paper, we introduce sparse\nlinear isotonic models (SLIMs) for highdimensional problems by hybridizing\nideas in parametric sparse linear models and AIMs, which enjoy a few appealing\nadvantages over both. In the high-dimensional setting, a two-step algorithm is\nproposed for estimating the sparse parameters as well as the monotone functions\nover predictors. Under mild statistical assumptions, we show that the algorithm\ncan accurately estimate the parameters. Promising preliminary experiments are\npresented to support the theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 20:20:45 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Chen", "Sheng", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1710.06012", "submitter": "Frank Noe", "authors": "Andreas Mardt, Luca Pasquali, Hao Wu and Frank No\\'e", "title": "VAMPnets: Deep learning of molecular kinetics", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-017-02388-1", "report-no": null, "categories": "stat.ML physics.bio-ph physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing demand for computing the relevant structures,\nequilibria and long-timescale kinetics of biomolecular processes, such as\nprotein-drug binding, from high-throughput molecular dynamics simulations.\nCurrent methods employ transformation of simulated coordinates into structural\nfeatures, dimension reduction, clustering the dimension-reduced data, and\nestimation of a Markov state model or related model of the interconversion\nrates between molecular structures. This handcrafted approach demands a\nsubstantial amount of modeling expertise, as poor decisions at any step will\nlead to large modeling errors. Here we employ the variational approach for\nMarkov processes (VAMP) to develop a deep learning framework for molecular\nkinetics using neural networks, dubbed VAMPnets. A VAMPnet encodes the entire\nmapping from molecular coordinates to Markov states, thus combining the whole\ndata processing pipeline in a single end-to-end framework. Our method performs\nequally or better than state-of-the art Markov modeling methods and provides\neasily interpretable few-state kinetic models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 22:21:22 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 16:17:47 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Mardt", "Andreas", ""], ["Pasquali", "Luca", ""], ["Wu", "Hao", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1710.06030", "submitter": "Martin Slawski", "authors": "Martin Slawski and Emanuel Ben-David", "title": "Linear Regression with Sparsely Permuted Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression analysis of multivariate data, it is tacitly assumed that\nresponse and predictor variables in each observed response-predictor pair\ncorrespond to the same entity or unit. In this paper, we consider the situation\nof \"permuted data\" in which this basic correspondence has been lost. Several\nrecent papers have considered this situation without further assumptions on the\nunderlying permutation. In applications, the latter is often to known to have\nadditional structure that can be leveraged. Specifically, we herein consider\nthe common scenario of \"sparsely permuted data\" in which only a small fraction\nof the data is affected by a mismatch between response and predictors. However,\nan adverse effect already observed for sparsely permuted data is that the least\nsquares estimator as well as other estimators not accounting for such partial\nmismatch are inconsistent. One approach studied in detail herein is to treat\npermuted data as outliers which motivates the use of robust regression\nformulations to estimate the regression parameter. The resulting estimate can\nsubsequently be used to recover the permutation. A notable benefit of the\nproposed approach is its computational simplicity given the general lack of\nprocedures for the above problem that are both statistically sound and\ncomputationally appealing.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 23:24:23 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 22:37:38 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Slawski", "Martin", ""], ["Ben-David", "Emanuel", ""]]}, {"id": "1710.06034", "submitter": "Tianbing Xu", "authors": "Tianbing Xu, Qiang Liu, Jian Peng", "title": "Stochastic Variance Reduction for Policy Gradient Estimation", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in policy gradient methods and deep learning have\ndemonstrated their applicability for complex reinforcement learning problems.\nHowever, the variance of the performance gradient estimates obtained from the\nsimulation is often excessive, leading to poor sample efficiency. In this\npaper, we apply the stochastic variance reduced gradient descent (SVRG) to\nmodel-free policy gradient to significantly improve the sample-efficiency. The\nSVRG estimation is incorporated into a trust-region Newton conjugate gradient\nframework for the policy optimization. On several Mujoco tasks, our method\nachieves significantly better performance compared to the state-of-the-art\nmodel-free policy gradient methods in robotic continuous control such as trust\nregion policy optimization (TRPO)\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 00:05:06 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 21:09:55 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 00:33:08 GMT"}, {"version": "v4", "created": "Thu, 29 Mar 2018 17:51:14 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Xu", "Tianbing", ""], ["Liu", "Qiang", ""], ["Peng", "Jian", ""]]}, {"id": "1710.06071", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee", "title": "PubMed 200k RCT: a Dataset for Sequential Sentence Classification in\n  Medical Abstracts", "comments": "Accepted as a conference paper at IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PubMed 200k RCT, a new dataset based on PubMed for sequential\nsentence classification. The dataset consists of approximately 200,000\nabstracts of randomized controlled trials, totaling 2.3 million sentences. Each\nsentence of each abstract is labeled with their role in the abstract using one\nof the following classes: background, objective, method, result, or conclusion.\nThe purpose of releasing this dataset is twofold. First, the majority of\ndatasets for sequential short-text classification (i.e., classification of\nshort texts that appear in sequences) are small: we hope that releasing a new\nlarge dataset will help develop more accurate algorithms for this task. Second,\nfrom an application perspective, researchers need better tools to efficiently\nskim through the literature. Automatically classifying each sentence in an\nabstract would help researchers read abstracts more efficiently, especially in\nfields where abstracts may be long, such as the medical field.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 03:22:00 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""]]}, {"id": "1710.06078", "submitter": "Felix Xiaofeng Ye", "authors": "Felix X.-F. Ye, Yi-an Ma and Hong Qian", "title": "Estimate exponential memory decay in Hidden Markov Model and its\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in hidden Markov model has been challenging in terms of scalability\ndue to dependencies in the observation data. In this paper, we utilize the\ninherent memory decay in hidden Markov models, such that the forward and\nbackward probabilities can be carried out with subsequences, enabling efficient\ninference over long sequences of observations. We formulate this forward\nfiltering process in the setting of the random dynamical system and there exist\nLyapunov exponents in the i.i.d random matrices production. And the rate of the\nmemory decay is known as $\\lambda_2-\\lambda_1$, the gap of the top two Lyapunov\nexponents almost surely. An efficient and accurate algorithm is proposed to\nnumerically estimate the gap after the soft-max parametrization. The length of\nsubsequences $B$ given the controlled error $\\epsilon$ is\n$B=\\log(\\epsilon)/(\\lambda_2-\\lambda_1)$. We theoretically prove the validity\nof the algorithm and demonstrate the effectiveness with numerical examples. The\nmethod developed here can be applied to widely used algorithms, such as\nmini-batch stochastic gradient method. Moreover, the continuity of Lyapunov\nspectrum ensures the estimated $B$ could be reused for the nearby parameter\nduring the inference.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 03:54:11 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Ye", "Felix X. -F.", ""], ["Ma", "Yi-an", ""], ["Qian", "Hong", ""]]}, {"id": "1710.06081", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin\n  Hu, Jianguo Li", "title": "Boosting Adversarial Attacks with Momentum", "comments": "CVPR 2018 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, which poses\nsecurity concerns on these algorithms due to the potentially severe\nconsequences. Adversarial attacks serve as an important surrogate to evaluate\nthe robustness of deep learning models before they are deployed. However, most\nof existing adversarial attacks can only fool a black-box model with a low\nsuccess rate. To address this issue, we propose a broad class of momentum-based\niterative algorithms to boost adversarial attacks. By integrating the momentum\nterm into the iterative process for attacks, our methods can stabilize update\ndirections and escape from poor local maxima during the iterations, resulting\nin more transferable adversarial examples. To further improve the success rates\nfor black-box attacks, we apply momentum iterative algorithms to an ensemble of\nmodels, and show that the adversarially trained models with a strong defense\nability are also vulnerable to our black-box attacks. We hope that the proposed\nmethods will serve as a benchmark for evaluating the robustness of various deep\nmodels and defense methods. With this method, we won the first places in NIPS\n2017 Non-targeted Adversarial Attack and Targeted Adversarial Attack\ncompetitions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 04:03:04 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 06:53:07 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 12:46:44 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Dong", "Yinpeng", ""], ["Liao", "Fangzhou", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""], ["Hu", "Xiaolin", ""], ["Li", "Jianguo", ""]]}, {"id": "1710.06085", "submitter": "Rahul Gopal Krishnan", "authors": "Rahul G. Krishnan, Dawen Liang, Matthew Hoffman", "title": "On the challenges of learning with inference networks on sparse,\n  high-dimensional data", "comments": "14 pages, 3 tables, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study parameter estimation in Nonlinear Factor Analysis (NFA) where the\ngenerative model is parameterized by a deep neural network. Recent work has\nfocused on learning such models using inference (or recognition) networks; we\nidentify a crucial problem when modeling large, sparse, high-dimensional\ndatasets -- underfitting. We study the extent of underfitting, highlighting\nthat its severity increases with the sparsity of the data. We propose methods\nto tackle it via iterative optimization inspired by stochastic variational\ninference \\citep{hoffman2013stochastic} and improvements in the sparse data\nrepresentation used for inference. The proposed techniques drastically improve\nthe ability of these powerful models to fit sparse data, achieving\nstate-of-the-art results on a benchmark text-count dataset and excellent\nresults on the task of top-N recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 04:17:07 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Krishnan", "Rahul G.", ""], ["Liang", "Dawen", ""], ["Hoffman", "Matthew", ""]]}, {"id": "1710.06169", "submitter": "Sarah Tan", "authors": "Sarah Tan, Rich Caruana, Giles Hooker, Yin Lou", "title": "Distill-and-Compare: Auditing Black-Box Models Using Transparent Model\n  Distillation", "comments": "Camera-ready version for AAAI/ACM AIES 2018. Data and pseudocode at\n  https://github.com/shftan/auditblackbox. Previously titled \"Detecting Bias in\n  Black-Box Models Using Transparent Model Distillation\". A short version was\n  presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": "10.1145/3278721.3278725", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box risk scoring models permeate our lives, yet are typically\nproprietary or opaque. We propose Distill-and-Compare, a model distillation and\ncomparison approach to audit such models. To gain insight into black-box\nmodels, we treat them as teachers, training transparent student models to mimic\nthe risk scores assigned by black-box models. We compare the student model\ntrained with distillation to a second un-distilled transparent model trained on\nground-truth outcomes, and use differences between the two models to gain\ninsight into the black-box model. Our approach can be applied in a realistic\nsetting, without probing the black-box model API. We demonstrate the approach\non four public data sets: COMPAS, Stop-and-Frisk, Chicago Police, and Lending\nClub. We also propose a statistical test to determine if a data set is missing\nkey features used to train the black-box model. Our test finds that the\nProPublica data is likely missing key feature(s) used in COMPAS.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 08:58:59 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 07:54:17 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 05:25:51 GMT"}, {"version": "v4", "created": "Thu, 11 Oct 2018 07:33:54 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Tan", "Sarah", ""], ["Caruana", "Rich", ""], ["Hooker", "Giles", ""], ["Lou", "Yin", ""]]}, {"id": "1710.06202", "submitter": "Kevin Cremanns", "authors": "Kevin Cremanns and Dirk Roos", "title": "Deep Gaussian Covariance Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correlation length-scale next to the noise variance are the most used\nhyperparameters for the Gaussian processes. Typically, stationary covariance\nfunctions are used, which are only dependent on the distances between input\npoints and thus invariant to the translations in the input space. The\noptimization of the hyperparameters is commonly done by maximizing the log\nmarginal likelihood. This works quite well, if the distances are uniform\ndistributed. In the case of a locally adapted or even sparse input space, the\nprediction of a test point can be worse dependent of its position. A possible\nsolution to this, is the usage of a non-stationary covariance function, where\nthe hyperparameters are calculated by a deep neural network. So that the\ncorrelation length scales and possibly the noise variance are dependent on the\ntest point. Furthermore, different types of covariance functions are trained\nsimultaneously, so that the Gaussian process prediction is an additive overlay\nof different covariance matrices. The right covariance functions combination\nand its hyperparameters are learned by the deep neural network. Additional, the\nGaussian process will be able to be trained by batches or online and so it can\nhandle arbitrarily large data sets. We call this framework Deep Gaussian\nCovariance Network (DGCP). There are also further extensions to this framework\npossible, for example sequentially dependent problems like time series or the\nlocal mixture of experts. The basic framework and some extension possibilities\nwill be presented in this work. Moreover, a comparison to some recent state of\nthe art surrogate model methods will be performed, also for a time dependent\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 10:57:21 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 13:30:35 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Cremanns", "Kevin", ""], ["Roos", "Dirk", ""]]}, {"id": "1710.06219", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim, Saehoon Kim, Seungjin Choi", "title": "Learning to Warm-Start Bayesian Hyperparameter Optimization", "comments": "14 pages, a preliminary version was presented at NIPS 2017 workshop\n  on Bayesian optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization aims to find the optimal hyperparameter\nconfiguration of a machine learning model, which provides the best performance\non a validation dataset. Manual search usually leads to get stuck in a local\nhyperparameter configuration, and heavily depends on human intuition and\nexperience. A simple alternative of manual search is random/grid search on a\nspace of hyperparameters, which still undergoes extensive evaluations of\nvalidation errors in order to find its best configuration. Bayesian\noptimization that is a global optimization method for black-box functions is\nnow popular for hyperparameter optimization, since it greatly reduces the\nnumber of validation error evaluations required, compared to random/grid\nsearch. Bayesian optimization generally finds the best hyperparameter\nconfiguration from random initialization without any prior knowledge. This\nmotivates us to let Bayesian optimization start from the configurations that\nwere successful on similar datasets, which are able to remarkably minimize the\nnumber of evaluations. In this paper, we propose deep metric learning to learn\nmeta-features over datasets such that the similarity over them is effectively\nmeasured by Euclidean distance between their associated meta-features. To this\nend, we introduce a Siamese network composed of deep feature and meta-feature\nextractors, where deep feature extractor provides a semantic representation of\neach instance in a dataset and meta-feature extractor aggregates a set of deep\nfeatures to encode a single representation over a dataset. Then, our learned\nmeta-features are used to select a few datasets similar to the new dataset, so\nthat hyperparameters in similar datasets are adopted as initializations to\nwarm-start Bayesian hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 11:34:32 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 12:31:26 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 14:37:01 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Kim", "Jungtaek", ""], ["Kim", "Saehoon", ""], ["Choi", "Seungjin", ""]]}, {"id": "1710.06234", "submitter": "Christian H\\\"ager", "authors": "Christian H\\\"ager and Henry D. Pfister", "title": "Nonlinear Interference Mitigation via Deep Neural Networks", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural-network-based approach is presented to efficiently implement digital\nbackpropagation (DBP). For a 32x100 km fiber-optic link, the resulting\n\"learned\" DBP significantly reduces the complexity compared to conventional DBP\nimplementations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 12:23:26 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""]]}, {"id": "1710.06261", "submitter": "Santosh Vempala", "authors": "Yin Tat Lee and Santosh S. Vempala", "title": "Convergence Rate of Riemannian Hamiltonian Monte Carlo and Faster\n  Polytope Volume Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first rigorous proof of the convergence of Riemannian Hamiltonian\nMonte Carlo, a general (and practical) method for sampling Gibbs distributions.\nOur analysis shows that the rate of convergence is bounded in terms of natural\nsmoothness parameters of an associated Riemannian manifold. We then apply the\nmethod with the manifold defined by the log barrier function to the problems of\n(1) uniformly sampling a polytope and (2) computing its volume, the latter by\nextending Gaussian cooling to the manifold setting. In both cases, the total\nnumber of steps needed is O^{*}(mn^{\\frac{2}{3}}), improving the state of the\nart. A key ingredient of our analysis is a proof of an analog of the KLS\nconjecture for Gibbs distributions over manifolds.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 13:30:27 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Lee", "Yin Tat", ""], ["Vempala", "Santosh S.", ""]]}, {"id": "1710.06273", "submitter": "Marwa El Halabi", "authors": "Marwa El Halabi, Francis Bach, and Volkan Cevher", "title": "Combinatorial Penalties: Which structures are preserved by convex\n  relaxations?", "comments": null, "journal-ref": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain. PMLR: Volume 84", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the homogeneous and the non-homogeneous convex relaxations for\ncombinatorial penalty functions defined on support sets. Our study identifies\nkey differences in the tightness of the resulting relaxations through the\nnotion of the lower combinatorial envelope of a set-function along with new\nnecessary conditions for support identification. We then propose a general\nadaptive estimator for convex monotone regularizers, and derive new sufficient\nconditions for support recovery in the asymptotic setting.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 13:41:21 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 18:02:14 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Halabi", "Marwa El", ""], ["Bach", "Francis", ""], ["Cevher", "Volkan", ""]]}, {"id": "1710.06276", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel, Vivien Seguy, Antoine Rolet", "title": "Smooth and Sparse Optimal Transport", "comments": "Accepted to AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropic regularization is quickly emerging as a new standard in optimal\ntransport (OT). It enables to cast the OT computation as a differentiable and\nunconstrained convex optimization problem, which can be efficiently solved\nusing the Sinkhorn algorithm. However, entropy keeps the transportation plan\nstrictly positive and therefore completely dense, unlike unregularized OT. This\nlack of sparsity can be problematic in applications where the transportation\nplan itself is of interest. In this paper, we explore regularizing the primal\nand dual OT formulations with a strongly convex term, which corresponds to\nrelaxing the dual and primal constraints with smooth approximations. We show\nhow to incorporate squared $2$-norm and group lasso regularizations within that\nframework, leading to sparse and group-sparse transportation plans. On the\ntheoretical side, we bound the approximation error introduced by regularizing\nthe primal and dual formulations. Our results suggest that, for the regularized\nprimal, the approximation error can often be smaller with squared $2$-norm than\nwith entropic regularization. We showcase our proposed framework on the task of\ncolor transfer.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 13:42:37 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 05:51:02 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Blondel", "Mathieu", ""], ["Seguy", "Vivien", ""], ["Rolet", "Antoine", ""]]}, {"id": "1710.06360", "submitter": "Hideaki Kano", "authors": "Hideaki Kano, Junya Honda, Kentaro Sakamaki, Kentaro Matsuura,\n  Atsuyoshi Nakamura, Masashi Sugiyama", "title": "Good Arm Identification via Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel stochastic multi-armed bandit problem called {\\em good\narm identification} (GAI), where a good arm is defined as an arm with expected\nreward greater than or equal to a given threshold. GAI is a pure-exploration\nproblem that a single agent repeats a process of outputting an arm as soon as\nit is identified as a good one before confirming the other arms are actually\nnot good. The objective of GAI is to minimize the number of samples for each\nprocess. We find that GAI faces a new kind of dilemma, the {\\em\nexploration-exploitation dilemma of confidence}, which is different difficulty\nfrom the best arm identification. As a result, an efficient design of\nalgorithms for GAI is quite different from that for the best arm\nidentification. We derive a lower bound on the sample complexity of GAI that is\ntight up to the logarithmic factor $\\mathrm{O}(\\log \\frac{1}{\\delta})$ for\nacceptance error rate $\\delta$. We also develop an algorithm whose sample\ncomplexity almost matches the lower bound. We also confirm experimentally that\nour proposed algorithm outperforms naive algorithms in synthetic settings based\non a conventional bandit problem and clinical trial researches for rheumatoid\narthritis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 16:08:16 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 09:31:52 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Kano", "Hideaki", ""], ["Honda", "Junya", ""], ["Sakamaki", "Kentaro", ""], ["Matsuura", "Kentaro", ""], ["Nakamura", "Atsuyoshi", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1710.06382", "submitter": "Jerry Chee", "authors": "Jerry Chee and Panos Toulis", "title": "Convergence diagnostics for stochastic gradient descent with constant\n  step size", "comments": "Accepted to Artificial Intelligence and Statistics, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many iterative procedures in stochastic optimization exhibit a transient\nphase followed by a stationary phase. During the transient phase the procedure\nconverges towards a region of interest, and during the stationary phase the\nprocedure oscillates in that region, commonly around a single point. In this\npaper, we develop a statistical diagnostic test to detect such phase transition\nin the context of stochastic gradient descent with constant learning rate. We\npresent theory and experiments suggesting that the region where the proposed\ndiagnostic is activated coincides with the convergence region. For a class of\nloss functions, we derive a closed-form solution describing such region.\nFinally, we suggest an application to speed up convergence of stochastic\ngradient descent by halving the learning rate each time stationarity is\ndetected. This leads to a new variant of stochastic gradient descent, which in\nmany settings is comparable to state-of-art.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 16:51:16 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 04:31:07 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Chee", "Jerry", ""], ["Toulis", "Panos", ""]]}, {"id": "1710.06451", "submitter": "Samuel L. Smith", "authors": "Samuel L. Smith and Quoc V. Le", "title": "A Bayesian Perspective on Generalization and Stochastic Gradient Descent", "comments": "13 pages, 9 figures. Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two questions at the heart of machine learning; how can we\npredict if a minimum will generalize to the test set, and why does stochastic\ngradient descent find minima that generalize well? Our work responds to Zhang\net al. (2016), who showed deep neural networks can easily memorize randomly\nlabeled training data, despite generalizing well on real labels of the same\ninputs. We show that the same phenomenon occurs in small linear models. These\nobservations are explained by the Bayesian evidence, which penalizes sharp\nminima but is invariant to model parameterization. We also demonstrate that,\nwhen one holds the learning rate fixed, there is an optimum batch size which\nmaximizes the test set accuracy. We propose that the noise introduced by small\nmini-batches drives the parameters towards minima whose evidence is large.\nInterpreting stochastic gradient descent as a stochastic differential equation,\nwe identify the \"noise scale\" $g = \\epsilon (\\frac{N}{B} - 1) \\approx \\epsilon\nN/B$, where $\\epsilon$ is the learning rate, $N$ the training set size and $B$\nthe batch size. Consequently the optimum batch size is proportional to both the\nlearning rate and the size of the training set, $B_{opt} \\propto \\epsilon N$.\nWe verify these predictions empirically.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 18:08:04 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 22:07:53 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 19:42:20 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Smith", "Samuel L.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1710.06462", "submitter": "Suchismit Mahapatra", "authors": "Suchismit Mahapatra, Varun Chandola", "title": "S-Isomap++: Multi Manifold Learning from Streaming Data", "comments": null, "journal-ref": null, "doi": "10.1109/BigData.2017.8257987", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning based methods have been widely used for non-linear\ndimensionality reduction (NLDR). However, in many practical settings, the need\nto process streaming data is a challenge for such methods, owing to the high\ncomputational complexity involved. Moreover, most methods operate under the\nassumption that the input data is sampled from a single manifold, embedded in a\nhigh dimensional space. We propose a method for streaming NLDR when the\nobserved data is either sampled from multiple manifolds or irregularly sampled\nfrom a single manifold. We show that existing NLDR methods, such as Isomap,\nfail in such situations, primarily because they rely on smoothness and\ncontinuity of the underlying manifold, which is violated in the scenarios\nexplored in this paper. However, the proposed algorithm is able to learn\neffectively in presence of multiple, and potentially intersecting, manifolds,\nwhile allowing for the input data to arrive as a massive stream.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 18:30:57 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 01:08:19 GMT"}, {"version": "v3", "created": "Sat, 17 Mar 2018 23:20:39 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Mahapatra", "Suchismit", ""], ["Chandola", "Varun", ""]]}, {"id": "1710.06487", "submitter": "SueYeon Chung", "authors": "SueYeon Chung, Daniel D. Lee, Haim Sompolinsky", "title": "Classification and Geometry of General Perceptual Manifolds", "comments": "24 pages, 12 figures, Supplementary Materials", "journal-ref": "Phys. Rev. X 8, 031003 (2018)", "doi": "10.1103/PhysRevX.8.031003", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptual manifolds arise when a neural population responds to an ensemble\nof sensory signals associated with different physical features (e.g.,\norientation, pose, scale, location, and intensity) of the same perceptual\nobject. Object recognition and discrimination requires classifying the\nmanifolds in a manner that is insensitive to variability within a manifold. How\nneuronal systems give rise to invariant object classification and recognition\nis a fundamental problem in brain theory as well as in machine learning. Here\nwe study the ability of a readout network to classify objects from their\nperceptual manifold representations. We develop a statistical mechanical theory\nfor the linear classification of manifolds with arbitrary geometry revealing a\nremarkable relation to the mathematics of conic decomposition. Novel\ngeometrical measures of manifold radius and manifold dimension are introduced\nwhich can explain the classification capacity for manifolds of various\ngeometries. The general theory is demonstrated on a number of representative\nmanifolds, including L2 ellipsoids prototypical of strictly convex manifolds,\nL1 balls representing polytopes consisting of finite sample points, and\norientation manifolds which arise from neurons tuned to respond to a continuous\nangle variable, such as object orientation. The effects of label sparsity on\nthe classification capacity of manifolds are elucidated, revealing a scaling\nrelation between label sparsity and manifold radius. Theoretical predictions\nare corroborated by numerical simulations using recently developed algorithms\nto compute maximum margin solutions for manifold dichotomies. Our theory and\nits extensions provide a powerful and rich framework for applying statistical\nmechanics of linear classification to data arising from neuronal responses to\nobject stimuli, as well as to artificial deep networks trained for object\nrecognition tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 20:06:25 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 03:27:25 GMT"}, {"version": "v3", "created": "Sun, 24 Jun 2018 15:46:57 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Chung", "SueYeon", ""], ["Lee", "Daniel D.", ""], ["Sompolinsky", "Haim", ""]]}, {"id": "1710.06514", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw and Jesse H. Krijthe and Marco Loog", "title": "Robust importance-weighted cross-validation under sample selection bias", "comments": "6 pages, 8 figures, Accepted to the IEEE International Workshop on\n  Machine Learning for Signal Processing 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-validation under sample selection bias can, in principle, be done by\nimportance-weighting the empirical risk. However, the importance-weighted risk\nestimator produces sub-optimal hyperparameter estimates in problem settings\nwhere large weights arise with high probability. We study its sampling variance\nas a function of the training data distribution and introduce a control variate\nto increase its robustness to problematically large weights.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 22:10:07 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 14:27:57 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 10:56:45 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kouw", "Wouter M.", ""], ["Krijthe", "Jesse H.", ""], ["Loog", "Marco", ""]]}, {"id": "1710.06551", "submitter": "Erik Schlicht", "authors": "Erik J. Schlicht", "title": "Exploiting oddsmaker bias to improve the prediction of NFL outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the outcome of sporting events has been a goal for many\ngroups who seek to maximize profit. What makes this challenging is that the\noutcome of an event can be influenced by many factors that dynamically change\nacross time. Oddsmakers attempt to estimate these factors by using both\nalgorithmic and subjective methods to set the spread. However, it is well-known\nthat both human and algorithmic decision-making can be biased, so this paper\nexplores if oddsmaker biases can be used in an exploitative manner, in order to\nimprove the prediction of NFL game outcomes. Real-world gambling data was used\nto train and test different predictive models under varying assumptions. The\nresults show that methods that leverage oddsmaker biases in an exploitative\nmanner perform best under the conditions tested in this paper. These findings\nsuggest that leveraging human and algorithmic decision biases in an\nexploitative manner may be useful for predicting the outcomes of competitive\nevents, and could lead to increased profit for those who have financial\ninterest in the outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 01:41:11 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 23:37:32 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Schlicht", "Erik J.", ""]]}, {"id": "1710.06561", "submitter": "Kaifeng Zhao", "authors": "Kaifeng Zhao, Seyed Hanif Mahboobi, Saeed Bagheri", "title": "Revenue-based Attribution Modeling for Online Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines and proposes several attribution modeling methods that\nquantify how revenue should be attributed to online advertising inputs. We\nadopt and further develop relative importance method, which is based on\nregression models that have been extensively studied and utilized to\ninvestigate the relationship between advertising efforts and market reaction\n(revenue). Relative importance method aims at decomposing and allocating\nmarginal contributions to the coefficient of determination (R^2) of regression\nmodels as attribution values. In particular, we adopt two alternative\nsubmethods to perform this decomposition: dominance analysis and relative\nweight analysis. Moreover, we demonstrate an extension of the decomposition\nmethods from standard linear model to additive model. We claim that our new\napproaches are more flexible and accurate in modeling the underlying\nrelationship and calculating the attribution values. We use simulation examples\nto demonstrate the superior performance of our new approaches over traditional\nmethods. We further illustrate the value of our proposed approaches using a\nreal advertising campaign dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 02:32:54 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Zhao", "Kaifeng", ""], ["Mahboobi", "Seyed Hanif", ""], ["Bagheri", "Saeed", ""]]}, {"id": "1710.06564", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Richard G. Clegg, Hamed Haddadi", "title": "Replacement AutoEncoder: A Privacy-Preserving Algorithm for Sensory Data\n  Analysis", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": "10.1109/IoTDI.2018.00025", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of sensors on mobile, Internet of things (IoT), and\nwearable devices generate time-series measurements of physical activities.\nThough access to the sensory data is critical to the success of many beneficial\napplications such as health monitoring or activity recognition, a wide range of\npotentially sensitive information about the individuals can also be discovered\nthrough access to sensory data and this cannot easily be protected using\ntraditional privacy approaches.\n  In this paper, we propose a privacy-preserving sensing framework for managing\naccess to time-series data in order to provide utility while protecting\nindividuals' privacy. We introduce Replacement AutoEncoder, a novel algorithm\nwhich learns how to transform discriminative features of data that correspond\nto sensitive inferences, into some features that have been more observed in\nnon-sensitive inferences, to protect users' privacy. This efficiency is\nachieved by defining a user-customized objective function for deep\nautoencoders. Our replacement method will not only eliminate the possibility of\nrecognizing sensitive inferences, it also eliminates the possibility of\ndetecting the occurrence of them. That is the main weakness of other approaches\nsuch as filtering or randomization. We evaluate the efficacy of the algorithm\nwith an activity recognition task in a multi-sensing environment using\nextensive experiments on three benchmark datasets. We show that it can retain\nthe recognition accuracy of state-of-the-art techniques while simultaneously\npreserving the privacy of sensitive information. Finally, we utilize the GANs\nfor detecting the occurrence of replacement, after releasing data, and show\nthat this can be done only if the adversarial network is trained on the users'\noriginal data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 02:45:44 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 14:09:05 GMT"}, {"version": "v3", "created": "Tue, 27 Feb 2018 12:45:14 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Clegg", "Richard G.", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1710.06570", "submitter": "Samuel Schoenholz", "authors": "Samuel S. Schoenholz, Jeffrey Pennington and Jascha Sohl-Dickstein", "title": "A Correspondence Between Random Neural Networks and Statistical Field\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent papers have provided evidence that practical design\nquestions about neural networks may be tackled theoretically by studying the\nbehavior of random networks. However, until now the tools available for\nanalyzing random neural networks have been relatively ad-hoc. In this work, we\nshow that the distribution of pre-activations in random neural networks can be\nexactly mapped onto lattice models in statistical physics. We argue that\nseveral previous investigations of stochastic networks actually studied a\nparticular factorial approximation to the full lattice model. For random linear\nnetworks and random rectified linear networks we show that the corresponding\nlattice models in the wide network limit may be systematically approximated by\na Gaussian distribution with covariance between the layers of the network. In\neach case, the approximate distribution can be diagonalized by Fourier\ntransformation. We show that this approximation accurately describes the\nresults of numerical simulations of wide random neural networks. Finally, we\ndemonstrate that in each case the large scale behavior of the random networks\ncan be approximated by an effective field theory.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 03:05:47 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Schoenholz", "Samuel S.", ""], ["Pennington", "Jeffrey", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1710.06574", "submitter": "Ruishan Liu", "authors": "Ruishan Liu, James Zou", "title": "The Effects of Memory Replay in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay is a key technique behind many recent advances in deep\nreinforcement learning. Allowing the agent to learn from earlier memories can\nspeed up learning and break undesirable temporal correlations. Despite its\nwide-spread application, very little is understood about the properties of\nexperience replay. How does the amount of memory kept affect learning dynamics?\nDoes it help to prioritize certain experiences? In this paper, we address these\nquestions by formulating a dynamical systems ODE model of Q-learning with\nexperience replay. We derive analytic solutions of the ODE for a simple\nsetting. We show that even in this very simple setting, the amount of memory\nkept can substantially affect the agent's performance. Too much or too little\nmemory both slow down learning. Moreover, we characterize regimes where\nprioritized replay harms the agent's learning. We show that our analytic\nsolutions have excellent agreement with experiments. Finally, we propose a\nsimple algorithm for adaptively changing the memory buffer size which achieves\nconsistently good empirical performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 03:19:55 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Liu", "Ruishan", ""], ["Zou", "James", ""]]}, {"id": "1710.06582", "submitter": "Xiaoming Zhang", "authors": "Feiran Huang, Xiaoming Zhang, Zhoujun Li, Tao Mei, Yueying He,\n  Zhonghua Zhao", "title": "Learning Social Image Embedding with Deep Multimodal Attention Networks", "comments": null, "journal-ref": "Proceedings of Thematic Workshops of the 25th ACM Multimedia 2017", "doi": "10.1145/3126686.3126720", "report-no": null, "categories": "cs.MM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning social media data embedding by deep models has attracted extensive\nresearch interest as well as boomed a lot of applications, such as link\nprediction, classification, and cross-modal search. However, for social images\nwhich contain both link information and multimodal contents (e.g., text\ndescription, and visual content), simply employing the embedding learnt from\nnetwork structure or data content results in sub-optimal social image\nrepresentation. In this paper, we propose a novel social image embedding\napproach called Deep Multimodal Attention Networks (DMAN), which employs a deep\nmodel to jointly embed multimodal contents and link information. Specifically,\nto effectively capture the correlations between multimodal contents, we propose\na multimodal attention network to encode the fine-granularity relation between\nimage regions and textual words. To leverage the network structure for\nembedding learning, a novel Siamese-Triplet neural network is proposed to model\nthe links among images. With the joint deep model, the learnt embedding can\ncapture both the multimodal contents and the nonlinear network information.\nExtensive experiments are conducted to investigate the effectiveness of our\napproach in the applications of multi-label classification and cross-modal\nsearch. Compared to state-of-the-art image embeddings, our proposed DMAN\nachieves significant improvement in the tasks of multi-label classification and\ncross-modal search.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 04:28:20 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Huang", "Feiran", ""], ["Zhang", "Xiaoming", ""], ["Li", "Zhoujun", ""], ["Mei", "Tao", ""], ["He", "Yueying", ""], ["Zhao", "Zhonghua", ""]]}, {"id": "1710.06595", "submitter": "Futoshi Futami", "authors": "Futoshi Futami, Issei Sato and Masashi Sugiyama", "title": "Variational Inference based on Robust Divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness to outliers is a central issue in real-world machine learning\napplications. While replacing a model to a heavy-tailed one (e.g., from\nGaussian to Student-t) is a standard approach for robustification, it can only\nbe applied to simple models. In this paper, based on Zellner's optimization and\nvariational formulation of Bayesian inference, we propose an outlier-robust\npseudo-Bayesian variational method by replacing the Kullback-Leibler divergence\nused for data fitting to a robust divergence such as the beta- and\ngamma-divergences. An advantage of our approach is that superior but complex\nmodels such as deep networks can also be handled. We theoretically prove that,\nfor deep networks with ReLU activation functions, the \\emph{influence function}\nin our proposed method is bounded, while it is unbounded in the ordinary\nvariational inference. This implies that our proposed method is robust to both\nof input and output outliers, while the ordinary variational method is not. We\nexperimentally demonstrate that our robust variational method outperforms\nordinary variational inference in regression and classification with deep\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 06:57:03 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 08:57:09 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Futami", "Futoshi", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1710.06635", "submitter": "Christian Clason", "authors": "Christoph Brauer, Christian Clason, Dirk Lorenz, Benedikt Wirth", "title": "A Sinkhorn-Newton method for entropic optimal transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the entropic regularization of discretized optimal transport and\npropose to solve its optimality conditions via a logarithmic Newton iteration.\nWe show a quadratic convergence rate and validate numerically that the method\ncompares favorably with the more commonly used Sinkhorn--Knopp algorithm for\nsmall regularization strength. We further investigate numerically the\nrobustness of the proposed method with respect to parameters such as the mesh\nsize of the discretization.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 09:19:50 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 18:29:40 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Brauer", "Christoph", ""], ["Clason", "Christian", ""], ["Lorenz", "Dirk", ""], ["Wirth", "Benedikt", ""]]}, {"id": "1710.06703", "submitter": "Amal Rannen Triki", "authors": "Amal Rannen Triki, Maxim Berman and Matthew B. Blaschko", "title": "Function Norms and Regularization in Deep Networks", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become increasingly important due to their\nexcellent empirical performance on a wide range of problems. However,\nregularization is generally achieved by indirect means, largely due to the\ncomplex set of functions defined by a network and the difficulty in measuring\nfunction complexity. There exists no method in the literature for additive\nregularization based on a norm of the function, as is classically considered in\nstatistical learning theory. In this work, we propose sampling-based\napproximations to weighted function norms as regularizers for deep neural\nnetworks. We provide, to the best of our knowledge, the first proof in the\nliterature of the NP-hardness of computing function norms of DNNs, motivating\nthe necessity of an approximate approach. We then derive a generalization bound\nfor functions trained with weighted norms and prove that a natural stochastic\noptimization strategy minimizes the bound. Finally, we empirically validate the\nimproved performance of the proposed regularization strategies for both convex\nfunction sets as well as DNNs on real-world classification and image\nsegmentation tasks demonstrating improved performance over weight decay,\ndropout, and batch normalization. Source code will be released at the time of\npublication.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 12:43:01 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 23:21:55 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Triki", "Amal Rannen", ""], ["Berman", "Maxim", ""], ["Blaschko", "Matthew B.", ""]]}, {"id": "1710.06763", "submitter": "Debasish Chatterjee", "authors": "Mohammed Rayyan Sheriff and Debasish Chatterjee", "title": "A complete characterization of optimal dictionaries for least squares\n  representation", "comments": "36 pages", "journal-ref": "Journal of Machine Learning Research, Vol 18, Paper No. 107,\n  1--28, 2017", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionaries are collections of vectors used for representations of elements\nin Euclidean spaces. While recent research on optimal dictionaries is focussed\non providing sparse (i.e., $\\ell_0$-optimal,) representations, here we consider\nthe problem of finding optimal dictionaries such that representations of\nsamples of a random vector are optimal in an $\\ell_2$-sense. For us, optimality\nof representation is equivalent to minimization of the average $\\ell_2$-norm of\nthe coefficients used to represent the random vector, with the lengths of the\ndictionary vectors being specified a priori. With the help of recent results on\nrank-$1$ decompositions of symmetric positive semidefinite matrices and the\ntheory of majorization, we provide a complete characterization of\n$\\ell_2$-optimal dictionaries. Our results are accompanied by polynomial time\nalgorithms that construct $\\ell_2$-optimal dictionaries from given data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 14:59:58 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Sheriff", "Mohammed Rayyan", ""], ["Chatterjee", "Debasish", ""]]}, {"id": "1710.06766", "submitter": "Jonathan Scarlett", "authors": "Jonathan Scarlett and Volkan Cevher", "title": "Phase Transitions in the Pooled Data Problem", "comments": "Accepted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the pooled data problem of identifying the labels\nassociated with a large collection of items, based on a sequence of pooled\ntests revealing the counts of each label within the pool. In the noiseless\nsetting, we identify an exact asymptotic threshold on the required number of\ntests with optimal decoding, and prove a phase transition between complete\nsuccess and complete failure. In addition, we present a novel noisy variation\nof the problem, and provide an information-theoretic framework for\ncharacterizing the required number of tests for general random noise models.\nOur results reveal that noise can make the problem considerably more difficult,\nwith strict increases in the scaling laws even at low noise levels. Finally, we\ndemonstrate similar behavior in an approximate recovery setting, where a given\nnumber of errors is allowed in the decoded labels.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 15:04:48 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Scarlett", "Jonathan", ""], ["Cevher", "Volkan", ""]]}, {"id": "1710.06818", "submitter": "Omer Gottesman", "authors": "Omer Gottesman, Weiwei Pan, Finale Doshi-Velez", "title": "Weighted Tensor Decomposition for Learning Latent Variables with Partial\n  Data", "comments": null, "journal-ref": "PMLR 84:1664-1672, 2018", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition methods are popular tools for learning latent variables\ngiven only lower-order moments of the data. However, the standard assumption is\nthat we have sufficient data to estimate these moments to high accuracy. In\nthis work, we consider the case in which certain dimensions of the data are not\nalways observed---common in applied settings, where not all measurements may be\ntaken for all observations---resulting in moment estimates of varying quality.\nWe derive a weighted tensor decomposition approach that is computationally as\nefficient as the non-weighted approach, and demonstrate that it outperforms\nmethods that do not appropriately leverage these less-observed dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 16:35:26 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Gottesman", "Omer", ""], ["Pan", "Weiwei", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1710.06900", "submitter": "Feras Saad", "authors": "Feras A. Saad, Vikash K. Mansinghka", "title": "Temporally-Reweighted Chinese Restaurant Process Mixtures for\n  Clustering, Imputing, and Forecasting Multivariate Time Series", "comments": "19 pages, 10 figures, 2 tables. Appearing in AISTATS 2018", "journal-ref": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics, PMLR 84:755-764, 2018", "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a Bayesian nonparametric method for forecasting,\nimputation, and clustering in sparsely observed, multivariate time series data.\nThe method is appropriate for jointly modeling hundreds of time series with\nwidely varying, non-stationary dynamics. Given a collection of $N$ time series,\nthe Bayesian model first partitions them into independent clusters using a\nChinese restaurant process prior. Within a cluster, all time series are modeled\njointly using a novel \"temporally-reweighted\" extension of the Chinese\nrestaurant process mixture. Markov chain Monte Carlo techniques are used to\nobtain samples from the posterior distribution, which are then used to form\npredictive inferences. We apply the technique to challenging forecasting and\nimputation tasks using seasonal flu data from the US Center for Disease Control\nand Prevention, demonstrating superior forecasting accuracy and competitive\nimputation accuracy as compared to multiple widely used baselines. We further\nshow that the model discovers interpretable clusters in datasets with hundreds\nof time series, using macroeconomic data from the Gapminder Foundation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 19:17:43 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 21:13:18 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Saad", "Feras A.", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "1710.06910", "submitter": "Yi Zhou", "authors": "Yi Zhou and Yingbin Liang", "title": "Characterization of Gradient Dominance and Regularity Conditions for\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has witnessed a successful application of deep learning to\nsolving many challenging problems in machine learning and artificial\nintelligence. However, the loss functions of deep neural networks (especially\nnonlinear networks) are still far from being well understood from a theoretical\naspect. In this paper, we enrich the current understanding of the landscape of\nthe square loss functions for three types of neural networks. Specifically,\nwhen the parameter matrices are square, we provide an explicit characterization\nof the global minimizers for linear networks, linear residual networks, and\nnonlinear networks with one hidden layer. Then, we establish two quadratic\ntypes of landscape properties for the square loss of these neural networks,\ni.e., the gradient dominance condition within the neighborhood of their full\nrank global minimizers, and the regularity condition along certain directions\nand within the neighborhood of their global minimizers. These two landscape\nproperties are desirable for the optimization around the global minimizers of\nthe loss function for these neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 19:53:57 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 14:49:30 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Zhou", "Yi", ""], ["Liang", "Yingbin", ""]]}, {"id": "1710.06940", "submitter": "Yunwen Xu", "authors": "Yunwen Xu, Rui Xu, Weizhong Yan, Paul Ardis", "title": "Concept Drift Learning with Alternating Learners", "comments": null, "journal-ref": "Y. Xu, R. Xu, W. Yan and P. Ardis, \"Concept drift learning with\n  alternating learners,\" 2017 International Joint Conference on Neural Networks\n  (IJCNN), Anchorage, AK, 2017, pp. 2104-2111", "doi": "10.1109/IJCNN.2017.7966108", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven predictive analytics are in use today across a number of\nindustrial applications, but further integration is hindered by the requirement\nof similarity among model training and test data distributions. This paper\naddresses the need of learning from possibly nonstationary data streams, or\nunder concept drift, a commonly seen phenomenon in practical applications. A\nsimple dual-learner ensemble strategy, alternating learners framework, is\nproposed. A long-memory model learns stable concepts from a long relevant time\nwindow, while a short-memory model learns transient concepts from a small\nrecent window. The difference in prediction performance of these two models is\nmonitored and induces an alternating policy to select, update and reset the two\nmodels. The method features an online updating mechanism to maintain the\nensemble accuracy, and a concept-dependent trigger to focus on relevant data.\nThrough empirical studies the method demonstrates effective tracking and\nprediction when the steaming data carry abrupt and/or gradual changes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 21:13:36 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Xu", "Yunwen", ""], ["Xu", "Rui", ""], ["Yan", "Weizhong", ""], ["Ardis", "Paul", ""]]}, {"id": "1710.06952", "submitter": "Xiangru Lian", "authors": "Xiangru Lian, Wei Zhang, Ce Zhang, Ji Liu", "title": "Asynchronous Decentralized Parallel Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most commonly used distributed machine learning systems are either\nsynchronous or centralized asynchronous. Synchronous algorithms like\nAllReduce-SGD perform poorly in a heterogeneous environment, while asynchronous\nalgorithms using a parameter server suffer from 1) communication bottleneck at\nparameter servers when workers are many, and 2) significantly worse convergence\nwhen the traffic to parameter server is congested. Can we design an algorithm\nthat is robust in a heterogeneous environment, while being communication\nefficient and maintaining the best-possible convergence rate? In this paper, we\npropose an asynchronous decentralized stochastic gradient decent algorithm\n(AD-PSGD) satisfying all above expectations. Our theoretical analysis shows\nAD-PSGD converges at the optimal $O(1/\\sqrt{K})$ rate as SGD and has linear\nspeedup w.r.t. number of workers. Empirically, AD-PSGD outperforms the best of\ndecentralized parallel SGD (D-PSGD), asynchronous parallel SGD (A-PSGD), and\nstandard data parallel SGD (AllReduce-SGD), often by orders of magnitude in a\nheterogeneous environment. When training ResNet-50 on ImageNet with up to 128\nGPUs, AD-PSGD converges (w.r.t epochs) similarly to the AllReduce-SGD, but each\nepoch can be up to 4-8X faster than its synchronous counterparts in a\nnetwork-sharing HPC environment. To the best of our knowledge, AD-PSGD is the\nfirst asynchronous algorithm that achieves a similar epoch-wise convergence\nrate as AllReduce-SGD, at an over 100-GPU scale.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 22:44:03 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 00:39:36 GMT"}, {"version": "v3", "created": "Tue, 25 Sep 2018 00:25:58 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Lian", "Xiangru", ""], ["Zhang", "Wei", ""], ["Zhang", "Ce", ""], ["Liu", "Ji", ""]]}, {"id": "1710.07006", "submitter": "Sahand Negahban", "authors": "Addison Hu and Sahand Negahban", "title": "Minimax Estimation of Bandable Precision Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse covariance matrix provides considerable insight for understanding\nstatistical models in the multivariate setting. In particular, when the\ndistribution over variables is assumed to be multivariate normal, the sparsity\npattern in the inverse covariance matrix, commonly referred to as the precision\nmatrix, corresponds to the adjacency matrix representation of the Gauss-Markov\ngraph, which encodes conditional independence statements between variables.\nMinimax results under the spectral norm have previously been established for\ncovariance matrices, both sparse and banded, and for sparse precision matrices.\nWe establish minimax estimation bounds for estimating banded precision matrices\nunder the spectral norm. Our results greatly improve upon the existing bounds;\nin particular, we find that the minimax rate for estimating banded precision\nmatrices matches that of estimating banded covariance matrices. The key insight\nin our analysis is that we are able to obtain barely-noisy estimates of $k\n\\times k$ subblocks of the precision matrix by inverting slightly wider blocks\nof the empirical covariance matrix along the diagonal. Our theoretical results\nare complemented by experiments demonstrating the sharpness of our bounds.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 05:26:22 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Hu", "Addison", ""], ["Negahban", "Sahand", ""]]}, {"id": "1710.07066", "submitter": "Filippo Elba", "authors": "Filippo Elba, Lisa Gnaulati, Fabio Voeller", "title": "Reti bayesiane per lo studio del fenomeno degli incidenti stradali tra i\n  giovani in Toscana", "comments": "in Italian", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to analyse adolescents' road accidents in Tuscany. The\nanalysis is based on the Database Edit of Osservatorio di Epidemiologia della\nToscana. Complexity and heterogeneity of Edit's data represet an interesting\nscope to apply Machine Learning methods. In particular, in this paper is\nproposed an analysis based on a Bayesian probabilistic network, used to\ndiscover relationships between adolescents' characteristics and behaviours that\nare more often associated with an audacious driving style. The probabilistic\nnetwork developed by this study can be considered a useful starting point for\nfollow up reasearches, aiming to develop a causal network, a tool to limit this\nphenomenon.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 10:19:54 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Elba", "Filippo", ""], ["Gnaulati", "Lisa", ""], ["Voeller", "Fabio", ""]]}, {"id": "1710.07110", "submitter": "Dawit Mureja Argaw", "authors": "Dawit Mureja, Hyunsin Park, Chang D. Yoo", "title": "Meta-Learning via Feature-Label Memory Network", "comments": "https://github.com/Dawitmu/Meta-Learning-via-Feature-Label-Memory-Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning typically requires training a very capable architecture using\nlarge datasets. However, many important learning problems demand an ability to\ndraw valid inferences from small size datasets, and such problems pose a\nparticular challenge for deep learning. In this regard, various researches on\n\"meta-learning\" are being actively conducted. Recent work has suggested a\nMemory Augmented Neural Network (MANN) for meta-learning. MANN is an\nimplementation of a Neural Turing Machine (NTM) with the ability to rapidly\nassimilate new data in its memory, and use this data to make accurate\npredictions. In models such as MANN, the input data samples and their\nappropriate labels from previous step are bound together in the same memory\nlocations. This often leads to memory interference when performing a task as\nthese models have to retrieve a feature of an input from a certain memory\nlocation and read only the label information bound to that location. In this\npaper, we tried to address this issue by presenting a more robust MANN. We\nrevisited the idea of meta-learning and proposed a new memory augmented neural\nnetwork by explicitly splitting the external memory into feature and label\nmemories. The feature memory is used to store the features of input data\nsamples and the label memory stores their labels. Hence, when predicting the\nlabel of a given input, our model uses its feature memory unit as a reference\nto extract the stored feature of the input, and based on that feature, it\nretrieves the label information of the input from the label memory unit. In\norder for the network to function in this framework, a new memory-writingmodule\nto encode label information into the label memory in accordance with the\nmeta-learning task structure is designed. Here, we demonstrate that our model\noutperforms MANN by a large margin in supervised one-shot classification tasks\nusing Omniglot and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 12:08:59 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Mureja", "Dawit", ""], ["Park", "Hyunsin", ""], ["Yoo", "Chang D.", ""]]}, {"id": "1710.07138", "submitter": "Takashi Ishida", "authors": "Takashi Ishida, Gang Niu, Masashi Sugiyama", "title": "Binary Classification from Positive-Confidence Data", "comments": "NeurIPS 2018 camera-ready version (this paper was selected for\n  spotlight presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we learn a binary classifier from only positive data, without any\nnegative data or unlabeled data? We show that if one can equip positive data\nwith confidence (positive-confidence), one can successfully learn a binary\nclassifier, which we name positive-confidence (Pconf) classification. Our work\nis related to one-class classification which is aimed at \"describing\" the\npositive class by clustering-related methods, but one-class classification does\nnot have the ability to tune hyper-parameters and their aim is not on\n\"discriminating\" positive and negative classes. For the Pconf classification\nproblem, we provide a simple empirical risk minimization framework that is\nmodel-independent and optimization-independent. We theoretically establish the\nconsistency and an estimation error bound, and demonstrate the usefulness of\nthe proposed method for training deep neural networks through experiments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 13:36:54 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 09:20:15 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 02:11:12 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Ishida", "Takashi", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1710.07276", "submitter": "Paul Rozdeba", "authors": "H. D. I. Abarbanel, P. J. Rozdeba, S. Shirman", "title": "Machine Learning as Statistical Data Assimilation", "comments": "arXiv admin note: text overlap with arXiv:1707.01415", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a strong equivalence between neural network based machine\nlearning (ML) methods and the formulation of statistical data assimilation\n(DA), known to be a problem in statistical physics. DA, as used widely in\nphysical and biological sciences, systematically transfers information in\nobservations to a model of the processes producing the observations. The\ncorrespondence is that layer label in the ML setting is the analog of time in\nthe data assimilation setting. Utilizing aspects of this equivalence we discuss\nhow to establish the global minimum of the cost functions in the ML context,\nusing a variational annealing method from DA. This provides a design method for\noptimal networks for ML applications and may serve as the basis for\nunderstanding the success of \"deep learning\". Results from an ML example are\npresented.\n  When the layer label is taken to be continuous, the Euler-Lagrange equation\nfor the ML optimization problem is an ordinary differential equation, and we\nsee that the problem being solved is a two point boundary value problem. The\nuse of continuous layers is denoted \"deepest learning\". The Hamiltonian version\nprovides a direct rationale for back propagation as a solution method for the\ncanonical momentum; however, it suggests other solution methods are to be\npreferred.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 06:05:23 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Abarbanel", "H. D. I.", ""], ["Rozdeba", "P. J.", ""], ["Shirman", "S.", ""]]}, {"id": "1710.07283", "submitter": "Stefan Depeweg", "authors": "Stefan Depeweg, Jos\\'e Miguel Hern\\'andez-Lobato, Finale Doshi-Velez,\n  Steffen Udluft", "title": "Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and\n  Risk-sensitive Learning", "comments": "This paper supersedes arXiv:1706.08495", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks with latent variables are scalable and flexible\nprobabilistic models: They account for uncertainty in the estimation of the\nnetwork weights and, by making use of latent variables, can capture complex\nnoise patterns in the data. We show how to extract and decompose uncertainty\ninto epistemic and aleatoric components for decision-making purposes. This\nallows us to successfully identify informative points for active learning of\nfunctions with heteroscedastic and bimodal noise. Using the decomposition we\nfurther define a novel risk-sensitive criterion for reinforcement learning to\nidentify policies that balance expected cost, model-bias and noise aversion.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 16:21:10 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 19:09:45 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 00:13:06 GMT"}, {"version": "v4", "created": "Fri, 15 Jun 2018 21:56:12 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Depeweg", "Stefan", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Doshi-Velez", "Finale", ""], ["Udluft", "Steffen", ""]]}, {"id": "1710.07314", "submitter": "Yunwen Xu", "authors": "Rui Xu, Yunwen Xu, Weizhong Yan", "title": "Power Plant Performance Modeling with Concept Drift", "comments": null, "journal-ref": "2017 International Joint Conference on Neural Networks (IJCNN),\n  Anchorage, AK, 2017, pp. 2096-2103", "doi": "10.1109/IJCNN.2017.7966108", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power plant is a complex and nonstationary system for which the traditional\nmachine learning modeling approaches fall short of expectations. The\nensemble-based online learning methods provide an effective way to continuously\nlearn from the dynamic environment and autonomously update models to respond to\nenvironmental changes. This paper proposes such an online ensemble regression\napproach to model power plant performance, which is critically important for\noperation optimization. The experimental results on both simulated and real\ndata show that the proposed method can achieve performance with less than 1%\nmean average percentage error, which meets the general expectations in field\noperations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 18:44:05 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Xu", "Rui", ""], ["Xu", "Yunwen", ""], ["Yan", "Weizhong", ""]]}, {"id": "1710.07322", "submitter": "Bruno Schneider", "authors": "Bruno Schneider, Dominik J\\\"ackle, Florian Stoffel, Alexandra Diehl,\n  Johannes Fuchs and Daniel Keim", "title": "Visual Integration of Data and Model Space in Ensemble Learning", "comments": "8 pages, 7 pictures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of classifier models typically deliver superior performance and can\noutperform single classifier models given a dataset and classification task at\nhand. However, the gain in performance comes together with the lack in\ncomprehensibility, posing a challenge to understand how each model affects the\nclassification outputs and where the errors come from. We propose a tight\nvisual integration of the data and the model space for exploring and combining\nclassifier models. We introduce a workflow that builds upon the visual\nintegration and enables the effective exploration of classification outputs and\nmodels. We then present a use case in which we start with an ensemble\nautomatically selected by a standard ensemble selection algorithm, and show how\nwe can manipulate models and alternative combinations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 19:10:16 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Schneider", "Bruno", ""], ["J\u00e4ckle", "Dominik", ""], ["Stoffel", "Florian", ""], ["Diehl", "Alexandra", ""], ["Fuchs", "Johannes", ""], ["Keim", "Daniel", ""]]}, {"id": "1710.07324", "submitter": "Alexander Novikov", "authors": "Pavel Izmailov, Alexander Novikov, Dmitry Kropotov", "title": "Scalable Gaussian Processes with Billions of Inducing Inputs via Tensor\n  Train Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method (TT-GP) for approximate inference in Gaussian Process\n(GP) models. We build on previous scalable GP research including stochastic\nvariational inference based on inducing inputs, kernel interpolation, and\nstructure exploiting algebra. The key idea of our method is to use Tensor Train\ndecomposition for variational parameters, which allows us to train GPs with\nbillions of inducing inputs and achieve state-of-the-art results on several\nbenchmarks. Further, our approach allows for training kernels based on deep\nneural networks without any modifications to the underlying GP model. A neural\nnetwork learns a multidimensional embedding for the data, which is used by the\nGP to make the final prediction. We train GP and neural network parameters\nend-to-end without pretraining, through maximization of GP marginal likelihood.\nWe show the efficiency of the proposed approach on several regression and\nclassification benchmark datasets including MNIST, CIFAR-10, and Airline.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 19:13:26 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 11:11:12 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Izmailov", "Pavel", ""], ["Novikov", "Alexander", ""], ["Kropotov", "Dmitry", ""]]}, {"id": "1710.07340", "submitter": "Lukas Pastorek", "authors": "Lukas Pastorek", "title": "Frequency Based Index Estimating the Subclusters' Connection Strength", "comments": "Acta aerarii publici - 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a frequency coefficient based on the Sen-Shorrocks-Thon (SST)\npoverty index notion is proposed. The clustering SST index can be used as the\nmethod for determination of the connection between similar neighbor\nsub-clusters. Consequently, connections can reveal existence of natural\nhomogeneous. Through estimation of the connection strength, we can also verify\ninformation about the estimated number of natural clusters that is necessary\nassumption of efficient market segmentation and campaign management and\nfinancial decisions. The index can be used as the complementary tool for the\nU-matrix visualization. The index is tested on an artificial dataset with known\nparameters and compared with results obtained by the Unified-distance matrix\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 20:10:59 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 16:57:00 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Pastorek", "Lukas", ""]]}, {"id": "1710.07393", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda, Junpei Watanabe, Shun Kataoka, kazuyuki Tanaka", "title": "Linear-Time Algorithm in Bayesian Image Denoising based on Gaussian\n  Markov Random Field", "comments": null, "journal-ref": null, "doi": "10.1587/transinf.2017EDP7346", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider Bayesian image denoising based on a Gaussian\nMarkov random field (GMRF) model, for which we propose an new algorithm. Our\nmethod can solve Bayesian image denoising problems, including hyperparameter\nestimation, in $O(n)$-time, where $n$ is the number of pixels in a given image.\nFrom the perspective of the order of the computational time, this is a\nstate-of-the-art algorithm for the present problem setting. Moreover, the\nresults of our numerical experiments we show our method is in fact effective in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 02:06:41 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 06:30:43 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yasuda", "Muneki", ""], ["Watanabe", "Junpei", ""], ["Kataoka", "Shun", ""], ["Tanaka", "kazuyuki", ""]]}, {"id": "1710.07400", "submitter": "David Koes", "authors": "Matthew Ragoza, Lillian Turner and David Ryan Koes", "title": "Ligand Pose Optimization with Atomic Grid-Based Convolutional Neural\n  Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Docking is an important tool in computational drug discovery that aims to\npredict the binding pose of a ligand to a target protein through a combination\nof pose scoring and optimization. A scoring function that is differentiable\nwith respect to atom positions can be used for both scoring and gradient-based\noptimization of poses for docking. Using a differentiable grid-based atomic\nrepresentation as input, we demonstrate that a scoring function learned by\ntraining a convolutional neural network (CNN) to identify binding poses can\nalso be applied to pose optimization. We also show that an iteratively-trained\nCNN that includes poses optimized by the first CNN in its training set performs\neven better at optimizing randomly initialized poses than either the first CNN\nscoring function or AutoDock Vina.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 02:37:39 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Ragoza", "Matthew", ""], ["Turner", "Lillian", ""], ["Koes", "David Ryan", ""]]}, {"id": "1710.07406", "submitter": "Ioannis Panageas", "authors": "Jason D. Lee, Ioannis Panageas, Georgios Piliouras, Max Simchowitz,\n  Michael I. Jordan and Benjamin Recht", "title": "First-order Methods Almost Always Avoid Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish that first-order methods avoid saddle points for almost all\ninitializations. Our results apply to a wide variety of first-order methods,\nincluding gradient descent, block coordinate descent, mirror descent and\nvariants thereof. The connecting thread is that such algorithms can be studied\nfrom a dynamical systems perspective in which appropriate instantiations of the\nStable Manifold Theorem allow for a global stability analysis. Thus, neither\naccess to second-order derivative information nor randomness beyond\ninitialization is necessary to provably avoid saddle points.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 03:34:56 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Lee", "Jason D.", ""], ["Panageas", "Ioannis", ""], ["Piliouras", "Georgios", ""], ["Simchowitz", "Max", ""], ["Jordan", "Michael I.", ""], ["Recht", "Benjamin", ""]]}, {"id": "1710.07425", "submitter": "Kazuto Fukuchi", "authors": "Kazuto Fukuchi, Quang Khai Tran, Jun Sakuma", "title": "Differentially Private Empirical Risk Minimization with Input\n  Perturbation", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for the differentially private ERM, input\nperturbation. Existing differentially private ERM implicitly assumed that the\ndata contributors submit their private data to a database expecting that the\ndatabase invokes a differentially private mechanism for publication of the\nlearned model. In input perturbation, each data contributor independently\nrandomizes her/his data by itself and submits the perturbed data to the\ndatabase. We show that the input perturbation framework theoretically\nguarantees that the model learned with the randomized data eventually satisfies\ndifferential privacy with the prescribed privacy parameters. At the same time,\ninput perturbation guarantees that local differential privacy is guaranteed to\nthe server. We also show that the excess risk bound of the model learned with\ninput perturbation is $O(1/n)$ under a certain condition, where $n$ is the\nsample size. This is the same as the excess risk bound of the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 06:24:31 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Fukuchi", "Kazuto", ""], ["Tran", "Quang Khai", ""], ["Sakuma", "Jun", ""]]}, {"id": "1710.07437", "submitter": "Arash Shahriari", "authors": "Arash Shahriari", "title": "Distributed Deep Transfer Learning by Basic Probability Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a popular practice in deep neural networks, but\nfine-tuning of large number of parameters is a hard task due to the complex\nwiring of neurons between splitting layers and imbalance distributions of data\nin pretrained and transferred domains. The reconstruction of the original\nwiring for the target domain is a heavy burden due to the size of\ninterconnections across neurons. We propose a distributed scheme that tunes the\nconvolutional filters individually while backpropagates them jointly by means\nof basic probability assignment. Some of the most recent advances in evidence\ntheory show that in a vast variety of the imbalanced regimes, optimizing of\nsome proper objective functions derived from contingency matrices prevents\nbiases towards high-prior class distributions. Therefore, the original filters\nget gradually transferred based on individual contributions to overall\nperformance of the target domain. This largely reduces the expected complexity\nof transfer learning whilst highly improves precision. Our experiments on\nstandard benchmarks and scenarios confirm the consistent improvement of our\ndistributed deep transfer learning strategy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 07:26:11 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Shahriari", "Arash", ""]]}, {"id": "1710.07438", "submitter": "Arash Shahriari", "authors": "Arash Shahriari", "title": "Unified Backpropagation for Multi-Objective Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common practice in most of deep convolutional neural architectures is to\nemploy fully-connected layers followed by Softmax activation to minimize\ncross-entropy loss for the sake of classification. Recent studies show that\nsubstitution or addition of the Softmax objective to the cost functions of\nsupport vector machines or linear discriminant analysis is highly beneficial to\nimprove the classification performance in hybrid neural networks. We propose a\nnovel paradigm to link the optimization of several hybrid objectives through\nunified backpropagation. This highly alleviates the burden of extensive\nboosting for independent objective functions or complex formulation of\nmultiobjective gradients. Hybrid loss functions are linked by basic probability\nassignment from evidence theory. We conduct our experiments for a variety of\nscenarios and standard datasets to evaluate the advantage of our proposed\nunification approach to deliver consistent improvements into the classification\nperformance of deep convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 07:31:12 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Shahriari", "Arash", ""]]}, {"id": "1710.07453", "submitter": "Andr\\'es Felipe L\\'opez-Lopera", "authors": "Andr\\'es F. L\\'opez-Lopera, Fran\\c{c}ois Bachoc, Nicolas Durrande, and\n  Olivier Roustant", "title": "Finite-dimensional Gaussian approximation with linear inequality\n  constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introducing inequality constraints in Gaussian process (GP) models can lead\nto more realistic uncertainties in learning a great variety of real-world\nproblems. We consider the finite-dimensional Gaussian approach from Maatouk and\nBay (2017) which can satisfy inequality conditions everywhere (either\nboundedness, monotonicity or convexity). Our contributions are threefold.\nFirst, we extend their approach in order to deal with general sets of linear\ninequalities. Second, we explore several Markov Chain Monte Carlo (MCMC)\ntechniques to approximate the posterior distribution. Third, we investigate\ntheoretical and numerical properties of the constrained likelihood for\ncovariance parameter estimation. According to experiments on both artificial\nand real data, our full framework together with a Hamiltonian Monte Carlo-based\nsampler provides efficient results on both data fitting and uncertainty\nquantification.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 08:39:49 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["L\u00f3pez-Lopera", "Andr\u00e9s F.", ""], ["Bachoc", "Fran\u00e7ois", ""], ["Durrande", "Nicolas", ""], ["Roustant", "Olivier", ""]]}, {"id": "1710.07457", "submitter": "Remi Flamary", "authors": "Nicolas Courty, R\\'emi Flamary, M\\'elanie Ducoffe", "title": "Learning Wasserstein Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein distance received a lot of attention recently in the\ncommunity of machine learning, especially for its principled way of comparing\ndistributions. It has found numerous applications in several hard problems,\nsuch as domain adaptation, dimensionality reduction or generative models.\nHowever, its use is still limited by a heavy computational cost. Our goal is to\nalleviate this problem by providing an approximation mechanism that allows to\nbreak its inherent complexity. It relies on the search of an embedding where\nthe Euclidean distance mimics the Wasserstein distance. We show that such an\nembedding can be found with a siamese architecture associated with a decoder\nnetwork that allows to move from the embedding space back to the original input\nspace. Once this embedding has been found, computing optimization problems in\nthe Wasserstein space (e.g. barycenters, principal directions or even\narchetypes) can be conducted extremely fast. Numerical experiments supporting\nthis idea are conducted on image datasets, and show the wide potential benefits\nof our method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 09:09:34 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Courty", "Nicolas", ""], ["Flamary", "R\u00e9mi", ""], ["Ducoffe", "M\u00e9lanie", ""]]}, {"id": "1710.07462", "submitter": "Robert M. Gower", "authors": "Robert M. Gower, Nicolas Le Roux and Francis Bach", "title": "Tracking the gradients using the Hessian: A new look at variance\n  reducing stochastic methods", "comments": "17 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to improve variance reducing stochastic methods through better\ncontrol variates. We first propose a modification of SVRG which uses the\nHessian to track gradients over time, rather than to recondition, increasing\nthe correlation of the control variates and leading to faster theoretical\nconvergence close to the optimum. We then propose accurate and computationally\nefficient approximations to the Hessian, both using a diagonal and a low-rank\nmatrix. Finally, we demonstrate the effectiveness of our method on a wide range\nof problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 09:31:06 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 22:15:22 GMT"}, {"version": "v3", "created": "Sat, 31 Mar 2018 19:14:10 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Gower", "Robert M.", ""], ["Roux", "Nicolas Le", ""], ["Bach", "Francis", ""]]}, {"id": "1710.07491", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Marek Kurzynski", "title": "Dynamic classifier chains for multi-label learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-33676-9_40", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the task of building a dynamic ensemble of chain\nclassifiers for multi-label classification. To do so, we proposed two concepts\nof classifier chains algorithms that are able to change label order of the\nchain without rebuilding the entire model. Such modes allows anticipating the\ninstance-specific chain order without a significant increase in computational\nburden. The proposed chain models are built using the Naive Bayes classifier\nand nearest neighbour approach as a base single-label classifiers. To take the\nbenefits of the proposed algorithms, we developed a simple heuristic that\nallows the system to find relatively good label order. The heuristic sort\nlabels according to the label-specific classification quality gained during the\nvalidation phase. The heuristic tries to minimise the phenomenon of error\npropagation in the chain. The experimental results showed that the proposed\nmodel based on Naive Bayes classifier the above-mentioned heuristic is an\nefficient tool for building dynamic chain classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 11:26:41 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 16:11:39 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Trajdos", "Pawel", ""], ["Kurzynski", "Marek", ""]]}, {"id": "1710.07547", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Karl {\\O}yvind Mikalsen and Robert Jenssen", "title": "Learning compressed representations of blood samples time series with\n  missing data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical measurements collected over time are naturally represented as\nmultivariate time series (MTS), which often contain missing data. An\nautoencoder can learn low dimensional vectorial representations of MTS that\npreserve important data characteristics, but cannot deal explicitly with\nmissing data. In this work, we propose a new framework that combines an\nautoencoder with the Time series Cluster Kernel (TCK), a kernel that accounts\nfor missingness patterns in MTS. Via kernel alignment, we incorporate TCK in\nthe autoencoder to improve the learned representations in presence of missing\ndata. We consider a classification problem of MTS with missing values,\nrepresenting blood samples of patients with surgical site infection. With our\napproach, rather than with a standard autoencoder, we learn representations in\nlow dimensions that can be classified better.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 14:29:52 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Mikalsen", "Karl \u00d8yvind", ""], ["Jenssen", "Robert", ""]]}, {"id": "1710.07600", "submitter": "Yury Maximov", "authors": "Andrii Riazanov, Yury Maximov, Michael Chertkov", "title": "Belief Propagation Min-Sum Algorithm for Generalized Min-Cost Network\n  Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief Propagation algorithms are instruments used broadly to solve graphical\nmodel optimization and statistical inference problems. In the general case of a\nloopy Graphical Model, Belief Propagation is a heuristic which is quite\nsuccessful in practice, even though its empirical success, typically, lacks\ntheoretical guarantees. This paper extends the short list of special cases\nwhere correctness and/or convergence of a Belief Propagation algorithm is\nproven. We generalize formulation of Min-Sum Network Flow problem by relaxing\nthe flow conservation (balance) constraints and then proving that the Belief\nPropagation algorithm converges to the exact result.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 16:39:35 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 09:12:09 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Riazanov", "Andrii", ""], ["Maximov", "Yury", ""], ["Chertkov", "Michael", ""]]}, {"id": "1710.07702", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Zachary Kaplan, Thabo Samakhoana, Daniel\n  Sanz-Alonso", "title": "On the Consistency of Graph-based Bayesian Learning and the Scalability\n  of Sampling Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach to semi-supervised learning proceeds by endowing the input\ndata with a graph structure in order to extract geometric information and\nincorporate it into a Bayesian framework. We introduce new theory that gives\nappropriate scalings of graph parameters that provably lead to a well-defined\nlimiting posterior as the size of the unlabeled data set grows. Furthermore, we\nshow that these consistency results have profound algorithmic implications.\nWhen consistency holds, carefully designed graph-based Markov chain Monte Carlo\nalgorithms are proved to have a uniform spectral gap, independent of the number\nof unlabeled inputs. Several numerical experiments corroborate both the\nstatistical consistency and the algorithmic scalability established by the\ntheory.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 20:57:14 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 16:26:30 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Kaplan", "Zachary", ""], ["Samakhoana", "Thabo", ""], ["Sanz-Alonso", "Daniel", ""]]}, {"id": "1710.07706", "submitter": "Supriya Kapur", "authors": "Supriya Kapur, Asit Mishra, and Debbie Marr", "title": "Low Precision RNNs: Quantizing RNNs Without Losing Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similar to convolution neural networks, recurrent neural networks (RNNs)\ntypically suffer from over-parameterization. Quantizing bit-widths of weights\nand activations results in runtime efficiency on hardware, yet it often comes\nat the cost of reduced accuracy. This paper proposes a quantization approach\nthat increases model size with bit-width reduction. This approach will allow\nnetworks to perform at their baseline accuracy while still maintaining the\nbenefits of reduced precision and overall model size reduction.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 21:12:30 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Kapur", "Supriya", ""], ["Mishra", "Asit", ""], ["Marr", "Debbie", ""]]}, {"id": "1710.07732", "submitter": "Nishant Mehta", "authors": "Peter D. Gr\\\"unwald and Nishant A. Mehta", "title": "A Tight Excess Risk Bound via a Unified\n  PAC-Bayesian-Rademacher-Shtarkov-MDL Complexity", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel notion of complexity that interpolates between and\ngeneralizes some classic existing complexity notions in learning theory: for\nestimators like empirical risk minimization (ERM) with arbitrary bounded\nlosses, it is upper bounded in terms of data-independent Rademacher complexity;\nfor generalized Bayesian estimators, it is upper bounded by the data-dependent\ninformation complexity (also known as stochastic or PAC-Bayesian,\n$\\mathrm{KL}(\\text{posterior} \\operatorname{\\|} \\text{prior})$ complexity. For\n(penalized) ERM, the new complexity reduces to (generalized) normalized maximum\nlikelihood (NML) complexity, i.e. a minimax log-loss individual-sequence\nregret. Our first main result bounds excess risk in terms of the new\ncomplexity. Our second main result links the new complexity via Rademacher\ncomplexity to $L_2(P)$ entropy, thereby generalizing earlier results of Opper,\nHaussler, Lugosi, and Cesa-Bianchi who did the log-loss case with $L_\\infty$.\nTogether, these results recover optimal bounds for VC- and large (polynomial\nentropy) classes, replacing localized Rademacher complexity by a simpler\nanalysis which almost completely separates the two aspects that determine the\nachievable rates: 'easiness' (Bernstein) conditions and model complexity.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 00:28:39 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Gr\u00fcnwald", "Peter D.", ""], ["Mehta", "Nishant A.", ""]]}, {"id": "1710.07739", "submitter": "Oran Shayer", "authors": "Oran Shayer, Dan Levi and Ethan Fetaya", "title": "Learning Discrete Weights Using the Local Reparameterization Trick", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in computer vision make use of large deep neural\nnetworks, utilizing the substantial speedup offered by GPUs. For applications\nrunning on limited hardware, however, high precision real-time processing can\nstill be a challenge. One approach to solving this problem is training networks\nwith binary or ternary weights, thus removing the need to calculate\nmultiplications and significantly reducing memory size. In this work, we\nintroduce LR-nets (Local reparameterization networks), a new method for\ntraining neural networks with discrete weights using stochastic parameters. We\nshow how a simple modification to the local reparameterization trick,\npreviously used to train Gaussian distributed weights, enables the training of\ndiscrete weights. Using the proposed training we test both binary and ternary\nmodels on MNIST, CIFAR-10 and ImageNet benchmarks and reach state-of-the-art\nresults on most experiments.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 02:06:09 GMT"}, {"version": "v2", "created": "Sat, 28 Oct 2017 00:48:21 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 12:20:03 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Shayer", "Oran", ""], ["Levi", "Dan", ""], ["Fetaya", "Ethan", ""]]}, {"id": "1710.07742", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Bo Dai, Xingguo Li, Zhen Liu, James M. Rehg, Le Song", "title": "Towards Black-box Iterative Machine Teaching", "comments": "Published in ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we make an important step towards the black-box machine\nteaching by considering the cross-space machine teaching, where the teacher and\nthe learner use different feature representations and the teacher can not fully\nobserve the learner's model. In such scenario, we study how the teacher is\nstill able to teach the learner to achieve faster convergence rate than the\ntraditional passive learning. We propose an active teacher model that can\nactively query the learner (i.e., make the learner take exams) for estimating\nthe learner's status and provably guide the learner to achieve faster\nconvergence. The sample complexities for both teaching and query are provided.\nIn the experiments, we compare the proposed active teacher with the omniscient\nteacher and verify the effectiveness of the active teacher model.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 02:36:08 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 22:37:51 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 21:56:44 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Liu", "Weiyang", ""], ["Dai", "Bo", ""], ["Li", "Xingguo", ""], ["Liu", "Zhen", ""], ["Rehg", "James M.", ""], ["Song", "Le", ""]]}, {"id": "1710.07746", "submitter": "Penghang Yin", "authors": "Penghang Yin, Minh Pham, Adam Oberman, Stanley Osher", "title": "Stochastic Backward Euler: An Implicit Gradient Descent Algorithm for\n  $k$-means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an implicit gradient descent algorithm for the\nclassic $k$-means problem. The implicit gradient step or backward Euler is\nsolved via stochastic fixed-point iteration, in which we randomly sample a\nmini-batch gradient in every iteration. It is the average of the fixed-point\ntrajectory that is carried over to the next gradient step. We draw connections\nbetween the proposed stochastic backward Euler and the recent entropy\nstochastic gradient descent (Entropy-SGD) for improving the training of deep\nneural networks. Numerical experiments on various synthetic and real datasets\nshow that the proposed algorithm provides better clustering results compared to\n$k$-means algorithms in the sense that it decreased the objective function (the\ncluster) and is much more robust to initialization.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 03:02:29 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 18:32:15 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 19:18:23 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Yin", "Penghang", ""], ["Pham", "Minh", ""], ["Oberman", "Adam", ""], ["Osher", "Stanley", ""]]}, {"id": "1710.07783", "submitter": "Aixiang Chen", "authors": "Aixiang Chen, Bingchuan Chen, Xiaolong Chai, Rui Bian, Hengguang Li", "title": "A Novel Stochastic Stratified Average Gradient Method: Convergence Rate\n  and Its Complexity", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SGD (Stochastic Gradient Descent) is a popular algorithm for large scale\noptimization problems due to its low iterative cost. However, SGD can not\nachieve linear convergence rate as FGD (Full Gradient Descent) because of the\ninherent gradient variance. To attack the problem, mini-batch SGD was proposed\nto get a trade-off in terms of convergence rate and iteration cost. In this\npaper, a general CVI (Convergence-Variance Inequality) equation is presented to\nstate formally the interaction of convergence rate and gradient variance. Then\na novel algorithm named SSAG (Stochastic Stratified Average Gradient) is\nintroduced to reduce gradient variance based on two techniques, stratified\nsampling and averaging over iterations that is a key idea in SAG (Stochastic\nAverage Gradient). Furthermore, SSAG can achieve linear convergence rate of\n$\\mathcal {O}((1-\\frac{\\mu}{8CL})^k)$ at smaller storage and iterative costs,\nwhere $C\\geq 2$ is the category number of training data. This convergence rate\ndepends mainly on the variance between classes, but not on the variance within\nthe classes. In the case of $C\\ll N$ ($N$ is the training data size), SSAG's\nconvergence rate is much better than SAG's convergence rate of $\\mathcal\n{O}((1-\\frac{\\mu}{8NL})^k)$. Our experimental results show SSAG outperforms SAG\nand many other algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 10:45:13 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 08:13:34 GMT"}, {"version": "v3", "created": "Sun, 3 Dec 2017 23:13:26 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Chen", "Aixiang", ""], ["Chen", "Bingchuan", ""], ["Chai", "Xiaolong", ""], ["Bian", "Rui", ""], ["Li", "Hengguang", ""]]}, {"id": "1710.07797", "submitter": "Junhong Lin", "authors": "Junhong Lin and Lorenzo Rosasco", "title": "Optimal Rates for Learning with Nystr\\\"om Stochastic Gradient Methods", "comments": "41pages, 6figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of nonparametric regression, we propose and study a\ncombination of stochastic gradient methods with Nystr\\\"om subsampling, allowing\nmultiple passes over the data and mini-batches. Generalization error bounds for\nthe studied algorithm are provided. Particularly, optimal learning rates are\nderived considering different possible choices of the step-size, the mini-batch\nsize, the number of iterations/passes, and the subsampling level. In comparison\nwith state-of-the-art algorithms such as the classic stochastic gradient\nmethods and kernel ridge regression with Nystr\\\"om, the studied algorithm has\nadvantages on the computational complexity, while achieving the same optimal\nlearning rates. Moreover, our results indicate that using mini-batches can\nreduce the total computational cost while achieving the same optimal\nstatistical results.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 12:36:39 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Lin", "Junhong", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1710.07804", "submitter": "Sijia Liu", "authors": "Sijia Liu and Jie Chen and Pin-Yu Chen and Alfred O. Hero", "title": "Zeroth-Order Online Alternating Direction Method of Multipliers:\n  Convergence Analysis and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design and analyze a new zeroth-order online algorithm,\nnamely, the zeroth-order online alternating direction method of multipliers\n(ZOO-ADMM), which enjoys dual advantages of being gradient-free operation and\nemploying the ADMM to accommodate complex structured regularizers. Compared to\nthe first-order gradient-based online algorithm, we show that ZOO-ADMM requires\n$\\sqrt{m}$ times more iterations, leading to a convergence rate of\n$O(\\sqrt{m}/\\sqrt{T})$, where $m$ is the number of optimization variables, and\n$T$ is the number of iterations. To accelerate ZOO-ADMM, we propose two\nminibatch strategies: gradient sample averaging and observation averaging,\nresulting in an improved convergence rate of $O(\\sqrt{1+q^{-1}m}/\\sqrt{T})$,\nwhere $q$ is the minibatch size. In addition to convergence analysis, we also\ndemonstrate ZOO-ADMM to applications in signal processing, statistics, and\nmachine learning.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 13:59:16 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 03:19:07 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liu", "Sijia", ""], ["Chen", "Jie", ""], ["Chen", "Pin-Yu", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1710.07818", "submitter": "Yue Zhao", "authors": "Yue Zhao, Jianshu Chen, H. Vincent Poor", "title": "A Learning-to-Infer Method for Real-Time Power Grid Multi-Line Outage\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying a potentially large number of simultaneous line outages in power\ntransmission networks in real time is a computationally hard problem. This is\nbecause the number of hypotheses grows exponentially with the network size. A\nnew \"Learning-to-Infer\" method is developed for efficient inference of every\nline status in the network. Optimizing the line outage detector is transformed\nto and solved as a discriminative learning problem based on Monte Carlo samples\ngenerated with power flow simulations. A major advantage of the developed\nLearning-to-Infer method is that the labeled data used for training can be\ngenerated in an arbitrarily large amount rapidly and at very little cost. As a\nresult, the power of offline training is fully exploited to learn very complex\nclassifiers for effective real-time multi-line outage identification. The\nproposed methods are evaluated in the IEEE 30, 118 and 300 bus systems.\nExcellent performance in identifying multi-line outages in real time is\nachieved with a reasonably small amount of data.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 15:58:46 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 00:45:08 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhao", "Yue", ""], ["Chen", "Jianshu", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1710.07830", "submitter": "Surat Teerapittayanon", "authors": "Bradley McDanel, Surat Teerapittayanon and H.T. Kung", "title": "Incomplete Dot Products for Dynamic Computation Scaling in Neural\n  Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of incomplete dot products (IDP) to dynamically adjust the\nnumber of input channels used in each layer of a convolutional neural network\nduring feedforward inference. IDP adds monotonically non-increasing\ncoefficients, referred to as a \"profile\", to the channels during training. The\nprofile orders the contribution of each channel in non-increasing order. At\ninference time, the number of channels used can be dynamically adjusted to\ntrade off accuracy for lowered power consumption and reduced latency by\nselecting only a beginning subset of channels. This approach allows for a\nsingle network to dynamically scale over a computation range, as opposed to\ntraining and deploying multiple networks to support different levels of\ncomputation scaling. Additionally, we extend the notion to multiple profiles,\neach optimized for some specific range of computation scaling. We present\nexperiments on the computation and accuracy trade-offs of IDP for popular image\nclassification models and datasets. We demonstrate that, for MNIST and\nCIFAR-10, IDP reduces computation significantly, e.g., by 75%, without\nsignificantly compromising accuracy. We argue that IDP provides a convenient\nand effective means for devices to lower computation costs dynamically to\nreflect the current computation budget of the system. For example, VGG-16 with\n50% IDP (using only the first 50% of channels) achieves 70% in accuracy on the\nCIFAR-10 dataset compared to the standard network which achieves only 35%\naccuracy when using the reduced channel set.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 17:37:11 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["McDanel", "Bradley", ""], ["Teerapittayanon", "Surat", ""], ["Kung", "H. T.", ""]]}, {"id": "1710.07850", "submitter": "Shiva Kasiviswanathan", "authors": "Shiva Prasad Kasiviswanathan, Nina Narodytska, Hongxia Jin", "title": "Deep Neural Network Approximation using Tensor Sketching", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are powerful learning models that achieve\nstate-of-the-art performance on many computer vision, speech, and language\nprocessing tasks. In this paper, we study a fundamental question that arises\nwhen designing deep network architectures: Given a target network architecture\ncan we design a smaller network architecture that approximates the operation of\nthe target network? The question is, in part, motivated by the challenge of\nparameter reduction (compression) in modern deep neural networks, as the ever\nincreasing storage and memory requirements of these networks pose a problem in\nresource constrained environments.\n  In this work, we focus on deep convolutional neural network architectures,\nand propose a novel randomized tensor sketching technique that we utilize to\ndevelop a unified framework for approximating the operation of both the\nconvolutional and fully connected layers. By applying the sketching technique\nalong different tensor dimensions, we design changes to the convolutional and\nfully connected layers that substantially reduce the number of effective\nparameters in a network. We show that the resulting smaller network can be\ntrained directly, and has a classification accuracy that is comparable to the\noriginal network.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 20:14:00 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Kasiviswanathan", "Shiva Prasad", ""], ["Narodytska", "Nina", ""], ["Jin", "Hongxia", ""]]}, {"id": "1710.07855", "submitter": "Mark Shifrin", "authors": "Mark Shifrin, Hava Siegelmann", "title": "Insulin Regimen ML-based control for T2DM patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\begin{abstract} We model individual T2DM patient blood glucose level (BGL)\nby stochastic process with discrete number of states mainly but not solely\ngoverned by medication regimen (e.g. insulin injections). BGL states change\notherwise according to various physiological triggers which render a\nstochastic, statistically unknown, yet assumed to be quasi-stationary, nature\nof the process. In order to express incentive for being in desired healthy BGL\nwe heuristically define a reward function which returns positive values for\ndesirable BG levels and negative values for undesirable BG levels. The state\nspace consists of sufficient number of states in order to allow for memoryless\nassumption. This, in turn, allows to formulate Markov Decision Process (MDP),\nwith an objective to maximize the total reward, summarized over a long run. The\nprobability law is found by model-based reinforcement learning (RL) and the\noptimal insulin treatment policy is retrieved from MDP solution.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 21:56:53 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Shifrin", "Mark", ""], ["Siegelmann", "Hava", ""]]}, {"id": "1710.07886", "submitter": "Ting Kei Pong", "authors": "Peiran Yu and Ting Kei Pong", "title": "Iteratively reweighted $\\ell_1$ algorithms with extrapolation", "comments": "Fixed typos in the termination criteria for the reweighted algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iteratively reweighted $\\ell_1$ algorithm is a popular algorithm for solving\na large class of optimization problems whose objective is the sum of a\nLipschitz differentiable loss function and a possibly nonconvex sparsity\ninducing regularizer. In this paper, motivated by the success of extrapolation\ntechniques in accelerating first-order methods, we study how widely used\nextrapolation techniques such as those in [4,5,22,28] can be incorporated to\npossibly accelerate the iteratively reweighted $\\ell_1$ algorithm. We consider\nthree versions of such algorithms. For each version, we exhibit an explicitly\ncheckable condition on the extrapolation parameters so that the sequence\ngenerated provably clusters at a stationary point of the optimization problem.\nWe also investigate global convergence under additional Kurdyka-$\\L$ojasiewicz\nassumptions on certain potential functions. Our numerical experiments show that\nour algorithms usually outperform the general iterative shrinkage and\nthresholding algorithm in [21] and an adaptation of the iteratively reweighted\n$\\ell_1$ algorithm in [23, Algorithm 7] with nonmonotone line-search for\nsolving random instances of log penalty regularized least squares problems in\nterms of both CPU time and solution quality.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 03:55:26 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 09:25:32 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Yu", "Peiran", ""], ["Pong", "Ting Kei", ""]]}, {"id": "1710.07939", "submitter": "Weining Shen", "authors": "Shan Suthaharan and Weining Shen", "title": "Elliptical modeling and pattern analysis for perturbation models and\n  classfication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characteristics (or numerical patterns) of a feature vector in the\ntransform domain of a perturbation model differ significantly from those of its\ncorresponding feature vector in the input domain. These differences - caused by\nthe perturbation techniques used for the transformation of feature patterns -\ndegrade the performance of machine learning techniques in the transform domain.\nIn this paper, we proposed a nonlinear parametric perturbation model that\ntransforms the input feature patterns to a set of elliptical patterns, and\nstudied the performance degradation issues associated with random forest\nclassification technique using both the input and transform domain features.\nCompared with the linear transformation such as Principal Component Analysis\n(PCA), the proposed method requires less statistical assumptions and is highly\nsuitable for the applications such as data privacy and security due to the\ndifficulty of inverting the elliptical patterns from the transform domain to\nthe input domain. In addition, we adopted a flexible block-wise dimensionality\nreduction step in the proposed method to accommodate the possible\nhigh-dimensional data in modern applications. We evaluated the empirical\nperformance of the proposed method on a network intrusion data set and a\nbiological data set, and compared the results with PCA in terms of\nclassification performance and data privacy protection (measured by the blind\nsource separation attack and signal interference ratio). Both results confirmed\nthe superior performance of the proposed elliptical transformation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 13:56:22 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Suthaharan", "Shan", ""], ["Shen", "Weining", ""]]}, {"id": "1710.07941", "submitter": "Zhifeng Kong", "authors": "Qi Lyu, Zhifeng Kong, Chao Shen, Tianwei Yue", "title": "WristAuthen: A Dynamic Time Wrapping Approach for User Authentication by\n  Hand-Interaction through Wrist-Worn Devices", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing trend of using wearable devices for context-aware computing and\npervasive sensing systems has raised its potentials for quick and reliable\nauthentication techniques. Since personal writing habitats differ from each\nother, it is possible to realize user authentication through writing. This is\nof great significance as sensible information is easily collected by these\ndevices. This paper presents a novel user authentication system through\nwrist-worn devices by analyzing the interaction behavior with users, which is\nboth accurate and efficient for future usage. The key feature of our approach\nlies in using much more effective Savitzky-Golay filter and Dynamic Time\nWrapping method to obtain fine-grained writing metrics for user authentication.\nThese new metrics are relatively unique from person to person and independent\nof the computing platform. Analyses are conducted on the wristband-interaction\ndata collected from 50 users with diversity in gender, age, and height.\nExtensive experimental results show that the proposed approach can identify\nusers in a timely and accurate manner, with a false-negative rate of 1.78\\%,\nfalse-positive rate of 6.7\\%, and Area Under ROC Curve of 0.983 . Additional\nexamination on robustness to various mimic attacks, tolerance to training data,\nand comparisons to further analyze the applicability.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 13:58:57 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Lyu", "Qi", ""], ["Kong", "Zhifeng", ""], ["Shen", "Chao", ""], ["Yue", "Tianwei", ""]]}, {"id": "1710.07954", "submitter": "Freweyni Kidane Teklehaymanot", "authors": "Freweyni K. Teklehaymanot, Michael Muma, and Abdelhak M. Zoubir", "title": "Bayesian Cluster Enumeration Criterion for Unsupervised Learning", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": "10.1109/TSP.2018.2866385", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new Bayesian Information Criterion (BIC) by formulating the\nproblem of estimating the number of clusters in an observed data set as\nmaximization of the posterior probability of the candidate models. Given that\nsome mild assumptions are satisfied, we provide a general BIC expression for a\nbroad class of data distributions. This serves as a starting point when\nderiving the BIC for specific distributions. Along this line, we provide a\nclosed-form BIC expression for multivariate Gaussian distributed variables. We\nshow that incorporating the data structure of the clustering problem into the\nderivation of the BIC results in an expression whose penalty term is different\nfrom that of the original BIC. We propose a two-step cluster enumeration\nalgorithm. First, a model-based unsupervised learning algorithm partitions the\ndata according to a given set of candidate models. Subsequently, the number of\nclusters is determined as the one associated with the model for which the\nproposed BIC is maximal. The performance of the proposed two-step algorithm is\ntested using synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 14:59:08 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 17:31:04 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 13:53:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Teklehaymanot", "Freweyni K.", ""], ["Muma", "Michael", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1710.07973", "submitter": "Mathukumalli Vidyasagar", "authors": "Mehmet Eren Ahsen and Mathukumalli Vidyasagar", "title": "An Approach to One-Bit Compressed Sensing Based on Probably\n  Approximately Correct Learning Theory", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of one-bit compressed sensing (OBCS) is formulated\nas a problem in probably approximately correct (PAC) learning. It is shown that\nthe Vapnik-Chervonenkis (VC-) dimension of the set of half-spaces in\n$\\mathbb{R}^n$ generated by $k$-sparse vectors is bounded below by $k \\lg\n(n/k)$ and above by $2k \\lg (n/k)$, plus some round-off terms. By coupling this\nestimate with well-established results in PAC learning theory, we show that a\nconsistent algorithm can recover a $k$-sparse vector with $O(k \\lg (n/k))$\nmeasurements, given only the signs of the measurement vector. This result holds\nfor \\textit{all} probability measures on $\\mathbb{R}^n$. It is further shown\nthat random sign-flipping errors result only in an increase in the constant in\nthe $O(k \\lg (n/k))$ estimate. Because constructing a consistent algorithm is\nnot straight-forward, we present a heuristic based on the $\\ell_1$-norm support\nvector machine, and illustrate that its computational performance is superior\nto a currently popular method.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 16:28:24 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Ahsen", "Mehmet Eren", ""], ["Vidyasagar", "Mathukumalli", ""]]}, {"id": "1710.07990", "submitter": "Daniel Larsson", "authors": "Daniel T. Larsson, Daniel Braun, Panagiotis Tsiotras", "title": "Hierarchical State Abstractions for Decision-Making Problems with\n  Computational Constraints", "comments": null, "journal-ref": "2017 IEEE Conference on Decision and Control", "doi": "10.1109/CDC.2017.8263809", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this semi-tutorial paper, we first review the information-theoretic\napproach to account for the computational costs incurred during the search for\noptimal actions in a sequential decision-making problem. The traditional (MDP)\nframework ignores computational limitations while searching for optimal\npolicies, essentially assuming that the acting agent is perfectly rational and\naims for exact optimality. Using the free-energy, a variational principle is\nintroduced that accounts not only for the value of a policy alone, but also\nconsiders the cost of finding this optimal policy. The solution of the\nvariational equations arising from this formulation can be obtained using\nfamiliar Bellman-like value iterations from dynamic programming (DP) and the\nBlahut-Arimoto (BA) algorithm from rate distortion theory. Finally, we\ndemonstrate the utility of the approach for generating hierarchies of state\nabstractions that can be used to best exploit the available computational\nresources. A numerical example showcases these concepts for a path-planning\nproblem in a grid world environment.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 17:59:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Larsson", "Daniel T.", ""], ["Braun", "Daniel", ""], ["Tsiotras", "Panagiotis", ""]]}, {"id": "1710.07991", "submitter": "Mrinal Haloi", "authors": "Mrinal Haloi", "title": "Rethinking Convolutional Semantic Segmentation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional semantic segmentation (DCSS) learning doesn't converge to\nan optimal local minimum with random parameters initializations; a pre-trained\nmodel on the same domain becomes necessary to achieve convergence.In this work,\nwe propose a joint cooperative end-to-end learning method for DCSS. It\naddresses many drawbacks with existing deep semantic segmentation learning; the\nproposed approach simultaneously learn both segmentation and classification;\ntaking away the essential need of the pre-trained model for learning\nconvergence. We present an improved inception based architecture with partial\nattention gating (PAG) over encoder information. The PAG also adds to achieve\nfaster convergence and better accuracy for segmentation task. We will show the\neffectiveness of this learning on a diabetic retinopathy classification and\nsegmentation dataset.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 18:13:24 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Haloi", "Mrinal", ""]]}, {"id": "1710.08005", "submitter": "Adam Elmachtoub", "authors": "Adam N. Elmachtoub, Paul Grigas", "title": "Smart \"Predict, then Optimize\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world analytics problems involve two significant challenges:\nprediction and optimization. Due to the typically complex nature of each\nchallenge, the standard paradigm is predict-then-optimize. By and large,\nmachine learning tools are intended to minimize prediction error and do not\naccount for how the predictions will be used in the downstream optimization\nproblem. In contrast, we propose a new and very general framework, called Smart\n\"Predict, then Optimize\" (SPO), which directly leverages the optimization\nproblem structure, i.e., its objective and constraints, for designing better\nprediction models. A key component of our framework is the SPO loss function\nwhich measures the decision error induced by a prediction.\n  Training a prediction model with respect to the SPO loss is computationally\nchallenging, and thus we derive, using duality theory, a convex surrogate loss\nfunction which we call the SPO+ loss. Most importantly, we prove that the SPO+\nloss is statistically consistent with respect to the SPO loss under mild\nconditions. Our SPO+ loss function can tractably handle any polyhedral, convex,\nor even mixed-integer optimization problem with a linear objective. Numerical\nexperiments on shortest path and portfolio optimization problems show that the\nSPO framework can lead to significant improvement under the\npredict-then-optimize paradigm, in particular when the prediction model being\ntrained is misspecified. We find that linear models trained using SPO+ loss\ntend to dominate random forest algorithms, even when the ground truth is highly\nnonlinear.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 19:44:46 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 04:45:54 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 22:35:21 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 23:53:39 GMT"}, {"version": "v5", "created": "Thu, 19 Nov 2020 23:45:01 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Elmachtoub", "Adam N.", ""], ["Grigas", "Paul", ""]]}, {"id": "1710.08012", "submitter": "Maryam Hashemzadeh", "authors": "Maryam Hashemzadeh, Reshad Hosseini and Majid Nili Ahmadabadi", "title": "Exploiting generalization in the subspaces for faster model-based\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the lack of enough generalization in the state-space, common methods\nin Reinforcement Learning (RL) suffer from slow learning speed especially in\nthe early learning trials. This paper introduces a model-based method in\ndiscrete state-spaces for increasing learning speed in terms of required\nexperience (but not required computational time) by exploiting generalization\nin the experiences of the subspaces. A subspace is formed by choosing a subset\nof features in the original state representation (full-space). Generalization\nand faster learning in a subspace are due to many-to-one mapping of experiences\nfrom the full-space to each state in the subspace. Nevertheless, due to\ninherent perceptual aliasing in the subspaces, the policy suggested by each\nsubspace does not generally converge to the optimal policy. Our approach,\ncalled Model Based Learning with Subspaces (MoBLeS), calculates confidence\nintervals of the estimated Q-values in the full-space and in the subspaces.\nThese confidence intervals are used in the decision making, such that the agent\nbenefits the most from the possible generalization while avoiding from\ndetriment of the perceptual aliasing in the subspaces. Convergence of MoBLeS to\nthe optimal policy is theoretically investigated. Additionally, we show through\nseveral experiments that MoBLeS improves the learning speed in the early\ntrials.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 20:50:52 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 11:51:13 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Hashemzadeh", "Maryam", ""], ["Hosseini", "Reshad", ""], ["Ahmadabadi", "Majid Nili", ""]]}, {"id": "1710.08045", "submitter": "Annie Marsden", "authors": "Annie Marsden, Sergio Bacallado", "title": "Sequential Matrix Completion", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for sequential matrix completion in a\nrecommender system setting, where the $(i,j)$th entry of the matrix corresponds\nto a user $i$'s rating of product $j$. The objective of the algorithm is to\nprovide a sequential policy for user-product pair recommendation which will\nyield the highest possible ratings after a finite time horizon. The algorithm\nuses a Gamma process factor model with two posterior-focused bandit policies,\nThompson Sampling and Information-Directed Sampling. While Thompson Sampling\nshows competitive performance in simulations, state-of-the-art performance is\nobtained from Information-Directed Sampling, which makes its recommendations\nbased off a ratio between the expected reward and a measure of information\ngain. To our knowledge, this is the first implementation of Information\nDirected Sampling on large real datasets.\n  This approach contributes to a recent line of research on bandit approaches\nto collaborative filtering including Kawale et al. (2015), Li et al. (2010),\nBresler et al. (2014), Li et al. (2016), Deshpande & Montanari (2012), and Zhao\net al. (2013). The setting of this paper, as has been noted in Kawale et al.\n(2015) and Zhao et al. (2013), presents significant challenges to bounding\nregret after finite horizons. We discuss these challenges in relation to\nsimpler models for bandits with side information, such as linear or gaussian\nprocess bandits, and hope the experiments presented here motivate further\nresearch toward theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 00:20:32 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Marsden", "Annie", ""], ["Bacallado", "Sergio", ""]]}, {"id": "1710.08079", "submitter": "Young Hun Jung", "authors": "Young Hun Jung, Ambuj Tewari", "title": "Online Boosting Algorithms for Multi-label Ranking", "comments": "12pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-label ranking approach to multi-label learning.\nBoosting is a natural method for multi-label ranking as it aggregates weak\npredictions through majority votes, which can be directly used as scores to\nproduce a ranking of the labels. We design online boosting algorithms with\nprovable loss bounds for multi-label ranking. We show that our first algorithm\nis optimal in terms of the number of learners required to attain a desired\naccuracy, but it requires knowledge of the edge of the weak learners. We also\ndesign an adaptive algorithm that does not require this knowledge and is hence\nmore practical. Experimental results on real data sets demonstrate that our\nalgorithms are at least as good as existing batch boosting algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 03:19:58 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 01:12:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jung", "Young Hun", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1710.08144", "submitter": "Rasmus Henningsson", "authors": "Rasmus Henningsson (1,2) and Magnus Fontes (1,2,3,4) ((1) The Centre\n  for Mathematical Sciences, Lund University, Sweden, (2) The International\n  Group for Data Analysis, Institut Pasteur, Paris, France, (3) The Center for\n  Genomic Medicine, Rigshospitalet, Copenhagen, Denmark, (4) Persimune, The\n  Centre of Excellence for Personalized Medicine, Copenhagen, Denmark)", "title": "SMSSVD - SubMatrix Selection Singular Value Decomposition", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High throughput biomedical measurements normally capture multiple overlaid\nbiologically relevant signals and often also signals representing different\ntypes of technical artefacts like e.g. batch effects. Signal identification and\ndecomposition are accordingly main objectives in statistical biomedical\nmodeling and data analysis. Existing methods, aimed at signal reconstruction\nand deconvolution, in general, are either supervised, contain parameters that\nneed to be estimated or present other types of ad hoc features. We here\nintroduce SubMatrix Selection SingularValue Decomposition (SMSSVD), a\nparameter-free unsupervised signal decomposition and dimension reduction\nmethod, designed to reduce noise, adaptively for each low-rank-signal in a\ngiven data matrix, and represent the signals in the data in a way that enable\nunbiased exploratory analysis and reconstruction of multiple overlaid signals,\nincluding identifying groups of variables that drive different signals.\n  The Submatrix Selection Singular Value Decomposition (SMSSVD) method produces\na denoised signal decomposition from a given data matrix. The SMSSVD method\nguarantees orthogonality between signal components in a straightforward manner\nand it is designed to make automation possible. We illustrate SMSSVD by\napplying it to several real and synthetic datasets and compare its performance\nto golden standard methods like PCA (Principal Component Analysis) and SPC\n(Sparse Principal Components, using Lasso constraints). The SMSSVD is\ncomputationally efficient and despite being a parameter-free method, in\ngeneral, outperforms existing statistical learning methods.\n  A Julia implementation of SMSSVD is openly available on GitHub\n(https://github.com/rasmushenningsson/SMSSVD.jl).\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 08:35:12 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Henningsson", "Rasmus", ""], ["Fontes", "Magnus", ""]]}, {"id": "1710.08165", "submitter": "Raaz Dwivedi", "authors": "Yuansi Chen, Raaz Dwivedi, Martin J. Wainwright, Bin Yu", "title": "Fast MCMC sampling algorithms on polytopes", "comments": "86 pages, 9 figures, First two authors contributed equally", "journal-ref": "The Journal of Machine Learning Research, 19(1), 2146-2231 (2019)", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze two new MCMC sampling algorithms, the Vaidya walk and\nthe John walk, for generating samples from the uniform distribution over a\npolytope. Both random walks are sampling algorithms derived from interior point\nmethods. The former is based on volumetric-logarithmic barrier introduced by\nVaidya whereas the latter uses John's ellipsoids. We show that the Vaidya walk\nmixes in significantly fewer steps than the logarithmic-barrier based Dikin\nwalk studied in past work. For a polytope in $\\mathbb{R}^d$ defined by $n >d$\nlinear constraints, we show that the mixing time from a warm start is bounded\nas $\\mathcal{O}(n^{0.5}d^{1.5})$, compared to the $\\mathcal{O}(nd)$ mixing time\nbound for the Dikin walk. The cost of each step of the Vaidya walk is of the\nsame order as the Dikin walk, and at most twice as large in terms of constant\npre-factors. For the John walk, we prove an\n$\\mathcal{O}(d^{2.5}\\cdot\\log^4(n/d))$ bound on its mixing time and conjecture\nthat an improved variant of it could achieve a mixing time of\n$\\mathcal{O}(d^2\\cdot\\text{polylog}(n/d))$. Additionally, we propose variants\nof the Vaidya and John walks that mix in polynomial time from a deterministic\nstarting point. The speed-up of the Vaidya walk over the Dikin walk are\nillustrated in numerical examples.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 09:33:02 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 04:59:43 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 08:39:58 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Chen", "Yuansi", ""], ["Dwivedi", "Raaz", ""], ["Wainwright", "Martin J.", ""], ["Yu", "Bin", ""]]}, {"id": "1710.08167", "submitter": "Jefrey Lijffijt", "authors": "Kai Puolam\\\"aki, Emilia Oikarinen, Bo Kang, Jefrey Lijffijt, Tijl De\n  Bie", "title": "Interactive Visual Data Exploration with Subjective Feedback: An\n  Information-Theoretic Approach", "comments": "12 pages, 9 figures, 2 tables, conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual exploration of high-dimensional real-valued datasets is a fundamental\ntask in exploratory data analysis (EDA). Existing methods use predefined\ncriteria to choose the representation of data. There is a lack of methods that\n(i) elicit from the user what she has learned from the data and (ii) show\npatterns that she does not know yet. We construct a theoretical model where\nidentified patterns can be input as knowledge to the system. The knowledge\nsyntax here is intuitive, such as \"this set of points forms a cluster\", and\nrequires no knowledge of maths. This background knowledge is used to find a\nMaximum Entropy distribution of the data, after which the system provides the\nuser data projections in which the data and the Maximum Entropy distribution\ndiffer the most, hence showing the user aspects of the data that are maximally\ninformative given the user's current knowledge. We provide an open source EDA\nsystem with tailored interactive visualizations to demonstrate these concepts.\nWe study the performance of the system and present use cases on both synthetic\nand real data. We find that the model and the prototype system allow the user\nto learn information efficiently from various data sources and the system works\nsufficiently fast in practice. We conclude that the information theoretic\napproach to exploratory data analysis where patterns observed by a user are\nformalized as constraints provides a principled, intuitive, and efficient basis\nfor constructing an EDA system.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 09:44:35 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Puolam\u00e4ki", "Kai", ""], ["Oikarinen", "Emilia", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "1710.08177", "submitter": "Saikat  Chatterjee", "authors": "Saikat Chatterjee, Alireza M. Javid, Mostafa Sadeghi, Partha P. Mitra,\n  Mikael Skoglund", "title": "Progressive Learning for Systematic Design of Large Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm for systematic design of a large artificial neural\nnetwork using a progression property. We find that some non-linear functions,\nsuch as the rectifier linear unit and its derivatives, hold the property. The\nsystematic design addresses the choice of network size and regularization of\nparameters. The number of nodes and layers in network increases in progression\nwith the objective of consistently reducing an appropriate cost. Each layer is\noptimized at a time, where appropriate parameters are learned using convex\noptimization. Regularization parameters for convex optimization do not need a\nsignificant manual effort for tuning. We also use random instances for some\nweight matrices, and that helps to reduce the number of parameters we learn.\nThe developed network is expected to show good generalization power due to\nappropriate regularization and use of random weights in the layers. This\nexpectation is verified by extensive experiments for classification and\nregression problems, using standard databases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 10:06:15 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Chatterjee", "Saikat", ""], ["Javid", "Alireza M.", ""], ["Sadeghi", "Mostafa", ""], ["Mitra", "Partha P.", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1710.08310", "submitter": "Kai Han", "authors": "Kai Han, Yunhe Wang, Chao Zhang, Chao Li, Chao Xu", "title": "AutoEncoder Inspired Unsupervised Feature Selection", "comments": "accepted by ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data in many areas such as computer vision and machine\nlearning tasks brings in computational and analytical difficulty. Feature\nselection which selects a subset from observed features is a widely used\napproach for improving performance and effectiveness of machine learning models\nwith high-dimensional data. In this paper, we propose a novel AutoEncoder\nFeature Selector (AEFS) for unsupervised feature selection which combines\nautoencoder regression and group lasso tasks. Compared to traditional feature\nselection methods, AEFS can select the most important features by excavating\nboth linear and nonlinear information among features, which is more flexible\nthan the conventional self-representation method for unsupervised feature\nselection with only linear assumptions. Experimental results on benchmark\ndataset show that the proposed method is superior to the state-of-the-art\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 14:44:17 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 01:19:12 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 13:54:48 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Han", "Kai", ""], ["Wang", "Yunhe", ""], ["Zhang", "Chao", ""], ["Li", "Chao", ""], ["Xu", "Chao", ""]]}, {"id": "1710.08402", "submitter": "Zachary Charles", "authors": "Zachary Charles, Dimitris Papailiopoulos", "title": "Stability and Generalization of Learning Algorithms that Converge to\n  Global Optima", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish novel generalization bounds for learning algorithms that\nconverge to global minima. We do so by deriving black-box stability results\nthat only depend on the convergence of a learning algorithm and the geometry\naround the minimizers of the loss function. The results are shown for nonconvex\nloss functions satisfying the Polyak-{\\L}ojasiewicz (PL) and the quadratic\ngrowth (QG) conditions. We further show that these conditions arise for some\nneural networks with linear activations. We use our black-box results to\nestablish the stability of optimization algorithms such as stochastic gradient\ndescent (SGD), gradient descent (GD), randomized coordinate descent (RCD), and\nthe stochastic variance reduced gradient method (SVRG), in both the PL and the\nstrongly convex setting. Our results match or improve state-of-the-art\ngeneralization bounds and can easily be extended to similar optimization\nalgorithms. Finally, we show that although our results imply comparable\nstability for SGD and GD in the PL setting, there exist simple neural networks\nwith multiple local minima where SGD is stable but GD is not.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 17:42:30 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1710.08446", "submitter": "Mihaela Rosca", "authors": "William Fedus, Mihaela Rosca, Balaji Lakshminarayanan, Andrew M. Dai,\n  Shakir Mohamed, Ian Goodfellow", "title": "Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At\n  Every Step", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a family of generative models that\ndo not minimize a single training criterion. Unlike other generative models,\nthe data distribution is learned via a game between a generator (the generative\nmodel) and a discriminator (a teacher providing training signal) that each\nminimize their own cost. GANs are designed to reach a Nash equilibrium at which\neach player cannot reduce their cost without changing the other players'\nparameters. One useful approach for the theory of GANs is to show that a\ndivergence between the training distribution and the model distribution obtains\nits minimum value at equilibrium. Several recent research directions have been\nmotivated by the idea that this divergence is the primary guide for the\nlearning process and that every step of learning should decrease the\ndivergence. We show that this view is overly restrictive. During GAN training,\nthe discriminator provides learning signal in situations where the gradients of\nthe divergences between distributions would not be useful. We provide empirical\ncounterexamples to the view of GAN training as divergence minimization.\nSpecifically, we demonstrate that GANs are able to learn distributions in\nsituations where the divergence minimization point of view predicts they would\nfail. We also show that gradient penalties motivated from the divergence\nminimization perspective are equally helpful when applied in other contexts in\nwhich the divergence minimization perspective does not predict they would be\nhelpful. This contributes to a growing body of evidence that GAN training may\nbe more usefully viewed as approaching Nash equilibria via trajectories that do\nnot necessarily minimize a specific divergence at each step.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 18:30:56 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 09:02:49 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 22:10:33 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Fedus", "William", ""], ["Rosca", "Mihaela", ""], ["Lakshminarayanan", "Balaji", ""], ["Dai", "Andrew M.", ""], ["Mohamed", "Shakir", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1710.08464", "submitter": "Benjamin Baron", "authors": "Benjamin Baron and Mirco Musolesi", "title": "Interpretable Machine Learning for Privacy-Preserving Pervasive Systems", "comments": null, "journal-ref": "IEEE Pervasive Computing, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our everyday interactions with pervasive systems generate traces that capture\nvarious aspects of human behavior and enable machine learning algorithms to\nextract latent information about users. In this paper, we propose a machine\nlearning interpretability framework that enables users to understand how these\ngenerated traces violate their privacy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 19:19:55 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 17:02:19 GMT"}, {"version": "v3", "created": "Wed, 29 Nov 2017 16:45:31 GMT"}, {"version": "v4", "created": "Tue, 9 Jan 2018 14:46:02 GMT"}, {"version": "v5", "created": "Wed, 13 Jun 2018 17:38:07 GMT"}, {"version": "v6", "created": "Tue, 4 Jun 2019 21:17:51 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Baron", "Benjamin", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1710.08473", "submitter": "Christopher Xie", "authors": "Christopher Xie, Alex Tank, Alec Greaves-Tunnell, Emily Fox", "title": "A Unified Framework for Long Range and Cold Start Forecasting of\n  Seasonal Profiles in Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing long-range forecasts is a fundamental challenge in time series\nmodeling, which is only compounded by the challenge of having to form such\nforecasts when a time series has never previously been observed. The latter\nchallenge is the time series version of the cold-start problem seen in\nrecommender systems which, to our knowledge, has not been addressed in previous\nwork. A similar problem occurs when a long range forecast is required after\nonly observing a small number of time points --- a warm start forecast. With\nthese aims in mind, we focus on forecasting seasonal profiles---or baseline\ndemand---for periods on the order of a year in three cases: the long range case\nwith multiple previously observed seasonal profiles, the cold start case with\nno previous observed seasonal profiles, and the warm start case with only a\nsingle partially observed profile. Classical time series approaches that\nperform iterated step-ahead forecasts based on previous observations struggle\nto provide accurate long range predictions; in settings with little to no\nobserved data, such approaches are simply not applicable. Instead, we present a\nstraightforward framework which combines ideas from high-dimensional regression\nand matrix factorization on a carefully constructed data matrix. Key to our\nformulation and resulting performance is leveraging (1) repeated patterns over\nfixed periods of time and across series, and (2) metadata associated with the\nindividual series; without this additional data, the cold-start/warm-start\nproblems are nearly impossible to solve. We demonstrate that our framework can\naccurately forecast an array of seasonal profiles on multiple large scale\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 19:37:00 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 19:48:07 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Xie", "Christopher", ""], ["Tank", "Alex", ""], ["Greaves-Tunnell", "Alec", ""], ["Fox", "Emily", ""]]}, {"id": "1710.08502", "submitter": "Feipeng Zhao", "authors": "Feipeng Zhao and Martin Renqiang Min and Chen Shen and Amit\n  Chakraborty", "title": "Convolutional Neural Knowledge Graph Learning", "comments": "evaluation mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous models for learning entity and relationship embeddings of knowledge\ngraphs such as TransE, TransH, and TransR aim to explore new links based on\nlearned representations. However, these models interpret relationships as\nsimple translations on entity embeddings. In this paper, we try to learn more\ncomplex connections between entities and relationships. In particular, we use a\nConvolutional Neural Network (CNN) to learn entity and relationship\nrepresentations in knowledge graphs. In our model, we treat entities and\nrelationships as one-dimensional numerical sequences with the same length.\nAfter that, we combine each triplet of head, relationship, and tail together as\na matrix with height 3. CNN is applied to the triplets to get confidence\nscores. Positive and manually corrupted negative triplets are used to train the\nembeddings and the CNN model simultaneously. Experimental results on public\nbenchmark datasets show that the proposed model outperforms state-of-the-art\nmodels on exploring unseen relationships, which proves that CNN is effective to\nlearn complex interactive patterns between entities and relationships.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 20:39:40 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 19:58:14 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Zhao", "Feipeng", ""], ["Min", "Martin Renqiang", ""], ["Shen", "Chen", ""], ["Chakraborty", "Amit", ""]]}, {"id": "1710.08511", "submitter": "Denisa Roberts", "authors": "Lucas Roberts and Denisa Roberts", "title": "An Expectation Maximization Framework for Yule-Simon Preferential\n  Attachment Models", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop an Expectation Maximization(EM) algorithm to\nestimate the parameter of a Yule-Simon distribution. The Yule-Simon\ndistribution exhibits the \"rich get richer\" effect whereby an 80-20 type of\nrule tends to dominate. These distributions are ubiquitous in industrial\nsettings. The EM algorithm presented provides both frequentist and Bayesian\nestimates of the $\\lambda$ parameter. By placing the estimation method within\nthe EM framework we are able to derive Standard errors of the resulting\nestimate. Additionally, we prove convergence of the Yule-Simon EM algorithm and\nstudy the rate of convergence. An explicit, closed form solution for the rate\nof convergence of the algorithm is given. Applications including graph node\ndegree distribution estimation are listed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 21:33:31 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 23:11:55 GMT"}, {"version": "v3", "created": "Sun, 16 Sep 2018 14:10:43 GMT"}, {"version": "v4", "created": "Sat, 14 Nov 2020 20:09:41 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Roberts", "Lucas", ""], ["Roberts", "Denisa", ""]]}, {"id": "1710.08530", "submitter": "Ali Heydari", "authors": "Ali Heydari", "title": "Stability Analysis of Optimal Adaptive Control using Value Iteration\n  with Approximation Errors", "comments": "A part of this paper is based on preliminary results presented in\n  arXiv:1412.5675", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive optimal control using value iteration initiated from a stabilizing\ncontrol policy is theoretically analyzed in terms of stability of the system\nduring the learning stage without ignoring the effects of approximation errors.\nThis analysis includes the system operated using any single/constant resulting\ncontrol policy and also using an evolving/time-varying control policy. A\nfeature of the presented results is providing estimations of the \\textit{region\nof attraction} so that if the initial condition is within the region, the whole\ntrajectory will remain inside it and hence, the function approximation results\nremain valid.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 22:20:22 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Heydari", "Ali", ""]]}, {"id": "1710.08531", "submitter": "Zhengping Che", "authors": "Sanjay Purushotham, Chuizheng Meng, Zhengping Che, Yan Liu", "title": "Benchmark of Deep Learning Models on Large Healthcare MIMIC Datasets", "comments": "Submitted to Journal of Biomedical Informatics (JBI). First two\n  authors have equal contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models (aka Deep Neural Networks) have revolutionized many\nfields including computer vision, natural language processing, speech\nrecognition, and is being increasingly used in clinical healthcare\napplications. However, few works exist which have benchmarked the performance\nof the deep learning models with respect to the state-of-the-art machine\nlearning models and prognostic scoring systems on publicly available healthcare\ndatasets. In this paper, we present the benchmarking results for several\nclinical prediction tasks such as mortality prediction, length of stay\nprediction, and ICD-9 code group prediction using Deep Learning models,\nensemble of machine learning models (Super Learner algorithm), SAPS II and SOFA\nscores. We used the Medical Information Mart for Intensive Care III (MIMIC-III)\n(v1.4) publicly available dataset, which includes all patients admitted to an\nICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the\nbenchmarking tasks. Our results show that deep learning models consistently\noutperform all the other approaches especially when the `raw' clinical time\nseries data is used as input features to the models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 22:23:34 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Purushotham", "Sanjay", ""], ["Meng", "Chuizheng", ""], ["Che", "Zhengping", ""], ["Liu", "Yan", ""]]}, {"id": "1710.08583", "submitter": "Abdollah Safari", "authors": "Abdollah Safari, Rachel MacKay Altman and Thomas M. Loughin", "title": "Display advertising: Estimating conversion probability efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of online display advertising is to entice users to \"convert\" (i.e.,\ntake a pre-defined action such as making a purchase) after clicking on the ad.\nAn important measure of the value of an ad is the probability of conversion.\nThe focus of this paper is the development of a computationally efficient,\naccurate, and precise estimator of conversion probability. The challenges\nassociated with this estimation problem are the delays in observing conversions\nand the size of the data set (both number of observations and number of\npredictors). Two models have previously been considered as a basis for\nestimation: A logistic regression model and a joint model for observed\nconversion statuses and delay times. Fitting the former is simple, but ignoring\nthe delays in conversion leads to an under-estimate of conversion probability.\nOn the other hand, the latter is less biased but computationally expensive to\nfit. Our proposed estimator is a compromise between these two estimators. We\napply our results to a data set from Criteo, a commerce marketing company that\npersonalizes online display advertisements for users.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 02:46:23 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Safari", "Abdollah", ""], ["Altman", "Rachel MacKay", ""], ["Loughin", "Thomas M.", ""]]}, {"id": "1710.08619", "submitter": "Sambuddha Ghosal", "authors": "Sambuddha Ghosal, David Blystone, Asheesh K. Singh, Baskar\n  Ganapathysubramanian, Arti Singh and Soumik Sarkar", "title": "Interpretable Deep Learning applied to Plant Stress Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Availability of an explainable deep learning model that can be applied to\npractical real world scenarios and in turn, can consistently, rapidly and\naccurately identify specific and minute traits in applicable fields of\nbiological sciences, is scarce. Here we consider one such real world example\nviz., accurate identification, classification and quantification of biotic and\nabiotic stresses in crop research and production. Up until now, this has been\npredominantly done manually by visual inspection and require specialized\ntraining. However, such techniques are hindered by subjectivity resulting from\ninter- and intra-rater cognitive variability. Here, we demonstrate the ability\nof a machine learning framework to identify and classify a diverse set of\nfoliar stresses in the soybean plant with remarkable accuracy. We also present\nan explanation mechanism using gradient-weighted class activation mapping that\nisolates the visual symptoms used by the model to make predictions. This\nunsupervised identification of unique visual symptoms for each stress provides\na quantitative measure of stress severity, allowing for identification,\nclassification and quantification in one framework. The learnt model appears to\nbe agnostic to species and make good predictions for other (non-soybean)\nspecies, demonstrating an ability of transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 06:49:03 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 21:33:19 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 22:10:09 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Ghosal", "Sambuddha", ""], ["Blystone", "David", ""], ["Singh", "Asheesh K.", ""], ["Ganapathysubramanian", "Baskar", ""], ["Singh", "Arti", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1710.08637", "submitter": "Vincent Gripon", "authors": "Vincent Gripon and Ghouthi B. Hacene and Matthias L\\\"owe and Franck\n  Vermet", "title": "Improving Accuracy of Nonparametric Transfer Learning via Vector\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning using deep neural networks as feature extractors has become\nincreasingly popular over the past few years. It allows to obtain\nstate-of-the-art accuracy on datasets too small to train a deep neural network\non its own, and it provides cutting edge descriptors that, combined with\nnonparametric learning methods, allow rapid and flexible deployment of\nperforming solutions in computationally restricted settings. In this paper, we\nare interested in showing that the features extracted using deep neural\nnetworks have specific properties which can be used to improve accuracy of\ndownstream nonparametric learning methods. Namely, we demonstrate that for some\ndistributions where information is embedded in a few coordinates, segmenting\nfeature vectors can lead to better accuracy. We show how this model can be\napplied to real datasets by performing experiments using three mainstream deep\nneural network feature extractors and four databases, in vision and audio.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 07:46:57 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Gripon", "Vincent", ""], ["Hacene", "Ghouthi B.", ""], ["L\u00f6we", "Matthias", ""], ["Vermet", "Franck", ""]]}, {"id": "1710.08717", "submitter": "Zhenwen Dai", "authors": "Matthias Seeger, Asmus Hetzel, Zhenwen Dai, Eric Meissner, Neil D.\n  Lawrence", "title": "Auto-Differentiating Linear Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development systems for deep learning (DL), such as Theano, Torch,\nTensorFlow, or MXNet, are easy-to-use tools for creating complex neural network\nmodels. Since gradient computations are automatically baked in, and execution\nis mapped to high performance hardware, these models can be trained end-to-end\non large amounts of data. However, it is currently not easy to implement many\nbasic machine learning primitives in these systems (such as Gaussian processes,\nleast squares estimation, principal components analysis, Kalman smoothing),\nmainly because they lack efficient support of linear algebra primitives as\ndifferentiable operators. We detail how a number of matrix decompositions\n(Cholesky, LQ, symmetric eigen) can be implemented as differentiable operators.\nWe have implemented these primitives in MXNet, running on CPU and GPU in single\nand double precision. We sketch use cases of these new operators, learning\nGaussian process and Bayesian linear regression models, where we demonstrate\nvery substantial reductions in implementation complexity and running time\ncompared to previous codes. Our MXNet extension allows end-to-end learning of\nhybrid models, which combine deep neural networks (DNNs) with Bayesian\nconcepts, with applications in advanced Gaussian process models, scalable\nBayesian optimization, and Bayesian active learning.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 11:58:45 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 15:13:38 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 13:48:27 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2018 09:40:13 GMT"}, {"version": "v5", "created": "Wed, 14 Aug 2019 13:08:25 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Seeger", "Matthias", ""], ["Hetzel", "Asmus", ""], ["Dai", "Zhenwen", ""], ["Meissner", "Eric", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1710.08728", "submitter": "Nicholas Horton", "authors": "Amelia McNamara and Nicholas J. Horton and Benjamin S. Baumer", "title": "Greater data science at baccalaureate institutions", "comments": "in press response to Donoho paper in Journal of Computational\n  Graphics and Statistics", "journal-ref": null, "doi": "10.1080/10618600.2017.1386568", "report-no": null, "categories": "stat.OT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Donoho's JCGS (in press) paper is a spirited call to action for\nstatisticians, who he points out are losing ground in the field of data science\nby refusing to accept that data science is its own domain. (Or, at least, a\ndomain that is becoming distinctly defined.) He calls on writings by John\nTukey, Bill Cleveland, and Leo Breiman, among others, to remind us that\nstatisticians have been dealing with data science for years, and encourages\nacceptance of the direction of the field while also ensuring that statistics is\ntightly integrated.\n  As faculty at baccalaureate institutions (where the growth of undergraduate\nstatistics programs has been dramatic), we are keen to ensure statistics has a\nplace in data science and data science education. In his paper, Donoho is\nprimarily focused on graduate education. At our undergraduate institutions, we\nare considering many of the same questions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 12:23:20 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["McNamara", "Amelia", ""], ["Horton", "Nicholas J.", ""], ["Baumer", "Benjamin S.", ""]]}, {"id": "1710.08729", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Marek Kurzynski", "title": "A Correction Method of a Binary Classifier Applied to Multi-label\n  Pairwise Models", "comments": null, "journal-ref": null, "doi": "10.1142/s0129065717500629", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we addressed the issue of applying a stochastic classifier and\na local, fuzzy confusion matrix under the framework of multi-label\nclassification. We proposed a novel solution to the problem of correcting label\npairwise ensembles. The main step of the correction procedure is to compute\nclassifier- specific competence and cross-competence measures, which estimates\nerror pattern of the underlying classifier. We considered two improvements of\nthe method of obtaining confusion matrices. The first one is aimed to deal with\nimbalanced labels. The other utilizes double labelled instances which are\nusually removed during the pairwise transformation. The proposed methods were\nevaluated using 29 benchmark datasets. In order to assess the efficiency of the\nintroduced models, they were compared against 1 state-of-the-art approach and\nthe correction scheme based on the original method of confusion matrix\nestimation. The comparison was performed using four different multi-label\nevaluation measures: macro and micro-averaged F1 loss, zero-one loss and\nHamming loss. Additionally, we investigated relations between classification\nquality, which is expressed in terms of different quality criteria, and\ncharacteristics of multi-label datasets such as average imbalance ratio or\nlabel density. The experimental study reveals that the correction approaches\nsignificantly outperforms the reference method only in terms of zero-one loss.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 12:23:22 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Trajdos", "Pawel", ""], ["Kurzynski", "Marek", ""]]}, {"id": "1710.08775", "submitter": "Patrick Forr\\'e", "authors": "Patrick Forr\\'e and Joris M. Mooij", "title": "Markov Properties for Graphical Models with Cycles and Latent Variables", "comments": "131 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate probabilistic graphical models that allow for both cycles and\nlatent variables. For this we introduce directed graphs with hyperedges\n(HEDGes), generalizing and combining both marginalized directed acyclic graphs\n(mDAGs) that can model latent (dependent) variables, and directed mixed graphs\n(DMGs) that can model cycles. We define and analyse several different Markov\nproperties that relate the graphical structure of a HEDG with a probability\ndistribution on a corresponding product space over the set of nodes, for\nexample factorization properties, structural equations properties,\nordered/local/global Markov properties, and marginal versions of these. The\nvarious Markov properties for HEDGes are in general not equivalent to each\nother when cycles or hyperedges are present, in contrast with the simpler case\nof directed acyclic graphical (DAG) models (also known as Bayesian networks).\nWe show how the Markov properties for HEDGes - and thus the corresponding\ngraphical Markov models - are logically related to each other.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 13:52:34 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Forr\u00e9", "Patrick", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1710.08816", "submitter": "Tatsuro Kawamoto", "authors": "Tatsuro Kawamoto", "title": "Algorithmic infeasibility of community detection in higher-order\n  networks", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In principle, higher-order networks that have multiple edge types are more\ninformative than their lower-order counterparts. In practice, however,\nexcessively rich information may be algorithmically infeasible to extract. It\nrequires an algorithm that assumes a high-dimensional model and such an\nalgorithm may perform poorly or be extremely sensitive to the initial estimate\nof the model parameters. Herein, we address this problem of community detection\nthrough a detectability analysis. We focus on the expectation-maximization (EM)\nalgorithm with belief propagation (BP), and analytically derive its algorithmic\ndetectability threshold, i.e., the limit of the modular structure strength\nbelow which the algorithm can no longer detect any modular structures. The\nresults indicate the existence of a phase in which the community detection of a\nlower-order network outperforms its higher-order counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 14:54:52 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Kawamoto", "Tatsuro", ""]]}, {"id": "1710.08841", "submitter": "Tatsuro Kawamoto", "authors": "Tatsuro Kawamoto", "title": "Algorithmic detectability threshold of the stochastic block model", "comments": "15 pages, 8 figures", "journal-ref": "Phys. Rev. E 97, 032301 (2018)", "doi": "10.1103/PhysRevE.97.032301", "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assumption that the values of model parameters are known or correctly\nlearned, i.e., the Nishimori condition, is one of the requirements for the\ndetectability analysis of the stochastic block model in statistical inference.\nIn practice, however, there is no example demonstrating that we can know the\nmodel parameters beforehand, and there is no guarantee that the model\nparameters can be learned accurately. In this study, we consider the\nexpectation--maximization (EM) algorithm with belief propagation (BP) and\nderive its algorithmic detectability threshold. Our analysis is not restricted\nto the community structure, but includes general modular structures. Because\nthe algorithm cannot always learn the planted model parameters correctly, the\nalgorithmic detectability threshold is qualitatively different from the one\nwith the Nishimori condition.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 15:18:13 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:24:59 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Kawamoto", "Tatsuro", ""]]}, {"id": "1710.08846", "submitter": "Yunchuan Kong", "authors": "Yunchuan Kong and Xiaodan Fan", "title": "A Bayesian Method for Joint Clustering of Vectorial Data and Network\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based integrative method for clustering objects given\nboth vectorial data, which describes the feature of each object, and network\ndata, which indicates the similarity of connected objects. The proposed general\nmodel is able to cluster the two types of data simultaneously within one\nintegrative probabilistic model, while traditional methods can only handle one\ndata type or depend on transforming one data type to another. Bayesian\ninference of the clustering is conducted based on a Markov chain Monte Carlo\nalgorithm. A special case of the general model combining the Gaussian mixture\nmodel and the stochastic block model is extensively studied. We used both\nsynthetic data and real data to evaluate this new method and compare it with\nalternative methods. The results show that our simultaneous clustering method\nperforms much better. This improvement is due to the power of the model-based\nprobabilistic approach for efficiently integrating information.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 15:26:46 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Kong", "Yunchuan", ""], ["Fan", "Xiaodan", ""]]}, {"id": "1710.08864", "submitter": "Jiawei Su", "authors": "Jiawei Su, Danilo Vasconcellos Vargas and Sakurai Kouichi", "title": "One pixel attack for fooling deep neural networks", "comments": null, "journal-ref": "IEEE Transactions on Evolutionary Computation}, Vol.23 , Issue.5 ,\n  pp. 828--841. Publisher: IEEE. 2019", "doi": "10.1109/TEVC.2019.2890858", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has revealed that the output of Deep Neural Networks (DNN)\ncan be easily altered by adding relatively small perturbations to the input\nvector. In this paper, we analyze an attack in an extremely limited scenario\nwhere only one pixel can be modified. For that we propose a novel method for\ngenerating one-pixel adversarial perturbations based on differential evolution\n(DE). It requires less adversarial information (a black-box attack) and can\nfool more types of networks due to the inherent features of DE. The results\nshow that 67.97% of the natural images in Kaggle CIFAR-10 test dataset and\n16.04% of the ImageNet (ILSVRC 2012) test images can be perturbed to at least\none target class by modifying just one pixel with 74.03% and 22.91% confidence\non average. We also show the same vulnerability on the original CIFAR-10\ndataset. Thus, the proposed attack explores a different take on adversarial\nmachine learning in an extreme limited scenario, showing that current DNNs are\nalso vulnerable to such low dimension attacks. Besides, we also illustrate an\nimportant application of DE (or broadly speaking, evolutionary computation) in\nthe domain of adversarial machine learning: creating tools that can effectively\ngenerate low-cost adversarial attacks against neural networks for evaluating\nrobustness.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 16:02:19 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 07:58:35 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 08:53:44 GMT"}, {"version": "v4", "created": "Thu, 22 Feb 2018 09:18:34 GMT"}, {"version": "v5", "created": "Mon, 28 Jan 2019 04:39:30 GMT"}, {"version": "v6", "created": "Fri, 3 May 2019 08:32:24 GMT"}, {"version": "v7", "created": "Thu, 17 Oct 2019 07:46:53 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Su", "Jiawei", ""], ["Vargas", "Danilo Vasconcellos", ""], ["Kouichi", "Sakurai", ""]]}, {"id": "1710.08873", "submitter": "Andrew Wagenmaker", "authors": "Andrew J. Wagenmaker and Brian E. Moore and Raj Rao Nadakuditi", "title": "Robust Photometric Stereo via Dictionary Learning", "comments": "To appear in IEEE Transactions on Computational Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photometric stereo is a method that seeks to reconstruct the normal vectors\nof an object from a set of images of the object illuminated under different\nlight sources. While effective in some situations, classical photometric stereo\nrelies on a diffuse surface model that cannot handle objects with complex\nreflectance patterns, and it is sensitive to non-idealities in the images. In\nthis work, we propose a novel approach to photometric stereo that relies on\ndictionary learning to produce robust normal vector reconstructions.\nSpecifically, we develop two formulations for applying dictionary learning to\nphotometric stereo. We propose a model that applies dictionary learning to\nregularize and reconstruct the normal vectors from the images under the classic\nLambertian reflectance model. We then generalize this model to explicitly model\nnon-Lambertian objects. We investigate both approaches through extensive\nexperimentation on synthetic and real benchmark datasets and observe\nstate-of-the-art performance compared to existing robust photometric stereo\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 16:30:29 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 23:11:01 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 21:23:23 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Wagenmaker", "Andrew J.", ""], ["Moore", "Brian E.", ""], ["Nadakuditi", "Raj Rao", ""]]}, {"id": "1710.08878", "submitter": "Andreas Haupt", "authors": "Andreas Haupt, Mohammad Khatami, Thomas Schultz, Ngoc Mai Tran", "title": "Classification on Large Networks: A Quantitative Bound via Motifs and\n  Graphons", "comments": "17 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When each data point is a large graph, graph statistics such as densities of\ncertain subgraphs (motifs) can be used as feature vectors for machine learning.\nWhile intuitive, motif counts are expensive to compute and difficult to work\nwith theoretically. Via graphon theory, we give an explicit quantitative bound\nfor the ability of motif homomorphisms to distinguish large networks under both\ngenerative and sampling noise. Furthermore, we give similar bounds for the\ngraph spectrum and connect it to homomorphism densities of cycles. This results\nin an easily computable classifier on graph data with theoretical performance\nguarantee. Our method yields competitive results on classification tasks for\nthe autoimmune disease Lupus Erythematosus.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 16:34:37 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Haupt", "Andreas", ""], ["Khatami", "Mohammad", ""], ["Schultz", "Thomas", ""], ["Tran", "Ngoc Mai", ""]]}, {"id": "1710.08882", "submitter": "Sijia Liu", "authors": "Sijia Liu, Yanzhi Wang, Makan Fardad and Pramod K. Varshney", "title": "A Memristor-Based Optimization Framework for AI Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memristors have recently received significant attention as ubiquitous\ndevice-level components for building a novel generation of computing systems.\nThese devices have many promising features, such as non-volatility, low power\nconsumption, high density, and excellent scalability. The ability to control\nand modify biasing voltages at the two terminals of memristors make them\npromising candidates to perform matrix-vector multiplications and solve systems\nof linear equations. In this article, we discuss how networks of memristors\narranged in crossbar arrays can be used for efficiently solving optimization\nand machine learning problems. We introduce a new memristor-based optimization\nframework that combines the computational merit of memristor crossbars with the\nadvantages of an operator splitting method, alternating direction method of\nmultipliers (ADMM). Here, ADMM helps in splitting a complex optimization\nproblem into subproblems that involve the solution of systems of linear\nequations. The capability of this framework is shown by applying it to linear\nprogramming, quadratic programming, and sparse optimization. In addition to\nADMM, implementation of a customized power iteration (PI) method for\neigenvalue/eigenvector computation using memristor crossbars is discussed. The\nmemristor-based PI method can further be applied to principal component\nanalysis (PCA). The use of memristor crossbars yields a significant speed-up in\ncomputation, and thus, we believe, has the potential to advance optimization\nand machine learning research in artificial intelligence (AI).\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 15:09:22 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Liu", "Sijia", ""], ["Wang", "Yanzhi", ""], ["Fardad", "Makan", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1710.08894", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk, Ilia Nouretdinov, Valery Manokhin, and Alex Gammerman", "title": "Conformal predictive distributions with kernels", "comments": "20 pages, 3 figures, prepared for the Proceedings of the Braverman\n  Readings (Boston, 28-30 April 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the checkered history of predictive distributions in\nstatistics and discusses two developments, one from recent literature and the\nother new. The first development is bringing predictive distributions into\nmachine learning, whose early development was so deeply influenced by two\nremarkable groups at the Institute of Automation and Remote Control. The second\ndevelopment is combining predictive distributions with kernel methods, which\nwere originated by one of those groups, including Emmanuel Braverman.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 17:10:49 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Vovk", "Vladimir", ""], ["Nouretdinov", "Ilia", ""], ["Manokhin", "Valery", ""], ["Gammerman", "Alex", ""]]}, {"id": "1710.08901", "submitter": "Pedro Gabriel Fonseca", "authors": "Pedro G. Fonseca and Hugo D. Lopes", "title": "Calibration of Machine Learning Classifiers for Probability of Default\n  Modelling", "comments": "Keywords: Binary classification, Probability of Default, Calibration,\n  Credit Risk, Isotonic Regression, Platt Scaling", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary classification is highly used in credit scoring in the estimation of\nprobability of default. The validation of such predictive models is based both\non rank ability, and also on calibration (i.e. how accurately the probabilities\noutput by the model map to the observed probabilities). In this study we cover\nthe current best practices regarding calibration for binary classification, and\nexplore how different approaches yield different results on real world credit\nscoring data. The limitations of evaluating credit scoring models using only\nrank ability metrics are explored. A benchmark is run on 18 real world\ndatasets, and results compared. The calibration techniques used are Platt\nScaling and Isotonic Regression. Also, different machine learning models are\nused: Logistic Regression, Random Forest Classifiers, and Gradient Boosting\nClassifiers. Results show that when the dataset is treated as a time series,\nthe use of re-calibration with Isotonic Regression is able to improve the long\nterm calibration better than the alternative methods. Using re-calibration, the\nnon-parametric models are able to outperform the Logistic Regression on Brier\nScore Loss.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 17:36:51 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Fonseca", "Pedro G.", ""], ["Lopes", "Hugo D.", ""]]}, {"id": "1710.08936", "submitter": "Hoi-To Wai", "authors": "Hoi-To Wai, Wei Shi, Angelia Nedic and Anna Scaglione", "title": "Curvature-aided Incremental Aggregated Gradient Method", "comments": "Final version submitted to Allerton Conference 2017 on Oct 8, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new algorithm for finite sum optimization which we call the\ncurvature-aided incremental aggregated gradient (CIAG) method. Motivated by the\nproblem of training a classifier for a d-dimensional problem, where the number\nof training data is $m$ and $m \\gg d \\gg 1$, the CIAG method seeks to\naccelerate incremental aggregated gradient (IAG) methods using aids from the\ncurvature (or Hessian) information, while avoiding the evaluation of matrix\ninverses required by the incremental Newton (IN) method. Specifically, our idea\nis to exploit the incrementally aggregated Hessian matrix to trace the full\ngradient vector at every incremental step, therefore achieving an improved\nlinear convergence rate over the state-of-the-art IAG methods. For strongly\nconvex problems, the fast linear convergence rate requires the objective\nfunction to be close to quadratic, or the initial point to be close to optimal\nsolution. Importantly, we show that running one iteration of the CIAG method\nyields the same improvement to the optimality gap as running one iteration of\nthe full gradient method, while the complexity is $O(d^2)$ for CIAG and $O(md)$\nfor the full gradient. Overall, the CIAG method strikes a balance between the\nhigh computation complexity incremental Newton-type methods and the slow IAG\nmethod. Our numerical results support the theoretical findings and show that\nthe CIAG method often converges with much fewer iterations than IAG, and\nrequires much shorter running time than IN when the problem dimension is high.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 18:12:33 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Wai", "Hoi-To", ""], ["Shi", "Wei", ""], ["Nedic", "Angelia", ""], ["Scaglione", "Anna", ""]]}, {"id": "1710.08952", "submitter": "Anthony Gamst", "authors": "Anthony Gamst, Jay-Calvin Reyes and Alden Walker", "title": "Estimating the Operating Characteristics of Ensemble Methods", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a technique for using the bootstrap to estimate the\noperating characteristics and their variability for certain types of ensemble\nmethods. Bootstrapping a model can require a huge amount of work if the\ntraining data set is large. Fortunately in many cases the technique lets us\ndetermine the effect of infinite resampling without actually refitting a single\nmodel. We apply the technique to the study of meta-parameter selection for\nrandom forests. We demonstrate that alternatives to bootstrap aggregation and\nto considering \\sqrt{d} features to split each node, where d is the number of\nfeatures, can produce improvements in predictive accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 19:00:16 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Gamst", "Anthony", ""], ["Reyes", "Jay-Calvin", ""], ["Walker", "Alden", ""]]}, {"id": "1710.08961", "submitter": "Milad Makkie", "authors": "Milad Makkie, Heng Huang, Yu Zhao, Athanasios V. Vasilakos, Tianming\n  Liu", "title": "Fast and Scalable Distributed Deep Convolutional Autoencoder for fMRI\n  Big Data Analytics", "comments": "This work is submitted to SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, analyzing task-based fMRI (tfMRI) data has become an\nessential tool for understanding brain function and networks. However, due to\nthe sheer size of tfMRI data, its intrinsic complex structure, and lack of\nground truth of underlying neural activities, modeling tfMRI data is hard and\nchallenging. Previously proposed data-modeling methods including Independent\nComponent Analysis (ICA) and Sparse Dictionary Learning only provided a weakly\nestablished model based on blind source separation under the strong assumption\nthat original fMRI signals could be linearly decomposed into time series\ncomponents with corresponding spatial maps. Meanwhile, analyzing and learning a\nlarge amount of tfMRI data from a variety of subjects has been shown to be very\ndemanding but yet challenging even with technological advances in computational\nhardware. Given the Convolutional Neural Network (CNN), a robust method for\nlearning high-level abstractions from low-level data such as tfMRI time series,\nin this work we propose a fast and scalable novel framework for distributed\ndeep Convolutional Autoencoder model. This model aims to both learn the complex\nhierarchical structure of the tfMRI data and to leverage the processing power\nof multiple GPUs in a distributed fashion. To implement such a model, we have\ncreated an enhanced processing pipeline on the top of Apache Spark and\nTensorflow library, leveraging from a very large cluster of GPU machines.\nExperimental data from applying the model on the Human Connectome Project (HCP)\nshow that the proposed model is efficient and scalable toward tfMRI big data\nanalytics, thus enabling data-driven extraction of hierarchical neuroscientific\ninformation from massive fMRI big data in the future.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 19:35:51 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 07:46:58 GMT"}, {"version": "v3", "created": "Sun, 4 Mar 2018 21:31:55 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Makkie", "Milad", ""], ["Huang", "Heng", ""], ["Zhao", "Yu", ""], ["Vasilakos", "Athanasios V.", ""], ["Liu", "Tianming", ""]]}, {"id": "1710.08963", "submitter": "Patrick Perry", "authors": "Patrick O. Perry and Kenneth Benoit", "title": "Scaling Text with the Class Affinity Model", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic methods for classifying text form a rich tradition in machine\nlearning and natural language processing. For many important problems, however,\nclass prediction is uninteresting because the class is known, and instead the\nfocus shifts to estimating latent quantities related to the text, such as\naffect or ideology. We focus on one such problem of interest, estimating the\nideological positions of 55 Irish legislators in the 1991 D\\'ail confidence\nvote. To solve the D\\'ail scaling problem and others like it, we develop a text\nmodeling framework that allows actors to take latent positions on a \"gray\"\nspectrum between \"black\" and \"white\" polar opposites. We are able to validate\nresults from this model by measuring the influences exhibited by individual\nwords, and we are able to quantify the uncertainty in the scaling estimates by\nusing a sentence-level block bootstrap. Applying our method to the D\\'ail\ndebate, we are able to scale the legislators between extreme pro-government and\npro-opposition in a way that reveals nuances in their speeches not captured by\ntheir votes or party affiliations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 19:38:20 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Perry", "Patrick O.", ""], ["Benoit", "Kenneth", ""]]}, {"id": "1710.09016", "submitter": "Siddarth Srinivasan", "authors": "Siddarth Srinivasan, Geoff Gordon, Byron Boots", "title": "Learning Hidden Quantum Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Quantum Markov Models (HQMMs) can be thought of as quantum\nprobabilistic graphical models that can model sequential data. We extend\nprevious work on HQMMs with three contributions: (1) we show how classical\nhidden Markov models (HMMs) can be simulated on a quantum circuit, (2) we\nreformulate HQMMs by relaxing the constraints for modeling HMMs on quantum\ncircuits, and (3) we present a learning algorithm to estimate the parameters of\nan HQMM from data. While our algorithm requires further optimization to handle\nlarger datasets, we are able to evaluate our algorithm using several synthetic\ndatasets. We show that on HQMM generated data, our algorithm learns HQMMs with\nthe same number of hidden states and predictive accuracy as the true HQMMs,\nwhile HMMs learned with the Baum-Welch algorithm require more states to match\nthe predictive accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 23:14:23 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Srinivasan", "Siddarth", ""], ["Gordon", "Geoff", ""], ["Boots", "Byron", ""]]}, {"id": "1710.09026", "submitter": "Markus Kliegl", "authors": "Markus Kliegl, Siddharth Goyal, Kexin Zhao, Kavya Srinet, Mohammad\n  Shoeybi", "title": "Trace norm regularization and faster inference for embedded speech\n  recognition RNNs", "comments": "Our optimized inference kernels are available at:\n  https://github.com/PaddlePaddle/farm (Note: This paper was submitted to, but\n  rejected from, ICLR 2018. We believe it may still be of value to others.\n  Please see the discussion here: https://openreview.net/forum?id=B1tC-LT6W)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate new techniques for compressing and speeding up dense\nmatrix multiplications as found in the fully connected and recurrent layers of\nneural networks for embedded large vocabulary continuous speech recognition\n(LVCSR). For compression, we introduce and study a trace norm regularization\ntechnique for training low rank factored versions of matrix multiplications.\nCompared to standard low rank training, we show that our method leads to good\naccuracy versus number of parameter trade-offs and can be used to speed up\ntraining of large models. For speedup, we enable faster inference on ARM\nprocessors through new open sourced kernels optimized for small batch sizes,\nresulting in 3x to 7x speed ups over the widely used gemmlowp library. Beyond\nLVCSR, we expect our techniques and kernels to be more generally applicable to\nembedded neural networks with large fully connected or recurrent layers.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 00:20:55 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 10:00:10 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Kliegl", "Markus", ""], ["Goyal", "Siddharth", ""], ["Zhao", "Kexin", ""], ["Srinet", "Kavya", ""], ["Shoeybi", "Mohammad", ""]]}, {"id": "1710.09180", "submitter": "Muktabh Mayank Srivastava", "authors": "Srikrishna Varadarajan, Muktabh Mayank Srivastava, Monika Grewal,\n  Pulkit Kumar", "title": "Anatomical labeling of brain CT scan anomalies using multi-context\n  nearest neighbor relation networks", "comments": "Accepted as a one page abstract at IEEE International Symposium on\n  Biomedical Imaging (ISBI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work is an endeavor to develop a deep learning methodology for automated\nanatomical labeling of a given region of interest (ROI) in brain computed\ntomography (CT) scans. We combine both local and global context to obtain a\nrepresentation of the ROI. We then use Relation Networks (RNs) to predict the\ncorresponding anatomy of the ROI based on its relationship score for each\nclass. Further, we propose a novel strategy employing nearest neighbors\napproach for training RNs. We train RNs to learn the relationship of the target\nROI with the joint representation of its nearest neighbors in each class\ninstead of all data-points in each class. The proposed strategy leads to better\ntraining of RNs along with increased performance as compared to training\nbaseline RN network.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 11:42:36 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 14:48:26 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Varadarajan", "Srikrishna", ""], ["Srivastava", "Muktabh Mayank", ""], ["Grewal", "Monika", ""], ["Kumar", "Pulkit", ""]]}, {"id": "1710.09196", "submitter": "Eric Laloy", "authors": "Eric Laloy, Romain H\\'erault, John Lee, Diederik Jacques, Niklas Linde", "title": "Inversion using a new low-dimensional representation of complex binary\n  geological media based on a deep neural network", "comments": null, "journal-ref": "Advances in Water Resources (2017)", "doi": "10.1016/j.advwatres.2017.09.029", "report-no": null, "categories": "stat.ML physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and high-fidelity prior sampling and inversion for complex\ngeological media is still a largely unsolved challenge. Here, we use a deep\nneural network of the variational autoencoder type to construct a parametric\nlow-dimensional base model parameterization of complex binary geological media.\nFor inversion purposes, it has the attractive feature that random draws from an\nuncorrelated standard normal distribution yield model realizations with spatial\ncharacteristics that are in agreement with the training set. In comparison with\nthe most commonly used parametric representations in probabilistic inversion,\nwe find that our dimensionality reduction (DR) approach outperforms principle\ncomponent analysis (PCA), optimization-PCA (OPCA) and discrete cosine transform\n(DCT) DR techniques for unconditional geostatistical simulation of a\nchannelized prior model. For the considered examples, important compression\nratios (200 - 500) are achieved. Given that the construction of our\nparameterization requires a training set of several tens of thousands of prior\nmodel realizations, our DR approach is more suited for probabilistic (or\ndeterministic) inversion than for unconditional (or point-conditioned)\ngeostatistical simulation. Probabilistic inversions of 2D steady-state and 3D\ntransient hydraulic tomography data are used to demonstrate the DR-based\ninversion. For the 2D case study, the performance is superior compared to\ncurrent state-of-the-art multiple-point statistics inversion by sequential\ngeostatistical resampling (SGR). Inversion results for the 3D application are\nalso encouraging.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 12:40:18 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Laloy", "Eric", ""], ["H\u00e9rault", "Romain", ""], ["Lee", "John", ""], ["Jacques", "Diederik", ""], ["Linde", "Niklas", ""]]}, {"id": "1710.09207", "submitter": "Tolga Ergen", "authors": "Tolga Ergen, Ali Hassan Mirza, Suleyman Serdar Kozat", "title": "Unsupervised and Semi-supervised Anomaly Detection with LSTM Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2935975", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate anomaly detection in an unsupervised framework and introduce\nLong Short Term Memory (LSTM) neural network based algorithms. In particular,\ngiven variable length data sequences, we first pass these sequences through our\nLSTM based structure and obtain fixed length sequences. We then find a decision\nfunction for our anomaly detectors based on the One Class Support Vector\nMachines (OC-SVM) and Support Vector Data Description (SVDD) algorithms. As the\nfirst time in the literature, we jointly train and optimize the parameters of\nthe LSTM architecture and the OC-SVM (or SVDD) algorithm using highly effective\ngradient and quadratic programming based training methods. To apply the\ngradient based training method, we modify the original objective criteria of\nthe OC-SVM and SVDD algorithms, where we prove the convergence of the modified\nobjective criteria to the original criteria. We also provide extensions of our\nunsupervised formulation to the semi-supervised and fully supervised\nframeworks. Thus, we obtain anomaly detection algorithms that can process\nvariable length data sequences while providing high performance, especially for\ntime series data. Our approach is generic so that we also apply this approach\nto the Gated Recurrent Unit (GRU) architecture by directly replacing our LSTM\nbased structure with the GRU based structure. In our experiments, we illustrate\nsignificant performance gains achieved by our algorithms with respect to the\nconventional methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 12:57:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ergen", "Tolga", ""], ["Mirza", "Ali Hassan", ""], ["Kozat", "Suleyman Serdar", ""]]}, {"id": "1710.09220", "submitter": "Anthony Bagnall Dr", "authors": "James Large, Jason Lines and Anthony Bagnall", "title": "The Heterogeneous Ensembles of Standard Classification Algorithms\n  (HESCA): the Whole is Greater than the Sum of its Parts", "comments": null, "journal-ref": "Data Min Knowl Disc 33, 1674-1709 (2019)", "doi": "10.1007/s10618-019-00638-y", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building classification models is an intrinsically practical exercise that\nrequires many design decisions prior to deployment. We aim to provide some\nguidance in this decision making process. Specifically, given a classification\nproblem with real valued attributes, we consider which classifier or family of\nclassifiers should one use. Strong contenders are tree based homogeneous\nensembles, support vector machines or deep neural networks. All three families\nof model could claim to be state-of-the-art, and yet it is not clear when one\nis preferable to the others. Our extensive experiments with over 200 data sets\nfrom two distinct archives demonstrate that, rather than choose a single family\nand expend computing resources on optimising that model, it is significantly\nbetter to build simpler versions of classifiers from each family and ensemble.\nWe show that the Heterogeneous Ensembles of Standard Classification Algorithms\n(HESCA), which ensembles based on error estimates formed on the train data, is\nsignificantly better (in terms of error, balanced error, negative log\nlikelihood and area under the ROC curve) than its individual components,\npicking the component that is best on train data, and a support vector machine\ntuned over 1089 different parameter configurations. We demonstrate HESCA+,\nwhich contains a deep neural network, a support vector machine and two decision\ntree forests, is significantly better than its components, picking the best\ncomponent, and HESCA. We analyse the results further and find that HESCA and\nHESCA+ are of particular value when the train set size is relatively small and\nthe problem has multiple classes. HESCA is a fast approach that is, on average,\nas good as state-of-the-art classifiers, whereas HESCA+ is significantly better\nthan average and represents a strong benchmark for future research.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 13:19:18 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Large", "James", ""], ["Lines", "Jason", ""], ["Bagnall", "Anthony", ""]]}, {"id": "1710.09230", "submitter": "Marco Loog", "authors": "Marco Loog", "title": "Supervised Classification: Quite a Brief Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original problem of supervised classification considers the task of\nautomatically assigning objects to their respective classes on the basis of\nnumerical measurements derived from these objects. Classifiers are the tools\nthat implement the actual functional mapping from these measurements---also\ncalled features or inputs---to the so-called class label---or output. The\nfields of pattern recognition and machine learning study ways of constructing\nsuch classifiers. The main idea behind supervised methods is that of learning\nfrom examples: given a number of example input-output relations, to what extent\ncan the general mapping be learned that takes any new and unseen feature vector\nto its correct class? This chapter provides a basic introduction to the\nunderlying ideas of how to come to a supervised classification problem. In\naddition, it provides an overview of some specific classification techniques,\ndelves into the issues of object representation and classifier evaluation, and\n(very) briefly covers some variations on the basic supervised classification\ntask that may also be of interest to the practitioner.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 13:42:40 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Loog", "Marco", ""]]}, {"id": "1710.09302", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Richard Baraniuk", "title": "Deep Neural Networks", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are universal function approximators providing\nstate-of- the-art solutions on wide range of applications. Common perceptual\ntasks such as speech recognition, image classification, and object tracking are\nnow commonly tackled via DNNs. Some fundamental problems remain: (1) the lack\nof a mathematical framework providing an explicit and interpretable\ninput-output formula for any topology, (2) quantification of DNNs stability\nregarding adversarial examples (i.e. modified inputs fooling DNN predictions\nwhilst undetectable to humans), (3) absence of generalization guarantees and\ncontrollable behaviors for ambiguous patterns, (4) leverage unlabeled data to\napply DNNs to domains where expert labeling is scarce as in the medical field.\nAnswering those points would provide theoretical perspectives for further\ndevelopments based on a common ground. Furthermore, DNNs are now deployed in\ntremendous societal applications, pushing the need to fill this theoretical gap\nto ensure control, reliability, and interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 15:23:01 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 20:32:56 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 21:49:49 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Balestriero", "Randall", ""], ["Baraniuk", "Richard", ""]]}, {"id": "1710.09363", "submitter": "Biswa Sengupta", "authors": "Alessandro Bay and Biswa Sengupta", "title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fisher information metric is an important foundation of information\ngeometry, wherein it allows us to approximate the local geometry of a\nprobability distribution. Recurrent neural networks such as the\nSequence-to-Sequence (Seq2Seq) networks that have lately been used to yield\nstate-of-the-art performance on speech translation or image captioning have so\nfar ignored the geometry of the latent embedding, that they iteratively learn.\nWe propose the information geometric Seq2Seq (GeoSeq2Seq) network which\nabridges the gap between deep recurrent neural networks and information\ngeometry. Specifically, the latent embedding offered by a recurrent network is\nencoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism\ncommon in computer vision. We utilise such a network to predict the shortest\nroutes between two nodes of a graph by learning the adjacency matrix using the\nGeoSeq2Seq formalism; our results show that for such a problem the\nprobabilistic representation of the latent embedding supersedes the\nnon-probabilistic embedding by 10-15\\%.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 17:52:14 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 20:08:06 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Bay", "Alessandro", ""], ["Sengupta", "Biswa", ""]]}, {"id": "1710.09412", "submitter": "Hongyi Zhang", "authors": "Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz", "title": "mixup: Beyond Empirical Risk Minimization", "comments": "ICLR camera ready version. Changes vs V1: fix repo URL; add ablation\n  studies; add mixup + dropout etc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large deep neural networks are powerful, but exhibit undesirable behaviors\nsuch as memorization and sensitivity to adversarial examples. In this work, we\npropose mixup, a simple learning principle to alleviate these issues. In\nessence, mixup trains a neural network on convex combinations of pairs of\nexamples and their labels. By doing so, mixup regularizes the neural network to\nfavor simple linear behavior in-between training examples. Our experiments on\nthe ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show\nthat mixup improves the generalization of state-of-the-art neural network\narchitectures. We also find that mixup reduces the memorization of corrupt\nlabels, increases the robustness to adversarial examples, and stabilizes the\ntraining of generative adversarial networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 18:30:49 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 21:39:25 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Zhang", "Hongyi", ""], ["Cisse", "Moustapha", ""], ["Dauphin", "Yann N.", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1710.09429", "submitter": "Gang Wang", "authors": "Gang Wang and Jia Chen and Georgios B. Giannakis", "title": "DPCA: Dimensionality Reduction for Discriminative Analytics of Multiple\n  Large-Scale Datasets", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) has well-documented merits for data\nextraction and dimensionality reduction. PCA deals with a single dataset at a\ntime, and it is challenged when it comes to analyzing multiple datasets. Yet in\ncertain setups, one wishes to extract the most significant information of one\ndataset relative to other datasets. Specifically, the interest may be on\nidentifying, namely extracting features that are specific to a single target\ndataset but not the others. This paper develops a novel approach for such\nso-termed discriminative data analysis, and establishes its optimality in the\nleast-squares (LS) sense under suitable data modeling assumptions. The\ncriterion reveals linear combinations of variables by maximizing the ratio of\nthe variance of the target data to that of the remainders. The novel approach\nsolves a generalized eigenvalue problem by performing SVD just once. Numerical\ntests using synthetic and real datasets showcase the merits of the proposed\napproach relative to its competing alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 19:24:37 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Wang", "Gang", ""], ["Chen", "Jia", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1710.09430", "submitter": "Venkata Krishna Pillutla", "authors": "Prateek Jain, Sham M. Kakade, Rahul Kidambi, Praneeth Netrapalli,\n  Venkata Krishna Pillutla, Aaron Sidford", "title": "A Markov Chain Theory Approach to Characterizing the Minimax Optimality\n  of Stochastic Gradient Descent (for Least Squares)", "comments": "Lemma 1 has been updated in v2", "journal-ref": null, "doi": "10.4230/LIPIcs.FSTTCS.2017.2", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides a simplified proof of the statistical minimax optimality\nof (iterate averaged) stochastic gradient descent (SGD), for the special case\nof least squares. This result is obtained by analyzing SGD as a stochastic\nprocess and by sharply characterizing the stationary covariance matrix of this\nprocess. The finite rate optimality characterization captures the constant\nfactors and addresses model mis-specification.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 19:28:13 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2018 21:13:33 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Jain", "Prateek", ""], ["Kakade", "Sham M.", ""], ["Kidambi", "Rahul", ""], ["Netrapalli", "Praneeth", ""], ["Pillutla", "Venkata Krishna", ""], ["Sidford", "Aaron", ""]]}, {"id": "1710.09435", "submitter": "Edward Raff", "authors": "Edward Raff, Jon Barker, Jared Sylvester, Robert Brandon, Bryan\n  Catanzaro, Charles Nicholas", "title": "Malware Detection by Eating a Whole EXE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce malware detection from raw byte sequences as a\nfruitful research area to the larger machine learning community. Building a\nneural network for such a problem presents a number of interesting challenges\nthat have not occurred in tasks such as image processing or NLP. In particular,\nwe note that detection from raw bytes presents a sequence problem with over two\nmillion time steps and a problem where batch normalization appear to hinder the\nlearning process. We present our initial work in building a solution to tackle\nthis problem, which has linear complexity dependence on the sequence length,\nand allows for interpretable sub-regions of the binary to be identified. In\ndoing so we will discuss the many challenges in building a neural network to\nprocess data at this scale, and the methods we used to work around them.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 19:48:54 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Raff", "Edward", ""], ["Barker", "Jon", ""], ["Sylvester", "Jared", ""], ["Brandon", "Robert", ""], ["Catanzaro", "Bryan", ""], ["Nicholas", "Charles", ""]]}, {"id": "1710.09443", "submitter": "Arya Pourzanjani", "authors": "Arya A Pourzanjani, Richard M Jiang, Brian Mitchell, Paul J Atzberger,\n  Linda R Petzold", "title": "Bayesian Inference over the Stiefel Manifold via the Givens\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach based on the Givens representation for posterior\ninference in statistical models with orthogonal matrix parameters, such as\nfactor models and probabilistic principal component analysis (PPCA). We show\nhow the Givens representation can be used to develop practical methods for\ntransforming densities over the Stiefel manifold into densities over subsets of\nEuclidean space. We show how to deal with issues arising from the topology of\nthe Stiefel manifold and how to inexpensively compute the change-of-measure\nterms. We introduce an auxiliary parameter approach that limits the impact of\ntopological issues. We provide both analysis of our methods and numerical\nexamples demonstrating the effectiveness of the approach. We also discuss how\nour Givens representation can be used to define general classes of\ndistributions over the space of orthogonal matrices. We then give\ndemonstrations on several examples showing how the Givens approach performs in\npractice in comparison with other methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 20:14:10 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 17:22:03 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 01:13:15 GMT"}, {"version": "v4", "created": "Sat, 2 Nov 2019 21:04:58 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Pourzanjani", "Arya A", ""], ["Jiang", "Richard M", ""], ["Mitchell", "Brian", ""], ["Atzberger", "Paul J", ""], ["Petzold", "Linda R", ""]]}, {"id": "1710.09447", "submitter": "Tianbao Yang", "authors": "Mingrui Liu, Tianbao Yang", "title": "Stochastic Non-convex Optimization with Strong High Probability\n  Second-order Convergence", "comments": "This short paper will appear at NIPS 2017 Optimization of Machine\n  Learning Workshop. Partial results are presented in arXiv:1709.08571. The\n  second version corrects a statement regarding previous work", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study stochastic non-convex optimization with non-convex\nrandom functions. Recent studies on non-convex optimization revolve around\nestablishing second-order convergence, i.e., converging to a nearly\nsecond-order optimal stationary points. However, existing results on stochastic\nnon-convex optimization are limited, especially with a high probability\nsecond-order convergence. We propose a novel updating step (named NCG-S) by\nleveraging a stochastic gradient and a noisy negative curvature of a stochastic\nHessian, where the stochastic gradient and Hessian are based on a proper\nmini-batch of random functions. Building on this step, we develop two\nalgorithms and establish their high probability second-order convergence. To\nthe best of our knowledge, the proposed stochastic algorithms are the first\nwith a second-order convergence in {\\it high probability} and a time complexity\nthat is {\\it almost linear} in the problem's dimensionality.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 20:26:33 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 04:56:31 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Liu", "Mingrui", ""], ["Yang", "Tianbao", ""]]}, {"id": "1710.09471", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Ryan A. Rossi, Rong Zhou, John Boaz Lee, Xiangnan\n  Kong, Theodore L. Willke and Hoda Eldardiry", "title": "Inductive Representation Learning in Large Attributed Graphs", "comments": "NIPS WiML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs (networks) are ubiquitous and allow us to model entities (nodes) and\nthe dependencies (edges) between them. Learning a useful feature representation\nfrom graph data lies at the heart and success of many machine learning tasks\nsuch as classification, anomaly detection, link prediction, among many others.\nMany existing techniques use random walks as a basis for learning features or\nestimating the parameters of a graph model for a downstream prediction task.\nExamples include recent node embedding methods such as DeepWalk, node2vec, as\nwell as graph-based deep learning algorithms. However, the simple random walk\nused by these methods is fundamentally tied to the identity of the node. This\nhas three main disadvantages. First, these approaches are inherently\ntransductive and do not generalize to unseen nodes and other graphs. Second,\nthey are not space-efficient as a feature vector is learned for each node which\nis impractical for large graphs. Third, most of these approaches lack support\nfor attributed graphs.\n  To make these methods more generally applicable, we propose a framework for\ninductive network representation learning based on the notion of attributed\nrandom walk that is not tied to node identity and is instead based on learning\na function $\\Phi : \\mathrm{\\rm \\bf x} \\rightarrow w$ that maps a node attribute\nvector $\\mathrm{\\rm \\bf x}$ to a type $w$. This framework serves as a basis for\ngeneralizing existing methods such as DeepWalk, node2vec, and many other\nprevious methods that leverage traditional random walks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 21:40:57 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 23:51:39 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Rossi", "Ryan A.", ""], ["Zhou", "Rong", ""], ["Lee", "John Boaz", ""], ["Kong", "Xiangnan", ""], ["Willke", "Theodore L.", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "1710.09508", "submitter": "Scott Linderman", "authors": "Scott W. Linderman, Gonzalo E. Mena, Hal Cooper, Liam Paninski, and\n  John P. Cunningham", "title": "Reparameterizing the Birkhoff Polytope for Variational Permutation\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many matching, tracking, sorting, and ranking problems require probabilistic\nreasoning about possible permutations, a set that grows factorially with\ndimension. Combinatorial optimization algorithms may enable efficient point\nestimation, but fully Bayesian inference poses a severe challenge in this\nhigh-dimensional, discrete space. To surmount this challenge, we start with the\nusual step of relaxing a discrete set (here, of permutation matrices) to its\nconvex hull, which here is the Birkhoff polytope: the set of all\ndoubly-stochastic matrices. We then introduce two novel transformations: first,\nan invertible and differentiable stick-breaking procedure that maps\nunconstrained space to the Birkhoff polytope; second, a map that rounds points\ntoward the vertices of the polytope. Both transformations include a temperature\nparameter that, in the limit, concentrates the densities on permutation\nmatrices. We then exploit these transformations and reparameterization\ngradients to introduce variational inference over permutation matrices, and we\ndemonstrate its utility in a series of experiments.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 01:45:52 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Linderman", "Scott W.", ""], ["Mena", "Gonzalo E.", ""], ["Cooper", "Hal", ""], ["Paninski", "Liam", ""], ["Cunningham", "John P.", ""]]}, {"id": "1710.09511", "submitter": "Shane Barratt", "authors": "Shane Barratt", "title": "InterpNET: Neural Introspection for Interpretable Deep Learning", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to explain their reasoning. On the contrary, deep neural\nnetworks are not. This paper attempts to bridge this gap by introducing a new\nway to design interpretable neural networks for classification, inspired by\nphysiological evidence of the human visual system's inner-workings. This paper\nproposes a neural network design paradigm, termed InterpNET, which can be\ncombined with any existing classification architecture to generate natural\nlanguage explanations of the classifications. The success of the module relies\non the assumption that the network's computation and reasoning is represented\nin its internal layer activations. While in principle InterpNET could be\napplied to any existing classification architecture, it is evaluated via an\nimage classification and explanation task. Experiments on a CUB bird\nclassification and explanation dataset show qualitatively and quantitatively\nthat the model is able to generate high-quality explanations. While the current\nstate-of-the-art METEOR score on this dataset is 29.2, InterpNET achieves a\nmuch higher METEOR score of 37.9.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 02:01:12 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 21:25:25 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Barratt", "Shane", ""]]}, {"id": "1710.09513", "submitter": "Qianxiao Li", "authors": "Qianxiao Li, Long Chen, Cheng Tai, Weinan E", "title": "Maximum Principle Based Algorithms for Deep Learning", "comments": "Published version", "journal-ref": "Journal of Machine Learning Research 18 (2018) 1-29", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous dynamical system approach to deep learning is explored in\norder to devise alternative frameworks for training algorithms. Training is\nrecast as a control problem and this allows us to formulate necessary\noptimality conditions in continuous time using the Pontryagin's maximum\nprinciple (PMP). A modification of the method of successive approximations is\nthen used to solve the PMP, giving rise to an alternative training algorithm\nfor deep learning. This approach has the advantage that rigorous error\nestimates and convergence results can be established. We also show that it may\navoid some pitfalls of gradient-based methods, such as slow convergence on flat\nlandscapes near saddle points. Furthermore, we demonstrate that it obtains\nfavorable initial convergence rate per-iteration, provided Hamiltonian\nmaximization can be efficiently carried out - a step which is still in need of\nimprovement. Overall, the approach opens up new avenues to attack problems\nassociated with deep learning, such as trapping in slow manifolds and\ninapplicability of gradient-based methods for discrete trainable variables.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 02:04:33 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 01:17:39 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 12:55:37 GMT"}, {"version": "v4", "created": "Sat, 2 Jun 2018 08:50:02 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Li", "Qianxiao", ""], ["Chen", "Long", ""], ["Tai", "Cheng", ""], ["E", "Weinan", ""]]}, {"id": "1710.09522", "submitter": "Jingwei Lu", "authors": "Jingwei Lu, David G. Politte, Joseph A. O'Sullivan", "title": "Laplacian Prior Variational Automatic Relevance Determination for\n  Transmission Tomography", "comments": "5 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic sparsity-driven problems, the fundamental L-1 penalty method\nhas been shown to have good performance in reconstructing signals for a wide\nrange of problems. However this performance relies on a good choice of penalty\nweight which is often found from empirical experiments. We propose an algorithm\ncalled the Laplacian variational automatic relevance determination (Lap-VARD)\nthat takes this penalty weight as a parameter of a prior Laplace distribution.\nOptimization of this parameter using an automatic relevance determination\nframework results in a balance between the sparsity and accuracy of signal\nreconstruction. Our algorithm is implemented in a transmission tomography model\nwith sparsity constraint in wavelet domain.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 03:31:41 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Lu", "Jingwei", ""], ["Politte", "David G.", ""], ["O'Sullivan", "Joseph A.", ""]]}, {"id": "1710.09537", "submitter": "Li Jing", "authors": "Rumen Dangovski and Li Jing and Marin Soljacic", "title": "Rotational Unit of Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concepts of unitary evolution matrices and associative memory have\nboosted the field of Recurrent Neural Networks (RNN) to state-of-the-art\nperformance in a variety of sequential tasks. However, RNN still have a limited\ncapacity to manipulate long-term memory. To bypass this weakness the most\nsuccessful applications of RNN use external techniques such as attention\nmechanisms. In this paper we propose a novel RNN model that unifies the\nstate-of-the-art approaches: Rotational Unit of Memory (RUM). The core of RUM\nis its rotational operation, which is, naturally, a unitary matrix, providing\narchitectures with the power to learn long-term dependencies by overcoming the\nvanishing and exploding gradients problem. Moreover, the rotational unit also\nserves as associative memory. We evaluate our model on synthetic memorization,\nquestion answering and language modeling tasks. RUM learns the Copying Memory\ntask completely and improves the state-of-the-art result in the Recall task.\nRUM's performance in the bAbI Question Answering task is comparable to that of\nmodels with attention mechanism. We also improve the state-of-the-art result to\n1.189 bits-per-character (BPC) loss in the Character Level Penn Treebank (PTB)\ntask, which is to signify the applications of RUM to real-world sequential\ndata. The universality of our construction, at the core of RNN, establishes RUM\nas a promising approach to language modeling, speech recognition and machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 04:36:35 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Dangovski", "Rumen", ""], ["Jing", "Li", ""], ["Soljacic", "Marin", ""]]}, {"id": "1710.09553", "submitter": "Michael Mahoney", "authors": "Charles H. Martin and Michael W. Mahoney", "title": "Rethinking generalization requires revisiting old ideas: statistical\n  mechanics approaches and complex learning behavior", "comments": "31 pages; added brief discussion of recent papers that use/extend\n  these ideas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach to understand the peculiar and counterintuitive\ngeneralization properties of deep neural networks. The approach involves going\nbeyond worst-case theoretical capacity control frameworks that have been\npopular in machine learning in recent years to revisit old ideas in the\nstatistical mechanics of neural networks. Within this approach, we present a\nprototypical Very Simple Deep Learning (VSDL) model, whose behavior is\ncontrolled by two control parameters, one describing an effective amount of\ndata, or load, on the network (that decreases when noise is added to the\ninput), and one with an effective temperature interpretation (that increases\nwhen algorithms are early stopped). Using this model, we describe how a very\nsimple application of ideas from the statistical mechanics theory of\ngeneralization provides a strong qualitative description of recently-observed\nempirical results regarding the inability of deep neural networks not to\noverfit training data, discontinuous learning and sharp transitions in the\ngeneralization properties of learning algorithms, etc.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 06:08:39 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 05:57:09 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Martin", "Charles H.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1710.09554", "submitter": "Liu Liu", "authors": "Liu Liu, Ji Liu and Dacheng Tao", "title": "Duality-free Methods for Stochastic Composition Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the composition optimization with two expected-value functions in\nthe form of $\\frac{1}{n}\\sum\\nolimits_{i = 1}^n F_i(\\frac{1}{m}\\sum\\nolimits_{j\n= 1}^m G_j(x))+R(x)$, { which formulates many important problems in statistical\nlearning and machine learning such as solving Bellman equations in\nreinforcement learning and nonlinear embedding}. Full Gradient or classical\nstochastic gradient descent based optimization algorithms are unsuitable or\ncomputationally expensive to solve this problem due to the inner expectation\n$\\frac{1}{m}\\sum\\nolimits_{j = 1}^m G_j(x)$. We propose a duality-free based\nstochastic composition method that combines variance reduction methods to\naddress the stochastic composition problem. We apply SVRG and SAGA based\nmethods to estimate the inner function, and duality-free method to estimate the\nouter function. We prove the linear convergence rate not only for the convex\ncomposition problem, but also for the case that the individual outer functions\nare non-convex while the objective function is strongly-convex. We also provide\nthe results of experiments that show the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 06:10:44 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Liu", "Liu", ""], ["Liu", "Ji", ""], ["Tao", "Dacheng", ""]]}, {"id": "1710.09567", "submitter": "Rajiv Sambasivan", "authors": "Rajiv Sambasivan, Sourish Das", "title": "Big Data Classification Using Augmented Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for classification tasks on big data. Experiments\nconducted as part of this study indicate that the algorithm can be as accurate\nas ensemble methods such as random forests or gradient boosted trees. Unlike\nensemble methods, the models produced by the algorithm can be easily\ninterpreted. The algorithm is based on a divide and conquer strategy and\nconsists of two steps. The first step consists of using a decision tree to\nsegment the large dataset. By construction, decision trees attempt to create\nhomogeneous class distributions in their leaf nodes. However, non-homogeneous\nleaf nodes are usually produced. The second step of the algorithm consists of\nusing a suitable classifier to determine the class labels for the\nnon-homogeneous leaf nodes. The decision tree segment provides a coarse segment\nprofile while the leaf level classifier can provide information about the\nattributes that affect the label within a segment.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 07:33:40 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Sambasivan", "Rajiv", ""], ["Das", "Sourish", ""]]}, {"id": "1710.09574", "submitter": "Takashi Shinozaki", "authors": "Takashi Shinozaki", "title": "Biologically Inspired Feedforward Supervised Learning for Deep\n  Self-Organizing Map Networks", "comments": "Presented at MLINI-2016 workshop, 2016 (arXiv:1701.01437)", "journal-ref": null, "doi": null, "report-no": "MLINI/2016/05", "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a novel deep neural network and its supervised\nlearning method that uses a feedforward supervisory signal. The method is\ninspired by the human visual system and performs human-like association-based\nlearning without any backward error propagation. The feedforward supervisory\nsignal that produces the correct result is preceded by the target signal and\nassociates its confirmed label with the classification result of the target\nsignal. It effectively uses a large amount of information from the feedforward\nsignal, and forms a continuous and rich learning representation. The method is\nvalidated using visual recognition tasks on the MNIST handwritten dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 07:56:16 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Shinozaki", "Takashi", ""]]}, {"id": "1710.09599", "submitter": "Sami Abu-El-Haija", "authors": "Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou, Alex Alemi", "title": "Watch Your Step: Learning Node Embeddings via Graph Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph embedding methods represent nodes in a continuous vector space,\npreserving information from the graph (e.g. by sampling random walks). There\nare many hyper-parameters to these methods (such as random walk length) which\nhave to be manually tuned for every graph. In this paper, we replace random\nwalk hyper-parameters with trainable parameters that we automatically learn via\nbackpropagation. In particular, we learn a novel attention model on the power\nseries of the transition matrix, which guides the random walk to optimize an\nupstream objective. Unlike previous approaches to attention models, the method\nthat we propose utilizes attention parameters exclusively on the data (e.g. on\nthe random walk), and not used by the model for inference. We experiment on\nlink prediction tasks, as we aim to produce embeddings that best-preserve the\ngraph structure, generalizing to unseen information. We improve\nstate-of-the-art on a comprehensive suite of real world datasets including\nsocial, collaboration, and biological networks. Adding attention to random\nwalks can reduce the error by 20% to 45% on datasets we attempted. Further, our\nlearned attention parameters are different for every graph, and our\nautomatically-found values agree with the optimal choice of hyper-parameter if\nwe manually tune existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 09:10:01 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 16:34:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Abu-El-Haija", "Sami", ""], ["Perozzi", "Bryan", ""], ["Al-Rfou", "Rami", ""], ["Alemi", "Alex", ""]]}, {"id": "1710.09657", "submitter": "Alireza Ahrabian", "authors": "Alireza Ahrabian and Shirin Enshaeifar and Clive Cheong-Took and Payam\n  Barnaghi", "title": "Segment Parameter Labelling in MCMC Mean-Shift Change Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of segmentation in time series data with\nrespect to a statistical parameter of interest in Bayesian models. It is common\nto assume that the parameters are distinct within each segment. As such, many\nBayesian change point detection models do not exploit the segment parameter\npatterns, which can improve performance. This work proposes a Bayesian\nmean-shift change point detection algorithm that makes use of repetition in\nsegment parameters, by introducing segment class labels that utilise a\nDirichlet process prior. The performance of the proposed approach was assessed\non both synthetic and real world data, highlighting the enhanced performance\nwhen using parameter labelling.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 12:02:45 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Ahrabian", "Alireza", ""], ["Enshaeifar", "Shirin", ""], ["Cheong-Took", "Clive", ""], ["Barnaghi", "Payam", ""]]}, {"id": "1710.09668", "submitter": "Bin Dong Dr.", "authors": "Zichao Long, Yiping Lu, Xianzhong Ma, Bin Dong", "title": "PDE-Net: Learning PDEs from Data", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an initial attempt to learn evolution PDEs from\ndata. Inspired by the latest development of neural network designs in deep\nlearning, we propose a new feed-forward deep network, called PDE-Net, to\nfulfill two objectives at the same time: to accurately predict dynamics of\ncomplex systems and to uncover the underlying hidden PDE models. The basic idea\nof the proposed PDE-Net is to learn differential operators by learning\nconvolution kernels (filters), and apply neural networks or other machine\nlearning methods to approximate the unknown nonlinear responses. Comparing with\nexisting approaches, which either assume the form of the nonlinear response is\nknown or fix certain finite difference approximations of differential\noperators, our approach has the most flexibility by learning both differential\noperators and the nonlinear responses. A special feature of the proposed\nPDE-Net is that all filters are properly constrained, which enables us to\neasily identify the governing PDE models while still maintaining the expressive\nand predictive power of the network. These constrains are carefully designed by\nfully exploiting the relation between the orders of differential operators and\nthe orders of sum rules of filters (an important concept originated from\nwavelet theory). We also discuss relations of the PDE-Net with some existing\nnetworks in computer vision such as Network-In-Network (NIN) and Residual\nNeural Network (ResNet). Numerical experiments show that the PDE-Net has the\npotential to uncover the hidden PDE of the observed dynamics, and predict the\ndynamical behavior for a relatively long time, even in a noisy environment.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 12:50:45 GMT"}, {"version": "v2", "created": "Mon, 1 Jan 2018 07:22:36 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Long", "Zichao", ""], ["Lu", "Yiping", ""], ["Ma", "Xianzhong", ""], ["Dong", "Bin", ""]]}, {"id": "1710.09710", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Marek Kurzynski", "title": "Weighting Scheme for a Pairwise Multi-label Classifier Based on the\n  Fuzzy Confusion Matrix", "comments": "arXiv admin note: substantial text overlap with arXiv:1710.08729", "journal-ref": null, "doi": "10.1016/j.patrec.2018.01.012", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we addressed the issue of applying a stochastic classifier and a\nlocal, fuzzy confusion matrix under the framework of multi-label\nclassification. We proposed a novel solution to the problem of correcting label\npairwise ensembles. The main step of the correction procedure is to compute\nclassifier-specific competence and cross-competence measures, which estimates\nerror pattern of the underlying classifier. At the fusion phase we employed two\nweighting approaches based on information theory. The classifier weights\npromote base classifiers which are the most susceptible to the correction based\non the fuzzy confusion matrix. During the experimental study, the proposed\napproach was compared against two reference methods. The comparison was made in\nterms of six different quality criteria. The conducted experiments reveals that\nthe proposed approach eliminates one of main drawbacks of the original\nFCM-based approach i.e. the original approach is vulnerable to the imbalanced\nclass/label distribution. What is more, the obtained results shows that the\nintroduced method achieves satisfying classification quality under all\nconsidered quality criteria. Additionally, the impact of fluctuations of data\nset characteristics is reduced.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 02:30:39 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 07:47:27 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Trajdos", "Pawel", ""], ["Kurzynski", "Marek", ""]]}, {"id": "1710.09768", "submitter": "Cencheng Shen", "authors": "Cencheng Shen and Carey E. Priebe and Joshua T. Vogelstein", "title": "From Distance Correlation to Multiscale Graph Correlation", "comments": "39 pages + Appendix 22 pages, 6 figures", "journal-ref": "Journal of the American Statistical Association, vol.115(529), pp\n  280-291, 2020", "doi": "10.1080/01621459.2018.1543125", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and developing a correlation measure that can detect general\ndependencies is not only imperative to statistics and machine learning, but\nalso crucial to general scientific discovery in the big data age. In this\npaper, we establish a new framework that generalizes distance correlation --- a\ncorrelation measure that was recently proposed and shown to be universally\nconsistent for dependence testing against all joint distributions of finite\nmoments --- to the Multiscale Graph Correlation (MGC). By utilizing the\ncharacteristic functions and incorporating the nearest neighbor machinery, we\nformalize the population version of local distance correlations, define the\noptimal scale in a given dependency, and name the optimal local correlation as\nMGC. The new theoretical framework motivates a theoretically sound Sample MGC\nand allows a number of desirable properties to be proved, including the\nuniversal consistency, convergence and almost unbiasedness of the sample\nversion. The advantages of MGC are illustrated via a comprehensive set of\nsimulations with linear, nonlinear, univariate, multivariate, and noisy\ndependencies, where it loses almost no power in monotone dependencies while\nachieving better performance in general dependencies, compared to distance\ncorrelation and other popular methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 15:47:17 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 00:15:26 GMT"}, {"version": "v3", "created": "Sun, 30 Sep 2018 14:04:59 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Shen", "Cencheng", ""], ["Priebe", "Carey E.", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1710.09787", "submitter": "Danny Barash", "authors": "Danny Barash and Matan Gavish", "title": "Optimal Shrinkage of Singular Values Under Random Data Contamination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A low rank matrix X has been contaminated by uniformly distributed noise,\nmissing values, outliers and corrupt entries. Reconstruction of X from the\nsingular values and singular vectors of the contaminated matrix Y is a key\nproblem in machine learning, computer vision and data science. In this paper we\nshow that common contamination models (including arbitrary combinations of\nuniform noise,missing values, outliers and corrupt entries) can be described\nefficiently using a single framework. We develop an asymptotically optimal\nalgorithm that estimates X by manipulation of the singular values of Y , which\napplies to any of the contamination models considered. Finally, we find an\nexplicit signal-to-noise cutoff, below which estimation of X from the singular\nvalue decomposition of Y must fail, in a well-defined sense.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:17:36 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 21:07:43 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Barash", "Danny", ""], ["Gavish", "Matan", ""]]}, {"id": "1710.09805", "submitter": "Weinan Zhang", "authors": "Long Chen, Fajie Yuan, Joemon M. Jose, Weinan Zhang", "title": "Improving Negative Sampling for Word Representation using Self-embedded\n  Features", "comments": "Accepted in WSDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although the word-popularity based negative sampler has shown superb\nperformance in the skip-gram model, the theoretical motivation behind\noversampling popular (non-observed) words as negative samples is still not well\nunderstood. In this paper, we start from an investigation of the gradient\nvanishing issue in the skipgram model without a proper negative sampler. By\nperforming an insightful analysis from the stochastic gradient descent (SGD)\nlearning perspective, we demonstrate that, both theoretically and intuitively,\nnegative samples with larger inner product scores are more informative than\nthose with lower scores for the SGD learner in terms of both convergence rate\nand accuracy. Understanding this, we propose an alternative sampling algorithm\nthat dynamically selects informative negative samples during each SGD update.\nMore importantly, the proposed sampler accounts for multi-dimensional\nself-embedded features during the sampling process, which essentially makes it\nmore effective than the original popularity-based (one-dimensional) sampler.\nEmpirical experiments further verify our observations, and show that our\nfine-grained samplers gain significant improvement over the existing ones\nwithout increasing computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:54:13 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 18:40:22 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 07:32:18 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Chen", "Long", ""], ["Yuan", "Fajie", ""], ["Jose", "Joemon M.", ""], ["Zhang", "Weinan", ""]]}, {"id": "1710.09809", "submitter": "Cedric Herzet", "authors": "C. Herzet and A. Dr\\'emeau", "title": "Joint Screening Tests for LASSO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper focusses on \"safe\" screening techniques for the LASSO problem.\nMotivated by the need for low-complexity algorithms, we propose a new approach,\ndubbed \"joint\" screening test, allowing to screen a set of atoms by carrying\nout one single test. The approach is particularized to two different sets of\natoms, respectively expressed as sphere and dome regions. After presenting the\nmathematical derivations of the tests, we elaborate on their relative\neffectiveness and discuss the practical use of such procedures.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 17:04:10 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 10:27:11 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Herzet", "C.", ""], ["Dr\u00e9meau", "A.", ""]]}, {"id": "1710.09825", "submitter": "Carlo Lucibello", "authors": "Carlo Baldassi, Federica Gerace, Hilbert J. Kappen, Carlo Lucibello,\n  Luca Saglietti, Enzo Tartaglione, Riccardo Zecchina", "title": "On the role of synaptic stochasticity in training low-precision neural\n  networks", "comments": "7 pages + 14 pages of supplementary material", "journal-ref": "Phys. Rev. Lett. 120, 268103 (2018)", "doi": "10.1103/PhysRevLett.120.268103", "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochasticity and limited precision of synaptic weights in neural network\nmodels are key aspects of both biological and hardware modeling of learning\nprocesses. Here we show that a neural network model with stochastic binary\nweights naturally gives prominence to exponentially rare dense regions of\nsolutions with a number of desirable properties such as robustness and good\ngeneralization performance, while typical solutions are isolated and hard to\nfind. Binary solutions of the standard perceptron problem are obtained from a\nsimple gradient descent procedure on a set of real values parametrizing a\nprobability distribution over the binary synapses. Both analytical and\nnumerical results are presented. An algorithmic extension aimed at training\ndiscrete deep neural networks is also investigated.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 17:42:23 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 03:17:32 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Baldassi", "Carlo", ""], ["Gerace", "Federica", ""], ["Kappen", "Hilbert J.", ""], ["Lucibello", "Carlo", ""], ["Saglietti", "Luca", ""], ["Tartaglione", "Enzo", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1710.09854", "submitter": "Jianqiao Wangni", "authors": "Jianqiao Wangni, Jialei Wang, Ji Liu, Tong Zhang", "title": "Gradient Sparsification for Communication-Efficient Distributed\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large scale machine learning applications require stochastic\noptimization algorithms to be implemented on distributed computational\narchitectures. A key bottleneck is the communication overhead for exchanging\ninformation such as stochastic gradients among different workers. In this\npaper, to reduce the communication cost we propose a convex optimization\nformulation to minimize the coding length of stochastic gradients. To solve the\noptimal sparsification efficiently, several simple and fast algorithms are\nproposed for approximate solution, with theoretical guaranteed for sparseness.\nExperiments on $\\ell_2$ regularized logistic regression, support vector\nmachines, and convolutional neural networks validate our sparsification\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 18:26:43 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Wangni", "Jianqiao", ""], ["Wang", "Jialei", ""], ["Liu", "Ji", ""], ["Zhang", "Tong", ""]]}, {"id": "1710.09859", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Maria L. Rizzo, Joshua T. Vogelstein", "title": "Kernel k-Groups via Hartigan's Method", "comments": "several improvements; connections with community detection and\n  stochastic block model. Matches published version", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2020", "doi": "10.1109/TPAMI.2020.2998120", "report-no": null, "categories": "stat.ML cs.CV cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy statistics was proposed by Sz\\' ekely in the 80's inspired by Newton's\ngravitational potential in classical mechanics and it provides a model-free\nhypothesis test for equality of distributions. In its original form, energy\nstatistics was formulated in Euclidean spaces. More recently, it was\ngeneralized to metric spaces of negative type. In this paper, we consider a\nformulation for the clustering problem using a weighted version of energy\nstatistics in spaces of negative type. We show that this approach leads to a\nquadratically constrained quadratic program in the associated kernel space,\nestablishing connections with graph partitioning problems and kernel methods in\nmachine learning. To find local solutions of such an optimization problem, we\npropose kernel k-groups, which is an extension of Hartigan's method to kernel\nspaces. Kernel k-groups is cheaper than spectral clustering and has the same\ncomputational cost as kernel k-means (which is based on Lloyd's heuristic) but\nour numerical results show an improved performance, especially in higher\ndimensions. Moreover, we verify the efficiency of kernel k-groups in community\ndetection in sparse stochastic block models which has fascinating applications\nin several areas of science.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 18:38:28 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 14:02:55 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 15:29:58 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 19:57:09 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Rizzo", "Maria L.", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1710.09953", "submitter": "Yu-Jun Li", "authors": "Jean Honorio, Yu-Jun Li", "title": "The Error Probability of Random Fourier Features is Dimensionality\n  Independent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the error probability of reconstructing kernel matrices from\nRandom Fourier Features for the Gaussian kernel function is at most\n$\\mathcal{O}(R^{2/3} \\exp(-D))$, where $D$ is the number of random features and\n$R$ is the diameter of the data domain. We also provide an\ninformation-theoretic method-independent lower bound of $\\Omega((1-\\exp(-R^2))\n\\exp(-D))$. Compared to prior work, we are the first to show that the error\nprobability for random Fourier features is independent of the dimensionality of\ndata points. As applications of our theory, we obtain dimension-independent\nbounds for kernel ridge regression and support vector machines.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 00:19:26 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 00:42:59 GMT"}, {"version": "v3", "created": "Sat, 14 Apr 2018 20:03:07 GMT"}, {"version": "v4", "created": "Fri, 18 May 2018 23:41:18 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Honorio", "Jean", ""], ["Li", "Yu-Jun", ""]]}, {"id": "1710.09979", "submitter": "Xiao-Bo Jin", "authors": "Xiao-Bo Jin, Xu-Yao Zhang, Kaizhu Huang and Guang-Gang Geng", "title": "Stochastic Conjugate Gradient Algorithm with Variance Reduction", "comments": "10 pages, 4 figures, appeared in IEEE TRANSACTIONS ON NEURAL NETWORKS\n  AND LEARNING SYSTEMS, CGVR algorithm is available on github:\n  https://github.com/xbjin/cgvr", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems,2018", "doi": "10.1109/TNNLS.2018.2868835", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conjugate gradient (CG) methods are a class of important methods for solving\nlinear equations and nonlinear optimization problems. In this paper, we propose\na new stochastic CG algorithm with variance reduction and we prove its linear\nconvergence with the Fletcher and Reeves method for strongly convex and smooth\nfunctions. We experimentally demonstrate that the CG with variance reduction\nalgorithm converges faster than its counterparts for four learning models,\nwhich may be convex, nonconvex or nonsmooth. In addition, its area under the\ncurve performance on six large-scale data sets is comparable to that of the\nLIBLINEAR solver for the L2-regularized L2-loss but with a significant\nimprovement in computational efficiency\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 03:47:41 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 11:33:01 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Jin", "Xiao-Bo", ""], ["Zhang", "Xu-Yao", ""], ["Huang", "Kaizhu", ""], ["Geng", "Guang-Gang", ""]]}, {"id": "1710.09997", "submitter": "Davood Hajinezhad", "authors": "Davood Hajinezhad, Mingyi Hong, Alfredo Garcia", "title": "Zeroth Order Nonconvex Multi-Agent Optimization over Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider distributed optimization problems over a\nmulti-agent network, where each agent can only partially evaluate the objective\nfunction, and it is allowed to exchange messages with its immediate neighbors.\nDifferently from all existing works on distributed optimization, our focus is\ngiven to optimizing a class of non-convex problems, and under the challenging\nsetting where each agent can only access the zeroth-order information (i.e.,\nthe functional values) of its local functions. For different types of network\ntopologies such as undirected connected networks or star networks, we develop\nefficient distributed algorithms and rigorously analyze their convergence and\nrate of convergence (to the set of stationary solutions). Numerical results are\nprovided to demonstrate the efficiency of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 06:15:40 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 14:09:28 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 04:17:57 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Hajinezhad", "Davood", ""], ["Hong", "Mingyi", ""], ["Garcia", "Alfredo", ""]]}, {"id": "1710.10006", "submitter": "Jong Chul Ye", "authors": "Yeo Hun Yoon and Jong Chul Ye", "title": "Deep Learning for Accelerated Ultrasound Imaging", "comments": "Invited paper for ICASSP 2018 Special Session for \"Machine Learning\n  in Medical Imaging: from Measurement to Diagnosis\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In portable, 3-D, or ultra-fast ultrasound (US) imaging systems, there is an\nincreasing demand to reconstruct high quality images from limited number of\ndata. However, the existing solutions require either hardware changes or\ncomputationally expansive algorithms. To overcome these limitations, here we\npropose a novel deep learning approach that interpolates the missing RF data by\nutilizing the sparsity of the RF data in the Fourier domain. Extensive\nexperimental results from sub-sampled RF data from a real US system confirmed\nthat the proposed method can effectively reduce the data rate without\nsacrificing the image quality.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 06:49:37 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Yoon", "Yeo Hun", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1710.10016", "submitter": "Soroosh Shafieezadeh-Abadeh", "authors": "Soroosh Shafieezadeh-Abadeh, Daniel Kuhn, Peyman Mohajerin Esfahani", "title": "Regularization via Mass Transportation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of regression and classification methods in supervised learning is\nto minimize the empirical risk, that is, the expectation of some loss function\nquantifying the prediction error under the empirical distribution. When facing\nscarce training data, overfitting is typically mitigated by adding\nregularization terms to the objective that penalize hypothesis complexity. In\nthis paper we introduce new regularization techniques using ideas from\ndistributionally robust optimization, and we give new probabilistic\ninterpretations to existing techniques. Specifically, we propose to minimize\nthe worst-case expected loss, where the worst case is taken over the ball of\nall (continuous or discrete) distributions that have a bounded transportation\ndistance from the (discrete) empirical distribution. By choosing the radius of\nthis ball judiciously, we can guarantee that the worst-case expected loss\nprovides an upper confidence bound on the loss on test data, thus offering new\ngeneralization bounds. We prove that the resulting regularized learning\nproblems are tractable and can be tractably kernelized for many popular loss\nfunctions. We validate our theoretical out-of-sample guarantees through\nsimulated and empirical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 07:52:45 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 08:48:21 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 08:14:21 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Shafieezadeh-Abadeh", "Soroosh", ""], ["Kuhn", "Daniel", ""], ["Esfahani", "Peyman Mohajerin", ""]]}, {"id": "1710.10021", "submitter": "Andrey Y. Lokhov", "authors": "Andrey Y. Lokhov, Marc Vuffray, Dmitry Shemetov, Deepjyoti Deka,\n  Michael Chertkov", "title": "Online Learning of Power Transmission Dynamics", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY math.OC physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing the dynamic state matrix of\ntransmission power grids from time-stamped PMU measurements in the regime of\nambient fluctuations. Using a maximum likelihood based approach, we construct a\nfamily of convex estimators that adapt to the structure of the problem\ndepending on the available prior information. The proposed method is fully\ndata-driven and does not assume any knowledge of system parameters. It can be\nimplemented in near real-time and requires a small amount of data. Our learning\nalgorithms can be used for model validation and calibration, and can also be\napplied to related problems of system stability, detection of forced\noscillations, generation re-dispatch, as well as to the estimation of the\nsystem state.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 08:14:54 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Lokhov", "Andrey Y.", ""], ["Vuffray", "Marc", ""], ["Shemetov", "Dmitry", ""], ["Deka", "Deepjyoti", ""], ["Chertkov", "Michael", ""]]}, {"id": "1710.10036", "submitter": "Yuhang Song", "authors": "Yuhang Song, Main Xu, Songyang Zhang, Liangyu Huo", "title": "Generalization Tower Network: A Novel Deep Neural Network Architecture\n  for Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) advances state-of-the-art reinforcement learning (RL), by\nincorporating deep neural networks in learning representations from the input\nto RL. However, the conventional deep neural network architecture is limited in\nlearning representations for multi-task RL (MT-RL), as multiple tasks can refer\nto different kinds of representations. In this paper, we thus propose a novel\ndeep neural network architecture, namely generalization tower network (GTN),\nwhich can achieve MT-RL within a single learned model. Specifically, the\narchitecture of GTN is composed of both horizontal and vertical streams. In our\nGTN architecture, horizontal streams are used to learn representation shared in\nsimilar tasks. In contrast, the vertical streams are introduced to be more\nsuitable for handling diverse tasks, which encodes hierarchical shared\nknowledge of these tasks. The effectiveness of the introduced vertical stream\nis validated by experimental results. Experimental results further verify that\nour GTN architecture is able to advance the state-of-the-art MT-RL, via being\ntested on 51 Atari games.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 09:11:26 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 09:44:17 GMT"}, {"version": "v3", "created": "Tue, 2 Jan 2018 01:06:10 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Song", "Yuhang", ""], ["Xu", "Main", ""], ["Zhang", "Songyang", ""], ["Huo", "Liangyu", ""]]}, {"id": "1710.10044", "submitter": "Will Dabney", "authors": "Will Dabney, Mark Rowland, Marc G. Bellemare, R\\'emi Munos", "title": "Distributional Reinforcement Learning with Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning an agent interacts with the environment by taking\nactions and observing the next state and reward. When sampled\nprobabilistically, these state transitions, rewards, and actions can all induce\nrandomness in the observed long-term return. Traditionally, reinforcement\nlearning algorithms average over this randomness to estimate the value\nfunction. In this paper, we build on recent work advocating a distributional\napproach to reinforcement learning in which the distribution over returns is\nmodeled explicitly instead of only estimating the mean. That is, we examine\nmethods of learning the value distribution instead of the value function. We\ngive results that close a number of gaps between the theoretical and\nalgorithmic results given by Bellemare, Dabney, and Munos (2017). First, we\nextend existing results to the approximate distribution setting. Second, we\npresent a novel distributional reinforcement learning algorithm consistent with\nour theoretical formulation. Finally, we evaluate this new algorithm on the\nAtari 2600 games, observing that it significantly outperforms many of the\nrecent improvements on DQN, including the related distributional algorithm C51.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 09:35:26 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Dabney", "Will", ""], ["Rowland", "Mark", ""], ["Bellemare", "Marc G.", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1710.10121", "submitter": "Yiping Lu", "authors": "Yiping Lu, Aoxiao Zhong, Quanzheng Li, Bin Dong", "title": "Beyond Finite Layer Neural Networks: Bridging Deep Architectures and\n  Numerical Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our work, we bridge deep neural network design with numerical differential\nequations. We show that many effective networks, such as ResNet, PolyNet,\nFractalNet and RevNet, can be interpreted as different numerical\ndiscretizations of differential equations. This finding brings us a brand new\nperspective on the design of effective deep architectures. We can take\nadvantage of the rich knowledge in numerical analysis to guide us in designing\nnew and potentially more effective deep networks. As an example, we propose a\nlinear multi-step architecture (LM-architecture) which is inspired by the\nlinear multi-step method solving ordinary differential equations. The\nLM-architecture is an effective structure that can be used on any ResNet-like\nnetworks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the\nnetworks obtained by applying the LM-architecture on ResNet and ResNeXt\nrespectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on\nboth CIFAR and ImageNet with comparable numbers of trainable parameters. In\nparticular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly\ncompress ($>50$\\%) the original networks while maintaining a similar\nperformance. This can be explained mathematically using the concept of modified\nequation from numerical analysis. Last but not least, we also establish a\nconnection between stochastic control and noise injection in the training\nprocess which helps to improve generalization of the networks. Furthermore, by\nrelating stochastic training strategy with stochastic dynamic system, we can\neasily apply stochastic training to the networks with the LM-architecture. As\nan example, we introduced stochastic depth to LM-ResNet and achieve significant\nimprovement over the original LM-ResNet on CIFAR10.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 13:19:59 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 09:19:19 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 04:20:58 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Lu", "Yiping", ""], ["Zhong", "Aoxiao", ""], ["Li", "Quanzheng", ""], ["Dong", "Bin", ""]]}, {"id": "1710.10161", "submitter": "Joeseph Smith", "authors": "Joeseph P. Smith, Andrew D. Gronewold", "title": "Development and analysis of a Bayesian water balance model for large\n  lake systems", "comments": "Final version for ArXiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Water balance models (WBMs) are often employed to understand regional\nhydrologic cycles over various time scales. Most WBMs, however, are\nphysically-based, and few employ state-of-the-art statistical methods to\nreconcile independent input measurement uncertainty and bias. Further, few WBMs\nexist for large lakes, and most large lake WBMs perform additive accounting,\nwith minimal consideration towards input data uncertainty. Here, we introduce a\nframework for improving a previously developed large lake statistical water\nbalance model (L2SWBM). Focusing on the water balances of Lakes Superior and\nMichigan-Huron, we demonstrate our new analytical framework, identifying\nL2SWBMs from 26 alternatives that adequately close the water balance of the\nlakes with satisfactory computation times compared with the prototype model. We\nexpect our new framework will be used to develop water balance models for other\nlakes around the world.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 12:49:05 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 16:07:24 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2018 01:10:25 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 21:29:33 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Smith", "Joeseph P.", ""], ["Gronewold", "Andrew D.", ""]]}, {"id": "1710.10196", "submitter": "Samuli Laine", "authors": "Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen", "title": "Progressive Growing of GANs for Improved Quality, Stability, and\n  Variation", "comments": "Final ICLR 2018 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new training methodology for generative adversarial networks.\nThe key idea is to grow both the generator and discriminator progressively:\nstarting from a low resolution, we add new layers that model increasingly fine\ndetails as training progresses. This both speeds the training up and greatly\nstabilizes it, allowing us to produce images of unprecedented quality, e.g.,\nCelebA images at 1024^2. We also propose a simple way to increase the variation\nin generated images, and achieve a record inception score of 8.80 in\nunsupervised CIFAR10. Additionally, we describe several implementation details\nthat are important for discouraging unhealthy competition between the generator\nand discriminator. Finally, we suggest a new metric for evaluating GAN results,\nboth in terms of image quality and variation. As an additional contribution, we\nconstruct a higher-quality version of the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 15:28:35 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 14:39:27 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 15:33:34 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Karras", "Tero", ""], ["Aila", "Timo", ""], ["Laine", "Samuli", ""], ["Lehtinen", "Jaakko", ""]]}, {"id": "1710.10197", "submitter": "Fei Tao", "authors": "Fei Tao and Gang Liu", "title": "Advanced LSTM: A Study about Better Time Dependency Modeling in Emotion\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long short-term memory (LSTM) is normally used in recurrent neural network\n(RNN) as basic recurrent unit. However,conventional LSTM assumes that the state\nat current time step depends on previous time step. This assumption constraints\nthe time dependency modeling capability. In this study, we propose a new\nvariation of LSTM, advanced LSTM (A-LSTM), for better temporal context\nmodeling. We employ A-LSTM in weighted pooling RNN for emotion recognition. The\nA-LSTM outperforms the conventional LSTM by 5.5% relatively. The A-LSTM based\nweighted pooling RNN can also complement the state-of-the-art emotion\nclassification framework. This shows the advantage of A-LSTM.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 15:29:09 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Tao", "Fei", ""], ["Liu", "Gang", ""]]}, {"id": "1710.10210", "submitter": "Mihai Cucuringu", "authors": "Mihai Cucuringu, Hemant Tyagi", "title": "On denoising modulo 1 samples of a function", "comments": "19 pages, 13 figures. To appear in AISTATS 2018. Corrected typos, and\n  made minor stylistic changes throughout. Main results unchanged. Added\n  section I (and Figure 13) in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an unknown smooth function $f: [0,1] \\rightarrow \\mathbb{R}$, and\nsay we are given $n$ noisy$\\mod 1$ samples of $f$, i.e., $y_i = (f(x_i) +\n\\eta_i)\\mod 1$ for $x_i \\in [0,1]$, where $\\eta_i$ denotes noise. Given the\nsamples $(x_i,y_i)_{i=1}^{n}$ our goal is to recover smooth, robust estimates\nof the clean samples $f(x_i) \\bmod 1$. We formulate a natural approach for\nsolving this problem which works with representations of mod 1 values over the\nunit circle. This amounts to solving a quadratically constrained quadratic\nprogram (QCQP) with non-convex constraints involving points lying on the unit\ncircle. Our proposed approach is based on solving its relaxation which is a\ntrust-region sub-problem, and hence solvable efficiently. We demonstrate its\nrobustness to noise % of our approach via extensive simulations on several\nsynthetic examples, and provide a detailed theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 15:55:50 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 01:57:33 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 01:06:00 GMT"}, {"version": "v4", "created": "Mon, 2 Apr 2018 17:03:14 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Tyagi", "Hemant", ""]]}, {"id": "1710.10230", "submitter": "Cyril Zhang", "authors": "Brian Bullins, Cyril Zhang, Yi Zhang", "title": "Not-So-Random Features", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a principled method for kernel learning, which relies on a\nFourier-analytic characterization of translation-invariant or\nrotation-invariant kernels. Our method produces a sequence of feature maps,\niteratively refining the SVM margin. We provide rigorous guarantees for\noptimality and generalization, interpreting our algorithm as online\nequilibrium-finding dynamics in a certain two-player min-max game. Evaluations\non synthetic and real-world datasets demonstrate scalability and consistent\nimprovements over related random features-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 16:28:06 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 00:50:27 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Bullins", "Brian", ""], ["Zhang", "Cyril", ""], ["Zhang", "Yi", ""]]}, {"id": "1710.10248", "submitter": "Vasily Pestun", "authors": "Vasily Pestun, Yiannis Vlassopoulos", "title": "Tensor network language model", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new statistical model suitable for machine learning of systems\nwith long distance correlations such as natural languages. The model is based\non directed acyclic graph decorated by multi-linear tensor maps in the vertices\nand vector spaces in the edges, called tensor network. Such tensor networks\nhave been previously employed for effective numerical computation of the\nrenormalization group flow on the space of effective quantum field theories and\nlattice models of statistical mechanics. We provide explicit algebro-geometric\nanalysis of the parameter moduli space for tree graphs, discuss model\nproperties and applications such as statistical translation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 17:26:57 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 16:03:48 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Pestun", "Vasily", ""], ["Vlassopoulos", "Yiannis", ""]]}, {"id": "1710.10280", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen, James L. McClelland", "title": "One-shot and few-shot learning of word embeddings", "comments": "15 pages, 7 figures, under review as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard deep learning systems require thousands or millions of examples to\nlearn a concept, and cannot integrate new concepts easily. By contrast, humans\nhave an incredible ability to do one-shot or few-shot learning. For instance,\nfrom just hearing a word used in a sentence, humans can infer a great deal\nabout it, by leveraging what the syntax and semantics of the surrounding words\ntells us. Here, we draw inspiration from this to highlight a simple technique\nby which deep recurrent networks can similarly exploit their prior knowledge to\nlearn a useful representation for a new word from little data. This could make\nnatural language processing systems much more flexible, by allowing them to\nlearn continually from the new words they encounter.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 18:05:22 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 16:53:05 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["McClelland", "James L.", ""]]}, {"id": "1710.10301", "submitter": "Corey Hudson", "authors": "Sapan Agarwal and Corey M. Hudson", "title": "Probability Series Expansion Classifier that is Interpretable by Design", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents a new classifier that is specifically designed to be fully\ninterpretable. This technique determines the probability of a class outcome,\nbased directly on probability assignments measured from the training data. The\naccuracy of the predicted probability can be improved by measuring more\nprobability estimates from the training data to create a series expansion that\nrefines the predicted probability. We use this work to classify four standard\ndatasets and achieve accuracies comparable to that of Random Forests. Because\nthis technique is interpretable by design, it is capable of determining the\ncombinations of features that contribute to a particular classification\nprobability for individual cases as well as the weightings of each of\ncombination of features.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 18:50:28 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Agarwal", "Sapan", ""], ["Hudson", "Corey M.", ""]]}, {"id": "1710.10313", "submitter": "Alan Do-Omri", "authors": "Alan Do-Omri, Dalei Wu and Xiaohua Liu", "title": "A Self-Training Method for Semi-Supervised GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the creation of Generative Adversarial Networks (GANs), much work has\nbeen done to improve their training stability, their generated image quality,\ntheir range of application but nearly none of them explored their self-training\npotential. Self-training has been used before the advent of deep learning in\norder to allow training on limited labelled training data and has shown\nimpressive results in semi-supervised learning. In this work, we combine these\ntwo ideas and make GANs self-trainable for semi-supervised learning tasks by\nexploiting their infinite data generation potential. Results show that using\neven the simplest form of self-training yields an improvement. We also show\nresults for a more complex self-training scheme that performs at least as well\nas the basic self-training scheme but with significantly less data\naugmentation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 19:43:21 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Do-Omri", "Alan", ""], ["Wu", "Dalei", ""], ["Liu", "Xiaohua", ""]]}, {"id": "1710.10321", "submitter": "Claire Donnat", "authors": "Claire Donnat, Marinka Zitnik, David Hallac, Jure Leskovec", "title": "Learning Structural Node Embeddings Via Diffusion Wavelets", "comments": "The 24th ACM SIGKDD International Conference on Knowledge Discovery &\n  Data Mining, August 19--23, 2018, London, United Kingdom", "journal-ref": null, "doi": "10.1145/3219819.3220025", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nodes residing in different parts of a graph can have similar structural\nroles within their local network topology. The identification of such roles\nprovides key insight into the organization of networks and can be used for a\nvariety of machine learning tasks. However, learning structural representations\nof nodes is a challenging problem, and it has typically involved manually\nspecifying and tailoring topological features for each node. In this paper, we\ndevelop GraphWave, a method that represents each node's network neighborhood\nvia a low-dimensional embedding by leveraging heat wavelet diffusion patterns.\nInstead of training on hand-selected features, GraphWave learns these\nembeddings in an unsupervised way. We mathematically prove that nodes with\nsimilar network neighborhoods will have similar GraphWave embeddings even\nthough these nodes may reside in very different parts of the network, and our\nmethod scales linearly with the number of edges. Experiments in a variety of\ndifferent settings demonstrate GraphWave's real-world potential for capturing\nstructural roles in networks, and our approach outperforms existing\nstate-of-the-art baselines in every experiment, by as much as 137%.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 20:07:38 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 16:33:36 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 05:18:36 GMT"}, {"version": "v4", "created": "Wed, 20 Jun 2018 17:05:35 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Donnat", "Claire", ""], ["Zitnik", "Marinka", ""], ["Hallac", "David", ""], ["Leskovec", "Jure", ""]]}, {"id": "1710.10328", "submitter": "Lixin Fan", "authors": "Lixin Fan", "title": "Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU\n  with Generalized Hamming Network", "comments": "10 pages, 5 figures, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit fuzzy neural network with a cornerstone notion of generalized\nhamming distance, which provides a novel and theoretically justified framework\nto re-interpret many useful neural network techniques in terms of fuzzy logic.\nIn particular, we conjecture and empirically illustrate that, the celebrated\nbatch normalization (BN) technique actually adapts the normalized bias such\nthat it approximates the rightful bias induced by the generalized hamming\ndistance. Once the due bias is enforced analytically, neither the optimization\nof bias terms nor the sophisticated batch normalization is needed. Also in the\nlight of generalized hamming distance, the popular rectified linear units\n(ReLU) can be treated as setting a minimal hamming distance threshold between\nnetwork inputs and weights. This thresholding scheme, on the one hand, can be\nimproved by introducing double thresholding on both extremes of neuron outputs.\nOn the other hand, ReLUs turn out to be non-essential and can be removed from\nnetworks trained for simple tasks like MNIST classification. The proposed\ngeneralized hamming network (GHN) as such not only lends itself to rigorous\nanalysis and interpretation within the fuzzy logic theory but also demonstrates\nfast learning speed, well-controlled behaviour and state-of-the-art\nperformances on a variety of learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 20:48:57 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Fan", "Lixin", ""]]}, {"id": "1710.10329", "submitter": "Naman Agarwal", "authors": "Naman Agarwal, Elad Hazan", "title": "Lower Bounds for Higher-Order Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods in convex and non-convex optimization employ\nhigher-order derivative information, either implicitly or explicitly. We\nexplore the limitations of higher-order optimization and prove that even for\nconvex optimization, a polynomial dependence on the approximation guarantee and\nhigher-order smoothness parameters is necessary. As a special case, we show\nNesterov's accelerated cubic regularization method to be nearly tight.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 20:52:33 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Agarwal", "Naman", ""], ["Hazan", "Elad", ""]]}, {"id": "1710.10335", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi, Nesreen K. Ahmed, Hoda Eldardiry, and Rong Zhou", "title": "Similarity-based Multi-label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification is an important learning problem with many\napplications. In this work, we propose a principled similarity-based approach\nfor multi-label learning called SML. We also introduce a similarity-based\napproach for predicting the label set size. The experimental results\ndemonstrate the effectiveness of SML for multi-label classification where it is\nshown to compare favorably with a wide variety of existing algorithms across a\nrange of evaluation criterion.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 21:20:31 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Ahmed", "Nesreen K.", ""], ["Eldardiry", "Hoda", ""], ["Zhou", "Rong", ""]]}, {"id": "1710.10345", "submitter": "Daniel Soudry", "authors": "Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar,\n  Nathan Srebro", "title": "The Implicit Bias of Gradient Descent on Separable Data", "comments": "Final JMLR version, with improved discussions over v3. Main\n  improvements in journal version over conference version (v2 appeared in\n  ICLR): We proved the measure zero case for main theorem (with implications\n  for the rates), and the multi-class case", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine gradient descent on unregularized logistic regression problems,\nwith homogeneous linear predictors on linearly separable datasets. We show the\npredictor converges to the direction of the max-margin (hard margin SVM)\nsolution. The result also generalizes to other monotone decreasing loss\nfunctions with an infimum at infinity, to multi-class problems, and to training\na weight layer in a deep network in a certain restricted setting. Furthermore,\nwe show this convergence is very slow, and only logarithmic in the convergence\nof the loss itself. This can help explain the benefit of continuing to optimize\nthe logistic or cross-entropy loss even after the training error is zero and\nthe training loss is extremely small, and, as we show, even if the validation\nloss increases. Our methodology can also aid in understanding implicit\nregularization n more complex models and with other optimization methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 21:47:58 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 21:12:01 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 17:53:26 GMT"}, {"version": "v4", "created": "Fri, 28 Dec 2018 10:51:36 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Soudry", "Daniel", ""], ["Hoffer", "Elad", ""], ["Nacson", "Mor Shpigel", ""], ["Gunasekar", "Suriya", ""], ["Srebro", "Nathan", ""]]}, {"id": "1710.10348", "submitter": "Bo Chang", "authors": "Bo Chang, Lili Meng, Eldad Haber, Frederick Tung, David Begert", "title": "Multi-level Residual Networks from Dynamical Systems View", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep residual networks (ResNets) and their variants are widely used in many\ncomputer vision applications and natural language processing tasks. However,\nthe theoretical principles for designing and training ResNets are still not\nfully understood. Recently, several points of view have emerged to try to\ninterpret ResNet theoretically, such as unraveled view, unrolled iterative\nestimation and dynamical systems view. In this paper, we adopt the dynamical\nsystems point of view, and analyze the lesioning properties of ResNet both\ntheoretically and experimentally. Based on these analyses, we additionally\npropose a novel method for accelerating ResNet training. We apply the proposed\nmethod to train ResNets and Wide ResNets for three image classification\nbenchmarks, reducing training time by more than 40% with superior or on-par\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 22:06:58 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 23:25:10 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Chang", "Bo", ""], ["Meng", "Lili", ""], ["Haber", "Eldad", ""], ["Tung", "Frederick", ""], ["Begert", "David", ""]]}, {"id": "1710.10352", "submitter": "Oliver Hennigh", "authors": "Oliver Hennigh", "title": "Automated Design using Neural Networks and Gradient Descent", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel method that makes use of deep neural networks and gradient\ndecent to perform automated design on complex real world engineering tasks. Our\napproach works by training a neural network to mimic the fitness function of a\ndesign optimization task and then, using the differential nature of the neural\nnetwork, perform gradient decent to maximize the fitness. We demonstrate this\nmethods effectiveness by designing an optimized heat sink and both 2D and 3D\nairfoils that maximize the lift drag ratio under steady state flow conditions.\nWe highlight that our method has two distinct benefits over other automated\ndesign approaches. First, evaluating the neural networks prediction of fitness\ncan be orders of magnitude faster then simulating the system of interest.\nSecond, using gradient decent allows the design space to be searched much more\nefficiently then other gradient free methods. These two strengths work together\nto overcome some of the current shortcomings of automated design.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 22:43:08 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Hennigh", "Oliver", ""]]}, {"id": "1710.10363", "submitter": "Sergio Valcarcel Macua", "authors": "Sergio Valcarcel Macua and Aleksi Tukiainen and Daniel\n  Garc\\'ia-Oca\\~na Hern\\'andez and David Baldazo and Enrique Munoz de Cote and\n  Santiago Zazo", "title": "Diff-DAC: Distributed Actor-Critic for Average Multitask Deep\n  Reinforcement Learning", "comments": null, "journal-ref": "Presented at Adaptive Learning Agents workshop (ALA2018), July\n  14th, 2018, Stockholm, Sweden", "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fully distributed actor-critic algorithm approximated by deep\nneural networks, named \\textit{Diff-DAC}, with application to single-task and\nto average multitask reinforcement learning (MRL). Each agent has access to\ndata from its local task only, but it aims to learn a policy that performs well\non average for the whole set of tasks. During the learning process, agents\ncommunicate their value-policy parameters to their neighbors, diffusing the\ninformation across the network, so that they converge to a common policy, with\nno need for a central node. The method is scalable, since the computational and\ncommunication costs per agent grow with its number of neighbors. We derive\nDiff-DAC's from duality theory and provide novel insights into the standard\nactor-critic framework, showing that it is actually an instance of the dual\nascent method that approximates the solution of a linear program. Experiments\nsuggest that Diff-DAC can outperform the single previous distributed MRL\napproach (i.e., Dist-MTLPS) and even the centralized architecture.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 00:55:01 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 18:10:08 GMT"}, {"version": "v3", "created": "Wed, 29 Nov 2017 16:21:47 GMT"}, {"version": "v4", "created": "Sun, 22 Apr 2018 10:34:09 GMT"}, {"version": "v5", "created": "Wed, 11 Dec 2019 08:03:01 GMT"}, {"version": "v6", "created": "Sun, 25 Oct 2020 14:41:10 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Macua", "Sergio Valcarcel", ""], ["Tukiainen", "Aleksi", ""], ["Hern\u00e1ndez", "Daniel Garc\u00eda-Oca\u00f1a", ""], ["Baldazo", "David", ""], ["de Cote", "Enrique Munoz", ""], ["Zazo", "Santiago", ""]]}, {"id": "1710.10370", "submitter": "Jian Du", "authors": "Jian Du, Shanghang Zhang, Guanhang Wu, Jose M. F. Moura, Soummya Kar", "title": "Topology Adaptive Graph Convolutional Networks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral graph convolutional neural networks (CNNs) require approximation to\nthe convolution to alleviate the computational complexity, resulting in\nperformance loss. This paper proposes the topology adaptive graph convolutional\nnetwork (TAGCN), a novel graph convolutional network defined in the vertex\ndomain. We provide a systematic way to design a set of fixed-size learnable\nfilters to perform convolutions on graphs. The topologies of these filters are\nadaptive to the topology of the graph when they scan the graph to perform\nconvolution. The TAGCN not only inherits the properties of convolutions in CNN\nfor grid-structured data, but it is also consistent with convolution as defined\nin graph signal processing. Since no approximation to the convolution is\nneeded, TAGCN exhibits better performance than existing spectral CNNs on a\nnumber of data sets and is also computationally simpler than other recent\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 02:12:51 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 14:02:52 GMT"}, {"version": "v3", "created": "Fri, 17 Nov 2017 01:58:56 GMT"}, {"version": "v4", "created": "Sun, 31 Dec 2017 22:19:33 GMT"}, {"version": "v5", "created": "Sun, 11 Feb 2018 20:53:09 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Du", "Jian", ""], ["Zhang", "Shanghang", ""], ["Wu", "Guanhang", ""], ["Moura", "Jose M. F.", ""], ["Kar", "Soummya", ""]]}, {"id": "1710.10381", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge and Jose C. Principe", "title": "Partitioning Relational Matrices of Similarities or Dissimilarities\n  using the Value of Information", "comments": "Submitted to the IEEE International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide an approach to clustering relational matrices whose\nentries correspond to either similarities or dissimilarities between objects.\nOur approach is based on the value of information, a parameterized,\ninformation-theoretic criterion that measures the change in costs associated\nwith changes in information. Optimizing the value of information yields a\ndeterministic annealing style of clustering with many benefits. For instance,\ninvestigators avoid needing to a priori specify the number of clusters, as the\npartitions naturally undergo phase changes, during the annealing process,\nwhereby the number of clusters changes in a data-driven fashion. The\nglobal-best partition can also often be identified.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 03:21:24 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Principe", "Jose C.", ""]]}, {"id": "1710.10388", "submitter": "Cheng Mao", "authors": "Cheng Mao, Jonathan Weed and Philippe Rigollet", "title": "Minimax Rates and Efficient Algorithms for Noisy Sorting", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge of interest in studying permutation-based\nmodels for ranking from pairwise comparison data. Despite being structurally\nricher and more robust than parametric ranking models, permutation-based models\nare less well understood statistically and generally lack efficient learning\nalgorithms. In this work, we study a prototype of permutation-based ranking\nmodels, namely, the noisy sorting model. We establish the optimal rates of\nlearning the model under two sampling procedures. Furthermore, we provide a\nfast algorithm to achieve near-optimal rates if the observations are sampled\nindependently. Along the way, we discover properties of the symmetric group\nwhich are of theoretical interest.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 04:45:51 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Mao", "Cheng", ""], ["Weed", "Jonathan", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1710.10403", "submitter": "Cheng-Hao Cai", "authors": "Cheng-Hao Cai, Yanyan Xu, Dengfeng Ke, Kaile Su, Jing Sun", "title": "Trainable back-propagated functional transfer matrices", "comments": "39 pages, 4 figures, submitted as a journal article", "journal-ref": "Appl. Intell. (2018)", "doi": "10.1007/s10489-018-1266-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connections between nodes of fully connected neural networks are usually\nrepresented by weight matrices. In this article, functional transfer matrices\nare introduced as alternatives to the weight matrices: Instead of using real\nweights, a functional transfer matrix uses real functions with trainable\nparameters to represent connections between nodes. Multiple functional transfer\nmatrices are then stacked together with bias vectors and activations to form\ndeep functional transfer neural networks. These neural networks can be trained\nwithin the framework of back-propagation, based on a revision of the delta\nrules and the error transmission rule for functional connections. In\nexperiments, it is demonstrated that the revised rules can be used to train a\nrange of functional connections: 20 different functions are applied to neural\nnetworks with up to 10 hidden layers, and most of them gain high test\naccuracies on the MNIST database. It is also demonstrated that a functional\ntransfer matrix with a memory function can roughly memorise a non-cyclical\nsequence of 400 digits.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 06:59:18 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Cai", "Cheng-Hao", ""], ["Xu", "Yanyan", ""], ["Ke", "Dengfeng", ""], ["Su", "Kaile", ""], ["Sun", "Jing", ""]]}, {"id": "1710.10404", "submitter": "Jinglin Chen", "authors": "Jinglin Chen, Jian Peng, Qiang Liu", "title": "Efficient Localized Inference for Large Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new localized inference algorithm for answering marginalization\nqueries in large graphical models with the correlation decay property. Given a\nquery variable and a large graphical model, we define a much smaller model in a\nlocal region around the query variable in the target model so that the marginal\ndistribution of the query variable can be accurately approximated. We introduce\ntwo approximation error bounds based on the Dobrushin's comparison theorem and\napply our bounds to derive a greedy expansion algorithm that efficiently guides\nthe selection of neighbor nodes for localized inference. We verify our\ntheoretical bounds on various datasets and demonstrate that our localized\ninference algorithm can provide fast and accurate approximation for large\ngraphical models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 07:02:07 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Chen", "Jinglin", ""], ["Peng", "Jian", ""], ["Liu", "Qiang", ""]]}, {"id": "1710.10467", "submitter": "Quan Wang", "authors": "Li Wan, Quan Wang, Alan Papir, Ignacio Lopez Moreno", "title": "Generalized End-to-End Loss for Speaker Verification", "comments": "Published at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new loss function called generalized end-to-end\n(GE2E) loss, which makes the training of speaker verification models more\nefficient than our previous tuple-based end-to-end (TE2E) loss function. Unlike\nTE2E, the GE2E loss function updates the network in a way that emphasizes\nexamples that are difficult to verify at each step of the training process.\nAdditionally, the GE2E loss does not require an initial stage of example\nselection. With these properties, our model with the new loss function\ndecreases speaker verification EER by more than 10%, while reducing the\ntraining time by 60% at the same time. We also introduce the MultiReader\ntechnique, which allows us to do domain adaptation - training a more accurate\nmodel that supports multiple keywords (i.e. \"OK Google\" and \"Hey Google\") as\nwell as multiple dialects.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 13:51:51 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 22:11:24 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 21:29:09 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 19:13:25 GMT"}, {"version": "v5", "created": "Mon, 9 Nov 2020 17:02:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wan", "Li", ""], ["Wang", "Quan", ""], ["Papir", "Alan", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1710.10468", "submitter": "Quan Wang", "authors": "Quan Wang, Carlton Downey, Li Wan, Philip Andrew Mansfield, Ignacio\n  Lopez Moreno", "title": "Speaker Diarization with LSTM", "comments": "Published at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many years, i-vector based audio embedding techniques were the dominant\napproach for speaker verification and speaker diarization applications.\nHowever, mirroring the rise of deep learning in various domains, neural network\nbased audio embeddings, also known as d-vectors, have consistently demonstrated\nsuperior speaker verification performance. In this paper, we build on the\nsuccess of d-vector based speaker verification systems to develop a new\nd-vector based approach to speaker diarization. Specifically, we combine\nLSTM-based d-vector audio embeddings with recent work in non-parametric\nclustering to obtain a state-of-the-art speaker diarization system. Our system\nis evaluated on three standard public datasets, suggesting that d-vector based\ndiarization systems offer significant advantages over traditional i-vector\nbased systems. We achieved a 12.0% diarization error rate on NIST SRE 2000\nCALLHOME, while our model is trained with out-of-domain data from voice search\nlogs.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 13:59:17 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 15:58:07 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 14:53:16 GMT"}, {"version": "v4", "created": "Thu, 16 Nov 2017 16:17:58 GMT"}, {"version": "v5", "created": "Wed, 31 Jan 2018 17:19:05 GMT"}, {"version": "v6", "created": "Fri, 14 Dec 2018 21:23:33 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Wang", "Quan", ""], ["Downey", "Carlton", ""], ["Wan", "Li", ""], ["Mansfield", "Philip Andrew", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1710.10470", "submitter": "Quan Wang", "authors": "F A Rezaur Rahman Chowdhury, Quan Wang, Ignacio Lopez Moreno, Li Wan", "title": "Attention-Based Models for Text-Dependent Speaker Verification", "comments": "Submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models have recently shown great performance on a range of\ntasks, such as speech recognition, machine translation, and image captioning\ndue to their ability to summarize relevant information that expands through the\nentire length of an input sequence. In this paper, we analyze the usage of\nattention mechanisms to the problem of sequence summarization in our end-to-end\ntext-dependent speaker recognition system. We explore different topologies and\ntheir variants of the attention layer, and compare different pooling methods on\nthe attention weights. Ultimately, we show that attention-based models can\nimproves the Equal Error Rate (EER) of our speaker verification system by\nrelatively 14% compared to our non-attention LSTM baseline model.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 14:12:29 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 15:48:14 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 20:58:17 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Chowdhury", "F A Rezaur Rahman", ""], ["Wang", "Quan", ""], ["Moreno", "Ignacio Lopez", ""], ["Wan", "Li", ""]]}, {"id": "1710.10513", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Yao Xie", "title": "Crime incidents embedding using restricted Boltzmann machines", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for detecting related crime series, by unsupervised\nlearning of the latent feature embeddings from narratives of crime record via\nthe Gaussian-Bernoulli Restricted Boltzmann Machines (RBM). This is a\ndrastically different approach from prior work on crime analysis, which\ntypically considers only time and location and at most category information.\nAfter the embedding, related cases are closer to each other in the Euclidean\nfeature space, and the unrelated cases are far apart, which is a good property\ncan enable subsequent analysis such as detection and clustering of related\ncases. Experiments over several series of related crime incidents hand labeled\nby the Atlanta Police Department reveal the promise of our embedding methods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 18:42:11 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 18:07:38 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 02:23:01 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Zhu", "Shixiang", ""], ["Xie", "Yao", ""]]}, {"id": "1710.10547", "submitter": "Abubakar Abid", "authors": "Amirata Ghorbani, Abubakar Abid, James Zou", "title": "Interpretation of Neural Networks is Fragile", "comments": "Published as a conference paper at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for machine learning to be deployed and trusted in many\napplications, it is crucial to be able to reliably explain why the machine\nlearning algorithm makes certain predictions. For example, if an algorithm\nclassifies a given pathology image to be a malignant tumor, then the doctor may\nneed to know which parts of the image led the algorithm to this classification.\nHow to interpret black-box predictors is thus an important and active area of\nresearch. A fundamental question is: how much can we trust the interpretation\nitself? In this paper, we show that interpretation of deep learning predictions\nis extremely fragile in the following sense: two perceptively indistinguishable\ninputs with the same predicted label can be assigned very different\ninterpretations. We systematically characterize the fragility of several\nwidely-used feature-importance interpretation methods (saliency maps, relevance\npropagation, and DeepLIFT) on ImageNet and CIFAR-10. Our experiments show that\neven small random perturbation can change the feature importance and new\nsystematic perturbations can lead to dramatically different interpretations\nwithout changing the label. We extend these results to show that\ninterpretations based on exemplars (e.g. influence functions) are similarly\nfragile. Our analysis of the geometry of the Hessian matrix gives insight on\nwhy fragility could be a fundamental challenge to the current interpretation\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 01:02:12 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 05:26:44 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1710.10551", "submitter": "Yining Wang", "authors": "Yining Wang, Simon Du, Sivaraman Balakrishnan, Aarti Singh", "title": "Stochastic Zeroth-order Optimization in High Dimensions", "comments": "Camera-ready version at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimizing a high-dimensional convex function\nusing stochastic zeroth-order queries. Under sparsity assumptions on the\ngradients or function values, we present two algorithms: a successive\ncomponent/feature selection algorithm and a noisy mirror descent algorithm\nusing Lasso gradient estimates, and show that both algorithms have convergence\nrates that de- pend only logarithmically on the ambient dimension of the\nproblem. Empirical results confirm our theoretical findings and show that the\nalgorithms we design outperform classical zeroth-order optimization methods in\nthe high-dimensional setting.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 02:11:48 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 02:26:27 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Wang", "Yining", ""], ["Du", "Simon", ""], ["Balakrishnan", "Sivaraman", ""], ["Singh", "Aarti", ""]]}, {"id": "1710.10568", "submitter": "Jianfei Chen", "authors": "Jianfei Chen, Jun Zhu and Le Song", "title": "Stochastic Training of Graph Convolutional Networks with Variance\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are powerful deep neural networks for\ngraph-structured data. However, GCN computes the representation of a node\nrecursively from its neighbors, making the receptive field size grow\nexponentially with the number of layers. Previous attempts on reducing the\nreceptive field size by subsampling neighbors do not have a convergence\nguarantee, and their receptive field size per node is still in the order of\nhundreds. In this paper, we develop control variate based algorithms which\nallow sampling an arbitrarily small neighbor size. Furthermore, we prove new\ntheoretical guarantee for our algorithms to converge to a local optimum of GCN.\nEmpirical results show that our algorithms enjoy a similar convergence with the\nexact algorithm using only two neighbors per node. The runtime of our\nalgorithms on a large Reddit dataset is only one seventh of previous neighbor\nsampling algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 06:14:00 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 12:55:08 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 15:23:22 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Chen", "Jianfei", ""], ["Zhu", "Jun", ""], ["Song", "Le", ""]]}, {"id": "1710.10570", "submitter": "Saiprasad Koturwar", "authors": "Saiprasad Koturwar, Shabbir Merchant", "title": "Weight Initialization of Deep Neural Networks(DNNs) using Data\n  Statistics", "comments": "The work is currently under progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) form the backbone of almost every\nstate-of-the-art technique in the fields such as computer vision, speech\nprocessing, and text analysis. The recent advances in computational technology\nhave made the use of DNNs more practical. Despite the overwhelming performances\nby DNN and the advances in computational technology, it is seen that very few\nresearchers try to train their models from the scratch. Training of DNNs still\nremains a difficult and tedious job. The main challenges that researchers face\nduring training of DNNs are the vanishing/exploding gradient problem and the\nhighly non-convex nature of the objective function which has up to million\nvariables. The approaches suggested in He and Xavier solve the vanishing\ngradient problem by providing a sophisticated initialization technique. These\napproaches have been quite effective and have achieved good results on standard\ndatasets, but these same approaches do not work very well on more practical\ndatasets. We think the reason for this is not making use of data statistics for\ninitializing the network weights. Optimizing such a high dimensional loss\nfunction requires careful initialization of network weights. In this work, we\npropose a data dependent initialization and analyze its performance against the\nstandard initialization techniques such as He and Xavier. We performed our\nexperiments on some practical datasets and the results show our algorithm's\nsuperior classification accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 07:23:19 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 08:25:20 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Koturwar", "Saiprasad", ""], ["Merchant", "Shabbir", ""]]}, {"id": "1710.10571", "submitter": "Aman Sinha", "authors": "Aman Sinha, Hongseok Namkoong, Riccardo Volpi, and John Duchi", "title": "Certifying Some Distributional Robustness with Principled Adversarial\n  Training", "comments": "ICLR 2018: https://openreview.net/forum?id=Hk6kPgZA-", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarial examples and researchers have\nproposed many heuristic attack and defense mechanisms. We address this problem\nthrough the principled lens of distributionally robust optimization, which\nguarantees performance under adversarial input perturbations. By considering a\nLagrangian penalty formulation of perturbing the underlying data distribution\nin a Wasserstein ball, we provide a training procedure that augments model\nparameter updates with worst-case perturbations of training data. For smooth\nlosses, our procedure provably achieves moderate levels of robustness with\nlittle computational or statistical cost relative to empirical risk\nminimization. Furthermore, our statistical guarantees allow us to efficiently\ncertify robustness for the population loss. For imperceptible perturbations,\nour method matches or outperforms heuristic approaches.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 07:27:57 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 18:01:49 GMT"}, {"version": "v3", "created": "Tue, 9 Jan 2018 20:20:25 GMT"}, {"version": "v4", "created": "Tue, 1 May 2018 05:52:13 GMT"}, {"version": "v5", "created": "Fri, 1 May 2020 07:29:34 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Sinha", "Aman", ""], ["Namkoong", "Hongseok", ""], ["Volpi", "Riccardo", ""], ["Duchi", "John", ""]]}, {"id": "1710.10600", "submitter": "Daniel Lopez Martinez", "authors": "Daniel Lopez-Martinez", "title": "Regularization approaches for support vector machines with applications\n  to biomedical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machine (SVM) is a widely used machine learning tool for\nclassification based on statistical learning theory. Given a set of training\ndata, the SVM finds a hyperplane that separates two different classes of data\npoints by the largest distance. While the standard form of SVM uses L2-norm\nregularization, other regularization approaches are particularly attractive for\nbiomedical datasets where, for example, sparsity and interpretability of the\nclassifier's coefficient values are highly desired features. Therefore, in this\npaper we consider different types of regularization approaches for SVMs, and\nexplore them in both synthetic and real biomedical datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 12:17:19 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Lopez-Martinez", "Daniel", ""]]}, {"id": "1710.10628", "submitter": "Cuong Nguyen", "authors": "Cuong V. Nguyen, Yingzhen Li, Thang D. Bui, Richard E. Turner", "title": "Variational Continual Learning", "comments": "Published at International Conference on Learning Representations\n  (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops variational continual learning (VCL), a simple but\ngeneral framework for continual learning that fuses online variational\ninference (VI) and recent advances in Monte Carlo VI for neural networks. The\nframework can successfully train both deep discriminative models and deep\ngenerative models in complex continual learning settings where existing tasks\nevolve over time and entirely new tasks emerge. Experimental results show that\nVCL outperforms state-of-the-art continual learning methods on a variety of\ntasks, avoiding catastrophic forgetting in a fully automatic way.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 15:30:58 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 11:40:11 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 14:51:43 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Nguyen", "Cuong V.", ""], ["Li", "Yingzhen", ""], ["Bui", "Thang D.", ""], ["Turner", "Richard E.", ""]]}, {"id": "1710.10629", "submitter": "Stefan Doerr", "authors": "Stefan Doerr, Igor Ariz-Extreme, Matthew J. Harvey, Gianni De\n  Fabritiis", "title": "Dimensionality reduction methods for molecular simulations", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular simulations produce very high-dimensional data-sets with millions\nof data points. As analysis methods are often unable to cope with so many\ndimensions, it is common to use dimensionality reduction and clustering methods\nto reach a reduced representation of the data. Yet these methods often fail to\ncapture the most important features necessary for the construction of a Markov\nmodel. Here we demonstrate the results of various dimensionality reduction\nmethods on two simulation data-sets, one of protein folding and another of\nprotein-ligand binding. The methods tested include a k-means clustering\nvariant, a non-linear auto encoder, principal component analysis and tICA. The\ndimension-reduced data is then used to estimate the implied timescales of the\nslowest process by a Markov state model analysis to assess the quality of the\nprojection. The projected dimensions learned from the data are visualized to\ndemonstrate which conformations the various methods choose to represent the\nmolecular process.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 15:33:42 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 10:00:57 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Doerr", "Stefan", ""], ["Ariz-Extreme", "Igor", ""], ["Harvey", "Matthew J.", ""], ["De Fabritiis", "Gianni", ""]]}, {"id": "1710.10646", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang", "title": "On the Consistency of Quick Shift", "comments": "Proceedings of 31st Conference on Neural Information Processing\n  Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quick Shift is a popular mode-seeking and clustering algorithm. We present\nfinite sample statistical consistency guarantees for Quick Shift on mode and\ncluster recovery under mild distributional assumptions. We then apply our\nresults to construct a consistent modal regression algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 16:49:38 GMT"}, {"version": "v2", "created": "Sat, 23 Dec 2017 07:28:02 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Jiang", "Heinrich", ""]]}, {"id": "1710.10655", "submitter": "Lalit Jain", "authors": "Anna C. Gilbert, Lalit Jain", "title": "If it ain't broke, don't fix it: Sparse metric repair", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern data-intensive computational problems either require, or benefit\nfrom distance or similarity data that adhere to a metric. The algorithms run\nfaster or have better performance guarantees. Unfortunately, in real\napplications, the data are messy and values are noisy. The distances between\nthe data points are far from satisfying a metric. Indeed, there are a number of\ndifferent algorithms for finding the closest set of distances to the given ones\nthat also satisfy a metric (sometimes with the extra condition of being\nEuclidean). These algorithms can have unintended consequences, they can change\na large number of the original data points, and alter many other features of\nthe data.\n  The goal of sparse metric repair is to make as few changes as possible to the\noriginal data set or underlying distances so as to ensure the resulting\ndistances satisfy the properties of a metric. In other words, we seek to\nminimize the sparsity (or the $\\ell_0$ \"norm\") of the changes we make to the\ndistances subject to the new distances satisfying a metric. We give three\ndifferent combinatorial algorithms to repair a metric sparsely. In one setting\nthe algorithm is guaranteed to return the sparsest solution and in the other\nsettings, the algorithms repair the metric. Without prior information, the\nalgorithms run in time proportional to the cube of the number of input data\npoints and, with prior information we can reduce the running time considerably.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 17:48:01 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Gilbert", "Anna C.", ""], ["Jain", "Lalit", ""]]}, {"id": "1710.10686", "submitter": "Vladimir Golkov", "authors": "Jan Kuka\\v{c}ka, Vladimir Golkov, Daniel Cremers", "title": "Regularization for Deep Learning: A Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is one of the crucial ingredients of deep learning, yet the\nterm regularization has various definitions, and regularization methods are\noften studied separately from each other. In our work we present a systematic,\nunifying taxonomy to categorize existing methods. We distinguish methods that\naffect data, network architectures, error terms, regularization terms, and\noptimization procedures. We do not provide all details about the listed\nmethods; instead, we present an overview of how the methods can be sorted into\nmeaningful categories and sub-categories. This helps revealing links and\nfundamental similarities between them. Finally, we include practical\nrecommendations both for users and for developers of new regularization\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 20:27:51 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Kuka\u010dka", "Jan", ""], ["Golkov", "Vladimir", ""], ["Cremers", "Daniel", ""]]}, {"id": "1710.10704", "submitter": "Alireza Bagheri", "authors": "Alireza Bagheri, Osvaldo Simeone, Bipin Rajendran", "title": "Training Probabilistic Spiking Neural Networks with First-to-spike\n  Decoding", "comments": "A shorter version will be published on Proc. IEEE ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-generation neural networks, or Spiking Neural Networks (SNNs), aim at\nharnessing the energy efficiency of spike-domain processing by building on\ncomputing elements that operate on, and exchange, spikes. In this paper, the\nproblem of training a two-layer SNN is studied for the purpose of\nclassification, under a Generalized Linear Model (GLM) probabilistic neural\nmodel that was previously considered within the computational neuroscience\nliterature. Conventional classification rules for SNNs operate offline based on\nthe number of output spikes at each output neuron. In contrast, a novel\ntraining method is proposed here for a first-to-spike decoding rule, whereby\nthe SNN can perform an early classification decision once spike firing is\ndetected at an output neuron. Numerical results bring insights into the optimal\nparameter selection for the GLM neuron and on the accuracy-complexity trade-off\nperformance of conventional and first-to-spike decoding.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 22:13:53 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 07:41:15 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 04:49:44 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Bagheri", "Alireza", ""], ["Simeone", "Osvaldo", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1710.10720", "submitter": "Lior Horesh", "authors": "Vernon Austel, Sanjeeb Dash, Oktay Gunluk, Lior Horesh, Leo Liberti,\n  Giacomo Nannicini and Baruch Schieber", "title": "Globally Optimal Symbolic Regression", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we introduce a new technique for symbolic regression that\nguarantees global optimality. This is achieved by formulating a mixed integer\nnon-linear program (MINLP) whose solution is a symbolic mathematical expression\nof minimum complexity that explains the observations. We demonstrate our\napproach by rediscovering Kepler's law on planetary motion using exoplanet data\nand Galileo's pendulum periodicity equation using experimental data.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 23:37:09 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 02:55:49 GMT"}, {"version": "v3", "created": "Wed, 15 Nov 2017 15:02:10 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Austel", "Vernon", ""], ["Dash", "Sanjeeb", ""], ["Gunluk", "Oktay", ""], ["Horesh", "Lior", ""], ["Liberti", "Leo", ""], ["Nannicini", "Giacomo", ""], ["Schieber", "Baruch", ""]]}, {"id": "1710.10728", "submitter": "Chengyu Liu", "authors": "Chengyu Liu, Wei Wang", "title": "Contextual Regression: An Accurate and Conveniently Interpretable\n  Nonlinear Model for Mining Discovery from Scientific Data", "comments": "18 pages of Main Article, 30 pages of Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms such as linear regression, SVM and neural network\nhave played an increasingly important role in the process of scientific\ndiscovery. However, none of them is both interpretable and accurate on\nnonlinear datasets. Here we present contextual regression, a method that joins\nthese two desirable properties together using a hybrid architecture of neural\nnetwork embedding and dot product layer. We demonstrate its high prediction\naccuracy and sensitivity through the task of predictive feature selection on a\nsimulated dataset and the application of predicting open chromatin sites in the\nhuman genome. On the simulated data, our method achieved high fidelity recovery\nof feature contributions under random noise levels up to 200%. On the open\nchromatin dataset, the application of our method not only outperformed the\nstate of the art method in terms of accuracy, but also unveiled two previously\nunfound open chromatin related histone marks. Our method can fill the blank of\naccurate and interpretable nonlinear modeling in scientific data mining tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 00:39:47 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Liu", "Chengyu", ""], ["Wang", "Wei", ""]]}, {"id": "1710.10733", "submitter": "Yash Sharma", "authors": "Yash Sharma, Pin-Yu Chen", "title": "Attacking the Madry Defense Model with $L_1$-based Adversarial Examples", "comments": "Accepted to ICLR 2018 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Madry Lab recently hosted a competition designed to test the robustness\nof their adversarially trained MNIST model. Attacks were constrained to perturb\neach pixel of the input image by a scaled maximal $L_\\infty$ distortion\n$\\epsilon$ = 0.3. This discourages the use of attacks which are not optimized\non the $L_\\infty$ distortion metric. Our experimental results demonstrate that\nby relaxing the $L_\\infty$ constraint of the competition, the elastic-net\nattack to deep neural networks (EAD) can generate transferable adversarial\nexamples which, despite their high average $L_\\infty$ distortion, have minimal\nvisual distortion. These results call into question the use of $L_\\infty$ as a\nsole measure for visual distortion, and further demonstrate the power of EAD at\ngenerating robust adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 00:57:34 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 07:31:59 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 03:28:21 GMT"}, {"version": "v4", "created": "Fri, 27 Jul 2018 22:01:59 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Sharma", "Yash", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "1710.10737", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Peter Richt\\'arik", "title": "Linearly convergent stochastic heavy ball method for minimizing\n  generalization error", "comments": "NIPS 2017, Workshop on Optimization for Machine Learning (camera\n  ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we establish the first linear convergence result for the\nstochastic heavy ball method. The method performs SGD steps with a fixed\nstepsize, amended by a heavy ball momentum term. In the analysis, we focus on\nminimizing the expected loss and not on finite-sum minimization, which is\ntypically a much harder problem. While in the analysis we constrain ourselves\nto quadratic loss, the overall objective is not necessarily strongly convex.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 01:49:34 GMT"}, {"version": "v2", "created": "Sat, 23 Dec 2017 02:18:06 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1710.10739", "submitter": "Bin Wang", "authors": "Bin Wang and Zhijian Ou", "title": "Learning neural trans-dimensional random field language models with\n  noise-contrastive estimation", "comments": "5 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trans-dimensional random field language models (TRF LMs) where sentences are\nmodeled as a collection of random fields, have shown close performance with\nLSTM LMs in speech recognition and are computationally more efficient in\ninference. However, the training efficiency of neural TRF LMs is not\nsatisfactory, which limits the scalability of TRF LMs on large training corpus.\nIn this paper, several techniques on both model formulation and parameter\nestimation are proposed to improve the training efficiency and the performance\nof neural TRF LMs. First, TRFs are reformulated in the form of exponential\ntilting of a reference distribution. Second, noise-contrastive estimation (NCE)\nis introduced to jointly estimate the model parameters and normalization\nconstants. Third, we extend the neural TRF LMs by marrying the deep\nconvolutional neural network (CNN) and the bidirectional LSTM into the\npotential function to extract the deep hierarchical features and\nbidirectionally sequential features. Utilizing all the above techniques enables\nthe successful and efficient training of neural TRF LMs on a 40x larger\ntraining set with only 1/3 training time and further reduces the WER with\nrelative reduction of 4.7% on top of a strong LSTM LM baseline.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 01:55:10 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Wang", "Bin", ""], ["Ou", "Zhijian", ""]]}, {"id": "1710.10742", "submitter": "Dustin Tran", "authors": "Dustin Tran, David M. Blei", "title": "Implicit Causal Models for Genome-wide Association Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in probabilistic generative models has accelerated, developing\nricher models with neural architectures, implicit densities, and with scalable\nalgorithms for their Bayesian inference. However, there has been limited\nprogress in models that capture causal relationships, for example, how\nindividual genetic factors cause major human diseases. In this work, we focus\non two challenges in particular: How do we build richer causal models, which\ncan capture highly nonlinear relationships and interactions between multiple\ncauses? How do we adjust for latent confounders, which are variables\ninfluencing both cause and effect and which prevent learning of causal\nrelationships? To address these challenges, we synthesize ideas from causality\nand modern probabilistic modeling. For the first, we describe implicit causal\nmodels, a class of causal models that leverages neural architectures with an\nimplicit density. For the second, we describe an implicit causal model that\nadjusts for confounders by sharing strength across examples. In experiments, we\nscale Bayesian inference on up to a billion genetic measurements. We achieve\nstate of the art accuracy for identifying causal factors: we significantly\noutperform existing genetics methods by an absolute difference of 15-45.3%.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 02:05:10 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Tran", "Dustin", ""], ["Blei", "David M.", ""]]}, {"id": "1710.10768", "submitter": "Makoto Aoshima", "authors": "Makoto Aoshima, Kazuyoshi Yata", "title": "Distance-based classifier by data transformation for high-dimension,\n  strongly spiked eigenvalue models", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider classifiers for high-dimensional data under the strongly spiked\neigenvalue (SSE) model. We first show that high-dimensional data often have the\nSSE model. We consider a distance-based classifier using eigenstructures for\nthe SSE model. We apply the noise reduction methodology to estimation of the\neigenvalues and eigenvectors in the SSE model. We create a new distance-based\nclassifier by transforming data from the SSE model to the non-SSE model. We\ngive simulation studies and discuss the performance of the new classifier.\nFinally, we demonstrate the new classifier by using microarray data sets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 04:32:30 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Aoshima", "Makoto", ""], ["Yata", "Kazuyoshi", ""]]}, {"id": "1710.10769", "submitter": "Penporn Koanantakool", "authors": "Penporn Koanantakool, Alnur Ali, Ariful Azad, Aydin Buluc, Dmitriy\n  Morozov, Leonid Oliker, Katherine Yelick, Sang-Yun Oh", "title": "Communication-Avoiding Optimization Methods for Distributed\n  Massive-Scale Sparse Inverse Covariance Estimation", "comments": "Main paper: 15 pages, appendix: 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across a variety of scientific disciplines, sparse inverse covariance\nestimation is a popular tool for capturing the underlying dependency\nrelationships in multivariate data. Unfortunately, most estimators are not\nscalable enough to handle the sizes of modern high-dimensional data sets (often\non the order of terabytes), and assume Gaussian samples. To address these\ndeficiencies, we introduce HP-CONCORD, a highly scalable optimization method\nfor estimating a sparse inverse covariance matrix based on a regularized\npseudolikelihood framework, without assuming Gaussianity. Our parallel proximal\ngradient method uses a novel communication-avoiding linear algebra algorithm\nand runs across a multi-node cluster with up to 1k nodes (24k cores), achieving\nparallel scalability on problems with up to ~819 billion parameters (1.28\nmillion dimensions); even on a single node, HP-CONCORD demonstrates\nscalability, outperforming a state-of-the-art method. We also use HP-CONCORD to\nestimate the underlying dependency structure of the brain from fMRI data, and\nuse the result to identify functional regions automatically. The results show\ngood agreement with a clustering from the neuroscience literature.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 04:32:41 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 16:06:51 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Koanantakool", "Penporn", ""], ["Ali", "Alnur", ""], ["Azad", "Ariful", ""], ["Buluc", "Aydin", ""], ["Morozov", "Dmitriy", ""], ["Oliker", "Leonid", ""], ["Yelick", "Katherine", ""], ["Oh", "Sang-Yun", ""]]}, {"id": "1710.10772", "submitter": "Xingwei Cao", "authors": "Xingwei Cao, Xuyang Zhao, Qibin Zhao", "title": "Tensorizing Generative Adversarial Nets", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) and its variants exhibit\nstate-of-the-art performance in the class of generative models. To capture\nhigher-dimensional distributions, the common learning procedure requires high\ncomputational complexity and a large number of parameters. The problem of\nemploying such massive framework arises when deploying it on a platform with\nlimited computational power such as mobile phones. In this paper, we present a\nnew generative adversarial framework by representing each layer as a tensor\nstructure connected by multilinear operations, aiming to reduce the number of\nmodel parameters by a large factor while preserving the generative performance\nand sample quality. To learn the model, we employ an efficient algorithm which\nalternatively optimizes both discriminator and generator. Experimental outcomes\ndemonstrate that our model can achieve high compression rate for model\nparameters up to $35$ times when compared to the original GAN for MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:05:02 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 03:23:03 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Cao", "Xingwei", ""], ["Zhao", "Xuyang", ""], ["Zhao", "Qibin", ""]]}, {"id": "1710.10776", "submitter": "Catherine Wong", "authors": "Catherine Wong and Andrea Gesmundo", "title": "Transfer Learning to Learn with Multitask Neural Model Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models require extensive architecture design exploration and\nhyperparameter optimization to perform well on a given task. The exploration of\nthe model design space is often made by a human expert, and optimized using a\ncombination of grid search and search heuristics over a large space of possible\nchoices. Neural Architecture Search (NAS) is a Reinforcement Learning approach\nthat has been proposed to automate architecture design. NAS has been\nsuccessfully applied to generate Neural Networks that rival the best\nhuman-designed architectures. However, NAS requires sampling, constructing, and\ntraining hundreds to thousands of models to achieve well-performing\narchitectures. This procedure needs to be executed from scratch for each new\ntask. The application of NAS to a wide set of tasks currently lacks a way to\ntransfer generalizable knowledge across tasks. In this paper, we present the\nMultitask Neural Model Search (MNMS) controller. Our goal is to learn a\ngeneralizable framework that can condition model construction on successful\nmodel searches for previously seen tasks, thus significantly speeding up the\nsearch for new tasks. We demonstrate that MNMS can conduct an automated\narchitecture search for multiple tasks simultaneously while still learning\nwell-performing, specialized models for each task. We then show that\npre-trained MNMS controllers can transfer learning to new tasks. By leveraging\nknowledge from previous searches, we find that pre-trained MNMS models start\nfrom a better location in the search space and reduce search time on unseen\ntasks, while still discovering models that outperform published human-designed\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:32:50 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Wong", "Catherine", ""], ["Gesmundo", "Andrea", ""]]}, {"id": "1710.10779", "submitter": "Cem Subakan", "authors": "Cem Subakan and Paris Smaragdis", "title": "Generative Adversarial Source Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative source separation methods such as non-negative matrix\nfactorization (NMF) or auto-encoders, rely on the assumption of an output\nprobability density. Generative Adversarial Networks (GANs) can learn data\ndistributions without needing a parametric assumption on the output density. We\nshow on a speech source separation experiment that, a multi-layer perceptron\ntrained with a Wasserstein-GAN formulation outperforms NMF, auto-encoders\ntrained with maximum likelihood, and variational auto-encoders in terms of\nsource to distortion ratio.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 05:42:25 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Subakan", "Cem", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1710.10781", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai", "title": "Stochastic variance reduced multiplicative update for nonnegative matrix\n  factorization", "comments": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF), a dimensionality reduction and factor\nanalysis method, is a special case in which factor matrices have low-rank\nnonnegative constraints. Considering the stochastic learning in NMF, we\nspecifically address the multiplicative update (MU) rule, which is the most\npopular, but which has slow convergence property. This present paper introduces\non the stochastic MU rule a variance-reduced technique of stochastic gradient.\nNumerical comparisons suggest that our proposed algorithms robustly outperform\nstate-of-the-art algorithms across different synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 06:14:17 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 21:45:46 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Kasai", "Hiroyuki", ""]]}, {"id": "1710.10784", "submitter": "Xiao Dong", "authors": "Xiao Dong, Jiasong Wu, Ling Zhou", "title": "How deep learning works --The geometry of deep learning", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Why and how that deep learning works well on different tasks remains a\nmystery from a theoretical perspective. In this paper we draw a geometric\npicture of the deep learning system by finding its analogies with two existing\ngeometric structures, the geometry of quantum computations and the geometry of\nthe diffeomorphic template matching. In this framework, we give the geometric\nstructures of different deep learning systems including convolutional neural\nnetworks, residual networks, recursive neural networks, recurrent neural\nnetworks and the equilibrium prapagation framework. We can also analysis the\nrelationship between the geometrical structures and their performance of\ndifferent networks in an algorithmic level so that the geometric framework may\nguide the design of the structures and algorithms of deep learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 06:42:23 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Dong", "Xiao", ""], ["Wu", "Jiasong", ""], ["Zhou", "Ling", ""]]}, {"id": "1710.10793", "submitter": "Soheil Feizi", "authors": "Soheil Feizi, Farzan Farnia, Tony Ginart and David Tse", "title": "Understanding GANs: the LQG Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become a popular method to learn\na probability model from data. In this paper, we aim to provide an\nunderstanding of some of the basic issues surrounding GANs including their\nformulation, generalization and stability on a simple benchmark where the data\nhas a high-dimensional Gaussian distribution. Even in this simple benchmark,\nthe GAN problem has not been well-understood as we observe that existing\nstate-of-the-art GAN architectures may fail to learn a proper generative\ndistribution owing to (1) stability issues (i.e., convergence to bad local\nsolutions or not converging at all), (2) approximation issues (i.e., having\nimproper global GAN optimizers caused by inappropriate GAN's loss functions),\nand (3) generalizability issues (i.e., requiring large number of samples for\ntraining). In this setup, we propose a GAN architecture which recovers the\nmaximum-likelihood solution and demonstrates fast generalization. Moreover, we\nanalyze global stability of different computational approaches for the proposed\nGAN optimization and highlight their pros and cons. Finally, we outline an\nextension of our model-based approach to design GANs in more complex setups\nthan the considered Gaussian benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 07:20:35 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 13:42:23 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Feizi", "Soheil", ""], ["Farnia", "Farzan", ""], ["Ginart", "Tony", ""], ["Tse", "David", ""]]}, {"id": "1710.10814", "submitter": "Lang-Chi Yu", "authors": "Lang-Chi Yu, Yi-Hsuan Yang, Yun-Ning Hung, Yi-An Chen", "title": "Hit Song Prediction for Pop Music by Siamese CNN with Ranking Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model for hit song prediction can be used in the pop music industry to\nidentify emerging trends and potential artists or songs before they are\nmarketed to the public. While most previous work formulates hit song prediction\nas a regression or classification problem, we present in this paper a\nconvolutional neural network (CNN) model that treats it as a ranking problem.\nSpecifically, we use a commercial dataset with daily play-counts to train a\nmulti-objective Siamese CNN model with Euclidean loss and pairwise ranking loss\nto learn from audio the relative ranking relations among songs. Besides, we\ndevise a number of pair sampling methods according to some empirical\nobservation of the data. Our experiment shows that the proposed model with a\nsampling method called A/B sampling leads to much higher accuracy in hit song\nprediction than the baseline regression model. Moreover, we can further improve\nthe accuracy by using a neural attention mechanism to extract the highlights of\nsongs and by using a separate CNN model to offer high-level features of songs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 09:10:11 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Yu", "Lang-Chi", ""], ["Yang", "Yi-Hsuan", ""], ["Hung", "Yun-Ning", ""], ["Chen", "Yi-An", ""]]}, {"id": "1710.10824", "submitter": "Shuliang Xu", "authors": "Lin Feng, Shuliang Xu, Feilong Wang, Shenglan Liu", "title": "Rough extreme learning machine: a new classification method based on\n  uncertainty measure", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extreme learning machine (ELM) is a new single hidden layer feedback neural\nnetwork. The weights of the input layer and the biases of neurons in hidden\nlayer are randomly generated, the weights of the output layer can be\nanalytically determined. ELM has been achieved good results for a large number\nof classification tasks. In this paper, a new extreme learning machine called\nrough extreme learning machine (RELM) was proposed. RELM uses rough set to\ndivide data into upper approximation set and lower approximation set, and the\ntwo approximation sets are utilized to train upper approximation neurons and\nlower approximation neurons. In addition, an attribute reduction is executed in\nthis algorithm to remove redundant attributes. The experimental results showed,\ncomparing with the comparison algorithms, RELM can get a better accuracy and\nrepeatability in most cases, RELM can not only maintain the advantages of fast\nspeed, but also effectively cope with the classification task for\nhigh-dimensional data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 09:37:20 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 09:03:36 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Feng", "Lin", ""], ["Xu", "Shuliang", ""], ["Wang", "Feilong", ""], ["Liu", "Shenglan", ""]]}, {"id": "1710.10866", "submitter": "Tadashi Kozuno", "authors": "Tadashi Kozuno, Eiji Uchibe, Kenji Doya", "title": "Unifying Value Iteration, Advantage Learning, and Dynamic Policy\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate dynamic programming algorithms, such as approximate value\niteration, have been successfully applied to many complex reinforcement\nlearning tasks, and a better approximate dynamic programming algorithm is\nexpected to further extend the applicability of reinforcement learning to\nvarious tasks. In this paper we propose a new, robust dynamic programming\nalgorithm that unifies value iteration, advantage learning, and dynamic policy\nprogramming. We call it generalized value iteration (GVI) and its approximated\nversion, approximate GVI (AGVI). We show AGVI's performance guarantee, which\nincludes performance guarantees for existing algorithms, as special cases. We\ndiscuss theoretical weaknesses of existing algorithms, and explain the\nadvantages of AGVI. Numerical experiments in a simple environment support\ntheoretical arguments, and suggest that AGVI is a promising alternative to\nprevious algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 11:05:32 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Kozuno", "Tadashi", ""], ["Uchibe", "Eiji", ""], ["Doya", "Kenji", ""]]}, {"id": "1710.10881", "submitter": "Armand Joulin", "authors": "Armand Joulin, Edouard Grave, Piotr Bojanowski, Maximilian Nickel,\n  Tomas Mikolov", "title": "Fast Linear Model for Knowledge Graph Embeddings", "comments": "Submitted AKBC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that a simple baseline based on a Bag-of-Words (BoW)\nrepresentation learns surprisingly good knowledge graph embeddings. By casting\nknowledge base completion and question answering as supervised classification\nproblems, we observe that modeling co-occurences of entities and relations\nleads to state-of-the-art performance with a training time of a few minutes\nusing the open sourced library fastText.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 11:46:23 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Joulin", "Armand", ""], ["Grave", "Edouard", ""], ["Bojanowski", "Piotr", ""], ["Nickel", "Maximilian", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1710.10903", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Guillem Cucurull, Arantxa Casanova, Adriana\n  Romero, Pietro Li\\`o, Yoshua Bengio", "title": "Graph Attention Networks", "comments": "To appear at ICLR 2018. 12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present graph attention networks (GATs), novel neural network\narchitectures that operate on graph-structured data, leveraging masked\nself-attentional layers to address the shortcomings of prior methods based on\ngraph convolutions or their approximations. By stacking layers in which nodes\nare able to attend over their neighborhoods' features, we enable (implicitly)\nspecifying different weights to different nodes in a neighborhood, without\nrequiring any kind of costly matrix operation (such as inversion) or depending\non knowing the graph structure upfront. In this way, we address several key\nchallenges of spectral-based graph neural networks simultaneously, and make our\nmodel readily applicable to inductive as well as transductive problems. Our GAT\nmodels have achieved or matched state-of-the-art results across four\nestablished transductive and inductive graph benchmarks: the Cora, Citeseer and\nPubmed citation network datasets, as well as a protein-protein interaction\ndataset (wherein test graphs remain unseen during training).\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 12:41:12 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 11:18:15 GMT"}, {"version": "v3", "created": "Sun, 4 Feb 2018 19:13:29 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Cucurull", "Guillem", ""], ["Casanova", "Arantxa", ""], ["Romero", "Adriana", ""], ["Li\u00f2", "Pietro", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1710.10916", "submitter": "Han Zhang", "authors": "Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang,\n  Xiaolei Huang, Dimitris Metaxas", "title": "StackGAN++: Realistic Image Synthesis with Stacked Generative\n  Adversarial Networks", "comments": "In IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI),\n  2018. (16 pages, 15 figures.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Generative Adversarial Networks (GANs) have shown remarkable success\nin various tasks, they still face challenges in generating high quality images.\nIn this paper, we propose Stacked Generative Adversarial Networks (StackGAN)\naiming at generating high-resolution photo-realistic images. First, we propose\na two-stage generative adversarial network architecture, StackGAN-v1, for\ntext-to-image synthesis. The Stage-I GAN sketches the primitive shape and\ncolors of the object based on given text description, yielding low-resolution\nimages. The Stage-II GAN takes Stage-I results and text descriptions as inputs,\nand generates high-resolution images with photo-realistic details. Second, an\nadvanced multi-stage generative adversarial network architecture, StackGAN-v2,\nis proposed for both conditional and unconditional generative tasks. Our\nStackGAN-v2 consists of multiple generators and discriminators in a tree-like\nstructure; images at multiple scales corresponding to the same scene are\ngenerated from different branches of the tree. StackGAN-v2 shows more stable\ntraining behavior than StackGAN-v1 by jointly approximating multiple\ndistributions. Extensive experiments demonstrate that the proposed stacked\ngenerative adversarial networks significantly outperform other state-of-the-art\nmethods in generating photo-realistic images.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 18:45:59 GMT"}, {"version": "v2", "created": "Mon, 25 Dec 2017 06:43:57 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 00:49:19 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Zhang", "Han", ""], ["Xu", "Tao", ""], ["Li", "Hongsheng", ""], ["Zhang", "Shaoting", ""], ["Wang", "Xiaogang", ""], ["Huang", "Xiaolei", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1710.10919", "submitter": "Patrick Heas", "authors": "Patrick H\\'eas and C\\'edric Herzet and Benoit Comb\\`es", "title": "Non-Linear Reduced Modeling by Generalized Kernel-Based Dynamic Mode\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced modeling of a computationally demanding dynamical system aims at\napproximating its trajectories, while optimizing the trade-off between accuracy\nand computational complexity. In this work, we propose to achieve such an\napproximation by first embedding the trajectories in a reproducing kernel\nHilbert space (RKHS), which exhibits appealing approximation and computational\ncapabilities, and then solving the associated reduced model problem. More\nspecifically, we propose a new efficient algorithm for data-driven reduced\nmodeling of non-linear dynamics based on linear approximations in a RKHS. This\nalgorithm takes advantage of the closed-form solution of a low-rank constraint\noptimization problem while exploiting advantageously kernel-based computations.\nReduced modeling with this algorithm reveals a gain in approximation accuracy,\nas shown by numerical simulations, and in complexity with respect to existing\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 13:06:19 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 13:18:37 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 10:44:48 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 16:18:29 GMT"}, {"version": "v5", "created": "Fri, 21 Feb 2020 13:58:06 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["H\u00e9as", "Patrick", ""], ["Herzet", "C\u00e9dric", ""], ["Comb\u00e8s", "Benoit", ""]]}, {"id": "1710.10928", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen and Matthias Hein", "title": "Optimization Landscape and Expressivity of Deep CNNs", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the loss landscape and expressiveness of practical deep\nconvolutional neural networks (CNNs) with shared weights and max pooling\nlayers. We show that such CNNs produce linearly independent features at a\n\"wide\" layer which has more neurons than the number of training samples. This\ncondition holds e.g. for the VGG network. Furthermore, we provide for such wide\nCNNs necessary and sufficient conditions for global minima with zero training\nerror. For the case where the wide layer is followed by a fully connected layer\nwe show that almost every critical point of the empirical loss is a global\nminimum with zero training error. Our analysis suggests that both depth and\nwidth are very important in deep learning. While depth brings more\nrepresentational power and allows the network to learn high level features,\nwidth smoothes the optimization landscape of the loss function in the sense\nthat a sufficiently wide network has a well-behaved loss surface with almost no\nbad local minima.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 13:24:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 12:49:58 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Nguyen", "Quynh", ""], ["Hein", "Matthias", ""]]}, {"id": "1710.10944", "submitter": "Yuan Zeng", "authors": "Yuan Zeng, Kevin Devincentis, Yao Xiao, Zubayer Ibne Ferdous, Xiaochen\n  Guo, Zhiyuan Yan, Yevgeny Berdichevsky", "title": "A Supervised STDP-based Training Algorithm for Living Neural Networks", "comments": "5 pages, 3 figures, Accepted by ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have shown great potential in many applications like speech\nrecognition, drug discovery, image classification, and object detection. Neural\nnetwork models are inspired by biological neural networks, but they are\noptimized to perform machine learning tasks on digital computers. The proposed\nwork explores the possibilities of using living neural networks in vitro as\nbasic computational elements for machine learning applications. A new\nsupervised STDP-based learning algorithm is proposed in this work, which\nconsiders neuron engineering constrains. A 74.7% accuracy is achieved on the\nMNIST benchmark for handwritten digit recognition.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 13:55:59 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 18:50:59 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 18:21:55 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Zeng", "Yuan", ""], ["Devincentis", "Kevin", ""], ["Xiao", "Yao", ""], ["Ferdous", "Zubayer Ibne", ""], ["Guo", "Xiaochen", ""], ["Yan", "Zhiyuan", ""], ["Berdichevsky", "Yevgeny", ""]]}, {"id": "1710.10951", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai", "title": "SGDLibrary: A MATLAB library for stochastic gradient descent algorithms", "comments": null, "journal-ref": "Journal of Machine Learning Research, vol.18, no.215, pp.1-5, 2018", "doi": null, "report-no": null, "categories": "cs.MS stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding the minimizer of a function $f:\n\\mathbb{R}^d \\rightarrow \\mathbb{R}$ of the finite-sum form $\\min f(w) =\n1/n\\sum_{i}^n f_i(w)$. This problem has been studied intensively in recent\nyears in the field of machine learning (ML). One promising approach for\nlarge-scale data is to use a stochastic optimization algorithm to solve the\nproblem. SGDLibrary is a readable, flexible and extensible pure-MATLAB library\nof a collection of stochastic optimization algorithms. The purpose of the\nlibrary is to provide researchers and implementers a comprehensive evaluation\nenvironment for the use of these algorithms on various ML problems.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 07:42:06 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 23:32:35 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Kasai", "Hiroyuki", ""]]}, {"id": "1710.11004", "submitter": "Akisato Kimura", "authors": "Masaya Hibino, Akisato Kimura, Takayoshi Yamashita, Yuji Yamauchi,\n  Hironobu Fujiyoshi", "title": "Denoising random forests", "comments": "20 pages, 10 figures, submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel type of random forests called a denoising random\nforests that are robust against noises contained in test samples. Such\nnoise-corrupted samples cause serious damage to the estimation performances of\nrandom forests, since unexpected child nodes are often selected and the leaf\nnodes that the input sample reaches are sometimes far from those for a clean\nsample. Our main idea for tackling this problem originates from a binary\nindicator vector that encodes a traversal path of a sample in the forest. Our\nproposed method effectively employs this vector by introducing denoising\nautoencoders into random forests. A denoising autoencoder can be trained with\nindicator vectors produced from clean and noisy input samples, and non-leaf\nnodes where incorrect decisions are made can be identified by comparing the\ninput and output of the trained denoising autoencoder. Multiple traversal paths\nwith respect to the nodes with incorrect decisions caused by the noises can\nthen be considered for the estimation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 15:16:51 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Hibino", "Masaya", ""], ["Kimura", "Akisato", ""], ["Yamashita", "Takayoshi", ""], ["Yamauchi", "Yuji", ""], ["Fujiyoshi", "Hironobu", ""]]}, {"id": "1710.11029", "submitter": "Pratik Chaudhari", "authors": "Pratik Chaudhari, Stefano Soatto", "title": "Stochastic gradient descent performs variational inference, converges to\n  limit cycles for deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is widely believed to perform implicit\nregularization when used to train deep neural networks, but the precise manner\nin which this occurs has thus far been elusive. We prove that SGD minimizes an\naverage potential over the posterior distribution of weights along with an\nentropic regularization term. This potential is however not the original loss\nfunction in general. So SGD does perform variational inference, but for a\ndifferent loss than the one used to compute the gradients. Even more\nsurprisingly, SGD does not even converge in the classical sense: we show that\nthe most likely trajectories of SGD for deep networks do not behave like\nBrownian motion around critical points. Instead, they resemble closed loops\nwith deterministic components. We prove that such \"out-of-equilibrium\" behavior\nis a consequence of highly non-isotropic gradient noise in SGD; the covariance\nmatrix of mini-batch gradients for deep networks has a rank as small as 1% of\nits dimension. We provide extensive empirical validation of these claims,\nproven in the appendix.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 15:58:18 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 08:04:21 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Chaudhari", "Pratik", ""], ["Soatto", "Stefano", ""]]}, {"id": "1710.11052", "submitter": "Dmitrij Schlesinger", "authors": "Dmitrij Schlesinger", "title": "A Connection between Feed-Forward Neural Networks and Probabilistic\n  Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two of the most popular modelling paradigms in computer vision are\nfeed-forward neural networks (FFNs) and probabilistic graphical models (GMs).\nVarious connections between the two have been studied in recent works, such as\ne.g. expressing mean-field based inference in a GM as an FFN. This paper\nestablishes a new connection between FFNs and GMs. Our key observation is that\nany FFN implements a certain approximation of a corresponding Bayesian network\n(BN). We characterize various benefits of having this connection. In\nparticular, it results in a new learning algorithm for BNs. We validate the\nproposed methods for a classification problem on CIFAR-10 dataset and for\nbinary image segmentation on Weizmann Horse dataset. We show that statistically\nlearned BNs improve performance, having at the same time essentially better\ngeneralization capability, than their FFN counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 16:31:24 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Schlesinger", "Dmitrij", ""]]}, {"id": "1710.11070", "submitter": "Yining Wang", "authors": "Yining Wang", "title": "Convergence Rates of Latent Topic Models Under Relaxed Identifiability\n  Conditions", "comments": "26 pages, 1 table. Added significantly more expositions, and a\n  numerical procedure to check the order of degeneracy. Proofs slightly altered\n  with explicit constants given at various places", "journal-ref": "Electronic Journal of Statistics, 13(1):37-66, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the frequentist convergence rate for the Latent\nDirichlet Allocation (Blei et al., 2003) topic models. We show that the maximum\nlikelihood estimator converges to one of the finitely many equivalent\nparameters in Wasserstein's distance metric at a rate of $n^{-1/4}$ without\nassuming separability or non-degeneracy of the underlying topics and/or the\nexistence of more than three words per document, thus generalizing the previous\nworks of Anandkumar et al. (2012, 2014) from an information-theoretical\nperspective. We also show that the $n^{-1/4}$ convergence rate is optimal in\nthe worst case.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 17:05:28 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 21:35:57 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Wang", "Yining", ""]]}, {"id": "1710.11153", "submitter": "Curtis Hawthorne", "authors": "Curtis Hawthorne, Erich Elsen, Jialin Song, Adam Roberts, Ian Simon,\n  Colin Raffel, Jesse Engel, Sageev Oore, Douglas Eck", "title": "Onsets and Frames: Dual-Objective Piano Transcription", "comments": "Examples available at https://goo.gl/magenta/onsets-frames-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We advance the state of the art in polyphonic piano music transcription by\nusing a deep convolutional and recurrent neural network which is trained to\njointly predict onsets and frames. Our model predicts pitch onset events and\nthen uses those predictions to condition framewise pitch predictions. During\ninference, we restrict the predictions from the framewise detector by not\nallowing a new note to start unless the onset detector also agrees that an\nonset for that pitch is present in the frame. We focus on improving onsets and\noffsets together instead of either in isolation as we believe this correlates\nbetter with human musical perception. Our approach results in over a 100%\nrelative improvement in note F1 score (with offsets) on the MAPS dataset.\nFurthermore, we extend the model to predict relative velocities of normalized\naudio which results in more natural-sounding transcriptions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 18:05:49 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 04:20:28 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Hawthorne", "Curtis", ""], ["Elsen", "Erich", ""], ["Song", "Jialin", ""], ["Roberts", "Adam", ""], ["Simon", "Ian", ""], ["Raffel", "Colin", ""], ["Engel", "Jesse", ""], ["Oore", "Sageev", ""], ["Eck", "Douglas", ""]]}, {"id": "1710.11176", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Nishant Vishwamitra, Hongxin Hu, Feng Luo", "title": "CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble\n  Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new deep convolutional neural network, CrescendoNet, by\nstacking simple building blocks without residual connections. Each Crescendo\nblock contains independent convolution paths with increased depths. The numbers\nof convolution layers and parameters are only increased linearly in Crescendo\nblocks. In experiments, CrescendoNet with only 15 layers outperforms almost all\nnetworks without residual connections on benchmark datasets, CIFAR10, CIFAR100,\nand SVHN. Given sufficient amount of data as in SVHN dataset, CrescendoNet with\n15 layers and 4.1M parameters can match the performance of DenseNet-BC with 250\nlayers and 15.3M parameters. CrescendoNet provides a new way to construct high\nperformance deep convolutional neural networks without residual connections.\nMoreover, through investigating the behavior and performance of subnetworks in\nCrescendoNet, we note that the high performance of CrescendoNet may come from\nits implicit ensemble behavior, which differs from the FractalNet that is also\na deep convolutional neural network without residual connections. Furthermore,\nthe independence between paths in CrescendoNet allows us to introduce a new\npath-wise training procedure, which can reduce the memory needed for training.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 18:35:01 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 17:01:21 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Zhang", "Xiang", ""], ["Vishwamitra", "Nishant", ""], ["Hu", "Hongxin", ""], ["Luo", "Feng", ""]]}, {"id": "1710.11198", "submitter": "Yihao Feng", "authors": "Hao Liu, Yihao Feng, Yi Mao, Dengyong Zhou, Jian Peng, Qiang Liu", "title": "Action-depedent Control Variates for Policy Optimization via Stein's\n  Identity", "comments": "The first two authors contributed equally. Author ordering determined\n  by coin flip over a Google Hangout. Accepted by ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have achieved remarkable successes in solving\nchallenging reinforcement learning problems. However, it still often suffers\nfrom the large variance issue on policy gradient estimation, which leads to\npoor sample efficiency during training. In this work, we propose a control\nvariate method to effectively reduce variance for policy gradient methods.\nMotivated by the Stein's identity, our method extends the previous control\nvariate methods used in REINFORCE and advantage actor-critic by introducing\nmore general action-dependent baseline functions. Empirical studies show that\nour method significantly improves the sample efficiency of the state-of-the-art\npolicy gradient approaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 19:03:48 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 21:33:17 GMT"}, {"version": "v3", "created": "Fri, 10 Nov 2017 04:06:07 GMT"}, {"version": "v4", "created": "Fri, 23 Feb 2018 07:10:10 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Liu", "Hao", ""], ["Feng", "Yihao", ""], ["Mao", "Yi", ""], ["Zhou", "Dengyong", ""], ["Peng", "Jian", ""], ["Liu", "Qiang", ""]]}, {"id": "1710.11205", "submitter": "Yi Zhou", "authors": "Yi Zhou and Yingbin Liang", "title": "Critical Points of Neural Networks: Analytical Forms and Landscape\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the success of deep learning to solving a variety of challenging\nmachine learning tasks, there is a rising interest in understanding loss\nfunctions for training neural networks from a theoretical aspect. Particularly,\nthe properties of critical points and the landscape around them are of\nimportance to determine the convergence performance of optimization algorithms.\nIn this paper, we provide full (necessary and sufficient) characterization of\nthe analytical forms for the critical points (as well as global minimizers) of\nthe square loss functions for various neural networks. We show that the\nanalytical forms of the critical points characterize the values of the\ncorresponding loss functions as well as the necessary and sufficient conditions\nto achieve global minimum. Furthermore, we exploit the analytical forms of the\ncritical points to characterize the landscape properties for the loss functions\nof these neural networks. One particular conclusion is that: The loss function\nof linear networks has no spurious local minimum, while the loss function of\none-hidden-layer nonlinear networks with ReLU activation function does have\nlocal minimum that is not global minimum.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 19:18:43 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Zhou", "Yi", ""], ["Liang", "Yingbin", ""]]}, {"id": "1710.11214", "submitter": "Allison Chaney", "authors": "Allison J.B. Chaney, Brandon M. Stewart, Barbara E. Engelhardt", "title": "How Algorithmic Confounding in Recommendation Systems Increases\n  Homogeneity and Decreases Utility", "comments": null, "journal-ref": null, "doi": "10.1145/3240323.3240370", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are ubiquitous and impact many domains; they have the\npotential to influence product consumption, individuals' perceptions of the\nworld, and life-altering decisions. These systems are often evaluated or\ntrained with data from users already exposed to algorithmic recommendations;\nthis creates a pernicious feedback loop. Using simulations, we demonstrate how\nusing data confounded in this way homogenizes user behavior without increasing\nutility.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 19:42:02 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 01:58:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Chaney", "Allison J. B.", ""], ["Stewart", "Brandon M.", ""], ["Engelhardt", "Barbara E.", ""]]}, {"id": "1710.11223", "submitter": "Yanjun  Qi Dr.", "authors": "Beilun Wang and Arshdeep Sekhon and Yanjun Qi", "title": "Fast and Scalable Learning of Sparse Changes in High-Dimensional\n  Gaussian Graphical Model Structure", "comments": "20pages, 6 figures, 10 tables; at AISTAT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of estimating the change in the dependency structures\nof two $p$-dimensional Gaussian Graphical models (GGMs). Previous studies for\nsparse change estimation in GGMs involve expensive and difficult non-smooth\noptimization. We propose a novel method, DIFFEE for estimating DIFFerential\nnetworks via an Elementary Estimator under a high-dimensional situation. DIFFEE\nis solved through a faster and closed form solution that enables it to work in\nlarge-scale settings. We conduct a rigorous statistical analysis showing that\nsurprisingly DIFFEE achieves the same asymptotic convergence rates as the\nstate-of-the-art estimators that are much more difficult to compute. Our\nexperimental results on multiple synthetic datasets and one real-world data\nabout brain connectivity show strong performance improvements over baselines,\nas well as significant computational benefits.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 20:15:20 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 16:14:25 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 17:57:26 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Wang", "Beilun", ""], ["Sekhon", "Arshdeep", ""], ["Qi", "Yanjun", ""]]}, {"id": "1710.11238", "submitter": "Yanjun  Qi Dr.", "authors": "Jack Lanchantin, Arshdeep Sekhon, Ritambhara Singh, Yanjun Qi", "title": "Prototype Matching Networks for Large-Scale Multi-label Genomic Sequence\n  Classification", "comments": "15 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental tasks in understanding genomics is the problem of\npredicting Transcription Factor Binding Sites (TFBSs). With more than hundreds\nof Transcription Factors (TFs) as labels, genomic-sequence based TFBS\nprediction is a challenging multi-label classification task. There are two\nmajor biological mechanisms for TF binding: (1) sequence-specific binding\npatterns on genomes known as \"motifs\" and (2) interactions among TFs known as\nco-binding effects. In this paper, we propose a novel deep architecture, the\nPrototype Matching Network (PMN) to mimic the TF binding mechanisms. Our PMN\nmodel automatically extracts prototypes (\"motif\"-like features) for each TF\nthrough a novel prototype-matching loss. Borrowing ideas from few-shot matching\nmodels, we use the notion of support set of prototypes and an LSTM to learn how\nTFs interact and bind to genomic sequences. On a reference TFBS dataset with\n$2.1$ $million$ genomic sequences, PMN significantly outperforms baselines and\nvalidates our design choices empirically. To our knowledge, this is the first\ndeep learning architecture that introduces prototype learning and considers\nTF-TF interactions for large-scale TFBS prediction. Not only is the proposed\narchitecture accurate, but it also models the underlying biology.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 21:04:49 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 16:47:26 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Lanchantin", "Jack", ""], ["Sekhon", "Arshdeep", ""], ["Singh", "Ritambhara", ""], ["Qi", "Yanjun", ""]]}, {"id": "1710.11239", "submitter": "Christoph Wehmeyer", "authors": "Christoph Wehmeyer and Frank No\\'e", "title": "Time-lagged autoencoders: Deep learning of slow collective variables for\n  molecular kinetics", "comments": null, "journal-ref": null, "doi": "10.1063/1.5011399", "report-no": null, "categories": "stat.ML cs.LG physics.bio-ph physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of deep learning techniques in the physical and\nchemical sciences, we apply a modification of an autoencoder type deep neural\nnetwork to the task of dimension reduction of molecular dynamics data. We can\nshow that our time-lagged autoencoder reliably finds low-dimensional embeddings\nfor high-dimensional feature spaces which capture the slow dynamics of the\nunderlying stochastic processes - beyond the capabilities of linear dimension\nreduction techniques.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 21:06:11 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Wehmeyer", "Christoph", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1710.11253", "submitter": "Pavel Kolev", "authors": "Karl Bringmann, Pavel Kolev, David P. Woodruff", "title": "Approximation Algorithms for $\\ell_0$-Low Rank Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $\\ell_0$-Low Rank Approximation Problem, where the goal is,\ngiven an $m \\times n$ matrix $A$, to output a rank-$k$ matrix $A'$ for which\n$\\|A'-A\\|_0$ is minimized. Here, for a matrix $B$, $\\|B\\|_0$ denotes the number\nof its non-zero entries. This NP-hard variant of low rank approximation is\nnatural for problems with no underlying metric, and its goal is to minimize the\nnumber of disagreeing data positions. We provide approximation algorithms which\nsignificantly improve the running time and approximation factor of previous\nwork. For $k > 1$, we show how to find, in poly$(mn)$ time for every $k$, a\nrank $O(k \\log(n/k))$ matrix $A'$ for which $\\|A'-A\\|_0 \\leq O(k^2 \\log(n/k))\n\\mathrm{OPT}$. To the best of our knowledge, this is the first algorithm with\nprovable guarantees for the $\\ell_0$-Low Rank Approximation Problem for $k >\n1$, even for bicriteria algorithms. For the well-studied case when $k = 1$, we\ngive a $(2+\\epsilon)$-approximation in {\\it sublinear time}, which is\nimpossible for other variants of low rank approximation such as for the\nFrobenius norm. We strengthen this for the well-studied case of binary matrices\nto obtain a $(1+O(\\psi))$-approximation in sublinear time, where $\\psi =\n\\mathrm{OPT}/\\lVert A\\rVert_0$. For small $\\psi$, our approximation factor is\n$1+o(1)$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 21:49:48 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 15:06:01 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Bringmann", "Karl", ""], ["Kolev", "Pavel", ""], ["Woodruff", "David P.", ""]]}, {"id": "1710.11258", "submitter": "Raghu Bollapragada", "authors": "Raghu Bollapragada, Richard Byrd and Jorge Nocedal", "title": "Adaptive Sampling Strategies for Stochastic Optimization", "comments": "32 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a stochastic optimization method that adaptively\ncontrols the sample size used in the computation of gradient approximations.\nUnlike other variance reduction techniques that either require additional\nstorage or the regular computation of full gradients, the proposed method\nreduces variance by increasing the sample size as needed. The decision to\nincrease the sample size is governed by an inner product test that ensures that\nsearch directions are descent directions with high probability. We show that\nthe inner product test improves upon the well known norm test, and can be used\nas a basis for an algorithm that is globally convergent on nonconvex functions\nand enjoys a global linear rate of convergence on strongly convex functions.\nNumerical experiments on logistic regression problems illustrate the\nperformance of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 22:01:56 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Bollapragada", "Raghu", ""], ["Byrd", "Richard", ""], ["Nocedal", "Jorge", ""]]}, {"id": "1710.11260", "submitter": "Yik Chau Lui", "authors": "Kry Yik Chau Lui, Yanshuai Cao, Maxime Gazeau, Kelvin Shuangjian Zhang", "title": "Implicit Manifold Learning on Generative Adversarial Networks", "comments": null, "journal-ref": "ICML 2017 Workshop on Implicit Models", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper raises an implicit manifold learning perspective in Generative\nAdversarial Networks (GANs), by studying how the support of the learned\ndistribution, modelled as a submanifold $\\mathcal{M}_{\\theta}$, perfectly match\nwith $\\mathcal{M}_{r}$, the support of the real data distribution. We show that\noptimizing Jensen-Shannon divergence forces $\\mathcal{M}_{\\theta}$ to perfectly\nmatch with $\\mathcal{M}_{r}$, while optimizing Wasserstein distance does not.\nOn the other hand, by comparing the gradients of the Jensen-Shannon divergence\nand the Wasserstein distances ($W_1$ and $W_2^2$) in their primal forms, we\nconjecture that Wasserstein $W_2^2$ may enjoy desirable properties such as\nreduced mode collapse. It is therefore interesting to design new distances that\ninherit the best from both distances.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 22:11:29 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Lui", "Kry Yik Chau", ""], ["Cao", "Yanshuai", ""], ["Gazeau", "Maxime", ""], ["Zhang", "Kelvin Shuangjian", ""]]}, {"id": "1710.11268", "submitter": "Ye Zhang", "authors": "Anderson Y. Zhang and Harrison H. Zhou", "title": "Theoretical and Computational Guarantees of Mean Field Variational\n  Inference for Community Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean field variational Bayes method is becoming increasingly popular in\nstatistics and machine learning. Its iterative Coordinate Ascent Variational\nInference algorithm has been widely applied to large scale Bayesian inference.\nSee Blei et al. (2017) for a recent comprehensive review. Despite the\npopularity of the mean field method there exist remarkably little fundamental\ntheoretical justifications. To the best of our knowledge, the iterative\nalgorithm has never been investigated for any high dimensional and complex\nmodel. In this paper, we study the mean field method for community detection\nunder the Stochastic Block Model. For an iterative Batch Coordinate Ascent\nVariational Inference algorithm, we show that it has a linear convergence rate\nand converges to the minimax rate within $\\log n$ iterations. This complements\nthe results of Bickel et al. (2013) which studied the global minimum of the\nmean field variational Bayes and obtained asymptotic normal estimation of\nglobal model parameters. In addition, we obtain similar optimality results for\nGibbs sampling and an iterative procedure to calculate maximum likelihood\nestimation, which can be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 23:29:52 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 03:18:08 GMT"}, {"version": "v3", "created": "Mon, 11 Dec 2017 18:14:32 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Zhang", "Anderson Y.", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1710.11272", "submitter": "Giovanni Alcantara", "authors": "Giovanni Alcantara", "title": "Empirical analysis of non-linear activation functions for Deep Neural\n  Networks in classification tasks", "comments": "7 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an overview of several non-linear activation functions in a neural\nnetwork architecture that have proven successful in many machine learning\napplications. We conduct an empirical analysis on the effectiveness of using\nthese function on the MNIST classification task, with the aim of clarifying\nwhich functions produce the best results overall. Based on this first set of\nresults, we examine the effects of building deeper architectures with an\nincreasing number of hidden layers. We also survey the impact of using, on the\nsame task, different initialisation schemes for the weights of our neural\nnetwork. Using these sets of experiments as a base, we conclude by providing a\noptimal neural network architecture that yields impressive results in accuracy\non the MNIST classification task.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 23:45:57 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Alcantara", "Giovanni", ""]]}, {"id": "1710.11278", "submitter": "Boris Hanin", "authors": "Boris Hanin, Mark Sellke", "title": "Approximating Continuous Functions by ReLU Nets of Minimal Width", "comments": "v2. 13p. Extended main result to higher dimensional output. Comments\n  welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article concerns the expressive power of depth in deep feed-forward\nneural nets with ReLU activations. Specifically, we answer the following\nquestion: for a fixed $d_{in}\\geq 1,$ what is the minimal width $w$ so that\nneural nets with ReLU activations, input dimension $d_{in}$, hidden layer\nwidths at most $w,$ and arbitrary depth can approximate any continuous,\nreal-valued function of $d_{in}$ variables arbitrarily well? It turns out that\nthis minimal width is exactly equal to $d_{in}+1.$ That is, if all the hidden\nlayer widths are bounded by $d_{in}$, then even in the infinite depth limit,\nReLU nets can only express a very limited class of functions, and, on the other\nhand, any continuous function on the $d_{in}$-dimensional unit cube can be\napproximated to arbitrary precision by ReLU nets in which all hidden layers\nhave width exactly $d_{in}+1.$ Our construction in fact shows that any\ncontinuous function $f:[0,1]^{d_{in}}\\to\\mathbb R^{d_{out}}$ can be\napproximated by a net of width $d_{in}+d_{out}$. We obtain quantitative depth\nestimates for such an approximation in terms of the modulus of continuity of\n$f$.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 00:26:56 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 21:47:40 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Hanin", "Boris", ""], ["Sellke", "Mark", ""]]}, {"id": "1710.11298", "submitter": "Dong Xia", "authors": "Dong Xia and Ming Yuan", "title": "Effective Tensor Sketching via Sparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT cs.NA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate effective sketching schemes via sparsification\nfor high dimensional multilinear arrays or tensors. More specifically, we\npropose a novel tensor sparsification algorithm that retains a subset of the\nentries of a tensor in a judicious way, and prove that it can attain a given\nlevel of approximation accuracy in terms of tensor spectral norm with a much\nsmaller sample complexity when compared with existing approaches. In\nparticular, we show that for a $k$th order $d\\times\\cdots\\times d$ cubic tensor\nof {\\it stable rank} $r_s$, the sample size requirement for achieving a\nrelative error $\\varepsilon$ is, up to a logarithmic factor, of the order\n$r_s^{1/2} d^{k/2} /\\varepsilon$ when $\\varepsilon$ is relatively large, and\n$r_s d /\\varepsilon^2$ and essentially optimal when $\\varepsilon$ is\nsufficiently small. It is especially noteworthy that the sample size\nrequirement for achieving a high accuracy is of an order independent of $k$. To\nfurther demonstrate the utility of our techniques, we also study how higher\norder singular value decomposition (HOSVD) of large tensors can be efficiently\napproximated via sparsification.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 02:04:39 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 15:31:16 GMT"}, {"version": "v3", "created": "Thu, 16 Nov 2017 14:20:51 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Xia", "Dong", ""], ["Yuan", "Ming", ""]]}, {"id": "1710.11303", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias and Frank Stephan", "title": "Algorithmic learning of probability distributions from random data in\n  the limit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying a probability distribution for some given\nrandomly sampled data in the limit, in the context of algorithmic learning\ntheory as proposed recently by Vinanyi and Chater. We show that there exists a\ncomputable partial learner for the computable probability measures, while by\nBienvenu, Monin and Shen it is known that there is no computable learner for\nthe computable probability measures. Our main result is the characterization of\nthe oracles that compute explanatory learners for the computable (continuous)\nprobability measures as the high oracles. This provides an analogue of a\nwell-known result of Adleman and Blum in the context of learning computable\nprobability distributions. We also discuss related learning notions such as\nbehaviorally correct learning and orther variations of explanatory learning, in\nthe context of learning probability distributions from data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 02:35:04 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 10:17:12 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 05:35:10 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Barmpalias", "George", ""], ["Stephan", "Frank", ""]]}, {"id": "1710.11304", "submitter": "Aaron Clauset", "authors": "Kansuke Ikehara and Aaron Clauset", "title": "Characterizing the structural diversity of complex networks across\n  domains", "comments": "23 pages, 11 figures, 2 tables; originally published as K. Ikehara,\n  \"The Structure of Complex Networks across Domains.\" MS Thesis, University of\n  Colorado Boulder (2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.data-an q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure of complex networks has been of interest in many scientific and\nengineering disciplines over the decades. A number of studies in the field have\nbeen focused on finding the common properties among different kinds of networks\nsuch as heavy-tail degree distribution, small-worldness and modular structure\nand they have tried to establish a theory of structural universality in complex\nnetworks. However, there is no comprehensive study of network structure across\na diverse set of domains in order to explain the structural diversity we\nobserve in the real-world networks. In this paper, we study 986 real-world\nnetworks of diverse domains ranging from ecological food webs to online social\nnetworks along with 575 networks generated from four popular network models.\nOur study utilizes a number of machine learning techniques such as random\nforest and confusion matrix in order to show the relationships among network\ndomains in terms of network structure. Our results indicate that there are some\npartitions of network categories in which networks are hard to distinguish\nbased purely on network structure. We have found that these partitions of\nnetwork categories tend to have similar underlying functions, constraints\nand/or generative mechanisms of networks even though networks in the same\npartition have different origins, e.g., biological processes, results of\nengineering by human being, etc. This suggests that the origin of a network,\nwhether it's biological, technological or social, may not necessarily be a\ndecisive factor of the formation of similar network structure. Our findings\nshed light on the possible direction along which we could uncover the hidden\nprinciples for the structural diversity of complex networks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 02:35:13 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Ikehara", "Kansuke", ""], ["Clauset", "Aaron", ""]]}, {"id": "1710.11306", "submitter": "Panos P. Markopoulos", "authors": "Panos P. Markopoulos, Dimitris G. Chachlakis, and Evangelos E.\n  Papalexakis", "title": "The Exact Solution to Rank-1 L1-norm TUCKER2 Decomposition", "comments": "This is a preprint; An edited/finalized version of this manuscript\n  has been submitted for publication to IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2018.2790901", "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study rank-1 {L1-norm-based TUCKER2} (L1-TUCKER2) decomposition of 3-way\ntensors, treated as a collection of $N$ $D \\times M$ matrices that are to be\njointly decomposed. Our contributions are as follows. i) We prove that the\nproblem is equivalent to combinatorial optimization over $N$ antipodal-binary\nvariables. ii) We derive the first two algorithms in the literature for its\nexact solution. The first algorithm has cost exponential in $N$; the second one\nhas cost polynomial in $N$ (under a mild assumption). Our algorithms are\naccompanied by formal complexity analysis. iii) We conduct numerical studies to\ncompare the performance of exact L1-TUCKER2 (proposed) with standard HOSVD,\nHOOI, GLRAM, PCA, L1-PCA, and TPCA-L1. Our studies show that L1-TUCKER2\noutperforms (in tensor approximation) all the above counterparts when the\nprocessed data are outlier corrupted.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 03:01:35 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Markopoulos", "Panos P.", ""], ["Chachlakis", "Dimitris G.", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1710.11315", "submitter": "Morteza Noshad", "authors": "Morteza Noshad Iranzad and Alfred O. Hero III", "title": "Rate-optimal Meta Learning of Classification Error", "comments": "Submitted to ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta learning of optimal classifier error rates allows an experimenter to\nempirically estimate the intrinsic ability of any estimator to discriminate\nbetween two populations, circumventing the difficult problem of estimating the\noptimal Bayes classifier. To this end we propose a weighted nearest neighbor\n(WNN) graph estimator for a tight bound on the Bayes classification error; the\nHenze-Penrose (HP) divergence. Similar to recently proposed HP estimators\n[berisha2016], the proposed estimator is non-parametric and does not require\ndensity estimation. However, unlike previous approaches the proposed estimator\nis rate-optimal, i.e., its mean squared estimation error (MSEE) decays to zero\nat the fastest possible rate of $O(1/M+1/N)$ where $M,N$ are the sample sizes\nof the respective populations. We illustrate the proposed WNN meta estimator\nfor several simulated and real data sets.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 03:52:56 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Iranzad", "Morteza Noshad", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1710.11345", "submitter": "Rose Yu", "authors": "Rose Yu, Guangyu Li, Yan Liu", "title": "Tensor Regression Meets Gaussian Processes", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank tensor regression, a new model class that learns high-order\ncorrelation from data, has recently received considerable attention. At the\nsame time, Gaussian processes (GP) are well-studied machine learning models for\nstructure learning. In this paper, we demonstrate interesting connections\nbetween the two, especially for multi-way data analysis. We show that low-rank\ntensor regression is essentially learning a multi-linear kernel in Gaussian\nprocesses, and the low-rank assumption translates to the constrained Bayesian\ninference problem. We prove the oracle inequality and derive the average case\nlearning curve for the equivalent GP model. Our finding implies that low-rank\ntensor regression, though empirically successful, is highly dependent on the\neigenvalues of covariance functions as well as variable correlations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 06:44:59 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Yu", "Rose", ""], ["Li", "Guangyu", ""], ["Liu", "Yan", ""]]}, {"id": "1710.11379", "submitter": "Georgios Arvanitidis", "authors": "Georgios Arvanitidis, Lars Kai Hansen, S{\\o}ren Hauberg", "title": "Latent Space Oddity: on the Curvature of Deep Generative Models", "comments": "Accepted at International Conference on Learning Representations\n  (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models provide a systematic way to learn nonlinear data\ndistributions, through a set of latent variables and a nonlinear \"generator\"\nfunction that maps latent points into the input space. The nonlinearity of the\ngenerator imply that the latent space gives a distorted view of the input\nspace. Under mild conditions, we show that this distortion can be characterized\nby a stochastic Riemannian metric, and demonstrate that distances and\ninterpolants are significantly improved under this metric. This in turn\nimproves probability distributions, sampling algorithms and clustering in the\nlatent space. Our geometric analysis further reveals that current generators\nprovide poor variance estimates and we propose a new generator architecture\nwith vastly improved variance estimates. Results are demonstrated on\nconvolutional and fully connected variational autoencoders, but the formalism\neasily generalize to other deep generative models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 09:10:10 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 16:00:28 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Arvanitidis", "Georgios", ""], ["Hansen", "Lars Kai", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "1710.11381", "submitter": "Yannic Kilcher", "authors": "Yannic Kilcher, Aurelien Lucchi, Thomas Hofmann", "title": "Semantic Interpolation in Implicit Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In implicit models, one often interpolates between sampled points in latent\nspace. As we show in this paper, care needs to be taken to match-up the\ndistributional assumptions on code vectors with the geometry of the\ninterpolating paths. Otherwise, typical assumptions about the quality and\nsemantics of in-between points may not be justified. Based on our analysis we\npropose to modify the prior code distribution to put significantly more\nprobability mass closer to the origin. As a result, linear interpolation paths\nare not only shortest paths, but they are also guaranteed to pass through\nhigh-density regions, irrespective of the dimensionality of the latent space.\nExperiments on standard benchmark image datasets demonstrate clear visual\nimprovements in the quality of the generated samples and exhibit more\nmeaningful interpolation paths.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 09:11:17 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 08:56:11 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 09:56:08 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Kilcher", "Yannic", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1710.11383", "submitter": "Yannic Kilcher", "authors": "Yannic Kilcher, Aurelien Lucchi, Thomas Hofmann", "title": "Flexible Prior Distributions for Deep Generative Models", "comments": "arXiv admin note: text overlap with arXiv:1707.09241", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training generative models with deep neural\nnetworks as generators, i.e. to map latent codes to data points. Whereas the\ndominant paradigm combines simple priors over codes with complex deterministic\nmodels, we argue that it might be advantageous to use more flexible code\ndistributions. We demonstrate how these distributions can be induced directly\nfrom the data. The benefits include: more powerful generative models, better\nmodeling of latent structure and explicit control of the degree of\ngeneralization.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 09:16:09 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 09:13:41 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Kilcher", "Yannic", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1710.11386", "submitter": "Yannic Kilcher", "authors": "Yannic Kilcher, Gary Becigneul, Thomas Hofmann", "title": "Parametrizing filters of a CNN with a GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly agreed that the use of relevant invariances as a good\nstatistical bias is important in machine-learning. However, most approaches\nthat explicitly incorporate invariances into a model architecture only make use\nof very simple transformations, such as translations and rotations. Hence,\nthere is a need for methods to model and extract richer transformations that\ncapture much higher-level invariances. To that end, we introduce a tool\nallowing to parametrize the set of filters of a trained convolutional neural\nnetwork with the latent space of a generative adversarial network. We then show\nthat the method can capture highly non-linear invariances of the data by\nvisualizing their effect in the data space.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 09:24:39 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Kilcher", "Yannic", ""], ["Becigneul", "Gary", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1710.11397", "submitter": "Andrew Warrington", "authors": "Andrew Warrington and Frank Wood", "title": "Updating the VESICLE-CNN Synapse Detector", "comments": "Submitted as two side extended abstract to NIPS 2017 workshop:\n  BigNeuro 2017: Analyzing brain data from nano to macroscale", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an updated version of the VESICLE-CNN algorithm presented by\nRoncal et al. (2014). The original implementation makes use of a patch-based\napproach. This methodology is known to be slow due to repeated computations. We\nupdate this implementation to be fully convolutional through the use of dilated\nconvolutions, recovering the expanded field of view achieved through the use of\nstrided maxpools, but without a degradation of spatial resolution. This updated\nimplementation performs as well as the original implementation, but with a\n$600\\times$ speedup at test time. We release source code and data into the\npublic domain.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 10:17:15 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Warrington", "Andrew", ""], ["Wood", "Frank", ""]]}, {"id": "1710.11417", "submitter": "Gregory Farquhar", "authors": "Gregory Farquhar, Tim Rockt\\\"aschel, Maximilian Igl, Shimon Whiteson", "title": "TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining deep model-free reinforcement learning with on-line planning is a\npromising approach to building on the successes of deep RL. On-line planning\nwith look-ahead trees has proven successful in environments where transition\nmodels are known a priori. However, in complex environments where transition\nmodels need to be learned from data, the deficiencies of learned models have\nlimited their utility for planning. To address these challenges, we propose\nTreeQN, a differentiable, recursive, tree-structured model that serves as a\ndrop-in replacement for any value function network in deep RL with discrete\nactions. TreeQN dynamically constructs a tree by recursively applying a\ntransition model in a learned abstract state space and then aggregating\npredicted rewards and state-values using a tree backup to estimate Q-values. We\nalso propose ATreeC, an actor-critic variant that augments TreeQN with a\nsoftmax layer to form a stochastic policy network. Both approaches are trained\nend-to-end, such that the learned model is optimised for its actual use in the\ntree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a\nbox-pushing task, as well as n-step DQN and value prediction networks (Oh et\nal. 2017) on multiple Atari games. Furthermore, we present ablation studies\nthat demonstrate the effect of different auxiliary losses on learning\ntransition models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 11:54:35 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 17:30:48 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Farquhar", "Gregory", ""], ["Rockt\u00e4schel", "Tim", ""], ["Igl", "Maximilian", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1710.11431", "submitter": "Anuj Karpatne", "authors": "Anuj Karpatne, William Watkins, Jordan Read, and Vipin Kumar", "title": "Physics-guided Neural Networks (PGNN): An Application in Lake\n  Temperature Modeling", "comments": "submitted to ACM SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel framework for combining scientific knowledge of\nphysics-based models with neural networks to advance scientific discovery. This\nframework, termed as physics-guided neural network (PGNN), leverages the output\nof physics-based model simulations along with observational features to\ngenerate predictions using a neural network architecture. Further, this paper\npresents a novel framework for using physics-based loss functions in the\nlearning objective of neural networks, to ensure that the model predictions not\nonly show lower errors on the training set but are also scientifically\nconsistent with the known physics on the unlabeled set. We illustrate the\neffectiveness of PGNN for the problem of lake temperature modeling, where\nphysical relationships between the temperature, density, and depth of water are\nused to design a physics-based loss function. By using scientific knowledge to\nguide the construction and learning of neural networks, we are able to show\nthat the proposed framework ensures better generalizability as well as\nscientific consistency of results.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:24:26 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 17:33:48 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Karpatne", "Anuj", ""], ["Watkins", "William", ""], ["Read", "Jordan", ""], ["Kumar", "Vipin", ""]]}, {"id": "1710.11438", "submitter": "Arthur Mensch", "authors": "Arthur Mensch (PARIETAL, NEUROSPIN), Julien Mairal (Thoth, LJK),\n  Danilo Bzdok, Bertrand Thirion (PARIETAL, NEUROSPIN), Ga\\\"el Varoquaux\n  (PARIETAL, NEUROSPIN)", "title": "Learning Neural Representations of Human Cognition across Many fMRI\n  Studies", "comments": "Advances in Neural Information Processing Systems, Dec 2017, Long\n  Beach, United States. 2017", "journal-ref": "Advances in Neural Information Processing Systems, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive neuroscience is enjoying rapid increase in extensive public\nbrain-imaging datasets. It opens the door to large-scale statistical models.\nFinding a unified perspective for all available data calls for scalable and\nautomated solutions to an old challenge: how to aggregate heterogeneous\ninformation on brain function into a universal cognitive system that relates\nmental operations/cognitive processes/psychological tasks to brain networks? We\ncast this challenge in a machine-learning approach to predict conditions from\nstatistical brain maps across different studies. For this, we leverage\nmulti-task learning and multi-scale dimension reduction to learn\nlow-dimensional representations of brain images that carry cognitive\ninformation and can be robustly associated with psychological stimuli. Our\nmulti-dataset classification model achieves the best prediction performance on\nseveral large reference datasets, compared to models without cognitive-aware\nlow-dimension representations, it brings a substantial performance boost to the\nanalysis of small datasets, and can be introspected to identify universal\ntemplate cognitive concepts.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:51:36 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 03:16:14 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mensch", "Arthur", "", "PARIETAL, NEUROSPIN"], ["Mairal", "Julien", "", "Thoth, LJK"], ["Bzdok", "Danilo", "", "PARIETAL, NEUROSPIN"], ["Thirion", "Bertrand", "", "PARIETAL, NEUROSPIN"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL, NEUROSPIN"]]}, {"id": "1710.11439", "submitter": "Yoshiaki Bando", "authors": "Yoshiaki Bando, Masato Mimura, Katsutoshi Itoyama, Kazuyoshi Yoshii,\n  Tatsuya Kawahara", "title": "Statistical Speech Enhancement Based on Probabilistic Integration of\n  Variational Autoencoder and Non-Negative Matrix Factorization", "comments": "5 pages, 3 figures, version that Eqs. (9), (19), and (20) in v2\n  (submitted to ICASSP 2018) are corrected. Samples available here:\n  http://sap.ist.i.kyoto-u.ac.jp/members/yoshiaki/demo/vae-nmf/", "journal-ref": null, "doi": "10.1109/ICASSP.2018.8461530", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a statistical method of single-channel speech enhancement\nthat uses a variational autoencoder (VAE) as a prior distribution on clean\nspeech. A standard approach to speech enhancement is to train a deep neural\nnetwork (DNN) to take noisy speech as input and output clean speech. Although\nthis supervised approach requires a very large amount of pair data for\ntraining, it is not robust against unknown environments. Another approach is to\nuse non-negative matrix factorization (NMF) based on basis spectra trained on\nclean speech in advance and those adapted to noise on the fly. This\nsemi-supervised approach, however, causes considerable signal distortion in\nenhanced speech due to the unrealistic assumption that speech spectrograms are\nlinear combinations of the basis spectra. Replacing the poor linear generative\nmodel of clean speech in NMF with a VAE---a powerful nonlinear deep generative\nmodel---trained on clean speech, we formulate a unified probabilistic\ngenerative model of noisy speech. Given noisy speech as observed data, we can\nsample clean speech from its posterior distribution. The proposed method\noutperformed the conventional DNN-based method in unseen noisy environments.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:52:09 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 04:58:48 GMT"}, {"version": "v3", "created": "Wed, 15 Nov 2017 11:57:51 GMT"}, {"version": "v4", "created": "Mon, 19 Mar 2018 07:04:46 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Bando", "Yoshiaki", ""], ["Mimura", "Masato", ""], ["Itoyama", "Katsutoshi", ""], ["Yoshii", "Kazuyoshi", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "1710.11469", "submitter": "Christina Heinze-Deml", "authors": "Christina Heinze-Deml and Nicolai Meinshausen", "title": "Conditional Variance Penalties and Domain Shift Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training a deep neural network for image classification, one can broadly\ndistinguish between two types of latent features of images that will drive the\nclassification. We can divide latent features into (i) \"core\" or \"conditionally\ninvariant\" features $X^\\text{core}$ whose distribution $X^\\text{core}\\vert Y$,\nconditional on the class $Y$, does not change substantially across domains and\n(ii) \"style\" features $X^{\\text{style}}$ whose distribution $X^{\\text{style}}\n\\vert Y$ can change substantially across domains. Examples for style features\ninclude position, rotation, image quality or brightness but also more complex\nones like hair color, image quality or posture for images of persons. Our goal\nis to minimize a loss that is robust under changes in the distribution of these\nstyle features. In contrast to previous work, we assume that the domain itself\nis not observed and hence a latent variable.\n  We do assume that we can sometimes observe a typically discrete identifier or\n\"$\\mathrm{ID}$ variable\". In some applications we know, for example, that two\nimages show the same person, and $\\mathrm{ID}$ then refers to the identity of\nthe person. The proposed method requires only a small fraction of images to\nhave $\\mathrm{ID}$ information. We group observations if they share the same\nclass and identifier $(Y,\\mathrm{ID})=(y,\\mathrm{id})$ and penalize the\nconditional variance of the prediction or the loss if we condition on\n$(Y,\\mathrm{ID})$. Using a causal framework, this conditional variance\nregularization (CoRe) is shown to protect asymptotically against shifts in the\ndistribution of the style variables. Empirically, we show that the CoRe penalty\nimproves predictive accuracy substantially in settings where domain changes\noccur in terms of image quality, brightness and color while we also look at\nmore complex changes such as changes in movement and posture.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 13:52:12 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 13:30:15 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 20:43:04 GMT"}, {"version": "v4", "created": "Tue, 8 May 2018 11:37:22 GMT"}, {"version": "v5", "created": "Sat, 13 Apr 2019 12:39:36 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Heinze-Deml", "Christina", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1710.11547", "submitter": "Natalia Ponomareva", "authors": "Natalia Ponomareva, Thomas Colthurst, Gilbert Hendry, Salem Haykal,\n  Soroush Radpour", "title": "Compact Multi-Class Boosted Trees", "comments": "Accepted for publication in IEEE Big Data 2017\n  http://cci.drexel.edu/bigdata/bigdata2017/AcceptedPapers.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted decision trees are a popular machine learning technique, in\npart because of their ability to give good accuracy with small models. We\ndescribe two extensions to the standard tree boosting algorithm designed to\nincrease this advantage. The first improvement extends the boosting formalism\nfrom scalar-valued trees to vector-valued trees. This allows individual trees\nto be used as multiclass classifiers, rather than requiring one tree per class,\nand drastically reduces the model size required for multiclass problems. We\nalso show that some other popular vector-valued gradient boosted trees\nmodifications fit into this formulation and can be easily obtained in our\nimplementation. The second extension, layer-by-layer boosting, takes smaller\nsteps in function space, which is empirically shown to lead to a faster\nconvergence and to a more compact ensemble. We have added both improvements to\nthe open-source TensorFlow Boosted trees (TFBT) package, and we demonstrate\ntheir efficacy on a variety of multiclass datasets. We expect these extensions\nwill be of particular interest to boosted tree applications that require small\nmodels, such as embedded devices, applications requiring fast inference, or\napplications desiring more interpretable models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 16:02:00 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Ponomareva", "Natalia", ""], ["Colthurst", "Thomas", ""], ["Hendry", "Gilbert", ""], ["Haykal", "Salem", ""], ["Radpour", "Soroush", ""]]}, {"id": "1710.11555", "submitter": "Natalia Ponomareva", "authors": "Natalia Ponomareva, Soroush Radpour, Gilbert Hendry, Salem Haykal,\n  Thomas Colthurst, Petr Mitrichev, Alexander Grushetsky", "title": "TF Boosted Trees: A scalable TensorFlow based framework for gradient\n  boosting", "comments": "European Conference on Machine Learning and Principles and Practice\n  of Knowledge Discovery in Databases (ECML PKDD 2017). The final publication\n  will be available at link.springer.com and is available on ECML website\n  http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TF Boosted Trees (TFBT) is a new open-sourced frame-work for the distributed\ntraining of gradient boosted trees. It is based on TensorFlow, and its\ndistinguishing features include a novel architecture, automatic loss\ndifferentiation, layer-by-layer boosting that results in smaller ensembles and\nfaster prediction, principled multi-class handling, and a number of\nregularization techniques to prevent overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 16:12:27 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Ponomareva", "Natalia", ""], ["Radpour", "Soroush", ""], ["Hendry", "Gilbert", ""], ["Haykal", "Salem", ""], ["Colthurst", "Thomas", ""], ["Mitrichev", "Petr", ""], ["Grushetsky", "Alexander", ""]]}, {"id": "1710.11577", "submitter": "Guokun Lai", "authors": "Guokun Lai, Hanxiao Liu, Yiming Yang", "title": "Learning Depthwise Separable Graph Convolution from Data Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Network (CNN) has gained tremendous success in computer\nvision tasks with its outstanding ability to capture the local latent features.\nRecently, there has been an increasing interest in extending convolution\noperations to the non-Euclidean geometry. Although various types of convolution\noperations have been proposed for graphs or manifolds, their connections with\ntraditional convolution over grid-structured data are not well-understood. In\nthis paper, we show that depthwise separable convolution can be successfully\ngeneralized for the unification of both graph-based and grid-based convolution\nmethods. Based on this insight we propose a novel Depthwise Separable Graph\nConvolution (DSGC) approach which is compatible with the tradition convolution\nnetwork and subsumes existing convolution methods as special cases. It is\nequipped with the combined strengths in model expressiveness, compatibility\n(relatively small number of parameters), modularity and computational\nefficiency in training. Extensive experiments show the outstanding performance\nof DSGC in comparison with strong baselines on multi-domain benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 16:48:12 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 18:32:25 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 05:58:53 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Lai", "Guokun", ""], ["Liu", "Hanxiao", ""], ["Yang", "Yiming", ""]]}, {"id": "1710.11595", "submitter": "Casey Kneale", "authors": "Casey Kneale, Steven D. Brown", "title": "Small Moving Window Calibration Models for Soft Sensing Processes with\n  Limited History", "comments": "Fixed many errors and improved clarity", "journal-ref": null, "doi": "10.1016/j.chemolab.2018.10.007", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Five simple soft sensor methodologies with two update conditions were\ncompared on two experimentally-obtained datasets and one simulated dataset. The\nsoft sensors investigated were moving window partial least squares regression\n(and a recursive variant), moving window random forest regression, the mean\nmoving window of $y$, and a novel random forest partial least squares\nregression ensemble (RF-PLS), all of which can be used with small sample sizes\nso that they can be rapidly placed online. It was found that, on two of the\ndatasets studied, small window sizes led to the lowest prediction errors for\nall of the moving window methods studied. On the majority of datasets studied,\nthe RF-PLS calibration method offered the lowest one-step-ahead prediction\nerrors compared to those of the other methods, and it demonstrated greater\npredictive stability at larger time delays than moving window PLS alone. It was\nfound that both the random forest and RF-PLS methods most adequately modeled\nthe datasets that did not feature purely monotonic increases in property\nvalues, but that both methods performed more poorly than moving window PLS\nmodels on one dataset with purely monotonic property values. Other data\ndependent findings are presented and discussed.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 17:15:37 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 22:45:10 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 16:52:15 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Kneale", "Casey", ""], ["Brown", "Steven D.", ""]]}]