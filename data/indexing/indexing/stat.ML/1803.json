[{"id": "1803.00067", "submitter": "Alan Mackey", "authors": "Alan Mackey, Xiyang Luo, Elad Eban", "title": "Constrained Classification and Ranking via Quantiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most machine learning applications, classification accuracy is not the\nprimary metric of interest. Binary classifiers which face class imbalance are\noften evaluated by the $F_\\beta$ score, area under the precision-recall curve,\nPrecision at K, and more. The maximization of many of these metrics can be\nexpressed as a constrained optimization problem, where the constraint is a\nfunction of the classifier's predictions.\n  In this paper we propose a novel framework for learning with constraints that\ncan be expressed as a predicted positive rate (or negative rate) on a subset of\nthe training data. We explicitly model the threshold at which a classifier must\noperate to satisfy the constraint, yielding a surrogate loss function which\navoids the complexity of constrained optimization. The method is model-agnostic\nand only marginally more expensive than minimization of the unconstrained loss.\nExperiments on a variety of benchmarks show competitive performance relative to\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 20:23:10 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Mackey", "Alan", ""], ["Luo", "Xiyang", ""], ["Eban", "Elad", ""]]}, {"id": "1803.00094", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen, Mahesh Chandra Mukkamala, Matthias Hein", "title": "Neural Networks Should Be Wide Enough to Learn Disconnected Decision\n  Regions", "comments": "Accepted at ICML 2018. Added discussion for non-pyramidal networks\n  and ReLU activation function", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent literature the important role of depth in deep learning has\nbeen emphasized. In this paper we argue that sufficient width of a feedforward\nnetwork is equally important by answering the simple question under which\nconditions the decision regions of a neural network are connected. It turns out\nthat for a class of activation functions including leaky ReLU, neural networks\nhaving a pyramidal structure, that is no layer has more hidden units than the\ninput dimension, produce necessarily connected decision regions. This implies\nthat a sufficiently wide hidden layer is necessary to guarantee that the\nnetwork can produce disconnected decision regions. We discuss the implications\nof this result for the construction of neural networks, in particular the\nrelation to the problem of adversarial manipulation of classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:28:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 10:47:26 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 09:14:57 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Nguyen", "Quynh", ""], ["Mukkamala", "Mahesh Chandra", ""], ["Hein", "Matthias", ""]]}, {"id": "1803.00101", "submitter": "Vladimir Feinberg", "authors": "Vladimir Feinberg, Alvin Wan, Ion Stoica, Michael I. Jordan, Joseph E.\n  Gonzalez, Sergey Levine", "title": "Model-Based Value Estimation for Efficient Model-Free Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent model-free reinforcement learning algorithms have proposed\nincorporating learned dynamics models as a source of additional data with the\nintention of reducing sample complexity. Such methods hold the promise of\nincorporating imagined data coupled with a notion of model uncertainty to\naccelerate the learning of continuous control tasks. Unfortunately, they rely\non heuristics that limit usage of the dynamics model. We present model-based\nvalue expansion, which controls for uncertainty in the model by only allowing\nimagination to fixed depth. By enabling wider use of learned dynamics models\nwithin a model-free reinforcement learning algorithm, we improve value\nestimation, which, in turn, reduces the sample complexity of learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:43:37 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Feinberg", "Vladimir", ""], ["Wan", "Alvin", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""], ["Gonzalez", "Joseph E.", ""], ["Levine", "Sergey", ""]]}, {"id": "1803.00113", "submitter": "Jeffrey Regier", "authors": "Jeffrey Regier, Andrew C. Miller, David Schlegel, Ryan P. Adams, Jon\n  D. McAuliffe, and Prabhat", "title": "Approximate Inference for Constructing Astronomical Catalogs from Images", "comments": "accepted to the Annals of Applied Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP astro-ph.IM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, fully generative model for constructing astronomical\ncatalogs from optical telescope image sets. Each pixel intensity is treated as\na random variable with parameters that depend on the latent properties of stars\nand galaxies. These latent properties are themselves modeled as random. We\ncompare two procedures for posterior inference. One procedure is based on\nMarkov chain Monte Carlo (MCMC) while the other is based on variational\ninference (VI). The MCMC procedure excels at quantifying uncertainty, while the\nVI procedure is 1000 times faster. On a supercomputer, the VI procedure\nefficiently uses 665,000 CPU cores to construct an astronomical catalog from 50\nterabytes of images in 14.6 minutes, demonstrating the scaling characteristics\nnecessary to construct catalogs for upcoming astronomical surveys.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:15:48 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 19:35:56 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 03:23:29 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Regier", "Jeffrey", ""], ["Miller", "Andrew C.", ""], ["Schlegel", "David", ""], ["Adams", "Ryan P.", ""], ["McAuliffe", "Jon D.", ""], ["Prabhat", "", ""]]}, {"id": "1803.00114", "submitter": "James Sharpnack", "authors": "Liwei Wu, Cho-Jui Hsieh, James Sharpnack", "title": "SQL-Rank: A Listwise Approach to Collaborative Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a listwise approach for constructing user-specific\nrankings in recommendation systems in a collaborative fashion. We contrast the\nlistwise approach to previous pointwise and pairwise approaches, which are\nbased on treating either each rating or each pairwise comparison as an\nindependent instance respectively. By extending the work of (Cao et al. 2007),\nwe cast listwise collaborative ranking as maximum likelihood under a\npermutation model which applies probability mass to permutations based on a low\nrank latent score matrix. We present a novel algorithm called SQL-Rank, which\ncan accommodate ties and missing data and can run in linear time. We develop a\ntheoretical framework for analyzing listwise ranking methods based on a novel\nrepresentation theory for the permutation model. Applying this framework to\ncollaborative ranking, we derive asymptotic statistical rates as the number of\nusers and items grow together. We conclude by demonstrating that our SQL-Rank\nmethod often outperforms current state-of-the-art algorithms for implicit\nfeedback such as Weighted-MF and BPR and achieve favorable results when\ncompared to explicit feedback algorithms such as matrix factorization and\ncollaborative ranking.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:26:43 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 14:19:57 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 22:22:55 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Wu", "Liwei", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "1803.00144", "submitter": "Trieu Trinh", "authors": "Trieu H. Trinh, Andrew M. Dai, Minh-Thang Luong, Quoc V. Le", "title": "Learning Longer-term Dependencies in RNNs with Auxiliary Losses", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in training recurrent neural networks (RNNs),\ncapturing long-term dependencies in sequences remains a fundamental challenge.\nMost approaches use backpropagation through time (BPTT), which is difficult to\nscale to very long sequences. This paper proposes a simple method that improves\nthe ability to capture long term dependencies in RNNs by adding an unsupervised\nauxiliary loss to the original objective. This auxiliary loss forces RNNs to\neither reconstruct previous events or predict next events in a sequence, making\ntruncated backpropagation feasible for long sequences and also improving full\nBPTT. We evaluate our method on a variety of settings, including pixel-by-pixel\nimage classification with sequence lengths up to 16\\,000, and a real document\nclassification benchmark. Our results highlight good performance and resource\nefficiency of this approach over competitive baselines, including other\nrecurrent models and a comparable sized Transformer. Further analyses reveal\nbeneficial effects of the auxiliary loss on optimization and regularization, as\nwell as extreme cases where there is little to no backpropagation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 00:28:07 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 17:49:15 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 08:35:57 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Trinh", "Trieu H.", ""], ["Dai", "Andrew M.", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""]]}, {"id": "1803.00149", "submitter": "Vikas Ramachandra", "authors": "Vikas Ramachandra", "title": "Deep Learning for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose deep learning techniques for econometrics,\nspecifically for causal inference and for estimating individual as well as\naverage treatment effects. The contribution of this paper is twofold: 1. For\ngeneralized neighbor matching to estimate individual and average treatment\neffects, we analyze the use of autoencoders for dimensionality reduction while\nmaintaining the local neighborhood structure among the data points in the\nembedding space. This deep learning based technique is shown to perform better\nthan simple k nearest neighbor matching for estimating treatment effects,\nespecially when the data points have several features/covariates but reside in\na low dimensional manifold in high dimensional space. We also observe better\nperformance than manifold learning methods for neighbor matching. 2. Propensity\nscore matching is one specific and popular way to perform matching in order to\nestimate average and individual treatment effects. We propose the use of deep\nneural networks (DNNs) for propensity score matching, and present a network\ncalled PropensityNet for this. This is a generalization of the logistic\nregression technique traditionally used to estimate propensity scores and we\nshow empirically that DNNs perform better than logistic regression at\npropensity score matching. Code for both methods will be made available shortly\non Github at: https://github.com/vikas84bf\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:01:16 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Ramachandra", "Vikas", ""]]}, {"id": "1803.00156", "submitter": "Eric Korman", "authors": "Eric O. Korman", "title": "Autoencoding topology", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning a manifold structure on a dataset is framed in terms\nof a generative model, to which we use ideas behind autoencoders (namely\nadversarial/Wasserstein autoencoders) to fit deep neural networks. From a\nmachine learning perspective, the resulting structure, an atlas of a manifold,\nmay be viewed as a combination of dimensionality reduction and \"fuzzy\"\nclustering.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:35:27 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Korman", "Eric O.", ""]]}, {"id": "1803.00158", "submitter": "Guihua Wen", "authors": "Li Huihui and Wen Guihua", "title": "Modeling reverse thinking for machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human inertial thinking schemes can be formed through learning, which are\nthen applied to quickly solve similar problems later. However, when problems\nare significantly different, inertial thinking generally presents the solutions\nthat are definitely imperfect. In such cases, people will apply creative\nthinking, such as reverse thinking, to solve problems. Similarly, machine\nlearning methods also form inertial thinking schemes through learning the\nknowledge from a large amount of data. However, when the testing data are\nvastly difference, the formed inertial thinking schemes will inevitably\ngenerate errors. This kind of inertial thinking is called illusion inertial\nthinking. Because all machine learning methods do not consider illusion\ninertial thinking, in this paper we propose a new method that uses reverse\nthinking to correct illusion inertial thinking, which increases the\ngeneralization ability of machine learning methods. Experimental results on\nbenchmark datasets are used to validate the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:45:30 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Huihui", "Li", ""], ["Guihua", "Wen", ""]]}, {"id": "1803.00183", "submitter": "Yunlong Feng", "authors": "Yunlong Feng and Yiming Ying", "title": "Learning with Correntropy-induced Losses for Regression with Mixture of\n  Symmetric Stable Noise", "comments": null, "journal-ref": null, "doi": "10.1016/j.acha.2019.09.001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, correntropy and its applications in machine learning have\nbeen drawing continuous attention owing to its merits in dealing with\nnon-Gaussian noise and outliers. However, theoretical understanding of\ncorrentropy, especially in the statistical learning context, is still limited.\nIn this study, within the statistical learning framework, we investigate\ncorrentropy based regression in the presence of non-Gaussian noise or outliers.\nMotivated by the practical way of generating non-Gaussian noise or outliers, we\nintroduce mixture of symmetric stable noise, which include Gaussian noise,\nCauchy noise, and their mixture as special cases, to model non-Gaussian noise\nor outliers. We demonstrate that under the mixture of symmetric stable noise\nassumption, correntropy based regression can learn the conditional mean\nfunction or the conditional median function well without resorting to the\nfinite-variance or even the finite first-order moment condition on the noise.\nIn particular, for the above two cases, we establish asymptotic optimal\nlearning rates for correntropy based regression estimators that are\nasymptotically of type $\\mathcal{O}(n^{-1})$. These results justify the\neffectiveness of the correntropy based regression estimators in dealing with\noutliers as well as non-Gaussian noise. We believe that the present study\ncompletes our understanding towards correntropy based regression from a\nstatistical learning viewpoint, and may also shed some light on robust\nstatistical learning for regression.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:01:54 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 01:13:10 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2018 01:20:37 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 01:47:58 GMT"}, {"version": "v5", "created": "Thu, 5 Sep 2019 03:27:09 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Feng", "Yunlong", ""], ["Ying", "Yiming", ""]]}, {"id": "1803.00184", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Zhijian Ou", "title": "Learning Sparse Structured Ensembles with SG-MCMC and Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble of neural networks is known to be more robust and accurate than\nan individual network, however usually with linearly-increased cost in both\ntraining and testing. In this work, we propose a two-stage method to learn\nSparse Structured Ensembles (SSEs) for neural networks. In the first stage, we\nrun SG-MCMC with group sparse priors to draw an ensemble of samples from the\nposterior distribution of network parameters. In the second stage, we apply\nweight-pruning to each sampled network and then perform retraining over the\nremained connections. In this way of learning SSEs with SG-MCMC and pruning, we\nnot only achieve high prediction accuracy since SG-MCMC enhances exploration of\nthe model-parameter space, but also reduce memory and computation cost\nsignificantly in both training and testing of NN ensembles. This is thoroughly\nevaluated in the experiments of learning SSE ensembles of both FNNs and LSTMs.\nFor example, in LSTM based language modeling (LM), we obtain 21% relative\nreduction in LM perplexity by learning a SSE of 4 large LSTM models, which has\nonly 30% of model parameters and 70% of computations in total, as compared to\nthe baseline large LSTM LM. To the best of our knowledge, this work represents\nthe first methodology and empirical study of integrating SG-MCMC, group sparse\nprior and network pruning together for learning NN ensembles.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:03:53 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 09:43:05 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 08:28:20 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Zhang", "Yichi", ""], ["Ou", "Zhijian", ""]]}, {"id": "1803.00186", "submitter": "Srinadh Bhojanapalli", "authors": "Srinadh Bhojanapalli, Nicolas Boumal, Prateek Jain, Praneeth\n  Netrapalli", "title": "Smoothed analysis for low-rank solutions to semidefinite programs in\n  quadratic penalty form", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semidefinite programs (SDP) are important in learning and combinatorial\noptimization with numerous applications. In pursuit of low-rank solutions and\nlow complexity algorithms, we consider the Burer--Monteiro factorization\napproach for solving SDPs. We show that all approximate local optima are global\noptima for the penalty formulation of appropriately rank-constrained SDPs as\nlong as the number of constraints scales sub-quadratically with the desired\nrank of the optimal solution. Our result is based on a simple penalty function\nformulation of the rank-constrained SDP along with a smoothed analysis to avoid\nworst-case cost matrices. We particularize our results to two applications,\nnamely, Max-Cut and matrix completion.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:11:11 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Bhojanapalli", "Srinadh", ""], ["Boumal", "Nicolas", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1803.00195", "submitter": "Jingfeng Wu", "authors": "Zhanxing Zhu, Jingfeng Wu, Bing Yu, Lei Wu, Jinwen Ma", "title": "The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of\n  Escaping from Sharp Minima and Regularization Effects", "comments": "ICML 2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the behavior of stochastic gradient descent (SGD) in the\ncontext of deep neural networks has raised lots of concerns recently. Along\nthis line, we study a general form of gradient based optimization dynamics with\nunbiased noise, which unifies SGD and standard Langevin dynamics. Through\ninvestigating this general optimization dynamics, we analyze the behavior of\nSGD on escaping from minima and its regularization effects. A novel indicator\nis derived to characterize the efficiency of escaping from minima through\nmeasuring the alignment of noise covariance and the curvature of loss function.\nBased on this indicator, two conditions are established to show which type of\nnoise structure is superior to isotropic noise in term of escaping efficiency.\nWe further show that the anisotropic noise in SGD satisfies the two conditions,\nand thus helps to escape from sharp and poor minima effectively, towards more\nstable and flat minima that typically generalize well. We systematically design\nvarious experiments to verify the benefits of the anisotropic noise, compared\nwith full gradient descent plus isotropic diffusion (i.e. Langevin dynamics).\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:46:36 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 10:19:15 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2018 08:16:16 GMT"}, {"version": "v4", "created": "Mon, 21 May 2018 15:01:58 GMT"}, {"version": "v5", "created": "Mon, 10 Jun 2019 05:19:32 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhu", "Zhanxing", ""], ["Wu", "Jingfeng", ""], ["Yu", "Bing", ""], ["Wu", "Lei", ""], ["Ma", "Jinwen", ""]]}, {"id": "1803.00196", "submitter": "Roberto Calandra", "authors": "Brian Yang, Grant Wang, Roberto Calandra, Daniel Contreras, Sergey\n  Levine and Kristofer Pister", "title": "Learning Flexible and Reusable Locomotion Primitives for a Microrobot", "comments": "8 pages. Accepted at RAL+ICRA2018", "journal-ref": null, "doi": "10.1109/LRA.2018.2806083", "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of gaits for robot locomotion can be a daunting process which\nrequires significant expert knowledge and engineering. This process is even\nmore challenging for robots that do not have an accurate physical model, such\nas compliant or micro-scale robots. Data-driven gait optimization provides an\nautomated alternative to analytical gait design. In this paper, we propose a\nnovel approach to efficiently learn a wide range of locomotion tasks with\nwalking robots. This approach formalizes locomotion as a contextual policy\nsearch task to collect data, and subsequently uses that data to learn\nmulti-objective locomotion primitives that can be used for planning. As a\nproof-of-concept we consider a simulated hexapod modeled after a recently\ndeveloped microrobot, and we thoroughly evaluate the performance of this\nmicrorobot on different tasks and gaits. Our results validate the proposed\ncontroller and learning scheme on single and multi-objective locomotion tasks.\nMoreover, the experimental simulations show that without any prior knowledge\nabout the robot used (e.g., dynamics model), our approach is capable of\nlearning locomotion primitives within 250 trials and subsequently using them to\nsuccessfully navigate through a maze.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:48:06 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Yang", "Brian", ""], ["Wang", "Grant", ""], ["Calandra", "Roberto", ""], ["Contreras", "Daniel", ""], ["Levine", "Sergey", ""], ["Pister", "Kristofer", ""]]}, {"id": "1803.00204", "submitter": "Chen Wang", "authors": "Chen Wang, Xiaomei Yang, Shaomin Fei, Kai Zhou, Xiaofeng Gong, Miao\n  Du, Ruisen Luo", "title": "Scalar Quantization as Sparse Least Square Optimization", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2019", "doi": "10.1109/TPAMI.2019.2952096", "report-no": null, "categories": "cs.LG cs.AI cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantization can be used to form new vectors/matrices with shared values\nclose to the original. In recent years, the popularity of scalar quantization\nfor value-sharing applications has been soaring as it has been found huge\nutilities in reducing the complexity of neural networks. Existing\nclustering-based quantization techniques, while being well-developed, have\nmultiple drawbacks including the dependency of the random seed, empty or\nout-of-the-range clusters, and high time complexity for a large number of\nclusters. To overcome these problems, in this paper, the problem of scalar\nquantization is examined from a new perspective, namely sparse least square\noptimization. Specifically, inspired by the property of sparse least square\nregression, several quantization algorithms based on $l_1$ least square are\nproposed. In addition, similar schemes with $l_1 + l_2$ and $l_0$\nregularization are proposed. Furthermore, to compute quantization results with\na given amount of values/clusters, this paper designed an iterative method and\na clustering-based method, and both of them are built on sparse least square.\nThe paper shows that the latter method is mathematically equivalent to an\nimproved version of k-means clustering-based quantization algorithm, although\nthe two algorithms originated from different intuitions. The algorithms\nproposed were tested with three types of data and their computational\nperformances, including information loss, time consumption, and the\ndistribution of the values of the sparse vectors, were compared and analyzed.\nThe paper offers a new perspective to probe the area of quantization, and the\nalgorithms proposed can outperform existing methods especially under some\nbit-width reduction scenarios, when the required post-quantization resolution\n(number of values) is not significantly lower than the original number.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:07:40 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 16:24:26 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 17:32:25 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 04:12:41 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Wang", "Chen", ""], ["Yang", "Xiaomei", ""], ["Fei", "Shaomin", ""], ["Zhou", "Kai", ""], ["Gong", "Xiaofeng", ""], ["Du", "Miao", ""], ["Luo", "Ruisen", ""]]}, {"id": "1803.00212", "submitter": "Christopher Metzler", "authors": "Christopher A. Metzler, Philip Schniter, Ashok Veeraraghavan, Richard\n  G. Baraniuk", "title": "prDeep: Robust Phase Retrieval with a Flexible Deep Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase retrieval algorithms have become an important component in many modern\ncomputational imaging systems. For instance, in the context of ptychography and\nspeckle correlation imaging, they enable imaging past the diffraction limit and\nthrough scattering media, respectively. Unfortunately, traditional phase\nretrieval algorithms struggle in the presence of noise. Progress has been made\nrecently on more robust algorithms using signal priors, but at the expense of\nlimiting the range of supported measurement models (e.g., to Gaussian or coded\ndiffraction patterns). In this work we leverage the regularization-by-denoising\nframework and a convolutional neural network denoiser to create prDeep, a new\nphase retrieval algorithm that is both robust and broadly applicable. We test\nand validate prDeep in simulation to demonstrate that it is robust to noise and\ncan handle a variety of system models.\n  A MatConvNet implementation of prDeep is available at\nhttps://github.com/ricedsp/prDeep.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:56:54 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 18:12:34 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Metzler", "Christopher A.", ""], ["Schniter", "Philip", ""], ["Veeraraghavan", "Ashok", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1803.00218", "submitter": "Ichiro Takeuchi Prof.", "authors": "Hiroyuki Hanada, Toshiyuki Takada, Jun Sakuma and Ichiro Takeuchi", "title": "Interval-based Prediction Uncertainty Bound Computation in Learning with\n  Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of machine learning with missing values is common in many areas.\nA simple approach is to first construct a dataset without missing values simply\nby discarding instances with missing entries or by imputing a fixed value for\neach missing entry, and then train a prediction model with the new dataset. A\ndrawback of this naive approach is that the uncertainty in the missing entries\nis not properly incorporated in the prediction. In order to evaluate prediction\nuncertainty, the multiple imputation (MI) approach has been studied, but the\nperformance of MI is sensitive to the choice of the probabilistic model of the\ntrue values in the missing entries, and the computational cost of MI is high\nbecause multiple models must be trained. In this paper, we propose an\nalternative approach called the Interval-based Prediction Uncertainty Bounding\n(IPUB) method. The IPUB method represents the uncertainties due to missing\nentries as intervals, and efficiently computes the lower and upper bounds of\nthe prediction results when all possible training sets constructed by imputing\narbitrary values in the intervals are considered. The IPUB method can be\napplied to a wide class of convex learning algorithms including penalized\nleast-squares regression, support vector machine (SVM), and logistic\nregression. We demonstrate the advantages of the IPUB method by comparing it\nwith an existing method in numerical experiment with benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 05:31:38 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Hanada", "Hiroyuki", ""], ["Takada", "Toshiyuki", ""], ["Sakuma", "Jun", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1803.00225", "submitter": "Tim Tsz-Kit Lau", "authors": "Jinshan Zeng, Tim Tsz-Kit Lau, Shaobo Lin, Yuan Yao", "title": "Global Convergence of Block Coordinate Descent in Deep Learning", "comments": "27 pages, 2 figures", "journal-ref": "Proceeding of the 36th International Conference on Machine\n  Learning (ICML), 2019", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has aroused extensive attention due to its great empirical\nsuccess. The efficiency of the block coordinate descent (BCD) methods has been\nrecently demonstrated in deep neural network (DNN) training. However,\ntheoretical studies on their convergence properties are limited due to the\nhighly nonconvex nature of DNN training. In this paper, we aim at providing a\ngeneral methodology for provable convergence guarantees for this type of\nmethods. In particular, for most of the commonly used DNN training models\ninvolving both two- and three-splitting schemes, we establish the global\nconvergence to a critical point at a rate of ${\\cal O}(1/k)$, where $k$ is the\nnumber of iterations. The results extend to general loss functions which have\nLipschitz continuous gradients and deep residual networks (ResNets). Our key\ndevelopment adds several new elements to the Kurdyka-{\\L}ojasiewicz inequality\nframework that enables us to carry out the global convergence analysis of BCD\nin the general scenario of deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 06:11:53 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 08:46:46 GMT"}, {"version": "v3", "created": "Sat, 26 Jan 2019 07:47:35 GMT"}, {"version": "v4", "created": "Sun, 12 May 2019 12:24:53 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zeng", "Jinshan", ""], ["Lau", "Tim Tsz-Kit", ""], ["Lin", "Shaobo", ""], ["Yao", "Yuan", ""]]}, {"id": "1803.00250", "submitter": "Alain Rakotomamonjy", "authors": "Alain Rakotomamonjy (LITIS), Abraham Traor\\'e (LITIS), Maxime Berar\n  (LITIS), R\\'emi Flamary (OCA), Nicolas Courty (OBELIX, PANAMA)", "title": "Distance Measure Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a distance-based discriminative framework for learning\nwith probability distributions. Instead of using kernel mean embeddings or\ngeneralized radial basis kernels, we introduce embeddings based on\ndissimilarity of distributions to some reference distributions denoted as\ntemplates. Our framework extends the theory of similarity of Balcan et al.\n(2008) to the population distribution case and we show that, for some learning\nproblems, some dissimilarity on distribution achieves low-error linear decision\nfunctions with high probability. Our key result is to prove that the theory\nalso holds for empirical distributions. Algorithmically, the proposed approach\nconsists in computing a mapping based on pairwise dissimilarity where learning\na linear decision function is amenable. Our experimental results show that the\nWasserstein distance embedding performs better than kernel mean embeddings and\ncomputing Wasserstein distance is far more tractable than estimating pairwise\nKullback-Leibler divergence of empirical distributions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 08:51:01 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 14:40:56 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 13:54:10 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Rakotomamonjy", "Alain", "", "LITIS"], ["Traor\u00e9", "Abraham", "", "LITIS"], ["Berar", "Maxime", "", "LITIS"], ["Flamary", "R\u00e9mi", "", "OCA"], ["Courty", "Nicolas", "", "OBELIX, PANAMA"]]}, {"id": "1803.00276", "submitter": "Faicel Chamroukhi", "authors": "Faicel Chamroukhi, Hien D. Nguyen", "title": "Model-Based Clustering and Classification of Functional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of complex data analysis is a central topic of modern statistical\nscience and learning systems and is becoming of broader interest with the\nincreasing prevalence of high-dimensional data. The challenge is to develop\nstatistical models and autonomous algorithms that are able to acquire knowledge\nfrom raw data for exploratory analysis, which can be achieved through\nclustering techniques or to make predictions of future data via classification\n(i.e., discriminant analysis) techniques. Latent data models, including mixture\nmodel-based approaches are one of the most popular and successful approaches in\nboth the unsupervised context (i.e., clustering) and the supervised one (i.e,\nclassification or discrimination). Although traditionally tools of multivariate\nanalysis, they are growing in popularity when considered in the framework of\nfunctional data analysis (FDA). FDA is the data analysis paradigm in which the\nindividual data units are functions (e.g., curves, surfaces), rather than\nsimple vectors. In many areas of application, the analyzed data are indeed\noften available in the form of discretized values of functions or curves (e.g.,\ntime series, waveforms) and surfaces (e.g., 2d-images, spatio-temporal data).\nThis functional aspect of the data adds additional difficulties compared to the\ncase of a classical multivariate (non-functional) data analysis. We review and\npresent approaches for model-based clustering and classification of functional\ndata. We derive well-established statistical models along with efficient\nalgorithmic tools to address problems regarding the clustering and the\nclassification of these high-dimensional data, including their heterogeneity,\nmissing information, and dynamical hidden structure. The presented models and\nalgorithms are illustrated on real-world functional data analysis problems from\nseveral application area.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 10:02:13 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 04:03:28 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Chamroukhi", "Faicel", ""], ["Nguyen", "Hien D.", ""]]}, {"id": "1803.00310", "submitter": "Henry WJ Reeve", "authors": "Henry WJ Reeve, Gavin Brown", "title": "Minimax rates for cost-sensitive learning on manifolds with approximate\n  nearest neighbours", "comments": "Published in ALT 2017", "journal-ref": "Algorithmic Learning Theory 2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximate nearest neighbour method for cost-sensitive\nclassification on low-dimensional manifolds embedded within a high-dimensional\nfeature space. We determine the minimax learning rates for distributions on a\nsmooth manifold, in a cost-sensitive setting. This generalises a classic result\nof Audibert and Tsybakov. Building upon recent work of Chaudhuri and Dasgupta\nwe prove that these minimax rates are attained by the approximate nearest\nneighbour algorithm, where neighbours are computed in a randomly projected\nlow-dimensional space. In addition, we give a bound on the number of dimensions\nrequired for the projection which depends solely upon the reach and dimension\nof the manifold, combined with the regularity of the marginal.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 11:26:34 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Reeve", "Henry WJ", ""], ["Brown", "Gavin", ""]]}, {"id": "1803.00316", "submitter": "Henry WJ Reeve", "authors": "Henry WJ Reeve, Joe Mellor, Gavin Brown", "title": "The K-Nearest Neighbour UCB algorithm for multi-armed bandits with\n  covariates", "comments": "To be presented at ALT 2018", "journal-ref": "Algorithmic Learning Theory 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and explore the k-Nearest Neighbour UCB algorithm\nfor multi-armed bandits with covariates. We focus on a setting where the\ncovariates are supported on a metric space of low intrinsic dimension, such as\na manifold embedded within a high dimensional ambient feature space. The\nalgorithm is conceptually simple and straightforward to implement. The\nk-Nearest Neighbour UCB algorithm does not require prior knowledge of the\neither the intrinsic dimension of the marginal distribution or the time\nhorizon. We prove a regret bound for the k-Nearest Neighbour UCB algorithm\nwhich is minimax optimal up to logarithmic factors. In particular, the\nalgorithm automatically takes advantage of both low intrinsic dimensionality of\nthe marginal distribution over the covariates and low noise in the data,\nexpressed as a margin condition. In addition, focusing on the case of bounded\nrewards, we give corresponding regret bounds for the k-Nearest Neighbour KL-UCB\nalgorithm, which is an analogue of the KL-UCB algorithm adapted to the setting\nof multi-armed bandits with covariates. Finally, we present empirical results\nwhich demonstrate the ability of both the k-Nearest Neighbour UCB and k-Nearest\nNeighbour KL-UCB to take advantage of situations where the data is supported on\nan unknown sub-manifold of a high-dimensional feature space.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 11:41:13 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Reeve", "Henry WJ", ""], ["Mellor", "Joe", ""], ["Brown", "Gavin", ""]]}, {"id": "1803.00387", "submitter": "Xinxin Du", "authors": "Xinxin Du, Marcelo H. Ang Jr., Sertac Karaman, Daniela Rus", "title": "A General Pipeline for 3D Detection of Vehicles", "comments": "Accepted at ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving requires 3D perception of vehicles and other objects in\nthe in environment. Much of the current methods support 2D vehicle detection.\nThis paper proposes a flexible pipeline to adopt any 2D detection network and\nfuse it with a 3D point cloud to generate 3D information with minimum changes\nof the 2D detection networks. To identify the 3D box, an effective model\nfitting algorithm is developed based on generalised car models and score maps.\nA two-stage convolutional neural network (CNN) is proposed to refine the\ndetected 3D box. This pipeline is tested on the KITTI dataset using two\ndifferent 2D detection networks. The 3D detection results based on these two\nnetworks are similar, demonstrating the flexibility of the proposed pipeline.\nThe results rank second among the 3D detection algorithms, indicating its\ncompetencies in 3D detection.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 15:32:23 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Du", "Xinxin", ""], ["Ang", "Marcelo H.", "Jr."], ["Karaman", "Sertac", ""], ["Rus", "Daniela", ""]]}, {"id": "1803.00420", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Yuanyuan Liu, James Cheng", "title": "Tractable and Scalable Schatten Quasi-Norm Approximations for Rank\n  Minimization", "comments": "26 pages, 7 figures, AISTATS 2016. arXiv admin note: text overlap\n  with arXiv:1606.01245", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Schatten quasi-norm was introduced to bridge the gap between the trace\nnorm and rank function. However, existing algorithms are too slow or even\nimpractical for large-scale problems. Motivated by the equivalence relation\nbetween the trace norm and its bilinear spectral penalty, we define two\ntractable Schatten norms, i.e.\\ the bi-trace and tri-trace norms, and prove\nthat they are in essence the Schatten-$1/2$ and $1/3$ quasi-norms,\nrespectively. By applying the two defined Schatten quasi-norms to various rank\nminimization problems such as MC and RPCA, we only need to solve much smaller\nfactor matrices. We design two efficient linearized alternating minimization\nalgorithms to solve our problems and establish that each bounded sequence\ngenerated by our algorithms converges to a critical point. We also provide the\nrestricted strong convexity (RSC) based and MC error bounds for our algorithms.\nOur experimental results verified both the efficiency and effectiveness of our\nalgorithms compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 03:29:33 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Cheng", "James", ""]]}, {"id": "1803.00422", "submitter": "Daniela Z\\\"oller", "authors": "Daniela Z\\\"oller, Stefan Lenz and Harald Binder", "title": "Distributed regression modeling for selecting markers under data\n  protection constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data protection constraints frequently require a distributed analysis of\ndata, i.e., individual-level data remains at many different sites, but analysis\nnevertheless has to be performed jointly. The corresponding aggregated data is\noften exchanged manually, requiring explicit permission before transfer, i.e.,\nthe number of data calls and the amount of data should be limited. Thus, only\nsimple aggregated summary statistics are typically transferred with just a\nsingle call. This does not allow for more complex tasks such as variable\nselection. As an alternative, we propose a multivariable regression approach\nfor identifying important markers by automatic variable selection based on\naggregated data from different locations in iterative calls. To minimize the\namount of transferred data and the number of calls, we also provide a heuristic\nvariant of the approach. When performing a global data standardization, the\nproposed methods yields the same results as when pooling individual-level data.\nIn a simulation study, the information loss introduced by a local\nstandardization is seen to be minimal. In a typical scenario, the heuristic\ndecreases the number of data calls from more than 10 to 3, rendering manual\ndata releases feasible. To make our approach widely available for application,\nwe provide an implementation on top of the DataSHIELD framework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 15:04:06 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 14:09:29 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Z\u00f6ller", "Daniela", ""], ["Lenz", "Stefan", ""], ["Binder", "Harald", ""]]}, {"id": "1803.00444", "submitter": "Adrian \\v{S}o\\v{s}i\\'c", "authors": "Adrian \\v{S}o\\v{s}i\\'c, Elmar Rueckert, Jan Peters, Abdelhak M.\n  Zoubir, Heinz Koeppl", "title": "Inverse Reinforcement Learning via Nonparametric Spatio-Temporal Subgoal\n  Modeling", "comments": "45 pages, 14 figures; ### Version 3 ### published in the Journal of\n  Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the field of inverse reinforcement learning (IRL) have led to\nsophisticated inference frameworks that relax the original modeling assumption\nof observing an agent behavior that reflects only a single intention. Instead\nof learning a global behavioral model, recent IRL methods divide the\ndemonstration data into parts, to account for the fact that different\ntrajectories may correspond to different intentions, e.g., because they were\ngenerated by different domain experts. In this work, we go one step further:\nusing the intuitive concept of subgoals, we build upon the premise that even a\nsingle trajectory can be explained more efficiently locally within a certain\ncontext than globally, enabling a more compact representation of the observed\nbehavior. Based on this assumption, we build an implicit intentional model of\nthe agent's goals to forecast its behavior in unobserved situations. The result\nis an integrated Bayesian prediction framework that significantly outperforms\nexisting IRL solutions and provides smooth policy estimates consistent with the\nexpert's plan. Most notably, our framework naturally handles situations where\nthe intentions of the agent change over time and classical IRL algorithms fail.\nIn addition, due to its probabilistic nature, the model can be\nstraightforwardly applied in active learning scenarios to guide the\ndemonstration process of the expert.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 15:31:28 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 16:30:20 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 10:52:08 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["\u0160o\u0161i\u0107", "Adrian", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""], ["Zoubir", "Abdelhak M.", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1803.00446", "submitter": "Nicolas Tempelmeier", "authors": "Nicolas Tempelmeier, Elena Demidova, Stefan Dietze", "title": "Inferring Missing Categorical Information in Noisy and Sparse Web Markup", "comments": null, "journal-ref": "Proceedings of The Web Conference 2018, 27th edition of the former\n  WWW conference", "doi": "10.1145/3178876.3186028", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded markup of Web pages has seen widespread adoption throughout the past\nyears driven by standards such as RDFa and Microdata and initiatives such as\nschema.org, where recent studies show an adoption by 39% of all Web pages\nalready in 2016. While this constitutes an important information source for\ntasks such as Web search, Web page classification or knowledge graph\naugmentation, individual markup nodes are usually sparsely described and often\nlack essential information. For instance, from 26 million nodes describing\nevents within the Common Crawl in 2016, 59% of nodes provide less than six\nstatements and only 257,000 nodes (0.96%) are typed with more specific event\nsubtypes. Nevertheless, given the scale and diversity of Web markup data, nodes\nthat provide missing information can be obtained from the Web in large\nquantities, in particular for categorical properties. Such data constitutes\npotential training data for inferring missing information to significantly\naugment sparsely described nodes. In this work, we introduce a supervised\napproach for inferring missing categorical properties in Web markup. Our\nexperiments, conducted on properties of events and movies, show a performance\nof 79% and 83% F1 score correspondingly, significantly outperforming existing\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 15:33:06 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Tempelmeier", "Nicolas", ""], ["Demidova", "Elena", ""], ["Dietze", "Stefan", ""]]}, {"id": "1803.00491", "submitter": "Pedro Mercado", "authors": "Pedro Mercado (1), Antoine Gautier (1), Francesco Tudisco (2) and\n  Matthias Hein (1) ((1) Saarland University, (2) University of Strathclyde)", "title": "The Power Mean Laplacian for Multilayer Graph Clustering", "comments": "19 pages, 3 figures. Accepted in Artificial Intelligence and\n  Statistics (AISTATS), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer graphs encode different kind of interactions between the same set\nof entities. When one wants to cluster such a multilayer graph, the natural\nquestion arises how one should merge the information different layers. We\nintroduce in this paper a one-parameter family of matrix power means for\nmerging the Laplacians from different layers and analyze it in expectation in\nthe stochastic block model. We show that this family allows to recover ground\ntruth clusters under different settings and verify this in real world data.\nWhile computing the matrix power mean can be very expensive for large graphs,\nwe introduce a numerical scheme to efficiently compute its eigenvectors for the\ncase of large sparse graphs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 16:43:01 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Mercado", "Pedro", "", "Saarland University"], ["Gautier", "Antoine", "", "Saarland University"], ["Tudisco", "Francesco", "", "University of Strathclyde"], ["Hein", "Matthias", "", "Saarland University"]]}, {"id": "1803.00500", "submitter": "Tom Lorimer", "authors": "Tom Lorimer, Karlis Kanders, Ruedi Stoop", "title": "Natural data structure extracted from neighborhood-similarity graphs", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2018.12.033", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'Big' high-dimensional data are commonly analyzed in low-dimensions, after\nperforming a dimensionality-reduction step that inherently distorts the data\nstructure. For the same purpose, clustering methods are also often used. These\nmethods also introduce a bias, either by starting from the assumption of a\nparticular geometric form of the clusters, or by using iterative schemes to\nenhance cluster contours, with uncontrollable consequences. The goal of data\nanalysis should, however, be to encode and detect structural data features at\nall scales and densities simultaneously, without assuming a parametric form of\ndata point distances, or modifying them. We propose a novel approach that\ndirectly encodes data point neighborhood similarities as a sparse graph. Our\nnon-iterative framework permits a transparent interpretation of data, without\naltering the original data dimension and metric. Several natural and synthetic\ndata applications demonstrate the efficacy of our novel approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:06:46 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Lorimer", "Tom", ""], ["Kanders", "Karlis", ""], ["Stoop", "Ruedi", ""]]}, {"id": "1803.00502", "submitter": "Zi Yin", "authors": "Zi Yin", "title": "Understand Functionality and Dimensionality of Vector Embeddings: the\n  Distributional Hypothesis, the Pairwise Inner Product Loss and Its\n  Bias-Variance Trade-off", "comments": "40 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector embedding is a foundational building block of many deep learning\nmodels, especially in natural language processing. In this paper, we present a\ntheoretical framework for understanding the effect of dimensionality on vector\nembeddings. We observe that the distributional hypothesis, a governing\nprinciple of statistical semantics, requires a natural unitary-invariance for\nvector embeddings. Motivated by the unitary-invariance observation, we propose\nthe Pairwise Inner Product (PIP) loss, a unitary-invariant metric on the\nsimilarity between two embeddings. We demonstrate that the PIP loss captures\nthe difference in functionality between embeddings, and that the PIP loss is\ntightly connect with two basic properties of vector embeddings, namely\nsimilarity and compositionality. By formulating the embedding training process\nas matrix factorization with noise, we reveal a fundamental bias-variance\ntrade-off between the signal spectrum and noise power in the dimensionality\nselection process. This bias-variance trade-off sheds light on many empirical\nobservations which have not been thoroughly explained, for example the\nexistence of an optimal dimensionality. Moreover, we discover two new results\nabout vector embeddings, namely their robustness against over-parametrization\nand their forward stability. The bias-variance trade-off of the PIP loss\nexplicitly answers the fundamental open problem of dimensionality selection for\nvector embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 17:02:17 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 01:41:59 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 17:46:36 GMT"}, {"version": "v4", "created": "Mon, 21 May 2018 05:13:02 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Yin", "Zi", ""]]}, {"id": "1803.00530", "submitter": "Buse Atli", "authors": "Buse Gul Atli, Alexander Jung", "title": "Online Feature Ranking for Intrusion Detection Systems", "comments": "Feature selection, streaming data, SVM, SGD, intrusion detection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current approaches to the design of intrusion detection systems apply\nfeature selection in a static, non-adaptive fashion. These methods often\nneglect the dynamic nature of network data which requires to use adaptive\nfeature selection techniques. In this paper, we present a simple technique\nbased on incremental learning of support vector machines in order to rank the\nfeatures in real time within a streaming model for network data. Some\nillustrative numerical experiments with two popular benchmark datasets show\nthat our approach allows to adapt to the changes in normal network behaviour\nand novel attack patterns which have not been experienced before.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 17:51:48 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 11:12:15 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Atli", "Buse Gul", ""], ["Jung", "Alexander", ""]]}, {"id": "1803.00546", "submitter": "Evangelos Michelioudakis", "authors": "Evangelos Michelioudakis and Alexander Artikis and Georgios Paliouras", "title": "Semi-Supervised Online Structure Learning for Composite Event\n  Recognition", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-019-05780-8", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online structure learning approaches, such as those stemming from Statistical\nRelational Learning, enable the discovery of complex relations in noisy data\nstreams. However, these methods assume the existence of fully-labelled training\ndata, which is unrealistic for most real-world applications. We present a novel\napproach for completing the supervision of a semi-supervised structure learning\ntask. We incorporate graph-cut minimisation, a technique that derives labels\nfor unlabelled data, based on their distance to their labelled counterparts. In\norder to adapt graph-cut minimisation to first order logic, we employ a\nsuitable structural distance for measuring the distance between sets of logical\natoms. The labelling process is achieved online (single-pass) by means of a\ncaching mechanism and the Hoeffding bound, a statistical tool to approximate\nglobally-optimal decisions from locally-optimal ones. We evaluate our approach\non the task of composite event recognition by using a benchmark dataset for\nhuman activity recognition, as well as a real dataset for maritime monitoring.\nThe evaluation suggests that our approach can effectively complete the missing\nlabels and eventually, improve the accuracy of the underlying structure\nlearning system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 18:31:07 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 09:13:50 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Michelioudakis", "Evangelos", ""], ["Artikis", "Alexander", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1803.00567", "submitter": "Marco Cuturi", "authors": "Gabriel Peyr\\'e, Marco Cuturi", "title": "Computational Optimal Transport", "comments": "new version with corrected typo in Eq. 4.43 and 4.44 (minus sign in\n  front of f, g now changed to +) a few more corrected typos", "journal-ref": "Foundations and Trends in Machine Learning, vol. 11, no. 5-6, pp.\n  355-607, 2019", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) theory can be informally described using the words of\nthe French mathematician Gaspard Monge (1746-1818): A worker with a shovel in\nhand has to move a large pile of sand lying on a construction site. The goal of\nthe worker is to erect with all that sand a target pile with a prescribed shape\n(for example, that of a giant sand castle). Naturally, the worker wishes to\nminimize her total effort, quantified for instance as the total distance or\ntime spent carrying shovelfuls of sand. Mathematicians interested in OT cast\nthat problem as that of comparing two probability distributions, two different\npiles of sand of the same volume. They consider all of the many possible ways\nto morph, transport or reshape the first pile into the second, and associate a\n\"global\" cost to every such transport, using the \"local\" consideration of how\nmuch it costs to move a grain of sand from one place to another. Recent years\nhave witnessed the spread of OT in several fields, thanks to the emergence of\napproximate solvers that can scale to sizes and dimensions that are relevant to\ndata sciences. Thanks to this newfound scalability, OT is being increasingly\nused to unlock various problems in imaging sciences (such as color or texture\nprocessing), computer vision and graphics (for shape manipulation) or machine\nlearning (for regression, classification and density fitting). This short book\nreviews OT with a bias toward numerical methods and their applications in data\nsciences, and sheds lights on the theoretical properties of OT that make it\nparticularly useful for some of these applications.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 18:28:43 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 16:52:43 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2019 09:50:50 GMT"}, {"version": "v4", "created": "Wed, 18 Mar 2020 09:54:55 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Peyr\u00e9", "Gabriel", ""], ["Cuturi", "Marco", ""]]}, {"id": "1803.00590", "submitter": "Hoang M. Le", "authors": "Hoang M. Le, Nan Jiang, Alekh Agarwal, Miroslav Dud\\'ik, Yisong Yue,\n  Hal Daum\\'e III", "title": "Hierarchical Imitation and Reinforcement Learning", "comments": "Proceedings of the 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to effectively leverage expert feedback to learn sequential\ndecision-making policies. We focus on problems with sparse rewards and long\ntime horizons, which typically pose significant challenges in reinforcement\nlearning. We propose an algorithmic framework, called hierarchical guidance,\nthat leverages the hierarchical structure of the underlying problem to\nintegrate different modes of expert interaction. Our framework can incorporate\ndifferent combinations of imitation learning (IL) and reinforcement learning\n(RL) at different levels, leading to dramatic reductions in both expert effort\nand cost of exploration. Using long-horizon benchmarks, including Montezuma's\nRevenge, we demonstrate that our approach can learn significantly faster than\nhierarchical RL, and be significantly more label-efficient than standard IL. We\nalso theoretically analyze labeling cost for certain instantiations of our\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 19:12:27 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 08:41:37 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Le", "Hoang M.", ""], ["Jiang", "Nan", ""], ["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Yue", "Yisong", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1803.00606", "submitter": "Christoph Dann", "authors": "Christoph Dann, Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John\n  Langford, Robert E. Schapire", "title": "On Oracle-Efficient PAC RL with Rich Observations", "comments": "appeared at NeurIPS 18; full paper including appendix; updated style\n  file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational tractability of PAC reinforcement learning with\nrich observations. We present new provably sample-efficient algorithms for\nenvironments with deterministic hidden state dynamics and stochastic rich\nobservations. These methods operate in an oracle model of computation --\naccessing policy and value function classes exclusively through standard\noptimization primitives -- and therefore represent computationally efficient\nalternatives to prior algorithms that require enumeration. With stochastic\nhidden state dynamics, we prove that the only known sample-efficient algorithm,\nOLIVE, cannot be implemented in the oracle model. We also present several\nexamples that illustrate fundamental challenges of tractable PAC reinforcement\nlearning in such general settings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 20:08:06 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 03:06:36 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 16:20:44 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2019 19:37:24 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Dann", "Christoph", ""], ["Jiang", "Nan", ""], ["Krishnamurthy", "Akshay", ""], ["Agarwal", "Alekh", ""], ["Langford", "John", ""], ["Schapire", "Robert E.", ""]]}, {"id": "1803.00641", "submitter": "Daniel Reem", "authors": "Daniel Reem, Simeon Reich, Alvaro De Pierro", "title": "Re-examination of Bregman functions and new properties of their\n  divergences", "comments": "Correction of a few very minor inaccuracies; added journal details\n  (volume, page numbers, etc.); some references were updated", "journal-ref": "Optimization 68 (2019), 279--348", "doi": "10.1080/02331934.2018.1543295", "report-no": null, "categories": "math.OC cs.IT math.IT physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bregman divergence (Bregman distance, Bregman measure of distance) is a\ncertain useful substitute for a distance, obtained from a well-chosen function\n(the \"Bregman function\"). Bregman functions and divergences have been\nextensively investigated during the last decades and have found applications in\noptimization, operations research, information theory, nonlinear analysis,\nmachine learning and more. This paper re-examines various aspects related to\nthe theory of Bregman functions and divergences. In particular, it presents\nmany sufficient conditions which allow the construction of Bregman functions in\na general setting and introduces new Bregman functions (such as a negative\niterated log entropy). Moreover, it sheds new light on several known Bregman\nfunctions such as quadratic entropies, the negative Havrda-Charv\\'at-Tsallis\nentropy, and the negative Boltzmann-Gibbs-Shannon entropy, and it shows that\nthe negative Burg entropy, which is not a Bregman function according to the\nclassical theory but nevertheless is known to have \"Bregmanian properties\",\ncan, by our re-examination of the theory, be considered as a Bregman function.\nOur analysis yields several by-products of independent interest such as the\nintroduction of the concept of relative uniform convexity (a certain\ngeneralization of uniform convexity), new properties of uniformly and strongly\nconvex functions, and results in Banach space theory.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 21:46:09 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2018 21:06:40 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 17:05:03 GMT"}, {"version": "v4", "created": "Mon, 8 Apr 2019 20:16:15 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Reem", "Daniel", ""], ["Reich", "Simeon", ""], ["De Pierro", "Alvaro", ""]]}, {"id": "1803.00650", "submitter": "Srinagesh Sharma", "authors": "Srinagesh Sharma, James W. Cutler", "title": "Kernel Embedding Approaches to Orbit Determination of Spacecraft\n  Clusters", "comments": "Submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel formulation and solution of orbit determination\nover finite time horizons as a learning problem. We present an approach to\norbit determination under very broad conditions that are satisfied for n-body\nproblems. These weak conditions allow us to perform orbit determination with\nnoisy and highly non-linear observations such as those presented by range-rate\nonly (Doppler only) observations. We show that domain generalization and\ndistribution regression techniques can learn to estimate orbits of a group of\nsatellites and identify individual satellites especially with prior\nunderstanding of correlations between orbits and provide asymptotic convergence\nconditions. The approach presented requires only visibility and observability\nof the underlying state from observations and is particularly useful for\nautonomous spacecraft operations using low-cost ground stations or sensors. We\nvalidate the orbit determination approach using observations of two spacecraft\n(GRIFEX and MCubed-2) along with synthetic datasets of multiple spacecraft\ndeployments and lunar orbits. We also provide a comparison with the standard\ntechniques (EKF) under highly noisy conditions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 22:47:35 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Sharma", "Srinagesh", ""], ["Cutler", "James W.", ""]]}, {"id": "1803.00651", "submitter": "Praneeth Narayanamurthy", "authors": "Namrata Vaswani and Praneeth Narayanamurthy", "title": "Static and Dynamic Robust PCA and Matrix Completion: A Review", "comments": "To appear in Proceedings of the IEEE, Special Issue on Rethinking PCA\n  for Modern Datasets. arXiv admin note: text overlap with arXiv:1711.09492", "journal-ref": "Proceedings of the IEEE ( Volume: 106, Issue: 8, Aug. 2018 )", "doi": "10.1109/JPROC.2018.2844126", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Components Analysis (PCA) is one of the most widely used dimension\nreduction techniques. Robust PCA (RPCA) refers to the problem of PCA when the\ndata may be corrupted by outliers. Recent work by Cand{\\`e}s, Wright, Li, and\nMa defined RPCA as a problem of decomposing a given data matrix into the sum of\na low-rank matrix (true data) and a sparse matrix (outliers). The column space\nof the low-rank matrix then gives the PCA solution. This simple definition has\nlead to a large amount of interesting new work on provably correct, fast, and\npractical solutions to RPCA. More recently, the dynamic (time-varying) version\nof the RPCA problem has been studied and a series of provably correct, fast,\nand memory efficient tracking solutions have been proposed. Dynamic RPCA (or\nrobust subspace tracking) is the problem of tracking data lying in a (slowly)\nchanging subspace while being robust to sparse outliers. This article provides\nan exhaustive review of the last decade of literature on RPCA and its dynamic\ncounterpart (robust subspace tracking), along with describing their theoretical\nguarantees, discussing the pros and cons of various approaches, and providing\nempirical comparisons of performance and speed.\n  A brief overview of the (low-rank) matrix completion literature is also\nprovided (the focus is on works not discussed in other recent reviews). This\nrefers to the problem of completing a low-rank matrix when only a subset of its\nentries are observed. It can be interpreted as a simpler special case of RPCA\nin which the indices of the outlier corrupted entries are known.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 22:48:53 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 21:25:01 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Vaswani", "Namrata", ""], ["Narayanamurthy", "Praneeth", ""]]}, {"id": "1803.00657", "submitter": "Dacheng Tao", "authors": "Chaoyue Wang, Chang Xu, Xin Yao, Dacheng Tao", "title": "Evolutionary Generative Adversarial Networks", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GAN) have been effective for learning\ngenerative models for real-world data. However, existing GANs (GAN and its\nvariants) tend to suffer from training problems such as instability and mode\ncollapse. In this paper, we propose a novel GAN framework called evolutionary\ngenerative adversarial networks (E-GAN) for stable GAN training and improved\ngenerative performance. Unlike existing GANs, which employ a pre-defined\nadversarial objective function alternately training a generator and a\ndiscriminator, we utilize different adversarial training objectives as mutation\noperations and evolve a population of generators to adapt to the environment\n(i.e., the discriminator). We also utilize an evaluation mechanism to measure\nthe quality and diversity of generated samples, such that only well-performing\ngenerator(s) are preserved and used for further training. In this way, E-GAN\novercomes the limitations of an individual adversarial training objective and\nalways preserves the best offspring, contributing to progress in and the\nsuccess of GANs. Experiments on several datasets demonstrate that E-GAN\nachieves convincing generative performance and reduces the training problems\ninherent in existing GANs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 23:15:38 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Wang", "Chaoyue", ""], ["Xu", "Chang", ""], ["Yao", "Xin", ""], ["Tao", "Dacheng", ""]]}, {"id": "1803.00676", "submitter": "Mengye Ren", "authors": "Mengye Ren, Eleni Triantafillou, Sachin Ravi, Jake Snell, Kevin\n  Swersky, Joshua B. Tenenbaum, Hugo Larochelle, Richard S. Zemel", "title": "Meta-Learning for Semi-Supervised Few-Shot Classification", "comments": "Published as a conference paper at ICLR 2018. 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In few-shot classification, we are interested in learning algorithms that\ntrain a classifier from only a handful of labeled examples. Recent progress in\nfew-shot classification has featured meta-learning, in which a parameterized\nmodel for a learning algorithm is defined and trained on episodes representing\ndifferent classification problems, each with a small labeled training set and\nits corresponding test set. In this work, we advance this few-shot\nclassification paradigm towards a scenario where unlabeled examples are also\navailable within each episode. We consider two situations: one where all\nunlabeled examples are assumed to belong to the same set of classes as the\nlabeled examples of the episode, as well as the more challenging situation\nwhere examples from other distractor classes are also provided. To address this\nparadigm, we propose novel extensions of Prototypical Networks (Snell et al.,\n2017) that are augmented with the ability to use unlabeled examples when\nproducing prototypes. These models are trained in an end-to-end way on\nepisodes, to learn to leverage the unlabeled examples successfully. We evaluate\nthese methods on versions of the Omniglot and miniImageNet benchmarks, adapted\nto this new framework augmented with unlabeled examples. We also propose a new\nsplit of ImageNet, consisting of a large set of classes, with a hierarchical\nstructure. Our experiments confirm that our Prototypical Networks can learn to\nimprove their predictions due to unlabeled examples, much like a\nsemi-supervised algorithm would.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 01:07:49 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Ren", "Mengye", ""], ["Triantafillou", "Eleni", ""], ["Ravi", "Sachin", ""], ["Snell", "Jake", ""], ["Swersky", "Kevin", ""], ["Tenenbaum", "Joshua B.", ""], ["Larochelle", "Hugo", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1803.00679", "submitter": "Ke Wang", "authors": "Sean O'Rourke and Van Vu and Ke Wang", "title": "Random perturbation and matrix sparsification and completion", "comments": "20 pages. Conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss general perturbation inequalities when the perturbation is random.\nAs applications, we obtain several new results concerning two important\nproblems: matrix sparsification and matrix completion.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 01:27:58 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["O'Rourke", "Sean", ""], ["Vu", "Van", ""], ["Wang", "Ke", ""]]}, {"id": "1803.00684", "submitter": "Boyuan Chen", "authors": "Boyuan Chen, Harvey Wu, Warren Mo, Ishanu Chattopadhyay, Hod Lipson", "title": "Autostacker: A Compositional Evolutionary Learning System", "comments": "Submitted to GECCO 2018 and currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an automatic machine learning (AutoML) modeling architecture\ncalled Autostacker, which combines an innovative hierarchical stacking\narchitecture and an Evolutionary Algorithm (EA) to perform efficient parameter\nsearch. Neither prior domain knowledge about the data nor feature preprocessing\nis needed. Using EA, Autostacker quickly evolves candidate pipelines with high\npredictive accuracy. These pipelines can be used as is or as a starting point\nfor human experts to build on. Autostacker finds innovative combinations and\nstructures of machine learning models, rather than selecting a single model and\noptimizing its hyperparameters. Compared with other AutoML systems on fifteen\ndatasets, Autostacker achieves state-of-art or competitive performance both in\nterms of test accuracy and time cost.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 02:02:38 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Chen", "Boyuan", ""], ["Wu", "Harvey", ""], ["Mo", "Warren", ""], ["Chattopadhyay", "Ishanu", ""], ["Lipson", "Hod", ""]]}, {"id": "1803.00744", "submitter": "Dev Goyal", "authors": "Dev Goyal, Zeeshan Syed, Jenna Wiens", "title": "Clinically Meaningful Comparisons Over Time: An Approach to Measuring\n  Patient Similarity based on Subsequence Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Longitudinal patient data has the potential to improve clinical risk\nstratification models for disease. However, chronic diseases that progress\nslowly over time are often heterogeneous in their clinical presentation.\nPatients may progress through disease stages at varying rates. This leads to\npathophysiological misalignment over time, making it difficult to consistently\ncompare patients in a clinically meaningful way. Furthermore, patients present\nclinically for the first time at different stages of disease. This eliminates\nthe possibility of simply aligning patients based on their initial\npresentation. Finally, patient data may be sampled at different rates due to\ndifferences in schedules or missed visits. To address these challenges, we\npropose a robust measure of patient similarity based on subsequence alignment.\nCompared to global alignment techniques that do not account for\npathophysiological misalignment, focusing on the most relevant subsequences\nallows for an accurate measure of similarity between patients. We demonstrate\nthe utility of our approach in settings where longitudinal data, while useful,\nare limited and lack a clear temporal alignment for comparison. Applied to the\ntask of stratifying patients for risk of progression to probable Alzheimer's\nDisease, our approach outperforms models that use only snapshot data (AUROC of\n0.839 vs. 0.812) and models that use global alignment techniques (AUROC of\n0.822). Our results support the hypothesis that patients' trajectories are\nuseful for quantifying inter-patient similarities and that using subsequence\nmatching and can help account for heterogeneity and misalignment in\nlongitudinal data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 07:43:27 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Goyal", "Dev", ""], ["Syed", "Zeeshan", ""], ["Wiens", "Jenna", ""]]}, {"id": "1803.00810", "submitter": "Dominik Janzing", "authors": "Dominik Janzing and Bernhard Schoelkopf", "title": "Detecting non-causal artifacts in multivariate linear regression models", "comments": "7 figures, latex", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider linear models where $d$ potential causes $X_1,...,X_d$ are\ncorrelated with one target quantity $Y$ and propose a method to infer whether\nthe association is causal or whether it is an artifact caused by overfitting or\nhidden common causes. We employ the idea that in the former case the vector of\nregression coefficients has 'generic' orientation relative to the covariance\nmatrix $\\Sigma_{XX}$ of $X$. Using an ICA based model for confounding, we show\nthat both confounding and overfitting yield regression vectors that concentrate\nmainly in the space of low eigenvalues of $\\Sigma_{XX}$.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 11:17:27 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Janzing", "Dominik", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1803.00816", "submitter": "Aleksandar Bojchevski", "authors": "Aleksandar Bojchevski, Oleksandr Shchur, Daniel Z\\\"ugner, Stephan\n  G\\\"unnemann", "title": "NetGAN: Generating Graphs via Random Walks", "comments": "ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML 2018), Stockholm, Sweden, pp. 609-618", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NetGAN - the first implicit generative model for graphs able to\nmimic real-world networks. We pose the problem of graph generation as learning\nthe distribution of biased random walks over the input graph. The proposed\nmodel is based on a stochastic neural network that generates discrete output\nsamples and is trained using the Wasserstein GAN objective. NetGAN is able to\nproduce graphs that exhibit well-known network patterns without explicitly\nspecifying them in the model definition. At the same time, our model exhibits\nstrong generalization properties, as highlighted by its competitive link\nprediction performance, despite not being trained specifically for this task.\nBeing the first approach to combine both of these desirable properties, NetGAN\nopens exciting avenues for further research.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 11:49:32 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 13:18:29 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Bojchevski", "Aleksandar", ""], ["Shchur", "Oleksandr", ""], ["Z\u00fcgner", "Daniel", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1803.00841", "submitter": "Rong Zhu", "authors": "Rong Zhu", "title": "Gradient-based Sampling: An Adaptive Importance Sampling for\n  Least-squares", "comments": null, "journal-ref": "30th Conference on Neural Information Processing Systems (NIPS\n  2016), Barcelona, Spain", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern data analysis, random sampling is an efficient and widely-used\nstrategy to overcome the computational difficulties brought by large sample\nsize. In previous studies, researchers conducted random sampling which is\naccording to the input data but independent on the response variable, however\nthe response variable may also be informative for sampling. In this paper we\npropose an adaptive sampling called the gradient-based sampling which is\ndependent on both the input data and the output for fast solving of\nleast-square (LS) problems. We draw the data points by random sampling from the\nfull data according to their gradient values. This sampling is computationally\nsaving, since the running time of computing the sampling probabilities is\nreduced to O(nd) where n is the full sample size and d is the dimension of the\ninput. Theoretically, we establish an error bound analysis of the general\nimportance sampling with respect to LS solution from full data. The result\nestablishes an improved performance of the use of our gradient- based sampling.\nSynthetic and real data sets are used to empirically argue that the\ngradient-based sampling has an obvious advantage over existing sampling methods\nfrom two aspects of statistical efficiency and computational saving.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 13:34:09 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Zhu", "Rong", ""]]}, {"id": "1803.00860", "submitter": "Xin Wang", "authors": "Jaime Lorenzo-Trueba, Fuming Fang, Xin Wang, Isao Echizen, Junichi\n  Yamagishi, Tomi Kinnunen", "title": "Can we steal your vocal identity from the Internet?: Initial\n  investigation of cloning Obama's voice using GAN, WaveNet and low-quality\n  found data", "comments": "conference manuscript submitted to Speaker Odyssey 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thanks to the growing availability of spoofing databases and rapid advances\nin using them, systems for detecting voice spoofing attacks are becoming more\nand more capable, and error rates close to zero are being reached for the\nASVspoof2015 database. However, speech synthesis and voice conversion paradigms\nthat are not considered in the ASVspoof2015 database are appearing. Such\nexamples include direct waveform modelling and generative adversarial networks.\nWe also need to investigate the feasibility of training spoofing systems using\nonly low-quality found data. For that purpose, we developed a generative\nadversarial network-based speech enhancement system that improves the quality\nof speech data found in publicly available sources. Using the enhanced data, we\ntrained state-of-the-art text-to-speech and voice conversion models and\nevaluated them in terms of perceptual speech quality and speaker similarity.\nThe results show that the enhancement models significantly improved the SNR of\nlow-quality degraded data found in publicly available sources and that they\nsignificantly improved the perceptual cleanliness of the source speech without\nsignificantly degrading the naturalness of the voice. However, the results also\nshow limitations when generating speech with the low-quality found data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 14:21:16 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Lorenzo-Trueba", "Jaime", ""], ["Fang", "Fuming", ""], ["Wang", "Xin", ""], ["Echizen", "Isao", ""], ["Yamagishi", "Junichi", ""], ["Kinnunen", "Tomi", ""]]}, {"id": "1803.00885", "submitter": "Felix Draxler", "authors": "Felix Draxler, Kambis Veschgini, Manfred Salmhofer, Fred A. Hamprecht", "title": "Essentially No Barriers in Neural Network Energy Landscape", "comments": "In Proceedings of 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:1308-1317, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training neural networks involves finding minima of a high-dimensional\nnon-convex loss function. Knowledge of the structure of this energy landscape\nis sparse. Relaxing from linear interpolations, we construct continuous paths\nbetween minima of recent neural network architectures on CIFAR10 and CIFAR100.\nSurprisingly, the paths are essentially flat in both the training and test\nlandscapes. This implies that neural networks have enough capacity for\nstructural changes, or that these changes are small between minima. Also, each\nminimum has at least one vanishing Hessian eigenvalue in addition to those\nresulting from trivial invariance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 15:22:10 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 21:59:03 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 17:45:05 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 14:55:25 GMT"}, {"version": "v5", "created": "Fri, 22 Feb 2019 11:20:22 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Draxler", "Felix", ""], ["Veschgini", "Kambis", ""], ["Salmhofer", "Manfred", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1803.00909", "submitter": "Shiyu Liang", "authors": "Shiyu Liang, Ruoyu Sun, Yixuan Li, R. Srikant", "title": "Understanding the Loss Surface of Neural Networks for Binary\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely conjectured that the reason that training algorithms for neural\nnetworks are successful because all local minima lead to similar performance,\nfor example, see (LeCun et al., 2015, Choromanska et al., 2015, Dauphin et al.,\n2014). Performance is typically measured in terms of two metrics: training\nperformance and generalization performance. Here we focus on the training\nperformance of single-layered neural networks for binary classification, and\nprovide conditions under which the training error is zero at all local minima\nof a smooth hinge loss function. Our conditions are roughly in the following\nform: the neurons have to be strictly convex and the surrogate loss function\nshould be a smooth version of hinge loss. We also provide counterexamples to\nshow that when the loss function is replaced with quadratic loss or logistic\nloss, the result may not hold.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 02:13:38 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 18:20:37 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Liang", "Shiyu", ""], ["Sun", "Ruoyu", ""], ["Li", "Yixuan", ""], ["Srikant", "R.", ""]]}, {"id": "1803.00930", "submitter": "Phaedon-Stelios Koutsourelakis", "authors": "Lukas Bruder, Phaedon-Stelios Koutsourelakis", "title": "Beyond black-boxes in Bayesian inverse problems and model validation:\n  applications in solid mechanics of elastography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper is motivated by one of the most fundamental challenges in\ninverse problems, that of quantifying model discrepancies and errors. While\nsignificant strides have been made in calibrating model parameters, the\noverwhelming majority of pertinent methods is based on the assumption of a\nperfect model. Motivated by problems in solid mechanics which, as all problems\nin continuum thermodynamics, are described by conservation laws and\nphenomenological constitutive closures, we argue that in order to quantify\nmodel uncertainty in a physically meaningful manner, one should break open the\nblack-box forward model. In particular we propose formulating an undirected\nprobabilistic model that explicitly accounts for the governing equations and\ntheir validity. This recasts the solution of both forward and inverse problems\nas probabilistic inference tasks where the problem's state variables should not\nonly be compatible with the data but also with the governing equations as well.\nEven though the probability densities involved do not contain any black-box\nterms, they live in much higher-dimensional spaces. In combination with the\nintractability of the normalization constant of the undirected model employed,\nthis poses significant challenges which we propose to address with a\nlinearly-scaling, double-layer of Stochastic Variational Inference. We\ndemonstrate the capabilities and efficacy of the proposed model in synthetic\nforward and inverse problems (with and without model error) in elastography.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 16:15:11 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 16:47:00 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2018 16:30:12 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Bruder", "Lukas", ""], ["Koutsourelakis", "Phaedon-Stelios", ""]]}, {"id": "1803.00967", "submitter": "Zi Wang", "authors": "Zi Wang and Caelan Reed Garrett and Leslie Pack Kaelbling and Tom\\'as\n  Lozano-P\\'erez", "title": "Active model learning and diverse action sampling for task and motion\n  planning", "comments": "Proceedings of the 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), Madrid, Spain.\n  https://www.youtube.com/playlist?list=PLoWhBFPMfSzDbc8CYelsbHZa1d3uz-W_c", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work is to augment the basic abilities of a robot by\nlearning to use new sensorimotor primitives to enable the solution of complex\nlong-horizon problems. Solving long-horizon problems in complex domains\nrequires flexible generative planning that can combine primitive abilities in\nnovel combinations to solve problems as they arise in the world. In order to\nplan to combine primitive actions, we must have models of the preconditions and\neffects of those actions: under what circumstances will executing this\nprimitive achieve some particular effect in the world?\n  We use, and develop novel improvements on, state-of-the-art methods for\nactive learning and sampling. We use Gaussian process methods for learning the\nconditions of operator effectiveness from small numbers of expensive training\nexamples collected by experimentation on a robot. We develop adaptive sampling\nmethods for generating diverse elements of continuous sets (such as robot\nconfigurations and object poses) during planning for solving a new task, so\nthat planning is as efficient as possible. We demonstrate these methods in an\nintegrated system, combining newly learned models with an efficient\ncontinuous-space robot task and motion planner to learn to solve long horizon\nproblems more efficiently than was previously possible.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 17:40:18 GMT"}, {"version": "v2", "created": "Sun, 12 Aug 2018 16:08:00 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wang", "Zi", ""], ["Garrett", "Caelan Reed", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "1803.00992", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Andrea Paudice, Luis Mu\\~noz-Gonz\\'alez, Emil C. Lupu", "title": "Label Sanitization against Label Flipping Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning systems rely on data collected in the wild from\nuntrusted sources, exposing the learning algorithms to data poisoning.\nAttackers can inject malicious data in the training dataset to subvert the\nlearning process, compromising the performance of the algorithm producing\nerrors in a targeted or an indiscriminate way. Label flipping attacks are a\nspecial case of data poisoning, where the attacker can control the labels\nassigned to a fraction of the training points. Even if the capabilities of the\nattacker are constrained, these attacks have been shown to be effective to\nsignificantly degrade the performance of the system. In this paper we propose\nan efficient algorithm to perform optimal label flipping poisoning attacks and\na mechanism to detect and relabel suspicious data points, mitigating the effect\nof such poisoning attacks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 18:43:22 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 19:26:48 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Paudice", "Andrea", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1803.01013", "submitter": "Tyler Maunu", "authors": "Gilad Lerman, Tyler Maunu", "title": "An Overview of Robust Subspace Recovery", "comments": "31 pages, 5 figures, 3 tables", "journal-ref": "Proceedings of the IEEE 106 (2018) 1380-1410", "doi": "10.1109/JPROC.2018.2853141", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will serve as an introduction to the body of work on robust\nsubspace recovery. Robust subspace recovery involves finding an underlying\nlow-dimensional subspace in a dataset that is possibly corrupted with outliers.\nWhile this problem is easy to state, it has been difficult to develop optimal\nalgorithms due to its underlying nonconvexity. This work emphasizes advantages\nand disadvantages of proposed approaches and unsolved problems in the area.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 19:16:07 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 00:08:44 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Lerman", "Gilad", ""], ["Maunu", "Tyler", ""]]}, {"id": "1803.01043", "submitter": "Mitch Hill", "authors": "Mitch Hill, Erik Nijkamp, Song-Chun Zhu", "title": "Building a Telescope to Look Into High-Dimensional Image Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image pattern can be represented by a probability distribution whose\ndensity is concentrated on different low-dimensional subspaces in the\nhigh-dimensional image space. Such probability densities have an astronomical\nnumber of local modes corresponding to typical pattern appearances. Related\ngroups of modes can join to form macroscopic image basins that represent\npattern concepts. Recent works use neural networks that capture high-order\nimage statistics to learn Gibbs models capable of synthesizing realistic images\nof many patterns. However, characterizing a learned probability density to\nuncover the Hopfield memories of the model, encoded by the structure of the\nlocal modes, remains an open challenge. In this work, we present novel\ncomputational experiments that map and visualize the local mode structure of\nGibbs densities. Efficient mapping requires identifying the global basins\nwithout enumerating the countless modes. Inspired by Grenander's jump-diffusion\nmethod, we propose a new MCMC tool called Attraction-Diffusion (AD) that can\ncapture the macroscopic structure of highly non-convex densities by measuring\nmetastability of local modes. AD involves altering the target density with a\nmagnetization potential penalizing distance from a known mode and running an\nMCMC sample of the altered density to measure the stability of the initial\nchain state. Using a low-dimensional generator network to facilitate\nexploration, we map image spaces with up to 12,288 dimensions (64 $\\times$ 64\npixels in RGB). Our work shows: (1) AD can efficiently map highly non-convex\nprobability densities, (2) metastable regions of pattern probability densities\ncontain coherent groups of images, and (3) the perceptibility of differences\nbetween training images influences the metastability of image basins.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 21:09:48 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Hill", "Mitch", ""], ["Nijkamp", "Erik", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1803.01088", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Alekh Agarwal, Miroslav Dud\\'ik, Haipeng Luo, Robert\n  E. Schapire", "title": "Practical Contextual Bandits with Regression Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in contextual bandits is to design general-purpose\nalgorithms that are both practically useful and theoretically well-founded. We\npresent a new technique that has the empirical and computational advantages of\nrealizability-based approaches combined with the flexibility of agnostic\nmethods. Our algorithms leverage the availability of a regression oracle for\nthe value-function class, a more realistic and reasonable oracle than the\nclassification oracles over policies typically assumed by agnostic methods. Our\napproach generalizes both UCB and LinUCB to far more expressive possible model\nclasses and achieves low regret under certain distributional assumptions. In an\nextensive empirical evaluation, compared to both realizability-based and\nagnostic baselines, we find that our approach typically gives comparable or\nsuperior results.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 01:50:35 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Foster", "Dylan J.", ""], ["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Luo", "Haipeng", ""], ["Schapire", "Robert E.", ""]]}, {"id": "1803.01113", "submitter": "Sanghamitra Dutta", "authors": "Sanghamitra Dutta, Gauri Joshi, Soumyadip Ghosh, Parijat Dube, Priya\n  Nagpurkar", "title": "Slow and Stale Gradients Can Win the Race: Error-Runtime Trade-offs in\n  Distributed SGD", "comments": "Single Column Version, 33 pages, 14 figures, Accepted at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Stochastic Gradient Descent (SGD) when run in a synchronous\nmanner, suffers from delays in waiting for the slowest learners (stragglers).\nAsynchronous methods can alleviate stragglers, but cause gradient staleness\nthat can adversely affect convergence. In this work we present a novel\ntheoretical characterization of the speed-up offered by asynchronous methods by\nanalyzing the trade-off between the error in the trained model and the actual\ntraining runtime (wallclock time). The novelty in our work is that our runtime\nanalysis considers random straggler delays, which helps us design and compare\ndistributed SGD algorithms that strike a balance between stragglers and\nstaleness. We also present a new convergence analysis of asynchronous SGD\nvariants without bounded or exponential delay assumptions, and a novel learning\nrate schedule to compensate for gradient staleness.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 06:17:18 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 19:47:57 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 23:30:45 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Joshi", "Gauri", ""], ["Ghosh", "Soumyadip", ""], ["Dube", "Parijat", ""], ["Nagpurkar", "Priya", ""]]}, {"id": "1803.01203", "submitter": "Shaobo Han", "authors": "Shaobo Han and David B. Dunson", "title": "Multiresolution Tensor Decomposition for Multiple Spatial Passing\n  Networks", "comments": "34 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is motivated by soccer positional passing networks collected\nacross multiple games. We refer to these data as replicated spatial passing\nnetworks---to accurately model such data it is necessary to take into account\nthe spatial positions of the passer and receiver for each passing event. This\nspatial registration and replicates that occur across games represent key\ndifferences with usual social network data. As a key step before investigating\nhow the passing dynamics influence team performance, we focus on developing\nmethods for summarizing different team's passing strategies. Our proposed\napproach relies on a novel multiresolution data representation framework and\nPoisson nonnegative block term decomposition model, which automatically\nproduces coarse-to-fine low-rank network motifs. The proposed methods are\napplied to detailed passing record data collected from the 2014 FIFA World Cup.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 16:57:48 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Han", "Shaobo", ""], ["Dunson", "David B.", ""]]}, {"id": "1803.01206", "submitter": "Simon Du", "authors": "Simon S. Du and Jason D. Lee", "title": "On the Power of Over-parametrization in Neural Networks with Quadratic\n  Activation", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new theoretical insights on why over-parametrization is effective\nin learning neural networks. For a $k$ hidden node shallow network with\nquadratic activation and $n$ training data points, we show as long as $ k \\ge\n\\sqrt{2n}$, over-parametrization enables local search algorithms to find a\n\\emph{globally} optimal solution for general smooth and convex loss functions.\nFurther, despite that the number of parameters may exceed the sample size,\nusing theory of Rademacher complexity, we show with weight decay, the solution\nalso generalizes well if the data is sampled from a regular distribution such\nas Gaussian. To prove when $k\\ge \\sqrt{2n}$, the loss function has benign\nlandscape properties, we adopt an idea from smoothed analysis, which may have\nother applications in studying loss surfaces of neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 17:37:57 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 23:59:37 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""]]}, {"id": "1803.01216", "submitter": "Matthias Rottmann", "authors": "Matthias Rottmann, Karsten Kahl and Hanno Gottschalk", "title": "Deep Bayesian Active Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications the process of generating label information is expensive\nand time consuming. We present a new method that combines active and\nsemi-supervised deep learning to achieve high generalization performance from a\ndeep convolutional neural network with as few known labels as possible. In a\nsetting where a small amount of labeled data as well as a large amount of\nunlabeled data is available, our method first learns the labeled data set. This\ninitialization is followed by an expectation maximization algorithm, where\nfurther training reduces classification entropy on the unlabeled data by\ntargeting a low entropy fit which is consistent with the labeled data. In\naddition the algorithm asks at a specified frequency an oracle for labels of\ndata with entropy above a certain entropy quantile. Using this active learning\ncomponent we obtain an agile labeling process that achieves high accuracy, but\nrequires only a small amount of known labels. For the MNIST dataset we report\nan error rate of 2.06% using only 300 labels and 1.06% for 1000 labels. These\nresults are obtained without employing any special network architecture or data\naugmentation.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 19:13:40 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Rottmann", "Matthias", ""], ["Kahl", "Karsten", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1803.01229", "submitter": "Maayan Frid-Adar", "authors": "Maayan Frid-Adar, Idit Diamant, Eyal Klang, Michal Amitai, Jacob\n  Goldberger, Hayit Greenspan", "title": "GAN-based Synthetic Medical Image Augmentation for increased CNN\n  Performance in Liver Lesion Classification", "comments": "Preprint submitted to Neurocomputing", "journal-ref": null, "doi": "10.1016/j.neucom.2018.09.013", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods, and in particular convolutional neural networks\n(CNNs), have led to an enormous breakthrough in a wide range of computer vision\ntasks, primarily by using large-scale annotated datasets. However, obtaining\nsuch datasets in the medical domain remains a challenge. In this paper, we\npresent methods for generating synthetic medical images using recently\npresented deep learning Generative Adversarial Networks (GANs). Furthermore, we\nshow that generated medical images can be used for synthetic data augmentation,\nand improve the performance of CNN for medical image classification. Our novel\nmethod is demonstrated on a limited dataset of computed tomography (CT) images\nof 182 liver lesions (53 cysts, 64 metastases and 65 hemangiomas). We first\nexploit GAN architectures for synthesizing high quality liver lesion ROIs. Then\nwe present a novel scheme for liver lesion classification using CNN. Finally,\nwe train the CNN using classic data augmentation and our synthetic data\naugmentation and compare performance. In addition, we explore the quality of\nour synthesized examples using visualization and expert assessment. The\nclassification performance using only classic data augmentation yielded 78.6%\nsensitivity and 88.4% specificity. By adding the synthetic data augmentation\nthe results increased to 85.7% sensitivity and 92.4% specificity. We believe\nthat this approach to synthetic data augmentation can generalize to other\nmedical classification applications and thus support radiologists' efforts to\nimprove diagnosis.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 20:20:38 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Frid-Adar", "Maayan", ""], ["Diamant", "Idit", ""], ["Klang", "Eyal", ""], ["Amitai", "Michal", ""], ["Goldberger", "Jacob", ""], ["Greenspan", "Hayit", ""]]}, {"id": "1803.01233", "submitter": "Quanquan Gu", "authors": "Xiao Zhang and Simon S. Du and Quanquan Gu", "title": "Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase\n  Procrustes Flow", "comments": "35 pages, 3 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the inductive matrix completion problem that aims to recover a\nrank-$r$ matrix with ambient dimension $d$ given $n$ features as the side prior\ninformation. The goal is to make use of the known $n$ features to reduce sample\nand computational complexities. We present and analyze a new gradient-based\nnon-convex optimization algorithm that converges to the true underlying matrix\nat a linear rate with sample complexity only linearly depending on $n$ and\nlogarithmically depending on $d$. To the best of our knowledge, all previous\nalgorithms either have a quadratic dependency on the number of features in\nsample complexity or a sub-linear computational convergence rate. In addition,\nwe provide experiments on both synthetic and real world data to demonstrate the\neffectiveness of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 20:42:29 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Zhang", "Xiao", ""], ["Du", "Simon S.", ""], ["Gu", "Quanquan", ""]]}, {"id": "1803.01257", "submitter": "Xiao Fu", "authors": "Xiao Fu and Kejun Huang and Nicholas D. Sidiropoulos and Wing-Kin Ma", "title": "Nonnegative Matrix Factorization for Signal and Data Analytics:\n  Identifiability, Algorithms, and Applications", "comments": "accepted version, IEEE Signal Processing Magazine; supplementary\n  materials added. Some minor revisions implemented", "journal-ref": null, "doi": "10.1109/MSP.2018.2877582", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has become a workhorse for signal and\ndata analytics, triggered by its model parsimony and interpretability. Perhaps\na bit surprisingly, the understanding to its model identifiability---the major\nreason behind the interpretability in many applications such as topic mining\nand hyperspectral imaging---had been rather limited until recent years.\nBeginning from the 2010s, the identifiability research of NMF has progressed\nconsiderably: Many interesting and important results have been discovered by\nthe signal processing (SP) and machine learning (ML) communities. NMF\nidentifiability has a great impact on many aspects in practice, such as\nill-posed formulation avoidance and performance-guaranteed algorithm design. On\nthe other hand, there is no tutorial paper that introduces NMF from an\nidentifiability viewpoint. In this paper, we aim at filling this gap by\noffering a comprehensive and deep tutorial on model identifiability of NMF as\nwell as the connections to algorithms and applications. This tutorial will help\nresearchers and graduate students grasp the essence and insights of NMF,\nthereby avoiding typical `pitfalls' that are often times due to unidentifiable\nNMF formulations. This paper will also help practitioners pick/design suitable\nfactorization tools for their own problems.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 22:48:14 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 05:49:47 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 16:45:48 GMT"}, {"version": "v4", "created": "Fri, 16 Nov 2018 18:41:45 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Fu", "Xiao", ""], ["Huang", "Kejun", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Ma", "Wing-Kin", ""]]}, {"id": "1803.01302", "submitter": "Yuancheng Zhu", "authors": "Yuancheng Zhu and John Lafferty", "title": "Distributed Nonparametric Regression under Communication Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of nonparametric estimation of a smooth\nfunction with data distributed across multiple machines. We assume an\nindependent sample from a white noise model is collected at each machine, and\nan estimator of the underlying true function needs to be constructed at a\ncentral machine. We place limits on the number of bits that each machine can\nuse to transmit information to the central machine. Our results give both\nasymptotic lower bounds and matching upper bounds on the statistical risk under\nvarious settings. We identify three regimes, depending on the relationship\namong the number of machines, the size of the data available at each machine,\nand the communication budget. When the communication budget is small, the\nstatistical risk depends solely on this communication bottleneck, regardless of\nthe sample size. In the regime where the communication budget is large, the\nclassic minimax risk in the non-distributed estimation setting is recovered. In\nan intermediate regime, the statistical risk depends on both the sample size\nand the communication budget.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 05:15:10 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2018 15:27:50 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Zhu", "Yuancheng", ""], ["Lafferty", "John", ""]]}, {"id": "1803.01314", "submitter": "Se Young Chun", "authors": "Shakarim Soltanayev, Se Young Chun", "title": "Training Deep Learning Based Denoisers without Ground Truth Data", "comments": "12 pages, 10 figures, 7 tables, NeurIPS 2018, this is an extended\n  version of it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed deep-learning-based denoisers often outperform\nstate-of-the-art conventional denoisers such as the BM3D. They are typically\ntrained to minimize the mean squared error (MSE) between the output image of a\ndeep neural network (DNN) and a ground truth image. Thus, it is important for\ndeep-learning-based denoisers to use high quality noiseless ground truth data\nfor high performance. However, it is often challenging or even infeasible to\nobtain noiseless images in some applications. Here, we propose a method based\non Stein's unbiased risk estimator (SURE) for training DNN denoisers based only\non the use of noisy images in the training data with Gaussian noise. We\ndemonstrate that our SURE-based method, without the use of ground truth data,\nis able to train DNN denoisers to yield performances close to those networks\ntrained with ground truth for both grayscale and color images. We also propose\na SURE-based refining method with a noisy test image for further performance\nimprovement. Our quick refining method outperformed conventional BM3D, deep\nimage prior, and often the networks trained with ground truth. Potential\nextension of our SURE-based methods to Poisson noise model was also\ninvestigated.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 07:55:40 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 08:23:32 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 06:57:36 GMT"}, {"version": "v4", "created": "Thu, 22 Apr 2021 02:48:50 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Soltanayev", "Shakarim", ""], ["Chun", "Se Young", ""]]}, {"id": "1803.01328", "submitter": "Mingyuan Zhou", "authors": "Hao Zhang, Bo Chen, Dandan Guo, Mingyuan Zhou", "title": "WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To train an inference network jointly with a deep generative topic model,\nmaking it both scalable to big corpora and fast in out-of-sample prediction, we\ndevelop Weibull hybrid autoencoding inference (WHAI) for deep latent Dirichlet\nallocation, which infers posterior samples via a hybrid of stochastic-gradient\nMCMC and autoencoding variational Bayes. The generative network of WHAI has a\nhierarchy of gamma distributions, while the inference network of WHAI is a\nWeibull upward-downward variational autoencoder, which integrates a\ndeterministic-upward deep neural network, and a stochastic-downward deep\ngenerative model based on a hierarchy of Weibull distributions. The Weibull\ndistribution can be used to well approximate a gamma distribution with an\nanalytic Kullback-Leibler divergence, and has a simple reparameterization via\nthe uniform noise, which help efficiently compute the gradients of the evidence\nlower bound with respect to the parameters of the inference network. The\neffectiveness and efficiency of WHAI are illustrated with experiments on big\ncorpora.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 09:53:59 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 14:57:35 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Bo", ""], ["Guo", "Dandan", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1803.01347", "submitter": "Brahim Khalil Abid", "authors": "Brahim Khalil Abid and Robert M. Gower", "title": "Greedy stochastic algorithms for entropy-regularized optimal transport\n  problems", "comments": "17 pages, 3 figures, AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) distances are finding evermore applications in machine\nlearning and computer vision, but their wide spread use in larger-scale\nproblems is impeded by their high computational cost. In this work we develop a\nfamily of fast and practical stochastic algorithms for solving the optimal\ntransport problem with an entropic penalization. This work extends the recently\ndeveloped Greenkhorn algorithm, in the sense that, the Greenkhorn algorithm is\na limiting case of this family. We also provide a simple and general\nconvergence theorem for all algorithms in the class, with rates that match the\nbest known rates of Greenkorn and the Sinkhorn algorithm, and conclude with\nnumerical experiments that show under what regime of penalization the new\nstochastic methods are faster than the aforementioned methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 12:32:11 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Abid", "Brahim Khalil", ""], ["Gower", "Robert M.", ""]]}, {"id": "1803.01349", "submitter": "Sotirios Chatzis", "authors": "Harris Partaourides and Sotirios P. Chatzis", "title": "Deep Network Regularization via Bayesian Inference of Synaptic\n  Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) often require good regularizers to generalize\nwell. Currently, state-of-the-art DNN regularization techniques consist in\nrandomly dropping units and/or connections on each iteration of the training\nalgorithm. Dropout and DropConnect are characteristic examples of such\nregularizers, that are widely popular among practitioners. However, a drawback\nof such approaches consists in the fact that their postulated probability of\nrandom unit/connection omission is a constant that must be heuristically\nselected based on the obtained performance in some validation set. To alleviate\nthis burden, in this paper we regard the DNN regularization problem from a\nBayesian inference perspective: We impose a sparsity-inducing prior over the\nnetwork synaptic weights, where the sparsity is induced by a set of\nBernoulli-distributed binary variables with Beta (hyper-)priors over their\nprior parameters. This way, we eventually allow for marginalizing over the DNN\nsynaptic connectivity for output generation, thus giving rise to an effective,\nheuristics-free, network regularization scheme. We perform Bayesian inference\nfor the resulting hierarchical model by means of an efficient Black-Box\nVariational inference scheme. We exhibit the advantages of our method over\nexisting approaches by conducting an extensive experimental evaluation using\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 12:41:34 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Partaourides", "Harris", ""], ["Chatzis", "Sotirios P.", ""]]}, {"id": "1803.01365", "submitter": "Arief Koesdwiady", "authors": "Arief Koesdwiady, and Fakhri Karray", "title": "New Results on Multi-Step Traffic Flow Prediction", "comments": "submitted to IEEE Trans on ITS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In its simplest form, the traffic flow prediction problem is restricted to\npredicting a single time-step into the future. Multi-step traffic flow\nprediction extends this set-up to the case where predicting multiple time-steps\ninto the future based on some finite history is of interest. This problem is\nsignificantly more difficult than its single-step variant and is known to\nsuffer from degradation in predictions as the time step increases. In this\npaper, two approaches to improve multi-step traffic flow prediction performance\nin recursive and multi-output settings are introduced. In particular, a model\nthat allows recursive prediction approaches to take into account the temporal\ncontext in term of time-step index when making predictions is introduced. In\naddition, a conditional generative adversarial network-based data augmentation\nmethod is proposed to improve prediction performance in the multi-output\nsetting. The experiments on a real-world traffic flow dataset show that the two\nmethods improve on multi-step traffic flow prediction in recursive and\nmulti-output settings, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 14:59:55 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 19:35:10 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Koesdwiady", "Arief", ""], ["Karray", "Fakhri", ""]]}, {"id": "1803.01370", "submitter": "Ching-pei Lee", "authors": "Ching-pei Lee, Cong Han Lim, Stephen J. Wright", "title": "A Distributed Quasi-Newton Algorithm for Empirical Risk Minimization\n  with Nonsmooth Regularization", "comments": "In the proceedings of The 24th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining, 2018", "journal-ref": null, "doi": "10.1145/3219819.3220075", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a communication- and computation-efficient distributed\noptimization algorithm using second-order information for solving ERM problems\nwith a nonsmooth regularization term. Current second-order and quasi-Newton\nmethods for this problem either do not work well in the distributed setting or\nwork only for specific regularizers. Our algorithm uses successive quadratic\napproximations, and we describe how to maintain an approximation of the Hessian\nand solve subproblems efficiently in a distributed manner. The proposed method\nenjoys global linear convergence for a broad range of non-strongly convex\nproblems that includes the most commonly used ERMs, thus requiring lower\ncommunication complexity. It also converges on non-convex problems, so has the\npotential to be used on applications such as deep learning. Initial\ncomputational results on convex problems demonstrate that our method\nsignificantly improves on communication cost and running time over the current\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 15:37:46 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 06:46:12 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Lee", "Ching-pei", ""], ["Lim", "Cong Han", ""], ["Wright", "Stephen J.", ""]]}, {"id": "1803.01420", "submitter": "Yuval Dagan", "authors": "Yuval Dagan and Ohad Shamir", "title": "Detecting Correlations with Little Memory and Communication", "comments": "Accepted for presentation at Conference on Learning Theory (COLT)\n  2018. Changes: Added a comparison to Raz [2016]; Corrected typos; Added\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying correlations in multivariate data, under\ninformation constraints: Either on the amount of memory that can be used by the\nalgorithm, or the amount of communication when the data is distributed across\nseveral machines. We prove a tight trade-off between the memory/communication\ncomplexity and the sample complexity, implying (for example) that to detect\npairwise correlations with optimal sample complexity, the number of required\nmemory/communication bits is at least quadratic in the dimension. Our results\nsubstantially improve those of Shamir [2014], which studied a similar question\nin a much more restricted setting. To the best of our knowledge, these are the\nfirst provable sample/memory/communication trade-offs for a practical\nestimation problem, using standard distributions, and in the natural regime\nwhere the memory/communication budget is larger than the size of a single data\npoint. To derive our theorems, we prove a new information-theoretic result,\nwhich may be relevant for studying other information-constrained learning\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 20:57:42 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 15:14:43 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Dagan", "Yuval", ""], ["Shamir", "Ohad", ""]]}, {"id": "1803.01422", "submitter": "Bryon Aragam", "authors": "Xun Zheng, Bryon Aragam, Pradeep Ravikumar, Eric P. Xing", "title": "DAGs with NO TEARS: Continuous Optimization for Structure Learning", "comments": "22 pages, 8 figures, accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the structure of directed acyclic graphs (DAGs, also known as\nBayesian networks) is a challenging problem since the search space of DAGs is\ncombinatorial and scales superexponentially with the number of nodes. Existing\napproaches rely on various local heuristics for enforcing the acyclicity\nconstraint. In this paper, we introduce a fundamentally different strategy: We\nformulate the structure learning problem as a purely \\emph{continuous}\noptimization problem over real matrices that avoids this combinatorial\nconstraint entirely. This is achieved by a novel characterization of acyclicity\nthat is not only smooth but also exact. The resulting problem can be\nefficiently solved by standard numerical algorithms, which also makes\nimplementation effortless. The proposed method outperforms existing ones,\nwithout imposing any structural assumptions on the graph such as bounded\ntreewidth or in-degree. Code implementing the proposed algorithm is open-source\nand publicly available at https://github.com/xunzheng/notears.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 21:09:13 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 01:29:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Zheng", "Xun", ""], ["Aragam", "Bryon", ""], ["Ravikumar", "Pradeep", ""], ["Xing", "Eric P.", ""]]}, {"id": "1803.01440", "submitter": "Antoine Dedieu", "authors": "Antoine Dedieu, Rahul Mazumder, Zhen Zhu, Hossein Vahabi", "title": "Hierarchical Modeling and Shrinkage for User Session Length Prediction\n  in Media Streaming", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important metric of users' satisfaction and engagement within on-line\nstreaming services is the user session length, i.e. the amount of time they\nspend on a service continuously without interruption. Being able to predict\nthis value directly benefits the recommendation and ad pacing contexts in music\nand video streaming services. Recent research has shown that predicting the\nexact amount of time spent is highly nontrivial due to many external factors\nfor which a user can end a session, and the lack of predictive covariates. Most\nof the other related literature on duration based user engagement has focused\non dwell time for websites, for search and display ads, mainly for post-click\nsatisfaction prediction or ad ranking.\n  In this work we present a novel framework inspired by hierarchical Bayesian\nmodeling to predict, at the moment of login, the amount of time a user will\nspend in the streaming service. The time spent by a user on a platform depends\nupon user-specific latent variables which are learned via hierarchical\nshrinkage. Our framework enjoys theoretical guarantees and naturally\nincorporates flexible parametric/nonparametric models on the covariates,\nincluding models robust to outliers. Our proposal is found to outperform\nstate-of- the-art estimators in terms of efficiency and predictive performance\non real world public and private datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 23:39:43 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 22:29:53 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Dedieu", "Antoine", ""], ["Mazumder", "Rahul", ""], ["Zhu", "Zhen", ""], ["Vahabi", "Hossein", ""]]}, {"id": "1803.01442", "submitter": "Guneet Dhillon", "authors": "Guneet S. Dhillon, Kamyar Azizzadenesheli, Zachary C. Lipton, Jeremy\n  Bernstein, Jean Kossaifi, Aran Khanna, Anima Anandkumar", "title": "Stochastic Activation Pruning for Robust Adversarial Defense", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to be vulnerable to adversarial examples. Carefully\nchosen perturbations to real images, while imperceptible to humans, induce\nmisclassification and threaten the reliability of deep learning systems in the\nwild. To guard against adversarial examples, we take inspiration from game\ntheory and cast the problem as a minimax zero-sum game between the adversary\nand the model. In general, for such games, the optimal strategy for both\nplayers requires a stochastic policy, also known as a mixed strategy. In this\nlight, we propose Stochastic Activation Pruning (SAP), a mixed strategy for\nadversarial defense. SAP prunes a random subset of activations (preferentially\npruning those with smaller magnitude) and scales up the survivors to\ncompensate. We can apply SAP to pretrained networks, including adversarially\ntrained models, without fine-tuning, providing robustness against adversarial\nexamples. Experiments demonstrate that SAP confers robustness against attacks,\nincreasing accuracy and preserving calibration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 00:17:05 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Dhillon", "Guneet S.", ""], ["Azizzadenesheli", "Kamyar", ""], ["Lipton", "Zachary C.", ""], ["Bernstein", "Jeremy", ""], ["Kossaifi", "Jean", ""], ["Khanna", "Aran", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1803.01454", "submitter": "Hussein Hazimeh", "authors": "Hussein Hazimeh and Rahul Mazumder", "title": "Fast Best Subset Selection: Coordinate Descent and Local Combinatorial\n  Optimization Algorithms", "comments": "To appear in Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $L_0$-regularized least squares problem (a.k.a. best subsets) is central\nto sparse statistical learning and has attracted significant attention across\nthe wider statistics, machine learning, and optimization communities. Recent\nwork has shown that modern mixed integer optimization (MIO) solvers can be used\nto address small to moderate instances of this problem. In spite of the\nusefulness of $L_0$-based estimators and generic MIO solvers, there is a steep\ncomputational price to pay when compared to popular sparse learning algorithms\n(e.g., based on $L_1$ regularization). In this paper, we aim to push the\nfrontiers of computation for a family of $L_0$-regularized problems with\nadditional convex penalties. We propose a new hierarchy of necessary optimality\nconditions for these problems. We develop fast algorithms, based on coordinate\ndescent and local combinatorial optimization, that are guaranteed to converge\nto solutions satisfying these optimality conditions. From a statistical\nviewpoint, an interesting story emerges. When the signal strength is high, our\ncombinatorial optimization algorithms have an edge in challenging statistical\nsettings. When the signal is lower, pure $L_0$ benefits from additional convex\nregularization. We empirically demonstrate that our family of $L_0$-based\nestimators can outperform the state-of-the-art sparse learning algorithms in\nterms of a combination of prediction, estimation, and variable selection\nmetrics under various regimes (e.g., different signal strengths, feature\ncorrelations, number of samples and features). Our new open-source sparse\nlearning toolkit L0Learn (available on CRAN and Github) reaches up to a\nthree-fold speedup (with $p$ up to $10^6$) when compared to competing toolkits\nsuch as glmnet and ncvreg.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 01:41:12 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 03:50:59 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 04:40:40 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Hazimeh", "Hussein", ""], ["Mazumder", "Rahul", ""]]}, {"id": "1803.01489", "submitter": "Ahmed Hefny", "authors": "Ahmed Hefny, Zita Marinho, Wen Sun, Siddhartha Srinivasa, Geoffrey\n  Gordon", "title": "Recurrent Predictive State Policy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Recurrent Predictive State Policy (RPSP) networks, a recurrent\narchitecture that brings insights from predictive state representations to\nreinforcement learning in partially observable environments. Predictive state\npolicy networks consist of a recursive filter, which keeps track of a belief\nabout the state of the environment, and a reactive policy that directly maps\nbeliefs to actions, to maximize the cumulative reward. The recursive filter\nleverages predictive state representations (PSRs) (Rosencrantz and Gordon,\n2004; Sun et al., 2016) by modeling predictive state-- a prediction of the\ndistribution of future observations conditioned on history and future actions.\nThis representation gives rise to a rich class of statistically consistent\nalgorithms (Hefny et al., 2018) to initialize the recursive filter. Predictive\nstate serves as an equivalent representation of a belief state. Therefore, the\npolicy component of the RPSP-network can be purely reactive, simplifying\ntraining while still allowing optimal behaviour. Moreover, we use the PSR\ninterpretation during training as well, by incorporating prediction error in\nthe loss function. The entire network (recursive filter and reactive policy) is\nstill differentiable and can be trained using gradient based methods. We\noptimize our policy using a combination of policy gradient based on rewards\n(Williams, 1992) and gradient descent based on prediction error. We show the\nefficacy of RPSP-networks under partial observability on a set of robotic\ncontrol tasks from OpenAI Gym. We empirically show that RPSP-networks perform\nwell compared with memory-preserving networks such as GRUs, as well as finite\nmemory models, being the overall best performing method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 03:59:48 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Hefny", "Ahmed", ""], ["Marinho", "Zita", ""], ["Sun", "Wen", ""], ["Srinivasa", "Siddhartha", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1803.01498", "submitter": "Dong Yin", "authors": "Dong Yin, Yudong Chen, Kannan Ramchandran, Peter Bartlett", "title": "Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale distributed learning, security issues have become increasingly\nimportant. Particularly in a decentralized environment, some computing units\nmay behave abnormally, or even exhibit Byzantine failures -- arbitrary and\npotentially adversarial behavior. In this paper, we develop distributed\nlearning algorithms that are provably robust against such failures, with a\nfocus on achieving optimal statistical performance. A main result of this work\nis a sharp analysis of two robust distributed gradient descent algorithms based\non median and trimmed mean operations, respectively. We prove statistical error\nrates for three kinds of population loss functions: strongly convex,\nnon-strongly convex, and smooth non-convex. In particular, these algorithms are\nshown to achieve order-optimal statistical error rates for strongly convex\nlosses. To achieve better communication efficiency, we further propose a\nmedian-based distributed algorithm that is provably robust, and uses only one\ncommunication round. For strongly convex quadratic loss, we show that this\nalgorithm achieves the same optimal error rate as the robust distributed\ngradient descent algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 05:04:17 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 06:34:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Yin", "Dong", ""], ["Chen", "Yudong", ""], ["Ramchandran", "Kannan", ""], ["Bartlett", "Peter", ""]]}, {"id": "1803.01500", "submitter": "Youngjin Kim", "authors": "Youngjin Kim, Minjung Kim, Gunhee Kim", "title": "Memorization Precedes Generation: Learning Unsupervised GANs with Memory\n  Networks", "comments": "Published in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to address two issues that commonly occur during\ntraining of unsupervised GANs. First, since GANs use only a continuous latent\ndistribution to embed multiple classes or clusters of data, they often do not\ncorrectly handle the structural discontinuity between disparate classes in a\nlatent space. Second, discriminators of GANs easily forget about past generated\nsamples by generators, incurring instability during adversarial training. We\nargue that these two infamous problems of unsupervised GAN training can be\nlargely alleviated by a learnable memory network to which both generators and\ndiscriminators can access. Generators can effectively learn representation of\ntraining samples to understand underlying cluster distributions of data, which\nease the structure discontinuity problem. At the same time, discriminators can\nbetter memorize clusters of previously generated samples, which mitigate the\nforgetting problem. We propose a novel end-to-end GAN model named memoryGAN,\nwhich involves a memory network that is unsupervisedly trainable and integrable\nto many existing GAN models. With evaluations on multiple datasets such as\nFashion-MNIST, CelebA, CIFAR10, and Chairs, we show that our model is\nprobabilistically interpretable, and generates realistic image samples of high\nvisual fidelity. The memoryGAN also achieves the state-of-the-art inception\nscores over unsupervised GAN models on the CIFAR10 dataset, without any\noptimization tricks and weaker divergences.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 05:17:42 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 02:47:12 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Kim", "Youngjin", ""], ["Kim", "Minjung", ""], ["Kim", "Gunhee", ""]]}, {"id": "1803.01541", "submitter": "Xiang Wei", "authors": "Xiang Wei, Boqing Gong, Zixia Liu, Wei Lu, Liqiang Wang", "title": "Improving the Improved Training of Wasserstein GANs: A Consistency Term\n  and Its Dual Effect", "comments": "Accepted as a conference paper in International Conference on\n  Learning Representation(ICLR). Xiang Wei and Boqing Gong contributed equally\n  in this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being impactful on a variety of problems and applications, the\ngenerative adversarial nets (GANs) are remarkably difficult to train. This\nissue is formally analyzed by \\cite{arjovsky2017towards}, who also propose an\nalternative direction to avoid the caveats in the minmax two-player training of\nGANs. The corresponding algorithm, called Wasserstein GAN (WGAN), hinges on the\n1-Lipschitz continuity of the discriminator. In this paper, we propose a novel\napproach to enforcing the Lipschitz continuity in the training procedure of\nWGANs. Our approach seamlessly connects WGAN with one of the recent\nsemi-supervised learning methods. As a result, it gives rise to not only better\nphoto-realistic samples than the previous methods but also state-of-the-art\nsemi-supervised learning results. In particular, our approach gives rise to the\ninception score of more than 5.0 with only 1,000 CIFAR-10 images and is the\nfirst that exceeds the accuracy of 90% on the CIFAR-10 dataset using only 4,000\nlabeled images, to the best of our knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 08:00:39 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Wei", "Xiang", ""], ["Gong", "Boqing", ""], ["Liu", "Zixia", ""], ["Lu", "Wei", ""], ["Wang", "Liqiang", ""]]}, {"id": "1803.01562", "submitter": "Hossein Rajabzadeh", "authors": "Hossein Rajabzadeh, Mansoor Zolghadri Jahromi, Mohammad Sadegh Zare,\n  Mostafa Fakhrahmad", "title": "Local Distance Metric Learning for Nearest Neighbor Algorithm", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning is a successful way to enhance the performance of\nthe nearest neighbor classifier. In most cases, however, the distribution of\ndata does not obey a regular form and may change in different parts of the\nfeature space. Regarding that, this paper proposes a novel local distance\nmetric learning method, namely Local Mahalanobis Distance Learning (LMDL), in\norder to enhance the performance of the nearest neighbor classifier. LMDL\nconsiders the neighborhood influence and learns multiple distance metrics for a\nreduced set of input samples. The reduced set is called as prototypes which try\nto preserve local discriminative information as much as possible. The proposed\nLMDL can be kernelized very easily, which is significantly desirable in the\ncase of highly nonlinear data. The quality as well as the efficiency of the\nproposed method assesses through a set of different experiments on various\ndatasets and the obtained results show that LDML as well as the kernelized\nversion is superior to the other related state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 08:45:47 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 20:21:22 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Rajabzadeh", "Hossein", ""], ["Jahromi", "Mansoor Zolghadri", ""], ["Zare", "Mohammad Sadegh", ""], ["Fakhrahmad", "Mostafa", ""]]}, {"id": "1803.01570", "submitter": "Rohit Babbar", "authors": "Rohit Babbar, Bernhard Sch\\\"olkopf", "title": "Adversarial Extreme Multi-label Classification", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal in extreme multi-label classification is to learn a classifier which\ncan assign a small subset of relevant labels to an instance from an extremely\nlarge set of target labels. Datasets in extreme classification exhibit a long\ntail of labels which have small number of positive training instances. In this\nwork, we pose the learning task in extreme classification with large number of\ntail-labels as learning in the presence of adversarial perturbations. This view\nmotivates a robust optimization framework and equivalence to a corresponding\nregularized objective.\n  Under the proposed robustness framework, we demonstrate efficacy of Hamming\nloss for tail-label detection in extreme classification. The equivalent\nregularized objective, in combination with proximal gradient based\noptimization, performs better than state-of-the-art methods on propensity\nscored versions of precision@k and nDCG@k(upto 20% relative improvement over\nPFastreXML - a leading tree-based approach and 60% relative improvement over\nSLEEC - a leading label-embedding approach). Furthermore, we also highlight the\nsub-optimality of a sparse solver in a widely used package for large-scale\nlinear classification, which is interesting in its own right. We also\ninvestigate the spectral properties of label graphs for providing novel\ninsights towards understanding the conditions governing the performance of\nHamming loss based one-vs-rest scheme vis-\\`a-vis label embedding methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 09:30:46 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Babbar", "Rohit", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1803.01575", "submitter": "Michiel Stock", "authors": "Michiel Stock, Tapio Pahikkala, Antti Airola, Bernard De Baets, Willem\n  Waegeman", "title": "A Comparative Study of Pairwise Learning Methods based on Kernel Ridge\n  Regression", "comments": "arXiv admin note: text overlap with arXiv:1606.04275", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems can be formulated as predicting labels for a\npair of objects. Problems of that kind are often referred to as pairwise\nlearning, dyadic prediction or network inference problems. During the last\ndecade kernel methods have played a dominant role in pairwise learning. They\nstill obtain a state-of-the-art predictive performance, but a theoretical\nanalysis of their behavior has been underexplored in the machine learning\nliterature.\n  In this work we review and unify existing kernel-based algorithms that are\ncommonly used in different pairwise learning settings, ranging from matrix\nfiltering to zero-shot learning. To this end, we focus on closed-form efficient\ninstantiations of Kronecker kernel ridge regression. We show that independent\ntask kernel ridge regression, two-step kernel ridge regression and a linear\nmatrix filter arise naturally as a special case of Kronecker kernel ridge\nregression, implying that all these methods implicitly minimize a squared loss.\nIn addition, we analyze universality, consistency and spectral filtering\nproperties. Our theoretical results provide valuable insights in assessing the\nadvantages and limitations of existing pairwise learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 09:49:55 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Stock", "Michiel", ""], ["Pahikkala", "Tapio", ""], ["Airola", "Antti", ""], ["De Baets", "Bernard", ""], ["Waegeman", "Willem", ""]]}, {"id": "1803.01576", "submitter": "Simon Barthelm\\'e", "authors": "Simon Barthelm\\'e, Pierre-Olivier Amblard, Nicolas Tremblay", "title": "Asymptotic Equivalence of Fixed-size and Varying-size Determinantal\n  Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal Point Processes (DPPs) are popular models for point processes\nwith repulsion. They appear in numerous contexts, from physics to graph theory,\nand display appealing theoretical properties. On the more practical side of\nthings, since DPPs tend to select sets of points that are some distance apart\n(repulsion), they have been advocated as a way of producing random subsets with\nhigh diversity. DPPs come in two variants: fixed-size and varying-size. A\nsample from a varying-size DPP is a subset of random cardinality, while in\nfixed-size \"$k$-DPPs\" the cardinality is fixed. The latter makes more sense in\nmany applications, but unfortunately their computational properties are less\nattractive, since, among other things, inclusion probabilities are harder to\ncompute. In this work we show that as the size of the ground set grows,\n$k$-DPPs and DPPs become equivalent, meaning that their inclusion probabilities\nconverge. As a by-product, we obtain saddlepoint formulas for inclusion\nprobabilities in $k$-DPPs. These turn out to be extremely accurate, and suffer\nless from numerical difficulties than exact methods do. Our results also\nsuggest that $k$-DPPs and DPPs also have equivalent maximum likelihood\nestimators. Finally, we obtain results on asymptotic approximations of\nelementary symmetric polynomials which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 09:59:04 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 06:17:32 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Barthelm\u00e9", "Simon", ""], ["Amblard", "Pierre-Olivier", ""], ["Tremblay", "Nicolas", ""]]}, {"id": "1803.01616", "submitter": "Roger Guimera", "authors": "Marc Tarres-Deulofeu, Antonia Godoy-Lorite, Roger Guimera, Marta\n  Sales-Pardo", "title": "Tensorial and bipartite block models for link prediction in layered\n  networks and temporal networks", "comments": null, "journal-ref": "Phys. Rev. E 99, 032307 (2019)", "doi": "10.1103/PhysRevE.99.032307", "report-no": null, "categories": "physics.soc-ph cs.SI physics.data-an q-bio.MN stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many real-world complex systems are well represented as multilayer networks;\npredicting interactions in those systems is one of the most pressing problems\nin predictive network science. To address this challenge, we introduce two\nstochastic block models for multilayer and temporal networks; one of them uses\nnodes as its fundamental unit, whereas the other focuses on links. We also\ndevelop scalable algorithms for inferring the parameters of these models.\nBecause our models describe all layers simultaneously, our approach takes full\nadvantage of the information contained in the whole network when making\npredictions about any particular layer. We illustrate the potential of our\napproach by analyzing two empirical datasets---a temporal network of email\ncommunications, and a network of drug interactions for treating different\ncancer types. We find that modeling all layers simultaneously does result, in\ngeneral, in more accurate link prediction. However, the most predictive model\ndepends on the dataset under consideration; whereas the node-based model is\nmore appropriate for predicting drug interactions, the link-based model is more\nappropriate for predicting email communication.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 11:48:13 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Tarres-Deulofeu", "Marc", ""], ["Godoy-Lorite", "Antonia", ""], ["Guimera", "Roger", ""], ["Sales-Pardo", "Marta", ""]]}, {"id": "1803.01626", "submitter": "M. Sadegh Talebi", "authors": "Mohammad Sadegh Talebi and Odalric-Ambrym Maillard", "title": "Variance-Aware Regret Bounds for Undiscounted Reinforcement Learning in\n  MDPs", "comments": "To appear in Proceedings of the 29th International Conference on\n  Algorithmic Learning Theory (ALT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of reinforcement learning in an unknown and discrete Markov\nDecision Process (MDP) under the average-reward criterion is considered, when\nthe learner interacts with the system in a single stream of observations,\nstarting from an initial state without any reset. We revisit the minimax lower\nbound for that problem by making appear the local variance of the bias function\nin place of the diameter of the MDP. Furthermore, we provide a novel analysis\nof the KL-UCRL algorithm establishing a high-probability regret bound scaling\nas $\\widetilde {\\mathcal O}\\Bigl({\\textstyle \\sqrt{S\\sum_{s,a}{\\bf\nV}^\\star_{s,a}T}}\\Big)$ for this algorithm for ergodic MDPs, where $S$ denotes\nthe number of states and where ${\\bf V}^\\star_{s,a}$ is the variance of the\nbias function with respect to the next-state distribution following action $a$\nin state $s$. The resulting bound improves upon the best previously known\nregret bound $\\widetilde {\\mathcal O}(DS\\sqrt{AT})$ for that algorithm, where\n$A$ and $D$ respectively denote the maximum number of actions (per state) and\nthe diameter of MDP. We finally compare the leading terms of the two bounds in\nsome benchmark MDPs indicating that the derived bound can provide an order of\nmagnitude improvement in some cases. Our analysis leverages novel variations of\nthe transportation lemma combined with Kullback-Leibler concentration\ninequalities, that we believe to be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 12:23:42 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Talebi", "Mohammad Sadegh", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1803.01682", "submitter": "Ray Jiang", "authors": "Ray Jiang, Sven Gowal, Timothy A. Mann, Danilo J. Rezende", "title": "Beyond Greedy Ranking: Slate Optimization via List-CVAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional solution to the recommendation problem greedily ranks\nindividual document candidates by prediction scores. However, this method fails\nto optimize the slate as a whole, and hence, often struggles to capture biases\ncaused by the page layout and document interdepedencies. The slate\nrecommendation problem aims to directly find the optimally ordered subset of\ndocuments (i.e. slates) that best serve users' interests. Solving this problem\nis hard due to the combinatorial explosion in all combinations of document\ncandidates and their display positions on the page. Therefore we propose a\nparadigm shift from the traditional viewpoint of solving a ranking problem to a\ndirect slate generation framework. In this paper, we introduce List Conditional\nVariational Auto-Encoders (List-CVAE), which learns the joint distribution of\ndocuments on the slate conditioned on user responses, and directly generates\nfull slates. Experiments on simulated and real-world data show that List-CVAE\noutperforms popular comparable ranking methods consistently on various scales\nof documents corpora.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 14:40:56 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 22:46:30 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 11:12:49 GMT"}, {"version": "v4", "created": "Wed, 23 May 2018 09:08:19 GMT"}, {"version": "v5", "created": "Thu, 24 May 2018 10:29:00 GMT"}, {"version": "v6", "created": "Sat, 23 Feb 2019 13:56:39 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Jiang", "Ray", ""], ["Gowal", "Sven", ""], ["Mann", "Timothy A.", ""], ["Rezende", "Danilo J.", ""]]}, {"id": "1803.01686", "submitter": "Yuanhang Su", "authors": "Yuanhang Su, C.-C. Jay Kuo", "title": "On Extended Long Short-term Memory and Dependent Bidirectional Recurrent\n  Neural Network", "comments": "github repo: https://github.com/yuanhangsu/ELSTM-DBRNN", "journal-ref": "Neurocomputing 356 (2019): 151-161", "doi": "10.1016/j.neucom.2019.04.044", "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we first analyze the memory behavior in three recurrent neural\nnetworks (RNN) cells; namely, the simple RNN (SRN), the long short-term memory\n(LSTM) and the gated recurrent unit (GRU), where the memory is defined as a\nfunction that maps previous elements in a sequence to the current output. Our\nstudy shows that all three of them suffer rapid memory decay. Then, to\nalleviate this effect, we introduce trainable scaling factors that act like an\nattention mechanism to adjust memory decay adaptively. The new design is called\nthe extended LSTM (ELSTM). Finally, to design a system that is robust to\nprevious erroneous predictions, we propose a dependent bidirectional recurrent\nneural network (DBRNN). Extensive experiments are conducted on different\nlanguage tasks to demonstrate the superiority of the proposed ELSTM and DBRNN\nsolutions. The ELTSM has achieved up to 30% increase in the labeled attachment\nscore (LAS) as compared to LSTM and GRU in the dependency parsing (DP) task.\nOur models also outperform other state-of-the-art models such as bi-attention\nand convolutional sequence to sequence (convseq2seq) by close to 10% in the\nLAS. The code is released as an open source\n(https://github.com/yuanhangsu/ELSTM-DBRNN)\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 02:47:13 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 05:43:49 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 04:30:02 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 23:26:31 GMT"}, {"version": "v5", "created": "Sun, 17 Nov 2019 21:39:02 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Su", "Yuanhang", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1803.01719", "submitter": "Boris Hanin", "authors": "Boris Hanin, David Rolnick", "title": "How to Start Training: The Effect of Initialization and Architecture", "comments": "Final Version, 16p, Accepted NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify and study two common failure modes for early training in deep\nReLU nets. For each we give a rigorous proof of when it occurs and how to avoid\nit, for fully connected and residual architectures. The first failure mode,\nexploding/vanishing mean activation length, can be avoided by initializing\nweights from a symmetric distribution with variance 2/fan-in and, for ResNets,\nby correctly weighting the residual modules. We prove that the second failure\nmode, exponentially large variance of activation length, never occurs in\nresidual nets once the first failure mode is avoided. In contrast, for fully\nconnected nets, we prove that this failure mode can happen and is avoided by\nkeeping constant the sum of the reciprocals of layer widths. We demonstrate\nempirically the effectiveness of our theoretical results in predicting when\nnetworks are able to start training. In particular, we note that many popular\ninitializations fail our criteria, whereas correct initialization and\narchitecture allows much deeper networks to be trained.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 15:17:50 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 13:37:00 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 14:52:46 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hanin", "Boris", ""], ["Rolnick", "David", ""]]}, {"id": "1803.01785", "submitter": "Sebastian Tschiatschek", "authors": "Sebastian Tschiatschek, Aytunc Sahin, Andreas Krause", "title": "Differentiable Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning of submodular functions from data. These functions are\nimportant in machine learning and have a wide range of applications, e.g. data\nsummarization, feature selection and active learning. Despite their\ncombinatorial nature, submodular functions can be maximized approximately with\nstrong theoretical guarantees in polynomial time. Typically, learning the\nsubmodular function and optimization of that function are treated separately,\ni.e. the function is first learned using a proxy objective and subsequently\nmaximized. In contrast, we show how to perform learning and optimization\njointly. By interpreting the output of greedy maximization algorithms as\ndistributions over sequences of items and smoothening these distributions, we\nobtain a differentiable objective. In this way, we can differentiate through\nthe maximization algorithms and optimize the model to work well with the\noptimization algorithm. We theoretically characterize the error made by our\napproach, yielding insights into the tradeoff of smoothness and accuracy. We\ndemonstrate the effectiveness of our approach for jointly learning and\noptimizing on synthetic maximum cut data, and on real world applications such\nas product recommendation and image collection summarization.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 17:16:22 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 20:06:50 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Tschiatschek", "Sebastian", ""], ["Sahin", "Aytunc", ""], ["Krause", "Andreas", ""]]}, {"id": "1803.01802", "submitter": "Friedrich Solowjow", "authors": "Friedrich Solowjow, Dominik Baumann, Jochen Garcke, Sebastian Trimpe", "title": "Event-triggered Learning for Resource-efficient Networked Control", "comments": "7 pages, 4 figures, to appear in the 2018 American Control Conference\n  (ACC)", "journal-ref": null, "doi": "10.23919/ACC.2018.8431102", "report-no": null, "categories": "cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common event-triggered state estimation (ETSE) algorithms save communication\nin networked control systems by predicting agents' behavior, and transmitting\nupdates only when the predictions deviate significantly. The effectiveness in\nreducing communication thus heavily depends on the quality of the dynamics\nmodels used to predict the agents' states or measurements. Event-triggered\nlearning is proposed herein as a novel concept to further reduce communication:\nwhenever poor communication performance is detected, an identification\nexperiment is triggered and an improved prediction model learned from data.\nEffective learning triggers are obtained by comparing the actual communication\nrate with the one that is expected based on the current model. By analyzing\nstatistical properties of the inter-communication times and leveraging powerful\nconvergence results, the proposed trigger is proven to limit learning\nexperiments to the necessary instants. Numerical and physical experiments\ndemonstrate that event-triggered learning improves robustness toward changing\nenvironments and yields lower communication rates than common ETSE.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 17:48:43 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 11:47:33 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Solowjow", "Friedrich", ""], ["Baumann", "Dominik", ""], ["Garcke", "Jochen", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1803.01814", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Ron Banner, Itay Golan, Daniel Soudry", "title": "Norm matters: efficient and accurate normalization schemes in deep\n  networks", "comments": "http://papers.nips.cc/paper/7485-norm-matters-efficient-and-accurate-normalization-schemes-in-deep-networks", "journal-ref": "NeurIPS2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, Batch-Normalization has been commonly used in deep\nnetworks, allowing faster training and high performance for a wide variety of\napplications. However, the reasons behind its merits remained unanswered, with\nseveral shortcomings that hindered its use for certain tasks. In this work, we\npresent a novel view on the purpose and function of normalization methods and\nweight-decay, as tools to decouple weights' norm from the underlying optimized\nobjective. This property highlights the connection between practices such as\nnormalization, weight decay and learning-rate adjustments. We suggest several\nalternatives to the widely used $L^2$ batch-norm, using normalization in $L^1$\nand $L^\\infty$ spaces that can substantially improve numerical stability in\nlow-precision implementations as well as provide computational and memory\nbenefits. We demonstrate that such methods enable the first batch-norm\nalternative to work for half-precision implementations. Finally, we suggest a\nmodification to weight-normalization, which improves its performance on\nlarge-scale tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 18:16:43 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 13:37:48 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 13:01:44 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Hoffer", "Elad", ""], ["Banner", "Ron", ""], ["Golan", "Itay", ""], ["Soudry", "Daniel", ""]]}, {"id": "1803.01833", "submitter": "Guillaume Martinet", "authors": "Samory Kpotufe, Guillaume Martinet", "title": "Marginal Singularity, and the Benefits of Labels in Covariate-Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new minimax results that concisely capture the relative benefits\nof source and target labeled data, under covariate-shift. Namely, we show that\nthe benefits of target labels are controlled by a transfer-exponent $\\gamma$\nthat encodes how singular Q is locally w.r.t. P, and interestingly allows\nsituations where transfer did not seem possible under previous insights. In\nfact, our new minimax analysis - in terms of $\\gamma$ - reveals a continuum of\nregimes ranging from situations where target labels have little benefit, to\nregimes where target labels dramatically improve classification. We then show\nthat a recently proposed semi-supervised procedure can be extended to adapt to\nunknown $\\gamma$, and therefore requests labels only when beneficial, while\nachieving minimax transfer rates.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 18:52:08 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 17:31:45 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 04:57:54 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kpotufe", "Samory", ""], ["Martinet", "Guillaume", ""]]}, {"id": "1803.01834", "submitter": "Alexander Ororbia II", "authors": "Alexander G. Ororbia, Ankur Mali, Daniel Kifer, and C. Lee Giles", "title": "Conducting Credit Assignment by Aligning Local Representations", "comments": "Full document revision/overhaul, new results/analyses, new diagrams,\n  addition of appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using back-propagation and its variants to train deep networks is often\nproblematic for new users. Issues such as exploding gradients, vanishing\ngradients, and high sensitivity to weight initialization strategies often make\nnetworks difficult to train, especially when users are experimenting with new\narchitectures. Here, we present Local Representation Alignment (LRA), a\ntraining procedure that is much less sensitive to bad initializations, does not\nrequire modifications to the network architecture, and can be adapted to\nnetworks with highly nonlinear and discrete-valued activation functions.\nFurthermore, we show that one variation of LRA can start with a null\ninitialization of network weights and still successfully train networks with a\nwide variety of nonlinearities, including tanh, ReLU-6, softplus, signum and\nothers that may draw their inspiration from biology.\n  A comprehensive set of experiments on MNIST and the much harder Fashion MNIST\ndata sets show that LRA can be used to train networks robustly and effectively,\nsucceeding even when back-propagation fails and outperforming other alternative\nlearning algorithms, such as target propagation and feedback alignment.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 18:54:02 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 21:10:27 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Ororbia", "Alexander G.", ""], ["Mali", "Ankur", ""], ["Kifer", "Daniel", ""], ["Giles", "C. Lee", ""]]}, {"id": "1803.01840", "submitter": "Kyriacos Shiarlis Mr", "authors": "Kyriacos Shiarlis, Markus Wulfmeier, Sasha Salter, Shimon Whiteson,\n  Ingmar Posner", "title": "TACO: Learning Task Decomposition via Temporal Alignment for Control", "comments": "12 Pages. Published at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many advanced Learning from Demonstration (LfD) methods consider the\ndecomposition of complex, real-world tasks into simpler sub-tasks. By reusing\nthe corresponding sub-policies within and between tasks, they provide training\ndata for each policy from different high-level tasks and compose them to\nperform novel ones. Existing approaches to modular LfD focus either on learning\na single high-level task or depend on domain knowledge and temporal\nsegmentation. In contrast, we propose a weakly supervised, domain-agnostic\napproach based on task sketches, which include only the sequence of sub-tasks\nperformed in each demonstration. Our approach simultaneously aligns the\nsketches with the observed demonstrations and learns the required sub-policies.\nThis improves generalisation in comparison to separate optimisation procedures.\nWe evaluate the approach on multiple domains, including a simulated 3D robot\narm control task using purely image-based observations. The results show that\nour approach performs commensurately with fully supervised approaches, while\nrequiring significantly less annotation effort.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 19:26:16 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 09:07:40 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Shiarlis", "Kyriacos", ""], ["Wulfmeier", "Markus", ""], ["Salter", "Sasha", ""], ["Whiteson", "Shimon", ""], ["Posner", "Ingmar", ""]]}, {"id": "1803.01901", "submitter": "Xintao Wu", "authors": "Yongkai Wu and Lu Zhang and Xintao Wu", "title": "On Discrimination Discovery and Removal in Ranked Data using Causal\n  Graph", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models learned from historical data are widely used to help\ncompanies and organizations make decisions. However, they may digitally\nunfairly treat unwanted groups, raising concerns about fairness and\ndiscrimination. In this paper, we study the fairness-aware ranking problem\nwhich aims to discover discrimination in ranked datasets and reconstruct the\nfair ranking. Existing methods in fairness-aware ranking are mainly based on\nstatistical parity that cannot measure the true discriminatory effect since\ndiscrimination is causal. On the other hand, existing methods in causal-based\nanti-discrimination learning focus on classification problems and cannot be\ndirectly applied to handle the ranked data. To address these limitations, we\npropose to map the rank position to a continuous score variable that represents\nthe qualification of the candidates. Then, we build a causal graph that\nconsists of both the discrete profile attributes and the continuous score. The\npath-specific effect technique is extended to the mixed-variable causal graph\nto identify both direct and indirect discrimination. The relationship between\nthe path-specific effects for the ranked data and those for the binary decision\nis theoretically analyzed. Finally, algorithms for discovering and removing\ndiscrimination from a ranked dataset are developed. Experiments using the real\ndataset show the effectiveness of our approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 19:53:40 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""]]}, {"id": "1803.01905", "submitter": "Mor Shpigel Nacson", "authors": "Mor Shpigel Nacson, Jason D. Lee, Suriya Gunasekar, Pedro H. P.\n  Savarese, Nathan Srebro, Daniel Soudry", "title": "Convergence of Gradient Descent on Separable Data", "comments": "AISTATS Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a detailed study on the implicit bias of gradient descent when\noptimizing loss functions with strictly monotone tails, such as the logistic\nloss, over separable datasets. We look at two basic questions: (a) what are the\nconditions on the tail of the loss function under which gradient descent\nconverges in the direction of the $L_2$ maximum-margin separator? (b) how does\nthe rate of margin convergence depend on the tail of the loss function and the\nchoice of the step size? We show that for a large family of super-polynomial\ntailed losses, gradient descent iterates on linear networks of any depth\nconverge in the direction of $L_2$ maximum-margin solution, while this does not\nhold for losses with heavier tails. Within this family, for simple linear\nmodels we show that the optimal rates with fixed step size is indeed obtained\nfor the commonly used exponentially tailed losses such as logistic loss.\nHowever, with a fixed step size the optimal convergence rate is extremely slow\nas $1/\\log(t)$, as also proved in Soudry et al. (2018). For linear models with\nexponential loss, we further prove that the convergence rate could be improved\nto $\\log (t) /\\sqrt{t}$ by using aggressive step sizes that compensates for the\nrapidly vanishing gradients. Numerical results suggest this method might be\nuseful for deep networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 20:03:46 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 11:55:53 GMT"}, {"version": "v3", "created": "Sun, 24 Mar 2019 09:56:50 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Nacson", "Mor Shpigel", ""], ["Lee", "Jason D.", ""], ["Gunasekar", "Suriya", ""], ["Savarese", "Pedro H. P.", ""], ["Srebro", "Nathan", ""], ["Soudry", "Daniel", ""]]}, {"id": "1803.01927", "submitter": "Alpha Albert Lee", "authors": "Yao Zhang, Andrew M. Saxe, Madhu S. Advani, Alpha A. Lee", "title": "Energy-entropy competition and the effectiveness of stochastic gradient\n  descent in machine learning", "comments": null, "journal-ref": null, "doi": "10.1080/00268976.2018.1483535", "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding parameters that minimise a loss function is at the core of many\nmachine learning methods. The Stochastic Gradient Descent algorithm is widely\nused and delivers state of the art results for many problems. Nonetheless,\nStochastic Gradient Descent typically cannot find the global minimum, thus its\nempirical effectiveness is hitherto mysterious. We derive a correspondence\nbetween parameter inference and free energy minimisation in statistical\nphysics. The degree of undersampling plays the role of temperature. Analogous\nto the energy-entropy competition in statistical physics, wide but shallow\nminima can be optimal if the system is undersampled, as is typical in many\napplications. Moreover, we show that the stochasticity in the algorithm has a\nnon-trivial correlation structure which systematically biases it towards wide\nminima. We illustrate our argument with two prototypical models: image\nclassification using deep learning, and a linear neural network where we can\nanalytically reveal the relationship between entropy and out-of-sample error.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 21:12:04 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Zhang", "Yao", ""], ["Saxe", "Andrew M.", ""], ["Advani", "Madhu S.", ""], ["Lee", "Alpha A.", ""]]}, {"id": "1803.01968", "submitter": "Theja Tulabandhula", "authors": "Debjyoti Saharoy and Theja Tulabandhula", "title": "An Online Algorithm for Learning Buyer Behavior under Realistic Pricing\n  Restrictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new efficient online algorithm to learn the parameters governing\nthe purchasing behavior of a utility maximizing buyer, who responds to prices,\nin a repeated interaction setting. The key feature of our algorithm is that it\ncan learn even non-linear buyer utility while working with arbitrary price\nconstraints that the seller may impose. This overcomes a major shortcoming of\nprevious approaches, which use unrealistic prices to learn these parameters\nmaking them unsuitable in practice.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 00:48:02 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Saharoy", "Debjyoti", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1803.01980", "submitter": "Luke Pfister", "authors": "Luke Pfister, Yoram Bresler", "title": "Learning Filter Bank Sparsifying Transforms", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2883021", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is said to follow the transform (or analysis) sparsity model if it\nbecomes sparse when acted on by a linear operator called a sparsifying\ntransform. Several algorithms have been designed to learn such a transform\ndirectly from data, and data-adaptive sparsifying transforms have demonstrated\nexcellent performance in signal restoration tasks. Sparsifying transforms are\ntypically learned using small sub-regions of data called patches, but these\nalgorithms often ignore redundant information shared between neighboring\npatches.\n  We show that many existing transform and analysis sparse representations can\nbe viewed as filter banks, thus linking the local properties of patch-based\nmodel to the global properties of a convolutional model. We propose a new\ntransform learning framework where the sparsifying transform is an undecimated\nperfect reconstruction filter bank. Unlike previous transform learning\nalgorithms, the filter length can be chosen independently of the number of\nfilter bank channels. Numerical results indicate filter bank sparsifying\ntransforms outperform existing patch-based transform learning for image\ndenoising while benefiting from additional flexibility in the design process.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 01:35:01 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Pfister", "Luke", ""], ["Bresler", "Yoram", ""]]}, {"id": "1803.02021", "submitter": "Yuhuai(Tony) Wu", "authors": "Yuhuai Wu, Mengye Ren, Renjie Liao, Roger Grosse", "title": "Understanding Short-Horizon Bias in Stochastic Meta-Optimization", "comments": "17 pages, 8 figures; To appear in ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Careful tuning of the learning rate, or even schedules thereof, can be\ncrucial to effective neural net training. There has been much recent interest\nin gradient-based meta-optimization, where one tunes hyperparameters, or even\nlearns an optimizer, in order to minimize the expected loss when the training\nprocedure is unrolled. But because the training procedure must be unrolled\nthousands of times, the meta-objective must be defined with an\norders-of-magnitude shorter time horizon than is typical for neural net\ntraining. We show that such short-horizon meta-objectives cause a serious bias\ntowards small step sizes, an effect we term short-horizon bias. We introduce a\ntoy problem, a noisy quadratic cost function, on which we analyze short-horizon\nbias by deriving and comparing the optimal schedules for short and long time\nhorizons. We then run meta-optimization experiments (both offline and online)\non standard benchmark datasets, showing that meta-optimization chooses too\nsmall a learning rate by multiple orders of magnitude, even when run with a\nmoderately long time horizon (100 steps) typical of work in the area. We\nbelieve short-horizon bias is a fundamental problem that needs to be addressed\nif meta-optimization is to scale to practical neural net training regimes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 05:01:37 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Wu", "Yuhuai", ""], ["Ren", "Mengye", ""], ["Liao", "Renjie", ""], ["Grosse", "Roger", ""]]}, {"id": "1803.02030", "submitter": "Jim Kay", "authors": "James W. Kay and Robin A. A. Ince", "title": "Exact partial information decompositions for Gaussian systems based on\n  dependency constraints", "comments": "39 pages, 9 figures, 9 tables", "journal-ref": "Entropy 2018, 20(4), 240", "doi": "10.3390/e20040240", "report-no": null, "categories": "cond-mat.stat-mech cs.IT math.IT physics.data-an q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Partial Information Decomposition (PID) [arXiv:1004.2515] provides a\ntheoretical framework to characterize and quantify the structure of\nmultivariate information sharing. A new method (Idep) has recently been\nproposed for computing a two-predictor PID over discrete spaces.\n[arXiv:1709.06653] A lattice of maximum entropy probability models is\nconstructed based on marginal dependency constraints, and the unique\ninformation that a particular predictor has about the target is defined as the\nminimum increase in joint predictor-target mutual information when that\nparticular predictor-target marginal dependency is constrained. Here, we apply\nthe Idep approach to Gaussian systems, for which the marginally constrained\nmaximum entropy models are Gaussian graphical models. Closed form solutions for\nthe Idep PID are derived for both univariate and multivariate Gaussian systems.\nNumerical and graphical illustrations are provided, together with practical and\ntheoretical comparisons of the Idep PID with the minimum mutual information PID\n(Immi). [arXiv:1411.2832] In particular, it is proved that the Immi method\ngenerally produces larger estimates of redundancy and synergy than does the\nIdep method. In discussion of the practical examples, the PIDs are complemented\nby the use of deviance tests for the comparison of Gaussian graphical models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 06:42:38 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kay", "James W.", ""], ["Ince", "Robin A. A.", ""]]}, {"id": "1803.02032", "submitter": "Adam Gustafson", "authors": "Adam Gustafson, Hariharan Narayanan", "title": "John's Walk", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.DS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an affine-invariant random walk for drawing uniform random samples\nfrom a convex body $\\mathcal{K} \\subset \\mathbb{R}^n$ that uses maximum volume\ninscribed ellipsoids, known as John's ellipsoids, for the proposal\ndistribution. Our algorithm makes steps using uniform sampling from the John's\nellipsoid of the symmetrization of $\\mathcal{K}$ at the current point. We show\nthat from a warm start, the random walk mixes in $\\widetilde{O}(n^7)$ steps\nwhere the log factors depend only on constants associated with the warm start\nand desired total variation distance to uniformity. We also prove polynomial\nmixing bounds starting from any fixed point $x$ such that for any chord $pq$ of\n$\\mathcal{K}$ containing $x$, $\\left|\\log \\frac{|p-x|}{|q-x|}\\right|$ is\nbounded above by a polynomial in $n$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 07:01:51 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 19:36:44 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Gustafson", "Adam", ""], ["Narayanan", "Hariharan", ""]]}, {"id": "1803.02042", "submitter": "Biau Gerard", "authors": "G\\'erard Biau (1), Beno\\^it Cadre (2), Laurent Rouv\\`i\\`ere (2) ((1)\n  LPSM UMR 8001, (2) IRMAR)", "title": "Accelerated Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient tree boosting is a prediction algorithm that sequentially produces a\nmodel in the form of linear combinations of decision trees, by solving an\ninfinite-dimensional optimization problem. We combine gradient boosting and\nNesterov's accelerated descent to design a new algorithm, which we call AGB\n(for Accelerated Gradient Boosting). Substantial numerical evidence is provided\non both synthetic and real-life data sets to assess the excellent performance\nof the method in a large variety of prediction problems. It is empirically\nshown that AGB is much less sensitive to the shrinkage parameter and outputs\npredictors that are considerably more sparse in the number of trees, while\nretaining the exceptional performance of gradient boosting.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 07:23:17 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Biau", "G\u00e9rard", ""], ["Cadre", "Beno\u00eet", ""], ["Rouv\u00ec\u00e8re", "Laurent", ""]]}, {"id": "1803.02043", "submitter": "Savitha Ramasamy", "authors": "Savitha Ramasamy, Kanagasabai Rajaraman, Pavitra Krishnaswamy, Vijay\n  Chandrasekhar", "title": "Online Deep Learning: Growing RBM on the fly", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel online learning algorithm for Restricted Boltzmann\nMachines (RBM), namely, the Online Generative Discriminative Restricted\nBoltzmann Machine (OGD-RBM), that provides the ability to build and adapt the\nnetwork architecture of RBM according to the statistics of streaming data. The\nOGD-RBM is trained in two phases: (1) an online generative phase for\nunsupervised feature representation at the hidden layer and (2) a\ndiscriminative phase for classification. The online generative training begins\nwith zero neurons in the hidden layer, adds and updates the neurons to adapt to\nstatistics of streaming data in a single pass unsupervised manner, resulting in\na feature representation best suited to the data. The discriminative phase is\nbased on stochastic gradient descent and associates the represented features to\nthe class labels. We demonstrate the OGD-RBM on a set of multi-category and\nbinary classification problems for data sets having varying degrees of\nclass-imbalance. We first apply the OGD-RBM algorithm on the multi-class MNIST\ndataset to characterize the network evolution. We demonstrate that the online\ngenerative phase converges to a stable, concise network architecture, wherein\nindividual neurons are inherently discriminative to the class labels despite\nunsupervised training. We then benchmark OGD-RBM performance to other machine\nlearning, neural network and ClassRBM techniques for credit scoring\napplications using 3 public non-stationary two-class credit datasets with\nvarying degrees of class-imbalance. We report that OGD-RBM improves accuracy by\n2.5-3% over batch learning techniques while requiring at least 24%-70% fewer\nneurons and fewer training samples. This online generative training approach\ncan be extended greedily to multiple layers for training Deep Belief Networks\nin non-stationary data mining applications without the need for a priori fixed\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 07:24:21 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Ramasamy", "Savitha", ""], ["Rajaraman", "Kanagasabai", ""], ["Krishnaswamy", "Pavitra", ""], ["Chandrasekhar", "Vijay", ""]]}, {"id": "1803.02108", "submitter": "Emiel Hoogeboom", "authors": "Emiel Hoogeboom, Jorn W.T. Peters, Taco S. Cohen, Max Welling", "title": "HexaConv", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of Convolutional Neural Networks stems in large part from\ntheir ability to exploit the translation invariance that is inherent in many\nlearning problems. Recently, it was shown that CNNs can exploit other\ninvariances, such as rotation invariance, by using group convolutions instead\nof planar convolutions. However, for reasons of performance and ease of\nimplementation, it has been necessary to limit the group convolution to\ntransformations that can be applied to the filters without interpolation. Thus,\nfor images with square pixels, only integer translations, rotations by\nmultiples of 90 degrees, and reflections are admissible.\n  Whereas the square tiling provides a 4-fold rotational symmetry, a hexagonal\ntiling of the plane has a 6-fold rotational symmetry. In this paper we show how\none can efficiently implement planar convolution and group convolution over\nhexagonal lattices, by re-using existing highly optimized convolution routines.\nWe find that, due to the reduced anisotropy of hexagonal filters, planar\nHexaConv provides better accuracy than planar convolution with square filters,\ngiven a fixed parameter budget. Furthermore, we find that the increased degree\nof symmetry of the hexagonal grid increases the effectiveness of group\nconvolutions, by allowing for more parameter sharing. We show that our method\nsignificantly outperforms conventional CNNs on the AID aerial scene\nclassification dataset, even outperforming ImageNet pre-trained models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 11:05:39 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Hoogeboom", "Emiel", ""], ["Peters", "Jorn W. T.", ""], ["Cohen", "Taco S.", ""], ["Welling", "Max", ""]]}, {"id": "1803.02222", "submitter": "Xi Fang", "authors": "Xi Fang, Zengmao Wang, Xinyao Tang, Chen Wu", "title": "Multi-class Active Learning: A Hybrid Informative and Representative\n  Criterion Inspired Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling each instance in a large dataset is extremely labor- and time-\nconsuming . One way to alleviate this problem is active learning, which aims to\nwhich discover the most valuable instances for labeling to construct a powerful\nclassifier. Considering both informativeness and representativeness provides a\npromising way to design a practical active learning. However, most existing\nactive learning methods select instances favoring either informativeness or\nrepresentativeness. Meanwhile, many are designed based on the binary class, so\nthat they may present suboptimal solutions on the datasets with multiple\nclasses. In this paper, a hybrid informative and representative criterion based\nmulti-class active learning approach is proposed. We combine the informative\ninformativeness and representativeness into one formula, which can be solved\nunder a unified framework. The informativeness is measured by the margin\nminimum while the representative information is measured by the maximum mean\ndiscrepancy. By minimizing the upper bound for the true risk, we generalize the\nempirical risk minimization principle to the active learning setting.\nSimultaneously, our proposed method makes full use of the label information,\nand the proposed active learning is designed based on multiple classes. So the\nproposed method is not suitable to the binary class but also the multiple\nclasses. We conduct our experiments on twelve benchmark UCI data sets, and the\nexperimental results demonstrate that the proposed method performs better than\nsome state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 14:32:15 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Fang", "Xi", ""], ["Wang", "Zengmao", ""], ["Tang", "Xinyao", ""], ["Wu", "Chen", ""]]}, {"id": "1803.02247", "submitter": "Fernando Gama", "authors": "Fernando Gama, Antonio G. Marques, Alejandro Ribeiro, Geert Leus", "title": "MIMO Graph Filters for Convolutional Neural Networks", "comments": "Submitted to 19th IEEE International Workshop on Signal Processing\n  Advances in Wireless Communications (SPAWC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Superior performance and ease of implementation have fostered the adoption of\nConvolutional Neural Networks (CNNs) for a wide array of inference and\nreconstruction tasks. CNNs implement three basic blocks: convolution, pooling\nand pointwise nonlinearity. Since the two first operations are well-defined\nonly on regular-structured data such as audio or images, application of CNNs to\ncontemporary datasets where the information is defined in irregular domains is\nchallenging. This paper investigates CNNs architectures to operate on signals\nwhose support can be modeled using a graph. Architectures that replace the\nregular convolution with a so-called linear shift-invariant graph filter have\nbeen recently proposed. This paper goes one step further and, under the\nframework of multiple-input multiple-output (MIMO) graph filters, imposes\nadditional structure on the adopted graph filters, to obtain three new (more\nparsimonious) architectures. The proposed architectures result in a lower\nnumber of model parameters, reducing the computational complexity, facilitating\nthe training, and mitigating the risk of overfitting. Simulations show that the\nproposed simpler architectures achieve similar performance as more complex\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 15:18:56 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Gama", "Fernando", ""], ["Marques", "Antonio G.", ""], ["Ribeiro", "Alejandro", ""], ["Leus", "Geert", ""]]}, {"id": "1803.02312", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Lin Yang, Mengdi Wang, Tuo Zhao", "title": "Dimensionality Reduction for Stationary Time Series via Stochastic\n  Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization naturally arises in machine learning. Efficient\nalgorithms with provable guarantees, however, are still largely missing, when\nthe objective function is nonconvex and the data points are dependent. This\npaper studies this fundamental challenge through a streaming PCA problem for\nstationary time series data. Specifically, our goal is to estimate the\nprinciple component of time series data with respect to the covariance matrix\nof the stationary distribution. Computationally, we propose a variant of Oja's\nalgorithm combined with downsampling to control the bias of the stochastic\ngradient caused by the data dependency. Theoretically, we quantify the\nuncertainty of our proposed stochastic algorithm based on diffusion\napproximations. This allows us to prove the asymptotic rate of convergence and\nfurther implies near optimal asymptotic sample complexity. Numerical\nexperiments are provided to support our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 17:38:03 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 17:37:35 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 17:54:14 GMT"}, {"version": "v4", "created": "Mon, 1 Oct 2018 16:47:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chen", "Minshuo", ""], ["Yang", "Lin", ""], ["Wang", "Mengdi", ""], ["Zhao", "Tuo", ""]]}, {"id": "1803.02323", "submitter": "Steven Young M", "authors": "Steven Young, Tamer Abdou, and Ayse Bener", "title": "Deep Super Learner: A Deep Ensemble for Classification Problems", "comments": "12 pages, 3 figures, accepted to the 31st Canadian Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become very popular for tasks such as predictive modeling\nand pattern recognition in handling big data. Deep learning is a powerful\nmachine learning method that extracts lower level features and feeds them\nforward for the next layer to identify higher level features that improve\nperformance. However, deep neural networks have drawbacks, which include many\nhyper-parameters and infinite architectures, opaqueness into results, and\nrelatively slower convergence on smaller datasets. While traditional machine\nlearning algorithms can address these drawbacks, they are not typically capable\nof the performance levels achieved by deep neural networks. To improve\nperformance, ensemble methods are used to combine multiple base learners. Super\nlearning is an ensemble that finds the optimal combination of diverse learning\nalgorithms. This paper proposes deep super learning as an approach which\nachieves log loss and accuracy results competitive to deep neural networks\nwhile employing traditional machine learning algorithms in a hierarchical\nstructure. The deep super learner is flexible, adaptable, and easy to train\nwith good performance across different tasks using identical hyper-parameter\nvalues. Using traditional machine learning requires fewer hyper-parameters,\nallows transparency into results, and has relatively fast convergence on\nsmaller datasets. Experimental results show that the deep super learner has\nsuperior performance compared to the individual base learners, single-layer\nensembles, and in some cases deep neural networks. Performance of the deep\nsuper learner may further be improved with task-specific tuning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 18:19:55 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Young", "Steven", ""], ["Abdou", "Tamer", ""], ["Bener", "Ayse", ""]]}, {"id": "1803.02329", "submitter": "Kevin Swersky", "authors": "Milad Hashemi, Kevin Swersky, Jamie A. Smith, Grant Ayers, Heiner\n  Litz, Jichuan Chang, Christos Kozyrakis, Parthasarathy Ranganathan", "title": "Learning Memory Access Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion in workload complexity and the recent slow-down in Moore's law\nscaling call for new approaches towards efficient computing. Researchers are\nnow beginning to use recent advances in machine learning in software\noptimizations, augmenting or replacing traditional heuristics and data\nstructures. However, the space of machine learning for computer hardware\narchitecture is only lightly explored. In this paper, we demonstrate the\npotential of deep learning to address the von Neumann bottleneck of memory\nperformance. We focus on the critical problem of learning memory access\npatterns, with the goal of constructing accurate and efficient memory\nprefetchers. We relate contemporary prefetching strategies to n-gram models in\nnatural language processing, and show how recurrent neural networks can serve\nas a drop-in replacement. On a suite of challenging benchmark datasets, we find\nthat neural networks consistently demonstrate superior performance in terms of\nprecision and recall. This work represents the first step towards practical\nneural-network based prefetching, and opens a wide range of exciting directions\nfor machine learning in computer architecture research.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 18:41:04 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Hashemi", "Milad", ""], ["Swersky", "Kevin", ""], ["Smith", "Jamie A.", ""], ["Ayers", "Grant", ""], ["Litz", "Heiner", ""], ["Chang", "Jichuan", ""], ["Kozyrakis", "Christos", ""], ["Ranganathan", "Parthasarathy", ""]]}, {"id": "1803.02398", "submitter": "David Koes", "authors": "Joshua Hochuli, Alec Helbling, Tamar Skaist, Matthew Ragoza, David\n  Ryan Koes", "title": "Visualizing Convolutional Neural Network Protein-Ligand Scoring", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmgm.2018.06.005", "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein-ligand scoring is an important step in a structure-based drug design\npipeline. Selecting a correct binding pose and predicting the binding affinity\nof a protein-ligand complex enables effective virtual screening. Machine\nlearning techniques can make use of the increasing amounts of structural data\nthat are becoming publicly available. Convolutional neural network (CNN)\nscoring functions in particular have shown promise in pose selection and\naffinity prediction for protein-ligand complexes. Neural networks are known for\nbeing difficult to interpret. Understanding the decisions of a particular\nnetwork can help tune parameters and training data to maximize performance.\nVisualization of neural networks helps decompose complex scoring functions into\npictures that are more easily parsed by humans. Here we present three methods\nfor visualizing how individual protein-ligand complexes are interpreted by 3D\nconvolutional neural networks. We also present a visualization of the\nconvolutional filters and their weights. We describe how the intuition provided\nby these visualizations aids in network design.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 19:40:51 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hochuli", "Joshua", ""], ["Helbling", "Alec", ""], ["Skaist", "Tamar", ""], ["Ragoza", "Matthew", ""], ["Koes", "David Ryan", ""]]}, {"id": "1803.02421", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore, John Robinson", "title": "Masked Conditional Neural Networks for Audio Classification", "comments": "Restricted BoltzmannMachine, RBM, Conditional Restricted Boltzmann\n  Machine, CRBM, Music Information Retrieval, MIR, Conditional Neural Network,\n  CLNN, Masked Conditional Neural Network, MCLNN, Deep Neural Network", "journal-ref": "International Conference on Artificial Neural Networks (ICANN)\n  Year: 2017", "doi": "10.1007/978-3-319-68612-7_40", "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the ConditionaL Neural Network (CLNN) and the Masked ConditionaL\nNeural Network (MCLNN) designed for temporal signal recognition. The CLNN takes\ninto consideration the temporal nature of the sound signal and the MCLNN\nextends upon the CLNN through a binary mask to preserve the spatial locality of\nthe features and allows an automated exploration of the features combination\nanalogous to hand-crafting the most relevant features for the recognition task.\nMCLNN has achieved competitive recognition accuracies on the GTZAN and the\nISMIR2004 music datasets that surpass several state-of-the-art neural network\nbased architectures and hand-crafted methods applied on both datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 20:54:00 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 10:56:33 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1803.02423", "submitter": "Daniel Sussman", "authors": "Daniel L. Sussman, Youngser Park, Carey E. Priebe, Vince Lyzinski", "title": "Matched Filters for Noisy Induced Subgraph Detection", "comments": "41 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding the vertex correspondence between two noisy graphs\nwith different number of vertices where the smaller graph is still large has\nmany applications in social networks, neuroscience, and computer vision. We\npropose a solution to this problem via a graph matching matched filter:\ncentering and padding the smaller adjacency matrix and applying graph matching\nmethods to align it to the larger network. The centering and padding schemes\ncan be incorporated into any algorithm that matches using adjacency matrices.\nUnder a statistical model for correlated pairs of graphs, which yields a noisy\ncopy of the small graph within the larger graph, the resulting optimization\nproblem can be guaranteed to recover the true vertex correspondence between the\nnetworks.\n  However, there are currently no efficient algorithms for solving this\nproblem. To illustrate the possibilities and challenges of such problems, we\nuse an algorithm that can exploit a partially known correspondence and show via\nvaried simulations and applications to {\\it Drosophila} and human connectomes\nthat this approach can achieve good performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 20:55:17 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 21:28:38 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 20:23:00 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Sussman", "Daniel L.", ""], ["Park", "Youngser", ""], ["Priebe", "Carey E.", ""], ["Lyzinski", "Vince", ""]]}, {"id": "1803.02432", "submitter": "Daniel Ting", "authors": "Daniel Ting, Michael I. Jordan", "title": "On Nonlinear Dimensionality Reduction, Linear Smoothing and Autoencoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop theory for nonlinear dimensionality reduction (NLDR). A number of\nNLDR methods have been developed, but there is limited understanding of how\nthese methods work and the relationships between them. There is limited basis\nfor using existing NLDR theory for deriving new algorithms. We provide a novel\nframework for analysis of NLDR via a connection to the statistical theory of\nlinear smoothers. This allows us to both understand existing methods and derive\nnew ones. We use this connection to smoothing to show that asymptotically,\nexisting NLDR methods correspond to discrete approximations of the solutions of\nsets of differential equations given a boundary condition. In particular, we\ncan characterize many existing methods in terms of just three limiting\ndifferential operators and boundary conditions. Our theory also provides a way\nto assert that one method is preferable to another; indeed, we show Local\nTangent Space Alignment is superior within a class of methods that assume a\nglobal coordinate chart defines an isometric embedding of the manifold.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 21:35:16 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Ting", "Daniel", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1803.02504", "submitter": "Bowen Wu", "authors": "Bowen Wu, Zhangling Chen, Jun Wang, Huaming Wu", "title": "Exponential Discriminative Metric Embedding in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the remarkable success achieved by the Convolutional Neural Networks\n(CNNs) in object recognition recently, deep learning is being widely used in\nthe computer vision community. Deep Metric Learning (DML), integrating deep\nlearning with conventional metric learning, has set new records in many fields,\nespecially in classification task. In this paper, we propose a replicable DML\nmethod, called Include and Exclude (IE) loss, to force the distance between a\nsample and its designated class center away from the mean distance of this\nsample to other class centers with a large margin in the exponential feature\nprojection space. With the supervision of IE loss, we can train CNNs to enhance\nthe intra-class compactness and inter-class separability, leading to great\nimprovements on several public datasets ranging from object recognition to face\nverification. We conduct a comparative study of our algorithm with several\ntypical DML methods on three kinds of networks with different capacity.\nExtensive experiments on three object recognition datasets and two face\nrecognition datasets demonstrate that IE loss is always superior to other\nmainstream DML methods and approach the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 02:39:34 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Wu", "Bowen", ""], ["Chen", "Zhangling", ""], ["Wang", "Jun", ""], ["Wu", "Huaming", ""]]}, {"id": "1803.02509", "submitter": "Yen-lung Tsai", "authors": "Tse-Yu Lin and Yen-Lung Tsai", "title": "An Application of HodgeRank to Online Peer Assessment", "comments": "7 pages. To appear in MLRec 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias and heterogeneity in peer assessment can lead to the issue of unfair\nscoring in the educational field. To deal with this problem, we propose a\nreference ranking method for an online peer assessment system using HodgeRank.\nSuch a scheme provides instructors with an objective scoring reference based on\nmathematics.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 02:53:54 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Lin", "Tse-Yu", ""], ["Tsai", "Yen-Lung", ""]]}, {"id": "1803.02517", "submitter": "Elizabeth Hou", "authors": "Elizabeth Hou, Alfred O. Hero", "title": "Sequential Maximum Margin Classifiers for Partially Labeled Data", "comments": null, "journal-ref": "2018 IEEE International Conference on Acoustics, Speech and Signal\n  Processing", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, data is not collected as one batch, but\nsequentially over time, and often it is not possible or desirable to wait until\nthe data is completely gathered before analyzing it. Thus, we propose a\nframework to sequentially update a maximum margin classifier by taking\nadvantage of the Maximum Entropy Discrimination principle. Our maximum margin\nclassifier allows for a kernel representation to represent large numbers of\nfeatures and can also be regularized with respect to a smooth sub-manifold,\nallowing it to incorporate unlabeled observations. We compare the performance\nof our classifier to its non-sequential equivalents in both simulated and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 03:55:18 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Hou", "Elizabeth", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1803.02525", "submitter": "Aleksandr Aravkin", "authors": "Jonathan Jonker, Aleksandr Y. Aravkin, James V. Burke, Gianluigi\n  Pillonetto, and Sarah Webster", "title": "Fast Robust Methods for Singular State-Space Models", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-space models are used in a wide range of time series analysis\nformulations. Kalman filtering and smoothing are work-horse algorithms in these\nsettings. While classic algorithms assume Gaussian errors to simplify\nestimation, recent advances use a broader range of optimization formulations to\nallow outlier-robust estimation, as well as constraints to capture prior\ninformation.\n  Here we develop methods on state-space models where either innovations or\nerror covariances may be singular. These models frequently arise in navigation\n(e.g. for `colored noise' models or deterministic integrals) and are ubiquitous\nin auto-correlated time series models such as ARMA. We reformulate all\nstate-space models (singular as well as nonsinguar) as constrained convex\noptimization problems, and develop an efficient algorithm for this\nreformulation. The convergence rate is {\\it locally linear}, with constants\nthat do not depend on the conditioning of the problem.\n  Numerical comparisons show that the new approach outperforms competing\napproaches for {\\it nonsingular} models, including state of the art interior\npoint (IP) methods. IP methods converge at superlinear rates; we expect them to\ndominate. However, the steep rate of the proposed approach (independent of\nproblem conditioning) combined with cheap iterations wins against IP in a\nrun-time comparison. We therefore suggest that the proposed approach be the\n{\\it default choice} for estimating state space models outside of the Gaussian\ncontext, regardless of whether the error covariances are singular or not.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 05:10:26 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 20:20:01 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Jonker", "Jonathan", ""], ["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""], ["Webster", "Sarah", ""]]}, {"id": "1803.02527", "submitter": "Ehsan Hajiramezanali", "authors": "Ehsan Hajiramezanali, Siamak Zamani Dadaneh, Paul de Figueiredo,\n  Sing-Hoi Sze, Mingyuan Zhou, and Xiaoning Qian", "title": "Differential Expression Analysis of Dynamical Sequencing Count Data with\n  a Gamma Markov Chain", "comments": "30 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation sequencing (NGS) to profile temporal changes in living\nsystems is gaining more attention for deriving better insights into the\nunderlying biological mechanisms compared to traditional static sequencing\nexperiments. Nonetheless, the majority of existing statistical tools for\nanalyzing NGS data lack the capability of exploiting the richer information\nembedded in temporal data. Several recent tools have been developed to analyze\nsuch data but they typically impose strict model assumptions, such as\nsmoothness on gene expression dynamic changes. To capture a broader range of\ngene expression dynamic patterns, we develop the gamma Markov negative binomial\n(GMNB) model that integrates a gamma Markov chain into a negative binomial\ndistribution model, allowing flexible temporal variation in NGS count data.\nUsing Bayes factors, GMNB enables more powerful temporal gene differential\nexpression analysis across different phenotypes or treatment conditions. In\naddition, it naturally handles the heterogeneity of sequencing depth in\ndifferent samples, removing the need for ad-hoc normalization. Efficient Gibbs\nsampling inference of the GMNB model parameters is achieved by exploiting novel\ndata augmentation techniques. Extensive experiments on both simulated and\nreal-world RNA-seq data show that GMNB outperforms existing methods in both\nreceiver operating characteristic (ROC) and precision-recall (PR) curves of\ndifferential expression analysis results.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 05:31:55 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Hajiramezanali", "Ehsan", ""], ["Dadaneh", "Siamak Zamani", ""], ["de Figueiredo", "Paul", ""], ["Sze", "Sing-Hoi", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1803.02544", "submitter": "Chengliang Yang", "authors": "Chengliang Yang, Anand Rangarajan, Sanjay Ranka", "title": "Visual Explanations From Deep 3D Convolutional Neural Networks for\n  Alzheimer's Disease Classification", "comments": "Accepted by 2018 American Medical Informatics Association Annual\n  Symposium (AMIA2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop three efficient approaches for generating visual explanations from\n3D convolutional neural networks (3D-CNNs) for Alzheimer's disease\nclassification. One approach conducts sensitivity analysis on hierarchical 3D\nimage segmentation, and the other two visualize network activations on a\nspatial map. Visual checks and a quantitative localization benchmark indicate\nthat all approaches identify important brain parts for Alzheimer's disease\ndiagnosis. Comparative analysis show that the sensitivity analysis based\napproach has difficulty handling loosely distributed cerebral cortex, and\napproaches based on visualization of activations are constrained by the\nresolution of the convolutional layer. The complementarity of these methods\nimproves the understanding of 3D-CNNs in Alzheimer's disease classification\nfrom different perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:07:39 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 01:29:14 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 00:28:49 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Yang", "Chengliang", ""], ["Rangarajan", "Anand", ""], ["Ranka", "Sanjay", ""]]}, {"id": "1803.02551", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu and James Glass", "title": "Extracting Domain Invariant Features by Unsupervised Learning for Robust\n  Automatic Speech Recognition", "comments": "accepted by 2018 International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition (ASR) systems can be\nsignificantly compromised by previously unseen conditions, which is typically\ndue to a mismatch between training and testing distributions. In this paper, we\naddress robustness by studying domain invariant features, such that domain\ninformation becomes transparent to ASR systems, resolving the mismatch problem.\nSpecifically, we investigate a recent model, called the Factorized Hierarchical\nVariational Autoencoder (FHVAE). FHVAEs learn to factorize sequence-level and\nsegment-level attributes into different latent variables without supervision.\nWe argue that the set of latent variables that contain segment-level\ninformation is our desired domain invariant feature for ASR. Experiments are\nconducted on Aurora-4 and CHiME-4, which demonstrate 41% and 27% absolute word\nerror rate reductions respectively on mismatched domains.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:30:36 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1803.02553", "submitter": "Hilmi Enes Egilmez", "authors": "Hilmi E. Egilmez, Eduardo Pavez, Antonio Ortega", "title": "Graph Learning from Filtered Signals: Graph System and Diffusion Kernel\n  Identification", "comments": "Submitted to IEEE Trans. on Signal and Information Processing over\n  Networks (13 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel graph signal processing framework for building\ngraph-based models from classes of filtered signals. In our framework,\ngraph-based modeling is formulated as a graph system identification problem,\nwhere the goal is to learn a weighted graph (a graph Laplacian matrix) and a\ngraph-based filter (a function of graph Laplacian matrices). In order to solve\nthe proposed problem, an algorithm is developed to jointly identify a graph and\na graph-based filter (GBF) from multiple signal/data observations. Our\nalgorithm is valid under the assumption that GBFs are one-to-one functions. The\nproposed approach can be applied to learn diffusion (heat) kernels, which are\npopular in various fields for modeling diffusion processes. In addition, for\nspecific choices of graph-based filters, the proposed problem reduces to a\ngraph Laplacian estimation problem. Our experimental results demonstrate that\nthe proposed algorithm outperforms the current state-of-the-art methods. We\nalso implement our framework on a real climate dataset for modeling of\ntemperature signals.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:37:44 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Egilmez", "Hilmi E.", ""], ["Pavez", "Eduardo", ""], ["Ortega", "Antonio", ""]]}, {"id": "1803.02596", "submitter": "Yu-Xiang Wang", "authors": "Yu-Xiang Wang", "title": "Revisiting differentially private linear regression: optimal and\n  adaptive prediction & estimation in unbounded domain", "comments": "Uncertainty in Artificial Intelligence (UAI-2018), Monterey, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of linear regression under a differential privacy\nconstraint. By consolidating existing pieces in the literature, we clarify the\ncorrect dependence of the feature, label and coefficient domains in the\noptimization error and estimation error, hence revealing the delicate price of\ndifferential privacy in statistical estimation and statistical learning.\nMoreover, we propose simple modifications of two existing DP algorithms: (a)\nposterior sampling, (b) sufficient statistics perturbation, and show that they\ncan be upgraded into **adaptive** algorithms that are able to exploit\ndata-dependent quantities and behave nearly optimally **for every instance**.\nExtensive experiments are conducted on both simulated data and real data, which\nconclude that both AdaOPS and AdaSSP outperform the existing techniques on\nnearly all 36 data sets that we test on.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 11:03:36 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 10:56:30 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Wang", "Yu-Xiang", ""]]}, {"id": "1803.02598", "submitter": "Adrien Wohrer", "authors": "Adrien Wohrer", "title": "Ising distribution as a latent variable model", "comments": "19 pages, 7 figures", "journal-ref": "Phys. Rev. E 99, 042147 (2019)", "doi": "10.1103/PhysRevE.99.042147", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past decades, the Ising distribution has attracted interest in\nmany applied disciplines, as the maximum entropy distribution associated to any\nset of correlated binary (`spin') variables with observed means and\ncovariances. However, numerically speaking, the Ising distribution is\nunpractical, so alternative models are often preferred to handle correlated\nbinary data. One popular alternative, especially in life sciences, is the Cox\ndistribution (or the closely related dichotomized Gaussian distribution and\nlog-normal Cox point process), where the spins are generated independently\nconditioned on the drawing of a latent variable with a multivariate normal\ndistribution. This article explores the conditions for a principled replacement\nof the Ising distribution by a Cox distribution. It shows that the Ising\ndistribution itself can be treated as a latent variable model, and it explores\nwhen this latent variable has a quasi-normal distribution. A variational\napproach to this question reveals a formal link with classic mean-field\nmethods, especially Opper and Winther's adaptive TAP approximation. This link\nis confirmed by weak coupling (Plefka) expansions of the different\napproximations and then by numerical tests. Overall, this study suggests that\nan Ising distribution can be replaced by a Cox distribution in practical\napplications, precisely when its parameters lie in the `mean-field domain'.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 11:20:29 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 21:37:30 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 15:40:24 GMT"}, {"version": "v4", "created": "Fri, 10 May 2019 08:47:05 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Wohrer", "Adrien", ""]]}, {"id": "1803.02603", "submitter": "Ieva Kazlauskaite", "authors": "Ieva Kazlauskaite, Carl Henrik Ek, Neill D. F. Campbell", "title": "Gaussian Process Latent Variable Alignment Learning", "comments": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019 (13 pages, 11 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model that can automatically learn alignments between\nhigh-dimensional data in an unsupervised manner. Our proposed method casts\nalignment learning in a framework where both alignment and data are modelled\nsimultaneously. Further, we automatically infer groupings of different types of\nsequences within the same dataset. We derive a probabilistic model built on\nnon-parametric priors that allows for flexible warps while at the same time\nproviding means to specify interpretable constraints. We demonstrate the\nefficacy of our approach with superior quantitative performance to the\nstate-of-the-art approaches and provide examples to illustrate the versatility\nof our model in automatic inference of sequence groupings, absent from previous\napproaches, as well as easy specification of high level priors for different\nmodalities of data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 11:30:05 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 09:41:10 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 12:52:03 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kazlauskaite", "Ieva", ""], ["Ek", "Carl Henrik", ""], ["Campbell", "Neill D. F.", ""]]}, {"id": "1803.02726", "submitter": "Natalie Stanley", "authors": "Natalie Stanley, Thomas Bonacci, Roland Kwitt, Marc Niethammer, Peter\n  J. Mucha", "title": "Stochastic Block Models with Multiple Continuous Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic block model (SBM) is a probabilistic model for community\nstructure in networks. Typically, only the adjacency matrix is used to perform\nSBM parameter inference. In this paper, we consider circumstances in which\nnodes have an associated vector of continuous attributes that are also used to\nlearn the node-to-community assignments and corresponding SBM parameters. While\nthis assumption is not realistic for every application, our model assumes that\nthe attributes associated with the nodes in a network's community can be\ndescribed by a common multivariate Gaussian model. In this augmented,\nattributed SBM, the objective is to simultaneously learn the SBM connectivity\nprobabilities with the multivariate Gaussian parameters describing each\ncommunity. While there are recent examples in the literature that combine\nconnectivity and attribute information to inform community detection, our model\nis the first augmented stochastic block model to handle multiple continuous\nattributes. This provides the flexibility in biological data to, for example,\naugment connectivity information with continuous measurements from multiple\nexperimental modalities. Because the lack of labeled network data often makes\ncommunity detection results difficult to validate, we highlight the usefulness\nof our model for two network prediction tasks: link prediction and\ncollaborative filtering. As a result of fitting this attributed stochastic\nblock model, one can predict the attribute vector or connectivity patterns for\na new node in the event of the complementary source of information\n(connectivity or attributes, respectively). We also highlight two biological\nexamples where the attributed stochastic block model provides satisfactory\nperformance in the link prediction and collaborative filtering tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 15:50:09 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Stanley", "Natalie", ""], ["Bonacci", "Thomas", ""], ["Kwitt", "Roland", ""], ["Niethammer", "Marc", ""], ["Mucha", "Peter J.", ""]]}, {"id": "1803.02780", "submitter": "Andrea Gesmundo", "authors": "Catherine Wong, Neil Houlsby, Yifeng Lu, Andrea Gesmundo", "title": "Transfer Learning with Neural AutoML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reduce the computational cost of Neural AutoML with transfer learning.\nAutoML relieves human effort by automating the design of ML algorithms. Neural\nAutoML has become popular for the design of deep learning architectures,\nhowever, this method has a high computation cost. To address this we propose\nTransfer Neural AutoML that uses knowledge from prior tasks to speed up network\ndesign. We extend RL-based architecture search methods to support parallel\ntraining on multiple tasks and then transfer the search strategy to new tasks.\nOn language and image classification tasks, Transfer Neural AutoML reduces\nconvergence time over single-task training by over an order of magnitude on\nmany tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 17:31:02 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 12:47:17 GMT"}, {"version": "v3", "created": "Tue, 11 Sep 2018 09:55:18 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2018 07:53:41 GMT"}, {"version": "v5", "created": "Mon, 28 Jan 2019 15:43:20 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wong", "Catherine", ""], ["Houlsby", "Neil", ""], ["Lu", "Yifeng", ""], ["Gesmundo", "Andrea", ""]]}, {"id": "1803.02781", "submitter": "Sukrut Rao", "authors": "Vaibhav B Sinha, Sukrut Rao, Vineeth N Balasubramanian", "title": "Fast Dawid-Skene: A Fast Vote Aggregation Scheme for Sentiment\n  Classification", "comments": "8 pages, 5 tables, 1 figure, KDD Workshop on Issues of Sentiment\n  Discovery and Opinion Mining (WISDOM) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world problems can now be effectively solved using supervised\nmachine learning. A major roadblock is often the lack of an adequate quantity\nof labeled data for training. A possible solution is to assign the task of\nlabeling data to a crowd, and then infer the true label using aggregation\nmethods. A well-known approach for aggregation is the Dawid-Skene (DS)\nalgorithm, which is based on the principle of Expectation-Maximization (EM). We\npropose a new simple, yet effective, EM-based algorithm, which can be\ninterpreted as a `hard' version of DS, that allows much faster convergence\nwhile maintaining similar accuracy in aggregation. We show the use of this\nalgorithm as a quick and effective technique for online, real-time sentiment\nannotation. We also prove that our algorithm converges to the estimated labels\nat a linear rate. Our experiments on standard datasets show a significant\nspeedup in time taken for aggregation - upto $\\sim$8x over Dawid-Skene and\n$\\sim$6x over other fast EM methods, at competitive accuracy performance. The\ncode for the implementation of the algorithms can be found at\nhttps://github.com/GoodDeeds/Fast-Dawid-Skene\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 17:31:20 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 15:13:52 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 20:22:38 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Sinha", "Vaibhav B", ""], ["Rao", "Sukrut", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1803.02782", "submitter": "Kajsa M{\\o}llersen", "authors": "Kajsa M{\\o}llersen, Jon Yngve Hardeberg, Fred Godtliebsen", "title": "A bag-to-class divergence approach to multiple-instance learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-instance (MI) learning, each object (bag) consists of multiple\nfeature vectors (instances), and is most commonly regarded as a set of points\nin a multidimensional space. A different viewpoint is that the instances are\nrealisations of random vectors with corresponding probability distribution, and\nthat a bag is the distribution, not the realisations. In MI classification,\neach bag in the training set has a class label, but the instances are\nunlabelled. By introducing the probability distribution space to bag-level\nclassification problems, dissimilarities between probability distributions\n(divergences) can be applied. The bag-to-bag Kullback-Leibler information is\nasymptotically the best classifier, but the typical sparseness of MI training\nsets is an obstacle. We introduce bag-to-class divergence to MI learning,\nemphasising the hierarchical nature of the random vectors that makes bags from\nthe same class different. We propose two properties for bag-to-class\ndivergences, and an additional property for sparse training sets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 17:33:29 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 23:39:08 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["M\u00f8llersen", "Kajsa", ""], ["Hardeberg", "Jon Yngve", ""], ["Godtliebsen", "Fred", ""]]}, {"id": "1803.02815", "submitter": "Gautam Kamath", "authors": "Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Jacob\n  Steinhardt, Alistair Stewart", "title": "Sever: A Robust Meta-Algorithm for Stochastic Optimization", "comments": "To appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensions, most machine learning methods are brittle to even a small\nfraction of structured outliers. To address this, we introduce a new\nmeta-algorithm that can take in a base learner such as least squares or\nstochastic gradient descent, and harden the learner to be resistant to\noutliers. Our method, Sever, possesses strong theoretical guarantees yet is\nalso highly scalable -- beyond running the base learner itself, it only\nrequires computing the top singular vector of a certain $n \\times d$ matrix. We\napply Sever on a drug design dataset and a spam classification dataset, and\nfind that in both cases it has substantially greater robustness than several\nbaselines. On the spam dataset, with $1\\%$ corruptions, we achieved $7.4\\%$\ntest error, compared to $13.4\\%-20.5\\%$ for the baselines, and $3\\%$ error on\nthe uncorrupted dataset. Similarly, on the drug design dataset, with $10\\%$\ncorruptions, we achieved $1.42$ mean-squared error test error, compared to\n$1.51$-$2.33$ for the baselines, and $1.23$ error on the uncorrupted dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 18:47:48 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 20:51:06 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kamath", "Gautam", ""], ["Kane", "Daniel M.", ""], ["Li", "Jerry", ""], ["Steinhardt", "Jacob", ""], ["Stewart", "Alistair", ""]]}, {"id": "1803.02839", "submitter": "Sean Cantrell", "authors": "Sean A. Cantrell", "title": "The emergent algebraic structure of RNNs and embeddings in NLP", "comments": "24 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the algebraic and geometric properties of a uni-directional GRU\nand word embeddings trained end-to-end on a text classification task. A\nhyperparameter search over word embedding dimension, GRU hidden dimension, and\na linear combination of the GRU outputs is performed. We conclude that words\nnaturally embed themselves in a Lie group and that RNNs form a nonlinear\nrepresentation of the group. Appealing to these results, we propose a novel\nclass of recurrent-like neural networks and a word embedding scheme.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 19:06:08 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Cantrell", "Sean A.", ""]]}, {"id": "1803.02865", "submitter": "Xiaoixa Wu", "authors": "Xiaoxia Wu and Rachel Ward and L\\'eon Bottou", "title": "WNGrad: Learn the Learning Rate in Gradient Descent", "comments": "10 pages, 3 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adjusting the learning rate schedule in stochastic gradient methods is an\nimportant unresolved problem which requires tuning in practice. If certain\nparameters of the loss function such as smoothness or strong convexity\nconstants are known, theoretical learning rate schedules can be applied.\nHowever, in practice, such parameters are not known, and the loss function of\ninterest is not convex in any case. The recently proposed batch normalization\nreparametrization is widely adopted in most neural network architectures today\nbecause, among other advantages, it is robust to the choice of Lipschitz\nconstant of the gradient in loss function, allowing one to set a large learning\nrate without worry. Inspired by batch normalization, we propose a general\nnonlinear update rule for the learning rate in batch and stochastic gradient\ndescent so that the learning rate can be initialized at a high value, and is\nsubsequently decreased according to gradient observations along the way. The\nproposed method is shown to achieve robustness to the relationship between the\nlearning rate and the Lipschitz constant, and near-optimal convergence rates in\nboth the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch\nsetting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We\nalso show through numerical evidence that such robustness of the proposed\nmethod extends to highly nonconvex and possibly non-smooth loss function in\ndeep learning problems.Our analysis establishes some first theoretical\nunderstanding into the observed robustness for batch normalization and weight\nnormalization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 20:30:35 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 20:31:14 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wu", "Xiaoxia", ""], ["Ward", "Rachel", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1803.02879", "submitter": "Devon Graham Mr", "authors": "Jason Hartford, Devon R Graham, Kevin Leyton-Brown, Siamak Ravanbakhsh", "title": "Deep Models of Interactions Across Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use deep learning to model interactions across two or more sets of\nobjects, such as user-movie ratings, protein-drug bindings, or ternary\nuser-item-tag interactions. The canonical representation of such interactions\nis a matrix (or a higher-dimensional tensor) with an exchangeability property:\nthe encoding's meaning is not changed by permuting rows or columns. We argue\nthat models should hence be Permutation Equivariant (PE): constrained to make\nthe same predictions across such permutations. We present a parameter-sharing\nscheme and prove that it could not be made any more expressive without\nviolating PE. This scheme yields three benefits. First, we demonstrate\nstate-of-the-art performance on multiple matrix completion benchmarks. Second,\nour models require a number of parameters independent of the numbers of\nobjects, and thus scale well to large datasets. Third, models can be queried\nabout new objects that were not available at training time, but for which\ninteractions have since been observed. In experiments, our models achieved\nsurprisingly good generalization performance on this matrix extrapolation task,\nboth within domains (e.g., new users and new movies drawn from the same\ndistribution used for training) and even across domains (e.g., predicting music\nratings after training on movies).\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 21:18:25 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 22:43:37 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Hartford", "Jason", ""], ["Graham", "Devon R", ""], ["Leyton-Brown", "Kevin", ""], ["Ravanbakhsh", "Siamak", ""]]}, {"id": "1803.02922", "submitter": "Partha Mitra", "authors": "Partha P Mitra", "title": "Fast Convergence for Stochastic and Distributed Gradient Descent in the\n  Interpolation Limit", "comments": "Accepted for presentation in EUSIPCO 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern supervised learning techniques, particularly those using deep nets,\ninvolve fitting high dimensional labelled data sets with functions containing\nvery large numbers of parameters. Much of this work is empirical. Interesting\nphenomena have been observed that require theoretical explanations; however the\nnon-convexity of the loss functions complicates the analysis. Recently it has\nbeen proposed that the success of these techniques rests partly in the\neffectiveness of the simple stochastic gradient descent algorithm in the so\ncalled interpolation limit in which all labels are fit perfectly. This analysis\nis made possible since the SGD algorithm reduces to a stochastic linear system\nnear the interpolating minimum of the loss function. Here we exploit this\ninsight by presenting and analyzing a new distributed algorithm for gradient\ndescent, also in the interpolating limit. The distributed SGD algorithm\npresented in the paper corresponds to gradient descent applied to a simple\npenalized distributed loss function, $L({\\bf w}_1,...,{\\bf w}_n) = \\Sigma_i\nl_i({\\bf w}_i) + \\mu \\sum_{<i,j>}|{\\bf w}_i-{\\bf w}_j|^2$. Here each node holds\nonly one sample, and its own parameter vector. The notation $<i,j>$ denotes\nedges of a connected graph defining the links between nodes. It is shown that\nthis distributed algorithm converges linearly (ie the error reduces\nexponentially with iteration number), with a rate\n$1-\\frac{\\eta}{n}\\lambda_{min}(H)<R<1$ where $\\lambda_{min}(H)$ is the smallest\nnonzero eigenvalue of the sample covariance or the Hessian H. In contrast with\nprevious usage of similar penalty functions to enforce consensus between nodes,\nin the interpolating limit it is not required to take the penalty parameter to\ninfinity for consensus to occur. The analysis further reinforces the utility of\nthe interpolation limit in the theoretical treatment of modern machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 00:19:11 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 05:40:57 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 03:42:41 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mitra", "Partha P", ""]]}, {"id": "1803.02933", "submitter": "Cesar A. Uribe", "authors": "C\\'esar A. Uribe and Darina Dvinskikh and Pavel Dvurechensky and\n  Alexander Gasnikov and Angelia Nedi\\'c", "title": "Distributed Computation of Wasserstein Barycenters over Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new \\cu{class-optimal} algorithm for the distributed computation\nof Wasserstein Barycenters over networks. Assuming that each node in a graph\nhas a probability distribution, we prove that every node can reach the\nbarycenter of all distributions held in the network by using local interactions\ncompliant with the topology of the graph. We provide an estimate for the\nminimum number of communication rounds required for the proposed method to\nachieve arbitrary relative precision both in the optimality of the solution and\nthe consensus among all agents for undirected fixed networks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 01:32:06 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 18:01:11 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Uribe", "C\u00e9sar A.", ""], ["Dvinskikh", "Darina", ""], ["Dvurechensky", "Pavel", ""], ["Gasnikov", "Alexander", ""], ["Nedi\u0107", "Angelia", ""]]}, {"id": "1803.02965", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Ngoc Duy Nguyen, Peter Vamplew, Saeid Nahavandi,\n  Richard Dazeley, Chee Peng Lim", "title": "A Multi-Objective Deep Reinforcement Learning Framework", "comments": "21 pages", "journal-ref": "Engineering Applications of Artificial Intelligence, 2020", "doi": "10.1016/j.engappai.2020.103915", "report-no": "Volume 96, November 2020, 103915", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new scalable multi-objective deep reinforcement\nlearning (MODRL) framework based on deep Q-networks. We develop a\nhigh-performance MODRL framework that supports both single-policy and\nmulti-policy strategies, as well as both linear and non-linear approaches to\naction selection. The experimental results on two benchmark problems\n(two-objective deep sea treasure environment and three-objective Mountain Car\nproblem) indicate that the proposed framework is able to find the\nPareto-optimal solutions effectively. The proposed framework is generic and\nhighly modularized, which allows the integration of different deep\nreinforcement learning algorithms in different complex problem domains. This\ntherefore overcomes many disadvantages involved with standard multi-objective\nreinforcement learning methods in the current literature. The proposed\nframework acts as a testbed platform that accelerates the development of MODRL\nfor solving increasingly complicated multi-objective problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 04:50:21 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 17:20:52 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 16:04:41 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Ngoc Duy", ""], ["Vamplew", "Peter", ""], ["Nahavandi", "Saeid", ""], ["Dazeley", "Richard", ""], ["Lim", "Chee Peng", ""]]}, {"id": "1803.03104", "submitter": "Oliver Lauwers", "authors": "Oliver Lauwers, Bart De Moor", "title": "Applicability and interpretation of the deterministic weighted cepstral\n  distance", "comments": "18 pages, 5 figures, submitted for review to Automatica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CV math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying similarity between data objects is an important part of modern\ndata science. Deciding what similarity measure to use is very application\ndependent. In this paper, we combine insights from systems theory and machine\nlearning, and investigate the weighted cepstral distance, which was previously\ndefined for signals coming from ARMA models. We provide an extension of this\ndistance to invertible deterministic linear time invariant single input single\noutput models, and assess its applicability. We show that it can always be\ninterpreted in terms of the poles and zeros of the underlying model, and that,\nin the case of stable, minimum-phase, or unstable, maximum-phase models, a\ngeometrical interpretation in terms of subspace angles can be given. We then\ndevise a method to assess stability and phase-type of the generating models,\nusing only input/output signal information. In this way, we prove a connection\nbetween the extended weighted cepstral distance and a weighted cepstral model\nnorm. In this way, we provide a purely data-driven way to assess different\nunderlying dynamics of input/output signal pairs, without the need for any\nsystem identification step. This can be useful in machine learning tasks such\nas time series clustering. An iPython tutorial is published complementary to\nthis paper, containing implementations of the various methods and algorithms\npresented here, as well as some numerical illustrations of the equivalences\nproven here.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 14:31:46 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Lauwers", "Oliver", ""], ["De Moor", "Bart", ""]]}, {"id": "1803.03146", "submitter": "Jade Shi", "authors": "Jade Shi (EteRNA players), Rhiju Das, and Vijay S. Pande", "title": "SentRNA: Improving computational RNA design by incorporating a prior of\n  human design strategies", "comments": "27 pages (not including Supplementary Information), 9 figures, 7\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solving the RNA inverse folding problem is a critical prerequisite to RNA\ndesign, an emerging field in bioengineering with a broad range of applications\nfrom reaction catalysis to cancer therapy. Although significant progress has\nbeen made in developing machine-based inverse RNA folding algorithms, current\napproaches still have difficulty designing sequences for large or complex\ntargets. On the other hand, human players of the online RNA design game EteRNA\nhave consistently shown superior performance in this regard, being able to\nreadily design sequences for targets that are challenging for machine\nalgorithms. Here we present a novel approach to the RNA design problem,\nSentRNA, a design agent consisting of a fully-connected neural network trained\nend-to-end using human-designed RNA sequences. We show that through this\napproach, SentRNA can solve complex targets previously unsolvable by any\nmachine-based approach and achieve state-of-the-art performance on two separate\nchallenging test sets. Our results demonstrate that incorporating human design\nstrategies into a design algorithm can significantly boost machine performance\nand suggests a new paradigm for machine-based RNA design.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 15:12:16 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 01:01:53 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Shi", "Jade", "", "EteRNA players"], ["Das", "Rhiju", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1803.03148", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Generating Artificial Data for Private Deep Learning", "comments": "Privacy-Enhancing Artificial Intelligence and Language Technologies,\n  AAAI Spring Symposium Series, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose generating artificial data that retain statistical\nproperties of real data as the means of providing privacy with respect to the\noriginal dataset. We use generative adversarial network to draw\nprivacy-preserving artificial data samples and derive an empirical method to\nassess the risk of information disclosure in a differential-privacy-like way.\nOur experiments show that we are able to generate artificial data of high\nquality and successfully train and validate machine learning models on this\ndata while limiting potential privacy loss.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 15:22:37 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 20:27:22 GMT"}, {"version": "v3", "created": "Sun, 28 Apr 2019 17:04:59 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "1803.03166", "submitter": "Aurelie Fischer", "authors": "Aur\\'elie Fischer (1), Mathilde Mougeot (1) ((1) LPSM UMR 8001)", "title": "Aggregation using input-output trade-off", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new learning strategy based on a seminal idea\nof Mojirsheibani (1999, 2000, 2002a, 2002b), who proposed a smart method for\ncombining several classifiers, relying on a consensus notion. In many\naggregation methods, the prediction for a new observation x is computed by\nbuilding a linear or convex combination over a collection of basic estimators\nr1(x),. .. , rm(x) previously calibrated using a training data set.\nMojirsheibani proposes to compute the prediction associated to a new\nobservation by combining selected outputs of the training examples. The output\nof a training example is selected if some kind of consensus is observed: the\npredictions computed for the training example with the different machines have\nto be \"similar\" to the prediction for the new observation. This approach has\nbeen recently extended to the context of regression in Biau et al. (2016). In\nthe original scheme, the agreement condition is actually required to hold for\nall individual estimators, which appears inadequate if there is one bad initial\nestimator. In practice, a few disagreements are allowed ; for establishing the\ntheoretical results, the proportion of estimators satisfying the condition is\nrequired to tend to 1. In this paper, we propose an alternative procedure,\nmixing the previous consensus ideas on the predictions with the Euclidean\ndistance computed between entries. This may be seen as an alternative approach\nallowing to reduce the effect of a possibly bad estimator in the initial list,\nusing a constraint on the inputs. We prove the consistency of our strategy in\nclassification and in regression. We also provide some numerical experiments on\nsimulated and real data to illustrate the benefits of this new aggregation\nmethod. On the whole, our practical study shows that our method may perform\nmuch better than the original combination technique, and, in particular,\nexhibit far less variance. We also show on simulated examples that this\nprocedure mixing inputs and outputs is still robust to high dimensional inputs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 15:43:34 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Fischer", "Aur\u00e9lie", "", "LPSM UMR 8001"], ["Mougeot", "Mathilde", "", "LPSM UMR 8001"]]}, {"id": "1803.03191", "submitter": "Trisha Lawrence Ms.", "authors": "Trisha Lawrence", "title": "A Bayesian and Machine Learning approach to estimating Influence Model\n  parameters for IM-RO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The rise of Online Social Networks (OSNs) has caused an insurmountable amount\nof interest from advertisers and researchers seeking to monopolize on its\nfeatures. Researchers aim to develop strategies for determining how information\nis propagated among users within an OSN that is captured by diffusion or\ninfluence models. We consider the influence models for the IM-RO problem, a\nnovel formulation to the Influence Maximization (IM) problem based on\nimplementing Stochastic Dynamic Programming (SDP). In contrast to existing\napproaches involving influence spread and the theory of submodular functions,\nthe SDP method focuses on optimizing clicks and ultimately revenue to\nadvertisers in OSNs. Existing approaches to influence maximization have been\nactively researched over the past decade, with applications to multiple fields,\nhowever, our approach is a more practical variant to the original IM problem.\nIn this paper, we provide an analysis on the influence models of the IM-RO\nproblem by conducting experiments on synthetic and real-world datasets. We\npropose a Bayesian and Machine Learning approach for estimating the parameters\nof the influence models for the (Influence Maximization- Revenue Optimization)\nIM-RO problem. We present a Bayesian hierarchical model and implement the\nwell-known Naive Bayes classifier (NBC), Decision Trees classifier (DTC) and\nRandom Forest classifier (RFC) on three real-world datasets. Compared to\nprevious approaches to estimating influence model parameters, our strategy has\nthe great advantage of being directly implementable in standard software\npackages such as WinBUGS/OpenBUGS/JAGS and Apache Spark. We demonstrate the\nefficiency and usability of our methods in terms of spreading information and\ngenerating revenue for advertisers in the context of OSNs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 16:33:09 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Lawrence", "Trisha", ""]]}, {"id": "1803.03234", "submitter": "Robert Bamler", "authors": "Robert Bamler and Stephan Mandt", "title": "Improving Optimization for Models With Continuous Symmetry Breaking", "comments": "In the proceedings of International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML 2018), in PMLR 80:423-432", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many loss functions in representation learning are invariant under a\ncontinuous symmetry transformation. For example, the loss function of word\nembeddings (Mikolov et al., 2013) remains unchanged if we simultaneously rotate\nall word and context embedding vectors. We show that representation learning\nmodels for time series possess an approximate continuous symmetry that leads to\nslow convergence of gradient descent. We propose a new optimization algorithm\nthat speeds up convergence using ideas from gauge theory in physics. Our\nalgorithm leads to orders of magnitude faster convergence and to more\ninterpretable representations, as we show for dynamic extensions of matrix\nfactorization and word embedding models. We further present an example\napplication of our proposed algorithm that translates modern words into their\nhistoric equivalents.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:07:40 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 21:28:34 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 18:29:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "1803.03241", "submitter": "Pravesh K Kothari", "authors": "Adam Klivans and Pravesh K. Kothari and Raghu Meka", "title": "Efficient Algorithms for Outlier-Robust Regression", "comments": "27 pages. Appeared in COLT 2018. This update removes Lemma 6.2 that\n  erroneously claimed an information-theoretic lower bound on error rate as a\n  function of fraction of outliers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first polynomial-time algorithm for performing linear or\npolynomial regression resilient to adversarial corruptions in both examples and\nlabels.\n  Given a sufficiently large (polynomial-size) training set drawn i.i.d. from\ndistribution D and subsequently corrupted on some fraction of points, our\nalgorithm outputs a linear function whose squared error is close to the squared\nerror of the best-fitting linear function with respect to D, assuming that the\nmarginal distribution of D over the input space is \\emph{certifiably\nhypercontractive}. This natural property is satisfied by many well-studied\ndistributions such as Gaussian, strongly log-concave distributions and, uniform\ndistribution on the hypercube among others. We also give a simple statistical\nlower bound showing that some distributional assumption is necessary to succeed\nin this setting.\n  These results are the first of their kind and were not known to be even\ninformation-theoretically possible prior to our work.\n  Our approach is based on the sum-of-squares (SoS) method and is inspired by\nthe recent applications of the method for parameter recovery problems in\nunsupervised learning. Our algorithm can be seen as a natural convex relaxation\nof the following conceptually simple non-convex optimization problem: find a\nlinear function and a large subset of the input corrupted sample such that the\nleast squares loss of the function over the subset is minimized over all\npossible large subsets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:30:31 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 04:04:29 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 15:42:45 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Klivans", "Adam", ""], ["Kothari", "Pravesh K.", ""], ["Meka", "Raghu", ""]]}, {"id": "1803.03289", "submitter": "Yuhui Xu", "authors": "Yuhui Xu, Yongzhuang Wang, Aojun Zhou, Weiyao Lin, Hongkai Xiong", "title": "Deep Neural Network Compression with Single and Multiple Level\n  Quantization", "comments": "Published in AAAI18. Code is available at\n  https://github.com/yuhuixu1993/SLQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization is an effective solution to compress deep neural\nnetworks for practical usage. Existing network quantization methods cannot\nsufficiently exploit the depth information to generate low-bit compressed\nnetwork. In this paper, we propose two novel network quantization approaches,\nsingle-level network quantization (SLQ) for high-bit quantization and\nmulti-level network quantization (MLQ) for extremely low-bit quantization\n(ternary).We are the first to consider the network quantization from both width\nand depth level. In the width level, parameters are divided into two parts: one\nfor quantization and the other for re-training to eliminate the quantization\nloss. SLQ leverages the distribution of the parameters to improve the width\nlevel. In the depth level, we introduce incremental layer compensation to\nquantize layers iteratively which decreases the quantization loss in each\niteration. The proposed approaches are validated with extensive experiments\nbased on the state-of-the-art neural networks including AlexNet, VGG-16,\nGoogleNet and ResNet-18. Both SLQ and MLQ achieve impressive results.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 01:47:52 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 08:29:21 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Xu", "Yuhui", ""], ["Wang", "Yongzhuang", ""], ["Zhou", "Aojun", ""], ["Lin", "Weiyao", ""], ["Xiong", "Hongkai", ""]]}, {"id": "1803.03319", "submitter": "Itay Evron", "authors": "Itay Evron, Edward Moroshko, Koby Crammer", "title": "Efficient Loss-Based Decoding on Graphs For Extreme Classification", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32 (2018),\n  7232-7243", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In extreme classification problems, learning algorithms are required to map\ninstances to labels from an extremely large label set. We build on a recent\nextreme classification framework with logarithmic time and space, and on a\ngeneral approach for error correcting output coding (ECOC) with loss-based\ndecoding, and introduce a flexible and efficient approach accompanied by\ntheoretical bounds. Our framework employs output codes induced by graphs, for\nwhich we show how to perform efficient loss-based decoding to potentially\nimprove accuracy. In addition, our framework offers a tradeoff between\naccuracy, model size and prediction time. We show how to find the sweet spot of\nthis tradeoff using only the training data. Our experimental study demonstrates\nthe validity of our assumptions and claims, and shows that our method is\ncompetitive with state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 21:54:19 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 07:06:23 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Evron", "Itay", ""], ["Moroshko", "Edward", ""], ["Crammer", "Koby", ""]]}, {"id": "1803.03324", "submitter": "Yujia Li", "authors": "Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, Peter Battaglia", "title": "Learning Deep Generative Models of Graphs", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are fundamental data structures which concisely capture the relational\nstructure in many important real-world domains, such as knowledge graphs,\nphysical and social interactions, language, and chemistry. Here we introduce a\npowerful new approach for learning generative models over graphs, which can\ncapture both their structure and attributes. Our approach uses graph neural\nnetworks to express probabilistic dependencies among a graph's nodes and edges,\nand can, in principle, learn distributions over any arbitrary graph. In a\nseries of experiments our results show that once trained, our models can\ngenerate good quality samples of both synthetic graphs as well as real\nmolecular graphs, both unconditionally and conditioned on data. Compared to\nbaselines that do not use graph-structured representations, our models often\nperform far better. We also explore key challenges of learning generative\nmodels of graphs, such as how to handle symmetries and ordering of elements\nduring the graph generation process, and offer possible solutions. Our work is\nthe first and most general approach for learning generative models over\narbitrary graphs, and opens new directions for moving away from restrictions of\nvector- and sequence-like knowledge representations, toward more expressive and\nflexible relational data structures.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 22:20:00 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Li", "Yujia", ""], ["Vinyals", "Oriol", ""], ["Dyer", "Chris", ""], ["Pascanu", "Razvan", ""], ["Battaglia", "Peter", ""]]}, {"id": "1803.03344", "submitter": "Matthew Dunlop", "authors": "Victor Chen, Matthew M. Dunlop, Omiros Papaspiliopoulos, Andrew M.\n  Stuart", "title": "Dimension-Robust MCMC in Bayesian Inverse Problems", "comments": "29 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The methodology developed in this article is motivated by a wide range of\nprediction and uncertainty quantification problems that arise in Statistics,\nMachine Learning and Applied Mathematics, such as non-parametric regression,\nmulti-class classification and inversion of partial differential equations. One\npopular formulation of such problems is as Bayesian inverse problems, where a\nprior distribution is used to regularize inference on a high-dimensional latent\nstate, typically a function or a field. It is common that such priors are\nnon-Gaussian, for example piecewise-constant or heavy-tailed, and/or\nhierarchical, in the sense of involving a further set of low-dimensional\nparameters, which, for example, control the scale or smoothness of the latent\nstate. In this formulation prediction and uncertainty quantification relies on\nefficient exploration of the posterior distribution of latent states and\nparameters. This article introduces a framework for efficient MCMC sampling in\nBayesian inverse problems that capitalizes upon two fundamental ideas in MCMC,\nnon-centred parameterisations of hierarchical models and dimension-robust\nsamplers for latent Gaussian processes. Using a range of diverse applications\nwe showcase that the proposed framework is dimension-robust, that is, the\nefficiency of the MCMC sampling does not deteriorate as the dimension of the\nlatent state gets higher. We showcase the full potential of the machinery we\ndevelop in the article in semi-supervised multi-class classification, where our\nsampling algorithm is used within an active learning framework to guide the\nselection of input data to manually label in order to achieve high predictive\naccuracy with a minimal number of labelled data.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 01:02:47 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 17:46:37 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Chen", "Victor", ""], ["Dunlop", "Matthew M.", ""], ["Papaspiliopoulos", "Omiros", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "1803.03348", "submitter": "Subhabrata Majumdar", "authors": "Subhabrata Majumdar, George Michailidis", "title": "Joint Estimation and Inference for Data Integration Problems based on\n  Multiple Multi-layered Gaussian Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of high-throughput technologies has enabled the\ngeneration of data from biological or disease processes that span multiple\nlayers, like genomic, proteomic or metabolomic data, and further pertain to\nmultiple sources, like disease subtypes or experimental conditions. In this\nwork, we propose a general statistical framework based on Gaussian graphical\nmodels for horizontal (i.e. across conditions or subtypes) and vertical (i.e.\nacross different layers containing data on molecular compartments) integration\nof information in such datasets. We start with decomposing the multi-layer\nproblem into a series of two-layer problems. For each two-layer problem, we\nmodel the outcomes at a node in the lower layer as dependent on those of other\nnodes in that layer, as well as all nodes in the upper layer. We use a\ncombination of neighborhood selection and group-penalized regression to obtain\nsparse estimates of all model parameters. Following this, we develop a\ndebiasing technique and asymptotic distributions of inter-layer directed edge\nweights that utilize already computed neighborhood selection coefficients for\nnodes in the upper layer. Subsequently, we establish global and simultaneous\ntesting procedures for these edge weights. Performance of the proposed\nmethodology is evaluated on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 01:30:04 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 22:51:36 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Majumdar", "Subhabrata", ""], ["Michailidis", "George", ""]]}, {"id": "1803.03376", "submitter": "Lifu Tu", "authors": "Lifu Tu, Kevin Gimpel", "title": "Learning Approximate Inference Networks for Structured Prediction", "comments": "accepted by ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Structured prediction energy networks (SPENs; Belanger & McCallum 2016) use\nneural network architectures to define energy functions that can capture\narbitrary dependencies among parts of structured outputs. Prior work used\ngradient descent for inference, relaxing the structured output to a set of\ncontinuous variables and then optimizing the energy with respect to them. We\nreplace this use of gradient descent with a neural network trained to\napproximate structured argmax inference. This \"inference network\" outputs\ncontinuous values that we treat as the output structure. We develop\nlarge-margin training criteria for joint training of the structured energy\nfunction and inference network. On multi-label classification we report\nspeed-ups of 10-60x compared to (Belanger et al, 2017) while also improving\naccuracy. For sequence labeling with simple structured energies, our approach\nperforms comparably to exact inference while being much faster at test time. We\nthen demonstrate improved accuracy by augmenting the energy with a \"label\nlanguage model\" that scores entire output label sequences, showing it can\nimprove handling of long-distance dependencies in part-of-speech tagging.\nFinally, we show how inference networks can replace dynamic programming for\ntest-time inference in conditional random fields, suggestive for their general\nuse for fast inference in structured settings.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 03:50:24 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Tu", "Lifu", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1803.03383", "submitter": "Christopher De Sa", "authors": "Christopher De Sa, Megan Leszczynski, Jian Zhang, Alana Marzoev,\n  Christopher R. Aberger, Kunle Olukotun, Christopher R\\'e", "title": "High-Accuracy Low-Precision Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision computation is often used to lower the time and energy cost of\nmachine learning, and recently hardware accelerators have been developed to\nsupport it. Still, it has been used primarily for inference - not training.\nPrevious low-precision training algorithms suffered from a fundamental\ntradeoff: as the number of bits of precision is lowered, quantization noise is\nadded to the model, which limits statistical accuracy. To address this issue,\nwe describe a simple low-precision stochastic gradient descent variant called\nHALP. HALP converges at the same theoretical rate as full-precision algorithms\ndespite the noise introduced by using low precision throughout execution. The\nkey idea is to use SVRG to reduce gradient variance, and to combine this with a\nnovel technique called bit centering to reduce quantization error. We show that\non the CPU, HALP can run up to $4 \\times$ faster than full-precision SVRG and\ncan match its convergence trajectory. We implemented HALP in TensorQuant, and\nshow that it exceeds the validation performance of plain low-precision SGD on\ntwo deep learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 04:50:27 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["De Sa", "Christopher", ""], ["Leszczynski", "Megan", ""], ["Zhang", "Jian", ""], ["Marzoev", "Alana", ""], ["Aberger", "Christopher R.", ""], ["Olukotun", "Kunle", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1803.03432", "submitter": "Favour Mandanji Nyikosa", "authors": "Favour M. Nyikosa, Michael A. Osborne and Stephen J. Roberts", "title": "Bayesian Optimization for Dynamic Problems", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose practical extensions to Bayesian optimization for solving dynamic\nproblems. We model dynamic objective functions using spatiotemporal Gaussian\nprocess priors which capture all the instances of the functions over time. Our\nextensions to Bayesian optimization use the information learnt from this model\nto guide the tracking of a temporally evolving minimum. By exploiting temporal\ncorrelations, the proposed method also determines when to make evaluations, how\nfast to make those evaluations, and it induces an appropriate budget of steps\nbased on the available information. Lastly, we evaluate our technique on\nsynthetic and real-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 09:31:15 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Nyikosa", "Favour M.", ""], ["Osborne", "Michael A.", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1803.03466", "submitter": "Xiantao Xiao", "authors": "Andre Milzarek, Xiantao Xiao, Shicong Cen, Zaiwen Wen, Michael Ulbrich", "title": "A Stochastic Semismooth Newton Method for Nonsmooth Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a globalized stochastic semismooth Newton method for\nsolving stochastic optimization problems involving smooth nonconvex and\nnonsmooth convex terms in the objective function. We assume that only noisy\ngradient and Hessian information of the smooth part of the objective function\nis available via calling stochastic first and second order oracles. The\nproposed method can be seen as a hybrid approach combining stochastic\nsemismooth Newton steps and stochastic proximal gradient steps. Two inexact\ngrowth conditions are incorporated to monitor the convergence and the\nacceptance of the semismooth Newton steps and it is shown that the algorithm\nconverges globally to stationary points in expectation. Moreover, under\nstandard assumptions and utilizing random matrix concentration inequalities, we\nprove that the proposed approach locally turns into a pure stochastic\nsemismooth Newton method and converges r-superlinearly with high probability.\nWe present numerical results and comparisons on $\\ell_1$-regularized logistic\nregression and nonconvex binary classification that demonstrate the efficiency\nof our algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 11:08:59 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Milzarek", "Andre", ""], ["Xiao", "Xiantao", ""], ["Cen", "Shicong", ""], ["Wen", "Zaiwen", ""], ["Ulbrich", "Michael", ""]]}, {"id": "1803.03467", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing\n  Xie, Minyi Guo", "title": "RippleNet: Propagating User Preferences on the Knowledge Graph for\n  Recommender Systems", "comments": "CIKM 2018", "journal-ref": null, "doi": "10.1145/3269206.3271739", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the sparsity and cold start problem of collaborative filtering,\nresearchers usually make use of side information, such as social networks or\nitem attributes, to improve recommendation performance. This paper considers\nthe knowledge graph as the source of side information. To address the\nlimitations of existing embedding-based and path-based methods for\nknowledge-graph-aware recommendation, we propose Ripple Network, an end-to-end\nframework that naturally incorporates the knowledge graph into recommender\nsystems. Similar to actual ripples propagating on the surface of water, Ripple\nNetwork stimulates the propagation of user preferences over the set of\nknowledge entities by automatically and iteratively extending a user's\npotential interests along links in the knowledge graph. The multiple \"ripples\"\nactivated by a user's historically clicked items are thus superposed to form\nthe preference distribution of the user with respect to a candidate item, which\ncould be used for predicting the final clicking probability. Through extensive\nexperiments on real-world datasets, we demonstrate that Ripple Network achieves\nsubstantial gains in a variety of scenarios, including movie, book and news\nrecommendation, over several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 11:12:01 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 12:15:17 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 03:28:32 GMT"}, {"version": "v4", "created": "Sat, 25 Aug 2018 05:52:08 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Wang", "Hongwei", ""], ["Zhang", "Fuzheng", ""], ["Wang", "Jialin", ""], ["Zhao", "Miao", ""], ["Li", "Wenjie", ""], ["Xie", "Xing", ""], ["Guo", "Minyi", ""]]}, {"id": "1803.03491", "submitter": "Hussain Kazmi", "authors": "Hussain Kazmi, Johan Suykens, Johan Driesen", "title": "Valuing knowledge, information and agency in Multi-agent Reinforcement\n  Learning: a case study in smart buildings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing energy efficiency in buildings can reduce costs and emissions\nsubstantially. Historically, this has been treated as a local, or single-agent,\noptimization problem. However, many buildings utilize the same types of thermal\nequipment e.g. electric heaters and hot water vessels. During operation,\noccupants in these buildings interact with the equipment differently thereby\ndriving them to diverse regions in the state-space. Reinforcement learning\nagents can learn from these interactions, recorded as sensor data, to optimize\nthe overall energy efficiency. However, if these agents operate individually at\na household level, they can not exploit the replicated structure in the\nproblem. In this paper, we demonstrate that this problem can indeed benefit\nfrom multi-agent collaboration by making use of targeted exploration of the\nstate-space allowing for better generalization. We also investigate trade-offs\nbetween integrating human knowledge and additional sensors. Results show that\nsavings of over 40% are possible with collaborative multi-agent systems making\nuse of either expert knowledge or additional sensors with no loss of occupant\ncomfort. We find that such multi-agent systems comfortably outperform\ncomparable single agent systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 12:48:03 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Kazmi", "Hussain", ""], ["Suykens", "Johan", ""], ["Driesen", "Johan", ""]]}, {"id": "1803.03544", "submitter": "Marco Melis", "authors": "Marco Melis, Davide Maiorca, Battista Biggio, Giorgio Giacinto and\n  Fabio Roli", "title": "Explaining Black-box Android Malware Detection", "comments": "Published on the Proceedings of 26th European Signal Processing\n  Conference (EUSIPCO '18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning models have been recently used for detecting malicious\nAndroid applications, reporting impressive performances on benchmark datasets,\neven when trained only on features statically extracted from the application,\nsuch as system calls and permissions. However, recent findings have highlighted\nthe fragility of such in-vitro evaluations with benchmark datasets, showing\nthat very few changes to the content of Android malware may suffice to evade\ndetection. How can we thus trust that a malware detector performing well on\nbenchmark data will continue to do so when deployed in an operating\nenvironment? To mitigate this issue, the most popular Android malware detectors\nuse linear, explainable machine-learning models to easily identify the most\ninfluential features contributing to each decision. In this work, we generalize\nthis approach to any black-box machine- learning model, by leveraging a\ngradient-based approach to identify the most influential local features. This\nenables using nonlinear models to potentially increase accuracy without\nsacrificing interpretability of decisions. Our approach also highlights the\nglobal characteristics learned by the model to discriminate between benign and\nmalware applications. Finally, as shown by our empirical analysis on a popular\nAndroid malware detection task, it also helps identifying potential\nvulnerabilities of linear and nonlinear models against adversarial\nmanipulations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 14:56:36 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 16:19:35 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Melis", "Marco", ""], ["Maiorca", "Davide", ""], ["Biggio", "Battista", ""], ["Giacinto", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1803.03571", "submitter": "Rion Brattig Correia", "authors": "Rion Brattig Correia and Luciana P. de Ara\\'ujo and Mauro M. Mattos\n  and Luis M. Rocha", "title": "City-wide Analysis of Electronic Health Records Reveals Gender and Age\n  Biases in the Administration of Known Drug-Drug Interactions", "comments": null, "journal-ref": "npj Digit. Med. 2, 74 (2019)", "doi": "10.1038/s41746-019-0141-x", "report-no": null, "categories": "cs.SI cs.CY cs.IR q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The occurrence of drug-drug-interactions (DDI) from multiple drug\ndispensations is a serious problem, both for individuals and health-care\nsystems, since patients with complications due to DDI are likely to reenter the\nsystem at a costlier level. We present a large-scale longitudinal study (18\nmonths) of the DDI phenomenon at the primary- and secondary-care level using\nelectronic health records (EHR) from the city of Blumenau in Southern Brazil\n(pop. $\\approx 340,000$). We found that 181 distinct drug pairs known to\ninteract were dispensed concomitantly to 12\\% of the patients in the city's\npublic health-care system. Further, 4\\% of the patients were dispensed drug\npairs that are likely to result in major adverse drug reactions (ADR)---with\ncosts estimated to be much larger than previously reported in smaller studies.\nThe large-scale analysis reveals that women have a 60\\% increased risk of DDI\nas compared to men; the increase becomes 90\\% when considering only DDI known\nto lead to major ADR. Furthermore, DDI risk increases substantially with age;\npatients aged 70-79 years have a 34\\% risk of DDI when they are dispensed two\nor more drugs concomitantly. Interestingly, a statistical null model\ndemonstrates that age- and female-specific risks from increased polypharmacy\nfail by far to explain the observed DDI risks in those populations, suggesting\nunknown social or biological causes. We also provide a network visualization of\ndrugs and demographic factors that characterize the DDI phenomenon and\ndemonstrate that accurate DDI prediction can be included in healthcare and\npublic-health management, to reduce DDI-related ADR and costs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 15:45:12 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 21:57:21 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 15:29:36 GMT"}, {"version": "v4", "created": "Thu, 2 Jan 2020 14:08:43 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Correia", "Rion Brattig", ""], ["de Ara\u00fajo", "Luciana P.", ""], ["Mattos", "Mauro M.", ""], ["Rocha", "Luis M.", ""]]}, {"id": "1803.03607", "submitter": "Emilio Rafael Balda", "authors": "Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar", "title": "On Generation of Adversarial Examples using Convex Programming", "comments": "Best Student Paper Award in ASILOMAR 2018", "journal-ref": "ASILOMAR 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed that deep learning architectures tend to make erroneous\ndecisions with high reliability for particularly designed adversarial\ninstances. In this work, we show that the perturbation analysis of these\narchitectures provides a framework for generating adversarial instances by\nconvex programming which, for classification tasks, is able to recover variants\nof existing non-adaptive adversarial methods. The proposed framework can be\nused for the design of adversarial noise under various desirable constraints\nand different types of networks. Moreover, this framework is capable of\nexplaining various existing adversarial methods and can be used to derive new\nalgorithms as well. We make use of these results to obtain novel algorithms.\nThe experiments show the competitive performance of the obtained solutions, in\nterms of fooling ratio, when benchmarked with well-known adversarial methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 17:24:45 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 11:32:36 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 08:33:19 GMT"}, {"version": "v4", "created": "Mon, 3 Dec 2018 22:14:52 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Balda", "Emilio Rafael", ""], ["Behboodi", "Arash", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1803.03623", "submitter": "Cong Feng", "authors": "Cong Feng and Jie Zhang", "title": "Hourly-Similarity Based Solar Forecasting Using Multi-Model Machine\n  Learning Blending", "comments": "2018 IEEE PES General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing penetration of solar power into power systems,\nforecasting becomes critical in power system operations. In this paper, an\nhourly-similarity (HS) based method is developed for 1-hour-ahead (1HA) global\nhorizontal irradiance (GHI) forecasting. This developed method utilizes diurnal\npatterns, statistical distinctions between different hours, and hourly\nsimilarities in solar data to improve the forecasting accuracy. The HS-based\nmethod is built by training multiple two-layer multi-model forecasting\nframework (MMFF) models independently with the same-hour subsets. The final\noptimal model is a combination of MMFF models with the best-performed blending\nalgorithm at every hour. At the forecasting stage, the most suitable model is\nselected to perform the forecasting subtask of a certain hour. The HS-based\nmethod is validated by 1-year data with six solar features collected by the\nNational Renewable Energy Laboratory (NREL). Results show that the HS-based\nmethod outperforms the non-HS (all-in-one) method significantly with the same\nMMFF architecture, wherein the optimal HS- based method outperforms the best\nall-in-one method by 10.94% and 7.74% based on the normalized mean absolute\nerror and normalized root mean square error, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 18:17:52 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Feng", "Cong", ""], ["Zhang", "Jie", ""]]}, {"id": "1803.03666", "submitter": "Chi-Ken Lu", "authors": "Chi-Ken Lu, Scott Cheng-Hsin Yang, Patrick Shafto", "title": "Standing Wave Decomposition Gaussian Process", "comments": "10 pages, 8 figures; updated version includes a modified introduction\n  and a new discussion on time complexity of our approximated GP method. New\n  references are added. Simulation package will be announced later; updated\n  with discussion of validity of perturbation treatment of Eq. (25) with added\n  Fig. 6 as evidence; simulation code at https://github.com/CoDaS-Lab/LG-SWD-GP", "journal-ref": "Phys. Rev. E 98, 032303 (2018)", "doi": "10.1103/PhysRevE.98.032303", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Standing Wave Decomposition (SWD) approximation to Gaussian\nProcess regression (GP). GP involves a costly matrix inversion operation, which\nlimits applicability to large data analysis. For an input space that can be\napproximated by a grid and when correlations among data are short-ranged, the\nkernel matrix inversion can be replaced by analytic diagonalization using the\nSWD. We show that this approach applies to uni- and multi-dimensional input\ndata, extends to include longer-range correlations, and the grid can be in a\nlatent space and used as inducing points. Through simulations, we show that our\napproximate method applied to the squared exponential kernel outperforms\nexisting methods in predictive accuracy per unit time in the regime where data\nare plentiful. Our SWD-GP is recommended for regression analyses where there is\na relatively large amount of data and/or there are constraints on computation\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 19:26:11 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 15:56:06 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2018 16:37:59 GMT"}, {"version": "v4", "created": "Mon, 17 Sep 2018 15:41:39 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Lu", "Chi-Ken", ""], ["Yang", "Scott Cheng-Hsin", ""], ["Shafto", "Patrick", ""]]}, {"id": "1803.03669", "submitter": "Mihai Cucuringu", "authors": "Mihai Cucuringu, Hemant Tyagi", "title": "Provably robust estimation of modulo 1 samples of a smooth function with\n  applications to phase unwrapping", "comments": "68 pages, 32 figures. arXiv admin note: text overlap with\n  arXiv:1710.10210", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an unknown smooth function $f: [0,1]^d \\rightarrow \\mathbb{R}$, and\nsay we are given $n$ noisy mod 1 samples of $f$, i.e., $y_i = (f(x_i) +\n\\eta_i)\\mod 1$, for $x_i \\in [0,1]^d$, where $\\eta_i$ denotes the noise. Given\nthe samples $(x_i,y_i)_{i=1}^{n}$, our goal is to recover smooth, robust\nestimates of the clean samples $f(x_i) \\bmod 1$. We formulate a natural\napproach for solving this problem, which works with angular embeddings of the\nnoisy mod 1 samples over the unit circle, inspired by the angular\nsynchronization framework. This amounts to solving a smoothness regularized\nleast-squares problem -- a quadratically constrained quadratic program (QCQP)\n-- where the variables are constrained to lie on the unit circle. Our approach\nis based on solving its relaxation, which is a trust-region sub-problem and\nhence solvable efficiently. We provide theoretical guarantees demonstrating its\nrobustness to noise for adversarial, and random Gaussian and Bernoulli noise\nmodels. To the best of our knowledge, these are the first such theoretical\nresults for this problem. We demonstrate the robustness and efficiency of our\napproach via extensive numerical simulations on synthetic data, along with a\nsimple least-squares solution for the unwrapping stage, that recovers the\noriginal samples of $f$ (up to a global shift). It is shown to perform well at\nhigh levels of noise, when taking as input the denoised modulo $1$ samples.\n  Finally, we also consider two other approaches for denoising the modulo 1\nsamples that leverage tools from Riemannian optimization on manifolds,\nincluding a Burer-Monteiro approach for a semidefinite programming relaxation\nof our formulation. For the two-dimensional version of the problem, which has\napplications in radar interferometry, we are able to solve instances of\nreal-world data with a million sample points in under 10 seconds, on a personal\nlaptop.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 19:31:53 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 16:50:52 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Tyagi", "Hemant", ""]]}, {"id": "1803.03672", "submitter": "Amin  Khajehnejad", "authors": "Amin Khajehnejad and Shima Hajimirza", "title": "Competitive Machine Learning: Best Theoretical Prediction vs\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is often used in competitive scenarios: Participants learn\nand fit static models, and those models compete in a shared platform. The\ncommon assumption is that in order to win a competition one has to have the\nbest predictive model, i.e., the model with the smallest out-sample error. Is\nthat necessarily true? Does the best theoretical predictive model for a target\nalways yield the best reward in a competition? If not, can one take the best\nmodel and purposefully change it into a theoretically inferior model which in\npractice results in a higher competitive edge? How does that modification look\nlike? And finally, if all participants modify their prediction models towards\nthe best practical performance, who benefits the most? players with inferior\nmodels, or those with theoretical superiority? The main theme of this paper is\nto raise these important questions and propose a theoretical model to answer\nthem. We consider a study case where two linear predictive models compete over\na shared target. The model with the closest estimate gets the whole reward,\nwhich is equal to the absolute value of the target. We characterize the reward\nfunction of each model, and using a basic game theoretic approach, demonstrate\nthat the inferior competitor can significantly improve his performance by\nchoosing optimal model coefficients that are different from the best\ntheoretical prediction. This is a preliminary study that emphasizes the fact\nthat in many applications where predictive machine learning is at the service\nof competition, much can be gained from practical (back-testing) optimization\nof the model compared to static prediction improvement.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 19:42:54 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Khajehnejad", "Amin", ""], ["Hajimirza", "Shima", ""]]}, {"id": "1803.03677", "submitter": "Soroush Pakniat", "authors": "Soroush Pakniat and Farzad Eskandari", "title": "Nonparametric Risk Assessment and Density Estimation for Persistence\n  Landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents approximate confidence intervals for each function of\nparameters in a Banach space based on a bootstrap algorithm. We apply kernel\ndensity approach to estimate the persistence landscape. In addition, we\nevaluate the quality distribution function estimator of random variables using\nintegrated mean square error (IMSE). The results of simulation studies show a\nsignificant improvement achieved by our approach compared to the standard\nversion of confidence intervals algorithm. In the next step, we provide several\nalgorithms to solve our model. Finally, real data analysis shows that the\naccuracy of our method compared to that of previous works for computing the\nconfidence interval.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 20:04:12 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Pakniat", "Soroush", ""], ["Eskandari", "Farzad", ""]]}, {"id": "1803.03684", "submitter": "Luciana Ferrer", "authors": "Luciana Ferrer", "title": "Scoring Formulation for Multi-Condition Joint PLDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint PLDA model, is a generalization of PLDA where the nuisance variable\nis no longer considered independent across samples, but potentially shared\n(tied) across samples that correspond to the same nuisance condition. The\noriginal work considered a single nuisance condition, deriving the EM and\nscoring formulas for this scenario. In this document, we show how to obtain\nlikelihood ratios for scoring when multiple nuisance conditions are allowed in\nthe model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 20:29:18 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Ferrer", "Luciana", ""]]}, {"id": "1803.03692", "submitter": "Zhinus Marzi", "authors": "Zhinus Marzi, Joao Hespanha and Upamanyu Madhow", "title": "On the information in spike timing: neural codes derived from\n  polychronous groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing evidence regarding the importance of spike timing in neural\ninformation processing, with even a small number of spikes carrying\ninformation, but computational models lag significantly behind those for rate\ncoding. Experimental evidence on neuronal behavior is consistent with the\ndynamical and state dependent behavior provided by recurrent connections. This\nmotivates the minimalistic abstraction investigated in this paper, aimed at\nproviding insight into information encoding in spike timing via recurrent\nconnections. We employ information-theoretic techniques for a simple reservoir\nmodel which encodes input spatiotemporal patterns into a sparse neural code,\ntranslating the polychronous groups introduced by Izhikevich into codewords on\nwhich we can perform standard vector operations. We show that the distance\nproperties of the code are similar to those for (optimal) random codes. In\nparticular, the code meets benchmarks associated with both linear\nclassification and capacity, with the latter scaling exponentially with\nreservoir size.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 20:53:31 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Marzi", "Zhinus", ""], ["Hespanha", "Joao", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "1803.03719", "submitter": "Pooyan Fazli", "authors": "Mahmoud Hamandi, Mike D'Arcy, and Pooyan Fazli", "title": "DeepMoTIon: Learning to Navigate Like Humans", "comments": "7 pages, In Proceedings of the IEEE International Conference on Robot\n  and Human Interactive Communication, RO-MAN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel human-aware navigation approach, where the robot learns to\nmimic humans to navigate safely in crowds. The presented model, referred to as\nDeepMoTIon, is trained with pedestrian surveillance data to predict human\nvelocity in the environment. The robot processes LiDAR scans via the trained\nnetwork to navigate to the target location. We conduct extensive experiments to\nassess the components of our network and prove their necessity to imitate\nhumans. Our experiments show that DeepMoTIion outperforms all the benchmarks in\nterms of human imitation, achieving a 24% reduction in time series-based path\ndeviation over the next best approach. In addition, while many other approaches\noften failed to reach the target, our method reached the target in 100% of the\ntest cases while complying with social norms and ensuring human safety.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 23:36:38 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 09:36:46 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 23:48:46 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Hamandi", "Mahmoud", ""], ["D'Arcy", "Mike", ""], ["Fazli", "Pooyan", ""]]}, {"id": "1803.03735", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran K. Thekumparampil, Chong Wang, Sewoong Oh, Li-Jia Li", "title": "Attention-based Graph Neural Network for Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently popularized graph neural networks achieve the state-of-the-art\naccuracy on a number of standard benchmark datasets for graph-based\nsemi-supervised learning, improving significantly over existing approaches.\nThese architectures alternate between a propagation layer that aggregates the\nhidden states of the local neighborhood and a fully-connected layer. Perhaps\nsurprisingly, we show that a linear model, that removes all the intermediate\nfully-connected layers, is still able to achieve a performance comparable to\nthe state-of-the-art models. This significantly reduces the number of\nparameters, which is critical for semi-supervised learning where number of\nlabeled examples are small. This in turn allows a room for designing more\ninnovative propagation layers. Based on this insight, we propose a novel graph\nneural network that removes all the intermediate fully-connected layers, and\nreplaces the propagation layers with attention mechanisms that respect the\nstructure of the graph. The attention mechanism allows us to learn a dynamic\nand adaptive local summary of the neighborhood to achieve more accurate\npredictions. In a number of experiments on benchmark citation networks\ndatasets, we demonstrate that our approach outperforms competing methods. By\nexamining the attention weights among neighbors, we show that our model\nprovides some interesting insights on how neighbors influence each other.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 02:01:35 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Thekumparampil", "Kiran K.", ""], ["Wang", "Chong", ""], ["Oh", "Sewoong", ""], ["Li", "Li-Jia", ""]]}, {"id": "1803.03756", "submitter": "Lili Zhang", "authors": "Lili Zhang, Jennifer Priestley and Xuelei Ni", "title": "Influence of the Event Rate on Discrimination Abilities of Bankruptcy\n  Prediction Models", "comments": null, "journal-ref": "International Journal of Database Management Systems. 2018\n  February 10(1): 1-14", "doi": "10.5121/ijdms.2018.10101", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In bankruptcy prediction, the proportion of events is very low, which is\noften oversampled to eliminate this bias. In this paper, we study the influence\nof the event rate on discrimination abilities of bankruptcy prediction models.\nFirst the statistical association and significance of public records and\nfirmographics indicators with the bankruptcy were explored. Then the event rate\nwas oversampled from 0.12% to 10%, 20%, 30%, 40%, and 50%, respectively. Seven\nmodels were developed, including Logistic Regression, Decision Tree, Random\nForest, Gradient Boosting, Support Vector Machine, Bayesian Network, and Neural\nNetwork. Under different event rates, models were comprehensively evaluated and\ncompared based on Kolmogorov-Smirnov Statistic, accuracy, F1 score, Type I\nerror, Type II error, and ROC curve on the hold-out dataset with their best\nprobability cut-offs. Results show that Bayesian Network is the most\ninsensitive to the event rate, while Support Vector Machine is the most\nsensitive.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 04:51:31 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zhang", "Lili", ""], ["Priestley", "Jennifer", ""], ["Ni", "Xuelei", ""]]}, {"id": "1803.03759", "submitter": "Sanjay Krishna Gouda", "authors": "Sanjay Krishna Gouda, Salil Kanetkar, David Harrison and Manfred K\n  Warmuth", "title": "Speech Recognition: Keyword Spotting Through Image Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of identifying voice commands has always been a challenge due to\nthe presence of noise and variability in speed, pitch, etc. We will compare the\nefficacies of several neural network architectures for the speech recognition\nproblem. In particular, we will build a model to determine whether a one second\naudio clip contains a particular word (out of a set of 10), an unknown word, or\nsilence. The models to be implemented are a CNN recommended by the Tensorflow\nSpeech Recognition tutorial, a low-latency CNN, and an adversarially trained\nCNN. The result is a demonstration of how to convert a problem in audio\nrecognition to the better-studied domain of image classification, where the\npowerful techniques of convolutional neural networks are fully developed.\nAdditionally, we demonstrate the applicability of the technique of Virtual\nAdversarial Training (VAT) to this problem domain, functioning as a powerful\nregularizer with promising potential future applications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 05:16:18 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 17:10:43 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Gouda", "Sanjay Krishna", ""], ["Kanetkar", "Salil", ""], ["Harrison", "David", ""], ["Warmuth", "Manfred K", ""]]}, {"id": "1803.03764", "submitter": "Arsenii Ashukha", "authors": "Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, Dmitry Vetrov", "title": "Variance Networks: When Expectation Does Not Meet Your Expectations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ordinary stochastic neural networks mostly rely on the expected values of\ntheir weights to make predictions, whereas the induced noise is mostly used to\ncapture the uncertainty, prevent overfitting and slightly boost the performance\nthrough test-time averaging. In this paper, we introduce variance layers, a\ndifferent kind of stochastic layers. Each weight of a variance layer follows a\nzero-mean distribution and is only parameterized by its variance. We show that\nsuch layers can learn surprisingly well, can serve as an efficient exploration\ntool in reinforcement learning tasks and provide a decent defense against\nadversarial attacks. We also show that a number of conventional Bayesian neural\nnetworks naturally converge to such zero-mean posteriors. We observe that in\nthese cases such zero-mean parameterization leads to a much better training\nobjective than conventional parameterizations where the mean is being learned.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 06:01:40 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 08:41:11 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 10:07:40 GMT"}, {"version": "v4", "created": "Wed, 4 Jul 2018 08:24:14 GMT"}, {"version": "v5", "created": "Mon, 18 Feb 2019 08:45:19 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Neklyudov", "Kirill", ""], ["Molchanov", "Dmitry", ""], ["Ashukha", "Arsenii", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1803.03769", "submitter": "Siong Thye Goh", "authors": "Siong Thye Goh, Cynthia Rudin", "title": "A Minimax Surrogate Loss Approach to Conditional Difference Estimation", "comments": "33 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new machine learning approach to estimate personalized treatment\neffects in the classical potential outcomes framework with binary outcomes. To\novercome the problem that both treatment and control outcomes for the same unit\nare required for supervised learning, we propose surrogate loss functions that\nincorporate both treatment and control data. The new surrogates yield tighter\nbounds than the sum of losses for treatment and control groups. A specific\nchoice of loss function, namely a type of hinge loss, yields a minimax support\nvector machine formulation. The resulting optimization problem requires the\nsolution to only a single convex optimization problem, incorporating both\ntreatment and control units, and it enables the kernel trick to be used to\nhandle nonlinear (also non-parametric) estimation. Statistical learning bounds\nare also presented for the framework, and experimental results.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 07:01:52 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 03:36:42 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Goh", "Siong Thye", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1803.03800", "submitter": "Pramod Kompalli", "authors": "Srayanta Mukherjee, Devashish Shankar, Atin Ghosh, Nilam Tathawadekar,\n  Pramod Kompalli, Sunita Sarawagi, Krishnendu Chaudhury", "title": "ARMDN: Associative and Recurrent Mixture Density Networks for eRetail\n  Demand Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate demand forecasts can help on-line retail organizations better plan\ntheir supply-chain processes. The challenge, however, is the large number of\nassociative factors that result in large, non-stationary shifts in demand,\nwhich traditional time series and regression approaches fail to model. In this\npaper, we propose a Neural Network architecture called AR-MDN, that\nsimultaneously models associative factors, time-series trends and the variance\nin the demand. We first identify several causal features and use a combination\nof feature embeddings, MLP and LSTM to represent them. We then model the output\ndensity as a learned mixture of Gaussian distributions. The AR-MDN can be\ntrained end-to-end without the need for additional supervision. We experiment\non a dataset of an year's worth of data over tens-of-thousands of products from\nFlipkart. The proposed architecture yields a significant improvement in\nforecasting accuracy when compared with existing alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 12:45:11 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 04:49:15 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Mukherjee", "Srayanta", ""], ["Shankar", "Devashish", ""], ["Ghosh", "Atin", ""], ["Tathawadekar", "Nilam", ""], ["Kompalli", "Pramod", ""], ["Sarawagi", "Sunita", ""], ["Chaudhury", "Krishnendu", ""]]}, {"id": "1803.03877", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz and Robert Sabourin and George D. C. Cavalcanti", "title": "On dynamic ensemble selection and data preprocessing for multi-class\n  imbalance learning", "comments": "Proceedings of the ICPRAI 2018 pp. 189-194", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-imbalance refers to classification problems in which many more\ninstances are available for certain classes than for others. Such imbalanced\ndatasets require special attention because traditional classifiers generally\nfavor the majority class which has a large number of instances. Ensemble of\nclassifiers have been reported to yield promising results. However, the\nmajority of ensemble methods applied too imbalanced learning are static ones.\nMoreover, they only deal with binary imbalanced problems. Hence, this paper\npresents an empirical analysis of dynamic selection techniques and data\npreprocessing methods for dealing with multi-class imbalanced problems. We\nconsidered five variations of preprocessing methods and four dynamic selection\nmethods. Our experiments conducted on 26 multi-class imbalanced problems show\nthat the dynamic ensemble improves the F-measure and the G-mean as compared to\nthe static ensemble. Moreover, data preprocessing plays an important role in\nsuch cases.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 01:46:31 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 15:52:59 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1803.03880", "submitter": "Soorya Gopalakrishnan", "authors": "Soorya Gopalakrishnan, Zhinus Marzi, Upamanyu Madhow, Ramtin Pedarsani", "title": "Combating Adversarial Attacks Using Sparse Representations", "comments": "Accepted at ICLR Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is by now well-known that small adversarial perturbations can induce\nclassification errors in deep neural networks (DNNs). In this paper, we make\nthe case that sparse representations of the input data are a crucial tool for\ncombating such attacks. For linear classifiers, we show that a sparsifying\nfront end is provably effective against $\\ell_{\\infty}$-bounded attacks,\nreducing output distortion due to the attack by a factor of roughly $K / N$\nwhere $N$ is the data dimension and $K$ is the sparsity level. We then extend\nthis concept to DNNs, showing that a \"locally linear\" model can be used to\ndevelop a theoretical foundation for crafting attacks and defenses.\nExperimental results for the MNIST dataset show the efficacy of the proposed\nsparsifying front end.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 02:02:46 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 10:36:47 GMT"}, {"version": "v3", "created": "Fri, 13 Jul 2018 17:16:53 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Gopalakrishnan", "Soorya", ""], ["Marzi", "Zhinus", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1803.03910", "submitter": "Li Zeng", "authors": "Li Zeng, Zhaolong Yu, Hongyu Zhao", "title": "A pathway-based kernel boosting method for sample classification using\n  genomic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of cancer genomic data has long suffered \"the curse of\ndimensionality\". Sample sizes for most cancer genomic studies are a few\nhundreds at most while there are tens of thousands of genomic features studied.\nVarious methods have been proposed to leverage prior biological knowledge, such\nas pathways, to more effectively analyze cancer genomic data. Most of the\nmethods focus on testing marginal significance of the associations between\npathways and clinical phenotypes. They can identify relevant pathways, but do\nnot involve predictive modeling. In this article, we propose a Pathway-based\nKernel Boosting (PKB) method for integrating gene pathway information for\nsample classification, where we use kernel functions calculated from each\npathway as base learners and learn the weights through iterative optimization\nof the classification loss function. We apply PKB and several competing methods\nto three cancer studies with pathological and clinical information, including\ntumor grade, stage, tumor sites, and metastasis status. Our results show that\nPKB outperforms other methods, and identifies pathways relevant to the outcome\nvariables.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 05:50:35 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zeng", "Li", ""], ["Yu", "Zhaolong", ""], ["Zhao", "Hongyu", ""]]}, {"id": "1803.03916", "submitter": "Xiang Gao", "authors": "Xiang Gao", "title": "Deep reinforcement learning for time series: playing idealized trading\n  games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-learning is investigated as an end-to-end solution to estimate the\noptimal strategies for acting on time series input. Experiments are conducted\non two idealized trading games. 1) Univariate: the only input is a wave-like\nprice time series, and 2) Bivariate: the input includes a random stepwise price\ntime series and a noisy signal time series, which is positively correlated with\nfuture price changes. The Univariate game tests whether the agent can capture\nthe underlying dynamics, and the Bivariate game tests whether the agent can\nutilize the hidden relation among the inputs. Stacked Gated Recurrent Unit\n(GRU), Long Short-Term Memory (LSTM) units, Convolutional Neural Network (CNN),\nand multi-layer perceptron (MLP) are used to model Q values. For both games,\nall agents successfully find a profitable strategy. The GRU-based agents show\nbest overall performance in the Univariate game, while the MLP-based agents\noutperform others in the Bivariate game.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 06:56:29 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Gao", "Xiang", ""]]}, {"id": "1803.03919", "submitter": "Yingxiang Yang", "authors": "Yingxiang Yang, Adams Wei Yu, Zhaoran Wang and Tuo Zhao", "title": "Detecting Nonlinear Causality in Multivariate Time Series with Sparse\n  Additive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric method for detecting nonlinear causal relationship\nwithin a set of multidimensional discrete time series, by using sparse additive\nmodels (SpAMs). We show that, when the input to the SpAM is a $\\beta$-mixing\ntime series, the model can be fitted by first approximating each unknown\nfunction with a linear combination of a set of B-spline bases, and then solving\na group-lasso-type optimization problem with nonconvex regularization.\nTheoretically, we characterize the oracle statistical properties of the\nproposed sparse estimator in function estimation and model selection.\nNumerically, we propose an efficient pathwise iterative shrinkage thresholding\nalgorithm (PISTA), which tames the nonconvexity and guarantees linear\nconvergence towards the desired sparse estimator with high probability.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 07:46:24 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 04:24:14 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Yang", "Yingxiang", ""], ["Yu", "Adams Wei", ""], ["Wang", "Zhaoran", ""], ["Zhao", "Tuo", ""]]}, {"id": "1803.03934", "submitter": "Massimiliano Pontil", "authors": "Andreas Maurer and Massimiliano Pontil", "title": "Empirical bounds for functions with weak interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide sharp empirical estimates of expectation, variance and normal\napproximation for a class of statistics whose variation in any argument does\nnot change too much when another argument is modified. Examples of such weak\ninteractions are furnished by U- and V-statistics, Lipschitz L-statistics and\nvarious error functionals of L2-regularized algorithms and Gibbs algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 10:28:45 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Maurer", "Andreas", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1803.03965", "submitter": "Pan Li", "authors": "Pan Li and Qiang Liu and Wentao Zhao and Dongxu Wang and Siqi Wang", "title": "BEBP: An Poisoning Method Against Machine Learning Based IDSs", "comments": "7 pages,5figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In big data era, machine learning is one of fundamental techniques in\nintrusion detection systems (IDSs). However, practical IDSs generally update\ntheir decision module by feeding new data then retraining learning models in a\nperiodical way. Hence, some attacks that comprise the data for training or\ntesting classifiers significantly challenge the detecting capability of machine\nlearning-based IDSs. Poisoning attack, which is one of the most recognized\nsecurity threats towards machine learning-based IDSs, injects some adversarial\nsamples into the training phase, inducing data drifting of training data and a\nsignificant performance decrease of target IDSs over testing data. In this\npaper, we adopt the Edge Pattern Detection (EPD) algorithm to design a novel\npoisoning method that attack against several machine learning algorithms used\nin IDSs. Specifically, we propose a boundary pattern detection algorithm to\nefficiently generate the points that are near to abnormal data but considered\nto be normal ones by current classifiers. Then, we introduce a Batch-EPD\nBoundary Pattern (BEBP) detection algorithm to overcome the limitation of the\nnumber of edge pattern points generated by EPD and to obtain more useful\nadversarial samples. Based on BEBP, we further present a moderate but effective\npoisoning method called chronic poisoning attack. Extensive experiments on\nsynthetic and three real network data sets demonstrate the performance of the\nproposed poisoning method against several well-known machine learning\nalgorithms and a practical intrusion detection method named FMIFS-LSSVM-IDS.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 14:15:50 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Li", "Pan", ""], ["Liu", "Qiang", ""], ["Zhao", "Wentao", ""], ["Wang", "Dongxu", ""], ["Wang", "Siqi", ""]]}, {"id": "1803.04015", "submitter": "Cem Tekin", "authors": "Eralp Tur\\u{g}ay and Doruk \\\"Oner and Cem Tekin", "title": "Multi-objective Contextual Bandit Problem with Similarity Information", "comments": "The 21st International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the multi-objective contextual bandit problem with\nsimilarity information. This problem extends the classical contextual bandit\nproblem with similarity information by introducing multiple and possibly\nconflicting objectives. Since the best arm in each objective can be different\ngiven the context, learning the best arm based on a single objective can\njeopardize the rewards obtained from the other objectives. In order to evaluate\nthe performance of the learner in this setup, we use a performance metric\ncalled the contextual Pareto regret. Essentially, the contextual Pareto regret\nis the sum of the distances of the arms chosen by the learner to the context\ndependent Pareto front. For this problem, we develop a new online learning\nalgorithm called Pareto Contextual Zooming (PCZ), which exploits the idea of\ncontextual zooming to learn the arms that are close to the Pareto front for\neach observed context by adaptively partitioning the joint context-arm set\naccording to the observed rewards and locations of the context-arm pairs\nselected in the past. Then, we prove that PCZ achieves $\\tilde O\n(T^{(1+d_p)/(2+d_p)})$ Pareto regret where $d_p$ is the Pareto zooming\ndimension that depends on the size of the set of near-optimal context-arm\npairs. Moreover, we show that this regret bound is nearly optimal by providing\nan almost matching $\\Omega (T^{(1+d_p)/(2+d_p)})$ lower bound.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 19:04:12 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Tur\u011fay", "Eralp", ""], ["\u00d6ner", "Doruk", ""], ["Tekin", "Cem", ""]]}, {"id": "1803.04042", "submitter": "Kai Xu", "authors": "Kai Xu, Dae Hoon Park, Chang Yi and Charles Sutton", "title": "Interpreting Deep Classifier by Visual Distillation of Dark Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting black box classifiers, such as deep networks, allows an analyst\nto validate a classifier before it is deployed in a high-stakes setting. A\nnatural idea is to visualize the deep network's representations, so as to \"see\nwhat the network sees\". In this paper, we demonstrate that standard dimension\nreduction methods in this setting can yield uninformative or even misleading\nvisualizations. Instead, we present DarkSight, which visually summarizes the\npredictions of a classifier in a way inspired by notion of dark knowledge.\nDarkSight embeds the data points into a low-dimensional space such that it is\neasy to compress the deep classifier into a simpler one, essentially combining\nmodel compression and dimension reduction. We compare DarkSight against t-SNE\nboth qualitatively and quantitatively, demonstrating that DarkSight\nvisualizations are more informative. Our method additionally yields a new\nconfidence measure based on dark knowledge by quantifying how unusual a given\nvector of predictions is.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 21:17:05 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Xu", "Kai", ""], ["Park", "Dae Hoon", ""], ["Yi", "Chang", ""], ["Sutton", "Charles", ""]]}, {"id": "1803.04051", "submitter": "Rakshit Trivedi", "authors": "Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, Hongyuan Zha", "title": "Representation Learning over Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we effectively encode evolving information over dynamic graphs into\nlow-dimensional representations? In this paper, we propose DyRep, an inductive\ndeep representation learning framework that learns a set of functions to\nefficiently produce low-dimensional node embeddings that evolves over time. The\nlearned embeddings drive the dynamics of two key processes namely,\ncommunication and association between nodes in dynamic graphs. These processes\nexhibit complex nonlinear dynamics that evolve at different time scales and\nsubsequently contribute to the update of node embeddings. We employ a\ntime-scale dependent multivariate point process model to capture these\ndynamics. We devise an efficient unsupervised learning procedure and\ndemonstrate that our approach significantly outperforms representative\nbaselines on two real-world datasets for the problem of dynamic link prediction\nand event time prediction.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 22:00:33 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 19:27:29 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Trivedi", "Rakshit", ""], ["Farajtabar", "Mehrdad", ""], ["Biswal", "Prasenjeet", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1803.04062", "submitter": "Elliot Meyerson", "authors": "Elliot Meyerson and Risto Miikkulainen", "title": "Pseudo-task Augmentation: From Deep Multitask Learning to Intratask\n  Sharing---and Back", "comments": "Published as a conference paper at ICML 2018; 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep multitask learning boosts performance by sharing learned structure\nacross related tasks. This paper adapts ideas from deep multitask learning to\nthe setting where only a single task is available. The method is formalized as\npseudo-task augmentation, in which models are trained with multiple decoders\nfor each task. Pseudo-tasks simulate the effect of training towards\nclosely-related tasks drawn from the same universe. In a suite of experiments,\npseudo-task augmentation is shown to improve performance on single-task\nlearning problems. When combined with multitask learning, further improvements\nare achieved, including state-of-the-art performance on the CelebA dataset,\nshowing that pseudo-task augmentation and multitask learning have complementary\nvalue. All in all, pseudo-task augmentation is a broadly applicable and\nefficient way to boost performance in deep learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 23:06:14 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 01:28:34 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1803.04084", "submitter": "Yun-Jhong Wu", "authors": "Yun-Jhong Wu, Elizaveta Levina, Ji Zhu", "title": "Link prediction for egocentrically sampled networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction in networks is typically accomplished by estimating or\nranking the probabilities of edges for all pairs of nodes. In practice,\nespecially for social networks, the data are often collected by egocentric\nsampling, which means selecting a subset of nodes and recording all of their\nedges. This sampling mechanism requires different prediction tools than the\ntypical assumption of links missing at random. We propose a new computationally\nefficient link prediction algorithm for egocentrically sampled networks, which\nestimates the underlying probability matrix by estimating its row space. For\nnetworks created by sampling rows, our method outperforms many popular link\nprediction and graphon estimation techniques.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 01:37:53 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Wu", "Yun-Jhong", ""], ["Levina", "Elizaveta", ""], ["Zhu", "Ji", ""]]}, {"id": "1803.04087", "submitter": "Adarsh Barik", "authors": "Adarsh Barik, Jean Honorio", "title": "Learning discrete Bayesian networks in polynomial time and sample\n  complexity", "comments": null, "journal-ref": "IEEE International Symposium on Information Theory (ISIT), 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of structure learning for Bayesian\nnetworks in which nodes take discrete values. The problem is NP-hard in general\nbut we show that under certain conditions we can recover the true structure of\na Bayesian network with sufficient number of samples. We develop a mathematical\nmodel which does not assume any specific conditional probability distributions\nfor the nodes. We use a primal-dual witness construction to prove that, under\nsome technical conditions on the interaction between node pairs, we can do\nexact recovery of the parents and children of a node by performing group\nl_12-regularized multivariate regression. Thus, we recover the true Bayesian\nnetwork structure. If degree of a node is bounded then the sample complexity of\nour proposed approach grows logarithmically with respect to the number of nodes\nin the Bayesian network. Furthermore, our method runs in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 01:49:39 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 04:30:05 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 20:58:55 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Barik", "Adarsh", ""], ["Honorio", "Jean", ""]]}, {"id": "1803.04186", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Alireza M. Javid, and Saikat Chatterjee", "title": "R3Net: Random Weights, Rectifier Linear Units and Robustness for\n  Artificial Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a neural network architecture with randomized features, a\nsign-splitter, followed by rectified linear units (ReLU). We prove that our\narchitecture exhibits robustness to the input perturbation: the output feature\nof the neural network exhibits a Lipschitz continuity in terms of the input\nperturbation. We further show that the network output exhibits a discrimination\nability that inputs that are not arbitrarily close generate output vectors\nwhich maintain distance between each other obeying a certain lower bound. This\nensures that two different inputs remain discriminable while contracting the\ndistance in the output feature space.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:04:17 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Javid", "Alireza M.", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1803.04189", "submitter": "Samuli Laine", "authors": "Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero\n  Karras, Miika Aittala, Timo Aila", "title": "Noise2Noise: Learning Image Restoration without Clean Data", "comments": "Added link to official implementation and updated MRI results to\n  match it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply basic statistical reasoning to signal reconstruction by machine\nlearning -- learning to map corrupted observations to clean signals -- with a\nsimple and powerful conclusion: it is possible to learn to restore images by\nonly looking at corrupted examples, at performance at and sometimes exceeding\ntraining using clean data, without explicit image priors or likelihood models\nof the corruption. In practice, we show that a single model learns photographic\nnoise removal, denoising synthetic Monte Carlo images, and reconstruction of\nundersampled MRI scans -- all corrupted by different processes -- based on\nnoisy data only.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:07:58 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 12:08:44 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 10:29:23 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Lehtinen", "Jaakko", ""], ["Munkberg", "Jacob", ""], ["Hasselgren", "Jon", ""], ["Laine", "Samuli", ""], ["Karras", "Tero", ""], ["Aittala", "Miika", ""], ["Aila", "Timo", ""]]}, {"id": "1803.04193", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Saikat Chatterjee, Peter H\\\"andel", "title": "Extreme Learning Machine for Graph Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we improve extreme learning machines for regression tasks\nusing a graph signal processing based regularization. We assume that the target\nsignal for prediction or regression is a graph signal. With this assumption, we\nuse the regularization to enforce that the output of an extreme learning\nmachine is smooth over a given graph. Simulation results with real data confirm\nthat such regularization helps significantly when the available training data\nis limited in size and corrupted by noise.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:12:48 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""], ["H\u00e4ndel", "Peter", ""]]}, {"id": "1803.04196", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Saikat Chatterjee, Peter H\\\"andel", "title": "Multi-kernel Regression For Graph Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a multi-kernel based regression method for graph signal processing\nwhere the target signal is assumed to be smooth over a graph. In multi-kernel\nregression, an effective kernel function is expressed as a linear combination\nof many basis kernel functions. We estimate the linear weights to learn the\neffective kernel function by appropriate regularization based on graph\nsmoothness. We show that the resulting optimization problem is shown to be\nconvex and pro- pose an accelerated projected gradient descent based solution.\nSimulation results using real-world graph signals show efficiency of the\nmulti-kernel based approach over a standard kernel based approach.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:20:07 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""], ["H\u00e4ndel", "Peter", ""]]}, {"id": "1803.04204", "submitter": "Akshay Krishnamurthy", "authors": "Akshay Krishnamurthy, Zhiwei Steven Wu, Vasilis Syrgkanis", "title": "Semiparametric Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies semiparametric contextual bandits, a generalization of the\nlinear stochastic bandit problem where the reward for an action is modeled as a\nlinear function of known action features confounded by an non-linear\naction-independent term. We design new algorithms that achieve\n$\\tilde{O}(d\\sqrt{T})$ regret over $T$ rounds, when the linear function is\n$d$-dimensional, which matches the best known bounds for the simpler\nunconfounded case and improves on a recent result of Greenewald et al. (2017).\nVia an empirical evaluation, we show that our algorithms outperform prior\napproaches when there are non-linear confounding effects on the rewards.\nTechnically, our algorithms use a new reward estimator inspired by\ndoubly-robust approaches and our proofs require new concentration inequalities\nfor self-normalized martingales.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:39:20 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 11:04:39 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Wu", "Zhiwei Steven", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1803.04209", "submitter": "Michael Teng", "authors": "Michael Teng and Frank Wood", "title": "High Throughput Synchronous Distributed Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new, high-throughput, synchronous, distributed, data-parallel,\nstochastic-gradient-descent learning algorithm. This algorithm uses amortized\ninference in a compute-cluster-specific, deep, generative, dynamical model to\nperform joint posterior predictive inference of the mini-batch gradient\ncomputation times of all worker-nodes in a parallel computing cluster. We show\nthat a synchronous parameter server can, by utilizing such a model, choose an\noptimal cutoff time beyond which mini-batch gradient messages from slow workers\nare ignored that maximizes overall mini-batch gradient computations per second.\nIn keeping with earlier findings we observe that, under realistic conditions,\neagerly discarding the mini-batch gradient computations of stragglers not only\nincreases throughput but actually increases the overall rate of convergence as\na function of wall-clock time by virtue of eliminating idleness. The principal\nnovel contribution and finding of this work goes beyond this by demonstrating\nthat using the predicted run-times from a generative model of cluster worker\nperformance to dynamically adjust the cutoff improves substantially over the\nstatic-cutoff prior art, leading to, among other things, significantly reduced\ndeep neural net training times on large computer clusters.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:51:38 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Teng", "Michael", ""], ["Wood", "Frank", ""]]}, {"id": "1803.04223", "submitter": "Jie Yang", "authors": "Jie Yang, Thomas Drake, Andreas Damianou, Yoelle Maarek", "title": "Leveraging Crowdsourcing Data For Deep Active Learning - An Application:\n  Learning Intents in Alexa", "comments": null, "journal-ref": null, "doi": "10.1145/3178876.3186033", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a generic Bayesian framework that enables any deep\nlearning model to actively learn from targeted crowds. Our framework inherits\nfrom recent advances in Bayesian deep learning, and extends existing work by\nconsidering the targeted crowdsourcing approach, where multiple annotators with\nunknown expertise contribute an uncontrolled amount (often limited) of\nannotations. Our framework leverages the low-rank structure in annotations to\nlearn individual annotator expertise, which then helps to infer the true labels\nfrom noisy and sparse annotations. It provides a unified Bayesian model to\nsimultaneously infer the true labels and train the deep learning model in order\nto reach an optimal learning efficacy. Finally, our framework exploits the\nuncertainty of the deep learning model during prediction as well as the\nannotators' estimated expertise to minimize the number of required annotations\nand annotators for optimally training the deep learning model.\n  We evaluate the effectiveness of our framework for intent classification in\nAlexa (Amazon's personal assistant), using both synthetic and real-world\ndatasets. Experiments show that our framework can accurately learn annotator\nexpertise, infer true labels, and effectively reduce the amount of annotations\nin model training as compared to state-of-the-art approaches. We further\ndiscuss the potential of our proposed framework in bridging machine learning\nand crowdsourcing towards improved human-in-the-loop systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 12:43:41 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Yang", "Jie", ""], ["Drake", "Thomas", ""], ["Damianou", "Andreas", ""], ["Maarek", "Yoelle", ""]]}, {"id": "1803.04232", "submitter": "Hongyi Ding", "authors": "Hongyi Ding, Young Lee, Issei Sato, Masashi Sugiyama", "title": "Variational Inference for Gaussian Process with Panel Count Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first framework for Gaussian-process-modulated Poisson\nprocesses when the temporal data appear in the form of panel counts. Panel\ncount data frequently arise when experimental subjects are observed only at\ndiscrete time points and only the numbers of occurrences of the events between\nsubsequent observation times are available. The exact occurrence timestamps of\nthe events are unknown. The method of conducting the efficient variational\ninference is presented, based on the assumption of a Gaussian-process-modulated\nintensity function. We derive a tractable lower bound to alleviate the problems\nof the intractable evidence lower bound inherent in the variational inference\nframework. Our algorithm outperforms classical methods on both synthetic and\nthree real panel count sets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 13:02:20 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Ding", "Hongyi", ""], ["Lee", "Young", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1803.04239", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas, Mike Davies, Pierre Vandergheynst", "title": "FeTa: A DCA Pruning Algorithm with Generalization Error Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent DNN pruning algorithms have succeeded in reducing the number of\nparameters in fully connected layers, often with little or no drop in\nclassification accuracy. However, most of the existing pruning schemes either\nhave to be applied during training or require a costly retraining procedure\nafter pruning to regain classification accuracy. We start by proposing a cheap\npruning algorithm for fully connected DNN layers based on difference of convex\nfunctions (DC) optimisation, that requires little or no retraining. We then\nprovide a theoretical analysis for the growth in the Generalization Error (GE)\nof a DNN for the case of bounded perturbations to the hidden layers, of which\nweight pruning is a special case. Our pruning method is orders of magnitude\nfaster than competing approaches, while our theoretical analysis sheds light to\npreviously observed problems in DNN pruning. Experiments on commnon feedforward\nneural networks validate our results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 13:19:33 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Pitas", "Konstantinos", ""], ["Davies", "Mike", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1803.04300", "submitter": "Patrick Schramowski", "authors": "Patrick Schramowski, Christian Bauckhage, Kristian Kersting", "title": "Neural Conditional Gradients", "comments": "arXiv admin note: text overlap with arXiv:1610.05120 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The move from hand-designed to learned optimizers in machine learning has\nbeen quite successful for gradient-based and -free optimizers. When facing a\nconstrained problem, however, maintaining feasibility typically requires a\nprojection step, which might be computationally expensive and not\ndifferentiable. We show how the design of projection-free convex optimization\nalgorithms can be cast as a learning problem based on Frank-Wolfe Networks:\nrecurrent networks implementing the Frank-Wolfe algorithm aka. conditional\ngradients. This allows them to learn to exploit structure when, e.g.,\noptimizing over rank-1 matrices. Our LSTM-learned optimizers outperform\nhand-designed as well learned but unconstrained ones. We demonstrate this for\ntraining support vector machines and softmax classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 15:10:45 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 08:41:52 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Schramowski", "Patrick", ""], ["Bauckhage", "Christian", ""], ["Kersting", "Kristian", ""]]}, {"id": "1803.04303", "submitter": "Markus Heinonen", "authors": "Markus Heinonen, Cagatay Yildiz, Henrik Mannerstr\\\"om, Jukka\n  Intosalmi, Harri L\\\"ahdesm\\\"aki", "title": "Learning unknown ODE models with Gaussian processes", "comments": "11 pages, 2 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional ODE modelling coefficients of an equation driving the system\nstate forward in time are estimated. However, for many complex systems it is\npractically impossible to determine the equations or interactions governing the\nunderlying dynamics. In these settings, parametric ODE model cannot be\nformulated. Here, we overcome this issue by introducing a novel paradigm of\nnonparametric ODE modelling that can learn the underlying dynamics of arbitrary\ncontinuous-time systems without prior knowledge. We propose to learn\nnon-linear, unknown differential functions from state observations using\nGaussian process vector fields within the exact ODE formalism. We demonstrate\nthe model's capabilities to infer dynamics from sparse data and to simulate the\nsystem forward into future.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 15:13:27 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Heinonen", "Markus", ""], ["Yildiz", "Cagatay", ""], ["Mannerstr\u00f6m", "Henrik", ""], ["Intosalmi", "Jukka", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "1803.04304", "submitter": "Ankit Singh Rawat", "authors": "Arya Mazumdar, Ankit Singh Rawat", "title": "Representation Learning and Recovery in the ReLU Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rectified linear units, or ReLUs, have become the preferred activation\nfunction for artificial neural networks. In this paper we consider two basic\nlearning problems assuming that the underlying data follow a generative model\nbased on a ReLU-network -- a neural network with ReLU activations. As a\nprimarily theoretical study, we limit ourselves to a single-layer network. The\nfirst problem we study corresponds to dictionary-learning in the presence of\nnonlinearity (modeled by the ReLU functions). Given a set of observation\nvectors $\\mathbf{y}^i \\in \\mathbb{R}^d, i =1, 2, \\dots , n$, we aim to recover\n$d\\times k$ matrix $A$ and the latent vectors $\\{\\mathbf{c}^i\\} \\subset\n\\mathbb{R}^k$ under the model $\\mathbf{y}^i = \\mathrm{ReLU}(A\\mathbf{c}^i\n+\\mathbf{b})$, where $\\mathbf{b}\\in \\mathbb{R}^d$ is a random bias. We show\nthat it is possible to recover the column space of $A$ within an error of\n$O(d)$ (in Frobenius norm) under certain conditions on the probability\ndistribution of $\\mathbf{b}$.\n  The second problem we consider is that of robust recovery of the signal in\nthe presence of outliers, i.e., large but sparse noise. In this setting we are\ninterested in recovering the latent vector $\\mathbf{c}$ from its noisy\nnonlinear sketches of the form $\\mathbf{v} = \\mathrm{ReLU}(A\\mathbf{c}) +\n\\mathbf{e}+\\mathbf{w}$, where $\\mathbf{e} \\in \\mathbb{R}^d$ denotes the\noutliers with sparsity $s$ and $\\mathbf{w} \\in \\mathbb{R}^d$ denote the dense\nbut small noise. This line of work has recently been studied (Soltanolkotabi,\n2017) without the presence of outliers. For this problem, we show that a\ngeneralized LASSO algorithm is able to recover the signal $\\mathbf{c} \\in\n\\mathbb{R}^k$ within an $\\ell_2$ error of $O(\\sqrt{\\frac{(k+s)\\log d}{d}})$\nwhen $A$ is a random Gaussian matrix.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 15:17:14 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Mazumdar", "Arya", ""], ["Rawat", "Ankit Singh", ""]]}, {"id": "1803.04347", "submitter": "Charles Jekel", "authors": "Charles F Jekel, Raphael T. Haftka", "title": "Classifying Online Dating Profiles on Tinder using FaceNet Facial\n  Embeddings", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.SI eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A method to produce personalized classification models to automatically\nreview online dating profiles on Tinder is proposed, based on the user's\nhistorical preference. The method takes advantage of a FaceNet facial\nclassification model to extract features which may be related to facial\nattractiveness. The embeddings from a FaceNet model were used as the features\nto describe an individual's face. A user reviewed 8,545 online dating profiles.\nFor each reviewed online dating profile, a feature set was constructed from the\nprofile images which contained just one face. Two approaches are presented to\ngo from the set of features for each face, to a set of profile features. A\nsimple logistic regression trained on the embeddings from just 20 profiles\ncould obtain a 65% validation accuracy. A point of diminishing marginal returns\nwas identified to occur around 80 profiles, at which the model accuracy of 73%\nwould only improve marginally after reviewing a significant number of\nadditional profiles.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 16:14:24 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Jekel", "Charles F", ""], ["Haftka", "Raphael T.", ""]]}, {"id": "1803.04364", "submitter": "Sheraz Khan", "authors": "Sheraz Khan, Javeria Hashmi, Fahimeh Mamashli, Konstantinos Michmizos,\n  Manfred Kitzbichler, Hari Bharadwaj, Yousra Bekhti, Santosh Ganesan, Keri A\n  Garel, Susan Whitfield-Gabrieli, Randy Gollub, Jian Kong, Lucia M Vaina,\n  Kunjan Rana, Steven Stufflebeam, Matti Hamalainen, and Tal Kenet", "title": "Maturation Trajectories of Cortical Resting-State Networks Depend on the\n  Mediating Frequency Band", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.DM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The functional significance of resting state networks and their abnormal\nmanifestations in psychiatric disorders are firmly established, as is the\nimportance of the cortical rhythms in mediating these networks. Resting state\nnetworks are known to undergo substantial reorganization from childhood to\nadulthood, but whether distinct cortical rhythms, which are generated by\nseparable neural mechanisms and are often manifested abnormally in psychiatric\nconditions, mediate maturation differentially, remains unknown. Using\nmagnetoencephalography (MEG) to map frequency band specific maturation of\nresting state networks from age 7 to 29 in 162 participants (31 independent),\nwe found significant changes with age in networks mediated by the beta\n(13-30Hz) and gamma (31-80Hz) bands. More specifically, gamma band mediated\nnetworks followed an expected asymptotic trajectory, but beta band mediated\nnetworks followed a linear trajectory. Network integration increased with age\nin gamma band mediated networks, while local segregation increased with age in\nbeta band mediated networks. Spatially, the hubs that changed in importance\nwith age in the beta band mediated networks had relatively little overlap with\nthose that showed the greatest changes in the gamma band mediated networks.\nThese findings are relevant for our understanding of the neural mechanisms of\ncortical maturation, in both typical and atypical development.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 01:04:40 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Khan", "Sheraz", ""], ["Hashmi", "Javeria", ""], ["Mamashli", "Fahimeh", ""], ["Michmizos", "Konstantinos", ""], ["Kitzbichler", "Manfred", ""], ["Bharadwaj", "Hari", ""], ["Bekhti", "Yousra", ""], ["Ganesan", "Santosh", ""], ["Garel", "Keri A", ""], ["Whitfield-Gabrieli", "Susan", ""], ["Gollub", "Randy", ""], ["Kong", "Jian", ""], ["Vaina", "Lucia M", ""], ["Rana", "Kunjan", ""], ["Stufflebeam", "Steven", ""], ["Hamalainen", "Matti", ""], ["Kenet", "Tal", ""]]}, {"id": "1803.04371", "submitter": "Junhong Lin", "authors": "Junhong Lin and Volkan Cevher", "title": "Optimal Rates of Sketched-regularized Algorithms for Least-Squares\n  Regression over Hilbert Spaces", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate regularized algorithms combining with projection for\nleast-squares regression problem over a Hilbert space, covering nonparametric\nregression over a reproducing kernel Hilbert space. We prove convergence\nresults with respect to variants of norms, under a capacity assumption on the\nhypothesis space and a regularity condition on the target function. As a\nresult, we obtain optimal rates for regularized algorithms with randomized\nsketches, provided that the sketch dimension is proportional to the effective\ndimension up to a logarithmic factor. As a byproduct, we obtain similar results\nfor Nystr\\\"{o}m regularized algorithms. Our results are the first ones with\noptimal, distribution-dependent rates that do not have any saturation effect\nfor sketched/Nystr\\\"{o}m regularized algorithms, considering both the\nattainable and non-attainable cases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 16:57:48 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 15:14:52 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Lin", "Junhong", ""], ["Cevher", "Volkan", ""]]}, {"id": "1803.04383", "submitter": "Lydia T. Liu", "authors": "Lydia T. Liu, Sarah Dean, Esther Rolf, Max Simchowitz, Moritz Hardt", "title": "Delayed Impact of Fair Machine Learning", "comments": "37 pages, 6 figures", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:3150-3158, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness in machine learning has predominantly been studied in static\nclassification settings without concern for how decisions change the underlying\npopulation over time. Conventional wisdom suggests that fairness criteria\npromote the long-term well-being of those groups they aim to protect.\n  We study how static fairness criteria interact with temporal indicators of\nwell-being, such as long-term improvement, stagnation, and decline in a\nvariable of interest. We demonstrate that even in a one-step feedback model,\ncommon fairness criteria in general do not promote improvement over time, and\nmay in fact cause harm in cases where an unconstrained objective would not.\n  We completely characterize the delayed impact of three standard criteria,\ncontrasting the regimes in which these exhibit qualitatively different\nbehavior. In addition, we find that a natural form of measurement error\nbroadens the regime in which fairness criteria perform favorably.\n  Our results highlight the importance of measurement and temporal modeling in\nthe evaluation of fairness criteria, suggesting a range of new challenges and\ntrade-offs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 17:20:56 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 20:34:16 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Liu", "Lydia T.", ""], ["Dean", "Sarah", ""], ["Rolf", "Esther", ""], ["Simchowitz", "Max", ""], ["Hardt", "Moritz", ""]]}, {"id": "1803.04386", "submitter": "Paul Vicol", "authors": "Yeming Wen, Paul Vicol, Jimmy Ba, Dustin Tran, Roger Grosse", "title": "Flipout: Efficient Pseudo-Independent Weight Perturbations on\n  Mini-Batches", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic neural net weights are used in a variety of contexts, including\nregularization, Bayesian neural nets, exploration in reinforcement learning,\nand evolution strategies. Unfortunately, due to the large number of weights,\nall the examples in a mini-batch typically share the same weight perturbation,\nthereby limiting the variance reduction effect of large mini-batches. We\nintroduce flipout, an efficient method for decorrelating the gradients within a\nmini-batch by implicitly sampling pseudo-independent weight perturbations for\neach example. Empirically, flipout achieves the ideal linear variance reduction\nfor fully connected networks, convolutional networks, and RNNs. We find\nsignificant speedups in training neural networks with multiplicative Gaussian\nperturbations. We show that flipout is effective at regularizing LSTMs, and\noutperforms previous methods. Flipout also enables us to vectorize evolution\nstrategies: in our experiments, a single GPU with flipout can handle the same\nthroughput as at least 40 CPU cores using existing methods, equivalent to a\nfactor-of-4 cost reduction on Amazon Web Services.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 17:25:21 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 17:56:10 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Wen", "Yeming", ""], ["Vicol", "Paul", ""], ["Ba", "Jimmy", ""], ["Tran", "Dustin", ""], ["Grosse", "Roger", ""]]}, {"id": "1803.04431", "submitter": "Zilong Tan", "authors": "Zilong Tan, Kimberly Roche, Xiang Zhou, Sayan Mukherjee", "title": "Scalable Algorithms for Learning High-Dimensional Linear Mixed Models", "comments": null, "journal-ref": "Proceedings of the Thirty Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI), 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear mixed models (LMMs) are used extensively to model dependecies of\nobservations in linear regression and are used extensively in many application\nareas. Parameter estimation for LMMs can be computationally prohibitive on big\ndata. State-of-the-art learning algorithms require computational complexity\nwhich depends at least linearly on the dimension $p$ of the covariates, and\noften use heuristics that do not offer theoretical guarantees. We present\nscalable algorithms for learning high-dimensional LMMs with sublinear\ncomputational complexity dependence on $p$. Key to our approach are novel dual\nestimators which use only kernel functions of the data, and fast computational\ntechniques based on the subsampled randomized Hadamard transform. We provide\ntheoretical guarantees for our learning algorithms, demonstrating the\nrobustness of parameter estimation. Finally, we complement the theory with\nexperiments on large synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 18:07:40 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Tan", "Zilong", ""], ["Roche", "Kimberly", ""], ["Zhou", "Xiang", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1803.04464", "submitter": "Adel Javanmard", "authors": "Adel Javanmard and Hamid Javadi", "title": "False Discovery Rate Control via Debiased Lasso", "comments": "accepted for publication in the Electronic Journal of statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of variable selection in high-dimensional statistical\nmodels where the goal is to report a set of variables, out of many predictors\n$X_1, \\dotsc, X_p$, that are relevant to a response of interest. For linear\nhigh-dimensional model, where the number of parameters exceeds the number of\nsamples $(p>n)$, we propose a procedure for variables selection and prove that\nit controls the \"directional\" false discovery rate (FDR) below a pre-assigned\nsignificance level $q\\in [0,1]$. We further analyze the statistical power of\nour framework and show that for designs with subgaussian rows and a common\nprecision matrix $\\Omega\\in\\mathbb{R}^{p\\times p}$, if the minimum nonzero\nparameter $\\theta_{\\min}$ satisfies $$\\sqrt{n} \\theta_{\\min} - \\sigma\n\\sqrt{2(\\max_{i\\in [p]}\\Omega_{ii})\\log\\left(\\frac{2p}{qs_0}\\right)} \\to\n\\infty\\,,$$ then this procedure achieves asymptotic power one. Our framework is\nbuilt upon the debiasing approach and assumes the standard condition $s_0 =\no(\\sqrt{n}/(\\log p)^2)$, where $s_0$ indicates the number of true positives\namong the $p$ features. Notably, this framework achieves exact directional FDR\ncontrol without any assumption on the amplitude of unknown regression\nparameters, and does not require any knowledge of the distribution of\ncovariates or the noise level. We test our method in synthetic and real data\nexperiments to assess its performance and to corroborate our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:03:33 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 06:14:48 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Javanmard", "Adel", ""], ["Javadi", "Hamid", ""]]}, {"id": "1803.04475", "submitter": "Enrico Camporeale", "authors": "Enrico Camporeale", "title": "Accuracy-Reliability Cost Function for Empirical Variance Estimation", "comments": "under review for ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the problem of assigning uncertainties to\nsingle-point predictions. We introduce a cost function that encodes the\ntrade-off between accuracy and reliability in probabilistic forecast. We derive\nanalytic formula for the case of forecasts of continuous scalar variables\nexpressed in terms of Gaussian distributions. The Accuracy-Reliability cost\nfunction can be used to empirically estimate the variance in heteroskedastic\nregression problems (input dependent noise), by solving a two-objective\noptimization problem. The simple philosophy behind this strategy is that\npredictions based on the estimated variances should be both accurate and\nreliable (i.e. statistical consistent with observations). We show several\nexamples with synthetic data, where the underlying hidden noise function can be\naccurately recovered, both in one and multi-dimensional problems. The practical\nimplementation of the method has been done using a Neural Network and, in the\none-dimensional case, with a simple polynomial fit.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:24:37 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Camporeale", "Enrico", ""]]}, {"id": "1803.04478", "submitter": "David Lattanzi", "authors": "Achyuthan Jootoo, David Lattanzi", "title": "Bridge type classification: supervised learning on a modified NBI\n  dataset", "comments": "Preprint of paper published in ASCE Journal of Computing\n  (https://ascelibrary.org/doi/full/10.1061/(ASCE)CP.1943-5487.0000712). 6\n  figures and 8 tables, provided at end of document", "journal-ref": "Journal of Computing in Civil Engineering 31.6 (2017): 04017063", "doi": "10.1061/(ASCE)CP.1943-5487.0000712", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key phase in the bridge design process is the selection of the structural\nsystem. Due to budget and time constraints, engineers typically rely on\nengineering judgment and prior experience when selecting a structural system,\noften considering a limited range of design alternatives. The objective of this\nstudy was to explore the suitability of supervised machine learning as a\npreliminary design aid that provides guidance to engineers with regards to the\nstatistically optimal bridge type to choose, ultimately improving the\nlikelihood of optimized design, design standardization, and reduced maintenance\ncosts. In order to devise this supervised learning system, data for over\n600,000 bridges from the National Bridge Inventory database were analyzed. Key\nattributes for determining the bridge structure type were identified through\nthree feature selection techniques. Potentially useful attributes like seismic\nintensity and historic data on the cost of materials (steel and concrete) were\nthen added from the US Geological Survey (USGS) database and Engineering News\nRecord. Decision tree, Bayes network and Support Vector Machines were used for\npredicting the bridge design type. Due to state-to-state variations in material\navailability, material costs, and design codes, supervised learning models\nbased on the complete data set did not yield favorable results. Supervised\nlearning models were then trained and tested using 10-fold cross validation on\ndata for each state. Inclusion of seismic data improved the model performance\nnoticeably. The data was then resampled to reduce the bias of the models\ntowards more common design types, and the supervised learning models thus\nconstructed showed further improvements in performance. The average recall and\nprecision for the state models was 88.6% and 88.0% using Decision Trees, 84.0%\nand 83.7% using Bayesian Networks, and 80.8% and 75.6% using SVM.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 16:33:30 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Jootoo", "Achyuthan", ""], ["Lattanzi", "David", ""]]}, {"id": "1803.04479", "submitter": "Evan N. Feinberg", "authors": "Evan N. Feinberg, Amir Barati Farimani, Rajendra Uprety, Amanda\n  Hunkele, Gavril W. Pasternak, Susruta Majumdar, and Vijay S. Pande", "title": "Machine Learning Harnesses Molecular Dynamics to Discover New $\\mu$\n  Opioid Chemotypes", "comments": "28 pages, machine learning, computational biology, GPCRs, molecular\n  dynamics, molecular docking, molecular simulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational chemists typically assay drug candidates by virtually screening\ncompounds against crystal structures of a protein despite the fact that some\ntargets, like the $\\mu$ Opioid Receptor and other members of the GPCR family,\ntraverse many non-crystallographic states. We discover new conformational\nstates of $\\mu OR$ with molecular dynamics simulation and then machine learn\nligand-structure relationships to predict opioid ligand function. These\nartificial intelligence models identified a novel $\\mu$ opioid chemotype.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:32:21 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Feinberg", "Evan N.", ""], ["Farimani", "Amir Barati", ""], ["Uprety", "Rajendra", ""], ["Hunkele", "Amanda", ""], ["Pasternak", "Gavril W.", ""], ["Majumdar", "Susruta", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1803.04489", "submitter": "Sean Billings", "authors": "Sean Billings", "title": "Probabilistic and Regularized Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the recently proposed Graph Convolutional Network\narchitecture proposed in (Kipf & Welling, 2016) The key points of their work is\nsummarized and their results are reproduced. Graph regularization and\nalternative graph convolution approaches are explored. I find that explicit\ngraph regularization was correctly rejected by (Kipf & Welling, 2016). I\nattempt to improve the performance of GCN by approximating a k-step transition\nmatrix in place of the normalized graph laplacian, but I fail to find positive\nresults. Nonetheless, the performance of several configurations of this GCN\nvariation is shown for the Cora, Citeseer, and Pubmed datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:47:16 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Billings", "Sean", ""]]}, {"id": "1803.04494", "submitter": "Sean Billings", "authors": "Sean Billings", "title": "Gradient Augmented Information Retrieval with Autoencoders and Semantic\n  Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will explore the use of autoencoders for semantic hashing in the\ncontext of Information Retrieval. This paper will summarize how to efficiently\ntrain an autoencoder in order to create meaningful and low-dimensional\nencodings of data. This paper will demonstrate how computing and storing the\nclosest encodings to an input query can help speed up search time and improve\nthe quality of our search results. The novel contributions of this paper\ninvolve using the representation of the data learned by an auto-encoder in\norder to augment our search query in various ways. I present and evaluate the\nnew gradient search augmentation (GSA) approach, as well as the more well-known\npseudo-relevance-feedback (PRF) adjustment. I find that GSA helps to improve\nthe performance of the TF-IDF based information retrieval system, and PRF\ncombined with GSA works best overall for the systems compared in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:49:30 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Billings", "Sean", ""]]}, {"id": "1803.04497", "submitter": "Onur Ozdemir", "authors": "Jacob A. Harer, Louis Y. Kim, Rebecca L. Russell, Onur Ozdemir,\n  Leonard R. Kosta, Akshay Rangamani, Lei H. Hamilton, Gabriel I. Centeno,\n  Jonathan R. Key, Paul M. Ellingwood, Erik Antelman, Alan Mackay, Marc W.\n  McConley, Jeffrey M. Opper, Peter Chin, Tomo Lazovich", "title": "Automated software vulnerability detection with machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thousands of security vulnerabilities are discovered in production software\neach year, either reported publicly to the Common Vulnerabilities and Exposures\ndatabase or discovered internally in proprietary code. Vulnerabilities often\nmanifest themselves in subtle ways that are not obvious to code reviewers or\nthe developers themselves. With the wealth of open source code available for\nanalysis, there is an opportunity to learn the patterns of bugs that can lead\nto security vulnerabilities directly from data. In this paper, we present a\ndata-driven approach to vulnerability detection using machine learning,\nspecifically applied to C and C++ programs. We first compile a large dataset of\nhundreds of thousands of open-source functions labeled with the outputs of a\nstatic analyzer. We then compare methods applied directly to source code with\nmethods applied to artifacts extracted from the build process, finding that\nsource-based models perform better. We also compare the application of deep\nneural network models with more traditional models such as random forests and\nfind the best performance comes from combining features learned by deep models\nwith tree-based models. Ultimately, our highest performing model achieves an\narea under the precision-recall curve of 0.49 and an area under the ROC curve\nof 0.87.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 13:00:05 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 13:27:12 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Harer", "Jacob A.", ""], ["Kim", "Louis Y.", ""], ["Russell", "Rebecca L.", ""], ["Ozdemir", "Onur", ""], ["Kosta", "Leonard R.", ""], ["Rangamani", "Akshay", ""], ["Hamilton", "Lei H.", ""], ["Centeno", "Gabriel I.", ""], ["Key", "Jonathan R.", ""], ["Ellingwood", "Paul M.", ""], ["Antelman", "Erik", ""], ["Mackay", "Alan", ""], ["McConley", "Marc W.", ""], ["Opper", "Jeffrey M.", ""], ["Chin", "Peter", ""], ["Lazovich", "Tomo", ""]]}, {"id": "1803.04547", "submitter": "Zhixin Zhou", "authors": "Zhixin Zhou and Arash A. Amini", "title": "Analysis of spectral clustering algorithms for community detection: the\n  general bipartite setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider spectral clustering algorithms for community detection under a\ngeneral bipartite stochastic block model (SBM). A modern spectral clustering\nalgorithm consists of three steps: (1) regularization of an appropriate\nadjacency or Laplacian matrix (2) a form of spectral truncation and (3) a\nk-means type algorithm in the reduced spectral domain. We focus on the\nadjacency-based spectral clustering and for the first step, propose a new\ndata-driven regularization that can restore the concentration of the adjacency\nmatrix even for the sparse networks. This result is based on recent work on\nregularization of random binary matrices, but avoids using unknown population\nlevel parameters, and instead estimates the necessary quantities from the data.\nWe also propose and study a novel variation of the spectral truncation step and\nshow how this variation changes the nature of the misclassification rate in a\ngeneral SBM. We then show how the consistency results can be extended to models\nbeyond SBMs, such as inhomogeneous random graph models with approximate\nclusters, including a graphon clustering problem, as well as general\nsub-Gaussian biclustering. A theme of the paper is providing a better\nunderstanding of the analysis of spectral methods for community detection and\nestablishing consistency results, under fairly general clustering models and\nfor a wide regime of degree growths, including sparse cases where the average\nexpected degree grows arbitrarily slowly.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 21:50:58 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 23:24:58 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zhou", "Zhixin", ""], ["Amini", "Arash A.", ""]]}, {"id": "1803.04566", "submitter": "Nicholas Waytowich", "authors": "Nicholas R. Waytowich, Vernon Lawhern, Javier O. Garcia, Jennifer\n  Cummings, Josef Faller, Paul Sajda, Jean M. Vettel", "title": "Compact Convolutional Neural Networks for Classification of Asynchronous\n  Steady-state Visual Evoked Potentials", "comments": "Accepted for publication at the Journal of Neural Engineering", "journal-ref": null, "doi": "10.1088/1741-2552/aae5d8", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steady-State Visual Evoked Potentials (SSVEPs) are neural oscillations from\nthe parietal and occipital regions of the brain that are evoked from flickering\nvisual stimuli. SSVEPs are robust signals measurable in the\nelectroencephalogram (EEG) and are commonly used in brain-computer interfaces\n(BCIs). However, methods for high-accuracy decoding of SSVEPs usually require\nhand-crafted approaches that leverage domain-specific knowledge of the stimulus\nsignals, such as specific temporal frequencies in the visual stimuli and their\nrelative spatial arrangement. When this knowledge is unavailable, such as when\nSSVEP signals are acquired asynchronously, such approaches tend to fail. In\nthis paper, we show how a compact convolutional neural network (Compact-CNN),\nwhich only requires raw EEG signals for automatic feature extraction, can be\nused to decode signals from a 12-class SSVEP dataset without the need for any\ndomain-specific knowledge or calibration data. We report across subject mean\naccuracy of approximately 80% (chance being 8.3%) and show this is\nsubstantially better than current state-of-the-art hand-crafted approaches\nusing canonical correlation analysis (CCA) and Combined-CCA. Furthermore, we\nanalyze our Compact-CNN to examine the underlying feature representation,\ndiscovering that the deep learner extracts additional phase and amplitude\nrelated features associated with the structure of the dataset. We discuss how\nour Compact-CNN shows promise for BCI applications that allow users to freely\ngaze/attend to any stimulus at any time (e.g., asynchronous BCI) as well as\nprovides a method for analyzing SSVEP signals in a way that might augment our\nunderstanding about the basic processing in the visual cortex.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 23:03:44 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 16:53:26 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Waytowich", "Nicholas R.", ""], ["Lawhern", "Vernon", ""], ["Garcia", "Javier O.", ""], ["Cummings", "Jennifer", ""], ["Faller", "Josef", ""], ["Sajda", "Paul", ""], ["Vettel", "Jean M.", ""]]}, {"id": "1803.04572", "submitter": "Ardavan Afshar", "authors": "Ardavan Afshar, Ioakeim Perros, Evangelos E. Papalexakis, Elizabeth\n  Searles, Joyce Ho, Jimeng Sun", "title": "COPA: Constrained PARAFAC2 for Sparse & Large Datasets", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PARAFAC2 has demonstrated success in modeling irregular tensors, where the\ntensor dimensions vary across one of the modes. An example scenario is modeling\ntreatments across a set of patients with the varying number of medical\nencounters over time. Despite recent improvements on unconstrained PARAFAC2,\nits model factors are usually dense and sensitive to noise which limits their\ninterpretability. As a result, the following open challenges remain: a) various\nmodeling constraints, such as temporal smoothness, sparsity and non-negativity,\nare needed to be imposed for interpretable temporal modeling and b) a scalable\napproach is required to support those constraints efficiently for large\ndatasets. To tackle these challenges, we propose a {\\it CO}nstrained {\\it\nPA}RAFAC2 (COPA) method, which carefully incorporates optimization constraints\nsuch as temporal smoothness, sparsity, and non-negativity in the resulting\nfactors. To efficiently support all those constraints, COPA adopts a hybrid\noptimization framework using alternating optimization and alternating direction\nmethod of multiplier (AO-ADMM). As evaluated on large electronic health record\n(EHR) datasets with hundreds of thousands of patients, COPA achieves\nsignificant speedups (up to 36 times faster) over prior PARAFAC2 approaches\nthat only attempt to handle a subset of the constraints that COPA enables.\nOverall, our method outperforms all the baselines attempting to handle a subset\nof the constraints in terms of speed, while achieving the same level of\naccuracy. Through a case study on temporal phenotyping of medically complex\nchildren, we demonstrate how the constraints imposed by COPA reveal concise\nphenotypes and meaningful temporal profiles of patients. The clinical\ninterpretation of both the phenotypes and the temporal profiles was confirmed\nby a medical expert.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 23:27:06 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 19:52:28 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Afshar", "Ardavan", ""], ["Perros", "Ioakeim", ""], ["Papalexakis", "Evangelos E.", ""], ["Searles", "Elizabeth", ""], ["Ho", "Joyce", ""], ["Sun", "Jimeng", ""]]}, {"id": "1803.04585", "submitter": "David Manheim", "authors": "David Manheim and Scott Garrabrant", "title": "Categorizing Variants of Goodhart's Law", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-fin.GN stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There are several distinct failure modes for overoptimization of systems on\nthe basis of metrics. This occurs when a metric which can be used to improve a\nsystem is used to an extent that further optimization is ineffective or\nharmful, and is sometimes termed Goodhart's Law. This class of failure is often\npoorly understood, partly because terminology for discussing them is ambiguous,\nand partly because discussion using this ambiguous terminology ignores\ndistinctions between different failure modes of this general type. This paper\nexpands on an earlier discussion by Garrabrant, which notes there are \"(at\nleast) four different mechanisms\" that relate to Goodhart's Law. This paper is\nintended to explore these mechanisms further, and specify more clearly how they\noccur. This discussion should be helpful in better understanding these types of\nfailures in economic regulation, in public policy, in machine learning, and in\nArtificial Intelligence alignment. The importance of Goodhart effects depends\non the amount of power directed towards optimizing the proxy, and so the\nincreased optimization power offered by artificial intelligence makes it\nespecially critical for that field.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 01:15:39 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 14:28:19 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 13:39:19 GMT"}, {"version": "v4", "created": "Sun, 24 Feb 2019 08:12:46 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Manheim", "David", ""], ["Garrabrant", "Scott", ""]]}, {"id": "1803.04654", "submitter": "Kar Wai Lim", "authors": "Kar Wai Lim, Young Lee, Leif Hanlen, Hongbiao Zhao", "title": "Simulation and Calibration of a Fully Bayesian Marked Multidimensional\n  Hawkes Process with Dissimilar Decays", "comments": "24 pages, long version of ACML paper with supplementary material", "journal-ref": "In Proceedings of the 6th Asian Conference on Machine Learning\n  (ACML), pp. 238-253. 2016", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simulation method for multidimensional Hawkes processes based on\nsuperposition theory of point processes. This formulation allows us to design\nefficient simulations for Hawkes processes with differing exponentially\ndecaying intensities. We demonstrate that inter-arrival times can be decomposed\ninto simpler auxiliary variables that can be sampled directly, giving exact\nsimulation with no approximation. We establish that the auxiliary variables\nprovides information on the parent process for each event time. The algorithm\ncorrectness is shown by verifying the simulated intensities with their\ntheoretical moments. A modular inference procedure consisting of Gibbs samplers\nthrough the auxiliary variable augmentation and adaptive rejection sampling is\npresented. Finally, we compare our proposed simulation method against existing\nmethods, and find significant improvement in terms of algorithm speed. Our\ninference algorithm is used to discover the strengths of mutually excitations\nin real dark networks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 06:44:56 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Lim", "Kar Wai", ""], ["Lee", "Young", ""], ["Hanlen", "Leif", ""], ["Zhao", "Hongbiao", ""]]}, {"id": "1803.04663", "submitter": "Tomoya Sakai", "authors": "Masayoshi Hayashi, Tomoya Sakai, Masashi Sugiyama", "title": "Binary Matrix Completion Using Unobserved Entries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matrix completion problem, which aims to recover a complete matrix from its\npartial observations, is one of the important problems in the machine learning\nfield and has been studied actively. However, there is a discrepancy between\nthe mainstream problem setting, which assumes continuous-valued observations,\nand some practical applications such as recommendation systems and SNS link\npredictions where observations take discrete or even binary values. To cope\nwith this problem, Davenport et al. (2014) proposed a binary matrix completion\n(BMC) problem, where observations are quantized into binary values. Hsieh et\nal. (2015) proposed a PU (Positive and Unlabeled) matrix completion problem,\nwhich is an extension of the BMC problem. This problem targets the setting\nwhere we cannot observe negative values, such as SNS link predictions. In the\nconstruction of their method for this setting, they introduced a methodology of\nthe classification problem, regarding each matrix entry as a sample. Their\nrisk, which defines losses over unobserved entries as well, indicates the\npossibility of the use of unobserved entries. In this paper, motivated by a\nsemi-supervised classification method recently proposed by Sakai et al. (2017),\nwe develop a method for the BMC problem which can use all of positive,\nnegative, and unobserved entries, by combining the risks of Davenport et al.\n(2014) and Hsieh et al. (2015). To the best of our knowledge, this is the first\nBMC method which exploits all kinds of matrix entries. We experimentally show\nthat an appropriate mixture of risks improves the performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 07:26:30 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Hayashi", "Masayoshi", ""], ["Sakai", "Tomoya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1803.04665", "submitter": "Emilie Kaufmann", "authors": "Maryam Aziz, Jesse Anderton, Emilie Kaufmann (SEQUEL, CNRS, CRIStAL),\n  Javed Aslam", "title": "Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of near-optimal arm identification in the fixed\nconfidence setting of the infinitely armed bandit problem when nothing is known\nabout the arm reservoir distribution. We (1) introduce a PAC-like framework\nwithin which to derive and cast results; (2) derive a sample complexity lower\nbound for near-optimal arm identification; (3) propose an algorithm that\nidentifies a nearly-optimal arm with high probability and derive an upper bound\non its sample complexity which is within a log factor of our lower bound; and\n(4) discuss whether our log^2(1/delta) dependence is inescapable for\n\"two-phase\" (select arms first, identify the best later) algorithms in the\ninfinite setting. This work permits the application of bandit models to a\nbroader class of problems where fewer assumptions hold.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 07:36:31 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Aziz", "Maryam", "", "SEQUEL, CNRS, CRIStAL"], ["Anderton", "Jesse", "", "SEQUEL, CNRS, CRIStAL"], ["Kaufmann", "Emilie", "", "SEQUEL, CNRS, CRIStAL"], ["Aslam", "Javed", ""]]}, {"id": "1803.04674", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Avinatan Hasidim, Haim Kaplan, Yishay Mansour", "title": "Hierarchical Reinforcement Learning: Approximating Optimal Discounted\n  TSP Using Local Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide theoretical guarantees for reward decomposition in\ndeterministic MDPs. Reward decomposition is a special case of Hierarchical\nReinforcement Learning, that allows one to learn many policies in parallel and\ncombine them into a composite solution. Our approach builds on mapping this\nproblem into a Reward Discounted Traveling Salesman Problem, and then deriving\napproximate solutions for it. In particular, we focus on approximate solutions\nthat are local, i.e., solutions that only observe information about the current\nstate. Local policies are easy to implement and do not require substantial\ncomputational resources as they do not perform planning. While local\ndeterministic policies, like Nearest Neighbor, are being used in practice for\nhierarchical reinforcement learning, we propose three stochastic policies that\nguarantee better performance than any deterministic policy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 08:13:11 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zahavy", "Tom", ""], ["Hasidim", "Avinatan", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1803.04765", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot and Patrick McDaniel", "title": "Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) enable innovative applications of machine\nlearning like image recognition, machine translation, or malware detection.\nHowever, deep learning is often criticized for its lack of robustness in\nadversarial settings (e.g., vulnerability to adversarial inputs) and general\ninability to rationalize its predictions. In this work, we exploit the\nstructure of deep learning to enable new learning-based inference and decision\nstrategies that achieve desirable properties such as robustness and\ninterpretability. We take a first step in this direction and introduce the Deep\nk-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest\nneighbors algorithm with representations of the data learned by each layer of\nthe DNN: a test input is compared to its neighboring training points according\nto the distance that separates them in the representations. We show the labels\nof these neighboring points afford confidence estimates for inputs outside the\nmodel's training manifold, including on malicious inputs like adversarial\nexamples--and therein provides protections against inputs that are outside the\nmodels understanding. This is because the nearest neighbors can be used to\nestimate the nonconformity of, i.e., the lack of support for, a prediction in\nthe training data. The neighbors also constitute human-interpretable\nexplanations of predictions. We evaluate the DkNN algorithm on several\ndatasets, and show the confidence estimates accurately identify inputs outside\nthe model, and that the explanations provided by nearest neighbors are\nintuitive and useful in understanding model failures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 13:02:13 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1803.04779", "submitter": "Jaideep Pathak", "authors": "Jaideep Pathak, Alexander Wikner, Rebeckah Fussell, Sarthak Chandra,\n  Brian Hunt, Michelle Girvan, Edward Ott", "title": "Hybrid Forecasting of Chaotic Processes: Using Machine Learning in\n  Conjunction with a Knowledge-Based Model", "comments": null, "journal-ref": null, "doi": "10.1063/1.5028373", "report-no": null, "categories": "cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model-based approach to forecasting chaotic dynamical systems utilizes\nknowledge of the physical processes governing the dynamics to build an\napproximate mathematical model of the system. In contrast, machine learning\ntechniques have demonstrated promising results for forecasting chaotic systems\npurely from past time series measurements of system state variables (training\ndata), without prior knowledge of the system dynamics. The motivation for this\npaper is the potential of machine learning for filling in the gaps in our\nunderlying mechanistic knowledge that cause widely-used knowledge-based models\nto be inaccurate. Thus we here propose a general method that leverages the\nadvantages of these two approaches by combining a knowledge-based model and a\nmachine learning technique to build a hybrid forecasting scheme. Potential\napplications for such an approach are numerous (e.g., improving weather\nforecasting). We demonstrate and test the utility of this approach using a\nparticular illustrative version of a machine learning known as reservoir\ncomputing, and we apply the resulting hybrid forecaster to a low-dimensional\nchaotic system, as well as to a high-dimensional spatiotemporal chaotic system.\nThese tests yield extremely promising results in that our hybrid technique is\nable to accurately predict for a much longer period of time than either its\nmachine-learning component or its model-based component alone.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 21:02:25 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Pathak", "Jaideep", ""], ["Wikner", "Alexander", ""], ["Fussell", "Rebeckah", ""], ["Chandra", "Sarthak", ""], ["Hunt", "Brian", ""], ["Girvan", "Michelle", ""], ["Ott", "Edward", ""]]}, {"id": "1803.04825", "submitter": "Raphael Hauser A", "authors": "Reka Kovacs, Oktay Gunluk, Raphael Hauser", "title": "Low-Rank Boolean Matrix Approximation by Integer Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank approximations of data matrices are an important dimensionality\nreduction tool in machine learning and regression analysis. We consider the\ncase of categorical variables, where it can be formulated as the problem of\nfinding low-rank approximations to Boolean matrices. In this paper we give what\nis to the best of our knowledge the first integer programming formulation that\nrelies on only polynomially many variables and constraints, we discuss how to\nsolve it computationally and report numerical tests on synthetic and real-world\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:17:00 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Kovacs", "Reka", ""], ["Gunluk", "Oktay", ""], ["Hauser", "Raphael", ""]]}, {"id": "1803.04837", "submitter": "Luchen Liu", "authors": "Luchen Liu, Jianhao Shen, Ming Zhang, Zichang Wang and Jian Tang", "title": "Learning the Joint Representation of Heterogeneous Temporal Events for\n  Clinical Endpoint Prediction", "comments": "8 pages, this paper has been accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of a large amount of electronic health records (EHR)\nprovides huge opportunities to improve health care service by mining these\ndata. One important application is clinical endpoint prediction, which aims to\npredict whether a disease, a symptom or an abnormal lab test will happen in the\nfuture according to patients' history records. This paper develops deep\nlearning techniques for clinical endpoint prediction, which are effective in\nmany practical applications. However, the problem is very challenging since\npatients' history records contain multiple heterogeneous temporal events such\nas lab tests, diagnosis, and drug administrations. The visiting patterns of\ndifferent types of events vary significantly, and there exist complex nonlinear\nrelationships between different events. In this paper, we propose a novel model\nfor learning the joint representation of heterogeneous temporal events. The\nmodel adds a new gate to control the visiting rates of different events which\neffectively models the irregular patterns of different events and their\nnonlinear correlations. Experiment results with real-world clinical data on the\ntasks of predicting death and abnormal lab tests prove the effectiveness of our\nproposed approach over competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:32:38 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 21:56:32 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 12:12:48 GMT"}, {"version": "v4", "created": "Sat, 17 Nov 2018 06:20:12 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Liu", "Luchen", ""], ["Shen", "Jianhao", ""], ["Zhang", "Ming", ""], ["Wang", "Zichang", ""], ["Tang", "Jian", ""]]}, {"id": "1803.04848", "submitter": "Esther Derman", "authors": "Esther Derman, Daniel J. Mankowitz, Timothy A. Mann, Shie Mannor", "title": "Soft-Robust Actor-Critic Policy-Gradient", "comments": "UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robust Reinforcement Learning aims to derive optimal behavior that accounts\nfor model uncertainty in dynamical systems. However, previous studies have\nshown that by considering the worst case scenario, robust policies can be\noverly conservative. Our soft-robust framework is an attempt to overcome this\nissue. In this paper, we present a novel Soft-Robust Actor-Critic algorithm\n(SR-AC). It learns an optimal policy with respect to a distribution over an\nuncertainty set and stays robust to model uncertainty but avoids the\nconservativeness of robust strategies. We show the convergence of SR-AC and\ntest the efficiency of our approach on different domains by comparing it\nagainst regular learning methods and their robust formulations.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 09:43:20 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 06:01:45 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Derman", "Esther", ""], ["Mankowitz", "Daniel J.", ""], ["Mann", "Timothy A.", ""], ["Mannor", "Shie", ""]]}, {"id": "1803.04899", "submitter": "Ievgen Redko", "authors": "Ievgen Redko, Nicolas Courty, R\\'emi Flamary, Devis Tuia", "title": "Optimal Transport for Multi-source Domain Adaptation under Target Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to tackle the problem of reducing discrepancies\nbetween multiple domains referred to as multi-source domain adaptation and\nconsider it under the target shift assumption: in all domains we aim to solve a\nclassification problem with the same output classes, but with labels'\nproportions differing across them. This problem, generally ignored in the vast\nmajority papers on domain adaptation papers, is nevertheless critical in\nreal-world applications, and we theoretically show its impact on the adaptation\nsuccess. To address this issue, we design a method based on optimal transport,\na theory that has been successfully used to tackle adaptation problems in\nmachine learning. Our method performs multi-source adaptation and target shift\ncorrection simultaneously by learning the class probabilities of the unlabeled\ntarget sample and the coupling allowing to align two (or more) probability\ndistributions. Experiments on both synthetic and real-world data related to\nsatellite image segmentation task show the superiority of the proposed method\nover the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 15:55:35 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 20:30:02 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 15:38:56 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Redko", "Ievgen", ""], ["Courty", "Nicolas", ""], ["Flamary", "R\u00e9mi", ""], ["Tuia", "Devis", ""]]}, {"id": "1803.04924", "submitter": "Hinnerk Christian Schmidt", "authors": "Christian Schmidt and Lenka Zdeborov\\'a", "title": "Dense Limit of the Dawid-Skene Model for Crowdsourcing and Regions of\n  Sub-optimality of Message Passing Algorithms", "comments": "16 pages, 7 figures", "journal-ref": "J. Phys. A: Math. Theor. 53 124001 (2020)", "doi": "10.1088/1751-8121/ab757f", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is a strategy to categorize data through the contribution of\nmany individuals. A wide range of theoretical and algorithmic contributions are\nbased on the model of Dawid and Skene [1]. Recently it was shown in [2,3] that,\nin certain regimes, belief propagation is asymptotically optimal for data\ngenerated from the Dawid-Skene model. This paper is motivated by this recent\nprogress. We analyze the dense limit of the Dawid-Skene model. It is shown that\nit belongs to a larger class of low-rank matrix estimation problems for which\nit is possible to express the asymptotic, Bayes-optimal, performance in a\nsimple closed form. In the dense limit the mapping to a low-rank matrix\nestimation problem provides an approximate message passing algorithm that\nsolves the problem algorithmically. We identify the regions where the algorithm\nefficiently computes the Bayes-optimal estimates. Our analysis refines the\nresults of [2,3] about optimality of message passing algorithms by\ncharacterizing regions of parameters where these algorithms do not match the\nBayes-optimal performance. We further study numerically the performance of\napproximate message passing, derived in the dense limit, on sparse instances\nand carry out experiments on a real world dataset.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 16:31:37 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 11:46:09 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Schmidt", "Christian", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1803.04926", "submitter": "Sebastian Schulze", "authors": "Sebastian Schulze and Owain Evans", "title": "Active Reinforcement Learning with Monte-Carlo Tree Search", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Reinforcement Learning (ARL) is a twist on RL where the agent observes\nreward information only if it pays a cost. This subtle change makes exploration\nsubstantially more challenging. Powerful principles in RL like optimism,\nThompson sampling, and random exploration do not help with ARL. We relate ARL\nin tabular environments to Bayes-Adaptive MDPs. We provide an ARL algorithm\nusing Monte-Carlo Tree Search that is asymptotically Bayes optimal.\nExperimentally, this algorithm is near-optimal on small Bandit problems and\nMDPs. On larger MDPs it outperforms a Q-learner augmented with specialised\nheuristics for ARL. By analysing exploration behaviour in detail, we uncover\nobstacles to scaling up simulation-based algorithms for ARL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 16:35:25 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 18:44:11 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 16:11:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Schulze", "Sebastian", ""], ["Evans", "Owain", ""]]}, {"id": "1803.04929", "submitter": "Olivier Goudet Dr", "authors": "Diviyan Kalainathan, Olivier Goudet, Isabelle Guyon, David Lopez-Paz,\n  Mich\\`ele Sebag", "title": "Structural Agnostic Modeling: Adversarial Learning of Causal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new causal discovery method, Structural Agnostic Modeling (SAM), is\npresented in this paper. Leveraging both conditional independencies and\ndistributional asymmetries in the data, SAM aims to find the underlying causal\nstructure from observational data. The approach is based on a game between\ndifferent players estimating each variable distribution conditionally to the\nothers as a neural net, and an adversary aimed at discriminating the overall\njoint conditional distribution, and that of the original data. A learning\ncriterion combining distribution estimation, sparsity and acyclicity\nconstraints is used to enforce the end-to-end optimization of the graph\nstructure and parameters through stochastic gradient descent. Besides a\ntheoretical analysis of the approach in the large sample limit, SAM is\nextensively experimentally validated on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 16:40:00 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 17:17:19 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 13:50:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kalainathan", "Diviyan", ""], ["Goudet", "Olivier", ""], ["Guyon", "Isabelle", ""], ["Lopez-Paz", "David", ""], ["Sebag", "Mich\u00e8le", ""]]}, {"id": "1803.04965", "submitter": "Neil Dhir", "authors": "Neil Dhir, Houman Dallali, Mo Rastgaar", "title": "Coregionalised Locomotion Envelopes - A Qualitative Approach", "comments": "5 pages. arXiv admin note: text overlap with arXiv:1106.6251 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  'Sharing of statistical strength' is a phrase often employed in machine\nlearning and signal processing. In sensor networks, for example, missing\nsignals from certain sensors may be predicted by exploiting their correlation\nwith observed signals acquired from other sensors. For humans, our hands move\nsynchronously with our legs, and we can exploit these implicit correlations for\npredicting new poses and for generating new natural-looking walking sequences.\nWe can also go much further and exploit this form of transfer learning, to\ndevelop new control schemas for robust control of rehabilitation robots. In\nthis short paper we introduce coregionalised locomotion envelopes - a method\nfor multi-dimensional manifold regression, on human locomotion variates. Herein\nwe render a qualitative description of this method.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 00:04:40 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Dhir", "Neil", ""], ["Dallali", "Houman", ""], ["Rastgaar", "Mo", ""]]}, {"id": "1803.04967", "submitter": "Aaron Tuor", "authors": "Andy Brown, Aaron Tuor, Brian Hutchinson, Nicole Nichols", "title": "Recurrent Neural Network Attention Mechanisms for Interpretable System\n  Log Anomaly Detection", "comments": "Submitted to the First Workshop On Machine Learning for Computer\n  Systems, ACM HPDC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently demonstrated state-of-the art performance on key\ntasks related to the maintenance of computer systems, such as intrusion\ndetection, denial of service attack detection, hardware and software system\nfailures, and malware detection. In these contexts, model interpretability is\nvital for administrator and analyst to trust and act on the automated analysis\nof machine learning models. Deep learning methods have been criticized as black\nbox oracles which allow limited insight into decision factors. In this work we\nseek to \"bridge the gap\" between the impressive performance of deep learning\nmodels and the need for interpretable model introspection. To this end we\npresent recurrent neural network (RNN) language models augmented with attention\nfor anomaly detection in system logs. Our methods are generally applicable to\nany computer system and logging source.\n  By incorporating attention variants into our RNN language models we create\nopportunities for model introspection and analysis without sacrificing\nstate-of-the art performance.\n  We demonstrate model performance and illustrate model interpretability on an\nintrusion detection task using the Los Alamos National Laboratory (LANL) cyber\nsecurity dataset, reporting upward of 0.99 area under the receiver operator\ncharacteristic curve despite being trained only on a single day's worth of\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 08:09:20 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Brown", "Andy", ""], ["Tuor", "Aaron", ""], ["Hutchinson", "Brian", ""], ["Nichols", "Nicole", ""]]}, {"id": "1803.05011", "submitter": "Yingying Zhu", "authors": "Yingying Zhu, Mert R. Sabuncu", "title": "A Probabilistic Disease Progression Model for Predicting Future Clinical\n  Outcome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of predicting the course of a\nprogressive disease, such as cancer or Alzheimer's. Progressive diseases often\nstart with mild symptoms that might precede a diagnosis, and each patient\nfollows their own trajectory. Patient trajectories exhibit wild variability,\nwhich can be associated with many factors such as genotype, age, or sex. An\nadditional layer of complexity is that, in real life, the amount and type of\ndata available for each patient can differ significantly. For example, for one\npatient we might have no prior history, whereas for another patient we might\nhave detailed clinical assessments obtained at multiple prior time-points. This\npaper presents a probabilistic model that can handle multiple modalities\n(including images and clinical assessments) and variable patient histories with\nirregular timings and missing entries, to predict clinical scores at future\ntime-points. We use a sigmoidal function to model latent disease progression,\nwhich gives rise to clinical observations in our generative model. We\nimplemented an approximate Bayesian inference strategy on the proposed model to\nestimate the parameters on data from a large population of subjects.\nFurthermore, the Bayesian framework enables the model to automatically\nfine-tune its predictions based on historical observations that might be\navailable on the test subject. We applied our method to a longitudinal\nAlzheimer's disease dataset with more than 3000 subjects [23] and present a\ndetailed empirical analysis of prediction performance under different\nscenarios, with comparisons against several benchmarks. We also demonstrate how\nthe proposed model can be interrogated to glean insights about temporal\ndynamics in Alzheimer's disease.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 19:05:08 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Zhu", "Yingying", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1803.05036", "submitter": "Markus Heinonen", "authors": "Pashupati Hegde, Markus Heinonen, Samuel Kaski", "title": "Variational zero-inflated Gaussian processes with sparse kernels", "comments": "10 pages, 8 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-inflated datasets, which have an excess of zero outputs, are commonly\nencountered in problems such as climate or rare event modelling. Conventional\nmachine learning approaches tend to overestimate the non-zeros leading to poor\nperformance. We propose a novel model family of zero-inflated Gaussian\nprocesses (ZiGP) for such zero-inflated datasets, produced by sparse kernels\nthrough learning a latent probit Gaussian process that can zero out kernel rows\nand columns whenever the signal is absent. The ZiGPs are particularly useful\nfor making the powerful Gaussian process networks more interpretable. We\nintroduce sparse GP networks where variable-order latent modelling is achieved\nthrough sparse mixing signals. We derive the non-trivial stochastic variational\ninference tractably for scalable learning of the sparse kernels in both models.\nThe novel output-sparse approach improves both prediction of zero-inflated data\nand interpretability of latent mixing models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 20:34:23 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Hegde", "Pashupati", ""], ["Heinonen", "Markus", ""], ["Kaski", "Samuel", ""]]}, {"id": "1803.05045", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou", "title": "Analysis of Nonautonomous Adversarial Systems", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks are used to generate images but still their\nconvergence properties are not well understood. There have been a few studies\nwho intended to investigate the stability properties of GANs as a dynamical\nsystem. This short writing can be seen in that direction. Among the proposed\nmethods for stabilizing training of GANs, {\\ss}-GAN was the first who proposed\na complete annealing strategy to change high-level conditions of the GAN\nobjective. In this note, we show by a simple example how annealing strategy\nworks in GANs. The theoretical analysis is supported by simple simulations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:06:58 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Mehrjou", "Arash", ""]]}, {"id": "1803.05070", "submitter": "Sugumar Murugesan", "authors": "Ashok Sundaresan, Sugumar Murugesan, Sean Davis, Karthik Kappaganthu,\n  ZhongYi Jin, Divya Jain, Anurag Maunder", "title": "A Multi-Modal Approach to Infer Image Affect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The group affect or emotion in an image of people can be inferred by\nextracting features about both the people in the picture and the overall makeup\nof the scene. The state-of-the-art on this problem investigates a combination\nof facial features, scene extraction and even audio tonality. This paper\ncombines three additional modalities, namely, human pose, text-based tagging\nand CNN extracted features / predictions. To the best of our knowledge, this is\nthe first time all of the modalities were extracted using deep neural networks.\nWe evaluate the performance of our approach against baselines and identify\ninsights throughout this paper.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 23:07:45 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Sundaresan", "Ashok", ""], ["Murugesan", "Sugumar", ""], ["Davis", "Sean", ""], ["Kappaganthu", "Karthik", ""], ["Jin", "ZhongYi", ""], ["Jain", "Divya", ""], ["Maunder", "Anurag", ""]]}, {"id": "1803.05104", "submitter": "Sungsoo Ahn", "authors": "Sungsoo Ahn, Michael Chertkov, Adrian Weller and Jinwoo Shin", "title": "Bucket Renormalization for Approximate Inference", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/ab3218", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models are a key tool in machine learning\napplications. Computing the partition function, i.e., normalizing constant, is\na fundamental task of statistical inference but it is generally computationally\nintractable, leading to extensive study of approximation methods. Iterative\nvariational methods are a popular and successful family of approaches. However,\neven state of the art variational methods can return poor results or fail to\nconverge on difficult instances. In this paper, we instead consider computing\nthe partition function via sequential summation over variables. We develop\nrobust approximate algorithms by combining ideas from mini-bucket elimination\nwith tensor network and renormalization group methods from statistical physics.\nThe resulting \"convergence-free\" methods show good empirical performance on\nboth synthetic and real-world benchmark models, even for difficult instances.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 02:16:54 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 04:46:26 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 17:04:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ahn", "Sungsoo", ""], ["Chertkov", "Michael", ""], ["Weller", "Adrian", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1803.05105", "submitter": "Liangyue Li", "authors": "Muge Li, Liangyue Li, and Feiping Nie", "title": "Ranking with Adaptive Neighbors", "comments": "published at Tsinghua Science and Technology 22(6), 2017", "journal-ref": null, "doi": "10.23919/TST.2017.8195354", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieving the most similar objects in a large-scale database for a given\nquery is a fundamental building block in many application domains, ranging from\nweb searches, visual, cross media, and document retrievals. State-of-the-art\napproaches have mainly focused on capturing the underlying geometry of the data\nmanifolds. Graph-based approaches, in particular, define various diffusion\nprocesses on weighted data graphs. Despite success, these approaches rely on\nfixed-weight graphs, making ranking sensitive to the input affinity matrix. In\nthis study, we propose a new ranking algorithm that simultaneously learns the\ndata affinity matrix and the ranking scores. The proposed optimization\nformulation assigns adaptive neighbors to each point in the data based on the\nlocal connectivity, and the smoothness constraint assigns similar ranking\nscores to similar data points. We develop a novel and efficient algorithm to\nsolve the optimization problem. Evaluations using synthetic and real datasets\nsuggest that the proposed algorithm can outperform the existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 02:23:11 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Li", "Muge", ""], ["Li", "Liangyue", ""], ["Nie", "Feiping", ""]]}, {"id": "1803.05112", "submitter": "Ikko Yamane", "authors": "Ikko Yamane, Florian Yger, Jamal Atif, Masashi Sugiyama", "title": "Uplift Modeling from Separate Labels", "comments": "17 pages, 7 figures, to appear in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling is aimed at estimating the incremental impact of an action on\nan individual's behavior, which is useful in various application domains such\nas targeted marketing (advertisement campaigns) and personalized medicine\n(medical treatments). Conventional methods of uplift modeling require every\ninstance to be jointly equipped with two types of labels: the taken action and\nits outcome. However, obtaining two labels for each instance at the same time\nis difficult or expensive in many real-world problems. In this paper, we\npropose a novel method of uplift modeling that is applicable to a more\npractical setting where only one type of labels is available for each instance.\nWe show a mean squared error bound for the proposed estimator and demonstrate\nits effectiveness through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 02:46:17 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 12:38:52 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 13:38:10 GMT"}, {"version": "v4", "created": "Mon, 1 Oct 2018 08:39:20 GMT"}, {"version": "v5", "created": "Tue, 20 Nov 2018 05:28:46 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Yamane", "Ikko", ""], ["Yger", "Florian", ""], ["Atif", "Jamal", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1803.05130", "submitter": "Kurt Riedel", "authors": "Kurt Riedel", "title": "Signal Processing and Piecewise Convex Estimation", "comments": null, "journal-ref": "ICIAM Proceedings 1993", "doi": null, "report-no": null, "categories": "stat.ME eess.SP math.ST physics.data-an stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems on signal processing reduce to nonparametric function\nestimation. We propose a new methodology, piecewise convex fitting (PCF), and\ngive a two-stage adaptive estimate. In the first stage, the number and location\nof the change points is estimated using strong smoothing. In the second stage,\na constrained smoothing spline fit is performed with the smoothing level chosen\nto minimize the MSE. The imposed constraint is that a single change point\noccurs in a region about each empirical change point of the first-stage\nestimate. This constraint is equivalent to requiring that the third derivative\nof the second-stage estimate has a single sign in a small neighborhood about\neach first-stage change point. We sketch how PCF may be applied to signal\nrecovery, instantaneous frequency estimation, surface reconstruction, image\nsegmentation, spectral estimation and multivariate adaptive regression.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 04:17:21 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Riedel", "Kurt", ""]]}, {"id": "1803.05159", "submitter": "Stanislaw Gorlow", "authors": "Pedro J. Villasana T. and Stanislaw Gorlow and Arvind T. Hariraman", "title": "Multiplicative Updates for Convolutional NMF Under $\\beta$-Divergence", "comments": null, "journal-ref": "Optim Lett (2019)", "doi": "10.1007/s11590-019-01434-9", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we generalize the convolutional NMF by taking the\n$\\beta$-divergence as the contrast function and present the correct\nmultiplicative updates for its factors in closed form. The new updates unify\nthe $\\beta$-NMF and the convolutional NMF. We state why almost all of the\nexisting updates are inexact and approximative w.r.t. the convolutional data\nmodel. We show that our updates are stable and that their convergence\nperformance is consistent across the most common values of $\\beta$.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 08:11:07 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 14:55:30 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["T.", "Pedro J. Villasana", ""], ["Gorlow", "Stanislaw", ""], ["Hariraman", "Arvind T.", ""]]}, {"id": "1803.05288", "submitter": "Elif Vural", "authors": "Mehmet Pilanci, Elif Vural", "title": "Domain Adaptation on Graphs by Learning Aligned Graph Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in semi-supervised learning with graph models is that the\nclass label function varies smoothly on the data graph, resulting in the rather\nstrict prior that the label function has low-frequency content. Meanwhile, in\nmany classification problems, the label function may vary abruptly in certain\ngraph regions, resulting in high-frequency components. Although the\nsemi-supervised estimation of class labels is an ill-posed problem in general,\nin several applications it is possible to find a source graph on which the\nlabel function has similar frequency content to that on the target graph where\nthe actual classification problem is defined. In this paper, we propose a\nmethod for domain adaptation on graphs motivated by these observations. Our\nalgorithm is based on learning the spectrum of the label function in a source\ngraph with many labeled nodes, and transferring the information of the spectrum\nto the target graph with fewer labeled nodes. While the frequency content of\nthe class label function can be identified through the graph Fourier transform,\nit is not easy to transfer the Fourier coefficients directly between the two\ngraphs, since no one-to-one match exists between the Fourier basis vectors of\nindependently constructed graphs in the domain adaptation setting. We solve\nthis problem by learning a transformation between the Fourier bases of the two\ngraphs that flexibly ``aligns'' them. The unknown class label function on the\ntarget graph is then reconstructed such that its spectrum matches that on the\nsource graph while also ensuring the consistency with the available labels. The\nproposed method is tested in the classification of image, online product\nreview, and social network data sets. Comparative experiments suggest that the\nproposed algorithm performs better than recent domain adaptation methods in the\nliterature in most settings.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 14:04:04 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 11:30:59 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 15:38:55 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Pilanci", "Mehmet", ""], ["Vural", "Elif", ""]]}, {"id": "1803.05307", "submitter": "Sergey Novoselov", "authors": "Sergey Novoselov, Oleg Kudashev, Vadim Schemelinin, Ivan Kremnev and\n  Galina Lavrentyeva", "title": "Deep CNN based feature extractor for text-prompted speaker recognition", "comments": "Submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is still not a very common tool in speaker verification field.\nWe study deep convolutional neural network performance in the text-prompted\nspeaker verification task. The prompted passphrase is segmented into word\nstates - i.e. digits -to test each digit utterance separately. We train a\nsingle high-level feature extractor for all states and use cosine similarity\nmetric for scoring. The key feature of our network is the Max-Feature-Map\nactivation function, which acts as an embedded feature selector. By using\nmultitask learning scheme to train the high-level feature extractor we were\nable to surpass the classic baseline systems in terms of quality and achieved\nimpressive results for such a novice approach, getting 2.85% EER on the RSR2015\nevaluation set. Fusion of the proposed and the baseline systems improves this\nresult.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 10:59:24 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Novoselov", "Sergey", ""], ["Kudashev", "Oleg", ""], ["Schemelinin", "Vadim", ""], ["Kremnev", "Ivan", ""], ["Lavrentyeva", "Galina", ""]]}, {"id": "1803.05337", "submitter": "Micha\\\"el Defferrard", "authors": "Micha\\\"el Defferrard, Sharada P. Mohanty, Sean F. Carroll, Marcel\n  Salath\\'e", "title": "Learning to Recognize Musical Genre from Audio", "comments": "submitted to WWW'18 after challenge round-1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We here summarize our experience running a challenge with open data for\nmusical genre recognition. Those notes motivate the task and the challenge\ndesign, show some statistics about the submissions, and present the results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 15:58:58 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Defferrard", "Micha\u00ebl", ""], ["Mohanty", "Sharada P.", ""], ["Carroll", "Sean F.", ""], ["Salath\u00e9", "Marcel", ""]]}, {"id": "1803.05339", "submitter": "Yilong Yang", "authors": "Run Han, Yilong Yang, Xiaoshan Li, Defang Ouyang", "title": "Predicting Oral Disintegrating Tablet Formulations by Neural Network\n  Techniques", "comments": "This is a post-peer-review, pre-copyedit version of an article\n  published in Asian Journal of Pharmaceutical Sciences. The final\n  authenticated version is available online at:\n  https://doi.org/10.1016/j.ajps.2018.01.003", "journal-ref": null, "doi": "10.1016/j.ajps.2018.01.003", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oral Disintegrating Tablets (ODTs) is a novel dosage form that can be\ndissolved on the tongue within 3min or less especially for geriatric and\npediatric patients. Current ODT formulation studies usually rely on the\npersonal experience of pharmaceutical experts and trial-and-error in the\nlaboratory, which is inefficient and time-consuming. The aim of current\nresearch was to establish the prediction model of ODT formulations with direct\ncompression process by Artificial Neural Network (ANN) and Deep Neural Network\n(DNN) techniques. 145 formulation data were extracted from Web of Science. All\ndata sets were divided into three parts: training set (105 data), validation\nset (20) and testing set (20). ANN and DNN were compared for the prediction of\nthe disintegrating time. The accuracy of the ANN model has reached 85.60%,\n80.00% and 75.00% on the training set, validation set and testing set\nrespectively, whereas that of the DNN model was 85.60%, 85.00% and 80.00%,\nrespectively. Compared with the ANN, DNN showed the better prediction for ODT\nformulations. It is the first time that deep neural network with the improved\ndataset selection algorithm is applied to formulation prediction on small data.\nThe proposed predictive approach could evaluate the critical parameters about\nquality control of formulation, and guide research and process development. The\nimplementation of this prediction model could effectively reduce drug product\ndevelopment timeline and material usage, and proactively facilitate the\ndevelopment of a robust drug product.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 15:05:11 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Han", "Run", ""], ["Yang", "Yilong", ""], ["Li", "Xiaoshan", ""], ["Ouyang", "Defang", ""]]}, {"id": "1803.05340", "submitter": "Lucas Lamata", "authors": "F. Albarr\\'an-Arriagada, J. C. Retamal, E. Solano, L. Lamata", "title": "Measurement-based adaptation protocol with quantum reinforcement\n  learning", "comments": null, "journal-ref": "Phys. Rev. A 98, 042315 (2018)", "doi": "10.1103/PhysRevA.98.042315", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning employs dynamical algorithms that mimic the human capacity\nto learn, where the reinforcement learning ones are among the most similar to\nhumans in this respect. On the other hand, adaptability is an essential aspect\nto perform any task efficiently in a changing environment, and it is\nfundamental for many purposes, such as natural selection. Here, we propose an\nalgorithm based on successive measurements to adapt one quantum state to a\nreference unknown state, in the sense of achieving maximum overlap. The\nprotocol naturally provides many identical copies of the reference state, such\nthat in each measurement iteration more information about it is obtained. In\nour protocol, we consider a system composed of three parts, the \"environment\"\nsystem, which provides the reference state copies; the register, which is an\nauxiliary subsystem that interacts with the environment to acquire information\nfrom it; and the agent, which corresponds to the quantum state that is adapted\nby digital feedback with input corresponding to the outcome of the measurements\non the register. With this proposal we can achieve an average fidelity between\nthe environment and the agent of more than $90\\% $ with less than $30$\niterations of the protocol. In addition, we extend the formalism to $ d\n$-dimensional states, reaching an average fidelity of around $80\\% $ in less\nthan $400$ iterations for $d=$ 11, for a variety of genuinely quantum and\nsemiclassical states. This work paves the way for the development of quantum\nreinforcement learning protocols using quantum data and for the future\ndeployment of semi-autonomous quantum systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 15:06:11 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 06:01:22 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Albarr\u00e1n-Arriagada", "F.", ""], ["Retamal", "J. C.", ""], ["Solano", "E.", ""], ["Lamata", "L.", ""]]}, {"id": "1803.05391", "submitter": "Zheng Zhan", "authors": "Yanzhi Wang, Zheng Zhan, Jiayu Li, Jian Tang, Bo Yuan, Liang Zhao,\n  Wujie Wen, Siyue Wang and Xue Lin", "title": "On the Universal Approximation Property and Equivalence of Stochastic\n  Computing-based Neural Networks and Binary Neural Networks", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale deep neural networks are both memory intensive and\ncomputation-intensive, thereby posing stringent requirements on the computing\nplatforms. Hardware accelerations of deep neural networks have been extensively\ninvestigated in both industry and academia. Specific forms of binary neural\nnetworks (BNNs) and stochastic computing based neural networks (SCNNs) are\nparticularly appealing to hardware implementations since they can be\nimplemented almost entirely with binary operations. Despite the obvious\nadvantages in hardware implementation, these approximate computing techniques\nare questioned by researchers in terms of accuracy and universal applicability.\nAlso it is important to understand the relative pros and cons of SCNNs and BNNs\nin theory and in actual hardware implementations. In order to address these\nconcerns, in this paper we prove that the \"ideal\" SCNNs and BNNs satisfy the\nuniversal approximation property with probability 1 (due to the stochastic\nbehavior). The proof is conducted by first proving the property for SCNNs from\nthe strong law of large numbers, and then using SCNNs as a \"bridge\" to prove\nfor BNNs. Based on the universal approximation property, we further prove that\nSCNNs and BNNs exhibit the same energy complexity. In other words, they have\nthe same asymptotic energy consumption with the growing of network size. We\nalso provide a detailed analysis of the pros and cons of SCNNs and BNNs for\nhardware implementations and conclude that SCNNs are more suitable for\nhardware.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:40:42 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 17:22:31 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Wang", "Yanzhi", ""], ["Zhan", "Zheng", ""], ["Li", "Jiayu", ""], ["Tang", "Jian", ""], ["Yuan", "Bo", ""], ["Zhao", "Liang", ""], ["Wen", "Wujie", ""], ["Wang", "Siyue", ""], ["Lin", "Xue", ""]]}, {"id": "1803.05397", "submitter": "Can Karakus", "authors": "Can Karakus, Yifan Sun, Suhas Diggavi, Wotao Yin", "title": "Redundancy Techniques for Straggler Mitigation in Distributed\n  Optimization and Learning", "comments": "39 pages, 14 figures. Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of distributed optimization and learning systems is bottlenecked\nby \"straggler\" nodes and slow communication links, which significantly delay\ncomputation. We propose a distributed optimization framework where the dataset\nis \"encoded\" to have an over-complete representation with built-in redundancy,\nand the straggling nodes in the system are dynamically left out of the\ncomputation at every iteration, whose loss is compensated by the embedded\nredundancy. We show that oblivious application of several popular optimization\nalgorithms on encoded data, including gradient descent, L-BFGS, proximal\ngradient under data parallelism, and coordinate descent under model\nparallelism, converge to either approximate or exact solutions of the original\nproblem when stragglers are treated as erasures. These convergence results are\ndeterministic, i.e., they establish sample path convergence for arbitrary\nsequences of delay patterns or distributions on the nodes, and are independent\nof the tail behavior of the delay distribution. We demonstrate that equiangular\ntight frames have desirable properties as encoding matrices, and propose\nefficient mechanisms for encoding large-scale data. We implement the proposed\ntechnique on Amazon EC2 clusters, and demonstrate its performance over several\nlearning problems, including matrix factorization, LASSO, ridge regression and\nlogistic regression, and compare the proposed method with uncoded,\nasynchronous, and data replication strategies.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:48:08 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Karakus", "Can", ""], ["Sun", "Yifan", ""], ["Diggavi", "Suhas", ""], ["Yin", "Wotao", ""]]}, {"id": "1803.05402", "submitter": "Jack Harmer PhD", "authors": "Jack Harmer, Linus Gissl\\'en, Jorge del Val, Henrik Holst, Joakim\n  Bergdahl, Tom Olsson, Kristoffer Sj\\\"o\\\"o, Magnus Nordin", "title": "Imitation Learning with Concurrent Actions in 3D Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe a novel deep reinforcement learning architecture\nthat allows multiple actions to be selected at every time-step in an efficient\nmanner. Multi-action policies allow complex behaviours to be learnt that would\notherwise be hard to achieve when using single action selection techniques. We\nuse both imitation learning and temporal difference (TD) reinforcement learning\n(RL) to provide a 4x improvement in training time and 2.5x improvement in\nperformance over single action selection TD RL. We demonstrate the capabilities\nof this network using a complex in-house 3D game. Mimicking the behavior of the\nexpert teacher significantly improves world state exploration and allows the\nagents vision system to be trained more rapidly than TD RL alone. This initial\ntraining technique kick-starts TD learning and the agent quickly learns to\nsurpass the capabilities of the expert.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:59:17 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 17:35:18 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 20:48:42 GMT"}, {"version": "v4", "created": "Thu, 31 May 2018 10:12:40 GMT"}, {"version": "v5", "created": "Thu, 6 Sep 2018 12:16:17 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Harmer", "Jack", ""], ["Gissl\u00e9n", "Linus", ""], ["del Val", "Jorge", ""], ["Holst", "Henrik", ""], ["Bergdahl", "Joakim", ""], ["Olsson", "Tom", ""], ["Sj\u00f6\u00f6", "Kristoffer", ""], ["Nordin", "Magnus", ""]]}, {"id": "1803.05407", "submitter": "Andrew Wilson", "authors": "Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov,\n  Andrew Gordon Wilson", "title": "Averaging Weights Leads to Wider Optima and Better Generalization", "comments": "Appears at the Conference on Uncertainty in Artificial Intelligence\n  (UAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are typically trained by optimizing a loss function with\nan SGD variant, in conjunction with a decaying learning rate, until\nconvergence. We show that simple averaging of multiple points along the\ntrajectory of SGD, with a cyclical or constant learning rate, leads to better\ngeneralization than conventional training. We also show that this Stochastic\nWeight Averaging (SWA) procedure finds much flatter solutions than SGD, and\napproximates the recent Fast Geometric Ensembling (FGE) approach with a single\nmodel. Using SWA we achieve notable improvement in test accuracy over\nconventional SGD training on a range of state-of-the-art residual networks,\nPyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and\nImageNet. In short, SWA is extremely easy to implement, improves\ngeneralization, and has almost no computational overhead.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 17:09:27 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 08:49:15 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 14:18:11 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Izmailov", "Pavel", ""], ["Podoprikhin", "Dmitrii", ""], ["Garipov", "Timur", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1803.05419", "submitter": "John Alexander Harston", "authors": "Thomas Teh, Chaiyawan Auepanwiriyakul, John Alexander Harston, A. Aldo\n  Faisal", "title": "Generalised Structural CNNs (SCNNs) for time series data with arbitrary\n  graph topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning methods, specifically convolutional neural networks (CNNs),\nhave seen a lot of success in the domain of image-based data, where the data\noffers a clearly structured topology in the regular lattice of pixels. This\n4-neighbourhood topological simplicity makes the application of convolutional\nmasks straightforward for time series data, such as video applications, but\nmany high-dimensional time series data are not organised in regular lattices,\nand instead values may have adjacency relationships with non-trivial\ntopologies, such as small-world networks or trees. In our application case,\nhuman kinematics, it is currently unclear how to generalise convolutional\nkernels in a principled manner. Therefore we define and implement here a\nframework for general graph-structured CNNs for time series analysis. Our\nalgorithm automatically builds convolutional layers using the specified\nadjacency matrix of the data dimensions and convolutional masks that scale with\nthe hop distance. In the limit of a lattice-topology our method produces the\nwell-known image convolutional masks. We test our method first on synthetic\ndata of arbitrarily-connected graphs and human hand motion capture data, where\nthe hand is represented by a tree capturing the mechanical dependencies of the\njoints. We are able to demonstrate, amongst other things, that inclusion of the\ngraph structure of the data dimensions improves model prediction significantly,\nwhen compared against a benchmark CNN model with only time convolution layers.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 17:39:11 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 17:23:12 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Teh", "Thomas", ""], ["Auepanwiriyakul", "Chaiyawan", ""], ["Harston", "John Alexander", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "1803.05428", "submitter": "Adam Roberts", "authors": "Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, Douglas Eck", "title": "A Hierarchical Latent Vector Model for Learning Long-Term Structure in\n  Music", "comments": "ICML Camera Ready Version (w/ fixed typos)", "journal-ref": "ICML 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Autoencoder (VAE) has proven to be an effective model for\nproducing semantically meaningful latent representations for natural data.\nHowever, it has thus far seen limited application to sequential data, and, as\nwe demonstrate, existing recurrent VAE models have difficulty modeling\nsequences with long-term structure. To address this issue, we propose the use\nof a hierarchical decoder, which first outputs embeddings for subsequences of\nthe input and then uses these embeddings to generate each subsequence\nindependently. This structure encourages the model to utilize its latent code,\nthereby avoiding the \"posterior collapse\" problem, which remains an issue for\nrecurrent VAEs. We apply this architecture to modeling sequences of musical\nnotes and find that it exhibits dramatically better sampling, interpolation,\nand reconstruction performance than a \"flat\" baseline model. An implementation\nof our \"MusicVAE\" is available online at http://g.co/magenta/musicvae-code.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:14:46 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 03:51:30 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 18:26:14 GMT"}, {"version": "v4", "created": "Mon, 30 Jul 2018 20:53:57 GMT"}, {"version": "v5", "created": "Mon, 11 Nov 2019 12:38:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Roberts", "Adam", ""], ["Engel", "Jesse", ""], ["Raffel", "Colin", ""], ["Hawthorne", "Curtis", ""], ["Eck", "Douglas", ""]]}, {"id": "1803.05554", "submitter": "Raj Agrawal", "authors": "Raj Agrawal and Tamara Broderick and Caroline Uhler", "title": "Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models", "comments": "Proceedings of the 30th International Conference on Machine Learning.\n  2018, to appear. 16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a Bayesian network (BN) from data can be useful for decision-making\nor discovering causal relationships. However, traditional methods often fail in\nmodern applications, which exhibit a larger number of observed variables than\ndata points. The resulting uncertainty about the underlying network as well as\nthe desire to incorporate prior information recommend a Bayesian approach to\nlearning the BN, but the highly combinatorial structure of BNs poses a striking\nchallenge for inference. The current state-of-the-art methods such as order\nMCMC are faster than previous methods but prevent the use of many natural\nstructural priors and still have running time exponential in the maximum\nindegree of the true directed acyclic graph (DAG) of the BN. We here propose an\nalternative posterior approximation based on the observation that, if we\nincorporate empirical conditional independence tests, we can focus on a\nhigh-probability DAG associated with each order of the vertices. We show that\nour method allows the desired flexibility in prior specification, removes\ntiming dependence on the maximum indegree and yields provably good posterior\napproximations; in addition, we show that it achieves superior accuracy,\nscalability, and sampler mixing on several datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 00:53:25 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 23:44:43 GMT"}, {"version": "v3", "created": "Sun, 24 Jun 2018 15:52:36 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Agrawal", "Raj", ""], ["Broderick", "Tamara", ""], ["Uhler", "Caroline", ""]]}, {"id": "1803.05573", "submitter": "Tim Salimans", "authors": "Tim Salimans, Han Zhang, Alec Radford, Dimitris Metaxas", "title": "Improving GANs Using Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Optimal Transport GAN (OT-GAN), a variant of generative\nadversarial nets minimizing a new metric measuring the distance between the\ngenerator distribution and the data distribution. This metric, which we call\nmini-batch energy distance, combines optimal transport in primal form with an\nenergy distance defined in an adversarially learned feature space, resulting in\na highly discriminative distance function with unbiased mini-batch gradients.\nExperimentally we show OT-GAN to be highly stable when trained with large\nmini-batches, and we present state-of-the-art results on several popular\nbenchmark problems for image generation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 02:34:46 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Salimans", "Tim", ""], ["Zhang", "Han", ""], ["Radford", "Alec", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1803.05589", "submitter": "Mohammad Emtiyaz Khan", "authors": "Wu Lin, Nicolas Hubacher, Mohammad Emtiyaz Khan", "title": "Variational Message Passing with Structured Inference Networks", "comments": "Added a missing term in the gradient of the lower bound", "journal-ref": "ICLR 2018", "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts on combining deep models with probabilistic graphical models\nare promising in providing flexible models that are also easy to interpret. We\npropose a variational message-passing algorithm for variational inference in\nsuch models. We make three contributions. First, we propose structured\ninference networks that incorporate the structure of the graphical model in the\ninference network of variational auto-encoders (VAE). Second, we establish\nconditions under which such inference networks enable fast amortized inference\nsimilar to VAE. Finally, we derive a variational message passing algorithm to\nperform efficient natural-gradient inference while retaining the efficiency of\nthe amortized inference. By simultaneously enabling structured, amortized, and\nnatural-gradient inference for deep structured models, our method simplifies\nand generalizes existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 04:26:24 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 13:21:32 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Lin", "Wu", ""], ["Hubacher", "Nicolas", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "1803.05591", "submitter": "Rahul Kidambi", "authors": "Rahul Kidambi, Praneeth Netrapalli, Prateek Jain and Sham M. Kakade", "title": "On the insufficiency of existing momentum schemes for Stochastic\n  Optimization", "comments": "28 pages, 10 figures. Updated acknowledgements. Appeared as an oral\n  presentation at International Conference on Learning Representations (ICLR),\n  2018. Code implementing the ASGD method can be found at\n  https://github.com/rahulkidambi/AccSGD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum based stochastic gradient methods such as heavy ball (HB) and\nNesterov's accelerated gradient descent (NAG) method are widely used in\npractice for training deep networks and other supervised learning models, as\nthey often provide significant improvements over stochastic gradient descent\n(SGD). Rigorously speaking, \"fast gradient\" methods have provable improvements\nover gradient descent only for the deterministic case, where the gradients are\nexact. In the stochastic case, the popular explanations for their wide\napplicability is that when these fast gradient methods are applied in the\nstochastic case, they partially mimic their exact gradient counterparts,\nresulting in some practical gain. This work provides a counterpoint to this\nbelief by proving that there exist simple problem instances where these methods\ncannot outperform SGD despite the best setting of its parameters. These\nnegative problem instances are, in an informal sense, generic; they do not look\nlike carefully constructed pathological instances. These results suggest (along\nwith empirical evidence) that HB or NAG's practical performance gains are a\nby-product of mini-batching.\n  Furthermore, this work provides a viable (and provable) alternative, which,\non the same set of problem instances, significantly improves over HB, NAG, and\nSGD's performance. This algorithm, referred to as Accelerated Stochastic\nGradient Descent (ASGD), is a simple to implement stochastic algorithm, based\non a relatively less popular variant of Nesterov's Acceleration. Extensive\nempirical results in this paper show that ASGD has performance gains over HB,\nNAG, and SGD.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 05:09:51 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 18:18:05 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Kidambi", "Rahul", ""], ["Netrapalli", "Praneeth", ""], ["Jain", "Prateek", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1803.05598", "submitter": "Hossein Mobahi", "authors": "Gamaleldin F. Elsayed, Dilip Krishnan, Hossein Mobahi, Kevin Regan,\n  Samy Bengio", "title": "Large Margin Deep Networks for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formulation of deep learning that aims at producing a large\nmargin classifier. The notion of margin, minimum distance to a decision\nboundary, has served as the foundation of several theoretically profound and\nempirically successful results for both classification and regression tasks.\nHowever, most large margin algorithms are applicable only to shallow models\nwith a preset feature representation; and conventional margin methods for\nneural networks only enforce margin at the output layer. Such methods are\ntherefore not well suited for deep networks.\n  In this work, we propose a novel loss function to impose a margin on any\nchosen set of layers of a deep network (including input and hidden layers). Our\nformulation allows choosing any norm on the metric measuring the margin. We\ndemonstrate that the decision boundary obtained by our loss has nice properties\ncompared to standard classification loss functions. Specifically, we show\nimproved empirical results on the MNIST, CIFAR-10 and ImageNet datasets on\nmultiple tasks: generalization from small training sets, corrupted labels, and\nrobustness against adversarial perturbations. The resulting loss is general and\ncomplementary to existing data augmentation (such as random/adversarial input\ntransform) and regularization techniques (such as weight decay, dropout, and\nbatch norm).\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 05:33:13 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 01:36:40 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Elsayed", "Gamaleldin F.", ""], ["Krishnan", "Dilip", ""], ["Mobahi", "Hossein", ""], ["Regan", "Kevin", ""], ["Bengio", "Samy", ""]]}, {"id": "1803.05621", "submitter": "Zhao Shen-Yi", "authors": "Shen-Yi Zhao, Gong-Duo Zhang, Ming-Wei Li, Wu-Jun Li", "title": "Proximal SCOPE for Distributed Sparse Learning: Better Data Partition\n  Implies Faster Convergence Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed sparse learning with a cluster of multiple machines has attracted\nmuch attention in machine learning, especially for large-scale applications\nwith high-dimensional data. One popular way to implement sparse learning is to\nuse $L_1$ regularization. In this paper, we propose a novel method, called\nproximal \\mbox{SCOPE}~(\\mbox{pSCOPE}), for distributed sparse learning with\n$L_1$ regularization. pSCOPE is based on a \\underline{c}ooperative\n\\underline{a}utonomous \\underline{l}ocal \\underline{l}earning~(\\mbox{CALL})\nframework. In the \\mbox{CALL} framework of \\mbox{pSCOPE}, we find that the data\npartition affects the convergence of the learning procedure, and subsequently\nwe define a metric to measure the goodness of a data partition. Based on the\ndefined metric, we theoretically prove that pSCOPE is convergent with a linear\nconvergence rate if the data partition is good enough. We also prove that\nbetter data partition implies faster convergence rate. Furthermore, pSCOPE is\nalso communication efficient. Experimental results on real data sets show that\npSCOPE can outperform other state-of-the-art distributed methods for sparse\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 07:38:50 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 16:34:29 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Zhao", "Shen-Yi", ""], ["Zhang", "Gong-Duo", ""], ["Li", "Ming-Wei", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1803.05649", "submitter": "Jakub Tomczak Ph.D.", "authors": "Rianne van den Berg and Leonard Hasenclever and Jakub M. Tomczak and\n  Max Welling", "title": "Sylvester Normalizing Flows for Variational Inference", "comments": "Published at UAI 2018, 12 pages, 3 figures, code at:\n  https://github.com/riannevdberg/sylvester-flows", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference relies on flexible approximate posterior distributions.\nNormalizing flows provide a general recipe to construct flexible variational\nposteriors. We introduce Sylvester normalizing flows, which can be seen as a\ngeneralization of planar flows. Sylvester normalizing flows remove the\nwell-known single-unit bottleneck from planar flows, making a single\ntransformation much more flexible. We compare the performance of Sylvester\nnormalizing flows against planar flows and inverse autoregressive flows and\ndemonstrate that they compare favorably on several datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 09:15:14 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 18:36:23 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Berg", "Rianne van den", ""], ["Hasenclever", "Leonard", ""], ["Tomczak", "Jakub M.", ""], ["Welling", "Max", ""]]}, {"id": "1803.05657", "submitter": "Lei Zhou", "authors": "Lei Zhou, Xiao Bai, Xianglong Liu, Jun Zhou and Hancock Edwin", "title": "Fast Subspace Clustering Based on the Kronecker Product", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering is a useful technique for many computer vision\napplications in which the intrinsic dimension of high-dimensional data is often\nsmaller than the ambient dimension. Spectral clustering, as one of the main\napproaches to subspace clustering, often takes on a sparse representation or a\nlow-rank representation to learn a block diagonal self-representation matrix\nfor subspace generation. However, existing methods require solving a large\nscale convex optimization problem with a large set of data, with computational\ncomplexity reaches O(N^3) for N data points. Therefore, the efficiency and\nscalability of traditional spectral clustering methods can not be guaranteed\nfor large scale datasets. In this paper, we propose a subspace clustering model\nbased on the Kronecker product. Due to the property that the Kronecker product\nof a block diagonal matrix with any other matrix is still a block diagonal\nmatrix, we can efficiently learn the representation matrix which is formed by\nthe Kronecker product of k smaller matrices. By doing so, our model\nsignificantly reduces the computational complexity to O(kN^{3/k}). Furthermore,\nour model is general in nature, and can be adapted to different regularization\nbased subspace clustering methods. Experimental results on two public datasets\nshow that our model significantly improves the efficiency compared with several\nstate-of-the-art methods. Moreover, we have conducted experiments on synthetic\ndata to verify the scalability of our model for large scale datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 09:31:44 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Zhou", "Lei", ""], ["Bai", "Xiao", ""], ["Liu", "Xianglong", ""], ["Zhou", "Jun", ""], ["Edwin", "Hancock", ""]]}, {"id": "1803.05776", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Saikat Chatterjee, Peter H\\\"andel", "title": "Gaussian Processes Over Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Gaussian processes for signals over graphs (GPG) using the apriori\nknowledge that the target vectors lie over a graph. We incorporate this\ninformation using a graph- Laplacian based regularization which enforces the\ntarget vectors to have a specific profile in terms of graph Fourier transform\ncoeffcients, for example lowpass or bandpass graph signals. We discuss how the\nregularization affects the mean and the variance in the prediction output. In\nparticular, we prove that the predictive variance of the GPG is strictly\nsmaller than the conventional Gaussian process (GP) for any non-trivial graph.\nWe validate our concepts by application to various real-world graph signals.\nOur experiments show that the performance of the GPG is superior to GP for\nsmall training data sizes and under noisy training.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 14:27:49 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 10:30:30 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""], ["H\u00e4ndel", "Peter", ""]]}, {"id": "1803.05784", "submitter": "St\\'ephane Ga\\\"iffas", "authors": "Jaouad Mourtada, St\\'ephane Ga\\\"iffas, Erwan Scornet", "title": "Minimax optimal rates for Mondrian trees and forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduced by Breiman, Random Forests are widely used classification and\nregression algorithms. While being initially designed as batch algorithms,\nseveral variants have been proposed to handle online learning. One particular\ninstance of such forests is the \\emph{Mondrian Forest}, whose trees are built\nusing the so-called Mondrian process, therefore allowing to easily update their\nconstruction in a streaming fashion. In this paper, we provide a thorough\ntheoretical study of Mondrian Forests in a batch learning setting, based on new\nresults about Mondrian partitions. Our results include consistency and\nconvergence rates for Mondrian Trees and Forests, that turn out to be minimax\noptimal on the set of $s$-H\\\"older function with $s \\in (0,1]$ (for trees and\nforests) and $s \\in (1,2]$ (for forests only), assuming a proper tuning of\ntheir complexity parameter in both cases. Furthermore, we prove that an\nadaptive procedure (to the unknown $s \\in (0, 2]$) can be constructed by\ncombining Mondrian Forests with a standard model aggregation algorithm. These\nresults are the first demonstrating that some particular random forests achieve\nminimax rates \\textit{in arbitrary dimension}. Owing to their remarkably simple\ndistributional properties, which lead to minimax rates, Mondrian trees are a\npromising basis for more sophisticated yet theoretically sound random forests\nvariants.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 14:43:04 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 12:41:45 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Mourtada", "Jaouad", ""], ["Ga\u00efffas", "St\u00e9phane", ""], ["Scornet", "Erwan", ""]]}, {"id": "1803.05796", "submitter": "Karlson Pfannschmidt", "authors": "Karlson Pfannschmidt, Pritha Gupta, Eyke H\\\"ullermeier", "title": "Deep Architectures for Learning Context-dependent Ranking Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object ranking is an important problem in the realm of preference learning.\nOn the basis of training data in the form of a set of rankings of objects,\nwhich are typically represented as feature vectors, the goal is to learn a\nranking function that predicts a linear order of any new set of objects.\nCurrent approaches commonly focus on ranking by scoring, i.e., on learning an\nunderlying latent utility function that seeks to capture the inherent utility\nof each object. These approaches, however, are not able to take possible\neffects of context-dependence into account, where context-dependence means that\nthe utility or usefulness of an object may also depend on what other objects\nare available as alternatives. In this paper, we formalize the problem of\ncontext-dependent ranking and present two general approaches based on two\nnatural representations of context-dependent ranking functions. Both approaches\nare instantiated by means of appropriate neural network architectures, which\nare evaluated on suitable benchmark task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 15:14:16 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 16:44:26 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Pfannschmidt", "Karlson", ""], ["Gupta", "Pritha", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1803.05867", "submitter": "Daniel Emaasit", "authors": "Daniel Emaasit, Matthew Johnson", "title": "Capturing Structure Implicitly from Time-Series having Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific fields such as insider-threat detection and highway-safety\nplanning often lack sufficient amounts of time-series data to estimate\nstatistical models for the purpose of scientific discovery. Moreover, the\navailable limited data are quite noisy. This presents a major challenge when\nestimating time-series models that are robust to overfitting and have\nwell-calibrated uncertainty estimates. Most of the current literature in these\nfields involve visualizing the time-series for noticeable structure and hard\ncoding them into pre-specified parametric functions. This approach is\nassociated with two limitations. First, given that such trends may not be\neasily noticeable in small data, it is difficult to explicitly incorporate\nexpressive structure into the models during formulation. Second, it is\ndifficult to know $\\textit{a priori}$ the most appropriate functional form to\nuse. To address these limitations, a nonparametric Bayesian approach was\nproposed to implicitly capture hidden structure from time series having limited\ndata. The proposed model, a Gaussian process with a spectral mixture kernel,\nprecludes the need to pre-specify a functional form and hard code trends, is\nrobust to overfitting and has well-calibrated uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 17:03:04 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Emaasit", "Daniel", ""], ["Johnson", "Matthew", ""]]}, {"id": "1803.05897", "submitter": "Jim Kay", "authors": "Jim W. Kay and William A. Phillips", "title": "Contrasting information theoretic decompositions of modulatory and\n  arithmetic interactions in neural information processing systems", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT q-bio.NC q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Biological and artificial neural systems are composed of many local\nprocessors, and their capabilities depend upon the transfer function that\nrelates each local processor's outputs to its inputs. This paper uses a recent\nadvance in the foundations of information theory to study the properties of\nlocal processors that use contextual input to amplify or attenuate transmission\nof information about their driving inputs. This advance enables the information\ntransmitted by processors with two distinct inputs to be decomposed into those\ncomponents unique to each input, that shared between the two inputs, and that\nwhich depends on both though it is in neither, i.e. synergy. The decompositions\nthat we report here show that contextual modulation has information processing\nproperties that contrast with those of all four simple arithmetic operators,\nthat it can take various forms, and that the form used in our previous studies\nof artificial neural nets composed of local processors with both driving and\ncontextual inputs is particularly well-suited to provide the distinctive\ncapabilities of contextual modulation under a wide range of conditions. We\nargue that the decompositions reported here could be compared with those\nobtained from empirical neurobiological and psychophysical data under\nconditions thought to reflect contextual modulation. That would then shed new\nlight on the underlying processes involved. Finally, we suggest that such\ndecompositions could aid the design of context-sensitive machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 17:51:21 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Kay", "Jim W.", ""], ["Phillips", "William A.", ""]]}, {"id": "1803.05976", "submitter": "Alejandro Mottini", "authors": "Alejandro Mottini, Rodrigo Acuna-Agost", "title": "Deep Choice Model Using Pointer Networks for Airline Itinerary\n  Prediction", "comments": null, "journal-ref": "KDD 2017, Proceedings of the 23rd ACM SIGKDD International\n  Conference on Knowledge Discovery and Data Mining, Pages 1575-1583", "doi": "10.1145/3097983.3098005", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel providers such as airlines and on-line travel agents are becoming more\nand more interested in understanding how passengers choose among alternative\nitineraries when searching for flights. This knowledge helps them better\ndisplay and adapt their offer, taking into account market conditions and\ncustomer needs. Some common applications are not only filtering and sorting\nalternatives, but also changing certain attributes in real-time (e.g., changing\nthe price). In this paper, we concentrate with the problem of modeling air\npassenger choices of flight itineraries. This problem has historically been\ntackled using classical Discrete Choice Modelling techniques. Traditional\nstatistical approaches, in particular the Multinomial Logit model (MNL), is\nwidely used in industrial applications due to its simplicity and general good\nperformance. However, MNL models present several shortcomings and assumptions\nthat might not hold in real applications. To overcome these difficulties, we\npresent a new choice model based on Pointer Networks. Given an input sequence,\nthis type of deep neural architecture combines Recurrent Neural Networks with\nthe Attention Mechanism to learn the conditional probability of an output whose\nvalues correspond to positions in an input sequence. Therefore, given a\nsequence of different alternatives presented to a customer, the model can learn\nto point to the one most likely to be chosen by the customer. The proposed\nmethod was evaluated on a real dataset that combines on-line user search logs\nand airline flight bookings. Experimental results show that the proposed model\noutperforms the traditional MNL model on several metrics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 19:55:56 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Mottini", "Alejandro", ""], ["Acuna-Agost", "Rodrigo", ""]]}, {"id": "1803.05985", "submitter": "Milena \\v{C}uki\\'c Dr", "authors": "Milena Cukic, David Pokrajac, Miodrag Stokic, slobodan Simic, Vlada\n  Radivojevic and Milos Ljubisavljevic", "title": "EEG machine learning with Higuchi fractal dimension and Sample Entropy\n  as features for successful detection of depression", "comments": "34 pages, 4 Figures, 2 tables", "journal-ref": "Cognitive Neurodynamics Springer Nature March 2020", "doi": "10.1007/s11571-020-09581-x", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable diagnosis of depressive disorder is essential for both optimal\ntreatment and prevention of fatal outcomes. In this study, we aimed to\nelucidate the effectiveness of two non-linear measures, Higuchi Fractal\nDimension (HFD) and Sample Entropy (SampEn), in detecting depressive disorders\nwhen applied on EEG. HFD and SampEn of EEG signals were used as features for\nseven machine learning algorithms including Multilayer Perceptron, Logistic\nRegression, Support Vector Machines with the linear and polynomial kernel,\nDecision Tree, Random Forest, and Naive Bayes classifier, discriminating EEG\nbetween healthy control subjects and patients diagnosed with depression. We\nconfirmed earlier observations that both non-linear measures can discriminate\nEEG signals of patients from healthy control subjects. The results suggest that\ngood classification is possible even with a small number of principal\ncomponents. Average accuracy among classifiers ranged from 90.24% to 97.56%.\nAmong the two measures, SampEn had better performance. Using HFD and SampEn and\na variety of machine learning techniques we can accurately discriminate\npatients diagnosed with depression vs controls which can serve as a highly\nsensitive, clinically relevant marker for the diagnosis of depressive\ndisorders.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 20:13:38 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Cukic", "Milena", ""], ["Pokrajac", "David", ""], ["Stokic", "Miodrag", ""], ["Simic", "slobodan", ""], ["Radivojevic", "Vlada", ""], ["Ljubisavljevic", "Milos", ""]]}, {"id": "1803.05999", "submitter": "Hadi Daneshmand", "authors": "Hadi Daneshmand, Jonas Kohler, Aurelien Lucchi, Thomas Hofmann", "title": "Escaping Saddles with Stochastic Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the variance of stochastic gradients along negative curvature\ndirections in certain non-convex machine learning models and show that\nstochastic gradients exhibit a strong component along these directions.\nFurthermore, we show that - contrary to the case of isotropic noise - this\nvariance is proportional to the magnitude of the corresponding eigenvalues and\nnot decreasing in the dimensionality. Based upon this observation we propose a\nnew assumption under which we show that the injection of explicit, isotropic\nnoise usually applied to make gradient descent escape saddle points can\nsuccessfully be replaced by a simple SGD step. Additionally - and under the\nsame condition - we derive the first convergence rate for plain SGD to a\nsecond-order stationary point in a number of iterations that is independent of\nthe problem dimension.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 20:48:06 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 16:18:17 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Daneshmand", "Hadi", ""], ["Kohler", "Jonas", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1803.06010", "submitter": "Shannon McCurdy", "authors": "Shannon R. McCurdy", "title": "Ridge Regression and Provable Deterministic Ridge Leverage Score\n  Sampling", "comments": "24 pages, 15 figures. Minor changes such as typos fixed, some\n  background discussion added, references added", "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS 2018),\n  Montreal, Canada", "doi": null, "report-no": null, "categories": "math.ST cs.DS stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ridge leverage scores provide a balance between low-rank approximation and\nregularization, and are ubiquitous in randomized linear algebra and machine\nlearning. Deterministic algorithms are also of interest in the moderately big\ndata regime, because deterministic algorithms provide interpretability to the\npractitioner by having no failure probability and always returning the same\nresults.\n  We provide provable guarantees for deterministic column sampling using ridge\nleverage scores. The matrix sketch returned by our algorithm is a column subset\nof the original matrix, yielding additional interpretability. Like the\nrandomized counterparts, the deterministic algorithm provides (1 + {\\epsilon})\nerror column subset selection, (1 + {\\epsilon}) error projection-cost\npreservation, and an additive-multiplicative spectral bound. We also show that\nunder the assumption of power-law decay of ridge leverage scores, this\ndeterministic algorithm is provably as accurate as randomized algorithms.\n  Lastly, ridge regression is frequently used to regularize ill-posed linear\nleast-squares problems. While ridge regression provides shrinkage for the\nregression coefficients, many of the coefficients remain small but non-zero.\nPerforming ridge regression with the matrix sketch returned by our algorithm\nand a particular regularization parameter forces coefficients to zero and has a\nprovable (1 + {\\epsilon}) bound on the statistical risk. As such, it is an\ninteresting alternative to elastic net regularization.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 21:35:55 GMT"}, {"version": "v2", "created": "Sun, 23 Dec 2018 21:06:18 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["McCurdy", "Shannon R.", ""]]}, {"id": "1803.06024", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Alex Dikopoltsev, Oren Cohen, Shie Mannor and Mordechai\n  Segev", "title": "Deep Learning Reconstruction of Ultra-Short Pulses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-short laser pulses with femtosecond to attosecond pulse duration are\nthe shortest systematic events humans can create. Characterization (amplitude\nand phase) of these pulses is a key ingredient in ultrafast science, e.g.,\nexploring chemical reactions and electronic phase transitions. Here, we propose\nand demonstrate, numerically and experimentally, the first deep neural network\ntechnique to reconstruct ultra-short optical pulses. We anticipate that this\napproach will extend the range of ultrashort laser pulses that can be\ncharacterized, e.g., enabling to diagnose very weak attosecond pulses.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 22:37:31 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Zahavy", "Tom", ""], ["Dikopoltsev", "Alex", ""], ["Cohen", "Oren", ""], ["Mannor", "Shie", ""], ["Segev", "Mordechai", ""]]}, {"id": "1803.06030", "submitter": "Urtats Etxegarai Susaeta", "authors": "Urtats Etxegarai, Eva Portillo, Jon Irazusta, Ander Arriandiaga,\n  Itziar Cabanes", "title": "Estimation of lactate threshold with machine learning techniques in\n  recreational runners", "comments": "33 pages, 16 figures", "journal-ref": "Applied Soft Computing, 63, 181-196 (2018)", "doi": "10.1016/j.asoc.2017.11.036", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lactate threshold is considered an essential parameter when assessing\nperformance of elite and recreational runners and prescribing training\nintensities in endurance sports. However, the measurement of blood lactate\nconcentration requires expensive equipment and the extraction of blood samples,\nwhich are inconvenient for frequent monitoring. Furthermore, most recreational\nrunners do not have access to routine assessment of their physical fitness by\nthe aforementioned equipment so they are not able to calculate the lactate\nthreshold without resorting to an expensive and specialized centre. Therefore,\nthe main objective of this study is to create an intelligent system capable of\nestimating the lactate threshold of recreational athletes participating in\nendurance running sports. The solution here proposed is based on a machine\nlearning system which models the lactate evolution using recurrent neural\nnetworks and includes the proposal of standardization of the temporal axis as\nwell as a modification of the stratified sampling method. The results show that\nthe proposed system accurately estimates the lactate threshold of 89.52% of the\nathletes and its correlation with the experimentally measured lactate threshold\nis very high (R=0,89). Moreover, its behaviour with the test dataset is as good\nas with the training set, meaning that the generalization power of the model is\nhigh. Therefore, in this study a machine learning based system is proposed as\nalternative to the traditional invasive lactate threshold measurement tests for\nrecreational runners.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 23:11:59 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 02:51:55 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Etxegarai", "Urtats", ""], ["Portillo", "Eva", ""], ["Irazusta", "Jon", ""], ["Arriandiaga", "Ander", ""], ["Cabanes", "Itziar", ""]]}, {"id": "1803.06031", "submitter": "Zhixin Zhou", "authors": "Zhixin Zhou and Arash A. Amini", "title": "Optimal Bipartite Network Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study bipartite community detection in networks, or more generally the\nnetwork biclustering problem. We present a fast two-stage procedure based on\nspectral initialization followed by the application of a pseudo-likelihood\nclassifier twice. Under mild regularity conditions, we establish the weak\nconsistency of the procedure (i.e., the convergence of the misclassification\nrate to zero) under a general bipartite stochastic block model. We show that\nthe procedure is optimal in the sense that it achieves the optimal convergence\nrate that is achievable by a biclustering oracle, adaptively over the whole\nclass, up to constants. This is further formalized by deriving a minimax lower\nbound over a class of biclustering problems. The optimal rate we obtain\nsharpens some of the existing results and generalizes others to a wide regime\nof average degree growth, from sparse networks with average degrees growing\narbitrarily slowly to fairly dense networks with average degrees of order\n$\\sqrt{n}$. As a special case, we recover the known exact recovery threshold in\nthe $\\log n$ regime of sparsity. To obtain the consistency result, as part of\nthe provable version of the algorithm, we introduce a sub-block partitioning\nscheme that is also computationally attractive, allowing for distributed\nimplementation of the algorithm without sacrificing optimality. The provable\nalgorithm is derived from a general class of pseudo-likelihood biclustering\nalgorithms that employ simple EM type updates. We show the effectiveness of\nthis general class by numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 23:19:30 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 22:53:26 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zhou", "Zhixin", ""], ["Amini", "Arash A.", ""]]}, {"id": "1803.06058", "submitter": "Geoff Pleiss", "authors": "Geoff Pleiss, Jacob R. Gardner, Kilian Q. Weinberger, Andrew Gordon\n  Wilson", "title": "Constant-Time Predictive Distributions for Gaussian Processes", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most compelling features of Gaussian process (GP) regression is\nits ability to provide well-calibrated posterior distributions. Recent advances\nin inducing point methods have sped up GP marginal likelihood and posterior\nmean computations, leaving posterior covariance estimation and sampling as the\nremaining computational bottlenecks. In this paper we address these\nshortcomings by using the Lanczos algorithm to rapidly approximate the\npredictive covariance matrix. Our approach, which we refer to as LOVE (LanczOs\nVariance Estimates), substantially improves time and space complexity. In our\nexperiments, LOVE computes covariances up to 2,000 times faster and draws\nsamples 18,000 times faster than existing methods, all without sacrificing\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 02:31:45 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 17:49:21 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 20:25:05 GMT"}, {"version": "v4", "created": "Wed, 20 Jun 2018 16:39:16 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Pleiss", "Geoff", ""], ["Gardner", "Jacob R.", ""], ["Weinberger", "Kilian Q.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1803.06070", "submitter": "Xenia Miscouridou", "authors": "Xenia Miscouridou, Fran\\c{c}ois Caron, Yee Whye Teh", "title": "Modelling sparsity, heterogeneity, reciprocity and community structure\n  in temporal interaction data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel class of network models for temporal dyadic interaction\ndata. Our goal is to capture a number of important features often observed in\nsocial interactions: sparsity, degree heterogeneity, community structure and\nreciprocity. We propose a family of models based on self-exciting Hawkes point\nprocesses in which events depend on the history of the process. The key\ncomponent is the conditional intensity function of the Hawkes Process, which\ncaptures the fact that interactions may arise as a response to past\ninteractions (reciprocity), or due to shared interests between individuals\n(community structure). In order to capture the sparsity and degree\nheterogeneity, the base (non time dependent) part of the intensity function\nbuilds on compound random measures following Todeschini et al. (2016). We\nconduct experiments on a variety of real-world temporal interaction data and\nshow that the proposed model outperforms many competing approaches for link\nprediction, and leads to interpretable parameters.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 04:00:41 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 18:31:05 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Miscouridou", "Xenia", ""], ["Caron", "Fran\u00e7ois", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1803.06071", "submitter": "Hongzhi Wang", "authors": "Zhixin Qi, Hongzhi Wang, Jianzhong Li, Hong Gao", "title": "Impacts of Dirty Data: and Experimental Evaluation", "comments": "22 pages, 192 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data quality issues have attracted widespread attention due to the negative\nimpacts of dirty data on data mining and machine learning results. The\nrelationship between data quality and the accuracy of results could be applied\non the selection of the appropriate algorithm with the consideration of data\nquality and the determination of the data share to clean. However, rare\nresearch has focused on exploring such relationship. Motivated by this, this\npaper conducts an experimental comparison for the effects of missing,\ninconsistent and conflicting data on classification and clustering algorithms.\nBased on the experimental findings, we provide guidelines for algorithm\nselection and data cleaning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 04:23:00 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 07:48:11 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Qi", "Zhixin", ""], ["Wang", "Hongzhi", ""], ["Li", "Jianzhong", ""], ["Gao", "Hong", ""]]}, {"id": "1803.06084", "submitter": "Tri Dao", "authors": "Tri Dao, Albert Gu, Alexander J. Ratner, Virginia Smith, Christopher\n  De Sa, Christopher R\\'e", "title": "A Kernel Theory of Modern Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation, a technique in which a training set is expanded with\nclass-preserving transformations, is ubiquitous in modern machine learning\npipelines. In this paper, we seek to establish a theoretical framework for\nunderstanding data augmentation. We approach this from two directions: First,\nwe provide a general model of augmentation as a Markov process, and show that\nkernels appear naturally with respect to this model, even when we do not employ\nkernel classification. Next, we analyze more directly the effect of\naugmentation on kernel classifiers, showing that data augmentation can be\napproximated by first-order feature averaging and second-order variance\nregularization components. These frameworks both serve to illustrate the ways\nin which data augmentation affects the downstream learning model, and the\nresulting analyses provide novel connections between prior work in invariant\nkernels, tangent propagation, and robust optimization. Finally, we provide\nseveral proof-of-concept applications showing that our theory can be useful for\naccelerating machine learning workflows, such as reducing the amount of\ncomputation needed to train using augmented data, and predicting the utility of\na transformation prior to training.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 06:05:32 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 17:58:12 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Dao", "Tri", ""], ["Gu", "Albert", ""], ["Ratner", "Alexander J.", ""], ["Smith", "Virginia", ""], ["De Sa", "Christopher", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1803.06111", "submitter": "Richard Kenway", "authors": "Richard Kenway", "title": "Vulnerability of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Renormalisation Group (RG) provides a framework in which it is possible\nto assess whether a deep-learning network is sensitive to small changes in the\ninput data and hence prone to error, or susceptible to adversarial attack.\nDistinct classification outputs are associated with different RG fixed points\nand sensitivity to small changes in the input data is due to the presence of\nrelevant operators at a fixed point. A numerical scheme, based on Monte Carlo\nRG ideas, is proposed for identifying the existence of relevant operators and\nthe corresponding directions of greatest sensitivity in the input data. Thus, a\ntrained deep-learning network may be tested for its robustness and, if it is\nvulnerable to attack, dangerous perturbations of the input data identified.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 08:52:04 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Kenway", "Richard", ""]]}, {"id": "1803.06118", "submitter": "Baptiste Broto", "authors": "Fran\\c{c}ois Bachoc (GdR MASCOT-NUM), Baptiste Broto (LADIS), Fabrice\n  Gamboa (IMT), Jean-Michel Loubes (IMT)", "title": "Gaussian Processes indexed on the symmetric group: prediction and\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of the supervised learning of a real function defined on a\nspace X , the so called Kriging method stands on a real Gaussian field defined\non X. The Euclidean case is well known and has been widely studied. In this\npaper, we explore the less classical case where X is the non commutative finite\ngroup of permutations. In this setting, we propose and study an harmonic\nanalysis of the covariance operators that enables to consider Gaussian\nprocesses models and forecasting issues. Our theory is motivated by statistical\nranking problems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 09:19:36 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2018 15:50:19 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 09:56:39 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 09:23:50 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Bachoc", "Fran\u00e7ois", "", "GdR MASCOT-NUM"], ["Broto", "Baptiste", "", "LADIS"], ["Gamboa", "Fabrice", "", "IMT"], ["Loubes", "Jean-Michel", "", "IMT"]]}, {"id": "1803.06247", "submitter": "Philipp Geiger", "authors": "Philipp Geiger, Michel Besserve, Justus Winkelmann, Claudius Proissl,\n  Bernhard Sch\\\"olkopf", "title": "Coordinating users of shared facilities via data-driven predictive\n  assistants and game theory", "comments": "Extended version, including supplement, of a paper at the 35th\n  Conference on Uncertainty in Artificial Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study data-driven assistants that provide congestion forecasts to users of\nshared facilities (roads, cafeterias, etc.), to support coordination between\nthem, and increase efficiency of such collective systems. Key questions are:\n(1) when and how much can (accurate) predictions help for coordination, and (2)\nwhich assistant algorithms reach optimal predictions?\n  First we lay conceptual ground for this setting where user preferences are a\npriori unknown and predictions influence outcomes. Addressing (1), we establish\nconditions under which self-fulfilling prophecies, i.e., \"perfect\"\n(probabilistic) predictions of what will happen, solve the coordination problem\nin the game-theoretic sense of selecting a Bayesian Nash equilibrium (BNE).\nNext we prove that such prophecies exist even in large-scale settings where\nonly aggregated statistics about users are available. This entails a new\n(nonatomic) BNE existence result. Addressing (2), we propose two assistant\nalgorithms that sequentially learn from users' reactions, together with\noptimality/convergence guarantees. We validate one of them in a large\nreal-world experiment.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 14:27:12 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 11:34:51 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 11:28:14 GMT"}, {"version": "v4", "created": "Wed, 24 Jul 2019 10:35:36 GMT"}, {"version": "v5", "created": "Fri, 24 Jan 2020 12:29:16 GMT"}, {"version": "v6", "created": "Thu, 29 Jul 2021 17:04:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Geiger", "Philipp", ""], ["Besserve", "Michel", ""], ["Winkelmann", "Justus", ""], ["Proissl", "Claudius", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1803.06272", "submitter": "Renjie Liao", "authors": "Renjie Liao, Marc Brockschmidt, Daniel Tarlow, Alexander L. Gaunt,\n  Raquel Urtasun, Richard Zemel", "title": "Graph Partition Neural Networks for Semi-Supervised Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present graph partition neural networks (GPNN), an extension of graph\nneural networks (GNNs) able to handle extremely large graphs. GPNNs alternate\nbetween locally propagating information between nodes in small subgraphs and\nglobally propagating information between the subgraphs. To efficiently\npartition graphs, we experiment with several partitioning algorithms and also\npropose a novel variant for fast processing of large scale graphs. We\nextensively test our model on a variety of semi-supervised node classification\ntasks. Experimental results indicate that GPNNs are either superior or\ncomparable to state-of-the-art methods on a wide variety of datasets for\ngraph-based semi-supervised classification. We also show that GPNNs can achieve\nsimilar performance as standard GNNs with fewer propagation steps.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 15:34:06 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Liao", "Renjie", ""], ["Brockschmidt", "Marc", ""], ["Tarlow", "Daniel", ""], ["Gaunt", "Alexander L.", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""]]}, {"id": "1803.06320", "submitter": "Florian Bernard", "authors": "Florian Bernard, Johan Thunberg, Jorge Goncalves, Christian Theobalt", "title": "Synchronisation of Partial Multi-Matchings via Non-negative\n  Factorisations", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2019.03.021", "report-no": null, "categories": "cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study permutation synchronisation for the challenging case of\npartial permutations, which plays an important role for the problem of matching\nmultiple objects (e.g. images or shapes). The term synchronisation refers to\nthe property that the set of pairwise matchings is cycle-consistent, i.e. in\nthe full matching case all compositions of pairwise matchings over cycles must\nbe equal to the identity. Motivated by clustering and matrix factorisation\nperspectives of cycle-consistency, we derive an algorithm to tackle the\npermutation synchronisation problem based on non-negative factorisations. In\norder to deal with the inherent non-convexity of the permutation\nsynchronisation problem, we use an initialisation procedure based on a novel\nrotation scheme applied to the solution of the spectral relaxation. Moreover,\nthis rotation scheme facilitates a convenient Euclidean projection to obtain a\nbinary solution after solving our relaxed problem. In contrast to\nstate-of-the-art methods, our approach is guaranteed to produce\ncycle-consistent results. We experimentally demonstrate the efficacy of our\nmethod and show that it achieves better results compared to existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 17:17:05 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 07:01:49 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 13:33:00 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Bernard", "Florian", ""], ["Thunberg", "Johan", ""], ["Goncalves", "Jorge", ""], ["Theobalt", "Christian", ""]]}, {"id": "1803.06321", "submitter": "M. Arjumand Masood", "authors": "M. Arjumand Masood and Finale Doshi-Velez", "title": "A particle-based variational approach to Bayesian Non-negative Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Non-negative Matrix Factorization (NMF) is a promising approach for\nunderstanding uncertainty and structure in matrix data. However, a large volume\nof applied work optimizes traditional non-Bayesian NMF objectives that fail to\nprovide a principled understanding of the non-identifiability inherent in NMF--\nan issue ideally addressed by a Bayesian approach. Despite their suitability,\ncurrent Bayesian NMF approaches have failed to gain popularity in an applied\nsetting; they sacrifice flexibility in modeling for tractable computation, tend\nto get stuck in local modes, and require many thousands of samples for\nmeaningful uncertainty estimates. We address these issues through a\nparticle-based variational approach to Bayesian NMF that only requires the\njoint likelihood to be differentiable for tractability, uses a novel\ninitialization technique to identify multiple modes in the posterior, and\nallows domain experts to inspect a `small' set of factorizations that\nfaithfully represent the posterior. We introduce and employ a class of\nlikelihood and prior distributions for NMF that formulate a Bayesian model\nusing popular non-Bayesian NMF objectives. On several real datasets, we obtain\nbetter particle approximations to the Bayesian NMF posterior in less time than\nbaselines and demonstrate the significant role that multimodality plays in\nNMF-related tasks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 17:20:19 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Masood", "M. Arjumand", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1803.06328", "submitter": "Tom Rainforth", "authors": "Tom Rainforth", "title": "Nesting Probabilistic Programs", "comments": "Published at UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.PL stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the notion of nesting probabilistic programming queries and\ninvestigate the resulting statistical implications. We demonstrate that while\nquery nesting allows the definition of models which could not otherwise be\nexpressed, such as those involving agents reasoning about other agents,\nexisting systems take approaches which lead to inconsistent estimates. We show\nhow to correct this by delineating possible ways one might want to nest queries\nand asserting the respective conditions required for convergence. We further\nintroduce a new online nested Monte Carlo estimator that makes it substantially\neasier to ensure these conditions are met, thereby providing a simple framework\nfor designing statistically correct inference engines. We prove the correctness\nof this online estimator and show that, when using the recommended setup, its\nasymptotic variance is always better than that of the equivalent fixed\nestimator, while its bias is always within a factor of two.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 17:30:35 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 14:48:32 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Rainforth", "Tom", ""]]}, {"id": "1803.06344", "submitter": "Andr\\'e Gensler", "authors": "Andr\\'e Gensler, Bernhard Sick", "title": "A Multi-Scheme Ensemble Using Coopetitive Soft-Gating With Application\n  to Power Forecasting for Renewable Energy Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a novel ensemble technique with a multi-scheme\nweighting based on a technique called coopetitive soft gating. This technique\ncombines both, ensemble member competition and cooperation, in order to\nmaximize the overall forecasting accuracy of the ensemble. The proposed\nalgorithm combines the ideas of multiple ensemble paradigms (power forecasting\nmodel ensemble, weather forecasting model ensemble, and lagged ensemble) in a\nhierarchical structure. The technique is designed to be used in a flexible\nmanner on single and multiple weather forecasting models, and for a variety of\nlead times. We compare the technique to other power forecasting models and\nensemble techniques with a flexible number of weather forecasting models, which\ncan have the same, or varying forecasting horizons. It is shown that the model\nis able to outperform those models on a number of publicly available data sets.\nThe article closes with a discussion of properties of the proposed model which\nare relevant in its application.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 14:23:37 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Gensler", "Andr\u00e9", ""], ["Sick", "Bernhard", ""]]}, {"id": "1803.06373", "submitter": "Harini Kannan", "authors": "Harini Kannan, Alexey Kurakin, Ian Goodfellow", "title": "Adversarial Logit Pairing", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop improved techniques for defending against\nadversarial examples at scale. First, we implement the state of the art version\nof adversarial training at unprecedented scale on ImageNet and investigate\nwhether it remains effective in this setting - an important open scientific\nquestion (Athalye et al., 2018). Next, we introduce enhanced defenses using a\ntechnique we call logit pairing, a method that encourages logits for pairs of\nexamples to be similar. When applied to clean examples and their adversarial\ncounterparts, logit pairing improves accuracy on adversarial examples over\nvanilla adversarial training; we also find that logit pairing on clean examples\nonly is competitive with adversarial training in terms of accuracy on two\ndatasets. Finally, we show that adversarial logit pairing achieves the state of\nthe art defense on ImageNet against PGD white box attacks, with an accuracy\nimprovement from 1.5% to 27.9%. Adversarial logit pairing also successfully\ndamages the current state of the art defense against black box attacks on\nImageNet (Tramer et al., 2018), dropping its accuracy from 66.6% to 47.1%. With\nthis new accuracy drop, adversarial logit pairing ties with Tramer et al.(2018)\nfor the state of the art on black box attacks on ImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 19:03:45 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Kannan", "Harini", ""], ["Kurakin", "Alexey", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1803.06386", "submitter": "Akbar Siami Namin", "authors": "Sima Siami-Namini and Akbar Siami Namin", "title": "Forecasting Economics and Financial Time Series: ARIMA vs. LSTM", "comments": "19 pages, 2 figures, 1 diagram, 2 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting time series data is an important subject in economics, business,\nand finance. Traditionally, there are several techniques to effectively\nforecast the next lag of time series data such as univariate Autoregressive\n(AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and\nmore notably Autoregressive Integrated Moving Average (ARIMA) with its many\nvariations. In particular, ARIMA model has demonstrated its outperformance in\nprecision and accuracy of predicting the next lags of time series. With the\nrecent advancement in computational power of computers and more importantly\ndeveloping more advanced machine learning algorithms and approaches such as\ndeep learning, new algorithms are developed to forecast time series data. The\nresearch question investigated in this article is that whether and how the\nnewly developed deep learning-based algorithms for forecasting time series\ndata, such as \"Long Short-Term Memory (LSTM)\", are superior to the traditional\nalgorithms. The empirical studies conducted and reported in this article show\nthat deep learning-based algorithms such as LSTM outperform traditional-based\nalgorithms such as ARIMA model. More specifically, the average reduction in\nerror rates obtained by LSTM is between 84 - 87 percent when compared to ARIMA\nindicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that\nthe number of training times, known as \"epoch\" in deep learning, has no effect\non the performance of the trained forecast model and it exhibits a truly random\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 20:01:48 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Siami-Namini", "Sima", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1803.06396", "submitter": "Renjie Liao", "authors": "Renjie Liao, Yuwen Xiong, Ethan Fetaya, Lisa Zhang, KiJung Yoon, Xaq\n  Pitkow, Raquel Urtasun, Richard Zemel", "title": "Reviving and Improving Recurrent Back-Propagation", "comments": "International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the recurrent back-propagation (RBP) algorithm,\ndiscuss the conditions under which it applies as well as how to satisfy them in\ndeep neural networks. We show that RBP can be unstable and propose two variants\nbased on conjugate gradient on the normal equations (CG-RBP) and Neumann series\n(Neumann-RBP). We further investigate the relationship between Neumann-RBP and\nback propagation through time (BPTT) and its truncated version (TBPTT). Our\nNeumann-RBP has the same time complexity as TBPTT but only requires constant\nmemory, whereas TBPTT's memory cost scales linearly with the number of\ntruncation steps. We examine all RBP variants along with BPTT and TBPTT in\nthree different application domains: associative memory with continuous\nHopfield networks, document classification in citation networks using graph\nneural networks and hyperparameter optimization for fully connected networks.\nAll experiments demonstrate that RBPs, especially the Neumann-RBP variant, are\nefficient and effective for optimizing convergent recurrent neural networks.\nCode is released at: \\url{https://github.com/lrjconan/RBP}.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 20:57:36 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 17:03:55 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 03:15:02 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 03:12:40 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Liao", "Renjie", ""], ["Xiong", "Yuwen", ""], ["Fetaya", "Ethan", ""], ["Zhang", "Lisa", ""], ["Yoon", "KiJung", ""], ["Pitkow", "Xaq", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""]]}, {"id": "1803.06401", "submitter": "Tzai-Shuen Chen", "authors": "Tzai-Shuen Chen", "title": "Evaluating Conditional Cash Transfer Policies with Machine Learning\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an out-of-sample prediction comparison between major\nmachine learning models and the structural econometric model. Over the past\ndecade, machine learning has established itself as a powerful tool in many\nprediction applications, but this approach is still not widely adopted in\nempirical economic studies. To evaluate the benefits of this approach, I use\nthe most common machine learning algorithms, CART, C4.5, LASSO, random forest,\nand adaboost, to construct prediction models for a cash transfer experiment\nconducted by the Progresa program in Mexico, and I compare the prediction\nresults with those of a previous structural econometric study. Two prediction\ntasks are performed in this paper: the out-of-sample forecast and the long-term\nwithin-sample simulation. For the out-of-sample forecast, both the mean\nabsolute error and the root mean square error of the school attendance rates\nfound by all machine learning models are smaller than those found by the\nstructural model. Random forest and adaboost have the highest accuracy for the\nindividual outcomes of all subgroups. For the long-term within-sample\nsimulation, the structural model has better performance than do all of the\nmachine learning models. The poor within-sample fitness of the machine learning\nmodel results from the inaccuracy of the income and pregnancy prediction\nmodels. The result shows that the machine learning model performs better than\ndoes the structural model when there are many data to learn; however, when the\ndata are limited, the structural model offers a more sensible prediction. The\nfindings of this paper show promise for adopting machine learning in economic\npolicy analyses in the era of big data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 21:14:02 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Chen", "Tzai-Shuen", ""]]}, {"id": "1803.06407", "submitter": "Calvin Murdock", "authors": "Calvin Murdock, Ming-Fang Chang, Simon Lucey", "title": "Deep Component Analysis via Alternating Direction Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a lack of theoretical understanding, deep neural networks have\nachieved unparalleled performance in a wide range of applications. On the other\nhand, shallow representation learning with component analysis is associated\nwith rich intuition and theory, but smaller capacity often limits its\nusefulness. To bridge this gap, we introduce Deep Component Analysis (DeepCA),\nan expressive multilayer model formulation that enforces hierarchical structure\nthrough constraints on latent variables in each layer. For inference, we\npropose a differentiable optimization algorithm implemented using recurrent\nAlternating Direction Neural Networks (ADNNs) that enable parameter learning\nusing standard backpropagation. By interpreting feed-forward networks as\nsingle-iteration approximations of inference in our model, we provide both a\nnovel theoretical perspective for understanding them and a practical technique\nfor constraining predictions with prior knowledge. Experimentally, we\ndemonstrate performance improvements on a variety of tasks, including\nsingle-image depth prediction with sparse output constraints.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 21:40:02 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Murdock", "Calvin", ""], ["Chang", "Ming-Fang", ""], ["Lucey", "Simon", ""]]}, {"id": "1803.06441", "submitter": "Hau-tieng Wu", "authors": "Chunyu Tan, Liming Zhang, Hau-tieng Wu", "title": "A Novel Blaschke Unwinding Adaptive Fourier Decomposition based Signal\n  Compression Algorithm with Application on ECG Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel signal compression algorithm based on the\nBlaschke unwinding adaptive Fourier decomposition (AFD). The Blaschke unwinding\nAFD is a newly developed signal decomposition theory. It utilizes the\nNevanlinna factorization and the maximal selection principle in each\ndecomposition step, and achieves a faster convergence rate with higher\nfidelity. The proposed compression algorithm is applied to the\nelectrocardiogram signal. To assess the performance of the proposed compression\nalgorithm, in addition to the generic assessment criteria, we consider the less\ndiscussed criteria related to the clinical needs -- for the heart rate\nvariability analysis purpose, how accurate the R peak information is preserved\nis evaluated. The experiments are conducted on the MIT-BIH arrhythmia benchmark\ndatabase. The results show that the proposed algorithm performs better than\nother state-of-the-art approaches. Meanwhile, it also well preserves the R peak\ninformation.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 01:33:33 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Tan", "Chunyu", ""], ["Zhang", "Liming", ""], ["Wu", "Hau-tieng", ""]]}, {"id": "1803.06443", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Shaoduo Gan, Ce Zhang, Tong Zhang, Ji Liu", "title": "Communication Compression for Decentralized Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing distributed learning systems is an art of balancing between\ncomputation and communication. There have been two lines of research that try\nto deal with slower networks: {\\em communication compression} for low bandwidth\nnetworks, and {\\em decentralization} for high latency networks. In this paper,\nWe explore a natural question: {\\em can the combination of both techniques lead\nto a system that is robust to both bandwidth and latency?}\n  Although the system implication of such combination is trivial, the\nunderlying theoretical principle and algorithm design is challenging: unlike\ncentralized algorithms, simply compressing exchanged information, even in an\nunbiased stochastic way, within the decentralized network would accumulate the\nerror and fail to converge. In this paper, we develop a framework of\ncompressed, decentralized training and propose two different strategies, which\nwe call {\\em extrapolation compression} and {\\em difference compression}. We\nanalyze both algorithms and prove both converge at the rate of $O(1/\\sqrt{nT})$\nwhere $n$ is the number of workers and $T$ is the number of iterations,\nmatching the convergence rate for full precision, centralized training. We\nvalidate our algorithms and find that our proposed algorithm outperforms the\nbest of merely decentralized and merely quantized algorithm significantly for\nnetworks with {\\em both} high latency and low bandwidth.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 01:51:09 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 00:15:49 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2018 23:10:01 GMT"}, {"version": "v4", "created": "Mon, 31 Dec 2018 21:20:01 GMT"}, {"version": "v5", "created": "Thu, 31 Jan 2019 20:20:32 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Tang", "Hanlin", ""], ["Gan", "Shaoduo", ""], ["Zhang", "Ce", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""]]}, {"id": "1803.06449", "submitter": "Hannah Wayment-Steele", "authors": "Hannah K. Wayment-Steele and Vijay S. Pande", "title": "Note: Variational Encoding of Protein Dynamics Benefits from Maximizing\n  Latent Autocorrelation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep Variational Auto-Encoder (VAE) frameworks become more widely used for\nmodeling biomolecular simulation data, we emphasize the capability of the VAE\narchitecture to concurrently maximize the timescale of the latent space while\ninferring a reduced coordinate, which assists in finding slow processes as\naccording to the variational approach to conformational dynamics. We\nadditionally provide evidence that the VDE framework (Hern\\'andez et al.,\n2017), which uses this autocorrelation loss along with a time-lagged\nreconstruction loss, obtains a variationally optimized latent coordinate in\ncomparison with related loss functions. We thus recommend leveraging the\nautocorrelation of the latent space while training neural network models of\nbiomolecular simulation data to better represent slow processes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 03:27:31 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Wayment-Steele", "Hannah K.", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1803.06453", "submitter": "Sathya N. Ravi", "authors": "Sathya N. Ravi, Tuan Dinh, Vishnu Lokhande, Vikas Singh", "title": "Constrained Deep Learning using Conditional Gradient and Applications in\n  Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of results have recently demonstrated the benefits of incorporating\nvarious constraints when training deep architectures in vision and machine\nlearning. The advantages range from guarantees for statistical generalization\nto better accuracy to compression. But support for general constraints within\nwidely used libraries remains scarce and their broader deployment within many\napplications that can benefit from them remains under-explored. Part of the\nreason is that Stochastic gradient descent (SGD), the workhorse for training\ndeep neural networks, does not natively deal with constraints with global scope\nvery well. In this paper, we revisit a classical first order scheme from\nnumerical optimization, Conditional Gradients (CG), that has, thus far had\nlimited applicability in training deep models. We show via rigorous analysis\nhow various constraints can be naturally handled by modifications of this\nalgorithm. We provide convergence guarantees and show a suite of immediate\nbenefits that are possible -- from training ResNets with fewer layers but\nbetter accuracy simply by substituting in our version of CG to faster training\nof GANs with 50% fewer epochs in image inpainting applications to provably\nbetter generalization guarantees using efficiently implementable forms of\nrecently proposed regularizers.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 03:59:34 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ravi", "Sathya N.", ""], ["Dinh", "Tuan", ""], ["Lokhande", "Vishnu", ""], ["Singh", "Vikas", ""]]}, {"id": "1803.06460", "submitter": "Aleksandr Aravkin", "authors": "Jize Zhang, Tim Leung and Aleksandr Y. Aravkin", "title": "Mean Reverting Portfolios via Penalized OU-Likelihood Estimation", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an optimization-based approach to con- struct a mean-reverting\nportfolio of assets. Our objectives are threefold: (1) design a portfolio that\nis well-represented by an Ornstein-Uhlenbeck process with parameters estimated\nby maximum likelihood, (2) select portfolios with desirable characteristics of\nhigh mean reversion and low variance, and (3) select a parsimonious portfolio,\ni.e. find a small subset of a larger universe of assets that can be used for\nlong and short positions. We present the full problem formulation, a\nspecialized algorithm that exploits partial minimization, and numerical\nexamples using both simulated and empirical price data.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 04:36:27 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Zhang", "Jize", ""], ["Leung", "Tim", ""], ["Aravkin", "Aleksandr Y.", ""]]}, {"id": "1803.06510", "submitter": "Yingjie Fei", "authors": "Yingjie Fei and Yudong Chen", "title": "Hidden Integrality of SDP Relaxation for Sub-Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the discrete clustering structures\nunder Sub-Gaussian Mixture Models. Our main results establish a hidden\nintegrality property of a semidefinite programming (SDP) relaxation for this\nproblem: while the optimal solutions to the SDP are not integer-valued in\ngeneral, their estimation errors can be upper bounded in terms of the error of\nan idealized integer program. The error of the integer program, and hence that\nof the SDP, are further shown to decay exponentially in the signal-to-noise\nratio. To the best of our knowledge, this is the first exponentially decaying\nerror bound for convex relaxations of mixture models, and our results reveal\nthe \"global-to-local\" mechanism that drives the performance of the SDP\nrelaxation.\n  A corollary of our results shows that in certain regimes the SDP solutions\nare in fact integral and exact, improving on existing exact recovery results\nfor convex relaxations. More generally, our results establish sufficient\nconditions for the SDP to correctly recover the cluster memberships of\n$(1-\\delta)$ fraction of the points for any $\\delta\\in(0,1)$. As a special\ncase, we show that under the $d$-dimensional Stochastic Ball Model, SDP\nachieves non-trivial (sometimes exact) recovery when the center separation is\nas small as $\\sqrt{1/d}$, which complements previous exact recovery results\nthat require constant separation.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 14:11:13 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Fei", "Yingjie", ""], ["Chen", "Yudong", ""]]}, {"id": "1803.06518", "submitter": "Eric Chi", "authors": "Eric C. Chi and Brian R. Gaines and Will Wei Sun and Hua Zhou and Jian\n  Yang", "title": "Provable Convex Co-clustering of Tensors", "comments": "to appear in Journal of Machine Learning Research", "journal-ref": "Journal of Machine Learning Research, 21(214):1-58, 2020", "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster analysis is a fundamental tool for pattern discovery of complex\nheterogeneous data. Prevalent clustering methods mainly focus on vector or\nmatrix-variate data and are not applicable to general-order tensors, which\narise frequently in modern scientific and business applications. Moreover,\nthere is a gap between statistical guarantees and computational efficiency for\nexisting tensor clustering solutions due to the nature of their non-convex\nformulations. In this work, we bridge this gap by developing a provable convex\nformulation of tensor co-clustering. Our convex co-clustering (CoCo) estimator\nenjoys stability guarantees and its computational and storage costs are\npolynomial in the size of the data. We further establish a non-asymptotic error\nbound for the CoCo estimator, which reveals a surprising \"blessing of\ndimensionality\" phenomenon that does not exist in vector or matrix-variate\ncluster analysis. Our theoretical findings are supported by extensive simulated\nstudies. Finally, we apply the CoCo estimator to the cluster analysis of\nadvertisement click tensor data from a major online company. Our clustering\nresults provide meaningful business insights to improve advertising\neffectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 15:15:28 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 16:53:43 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Chi", "Eric C.", ""], ["Gaines", "Brian R.", ""], ["Sun", "Will Wei", ""], ["Zhou", "Hua", ""], ["Yang", "Jian", ""]]}, {"id": "1803.06521", "submitter": "Sitan Chen", "authors": "Sitan Chen, Ankur Moitra", "title": "Beyond the Low-Degree Algorithm: Mixtures of Subcubes and Their\n  Applications", "comments": "62 pages; to appear in STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of learning mixtures of $k$ subcubes over\n$\\{0,1\\}^n$, which contains many classic learning theory problems as a special\ncase (and is itself a special case of others). We give a surprising $n^{O(\\log\nk)}$-time learning algorithm based on higher-order multilinear moments. It is\nnot possible to learn the parameters because the same distribution can be\nrepresented by quite different models. Instead, we develop a framework for\nreasoning about how multilinear moments can pinpoint essential features of the\nmixture, like the number of components.\n  We also give applications of our algorithm to learning decision trees with\nstochastic transitions (which also capture interesting scenarios where the\ntransitions are deterministic but there are latent variables). Using our\nalgorithm for learning mixtures of subcubes, we can approximate the Bayes\noptimal classifier within additive error $\\epsilon$ on $k$-leaf decision trees\nwith at most $s$ stochastic transitions on any root-to-leaf path in $n^{O(s +\n\\log k)}\\cdot\\text{poly}(1/\\epsilon)$ time. In this stochastic setting, the\nclassic Occam algorithms for learning decision trees with zero stochastic\ntransitions break down, while the low-degree algorithm of Linial et al.\ninherently has a quasipolynomial dependence on $1/\\epsilon$.\n  In contrast, as we will show, mixtures of $k$ subcubes are uniquely\ndetermined by their degree $2 \\log k$ moments and hence provide a useful\nabstraction for simultaneously achieving the polynomial dependence on\n$1/\\epsilon$ of the classic Occam algorithms for decision trees and the\nflexibility of the low-degree algorithm in being able to accommodate stochastic\ntransitions. Using our multilinear moment techniques, we also give the first\nimproved upper and lower bounds since the work of Feldman et al. for the\nrelated but harder problem of learning mixtures of binary product\ndistributions.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 15:26:04 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 17:43:48 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Chen", "Sitan", ""], ["Moitra", "Ankur", ""]]}, {"id": "1803.06531", "submitter": "Deepjyoti Deka", "authors": "Deepjyoti Deka, Michael Chertkov, Scott Backhaus", "title": "Topology Estimation using Graphical Models in Multi-Phase Power\n  Distribution Grids", "comments": "12 pages 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution grid is the medium and low voltage part of a large power system.\nStructurally, the majority of distribution networks operate radially, such that\nenergized lines form a collection of trees, i.e. forest, with a substation\nbeing at the root of any tree. The operational topology/forest may change from\ntime to time, however tracking these changes, even though important for the\ndistribution grid operation and control, is hindered by limited real-time\nmonitoring. This paper develops a learning framework to reconstruct radial\noperational structure of the distribution grid from synchronized voltage\nmeasurements in the grid subject to the exogenous fluctuations in nodal power\nconsumption. To detect operational lines our learning algorithm uses\nconditional independence tests for continuous random variables that is\napplicable to a wide class of probability distributions of the nodal\nconsumption and Gaussian injections in particular. Moreover, our algorithm\napplies to the practical case of unbalanced three-phase power flow. Algorithm\nperformance is validated on AC power flow simulations over IEEE distribution\ngrid test cases.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 16:18:40 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 15:43:51 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Deka", "Deepjyoti", ""], ["Chertkov", "Michael", ""], ["Backhaus", "Scott", ""]]}, {"id": "1803.06561", "submitter": "Chen Yu", "authors": "Chen Yu, Bojan Karlas, Jie Zhong, Ce Zhang, Ji Liu", "title": "AutoML from Service Provider's Perspective: Multi-device, Multi-tenant\n  Model Selection with GP-EI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AutoML has become a popular service that is provided by most leading cloud\nservice providers today. In this paper, we focus on the AutoML problem from the\n\\emph{service provider's perspective}, motivated by the following practical\nconsideration: When an AutoML service needs to serve {\\em multiple users} with\n{\\em multiple devices} at the same time, how can we allocate these devices to\nusers in an efficient way? We focus on GP-EI, one of the most popular\nalgorithms for automatic model selection and hyperparameter tuning, used by\nsystems such as Google Vizer. The technical contribution of this paper is the\nfirst multi-device, multi-tenant algorithm for GP-EI that is aware of\n\\emph{multiple} computation devices and multiple users sharing the same set of\ncomputation devices. Theoretically, given $N$ users and $M$ devices, we obtain\na regret bound of $O((\\text{\\bf {MIU}}(T,K) + M)\\frac{N^2}{M})$, where\n$\\text{\\bf {MIU}}(T,K)$ refers to the maximal incremental uncertainty up to\ntime $T$ for the covariance matrix $K$. Empirically, we evaluate our algorithm\non two applications of automatic model selection, and show that our algorithm\nsignificantly outperforms the strategy of serving users independently.\nMoreover, when multiple computation devices are available, we achieve\nnear-linear speedup when the number of users is much larger than the number of\ndevices.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 19:56:18 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 01:02:26 GMT"}, {"version": "v3", "created": "Sun, 28 Oct 2018 02:59:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Yu", "Chen", ""], ["Karlas", "Bojan", ""], ["Zhong", "Jie", ""], ["Zhang", "Ce", ""], ["Liu", "Ji", ""]]}, {"id": "1803.06567", "submitter": "Krishnamurthy Dvijotham", "authors": "Krishnamurthy (Dj) Dvijotham, Robert Stanforth, Sven Gowal, Timothy\n  Mann, Pushmeet Kohli", "title": "A Dual Approach to Scalable Verification of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of formally verifying desirable properties\nof neural networks, i.e., obtaining provable guarantees that neural networks\nsatisfy specifications relating their inputs and outputs (robustness to bounded\nnorm adversarial perturbations, for example). Most previous work on this topic\nwas limited in its applicability by the size of the network, network\narchitecture and the complexity of properties to be verified. In contrast, our\nframework applies to a general class of activation functions and specifications\non neural network inputs and outputs. We formulate verification as an\noptimization problem (seeking to find the largest violation of the\nspecification) and solve a Lagrangian relaxation of the optimization problem to\nobtain an upper bound on the worst case violation of the specification being\nverified. Our approach is anytime i.e. it can be stopped at any time and a\nvalid bound on the maximum violation can be obtained. We develop specialized\nverification algorithms with provable tightness guarantees under special\nassumptions and demonstrate the practical significance of our general\nverification approach on a variety of verification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 20:13:28 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 17:41:19 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Krishnamurthy", "", "", "Dj"], ["Dvijotham", "", ""], ["Stanforth", "Robert", ""], ["Gowal", "Sven", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1803.06585", "submitter": "Yibo Lin", "authors": "Jiong Zhang, Yibo Lin, Zhao Song, Inderjit S. Dhillon", "title": "Learning Long Term Dependencies via Fourier Recurrent Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is a known fact that training recurrent neural networks for tasks that\nhave long term dependencies is challenging. One of the main reasons is the\nvanishing or exploding gradient problem, which prevents gradient information\nfrom propagating to early layers. In this paper we propose a simple recurrent\narchitecture, the Fourier Recurrent Unit (FRU), that stabilizes the gradients\nthat arise in its training while giving us stronger expressive power.\nSpecifically, FRU summarizes the hidden states $h^{(t)}$ along the temporal\ndimension with Fourier basis functions. This allows gradients to easily reach\nany layer due to FRU's residual learning structure and the global support of\ntrigonometric functions. We show that FRU has gradient lower and upper bounds\nindependent of temporal dimension. We also show the strong expressivity of\nsparse Fourier basis, from which FRU obtains its strong expressive power. Our\nexperimental study also demonstrates that with fewer parameters the proposed\narchitecture outperforms other recurrent architectures on many tasks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 23:06:31 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Zhang", "Jiong", ""], ["Lin", "Yibo", ""], ["Song", "Zhao", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1803.06586", "submitter": "Christopher Tosh", "authors": "Christopher Tosh, Sanjoy Dasgupta", "title": "Structural query-by-committee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we describe a framework that unifies many different interactive\nlearning tasks. We present a generalization of the {\\it query-by-committee}\nactive learning algorithm for this setting, and we study its consistency and\nrate of convergence, both theoretically and empirically, with and without\nnoise.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 23:39:57 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Tosh", "Christopher", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "1803.06589", "submitter": "Reza Sadeghi", "authors": "Reza Sadeghi, Tanvi Banerjee, William Romine", "title": "Early hospital mortality prediction using vital signals", "comments": "11 pages, 5 figures, preprint of accepted paper in IEEE&ACM CHASE\n  2018 and published in Smart Health journal", "journal-ref": "Smart Health 9-10 (2018) 265-274", "doi": "10.1016/j.smhl.2018.07.001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early hospital mortality prediction is critical as intensivists strive to\nmake efficient medical decisions about the severely ill patients staying in\nintensive care units. As a result, various methods have been developed to\naddress this problem based on clinical records. However, some of the laboratory\ntest results are time-consuming and need to be processed. In this paper, we\npropose a novel method to predict mortality using features extracted from the\nheart signals of patients within the first hour of ICU admission. In order to\npredict the risk, quantitative features have been computed based on the heart\nrate signals of ICU patients. Each signal is described in terms of 12\nstatistical and signal-based features. The extracted features are fed into\neight classifiers: decision tree, linear discriminant, logistic regression,\nsupport vector machine (SVM), random forest, boosted trees, Gaussian SVM, and\nK-nearest neighborhood (K-NN). To derive insight into the performance of the\nproposed method, several experiments have been conducted using the well-known\nclinical dataset named Medical Information Mart for Intensive Care III\n(MIMIC-III). The experimental results demonstrate the capability of the\nproposed method in terms of precision, recall, F1-score, and area under the\nreceiver operating characteristic curve (AUC). The decision tree classifier\nsatisfies both accuracy and interpretability better than the other classifiers,\nproducing an F1-score and AUC equal to 0.91 and 0.93, respectively. It\nindicates that heart rate signals can be used for predicting mortality in\npatients in the ICU, achieving a comparable performance with existing\npredictions that rely on high dimensional features from clinical records which\nneed to be processed and may contain missing information.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 00:35:42 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 06:06:50 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Sadeghi", "Reza", ""], ["Banerjee", "Tanvi", ""], ["Romine", "William", ""]]}, {"id": "1803.06604", "submitter": "Haichuan Yang", "authors": "Ke Ren, Haichuan Yang, Yu Zhao, Mingshan Xue, Hongyu Miao, Shuai\n  Huang, Ji Liu", "title": "A Robust AUC Maximization Framework with Simultaneous Outlier Detection\n  and Feature Selection for Positive-Unlabeled Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The positive-unlabeled (PU) classification is a common scenario in real-world\napplications such as healthcare, text classification, and bioinformatics, in\nwhich we only observe a few samples labeled as \"positive\" together with a large\nvolume of \"unlabeled\" samples that may contain both positive and negative\nsamples. Building robust classifier for the PU problem is very challenging,\nespecially for complex data where the negative samples overwhelm and mislabeled\nsamples or corrupted features exist. To address these three issues, we propose\na robust learning framework that unifies AUC maximization (a robust metric for\nbiased labels), outlier detection (for excluding wrong labels), and feature\nselection (for excluding corrupted features). The generalization error bounds\nare provided for the proposed model that give valuable insight into the\ntheoretical performance of the method and lead to useful practical guidance,\ne.g., to train a model, we find that the included unlabeled samples are\nsufficient as long as the sample size is comparable to the number of positive\nsamples in the training process. Empirical comparisons and two real-world\napplications on surgical site infection (SSI) and EEG seizure detection are\nalso conducted to show the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 05:09:53 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Ren", "Ke", ""], ["Yang", "Haichuan", ""], ["Zhao", "Yu", ""], ["Xue", "Mingshan", ""], ["Miao", "Hongyu", ""], ["Huang", "Shuai", ""], ["Liu", "Ji", ""]]}, {"id": "1803.06675", "submitter": "Xiaohan Yan", "authors": "Xiaohan Yan, Jacob Bien", "title": "Rare Feature Selection in High Dimensions", "comments": "42 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common in modern prediction problems for many predictor variables to be\ncounts of rarely occurring events. This leads to design matrices in which many\ncolumns are highly sparse. The challenge posed by such \"rare features\" has\nreceived little attention despite its prevalence in diverse areas, ranging from\nnatural language processing (e.g., rare words) to biology (e.g., rare species).\nWe show, both theoretically and empirically, that not explicitly accounting for\nthe rareness of features can greatly reduce the effectiveness of an analysis.\nWe next propose a framework for aggregating rare features into denser features\nin a flexible manner that creates better predictors of the response. Our\nstrategy leverages side information in the form of a tree that encodes feature\nsimilarity.\n  We apply our method to data from TripAdvisor, in which we predict the\nnumerical rating of a hotel based on the text of the associated review. Our\nmethod achieves high accuracy by making effective use of rare words; by\ncontrast, the lasso is unable to identify highly predictive words if they are\ntoo rare. A companion R package, called rare, implements our new estimator,\nusing the alternating direction method of multipliers.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 15:15:49 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 19:30:27 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Yan", "Xiaohan", ""], ["Bien", "Jacob", ""]]}, {"id": "1803.06716", "submitter": "Ilias Zadik", "authors": "David Gamarnik, Ilias Zadik", "title": "High Dimensional Linear Regression using Lattice Basis Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a high dimensional linear regression problem where the goal is to\nefficiently recover an unknown vector $\\beta^*$ from $n$ noisy linear\nobservations $Y=X\\beta^*+W \\in \\mathbb{R}^n$, for known $X \\in \\mathbb{R}^{n\n\\times p}$ and unknown $W \\in \\mathbb{R}^n$. Unlike most of the literature on\nthis model we make no sparsity assumption on $\\beta^*$. Instead we adopt a\nregularization based on assuming that the underlying vectors $\\beta^*$ have\nrational entries with the same denominator $Q \\in \\mathbb{Z}_{>0}$. We call\nthis $Q$-rationality assumption.\n  We propose a new polynomial-time algorithm for this task which is based on\nthe seminal Lenstra-Lenstra-Lovasz (LLL) lattice basis reduction algorithm. We\nestablish that under the $Q$-rationality assumption, our algorithm recovers\nexactly the vector $\\beta^*$ for a large class of distributions for the iid\nentries of $X$ and non-zero noise $W$. We prove that it is successful under\nsmall noise, even when the learner has access to only one observation ($n=1$).\nFurthermore, we prove that in the case of the Gaussian white noise for $W$,\n$n=o\\left(p/\\log p\\right)$ and $Q$ sufficiently large, our algorithm tolerates\na nearly optimal information-theoretic level of the noise.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 19:02:22 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 00:30:03 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Gamarnik", "David", ""], ["Zadik", "Ilias", ""]]}, {"id": "1803.06727", "submitter": "Evgeny Burnaev", "authors": "Alexander Korotin and Vladimir V'yugin and Evgeny Burnaev", "title": "Aggregating Strategies for Long-term Forecasting", "comments": "20 pages, 4 figures", "journal-ref": "PMLR 91:63-82, 2018", "doi": null, "report-no": null, "categories": "cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article is devoted to investigating the application of aggregating\nalgorithms to the problem of the long-term forecasting. We examine the classic\naggregating algorithms based on the exponential reweighing. For the general\nVovk's aggregating algorithm we provide its generalization for the long-term\nforecasting. For the special basic case of Vovk's algorithm we provide its two\nmodifications for the long-term forecasting. The first one is theoretically\nclose to an optimal algorithm and is based on replication of independent\ncopies. It provides the time-independent regret bound with respect to the best\nexpert in the pool. The second one is not optimal but is more practical and has\n$O(\\sqrt{T})$ regret bound, where $T$ is the length of the game.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 20:04:07 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Korotin", "Alexander", ""], ["V'yugin", "Vladimir", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1803.06773", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Vitchyr Pong, Aurick Zhou, Murtaza Dalal, Pieter\n  Abbeel, Sergey Levine", "title": "Composable Deep Reinforcement Learning for Robotic Manipulation", "comments": "Videos: https://sites.google.com/view/composing-real-world-policies/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning has been shown to exhibit good\nperformance in domains ranging from video games to simulated robotic\nmanipulation and locomotion. However, model-free methods are known to perform\npoorly when the interaction time with the environment is limited, as is the\ncase for most real-world robotic tasks. In this paper, we study how maximum\nentropy policies trained using soft Q-learning can be applied to real-world\nrobotic manipulation. The application of this method to real-world manipulation\nis facilitated by two important features of soft Q-learning. First, soft\nQ-learning can learn multimodal exploration strategies by learning policies\nrepresented by expressive energy-based models. Second, we show that policies\nlearned with soft Q-learning can be composed to create new policies, and that\nthe optimality of the resulting policy can be bounded in terms of the\ndivergence between the composed policies. This compositionality provides an\nespecially valuable tool for real-world manipulation, where constructing new\npolicies by composing existing skills can provide a large gain in efficiency\nover training from scratch. Our experimental evaluation demonstrates that soft\nQ-learning is substantially more sample efficient than prior model-free deep\nreinforcement learning methods, and that compositionality can be performed for\nboth simulated and real-world tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 01:17:16 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Pong", "Vitchyr", ""], ["Zhou", "Aurick", ""], ["Dalal", "Murtaza", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1803.06795", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang, Xin Yuan, Lawrence Carin", "title": "Nonlocal Low-Rank Tensor Factor Analysis for Image Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank signal modeling has been widely leveraged to capture non-local\ncorrelation in image processing applications. We propose a new method that\nemploys low-rank tensor factor analysis for tensors generated by grouped image\npatches. The low-rank tensors are fed into the alternative direction multiplier\nmethod (ADMM) to further improve image reconstruction. The motivating\napplication is compressive sensing (CS), and a deep convolutional architecture\nis adopted to approximate the expensive matrix inversion in CS applications. An\niterative algorithm based on this low-rank tensor factorization strategy,\ncalled NLR-TFA, is presented in detail. Experimental results on noiseless and\nnoisy CS measurements demonstrate the superiority of the proposed approach,\nespecially at low CS sampling rates.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 03:48:14 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Zhang", "Xinyuan", ""], ["Yuan", "Xin", ""], ["Carin", "Lawrence", ""]]}, {"id": "1803.06852", "submitter": "Furui Liu", "authors": "Furui Liu, Laiwan Chan", "title": "Confounder Detection in High Dimensional Linear Models using First\n  Moments of Spectral Measures", "comments": "Accepted at Neural Computation", "journal-ref": null, "doi": "10.1162/neco_a_01099", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the confounder detection problem in the linear model,\nwhere the target variable $Y$ is predicted using its $n$ potential causes\n$X_n=(x_1,...,x_n)^T$. Based on an assumption of rotation invariant generating\nprocess of the model, recent study shows that the spectral measure induced by\nthe regression coefficient vector with respect to the covariance matrix of\n$X_n$ is close to a uniform measure in purely causal cases, but it differs from\na uniform measure characteristically in the presence of a scalar confounder.\nThen, analyzing spectral measure pattern could help to detect confounding. In\nthis paper, we propose to use the first moment of the spectral measure for\nconfounder detection. We calculate the first moment of the regression vector\ninduced spectral measure, and compare it with the first moment of a uniform\nspectral measure, both defined with respect to the covariance matrix of $X_n$.\nThe two moments coincide in non-confounding cases, and differ from each other\nin the presence of confounding. This statistical causal-confounding asymmetry\ncan be used for confounder detection. Without the need of analyzing the\nspectral measure pattern, our method does avoid the difficulty of metric choice\nand multiple parameter optimization. Experiments on synthetic and real data\nshow the performance of this method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 10:00:47 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 14:23:57 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Liu", "Furui", ""], ["Chan", "Laiwan", ""]]}, {"id": "1803.06898", "submitter": "Yaniv Shachor", "authors": "Yaniv Shachor, Hayit Greenspan, Jacob Goldberger", "title": "A Mixture of Views Network with Applications to the Classification of\n  Breast Microcalcifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine data fusion methods for multi-view data\nclassification. We present a decision concept which explicitly takes into\naccount the input multi-view structure, where for each case there is a\ndifferent subset of relevant views. This data fusion concept, which we dub\nMixture of Views, is implemented by a special purpose neural network\narchitecture. It is demonstrated on the task of classifying breast\nmicrocalcifications as benign or malignant based on CC and MLO mammography\nviews. The single view decisions are combined by a data-driven decision,\naccording to the relevance of each view in a given case, into a global\ndecision. The method is evaluated on a large multi-view dataset extracted from\nthe standardized digital database for screening mammography (DDSM). The\nexperimental results show that our method outperforms previously suggested\nfusion methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 13:11:10 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Shachor", "Yaniv", ""], ["Greenspan", "Hayit", ""], ["Goldberger", "Jacob", ""]]}, {"id": "1803.06905", "submitter": "Hongyu Zhu", "authors": "Hongyu Zhu, Mohamed Akrout, Bojian Zheng, Andrew Pelegris, Amar\n  Phanishayee, Bianca Schroeder, and Gennady Pekhimenko", "title": "TBD: Benchmarking and Analyzing Deep Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent popularity of deep neural networks (DNNs) has generated a lot of\nresearch interest in performing DNN-related computation efficiently. However,\nthe primary focus is usually very narrow and limited to (i) inference -- i.e.\nhow to efficiently execute already trained models and (ii) image classification\nnetworks as the primary benchmark for evaluation.\n  Our primary goal in this work is to break this myopic view by (i) proposing a\nnew benchmark for DNN training, called TBD (TBD is short for Training Benchmark\nfor DNNs), that uses a representative set of DNN models that cover a wide range\nof machine learning applications: image classification, machine translation,\nspeech recognition, object detection, adversarial networks, reinforcement\nlearning, and (ii) by performing an extensive performance analysis of training\nthese different applications on three major deep learning frameworks\n(TensorFlow, MXNet, CNTK) across different hardware configurations (single-GPU,\nmulti-GPU, and multi-machine). TBD currently covers six major application\ndomains and eight different state-of-the-art models.\n  We present a new toolchain for performance analysis for these models that\ncombines the targeted usage of existing performance analysis tools, careful\nselection of new and existing metrics and methodologies to analyze the results,\nand utilization of domain specific characteristics of DNN training. We also\nbuild a new set of tools for memory profiling in all three major frameworks;\nmuch needed tools that can finally shed some light on precisely how much memory\nis consumed by different data structures (weights, activations, gradients,\nworkspace) in DNN training. By using our tools and methodologies, we make\nseveral important observations and recommendations on where the future research\nand optimization of DNN training should be focused.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 05:16:06 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 01:21:40 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zhu", "Hongyu", ""], ["Akrout", "Mohamed", ""], ["Zheng", "Bojian", ""], ["Pelegris", "Andrew", ""], ["Phanishayee", "Amar", ""], ["Schroeder", "Bianca", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "1803.06917", "submitter": "Justin Sirignano", "authors": "Justin Sirignano and Rama Cont", "title": "Universal features of price formation in financial markets: perspectives\n  from Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a large-scale Deep Learning approach applied to a high-frequency\ndatabase containing billions of electronic market quotes and transactions for\nUS equities, we uncover nonparametric evidence for the existence of a universal\nand stationary price formation mechanism relating the dynamics of supply and\ndemand for a stock, as revealed through the order book, to subsequent\nvariations in its market price. We assess the model by testing its\nout-of-sample predictions for the direction of price moves given the history of\nprice and order flow, across a wide range of stocks and time periods. The\nuniversal price formation model is shown to exhibit a remarkably stable\nout-of-sample prediction accuracy across time, for a wide range of stocks from\ndifferent sectors. Interestingly, these results also hold for stocks which are\nnot part of the training sample, showing that the relations captured by the\nmodel are universal and not asset-specific.\n  The universal model --- trained on data from all stocks --- outperforms, in\nterms of out-of-sample prediction accuracy, asset-specific linear and nonlinear\nmodels trained on time series of any given stock, showing that the universal\nnature of price formation weighs in favour of pooling together financial data\nfrom various stocks, rather than designing asset- or sector-specific models as\ncommonly done. Standard data normalizations based on volatility, price level or\naverage spread, or partitioning the training data into sectors or categories\nsuch as large/small tick stocks, do not improve training results. On the other\nhand, inclusion of price and order flow history over many past observations is\nshown to improve forecasting performance, showing evidence of path-dependence\nin price dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 13:46:37 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Sirignano", "Justin", ""], ["Cont", "Rama", ""]]}, {"id": "1803.06952", "submitter": "Silvia-Laura Pintea", "authors": "Silvia L. Pintea, and Jan C. van Gemert, and Arnold W. M. Smeulders", "title": "Asymmetric kernel in Gaussian Processes for learning target variance", "comments": "Accepted in Pattern Recognition Letters, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work incorporates the multi-modality of the data distribution into a\nGaussian Process regression model. We approach the problem from a\ndiscriminative perspective by learning, jointly over the training data, the\ntarget space variance in the neighborhood of a certain sample through metric\nlearning. We start by using data centers rather than all training samples.\nSubsequently, each center selects an individualized kernel metric. This enables\neach center to adjust the kernel space in its vicinity in correspondence with\nthe topology of the targets --- a multi-modal approach. We additionally add\ndescriptiveness by allowing each center to learn a precision matrix. We\ndemonstrate empirically the reliability of the model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:34:35 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Pintea", "Silvia L.", ""], ["van Gemert", "Jan C.", ""], ["Smeulders", "Arnold W. M.", ""]]}, {"id": "1803.06959", "submitter": "Ari Morcos", "authors": "Ari S. Morcos, David G.T. Barrett, Neil C. Rabinowitz, Matthew\n  Botvinick", "title": "On the importance of single directions for generalization", "comments": "ICLR 2018 conference paper; added additional methodological details", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their ability to memorize large datasets, deep neural networks often\nachieve good generalization performance. However, the differences between the\nlearned solutions of networks which generalize and those which do not remain\nunclear. Additionally, the tuning properties of single directions (defined as\nthe activation of a single unit or some linear combination of units in response\nto some input) have been highlighted, but their importance has not been\nevaluated. Here, we connect these lines of inquiry to demonstrate that a\nnetwork's reliance on single directions is a good predictor of its\ngeneralization performance, across networks trained on datasets with different\nfractions of corrupted labels, across ensembles of networks trained on datasets\nwith unmodified labels, across different hyperparameters, and over the course\nof training. While dropout only regularizes this quantity up to a point, batch\nnormalization implicitly discourages single direction reliance, in part by\ndecreasing the class selectivity of individual units. Finally, we find that\nclass selectivity is a poor predictor of task importance, suggesting not only\nthat networks which generalize well minimize their dependence on individual\nunits by reducing their selectivity, but also that individually selective units\nmay not be necessary for strong network performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:42:19 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 10:03:34 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 10:48:45 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 09:55:52 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Morcos", "Ari S.", ""], ["Barrett", "David G. T.", ""], ["Rabinowitz", "Neil C.", ""], ["Botvinick", "Matthew", ""]]}, {"id": "1803.06969", "submitter": "Marco Baity-Jesi", "authors": "M. Baity-Jesi, L. Sagun, M. Geiger, S. Spigler, G. Ben Arous, C.\n  Cammarota, Y. LeCun, M. Wyart, G. Biroli", "title": "Comparing Dynamics: Deep Neural Networks versus Glassy Systems", "comments": "10 pages, 5 figures. Version accepted at ICML 2018", "journal-ref": "PMLR 80:324-333, 2018; Republication with DOI (cite this one): J.\n  Stat. Mech. (2019) 124013", "doi": "10.1088/1742-5468/ab3281", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze numerically the training dynamics of deep neural networks (DNN) by\nusing methods developed in statistical physics of glassy systems. The two main\nissues we address are (1) the complexity of the loss landscape and of the\ndynamics within it, and (2) to what extent DNNs share similarities with glassy\nsystems. Our findings, obtained for different architectures and datasets,\nsuggest that during the training process the dynamics slows down because of an\nincreasingly large number of flat directions. At large times, when the loss is\napproaching zero, the system diffuses at the bottom of the landscape. Despite\nsome similarities with the dynamics of mean-field glassy systems, in\nparticular, the absence of barrier crossing, we find distinctive dynamical\nbehaviors in the two cases, showing that the statistical properties of the\ncorresponding loss and energy landscapes are different. In contrast, when the\nnetwork is under-parametrized we observe a typical glassy behavior, thus\nsuggesting the existence of different phases depending on whether the network\nis under-parametrized or over-parametrized.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:59:01 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 10:46:06 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Baity-Jesi", "M.", ""], ["Sagun", "L.", ""], ["Geiger", "M.", ""], ["Spigler", "S.", ""], ["Arous", "G. Ben", ""], ["Cammarota", "C.", ""], ["LeCun", "Y.", ""], ["Wyart", "M.", ""], ["Biroli", "G.", ""]]}, {"id": "1803.06971", "submitter": "Lilian Besson", "authors": "Lilian Besson (IETR), Emilie Kaufmann (SEQUEL, CNRS)", "title": "What Doubling Tricks Can and Can't Do for Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online reinforcement learning algorithm is anytime if it does not need to\nknow in advance the horizon T of the experiment. A well-known technique to\nobtain an anytime algorithm from any non-anytime algorithm is the \"Doubling\nTrick\". In the context of adversarial or stochastic multi-armed bandits, the\nperformance of an algorithm is measured by its regret, and we study two\nfamilies of sequences of growing horizons (geometric and exponential) to\ngeneralize previously known results that certain doubling tricks can be used to\nconserve certain regret bounds. In a broad setting, we prove that a geometric\ndoubling trick can be used to conserve (minimax) bounds in $R\\_T = O(\\sqrt{T})$\nbut cannot conserve (distribution-dependent) bounds in $R\\_T = O(\\log T)$. We\ngive insights as to why exponential doubling tricks may be better, as they\nconserve bounds in $R\\_T = O(\\log T)$, and are close to conserving bounds in\n$R\\_T = O(\\sqrt{T})$.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:02:15 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Besson", "Lilian", "", "IETR"], ["Kaufmann", "Emilie", "", "SEQUEL, CNRS"]]}, {"id": "1803.06978", "submitter": "Cihang Xie", "authors": "Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou\n  Ren, Alan Yuille", "title": "Improving Transferability of Adversarial Examples with Input Diversity", "comments": "CVPR 2019, code is available at:\n  https://github.com/cihangxie/DI-2-FGSM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though CNNs have achieved the state-of-the-art performance on various vision\ntasks, they are vulnerable to adversarial examples --- crafted by adding\nhuman-imperceptible perturbations to clean images. However, most of the\nexisting adversarial attacks only achieve relatively low success rates under\nthe challenging black-box setting, where the attackers have no knowledge of the\nmodel structure and parameters. To this end, we propose to improve the\ntransferability of adversarial examples by creating diverse input patterns.\nInstead of only using the original images to generate adversarial examples, our\nmethod applies random transformations to the input images at each iteration.\nExtensive experiments on ImageNet show that the proposed attack method can\ngenerate adversarial examples that transfer much better to different networks\nthan existing baselines. By evaluating our method against top defense solutions\nand official baselines from NIPS 2017 adversarial competition, the enhanced\nattack reaches an average success rate of 73.0%, which outperforms the top-1\nattack submission in the NIPS competition by a large margin of 6.6%. We hope\nthat our proposed attack strategy can serve as a strong benchmark baseline for\nevaluating the robustness of networks to adversaries and the effectiveness of\ndifferent defense methods in the future. Code is available at\nhttps://github.com/cihangxie/DI-2-FGSM.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:07:51 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 00:15:38 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 02:29:17 GMT"}, {"version": "v4", "created": "Sat, 1 Jun 2019 17:12:24 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Xie", "Cihang", ""], ["Zhang", "Zhishuai", ""], ["Zhou", "Yuyin", ""], ["Bai", "Song", ""], ["Wang", "Jianyu", ""], ["Ren", "Zhou", ""], ["Yuille", "Alan", ""]]}, {"id": "1803.06989", "submitter": "Stefan Steinerberger", "authors": "George C. Linderman, Stefan Steinerberger", "title": "Numerical Integration on Graphs: where to sample and how to weigh", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G=(V,E,w)$ be a finite, connected graph with weighted edges. We are\ninterested in the problem of finding a subset $W \\subset V$ of vertices and\nweights $a_w$ such that $$ \\frac{1}{|V|}\\sum_{v \\in V}^{}{f(v)} \\sim \\sum_{w\n\\in W}{a_w f(w)}$$ for functions $f:V \\rightarrow \\mathbb{R}$ that are `smooth'\nwith respect to the geometry of the graph. The main application are problems\nwhere $f$ is known to somehow depend on the underlying graph but is expensive\nto evaluate on even a single vertex. We prove an inequality showing that the\nintegration problem can be rewritten as a geometric problem (`the optimal\npacking of heat balls'). We discuss how one would construct approximate\nsolutions of the heat ball packing problem; numerical examples demonstrate the\nefficiency of the method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:27:59 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Linderman", "George C.", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "1803.06992", "submitter": "Elena Facco", "authors": "Elena Facco, Maria d'Errico, Alex Rodriguez, Alessandro Laio", "title": "Estimating the intrinsic dimension of datasets by a minimal neighborhood\n  information", "comments": "Scientific Reports 2017", "journal-ref": null, "doi": "10.1038/s41598-017-11873-y", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing large volumes of high-dimensional data is an issue of fundamental\nimportance in data science, molecular simulations and beyond. Several\napproaches work on the assumption that the important content of a dataset\nbelongs to a manifold whose Intrinsic Dimension (ID) is much lower than the\ncrude large number of coordinates. Such manifold is generally twisted and\ncurved, in addition points on it will be non-uniformly distributed: two factors\nthat make the identification of the ID and its exploitation really hard. Here\nwe propose a new ID estimator using only the distance of the first and the\nsecond nearest neighbor of each point in the sample. This extreme minimality\nenables us to reduce the effects of curvature, of density variation, and the\nresulting computational cost. The ID estimator is theoretically exact in\nuniformly distributed datasets, and provides consistent measures in general.\nWhen used in combination with block analysis, it allows discriminating the\nrelevant dimensions as a function of the block size. This allows estimating the\nID even when the data lie on a manifold perturbed by a high-dimensional noise,\na situation often encountered in real world data sets. We demonstrate the\nusefulness of the approach on molecular simulations and image analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:31:41 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Facco", "Elena", ""], ["d'Errico", "Maria", ""], ["Rodriguez", "Alex", ""], ["Laio", "Alessandro", ""]]}, {"id": "1803.07054", "submitter": "Nicolai Baldin", "authors": "Nicolai Baldin, Quentin Berthet", "title": "Optimal link prediction with matrix logistic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of link prediction, based on partial observation of a\nlarge network, and on side information associated to its vertices. The\ngenerative model is formulated as a matrix logistic regression. The performance\nof the model is analysed in a high-dimensional regime under a structural\nassumption. The minimax rate for the Frobenius-norm risk is established and a\ncombinatorial estimator based on the penalised maximum likelihood approach is\nshown to achieve it. Furthermore, it is shown that this rate cannot be attained\nby any (randomised) algorithm computable in polynomial time under a\ncomputational complexity assumption.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:32:50 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Baldin", "Nicolai", ""], ["Berthet", "Quentin", ""]]}, {"id": "1803.07055", "submitter": "Horia Mania", "authors": "Horia Mania, Aurelia Guy, Benjamin Recht", "title": "Simple random search provides a competitive approach to reinforcement\n  learning", "comments": "22 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common belief in model-free reinforcement learning is that methods based on\nrandom search in the parameter space of policies exhibit significantly worse\nsample complexity than those that explore the space of actions. We dispel such\nbeliefs by introducing a random search method for training static, linear\npolicies for continuous control problems, matching state-of-the-art sample\nefficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a\nnearly optimal controller for a challenging instance of the Linear Quadratic\nRegulator, a classical problem in control theory, when the dynamics are not\nknown. Computationally, our random search algorithm is at least 15 times more\nefficient than the fastest competing model-free methods on these benchmarks. We\ntake advantage of this computational efficiency to evaluate the performance of\nour method over hundreds of random seeds and many different hyperparameter\nconfigurations for each benchmark task. Our simulations highlight a high\nvariability in performance in these benchmark tasks, suggesting that commonly\nused estimations of sample efficiency do not adequately evaluate the\nperformance of RL algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:35:14 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Mania", "Horia", ""], ["Guy", "Aurelia", ""], ["Recht", "Benjamin", ""]]}, {"id": "1803.07067", "submitter": "Ashique Rupam Mahmood", "authors": "A. Rupam Mahmood, Dmytro Korenkevych, Brent J. Komer, James Bergstra", "title": "Setting up a Reinforcement Learning Task with a Real-World Robot", "comments": "Submitted to 2018 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach to developing hard-to-engineer\nadaptive solutions for complex and diverse robotic tasks. However, learning\nwith real-world robots is often unreliable and difficult, which resulted in\ntheir low adoption in reinforcement learning research. This difficulty is\nworsened by the lack of guidelines for setting up learning tasks with robots.\nIn this work, we develop a learning task with a UR5 robotic arm to bring to\nlight some key elements of a task setup and study their contributions to the\nchallenges with robots. We find that learning performance can be highly\nsensitive to the setup, and thus oversights and omissions in setup details can\nmake effective learning, reproducibility, and fair comparison hard. Our study\nsuggests some mitigating steps to help future experimenters avoid difficulties\nand pitfalls. We show that highly reliable and repeatable experiments can be\nperformed in our setup, indicating the possibility of reinforcement learning\nresearch extensively based on real-world robots.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:59:05 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Mahmood", "A. Rupam", ""], ["Korenkevych", "Dmytro", ""], ["Komer", "Brent J.", ""], ["Bergstra", "James", ""]]}, {"id": "1803.07068", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, Ji Liu", "title": "D$^2$: Decentralized Training over Decentralized Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While training a machine learning model using multiple workers, each of which\ncollects data from their own data sources, it would be most useful when the\ndata collected from different workers can be {\\em unique} and {\\em different}.\nIronically, recent analysis of decentralized parallel stochastic gradient\ndescent (D-PSGD) relies on the assumption that the data hosted on different\nworkers are {\\em not too different}. In this paper, we ask the question: {\\em\nCan we design a decentralized parallel stochastic gradient descent algorithm\nthat is less sensitive to the data variance across workers?} In this paper, we\npresent D$^2$, a novel decentralized parallel stochastic gradient descent\nalgorithm designed for large data variance \\xr{among workers} (imprecisely,\n\"decentralized\" data). The core of D$^2$ is a variance blackuction extension of\nthe standard D-PSGD algorithm, which improves the convergence rate from\n$O\\left({\\sigma \\over \\sqrt{nT}} + {(n\\zeta^2)^{\\frac{1}{3}} \\over\nT^{2/3}}\\right)$ to $O\\left({\\sigma \\over \\sqrt{nT}}\\right)$ where $\\zeta^{2}$\ndenotes the variance among data on different workers. As a result, D$^2$ is\nrobust to data variance among workers. We empirically evaluated D$^2$ on image\nclassification tasks where each worker has access to only the data of a limited\nset of labels, and find that D$^2$ significantly outperforms D-PSGD.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:59:11 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 00:13:16 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Tang", "Hanlin", ""], ["Lian", "Xiangru", ""], ["Yan", "Ming", ""], ["Zhang", "Ce", ""], ["Liu", "Ji", ""]]}, {"id": "1803.07102", "submitter": "Felipe Tobar", "authors": "Gonzalo Rios and Felipe Tobar", "title": "Learning non-Gaussian Time Series using the Box-Cox Gaussian Process", "comments": "Accepted at IEEE IJCNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are Bayesian nonparametric generative models that\nprovide interpretability of hyperparameters, admit closed-form expressions for\ntraining and inference, and are able to accurately represent uncertainty. To\nmodel general non-Gaussian data with complex correlation structure, GPs can be\npaired with an expressive covariance kernel and then fed into a nonlinear\ntransformation (or warping). However, overparametrising the kernel and the\nwarping is known to, respectively, hinder gradient-based training and make the\npredictions computationally expensive. We remedy this issue by (i) training the\nmodel using derivative-free global-optimisation techniques so as to find\nmeaningful maxima of the model likelihood, and (ii) proposing a warping\nfunction based on the celebrated Box-Cox transformation that requires minimal\nnumerical approximations---unlike existing warped GP models. We validate the\nproposed approach by first showing that predictions can be computed\nanalytically, and then on a learning, reconstruction and forecasting experiment\nusing real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 18:21:34 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Rios", "Gonzalo", ""], ["Tobar", "Felipe", ""]]}, {"id": "1803.07152", "submitter": "G\\'abor Petneh\\'azi", "authors": "G\\'abor Petneh\\'azi and J\\'ozsef G\\'all", "title": "Exploring the predictability of range-based volatility estimators using\n  RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the predictability of several range-based stock volatility\nestimators, and compare them to the standard close-to-close estimator which is\nmost commonly acknowledged as the volatility. The patterns of volatility\nchanges are analyzed using LSTM recurrent neural networks, which are a state of\nthe art method of sequence learning. We implement the analysis on all current\nconstituents of the Dow Jones Industrial Average index, and report averaged\nevaluation results. We find that changes in the values of range-based\nestimators are more predictable than that of the estimator using daily closing\nvalues only.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 20:31:09 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Petneh\u00e1zi", "G\u00e1bor", ""], ["G\u00e1ll", "J\u00f3zsef", ""]]}, {"id": "1803.07164", "submitter": "Vasilis Syrgkanis", "authors": "Greg Lewis, Vasilis Syrgkanis", "title": "Adversarial Generalized Method of Moments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.GT cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an approach for learning deep neural net representations of models\ndescribed via conditional moment restrictions. Conditional moment restrictions\nare widely used, as they are the language by which social scientists describe\nthe assumptions they make to enable causal inference. We formulate the problem\nof estimating the underling model as a zero-sum game between a modeler and an\nadversary and apply adversarial training. Our approach is similar in nature to\nGenerative Adversarial Networks (GAN), though here the modeler is learning a\nrepresentation of a function that satisfies a continuum of moment conditions\nand the adversary is identifying violating moments. We outline ways of\nconstructing effective adversaries in practice, including kernels centered by\nk-means clustering, and random forests. We examine the practical performance of\nour approach in the setting of non-parametric instrumental variable regression.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 21:02:51 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 13:27:54 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Lewis", "Greg", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1803.07192", "submitter": "Raunak Dey", "authors": "Raunak Dey, Zhongjie Lu, Yi Hong", "title": "Diagnostic Classification Of Lung Nodules Using 3D Neural Networks", "comments": "Accepted for publication in IEEE International Symposium on\n  Biomedical Imaging (ISBI) 2018 Copyright c 2018 IEEE", "journal-ref": null, "doi": "10.1109/ISBI.2018.8363687", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is the leading cause of cancer-related death worldwide. Early\ndiagnosis of pulmonary nodules in Computed Tomography (CT) chest scans provides\nan opportunity for designing effective treatment and making financial and care\nplans. In this paper, we consider the problem of diagnostic classification\nbetween benign and malignant lung nodules in CT images, which aims to learn a\ndirect mapping from 3D images to class labels. To achieve this goal, four\ntwo-pathway Convolutional Neural Networks (CNN) are proposed, including a basic\n3D CNN, a novel multi-output network, a 3D DenseNet, and an augmented 3D\nDenseNet with multi-outputs. These four networks are evaluated on the public\nLIDC-IDRI dataset and outperform most existing methods. In particular, the 3D\nmulti-output DenseNet (MoDenseNet) achieves the state-of-the-art classification\naccuracy on the task of end-to-end lung nodule diagnosis. In addition, the\nnetworks pretrained on the LIDC-IDRI dataset can be further extended to handle\nsmaller datasets using transfer learning. This is demonstrated on our dataset\nwith encouraging prediction accuracy in lung nodule classification.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 23:02:37 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Dey", "Raunak", ""], ["Lu", "Zhongjie", ""], ["Hong", "Yi", ""]]}, {"id": "1803.07200", "submitter": "Hamid Khodabandehlou", "authors": "Hamid Khodabandehlou and M. Sami Fadali", "title": "Training Recurrent Neural Networks as a Constraint Satisfaction Problem", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new approach for training artificial neural networks\nusing techniques for solving the constraint satisfaction problem (CSP). The\nquotient gradient system (QGS) is a trajectory-based method for solving the\nCSP. This study converts the training set of a neural network into a CSP and\nuses the QGS to find its solutions. The QGS finds the global minimum of the\noptimization problem by tracking trajectories of a nonlinear dynamical system\nand does not stop at a local minimum of the optimization problem. Lyapunov\ntheory is used to prove the asymptotic stability of the solutions with and\nwithout the presence of measurement errors. Numerical examples illustrate the\neffectiveness of the proposed methodology and compare it to a genetic algorithm\nand error backpropagation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 00:12:26 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 17:56:14 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 18:26:29 GMT"}, {"version": "v4", "created": "Tue, 3 Apr 2018 01:20:13 GMT"}, {"version": "v5", "created": "Tue, 17 Apr 2018 00:31:40 GMT"}, {"version": "v6", "created": "Sun, 6 May 2018 22:21:51 GMT"}, {"version": "v7", "created": "Mon, 14 May 2018 05:14:29 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Khodabandehlou", "Hamid", ""], ["Fadali", "M. Sami", ""]]}, {"id": "1803.07225", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Ga\\\"etan Hadjeres", "title": "Monte Carlo Information Geometry: The dually flat case", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential families and mixture families are parametric probability models\nthat can be geometrically studied as smooth statistical manifolds with respect\nto any statistical divergence like the Kullback-Leibler (KL) divergence or the\nHellinger divergence. When equipping a statistical manifold with the KL\ndivergence, the induced manifold structure is dually flat, and the KL\ndivergence between distributions amounts to an equivalent Bregman divergence on\ntheir corresponding parameters. In practice, the corresponding Bregman\ngenerators of mixture/exponential families require to perform definite integral\ncalculus that can either be too time-consuming (for exponentially large\ndiscrete support case) or even do not admit closed-form formula (for continuous\nsupport case). In these cases, the dually flat construction remains theoretical\nand cannot be used by information-geometric algorithms. To bypass this problem,\nwe consider performing stochastic Monte Carlo (MC) estimation of those\nintegral-based mixture/exponential family Bregman generators. We show that,\nunder natural assumptions, these MC generators are almost surely Bregman\ngenerators. We define a series of dually flat information geometries, termed\nMonte Carlo Information Geometries, that increasingly-finely approximate the\nuntractable geometry. The advantage of this MCIG is that it allows a practical\nuse of the Bregman algorithmic toolbox on a wide range of probability\ndistribution families. We demonstrate our approach with a clustering task on a\nmixture family manifold.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 02:39:37 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Nielsen", "Frank", ""], ["Hadjeres", "Ga\u00ebtan", ""]]}, {"id": "1803.07246", "submitter": "Cathy Wu", "authors": "Cathy Wu, Aravind Rajeswaran, Yan Duan, Vikash Kumar, Alexandre M\n  Bayen, Sham Kakade, Igor Mordatch, Pieter Abbeel", "title": "Variance Reduction for Policy Gradient with Action-Dependent Factorized\n  Baselines", "comments": "Accepted to ICLR 2018, Oral (2%)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have enjoyed great success in deep reinforcement\nlearning but suffer from high variance of gradient estimates. The high variance\nproblem is particularly exasperated in problems with long horizons or\nhigh-dimensional action spaces. To mitigate this issue, we derive a bias-free\naction-dependent baseline for variance reduction which fully exploits the\nstructural form of the stochastic policy itself and does not make any\nadditional assumptions about the MDP. We demonstrate and quantify the benefit\nof the action-dependent baseline through both theoretical analysis as well as\nnumerical results, including an analysis of the suboptimality of the optimal\nstate-dependent baseline. The result is a computationally efficient policy\ngradient algorithm, which scales to high-dimensional control problems, as\ndemonstrated by a synthetic 2000-dimensional target matching task. Our\nexperimental results indicate that action-dependent baselines allow for faster\nlearning on standard reinforcement learning benchmarks and high-dimensional\nhand manipulation and synthetic tasks. Finally, we show that the general idea\nof including additional information in baselines for improved variance\nreduction can be extended to partially observed and multi-agent tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 03:52:04 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wu", "Cathy", ""], ["Rajeswaran", "Aravind", ""], ["Duan", "Yan", ""], ["Kumar", "Vikash", ""], ["Bayen", "Alexandre M", ""], ["Kakade", "Sham", ""], ["Mordatch", "Igor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1803.07247", "submitter": "Ziping Zhao", "authors": "Ziping Zhao, Daniel P. Palomar", "title": "Sparse Reduced Rank Regression With Nonconvex Regularization", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.CP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the estimation problem for sparse reduced rank regression\n(SRRR) model is considered. The SRRR model is widely used for dimension\nreduction and variable selection with applications in signal processing,\neconometrics, etc. The problem is formulated to minimize the least squares loss\nwith a sparsity-inducing penalty considering an orthogonality constraint.\nConvex sparsity-inducing functions have been used for SRRR in literature. In\nthis work, a nonconvex function is proposed for better sparsity inducing. An\nefficient algorithm is developed based on the alternating minimization (or\nprojection) method to solve the nonconvex optimization problem. Numerical\nsimulations show that the proposed algorithm is much more efficient compared to\nthe benchmark methods and the nonconvex function can result in a better\nestimation accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 04:07:02 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Zhao", "Ziping", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "1803.07276", "submitter": "Zhenglin Wu", "authors": "Haohan Wang, Zhenglin Wu and Eric P. Xing", "title": "Removing Confounding Factors Associated Weights in Deep Neural Networks\n  Improves the Prediction Accuracy for Healthcare Applications", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of healthcare data has brought the opportunities of\napplying data-driven approaches, such as machine learning methods, to assist\ndiagnosis. Recently, many deep learning methods have been shown with impressive\nsuccesses in predicting disease status with raw input data. However, the\n\"black-box\" nature of deep learning and the high-reliability requirement of\nbiomedical applications have created new challenges regarding the existence of\nconfounding factors. In this paper, with a brief argument that inappropriate\nhandling of confounding factors will lead to models' sub-optimal performance in\nreal-world applications, we present an efficient method that can remove the\ninfluences of confounding factors such as age or gender to improve the\nacross-cohort prediction accuracy of neural networks. One distinct advantage of\nour method is that it only requires minimal changes of the baseline model's\narchitecture so that it can be plugged into most of the existing neural\nnetworks. We conduct experiments across CT-scan, MRA, and EEG brain wave with\nconvolutional neural networks and LSTM to verify the efficiency of our method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 07:24:40 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 19:25:39 GMT"}, {"version": "v3", "created": "Fri, 31 Aug 2018 05:35:08 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Wang", "Haohan", ""], ["Wu", "Zhenglin", ""], ["Xing", "Eric P.", ""]]}, {"id": "1803.07300", "submitter": "Matus Telgarsky", "authors": "Ziwei Ji and Matus Telgarsky", "title": "Risk and parameter convergence of logistic regression", "comments": "Appears in COLT 2019 with the title \"The implicit bias of gradient\n  descent on nonseparable data\" (and no other changes)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent, when applied to the task of logistic regression, outputs\niterates which are biased to follow a unique ray defined by the data. The\ndirection of this ray is the maximum margin predictor of a maximal linearly\nseparable subset of the data; the gradient descent iterates converge to this\nray in direction at the rate $\\mathcal{O}(\\ln\\ln t / \\ln t)$. The ray does not\npass through the origin in general, and its offset is the bounded global\noptimum of the risk over the remaining data; gradient descent recovers this\noffset at a rate $\\mathcal{O}((\\ln t)^2 / \\sqrt{t})$.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 08:47:27 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 07:53:44 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 13:57:05 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1803.07348", "submitter": "Thomas Kerdreux", "authors": "Thomas Kerdreux, Fabian Pedregosa and Alexandre d'Aspremont", "title": "Frank-Wolfe with Subsampling Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze two novel randomized variants of the Frank-Wolfe (FW) or\nconditional gradient algorithm. While classical FW algorithms require solving a\nlinear minimization problem over the domain at each iteration, the proposed\nmethod only requires to solve a linear minimization problem over a small\n\\emph{subset} of the original domain. The first algorithm that we propose is a\nrandomized variant of the original FW algorithm and achieves a\n$\\mathcal{O}(1/t)$ sublinear convergence rate as in the deterministic\ncounterpart. The second algorithm is a randomized variant of the Away-step FW\nalgorithm, and again as its deterministic counterpart, reaches linear (i.e.,\nexponential) convergence rate making it the first provably convergent\nrandomized variant of Away-step FW. In both cases, while subsampling reduces\nthe convergence rate by a constant factor, the linear minimization step can be\na fraction of the cost of that of the deterministic versions, especially when\nthe data is streamed. We illustrate computational gains of the algorithms on\nregression problems, involving both $\\ell_1$ and latent group lasso penalties.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 10:18:59 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Kerdreux", "Thomas", ""], ["Pedregosa", "Fabian", ""], ["d'Aspremont", "Alexandre", ""]]}, {"id": "1803.07416", "submitter": "Ryan Sepassi", "authors": "Ashish Vaswani, Samy Bengio, Eugene Brevdo, Francois Chollet, Aidan N.\n  Gomez, Stephan Gouws, Llion Jones, {\\L}ukasz Kaiser, Nal Kalchbrenner, Niki\n  Parmar, Ryan Sepassi, Noam Shazeer, Jakob Uszkoreit", "title": "Tensor2Tensor for Neural Machine Translation", "comments": "arXiv admin note: text overlap with arXiv:1706.03762", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Tensor2Tensor is a library for deep learning models that is well-suited for\nneural machine translation and includes the reference implementation of the\nstate-of-the-art Transformer model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 18:49:22 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Vaswani", "Ashish", ""], ["Bengio", "Samy", ""], ["Brevdo", "Eugene", ""], ["Chollet", "Francois", ""], ["Gomez", "Aidan N.", ""], ["Gouws", "Stephan", ""], ["Jones", "Llion", ""], ["Kaiser", "\u0141ukasz", ""], ["Kalchbrenner", "Nal", ""], ["Parmar", "Niki", ""], ["Sepassi", "Ryan", ""], ["Shazeer", "Noam", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1803.07418", "submitter": "Yang Feng", "authors": "Emre Demirkaya, Yang Feng, Pallavi Basu, Jinchi Lv", "title": "Large-Scale Model Selection with Misspecification", "comments": "38 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1412.7468", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection is crucial to high-dimensional learning and inference for\ncontemporary big data applications in pinpointing the best set of covariates\namong a sequence of candidate interpretable models. Most existing work assumes\nimplicitly that the models are correctly specified or have fixed\ndimensionality. Yet both features of model misspecification and high\ndimensionality are prevalent in practice. In this paper, we exploit the\nframework of model selection principles in misspecified models originated in Lv\nand Liu (2014) and investigate the asymptotic expansion of Bayesian principle\nof model selection in the setting of high-dimensional misspecified models. With\na natural choice of prior probabilities that encourages interpretability and\nincorporates Kullback-Leibler divergence, we suggest the high-dimensional\ngeneralized Bayesian information criterion with prior probability (HGBIC_p) for\nlarge-scale model selection with misspecification. Our new information\ncriterion characterizes the impacts of both model misspecification and high\ndimensionality on model selection. We further establish the consistency of\ncovariance contrast matrix estimation and the model selection consistency of\nHGBIC_p in ultra-high dimensions under some mild regularity conditions. The\nadvantages of our new method are supported by numerical studies.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 03:10:12 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Demirkaya", "Emre", ""], ["Feng", "Yang", ""], ["Basu", "Pallavi", ""], ["Lv", "Jinchi", ""]]}, {"id": "1803.07445", "submitter": "Henggang Cui Dr", "authors": "Henggang Cui, Gregory R. Ganger, Phillip B. Gibbons", "title": "MLtuner: System Support for Automatic Machine Learning Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MLtuner automatically tunes settings for training tunables (such as the\nlearning rate, the momentum, the mini-batch size, and the data staleness bound)\nthat have a significant impact on large-scale machine learning (ML)\nperformance. Traditionally, these tunables are set manually, which is\nunsurprisingly error-prone and difficult to do without extensive domain\nknowledge. MLtuner uses efficient snapshotting, branching, and\noptimization-guided online trial-and-error to find good initial settings as\nwell as to re-tune settings during execution. Experiments show that MLtuner can\nrobustly find and re-tune tunable settings for a variety of ML applications,\nincluding image classification (for 3 models and 2 datasets), video\nclassification, and matrix factorization. Compared to state-of-the-art ML\nauto-tuning approaches, MLtuner is more robust for large problems and over an\norder of magnitude faster.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 14:17:36 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Cui", "Henggang", ""], ["Ganger", "Gregory R.", ""], ["Gibbons", "Phillip B.", ""]]}, {"id": "1803.07482", "submitter": "Ethan Knight", "authors": "Ethan Knight, Osher Lerner", "title": "Natural Gradient Deep Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm to train a deep Q-learning agent using\nnatural-gradient techniques. We compare the original deep Q-network (DQN)\nalgorithm to its natural-gradient counterpart, which we refer to as NGDQN, on a\ncollection of classic control domains. Without employing target networks, NGDQN\nsignificantly outperforms DQN without target networks, and performs no worse\nthan DQN with target networks, suggesting that NGDQN stabilizes training and\ncan help reduce the need for additional hyperparameter tuning. We also find\nthat NGDQN is less sensitive to hyperparameter optimization relative to DQN.\nTogether these results suggest that natural-gradient techniques can improve\nvalue-function optimization in deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 15:22:52 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 20:10:03 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Knight", "Ethan", ""], ["Lerner", "Osher", ""]]}, {"id": "1803.07517", "submitter": "Gabrielle Ras", "authors": "Gabrielle Ras, Marcel van Gerven, Pim Haselager", "title": "Explanation Methods in Deep Learning: Users, Values, Concerns and\n  Challenges", "comments": "14 pages, 1 figure, This article will appear as a chapter in\n  Explainable and Interpretable Models in Computer Vision and Machine Learning\n  Springer series on Challenges in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 16:44:47 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 15:06:04 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Ras", "Gabrielle", ""], ["van Gerven", "Marcel", ""], ["Haselager", "Pim", ""]]}, {"id": "1803.07519", "submitter": "Minhui Xue", "authors": "Lei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li,\n  Chunyang Chen, Ting Su, Li Li, Yang Liu, Jianjun Zhao, Yadong Wang", "title": "DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems", "comments": "The 33rd IEEE/ACM International Conference on Automated Software\n  Engineering (ASE 2018)", "journal-ref": "DeepGauge: Multi-Granularity Testing Criteria for Deep Learning\n  Systems. In Proceedings of the 33rd ACM/IEEE International Conference on\n  Automated Software Engineering (ASE 18), September 3-7, 2018, Montpellier,\n  France", "doi": "10.1145/3238147.3238202", "report-no": null, "categories": "cs.SE cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) defines a new data-driven programming paradigm that\nconstructs the internal system logic of a crafted neuron network through a set\nof training data. We have seen wide adoption of DL in many safety-critical\nscenarios. However, a plethora of studies have shown that the state-of-the-art\nDL systems suffer from various vulnerabilities which can lead to severe\nconsequences when applied to real-world applications. Currently, the testing\nadequacy of a DL system is usually measured by the accuracy of test data.\nConsidering the limitation of accessible high quality test data, good accuracy\nperformance on test data can hardly provide confidence to the testing adequacy\nand generality of DL systems. Unlike traditional software systems that have\nclear and controllable logic and functionality, the lack of interpretability in\na DL system makes system analysis and defect detection difficult, which could\npotentially hinder its real-world deployment. In this paper, we propose\nDeepGauge, a set of multi-granularity testing criteria for DL systems, which\naims at rendering a multi-faceted portrayal of the testbed. The in-depth\nevaluation of our proposed testing criteria is demonstrated on two well-known\ndatasets, five DL systems, and with four state-of-the-art adversarial attack\ntechniques against DL. The potential usefulness of DeepGauge sheds light on the\nconstruction of more generic and robust DL systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 16:52:12 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 05:02:54 GMT"}, {"version": "v3", "created": "Sat, 28 Jul 2018 07:47:27 GMT"}, {"version": "v4", "created": "Tue, 14 Aug 2018 23:07:39 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Zhang", "Fuyuan", ""], ["Sun", "Jiyuan", ""], ["Xue", "Minhui", ""], ["Li", "Bo", ""], ["Chen", "Chunyang", ""], ["Su", "Ting", ""], ["Li", "Li", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Wang", "Yadong", ""]]}, {"id": "1803.07534", "submitter": "Charles Lu", "authors": "Charles Lu, M. Marx, M. Zahid, C. W. Lo, C. Chennubhotla, S. P. Quinn", "title": "Stacked Neural Networks for end-to-end ciliary motion analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cilia are hairlike structures protruding from nearly every cell in the body.\nDiseases known as ciliopathies, where cilia function is disrupted, can result\nin a wide spectrum of disorders. However, most techniques for assessing ciliary\nmotion rely on manual identification and tracking of cilia; this process is\nlaborious and error-prone, and does not scale well. Even where automated\nciliary motion analysis tools exist, their applicability is limited. Here, we\npropose an end-to-end computational machine learning pipeline that\nautomatically identifies regions of cilia from videos, extracts patches of\ncilia, and classifies patients as exhibiting normal or abnormal ciliary motion.\nIn particular, we demonstrate how convolutional LSTM are able to encode complex\nfeatures while remaining sensitive enough to differentiate between a variety of\nmotion patterns. Our framework achieves 90% with only a few hundred training\nepochs. We find that the combination of segmentation and classification\nnetworks in a single pipeline yields performance comparable to existing\ncomputational pipelines, while providing the additional benefit of an\nend-to-end, fully-automated analysis toolbox for ciliary motion.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 17:17:39 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Lu", "Charles", ""], ["Marx", "M.", ""], ["Zahid", "M.", ""], ["Lo", "C. W.", ""], ["Chennubhotla", "C.", ""], ["Quinn", "S. P.", ""]]}, {"id": "1803.07551", "submitter": "Steindor Saemundsson", "authors": "Steind\\'or S{\\ae}mundsson, Katja Hofmann, Marc Peter Deisenroth", "title": "Meta Reinforcement Learning with Latent Variable Gaussian Processes", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from small data sets is critical in many practical applications\nwhere data collection is time consuming or expensive, e.g., robotics, animal\nexperiments or drug design. Meta learning is one way to increase the data\nefficiency of learning algorithms by generalizing learned concepts from a set\nof training tasks to unseen, but related, tasks. Often, this relationship\nbetween tasks is hard coded or relies in some other way on human expertise. In\nthis paper, we frame meta learning as a hierarchical latent variable model and\ninfer the relationship between tasks automatically from data. We apply our\nframework in a model-based reinforcement learning setting and show that our\nmeta-learning model effectively generalizes to novel tasks by identifying how\nnew tasks relate to prior ones from minimal data. This results in up to a 60%\nreduction in the average interaction time needed to solve tasks compared to\nstrong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 17:51:10 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 09:28:57 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["S\u00e6mundsson", "Steind\u00f3r", ""], ["Hofmann", "Katja", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1803.07554", "submitter": "Lijun Ding", "authors": "Lijun Ding, Yudong Chen", "title": "Leave-one-out Approach for Matrix Completion: Primal and Dual Analysis", "comments": "45 pages. The sample complexity for nuclear norm minimization has\n  been reduced to $\\mathcal{O}(\\mu r \\log(\\mu r)d \\log d )$ from\n  $\\mathcal{O}(\\mu^2 r^3 d \\log d)$ in the early version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a powerful technique based on Leave-one-out\nanalysis to the study of low-rank matrix completion problems. Using this\ntechnique, we develop a general approach for obtaining fine-grained, entrywise\nbounds for iterative stochastic procedures in the presence of probabilistic\ndependency. We demonstrate the power of this approach in analyzing two of the\nmost important algorithms for matrix completion: (i) the non-convex approach\nbased on Projected Gradient Descent (PGD) for a rank-constrained formulation,\nalso known as the Singular Value Projection algorithm, and (ii) the convex\nrelaxation approach based on nuclear norm minimization (NNM).\n  Using this approach, we establish the first convergence guarantee for the\noriginal form of PGD without regularization or sample splitting}, and in\nparticular shows that it converges linearly in the infinity norm. For NNM, we\nuse this approach to study a fictitious iterative procedure that arises in the\ndual analysis. Our results show that \\NNM recovers an $ d $-by-$ d $ rank-$ r $\nmatrix with $\\mathcal{O}(\\mu r \\log(\\mu r) d \\log d )$ observed entries. This\nbound has optimal dependence on the matrix dimension and is independent of the\ncondition number. To the best of our knowledge, this is the first sample\ncomplexity result for a tractable matrix completion algorithm that satisfies\nthese two properties simultaneously.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 17:54:49 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 02:01:03 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 04:45:20 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ding", "Lijun", ""], ["Chen", "Yudong", ""]]}, {"id": "1803.07612", "submitter": "Eric Zhan", "authors": "Eric Zhan, Stephan Zheng, Yisong Yue, Long Sha, Patrick Lucey", "title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of training sequential generative models for capturing\ncoordinated multi-agent trajectory behavior, such as offensive basketball\ngameplay. When modeling such settings, it is often beneficial to design\nhierarchical models that can capture long-term coordination using intermediate\nvariables. Furthermore, these intermediate variables should capture interesting\nhigh-level behavioral semantics in an interpretable and manipulatable way. We\npresent a hierarchical framework that can effectively learn such sequential\ngenerative models. Our approach is inspired by recent work on leveraging\nprogrammatically produced weak labels, which we extend to the spatiotemporal\nregime. In addition to synthetic settings, we show how to instantiate our\nframework to effectively model complex interactions between basketball players\nand generate realistic multi-agent trajectories of basketball gameplay over\nlong time periods. We validate our approach using both quantitative and\nqualitative evaluations, including a user study comparison conducted with\nprofessional sports analysts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 19:19:13 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 08:31:55 GMT"}, {"version": "v3", "created": "Fri, 23 Mar 2018 06:35:59 GMT"}, {"version": "v4", "created": "Mon, 2 Apr 2018 18:36:15 GMT"}, {"version": "v5", "created": "Sun, 20 May 2018 20:48:45 GMT"}, {"version": "v6", "created": "Fri, 22 Feb 2019 05:40:13 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Zhan", "Eric", ""], ["Zheng", "Stephan", ""], ["Yue", "Yisong", ""], ["Sha", "Long", ""], ["Lucey", "Patrick", ""]]}, {"id": "1803.07617", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Alexander Rakhlin and Karthik Sridharan", "title": "Online Learning: Sufficient Statistics and the Burkholder Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We uncover a fairly general principle in online learning: If regret can be\n(approximately) expressed as a function of certain \"sufficient statistics\" for\nthe data sequence, then there exists a special Burkholder function that 1) can\nbe used algorithmically to achieve the regret bound and 2) only depends on\nthese sufficient statistics, not the entire data sequence, so that the online\nstrategy is only required to keep the sufficient statistics in memory. This\ncharacterization is achieved by bringing the full power of the Burkholder\nMethod --- originally developed for certifying probabilistic martingale\ninequalities --- to bear on the online learning setting.\n  To demonstrate the scope and effectiveness of the Burkholder method, we\ndevelop a novel online strategy for matrix prediction that attains a regret\nbound corresponding to the variance term in matrix concentration inequalities.\nWe also present a linear-time/space prediction strategy for parameter free\nsupervised learning with linear classes and general smooth norms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 19:29:46 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1803.07634", "submitter": "Twan van Laarhoven", "authors": "Twan van Laarhoven, Elena Marchiori", "title": "Domain Adaptation with Randomized Expectation Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) is the task of classifying an unlabeled dataset\n(target) using a labeled dataset (source) from a related domain. The majority\nof successful DA methods try to directly match the distributions of the source\nand target data by transforming the feature space. Despite their success, state\nof the art methods based on this approach are either involved or unable to\ndirectly scale to data with many features. This article shows that domain\nadaptation can be successfully performed by using a very simple randomized\nexpectation maximization (EM) method. We consider two instances of the method,\nwhich involve logistic regression and support vector machine, respectively. The\nunderlying assumption of the proposed method is the existence of a good single\nlinear classifier for both source and target domain. The potential limitations\nof this assumption are alleviated by the flexibility of the method, which can\ndirectly incorporate deep features extracted from a pre-trained deep neural\nnetwork. The resulting algorithm is strikingly easy to implement and apply. We\ntest its performance on 36 real-life adaptation tasks over text and image data\nwith diverse characteristics. The method achieves state-of-the-art results,\ncompetitive with those of involved end-to-end deep transfer-learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 20:13:09 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["van Laarhoven", "Twan", ""], ["Marchiori", "Elena", ""]]}, {"id": "1803.07658", "submitter": "Benjamin Mark", "authors": "Yuan Li, Benjamin Mark, Garvesh Raskutti, Rebecca Willett, Hyebin\n  Song, David Neiman", "title": "Graph-based regularization for regression problems with alignment and\n  highly-correlated designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse models for high-dimensional linear regression and machine learning\nhave received substantial attention over the past two decades. Model selection,\nor determining which features or covariates are the best explanatory variables,\nis critical to the interpretability of a learned model. Much of the current\nliterature assumes that covariates are only mildly correlated. However, in many\nmodern applications covariates are highly correlated and do not exhibit key\nproperties (such as the restricted eigenvalue condition, restricted isometry\nproperty, or other related assumptions). This work considers a high-dimensional\nregression setting in which a graph governs both correlations among the\ncovariates and the similarity among regression coefficients -- meaning there is\n\\emph{alignment} between the covariates and regression coefficients. Using side\ninformation about the strength of correlations among features, we form a graph\nwith edge weights corresponding to pairwise covariances. This graph is used to\ndefine a graph total variation regularizer that promotes similar weights for\ncorrelated features.\n  This work shows how the proposed graph-based regularization yields\nmean-squared error guarantees for a broad range of covariance graph structures.\nThese guarantees are optimal for many specific covariance graphs, including\nblock and lattice graphs. Our proposed approach outperforms other methods for\nhighly-correlated design in a variety of experiments on synthetic data and real\nbiochemistry data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 21:07:36 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 02:04:21 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 15:02:10 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Li", "Yuan", ""], ["Mark", "Benjamin", ""], ["Raskutti", "Garvesh", ""], ["Willett", "Rebecca", ""], ["Song", "Hyebin", ""], ["Neiman", "David", ""]]}, {"id": "1803.07661", "submitter": "Zhe Li", "authors": "Zhe Li, Shuo Wang, Caiwen Ding, Qinru Qiu, Yanzhi Wang, Yun Liang", "title": "Efficient Recurrent Neural Networks using Structured Matrices in FPGAs", "comments": "To appear in International Conference on Learning Representations\n  2018 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are becoming increasingly important for time\nseries-related applications which require efficient and real-time\nimplementations. The recent pruning based work ESE suffers from degradation of\nperformance/energy efficiency due to the irregular network structure after\npruning. We propose block-circulant matrices for weight matrix representation\nin RNNs, thereby achieving simultaneous model compression and acceleration. We\naim to implement RNNs in FPGA with highest performance and energy efficiency,\nwith certain accuracy requirement (negligible accuracy degradation).\nExperimental results on actual FPGA deployments shows that the proposed\nframework achieves a maximum energy efficiency improvement of 35.7$\\times$\ncompared with ESE.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 21:21:22 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 17:26:10 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Li", "Zhe", ""], ["Wang", "Shuo", ""], ["Ding", "Caiwen", ""], ["Qiu", "Qinru", ""], ["Wang", "Yanzhi", ""], ["Liang", "Yun", ""]]}, {"id": "1803.07679", "submitter": "Fabio Daolio", "authors": "\\^Angelo Cardoso, Fabio Daolio and Sa\\'ul Vargas", "title": "Product Characterisation towards Personalisation: Learning Attributes\n  from Unstructured Data to Recommend Fashion Products", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a solution to tackle a common set of challenges in\ne-commerce, which arise from the fact that new products are continually being\nadded to the catalogue. The challenges involve properly personalising the\ncustomer experience, forecasting demand and planning the product range. We\nargue that the foundational piece to solve all of these problems is having\nconsistent and detailed information about each product, information that is\nrarely available or consistent given the multitude of suppliers and types of\nproducts. We describe in detail the architecture and methodology implemented at\nASOS, one of the world's largest fashion e-commerce retailers, to tackle this\nproblem. We then show how this quantitative understanding of the products can\nbe leveraged to improve recommendations in a hybrid recommender system\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 22:25:29 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Cardoso", "\u00c2ngelo", ""], ["Daolio", "Fabio", ""], ["Vargas", "Sa\u00fal", ""]]}, {"id": "1803.07710", "submitter": "KiJung Yoon", "authors": "KiJung Yoon, Renjie Liao, Yuwen Xiong, Lisa Zhang, Ethan Fetaya,\n  Raquel Urtasun, Richard Zemel, Xaq Pitkow", "title": "Inference in Probabilistic Graphical Models by Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental computation for statistical inference and accurate\ndecision-making is to compute the marginal probabilities or most probable\nstates of task-relevant variables. Probabilistic graphical models can\nefficiently represent the structure of such complex data, but performing these\ninferences is generally difficult. Message-passing algorithms, such as belief\npropagation, are a natural way to disseminate evidence amongst correlated\nvariables while exploiting the graph structure, but these algorithms can\nstruggle when the conditional dependency graphs contain loops. Here we use\nGraph Neural Networks (GNNs) to learn a message-passing algorithm that solves\nthese inference tasks. We first show that the architecture of GNNs is\nwell-matched to inference tasks. We then demonstrate the efficacy of this\ninference approach by training GNNs on a collection of graphical models and\nshowing that they substantially outperform belief propagation on loopy graphs.\nOur message-passing algorithms generalize out of the training set to larger\ngraphs and graphs with different structure.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 01:09:07 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 14:09:34 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 21:26:30 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2019 15:02:25 GMT"}, {"version": "v5", "created": "Thu, 27 Jun 2019 15:10:06 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Yoon", "KiJung", ""], ["Liao", "Renjie", ""], ["Xiong", "Yuwen", ""], ["Zhang", "Lisa", ""], ["Fetaya", "Ethan", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""], ["Pitkow", "Xaq", ""]]}, {"id": "1803.07712", "submitter": "Furui Liu", "authors": "Furui Liu, Laiwan Chan", "title": "Causal Inference on Discrete Data via Estimating Distance Correlations", "comments": null, "journal-ref": "Neural Computation, Vol. 28, No. 5, 2016", "doi": "10.1162/NECO_a_00820", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the problem of inferring causal directions when\nthe data is on discrete domain. By considering the distribution of the cause\n$P(X)$ and the conditional distribution mapping cause to effect $P(Y|X)$ as\nindependent random variables, we propose to infer the causal direction via\ncomparing the distance correlation between $P(X)$ and $P(Y|X)$ with the\ndistance correlation between $P(Y)$ and $P(X|Y)$. We infer \"$X$ causes $Y$\" if\nthe dependence coefficient between $P(X)$ and $P(Y|X)$ is smaller. Experiments\nare performed to show the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 01:39:08 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 15:47:04 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 03:04:11 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Liu", "Furui", ""], ["Chan", "Laiwan", ""]]}, {"id": "1803.07726", "submitter": "Cong Ma", "authors": "Yuxin Chen, Yuejie Chi, Jianqing Fan, Cong Ma", "title": "Gradient Descent with Random Initialization: Fast Global Convergence for\n  Nonconvex Phase Retrieval", "comments": "Accepted to Mathematical Programming", "journal-ref": "Mathematical Programming 2019, Volume 176, Issue 1-2, 5-37", "doi": "10.1007/s10107-019-01363-6", "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.NA math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of solving systems of quadratic equations,\nnamely, recovering an object of interest\n$\\mathbf{x}^{\\natural}\\in\\mathbb{R}^{n}$ from $m$ quadratic equations/samples\n$y_{i}=(\\mathbf{a}_{i}^{\\top}\\mathbf{x}^{\\natural})^{2}$, $1\\leq i\\leq m$. This\nproblem, also dubbed as phase retrieval, spans multiple domains including\nphysical sciences and machine learning.\n  We investigate the efficiency of gradient descent (or Wirtinger flow)\ndesigned for the nonconvex least squares problem. We prove that under Gaussian\ndesigns, gradient descent --- when randomly initialized --- yields an\n$\\epsilon$-accurate solution in $O\\big(\\log n+\\log(1/\\epsilon)\\big)$ iterations\ngiven nearly minimal samples, thus achieving near-optimal computational and\nsample complexities at once. This provides the first global convergence\nguarantee concerning vanilla gradient descent for phase retrieval, without the\nneed of (i) carefully-designed initialization, (ii) sample splitting, or (iii)\nsophisticated saddle-point escaping schemes. All of these are achieved by\nexploiting the statistical models in analyzing optimization algorithms, via a\nleave-one-out approach that enables the decoupling of certain statistical\ndependency between the gradient descent iterates and the data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:14:16 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 13:56:11 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Chen", "Yuxin", ""], ["Chi", "Yuejie", ""], ["Fan", "Jianqing", ""], ["Ma", "Cong", ""]]}, {"id": "1803.07753", "submitter": "Salar Fattahi", "authors": "Salar Fattahi, Somayeh Sojoudi", "title": "Sample Complexity of Sparse System Identification Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the system identification problem for sparse linear\ntime-invariant systems. We propose a sparsity promoting block-regularized\nestimator to identify the dynamics of the system with only a limited number of\ninput-state data samples. We characterize the properties of this estimator\nunder high-dimensional scaling, where the growth rate of the system dimension\nis comparable to or even faster than that of the number of available sample\ntrajectories. In particular, using contemporary results on high-dimensional\nstatistics, we show that the proposed estimator results in a small element-wise\nerror, provided that the number of sample trajectories is above a threshold.\nThis threshold depends polynomially on the size of each block and the number of\nnonzero elements at different rows of input and state matrices, but only\nlogarithmically on the system dimension. A by-product of this result is that\nthe number of sample trajectories required for sparse system identification is\nsignificantly smaller than the dimension of the system. Furthermore, we show\nthat, unlike the recently celebrated least-squares estimators for system\nidentification problems, the method developed in this work is capable of\n\\textit{exact recovery} of the underlying sparsity structure of the system with\nthe aforementioned number of data samples. Extensive case studies on\nsynthetically generated systems, physical mass-spring networks, and multi-agent\nsystems are offered to demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 05:55:11 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 20:42:24 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Fattahi", "Salar", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1803.07770", "submitter": "Christopher J. Cueva", "authors": "Christopher J. Cueva and Xue-Xin Wei", "title": "Emergence of grid-like representations by training recurrent neural\n  networks to perform spatial localization", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR) 2018", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decades of research on the neural code underlying spatial navigation have\nrevealed a diverse set of neural response properties. The Entorhinal Cortex\n(EC) of the mammalian brain contains a rich set of spatial correlates,\nincluding grid cells which encode space using tessellating patterns. However,\nthe mechanisms and functional significance of these spatial representations\nremain largely mysterious. As a new way to understand these neural\nrepresentations, we trained recurrent neural networks (RNNs) to perform\nnavigation tasks in 2D arenas based on velocity inputs. Surprisingly, we find\nthat grid-like spatial response patterns emerge in trained networks, along with\nunits that exhibit other spatial correlates, including border cells and\nband-like cells. All these different functional types of neurons have been\nobserved experimentally. The order of the emergence of grid-like and border\ncells is also consistent with observations from developmental studies.\nTogether, our results suggest that grid cells, border cells and others as\nobserved in EC may be a natural solution for representing space efficiently\ngiven the predominant recurrent connections in the neural circuits.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 07:09:57 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Cueva", "Christopher J.", ""], ["Wei", "Xue-Xin", ""]]}, {"id": "1803.07819", "submitter": "Biau Gerard", "authors": "G. Biau (LPSM), B. Cadre (ENS Rennes), M. Sangnier (LPSM), U.\n  Tanielian (LPSM)", "title": "Some Theoretical Properties of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a class of generative algorithms\nthat have been shown to produce state-of-the art samples, especially in the\ndomain of image creation. The fundamental principle of GANs is to approximate\nthe unknown distribution of a given data set by optimizing an objective\nfunction through an adversarial game between a family of generators and a\nfamily of discriminators. In this paper, we offer a better theoretical\nunderstanding of GANs by analyzing some of their mathematical and statistical\nproperties. We study the deep connection between the adversarial principle\nunderlying GANs and the Jensen-Shannon divergence, together with some\noptimality characteristics of the problem. An analysis of the role of the\ndiscriminator family via approximation arguments is also provided. In addition,\ntaking a statistical point of view, we study the large sample properties of the\nestimated distribution and prove in particular a central limit theorem. Some of\nour results are illustrated with simulated examples.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 09:52:14 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Biau", "G.", "", "LPSM"], ["Cadre", "B.", "", "ENS Rennes"], ["Sangnier", "M.", "", "LPSM"], ["Tanielian", "U.", "", "LPSM"]]}, {"id": "1803.07821", "submitter": "Riikka Huusari", "authors": "Riikka Huusari (LIS, QARMA, AMU), Hachem Kadri (QARMA, LIS, AMU),\n  C\\'ecile Capponi (QARMA, LIS, AMU)", "title": "Multi-view Metric Learning in Vector-valued Kernel Spaces", "comments": null, "journal-ref": "The 21st International Conference on Artificial Intelligence and\n  Statistics, Apr 2018, Lanzarote, Spain", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of metric learning for multi-view data and present a\nnovel method for learning within-view as well as between-view metrics in\nvector-valued kernel spaces, as a way to capture multi-modal structure of the\ndata. We formulate two convex optimization problems to jointly learn the metric\nand the classifier or regressor in kernel feature spaces. An iterative\nthree-step multi-view metric learning algorithm is derived from the\noptimization problems. In order to scale the computation to large training\nsets, a block-wise Nystr{\\\"o}m approximation of the multi-view kernel matrix is\nintroduced. We justify our approach theoretically and experimentally, and show\nits performance on real-world datasets against relevant state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 09:56:33 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Huusari", "Riikka", "", "LIS, QARMA, AMU"], ["Kadri", "Hachem", "", "QARMA, LIS, AMU"], ["Capponi", "C\u00e9cile", "", "QARMA, LIS, AMU"]]}, {"id": "1803.07859", "submitter": "Jack Kuipers", "authors": "Jack Kuipers, Polina Suter and Giusi Moffa", "title": "Efficient Sampling and Structure Learning of Bayesian Networks", "comments": "Revised version. 40 pages including 16 pages of supplement, 5 figures\n  and 15 supplemental figures; R package BiDAG is available at\n  https://CRAN.R-project.org/package=BiDAG", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks are probabilistic graphical models widely employed to\nunderstand dependencies in high dimensional data, and even to facilitate causal\ndiscovery. Learning the underlying network structure, which is encoded as a\ndirected acyclic graph (DAG) is highly challenging mainly due to the vast\nnumber of possible networks. Efforts have focussed on two fronts:\nconstraint-based methods that perform conditional independence tests to exclude\nedges and score and search approaches which explore the DAG space with greedy\nor MCMC schemes. Here we synthesise these two fields in a novel hybrid method\nwhich reduces the complexity of MCMC approaches to that of a constraint-based\nmethod. Individual steps in the MCMC scheme only require simple table lookups\nso that very long chains can be efficiently obtained. Furthermore, the scheme\nincludes an iterative procedure to correct for errors from the conditional\nindependence tests. The algorithm offers markedly superior performance to\nalternatives, particularly because DAGs can also be sampled from the posterior\ndistribution, enabling full Bayesian model averaging for much larger Bayesian\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 11:12:42 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 15:25:13 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 18:33:10 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Kuipers", "Jack", ""], ["Suter", "Polina", ""], ["Moffa", "Giusi", ""]]}, {"id": "1803.07868", "submitter": "Florian Wenzel", "authors": "Patrick J\\\"ahnichen, Florian Wenzel, Marius Kloft, Stephan Mandt", "title": "Scalable Generalized Dynamic Topic Models", "comments": "Published version, International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic topic models (DTMs) model the evolution of prevalent themes in\nliterature, online media, and other forms of text over time. DTMs assume that\nword co-occurrence statistics change continuously and therefore impose\ncontinuous stochastic process priors on their model parameters. These dynamical\npriors make inference much harder than in regular topic models, and also limit\nscalability. In this paper, we present several new results around DTMs. First,\nwe extend the class of tractable priors from Wiener processes to the generic\nclass of Gaussian processes (GPs). This allows us to explore topics that\ndevelop smoothly over time, that have a long-term memory or are temporally\nconcentrated (for event detection). Second, we show how to perform scalable\napproximate inference in these models based on ideas around stochastic\nvariational inference and sparse Gaussian processes. This way we can train a\nrich family of DTMs to massive data. Our experiments on several large-scale\ndatasets show that our generalized model allows us to find interesting patterns\nthat were not accessible by previous approaches.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 11:50:35 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["J\u00e4hnichen", "Patrick", ""], ["Wenzel", "Florian", ""], ["Kloft", "Marius", ""], ["Mandt", "Stephan", ""]]}, {"id": "1803.07879", "submitter": "Karl {\\O}yvind Mikalsen", "authors": "Karl {\\O}yvind Mikalsen, Cristina Soguero-Ruiz, Filippo Maria Bianchi,\n  Arthur Revhaug and Robert Jenssen", "title": "An Unsupervised Multivariate Time Series Kernel Approach for Identifying\n  Patients with Surgical Site Infection from Blood Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large fraction of the electronic health records consists of clinical\nmeasurements collected over time, such as blood tests, which provide important\ninformation about the health status of a patient. These sequences of clinical\nmeasurements are naturally represented as time series, characterized by\nmultiple variables and the presence of missing data, which complicate analysis.\nIn this work, we propose a surgical site infection detection framework for\npatients undergoing colorectal cancer surgery that is completely unsupervised,\nhence alleviating the problem of getting access to labelled training data. The\nframework is based on powerful kernels for multivariate time series that\naccount for missing data when computing similarities. Our approach show\nsuperior performance compared to baselines that have to resort to imputation\ntechniques and performs comparable to a supervised classification baseline.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 12:20:43 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Mikalsen", "Karl \u00d8yvind", ""], ["Soguero-Ruiz", "Cristina", ""], ["Bianchi", "Filippo Maria", ""], ["Revhaug", "Arthur", ""], ["Jenssen", "Robert", ""]]}, {"id": "1803.07952", "submitter": "Chi-Hua Chen", "authors": "Ming-Yen Wu, Chi-Hua Chen, Chi-Chun Lo", "title": "An Exercise Fatigue Detection Model Based on Machine Learning Methods", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an exercise fatigue detection model based on real-time\nclinical data which includes time domain analysis, frequency domain analysis,\ndetrended fluctuation analysis, approximate entropy, and sample entropy.\nFurthermore, this study proposed a feature extraction method which is combined\nwith an analytical hierarchy process to analyze and extract critical features.\nFinally, machine learning algorithms were adopted to analyze the data of each\nfeature for the detection of exercise fatigue. The practical experimental\nresults showed that the proposed exercise fatigue detection model and feature\nextraction method could precisely detect the level of exercise fatigue, and the\naccuracy of exercise fatigue detection could be improved up to 98.65%.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 13:23:42 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Wu", "Ming-Yen", ""], ["Chen", "Chi-Hua", ""], ["Lo", "Chi-Chun", ""]]}, {"id": "1803.07954", "submitter": "Vasileios Tzoumas", "authors": "Vasileios Tzoumas, Ali Jadbabaie, George J. Pappas", "title": "Resilient Monotone Sequential Maximization", "comments": "Extended version accepted in IEEE TAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications in machine learning, optimization, and control require the\nsequential selection of a few system elements, such as sensors, data, or\nactuators, to optimize the system performance across multiple time steps.\nHowever, in failure-prone and adversarial environments, sensors get attacked,\ndata get deleted, and actuators fail. Thence, traditional sequential design\nparadigms become insufficient and, in contrast, resilient sequential designs\nthat adapt against system-wide attacks, deletions, or failures become\nimportant. In general, resilient sequential design problems are computationally\nhard. Also, even though they often involve objective functions that are\nmonotone and (possibly) submodular, no scalable approximation algorithms are\nknown for their solution. In this paper, we provide the first scalable\nalgorithm, that achieves the following characteristics: system-wide resiliency,\ni.e., the algorithm is valid for any number of denial-of-service attacks,\ndeletions, or failures; adaptiveness, i.e., at each time step, the algorithm\nselects system elements based on the history of inflicted attacks, deletions,\nor failures; and provable approximation performance, i.e., the algorithm\nguarantees for monotone objective functions a solution close to the optimal. We\nquantify the algorithm's approximation performance using a notion of curvature\nfor monotone (not necessarily submodular) set functions. Finally, we support\nour theoretical analyses with simulated experiments, by considering a\ncontrol-aware sensor scheduling scenario, namely, sensing-constrained robot\nnavigation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 15:00:33 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 14:22:28 GMT"}, {"version": "v3", "created": "Sun, 25 Mar 2018 23:41:13 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 15:42:46 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Tzoumas", "Vasileios", ""], ["Jadbabaie", "Ali", ""], ["Pappas", "George J.", ""]]}, {"id": "1803.07964", "submitter": "Bicheng Ying", "authors": "Bicheng Ying and Kun Yuan and Stefan Vlaski and Ali H. Sayed", "title": "Stochastic Learning under Random Reshuffling with Constant Step-sizes", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2878551", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In empirical risk optimization, it has been observed that stochastic gradient\nimplementations that rely on random reshuffling of the data achieve better\nperformance than implementations that rely on sampling the data uniformly.\nRecent works have pursued justifications for this behavior by examining the\nconvergence rate of the learning process under diminishing step-sizes. This\nwork focuses on the constant step-size case and strongly convex loss function.\nIn this case, convergence is guaranteed to a small neighborhood of the\noptimizer albeit at a linear rate. The analysis establishes analytically that\nrandom reshuffling outperforms uniform sampling by showing explicitly that\niterates approach a smaller neighborhood of size $O(\\mu^2)$ around the\nminimizer rather than $O(\\mu)$. Furthermore, we derive an analytical expression\nfor the steady-state mean-square-error performance of the algorithm, which\nhelps clarify in greater detail the differences between sampling with and\nwithout replacement. We also explain the periodic behavior that is observed in\nrandom reshuffling implementations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 15:27:52 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 18:48:57 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ying", "Bicheng", ""], ["Yuan", "Kun", ""], ["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1803.07976", "submitter": "Cristina Rottondi", "authors": "Francesco Musumeci, Cristina Rottondi, Avishek Nag, Irene Macaluso,\n  Darko Zibar, Marco Ruffini, and Massimo Tornatore", "title": "An Overview on Application of Machine Learning Techniques in Optical\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's telecommunication networks have become sources of enormous amounts of\nwidely heterogeneous data. This information can be retrieved from network\ntraffic traces, network alarms, signal quality indicators, users' behavioral\ndata, etc. Advanced mathematical tools are required to extract meaningful\ninformation from these data and take decisions pertaining to the proper\nfunctioning of the networks from the network-generated data. Among these\nmathematical tools, Machine Learning (ML) is regarded as one of the most\npromising methodological approaches to perform network-data analysis and enable\nautomated network self-configuration and fault management. The adoption of ML\ntechniques in the field of optical communication networks is motivated by the\nunprecedented growth of network complexity faced by optical networks in the\nlast few years. Such complexity increase is due to the introduction of a huge\nnumber of adjustable and interdependent system parameters (e.g., routing\nconfigurations, modulation format, symbol rate, coding schemes, etc.) that are\nenabled by the usage of coherent transmission/reception technologies, advanced\ndigital signal processing and compensation of nonlinear effects in optical\nfiber propagation. In this paper we provide an overview of the application of\nML to optical communications and networking. We classify and survey relevant\nliterature dealing with the topic, and we also provide an introductory tutorial\non ML for researchers and practitioners interested in this field. Although a\ngood number of research papers have recently appeared, the application of ML to\noptical networks is still in its infancy: to stimulate further work in this\narea, we conclude the paper proposing new possible research directions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 15:58:36 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 19:23:31 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 08:37:30 GMT"}, {"version": "v4", "created": "Sat, 1 Dec 2018 13:57:13 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Musumeci", "Francesco", ""], ["Rottondi", "Cristina", ""], ["Nag", "Avishek", ""], ["Macaluso", "Irene", ""], ["Zibar", "Darko", ""], ["Ruffini", "Marco", ""], ["Tornatore", "Massimo", ""]]}, {"id": "1803.07980", "submitter": "Tianchen Zhao Mr.", "authors": "Tianchen Zhao", "title": "Information Theoretic Interpretation of Deep learning", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We interpret part of the experimental results of Shwartz-Ziv and Tishby\n[2017]. Inspired by these results, we established a conjecture of the dynamics\nof the machinary of deep neural network. This conjecture can be used to explain\nthe counterpart result by Saxe et al. [2018].\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:03:29 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 02:36:59 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Zhao", "Tianchen", ""]]}, {"id": "1803.07994", "submitter": "Joachim Folz", "authors": "Joachim Folz and Sebastian Palacio and Joern Hees and Damian Borth and\n  Andreas Dengel", "title": "Adversarial Defense based on Structure-to-Signal Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack methods have demonstrated the fragility of deep neural\nnetworks. Their imperceptible perturbations are frequently able fool\nclassifiers into potentially dangerous misclassifications. We propose a novel\nway to interpret adversarial perturbations in terms of the effective input\nsignal that classifiers actually use. Based on this, we apply specially trained\nautoencoders, referred to as S2SNets, as defense mechanism. They follow a\ntwo-stage training scheme: first unsupervised, followed by a fine-tuning of the\ndecoder, using gradients from an existing classifier. S2SNets induce a shift in\nthe distribution of gradients propagated through them, stripping them from\nclass-dependent signal. We analyze their robustness against several white-box\nand gray-box scenarios on the large ImageNet dataset. Our approach reaches\ncomparable resilience in white-box attack scenarios as other state-of-the-art\ndefenses in gray-box scenarios. We further analyze the relationships of\nAlexNet, VGG 16, ResNet 50 and Inception v3 in adversarial space, and found\nthat VGG 16 is the easiest to fool, while perturbations from ResNet 50 are the\nmost transferable.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:25:26 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Folz", "Joachim", ""], ["Palacio", "Sebastian", ""], ["Hees", "Joern", ""], ["Borth", "Damian", ""], ["Dengel", "Andreas", ""]]}, {"id": "1803.08000", "submitter": "Indrayudh Ghosal", "authors": "Indrayudh Ghosal, Giles Hooker", "title": "Boosting Random Forests to Reduce Bias; One-Step Boosted Forest and its\n  Variance Estimate", "comments": "39 pages, 7 tables, 3 figures", "journal-ref": null, "doi": "10.1080/10618600.2020.1820345", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose using the principle of boosting to reduce the bias\nof a random forest prediction in the regression setting. From the original\nrandom forest fit we extract the residuals and then fit another random forest\nto these residuals. We call the sum of these two random forests a\n\\textit{one-step boosted forest}. We show with simulated and real data that the\none-step boosted forest has a reduced bias compared to the original random\nforest. The paper also provides a variance estimate of the one-step boosted\nforest by an extension of the infinitesimal Jackknife estimator. Using this\nvariance estimate we can construct prediction intervals for the boosted forest\nand we show that they have good coverage probabilities. Combining the bias\nreduction and the variance estimate we show that the one-step boosted forest\nhas a significant reduction in predictive mean squared error and thus an\nimprovement in predictive performance. When applied on datasets from the UCI\ndatabase, one-step boosted forest performs better than random forest and\ngradient boosting machine algorithms. Theoretically we can also extend such a\nboosting process to more than one step and the same principles outlined in this\npaper can be used to find variance estimates for such predictors. Such boosting\nwill reduce bias even further but it risks over-fitting and also increases the\ncomputational burden.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:41:30 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 16:34:47 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 20:00:30 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Ghosal", "Indrayudh", ""], ["Hooker", "Giles", ""]]}, {"id": "1803.08010", "submitter": "Zheng Xie", "authors": "Zheng Xie, Guannan Liu, Junjie Wu, and Yong Tan", "title": "Social Media Would Not Lie: Prediction of the 2016 Taiwan Election via\n  Online Heterogeneous Data", "comments": null, "journal-ref": "EPJ Data Science,2018,7:32", "doi": "10.1140/epjds/s13688-018-0163-7", "report-no": null, "categories": "cs.SI physics.soc-ph stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of online media has attracted researchers from various domains\nto explore human behavior and make interesting predictions. In this research,\nwe leverage heterogeneous social media data collected from various online\nplatforms to predict Taiwan's 2016 presidential election. In contrast to most\nexisting research, we take a \"signal\" view of heterogeneous information and\nadopt the Kalman filter to fuse multiple signals into daily vote predictions\nfor the candidates. We also consider events that influenced the election in a\nquantitative manner based on the so-called event study model that originated in\nthe field of financial research. We obtained the following interesting\nfindings. First, public opinions in online media dominate traditional polls in\nTaiwan election prediction in terms of both predictive power and timeliness.\nBut offline polls can still function on alleviating the sample bias of online\nopinions. Second, although online signals converge as election day approaches,\nthe simple Facebook \"Like\" is consistently the strongest indicator of the\nelection result. Third, most influential events have a strong connection to\ncross-strait relations, and the Chou Tzu-yu flag incident followed by the\napology video one day before the election increased the vote share of Tsai\nIng-Wen by 3.66%. This research justifies the predictive power of online media\nin politics and the advantages of information fusion. The combined use of the\nKalman filter and the event study method contributes to the data-driven\npolitical analytics paradigm for both prediction and attribution purposes.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:53:19 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 01:44:22 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Xie", "Zheng", ""], ["Liu", "Guannan", ""], ["Wu", "Junjie", ""], ["Tan", "Yong", ""]]}, {"id": "1803.08021", "submitter": "Shusen Wang", "authors": "Miles E. Lopes, Shusen Wang, Michael W. Mahoney", "title": "Error Estimation for Randomized Least-Squares Algorithms via the\n  Bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the course of the past decade, a variety of randomized algorithms have\nbeen proposed for computing approximate least-squares (LS) solutions in\nlarge-scale settings. A longstanding practical issue is that, for any given\ninput, the user rarely knows the actual error of an approximate solution\n(relative to the exact solution). Likewise, it is difficult for the user to\nknow precisely how much computation is needed to achieve the desired error\ntolerance. Consequently, the user often appeals to worst-case error bounds that\ntend to offer only qualitative guidance. As a more practical alternative, we\npropose a bootstrap method to compute a posteriori error estimates for\nrandomized LS algorithms. These estimates permit the user to numerically assess\nthe error of a given solution, and to predict how much work is needed to\nimprove a \"preliminary\" solution. In addition, we provide theoretical\nconsistency results for the method, which are the first such results in this\ncontext (to the best of our knowledge). From a practical standpoint, the method\nalso has considerable flexibility, insofar as it can be applied to several\npopular sketching algorithms, as well as a variety of error metrics. Moreover,\nthe extra step of error estimation does not add much cost to an underlying\nsketching algorithm. Finally, we demonstrate the effectiveness of the method\nwith empirical results.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:19:41 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 05:01:36 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Lopes", "Miles E.", ""], ["Wang", "Shusen", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1803.08066", "submitter": "Katherine Fraser", "authors": "Katherine Fraser and Matthew D. Schwartz", "title": "Jet Charge and Machine Learning", "comments": "17 pages, 8 figures, 1 table; Updated to JHEP version", "journal-ref": "JHEP10 (2018) 093", "doi": "10.1007/JHEP10(2018)093", "report-no": null, "categories": "hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning techniques, such as convolutional, recurrent and\nrecursive neural networks, have shown promise for jet substructure at the Large\nHadron Collider. For example, they have demonstrated effectiveness at boosted\ntop or W boson identification or for quark/gluon discrimination. We explore\nthese methods for the purpose of classifying jets according to their electric\ncharge. We find that both neural networks that incorporate distance within the\njet as an input and boosted decision trees including radial distance\ninformation can provide significant improvement in jet charge extraction over\ncurrent methods. Specifically, convolutional, recurrent, and recursive networks\ncan provide the largest improvement over traditional methods, in part by\neffectively utilizing distance within the jet or clustering history. The\nadvantages of using a fixed-size input representation (as with the CNN) or a\nsmall input representation (as with the RNN) suggest that both convolutional\nand recurrent networks will be essential to the future of modern machine\nlearning at colliders.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 18:02:02 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 19:07:53 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Fraser", "Katherine", ""], ["Schwartz", "Matthew D.", ""]]}, {"id": "1803.08089", "submitter": "Massimiliano Pontil", "authors": "Giulia Denevi, Carlo Ciliberto, Dimitris Stamos, Massimiliano Pontil", "title": "Incremental Learning-to-Learn with Statistical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learning-to-learn the goal is to infer a learning algorithm that works\nwell on a class of tasks sampled from an unknown meta distribution. In contrast\nto previous work on batch learning-to-learn, we consider a scenario where tasks\nare presented sequentially and the algorithm needs to adapt incrementally to\nimprove its performance on future tasks. Key to this setting is for the\nalgorithm to rapidly incorporate new observations into the model as they\narrive, without keeping them in memory. We focus on the case where the\nunderlying algorithm is ridge regression parameterized by a positive\nsemidefinite matrix. We propose to learn this matrix by applying a stochastic\nstrategy to minimize the empirical error incurred by ridge regression on future\ntasks sampled from the meta distribution. We study the statistical properties\nof the proposed algorithm and prove non-asymptotic bounds on its excess\ntransfer risk, that is, the generalization performance on new tasks from the\nsame meta distribution. We compare our online learning-to-learn approach with a\nstate of the art batch method, both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 18:50:18 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Denevi", "Giulia", ""], ["Ciliberto", "Carlo", ""], ["Stamos", "Dimitris", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1803.08101", "submitter": "Geoff Boeing", "authors": "Geoff Boeing", "title": "Clustering to Reduce Spatial Data Set Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally it had been a problem that researchers did not have access to\nenough spatial data to answer pressing research questions or build compelling\nvisualizations. Today, however, the problem is often that we have too much\ndata. Spatially redundant or approximately redundant points may refer to a\nsingle feature (plus noise) rather than many distinct spatial features. We use\na machine learning approach with density-based clustering to compress such\nspatial data into a set of representative features.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 19:38:27 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Boeing", "Geoff", ""]]}, {"id": "1803.08118", "submitter": "David Burns", "authors": "David M. Burns, Cari M. Whyne", "title": "Seglearn: A Python Package for Learning Sequences and Time Series", "comments": null, "journal-ref": "Journal of Machine Learning Research 19 (2018) 1-7", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seglearn is an open-source python package for machine learning time series or\nsequences using a sliding window segmentation approach. The implementation\nprovides a flexible pipeline for tackling classification, regression, and\nforecasting problems with multivariate sequence and contextual data. This\npackage is compatible with scikit-learn and is listed under scikit-learn\nRelated Projects. The package depends on numpy, scipy, and scikit-learn.\nSeglearn is distributed under the BSD 3-Clause License. Documentation includes\na detailed API description, user guide, and examples. Unit tests provide a high\ndegree of code coverage.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 20:30:34 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 19:45:08 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 17:11:55 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Burns", "David M.", ""], ["Whyne", "Cari M.", ""]]}, {"id": "1803.08137", "submitter": "Sathya N. Ravi", "authors": "Sathya N. Ravi, Ronak Mehta, Vikas Singh", "title": "Robust Blind Deconvolution via Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the Blind Deconvolution problem with a focus on understanding its\nrobustness and convergence properties. Provable robustness to noise and other\nperturbations is receiving recent interest in vision, from obtaining immunity\nto adversarial attacks to assessing and describing failure modes of algorithms\nin mission critical applications. Further, many blind deconvolution methods\nbased on deep architectures internally make use of or optimize the basic\nformulation, so a clearer understanding of how this sub-module behaves, when it\ncan be solved, and what noise injection it can tolerate is a first order\nrequirement. We derive new insights into the theoretical underpinnings of blind\ndeconvolution. The algorithm that emerges has nice convergence guarantees and\nis provably robust in a sense we formalize in the paper. Interestingly, these\ntechnical results play out very well in practice, where on standard datasets\nour algorithm yields results competitive with or superior to the state of the\nart. Keywords: blind deconvolution, robust continuous optimization\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 20:55:26 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Ravi", "Sathya N.", ""], ["Mehta", "Ronak", ""], ["Singh", "Vikas", ""]]}, {"id": "1803.08153", "submitter": "Arash Behboodi", "authors": "Linchen Xiao, Arash Behboodi, Rudolf Mathar", "title": "Learning the Localization Function: Machine Learning Approach to\n  Fingerprinting Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considered as a data-driven approach, Fingerprinting Localization Solutions\n(FPSs) enjoy huge popularity due to their good performance and minimal\nenvironment information requirement. This papers addresses applications of\nartificial intelligence to solve two problems in Received Signal Strength\nIndicator (RSSI) based FPS, first the cumbersome training database construction\nand second the extrapolation of fingerprinting algorithm for similar buildings\nwith slight environmental changes. After a concise overview of deep learning\ndesign techniques, two main techniques widely used in deep learning are\nexploited for the above mentioned issues namely data augmentation and transfer\nlearning. We train a multi-layer neural network that learns the mapping from\nthe observations to the locations. A data augmentation method is proposed to\nincrease the training database size based on the structure of RSSI measurements\nand hence reducing effectively the amount of training data. Then it is shown\nexperimentally how a model trained for a particular building can be transferred\nto a similar one by fine tuning with significantly smaller training numbers.\nThe paper implicitly discusses the new guidelines to consider about deep\nlearning designs when they are employed in a new application context.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 22:25:34 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Xiao", "Linchen", ""], ["Behboodi", "Arash", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1803.08161", "submitter": "Xiao Chen", "authors": "C. Soizea, R. Ghanem, C. Safta, X. Huan, Z. P. Vane, J. Oefelein, G.\n  Lacaz, H. N. Najm, Q. Tang, X. Chen", "title": "Entropy-based closure for probabilistic learning on manifolds", "comments": "Co author is not happy with the paper would like to withdraw\n  submission and improve the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, the authors proposed a general methodology for\nprobabilistic learning on manifolds. The method was used to generate numerical\nsamples that are statistically consistent with an existing dataset construed as\na realization from a non-Gaussian random vector. The manifold structure is\nlearned using diffusion manifolds and the statistical sample generation is\naccomplished using a projected Ito stochastic differential equation. This\nprobabilistic learning approach has been extended to polynomial chaos\nrepresentation of databases on manifolds and to probabilistic nonconvex\nconstrained optimization with a fixed budget of function evaluations. The\nmethodology introduces an isotropic-diffusion kernel with hyperparameter\n{\\epsilon}. Currently, {\\epsilon} is more or less arbitrarily chosen. In this\npaper, we propose a selection criterion for identifying an optimal value of\n{\\epsilon}, based on a maximum entropy argument. The result is a comprehensive,\nclosed, probabilistic model for characterizing data sets with hidden\nconstraints. This entropy argument ensures that out of all possible models,\nthis is the one that is the most uncertain beyond any specified constraints,\nwhich is selected. Applications are presented for several databases.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 22:46:31 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 21:22:19 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Soizea", "C.", ""], ["Ghanem", "R.", ""], ["Safta", "C.", ""], ["Huan", "X.", ""], ["Vane", "Z. P.", ""], ["Oefelein", "J.", ""], ["Lacaz", "G.", ""], ["Najm", "H. N.", ""], ["Tang", "Q.", ""], ["Chen", "X.", ""]]}, {"id": "1803.08178", "submitter": "Zac Cranko", "authors": "Zac Cranko and Richard Nock", "title": "Boosted Density Estimation Remastered", "comments": "Contains lots of essential info", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been a steady increase in the number iterative approaches\nto density estimation. However, an accompanying burst of formal convergence\nguarantees has not followed; all results pay the price of heavy assumptions\nwhich are often unrealistic or hard to check. The Generative Adversarial\nNetwork (GAN) literature --- seemingly orthogonal to the aforementioned pursuit\n--- has had the side effect of a renewed interest in variational divergence\nminimisation (notably $f$-GAN). We show that by introducing a weak learning\nassumption (in the sense of the classical boosting framework) we are able to\nimport some recent results from the GAN literature to develop an iterative\nboosted density estimation algorithm, including formal convergence results with\nrates, that does not suffer the shortcomings other approaches. We show that the\ndensity fit is an exponential family, and as part of our analysis obtain an\nimproved variational characterisation of $f$-GAN.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 00:09:00 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 01:52:06 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 03:45:54 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Cranko", "Zac", ""], ["Nock", "Richard", ""]]}, {"id": "1803.08182", "submitter": "Panos Stinis", "authors": "Panos Stinis, Tobias Hagge, Alexandre M. Tartakovsky, Enoch Yeung", "title": "Enforcing constraints for interpolation and extrapolation in Generative\n  Adversarial Networks", "comments": "29 pages; v2 has major text revision/restructuring, includes results\n  for the Lorenz system and has several more references", "journal-ref": null, "doi": "10.1016/j.jcp.2019.07.042", "report-no": "PNNL-SA-133233", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest ways to enforce given constraints in the output of a Generative\nAdversarial Network (GAN) generator both for interpolation and extrapolation\n(prediction). For the case of dynamical systems, given a time series, we wish\nto train GAN generators that can be used to predict trajectories starting from\na given initial condition. In this setting, the constraints can be in algebraic\nand/or differential form. Even though we are predominantly interested in the\ncase of extrapolation, we will see that the tasks of interpolation and\nextrapolation are related. However, they need to be treated differently.\n  For the case of interpolation, the incorporation of constraints is built into\nthe training of the GAN. The incorporation of the constraints respects the\nprimary game-theoretic setup of a GAN so it can be combined with existing\nalgorithms. However, it can exacerbate the problem of instability during\ntraining that is well-known for GANs. We suggest adding small noise to the\nconstraints as a simple remedy that has performed well in our numerical\nexperiments.\n  The case of extrapolation (prediction) is more involved. During training, the\nGAN generator learns to interpolate a noisy version of the data and we enforce\nthe constraints. This approach has connections with model reduction that we can\nutilize to improve the efficiency and accuracy of the training. Depending on\nthe form of the constraints, we may enforce them also during prediction through\na projection step. We provide examples of linear and nonlinear systems of\ndifferential equations to illustrate the various constructions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 00:25:07 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 21:33:03 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Stinis", "Panos", ""], ["Hagge", "Tobias", ""], ["Tartakovsky", "Alexandre M.", ""], ["Yeung", "Enoch", ""]]}, {"id": "1803.08198", "submitter": "Hoi-To Wai", "authors": "Hoi-To Wai, Nikolaos M. Freris, Angelia Nedic, Anna Scaglione", "title": "SUCAG: Stochastic Unbiased Curvature-aided Gradient Method for\n  Distributed Optimization", "comments": "to appear in CDC 2018, 17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose and analyze a new stochastic gradient method, which we call\nStochastic Unbiased Curvature-aided Gradient (SUCAG), for finite sum\noptimization problems. SUCAG constitutes an unbiased total gradient tracking\ntechnique that uses Hessian information to accelerate con- vergence. We analyze\nour method under the general asynchronous model of computation, in which each\nfunction is selected infinitely often with possibly unbounded (but sublinear)\ndelay. For strongly convex problems, we establish linear convergence for the\nSUCAG method. When the initialization point is sufficiently close to the\noptimal solution, the established convergence rate is only dependent on the\ncondition number of the problem, making it strictly faster than the known rate\nfor the SAGA method. Furthermore, we describe a Markov-driven approach of\nimplementing the SUCAG method in a distributed asynchronous multi-agent\nsetting, via gossiping along a random walk on an undirected communication\ngraph. We show that our analysis applies as long as the graph is connected and,\nnotably, establishes an asymptotic linear convergence rate that is robust to\nthe graph topology. Numerical results demonstrate the merits of our algorithm\nover existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 01:46:49 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 23:09:36 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Wai", "Hoi-To", ""], ["Freris", "Nikolaos M.", ""], ["Nedic", "Angelia", ""], ["Scaglione", "Anna", ""]]}, {"id": "1803.08203", "submitter": "Kamil Nar", "authors": "Kamil Nar, Shankar Sastry", "title": "Residual Networks: Lyapunov Stability and Convex Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While training error of most deep neural networks degrades as the depth of\nthe network increases, residual networks appear to be an exception. We show\nthat the main reason for this is the Lyapunov stability of the gradient descent\nalgorithm: for an arbitrarily chosen step size, the equilibria of the gradient\ndescent are most likely to remain stable for the parametrization of residual\nnetworks. We then present an architecture with a pair of residual networks to\napproximate a large class of functions by decomposing them into a convex and a\nconcave part. Some parameters of this model are shown to change little during\ntraining, and this imperfect optimization prevents overfitting the data and\nleads to solutions with small Lipschitz constants, while providing clues about\nthe generalization of other deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 02:14:08 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Nar", "Kamil", ""], ["Sastry", "Shankar", ""]]}, {"id": "1803.08207", "submitter": "Tristan Bepler", "authors": "Tristan Bepler, Andrew Morin, Julia Brasch, Lawrence Shapiro, Alex J.\n  Noble, and Bonnie Berger", "title": "Positive-unlabeled convolutional neural networks for particle picking in\n  cryo-electron micrographs", "comments": "43 pages, 5 main figures, 6 supplemental figures", "journal-ref": "Nature Methods (2019)", "doi": "10.1038/s41592-019-0575-8", "report-no": null, "categories": "q-bio.QM cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryo-electron microscopy (cryoEM) is an increasingly popular method for\nprotein structure determination. However, identifying a sufficient number of\nparticles for analysis (often >100,000) can take months of manual effort.\nCurrent computational approaches are limited by high false positive rates and\nrequire significant ad-hoc post-processing, especially for unusually shaped\nparticles. To address this shortcoming, we develop Topaz, an efficient and\naccurate particle picking pipeline using neural networks trained with few\nlabeled particles by newly leveraging the remaining unlabeled particles through\nthe framework of positive-unlabeled (PU) learning. Remarkably, despite using\nminimal labeled particles, Topaz allows us to improve reconstruction resolution\nby up to 0.15 {\\AA} over published particles on three public cryoEM datasets\nwithout any post-processing. Furthermore, we show that our novel\ngeneralized-expectation criteria approach to PU learning outperforms existing\ngeneral PU learning approaches when applied to particle detection, especially\nfor challenging datasets of non-globular proteins. We expect Topaz to be an\nessential component of cryoEM analysis.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 02:24:22 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 19:18:18 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Bepler", "Tristan", ""], ["Morin", "Andrew", ""], ["Brasch", "Julia", ""], ["Shapiro", "Lawrence", ""], ["Noble", "Alex J.", ""], ["Berger", "Bonnie", ""]]}, {"id": "1803.08276", "submitter": "Maxime Jumelle", "authors": "Maxime Jumelle, Taqiyeddine Sakmeche", "title": "Speaker Clustering With Neural Networks And Audio Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speaker clustering is the task of differentiating speakers in a recording. In\na way, the aim is to answer \"who spoke when\" in audio recordings. A common\nmethod used in industry is feature extraction directly from the recording\nthanks to MFCC features, and by using well-known techniques such as Gaussian\nMixture Models (GMM) and Hidden Markov Models (HMM). In this paper, we studied\nneural networks (especially CNN) followed by clustering and audio processing in\nthe quest to reach similar accuracy to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 09:21:56 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Jumelle", "Maxime", ""], ["Sakmeche", "Taqiyeddine", ""]]}, {"id": "1803.08312", "submitter": "Antonio Pertusa", "authors": "Aurelia Bustos and Antonio Pertusa", "title": "Learning Eligibility in Cancer Clinical Trials using Deep Neural\n  Networks", "comments": null, "journal-ref": "Applied Sciences, 8(7), 2018", "doi": "10.3390/app8071206", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interventional cancer clinical trials are generally too restrictive, and some\npatients are often excluded on the basis of comorbidity, past or concomitant\ntreatments, or the fact that they are over a certain age. The efficacy and\nsafety of new treatments for patients with these characteristics are,\ntherefore, not defined. In this work, we built a model to automatically predict\nwhether short clinical statements were considered inclusion or exclusion\ncriteria. We used protocols from cancer clinical trials that were available in\npublic registries from the last 18 years to train word-embeddings, and we\nconstructed a~dataset of 6M short free-texts labeled as eligible or not\neligible. A text classifier was trained using deep neural networks, with\npre-trained word-embeddings as inputs, to predict whether or not short\nfree-text statements describing clinical information were considered eligible.\nWe additionally analyzed the semantic reasoning of the word-embedding\nrepresentations obtained and were able to identify equivalent treatments for a\ntype of tumor analogous with the drugs used to treat other tumors. We show that\nrepresentation learning using {deep} neural networks can be successfully\nleveraged to extract the medical knowledge from clinical trial protocols for\npotentially assisting practitioners when prescribing treatments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 11:38:53 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 14:45:57 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 10:06:35 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Bustos", "Aurelia", ""], ["Pertusa", "Antonio", ""]]}, {"id": "1803.08355", "submitter": "Alexandre Garcia", "authors": "Alexandre Garcia, Slim Essid, Chlo\\'e Clavel, Florence d'Alch\\'e-Buc", "title": "Structured Output Learning with Abstention: Application to Accurate\n  Opinion Prediction", "comments": null, "journal-ref": "Proceedings of Machine Learning Research 80 (2018) 1695-1703", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by Supervised Opinion Analysis, we propose a novel framework\ndevoted to Structured Output Learning with Abstention (SOLA). The structure\nprediction model is able to abstain from predicting some labels in the\nstructured output at a cost chosen by the user in a flexible way. For that\npurpose, we decompose the problem into the learning of a pair of predictors,\none devoted to structured abstention and the other, to structured output\nprediction. To compare fully labeled training data with predictions potentially\ncontaining abstentions, we define a wide class of asymmetric abstention-aware\nlosses. Learning is achieved by surrogate regression in an appropriate feature\nspace while prediction with abstention is performed by solving a new pre-image\nproblem. Thus, SOLA extends recent ideas about Structured Output Prediction via\nsurrogate problems and calibration theory and enjoys statistical guarantees on\nthe resulting excess risk. Instantiated on a hierarchical abstention-aware\nloss, SOLA is shown to be relevant for fine-grained opinion mining and gives\nstate-of-the-art results on this task. Moreover, the abstention-aware\nrepresentations can be used to competitively predict user-review ratings based\non a sentence-level opinion predictor.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 13:48:30 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 13:31:51 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Garcia", "Alexandre", ""], ["Essid", "Slim", ""], ["Clavel", "Chlo\u00e9", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "1803.08367", "submitter": "Hartmut Maennel", "authors": "Hartmut Maennel, Olivier Bousquet, Sylvain Gelly", "title": "Gradient Descent Quantizes ReLU Network Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are often trained in the over-parametrized regime (i.e.\nwith far more parameters than training examples), and understanding why the\ntraining converges to solutions that generalize remains an open problem.\nSeveral studies have highlighted the fact that the training procedure, i.e.\nmini-batch Stochastic Gradient Descent (SGD) leads to solutions that have\nspecific properties in the loss landscape. However, even with plain Gradient\nDescent (GD) the solutions found in the over-parametrized regime are pretty\ngood and this phenomenon is poorly understood.\n  We propose an analysis of this behavior for feedforward networks with a ReLU\nactivation function under the assumption of small initialization and learning\nrate and uncover a quantization effect: The weight vectors tend to concentrate\nat a small number of directions determined by the input data. As a consequence,\nwe show that for given input data there are only finitely many, \"simple\"\nfunctions that can be obtained, independent of the network size. This puts\nthese functions in analogy to linear interpolations (for given input data there\nare finitely many triangulations, which each determine a function by linear\ninterpolation). We ask whether this analogy extends to the generalization\nproperties - while the usual distribution-independent generalization property\ndoes not hold, it could be that for e.g. smooth functions with bounded second\nderivative an approximation property holds which could \"explain\" generalization\nof networks (of unbounded size) to unseen inputs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:08:58 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Maennel", "Hartmut", ""], ["Bousquet", "Olivier", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1803.08374", "submitter": "Shao-Bo Lin", "authors": "Jian Fang, Shaobo Lin, Zongben Xu", "title": "Learning through deterministic assignment of hidden parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning frequently boils down to determining hidden and bright\nparameters in a parameterized hypothesis space based on finite input-output\nsamples. The hidden parameters determine the attributions of hidden predictors\nor the nonlinear mechanism of an estimator, while the bright parameters\ncharacterize how hidden predictors are linearly combined or the linear\nmechanism. In traditional learning paradigm, hidden and bright parameters are\nnot distinguished and trained simultaneously in one learning process. Such an\none-stage learning (OSL) brings a benefit of theoretical analysis but suffers\nfrom the high computational burden. To overcome this difficulty, a two-stage\nlearning (TSL) scheme, featured by learning through deterministic assignment of\nhidden parameters (LtDaHP) was proposed, which suggests to deterministically\ngenerate the hidden parameters by using minimal Riesz energy points on a sphere\nand equally spaced points in an interval. We theoretically show that with such\ndeterministic assignment of hidden parameters, LtDaHP with a neural network\nrealization almost shares the same generalization performance with that of OSL.\nWe also present a series of simulations and application examples to support the\noutperformance of LtDaHP\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:25:39 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 02:41:23 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Fang", "Jian", ""], ["Lin", "Shaobo", ""], ["Xu", "Zongben", ""]]}, {"id": "1803.08375", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "Deep Learning using Rectified Linear Units (ReLU)", "comments": "7 pages, 11 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the use of rectified linear units (ReLU) as the classification\nfunction in a deep neural network (DNN). Conventionally, ReLU is used as an\nactivation function in DNNs, with Softmax function as their classification\nfunction. However, there have been several studies on using a classification\nfunction other than Softmax, and this study is an addition to those. We\naccomplish this by taking the activation of the penultimate layer $h_{n - 1}$\nin a neural network, then multiply it by weight parameters $\\theta$ to get the\nraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,\ni.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide\nclass predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:30:17 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 06:13:13 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1803.08416", "submitter": "Ashkan Panahi", "authors": "Ashkan Panahi, Hamid Krim and Liyi Dai", "title": "Demystifying Deep Learning: A Geometric Approach to Iterative\n  Projections", "comments": "To be appeared in the ICASSP 2018 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric approaches to Learning, such as deep learning (DL), are highly\npopular in nonlinear regression, in spite of their extremely difficult training\nwith their increasing complexity (e.g. number of layers in DL). In this paper,\nwe present an alternative semi-parametric framework which foregoes the\nordinarily required feedback, by introducing the novel idea of geometric\nregularization. We show that certain deep learning techniques such as residual\nnetwork (ResNet) architecture are closely related to our approach. Hence, our\ntechnique can be used to analyze these types of deep learning. Moreover, we\npresent preliminary results which confirm that our approach can be easily\ntrained to obtain complex structures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:49:32 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Panahi", "Ashkan", ""], ["Krim", "Hamid", ""], ["Dai", "Liyi", ""]]}, {"id": "1803.08456", "submitter": "Stephan Alaniz", "authors": "Stephan Alaniz", "title": "Deep Reinforcement Learning with Model Learning and Monte Carlo Tree\n  Search in Minecraft", "comments": "The 3rd Multidisciplinary Conference on Reinforcement Learning and\n  Decision Making (RLDM) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been successfully applied to several\nvisual-input tasks using model-free methods. In this paper, we propose a\nmodel-based approach that combines learning a DNN-based transition model with\nMonte Carlo tree search to solve a block-placing task in Minecraft. Our learned\ntransition model predicts the next frame and the rewards one step ahead given\nthe last four frames of the agent's first-person-view image and the current\naction. Then a Monte Carlo tree search algorithm uses this model to plan the\nbest sequence of actions for the agent to perform. On the proposed task in\nMinecraft, our model-based approach reaches the performance comparable to the\nDeep Q-Network's, but learns faster and, thus, is more training sample\nefficient.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 16:53:34 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Alaniz", "Stephan", ""]]}, {"id": "1803.08471", "submitter": "Hanna Wallach", "authors": "Aaron Schein, Zhiwei Steven Wu, Alexandra Schofield, Mingyuan Zhou,\n  Hanna Wallach", "title": "Locally Private Bayesian Inference for Count Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general method for privacy-preserving Bayesian inference in\nPoisson factorization, a broad class of models that includes some of the most\nwidely used models in the social sciences. Our method satisfies limited\nprecision local privacy, a generalization of local differential privacy, which\nwe introduce to formulate privacy guarantees appropriate for sparse count data.\nWe develop an MCMC algorithm that approximates the locally private posterior\nover model parameters given data that has been locally privatized by the\ngeometric mechanism (Ghosh et al., 2012). Our solution is based on two\ninsights: 1) a novel reinterpretation of the geometric mechanism in terms of\nthe Skellam distribution (Skellam, 1946) and 2) a general theorem that relates\nthe Skellam to the Bessel distribution (Yuan & Kalbfleisch, 2000). We\ndemonstrate our method in two case studies on real-world email data in which we\nshow that our method consistently outperforms the commonly-used naive approach,\nobtaining higher quality topics in text and more accurate link prediction in\nnetworks. On some tasks, our privacy-preserving method even outperforms\nnon-private inference which conditions on the true data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:14:29 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 01:20:02 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 21:44:51 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Schein", "Aaron", ""], ["Wu", "Zhiwei Steven", ""], ["Schofield", "Alexandra", ""], ["Zhou", "Mingyuan", ""], ["Wallach", "Hanna", ""]]}, {"id": "1803.08475", "submitter": "Wouter Kool", "authors": "Wouter Kool, Herke van Hoof and Max Welling", "title": "Attention, Learn to Solve Routing Problems!", "comments": "Accepted at ICLR 2019. 25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently presented idea to learn heuristics for combinatorial\noptimization problems is promising as it can save costly development. However,\nto push this idea towards practical implementation, we need better models and\nbetter ways of training. We contribute in both directions: we propose a model\nbased on attention layers with benefits over the Pointer Network and we show\nhow to train this model using REINFORCE with a simple baseline based on a\ndeterministic greedy rollout, which we find is more efficient than using a\nvalue function. We significantly improve over recent learned heuristics for the\nTravelling Salesman Problem (TSP), getting close to optimal results for\nproblems up to 100 nodes. With the same hyperparameters, we learn strong\nheuristics for two variants of the Vehicle Routing Problem (VRP), the\nOrienteering Problem (OP) and (a stochastic variant of) the Prize Collecting\nTSP (PCTSP), outperforming a wide range of baselines and getting results close\nto highly optimized and specialized algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:22:24 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 12:37:55 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 09:10:08 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Kool", "Wouter", ""], ["van Hoof", "Herke", ""], ["Welling", "Max", ""]]}, {"id": "1803.08533", "submitter": "Lewis Smith", "authors": "Lewis Smith and Yarin Gal", "title": "Understanding Measures of Uncertainty for Adversarial Example Detection", "comments": "10 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring uncertainty is a promising technique for detecting adversarial\nexamples, crafted inputs on which the model predicts an incorrect class with\nhigh confidence. But many measures of uncertainty exist, including predictive\nen- tropy and mutual information, each capturing different types of\nuncertainty. We study these measures, and shed light on why mutual information\nseems to be effective at the task of adversarial example detection. We\nhighlight failure modes for MC dropout, a widely used approach for estimating\nuncertainty in deep models. This leads to an improved understanding of the\ndrawbacks of current methods, and a proposal to improve the quality of\nuncertainty estimates using probabilistic model ensembles. We give illustrative\nexperiments using MNIST to demonstrate the intuition underlying the different\nmeasures of uncertainty, as well as experiments on a real world Kaggle dogs vs\ncats classification dataset.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 18:26:22 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Smith", "Lewis", ""], ["Gal", "Yarin", ""]]}, {"id": "1803.08577", "submitter": "Francois Fagan", "authors": "Francois Fagan and Garud Iyengar", "title": "Unbiased scalable softmax optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural network and language models rely on softmax distributions with\nan extremely large number of categories. Since calculating the softmax\nnormalizing constant in this context is prohibitively expensive, there is a\ngrowing literature of efficiently computable but biased estimates of the\nsoftmax. In this paper we propose the first unbiased algorithms for maximizing\nthe softmax likelihood whose work per iteration is independent of the number of\nclasses and datapoints (and no extra work is required at the end of each\nepoch). We show that our proposed unbiased methods comprehensively outperform\nthe state-of-the-art on seven real world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 20:32:32 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Fagan", "Francois", ""], ["Iyengar", "Garud", ""]]}, {"id": "1803.08584", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Tingran Gao, and James Evans", "title": "Curvature of Hypergraphs via Multi-Marginal Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DM cs.SI math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel definition of curvature for hypergraphs, a natural\ngeneralization of graphs, by introducing a multi-marginal optimal transport\nproblem for a naturally defined random walk on the hypergraph. This curvature,\ntermed \\emph{coarse scalar curvature}, generalizes a recent definition of Ricci\ncurvature for Markov chains on metric spaces by Ollivier [Journal of Functional\nAnalysis 256 (2009) 810-864], and is related to the scalar curvature when the\nhypergraph arises naturally from a Riemannian manifold. We investigate basic\nproperties of the coarse scalar curvature and obtain several bounds. Empirical\nexperiments indicate that coarse scalar curvatures are capable of detecting\n\"bridges\" across connected components in hypergraphs, suggesting it is an\nappropriate generalization of curvature on simple graphs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 21:13:35 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Gao", "Tingran", ""], ["Evans", "James", ""]]}, {"id": "1803.08586", "submitter": "Yining Wang", "authors": "Yining Wang, Sivaraman Balakrishnan, Aarti Singh", "title": "Optimization of Smooth Functions with Noisy Observations: Local Minimax\n  Rates", "comments": "29 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of global optimization of an unknown non-convex\nsmooth function with zeroth-order feedback. In this setup, an algorithm is\nallowed to adaptively query the underlying function at different locations and\nreceives noisy evaluations of function values at the queried points (i.e. the\nalgorithm has access to zeroth-order information). Optimization performance is\nevaluated by the expected difference of function values at the estimated\noptimum and the true optimum. In contrast to the classical optimization setup,\nfirst-order information like gradients are not directly accessible to the\noptimization algorithm. We show that the classical minimax framework of\nanalysis, which roughly characterizes the worst-case query complexity of an\noptimization algorithm in this setting, leads to excessively pessimistic\nresults. We propose a local minimax framework to study the fundamental\ndifficulty of optimizing smooth functions with adaptive function evaluations,\nwhich provides a refined picture of the intrinsic difficulty of zeroth-order\noptimization. We show that for functions with fast level set growth around the\nglobal minimum, carefully designed optimization algorithms can identify a near\nglobal minimizer with many fewer queries. For the special case of strongly\nconvex and smooth functions, our implied convergence rates match the ones\ndeveloped for zeroth-order convex optimization problems. At the other end of\nthe spectrum, for worst-case smooth functions no algorithm can converge faster\nthan the minimax rate of estimating the entire unknown function in the\n$\\ell_\\infty$-norm. We provide an intuitive and efficient algorithm that\nattains the derived upper error bounds.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 21:21:02 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Wang", "Yining", ""], ["Balakrishnan", "Sivaraman", ""], ["Singh", "Aarti", ""]]}, {"id": "1803.08591", "submitter": "Di Chen", "authors": "Di Chen, Yexiang Xue, Carla P. Gomes", "title": "End-to-End Learning for the Deep Multivariate Probit Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multivariate probit model (MVP) is a popular classic model for studying\nbinary responses of multiple entities. Nevertheless, the computational\nchallenge of learning the MVP model, given that its likelihood involves\nintegrating over a multidimensional constrained space of latent variables,\nsignificantly limits its application in practice. We propose a flexible deep\ngeneralization of the classic MVP, the Deep Multivariate Probit Model (DMVP),\nwhich is an end-to-end learning scheme that uses an efficient parallel sampling\nprocess of the multivariate probit model to exploit GPU-boosted deep neural\nnetworks. We present both theoretical and empirical analysis of the convergence\nbehavior of DMVP's sampling process with respect to the resolution of the\ncorrelation structure. We provide convergence guarantees for DMVP and our\nempirical analysis demonstrates the advantages of DMVP's sampling compared with\nstandard MCMC-based methods. We also show that when applied to multi-entity\nmodelling problems, which are natural DMVP applications, DMVP trains faster\nthan classical MVP, by at least an order of magnitude, captures rich\ncorrelations among entities, and further improves the joint likelihood of\nentities compared with several competitive models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 21:35:39 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 23:57:40 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 23:58:27 GMT"}, {"version": "v4", "created": "Fri, 13 Jul 2018 07:40:03 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Chen", "Di", ""], ["Xue", "Yexiang", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1803.08600", "submitter": "Philippe Von Wurstemberger", "authors": "Arnulf Jentzen and Philippe von Wurstemberger", "title": "Lower error bounds for the stochastic gradient descent optimization\n  algorithm: Sharp convergence rates for slowly and fast decaying learning\n  rates", "comments": "42 pages", "journal-ref": "J. Complexity 57 (2020), 101438", "doi": "10.1016/j.jco.2019.101438", "report-no": null, "categories": "math.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic gradient descent (SGD) optimization algorithm plays a central\nrole in a series of machine learning applications. The scientific literature\nprovides a vast amount of upper error bounds for the SGD method. Much less\nattention as been paid to proving lower error bounds for the SGD method. It is\nthe key contribution of this paper to make a step in this direction. More\nprecisely, in this article we establish for every $\\gamma, \\nu \\in (0,\\infty)$\nessentially matching lower and upper bounds for the mean square error of the\nSGD process with learning rates $(\\frac{\\gamma}{n^\\nu})_{n \\in \\mathbb{N}}$\nassociated to a simple quadratic stochastic optimization problem. This allows\nus to precisely quantify the mean square convergence rate of the SGD method in\ndependence on the asymptotic behavior of the learning rates.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 22:31:03 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Jentzen", "Arnulf", ""], ["von Wurstemberger", "Philippe", ""]]}, {"id": "1803.08647", "submitter": "Hao Ge", "authors": "Hao Ge, Yin Xia, Xu Chen, Randall Berry and Ying Wu", "title": "Fictitious GAN: Training GANs with Historical Models", "comments": "19 pages. First three authors have equal contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are powerful tools for learning\ngenerative models. In practice, the training may suffer from lack of\nconvergence. GANs are commonly viewed as a two-player zero-sum game between two\nneural networks. Here, we leverage this game theoretic view to study the\nconvergence behavior of the training process. Inspired by the fictitious play\nlearning process, a novel training method, referred to as Fictitious GAN, is\nintroduced. Fictitious GAN trains the deep neural networks using a mixture of\nhistorical models. Specifically, the discriminator (resp. generator) is updated\naccording to the best-response to the mixture outputs from a sequence of\npreviously trained generators (resp. discriminators). It is shown that\nFictitious GAN can effectively resolve some convergence issues that cannot be\nresolved by the standard training approach. It is proved that asymptotically\nthe average of the generator outputs has the same distribution as the data\nsamples.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 03:46:12 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 18:50:03 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Ge", "Hao", ""], ["Xia", "Yin", ""], ["Chen", "Xu", ""], ["Berry", "Randall", ""], ["Wu", "Ying", ""]]}, {"id": "1803.08651", "submitter": "Rahul Meshram", "authors": "Rahul Meshram, D. Manjunath and Nikhil Karamchandani", "title": "Learning Recommendations While Influencing Interests", "comments": "13 pages, submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized recommendation systems (RS) are extensively used in many\nservices. Many of these are based on learning algorithms where the RS uses the\nrecommendation history and the user response to learn an optimal strategy.\nFurther, these algorithms are based on the assumption that the user interests\nare rigid. Specifically, they do not account for the effect of learning\nstrategy on the evolution of the user interests. In this paper we develop\ninfluence models for a learning algorithm that is used to optimally recommend\nwebsites to web users. We adapt the model of \\cite{Ioannidis10} to include an\nitem-dependent reward to the RS from the suggestions that are accepted by the\nuser. For this we first develop a static optimisation scheme when all the\nparameters are known. Next we develop a stochastic approximation based learning\nscheme for the RS to learn the optimal strategy when the user profiles are not\nknown. Finally, we describe several user-influence models for the learning\nalgorithm and analyze their effect on the steady user interests and on the\nsteady state optimal strategy as compared to that when the users are not\ninfluenced.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 04:09:24 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Meshram", "Rahul", ""], ["Manjunath", "D.", ""], ["Karamchandani", "Nikhil", ""]]}, {"id": "1803.08661", "submitter": "Saul Toscano-Palmerin", "authors": "Saul Toscano-Palmerin, Peter I. Frazier", "title": "Bayesian Optimization with Expensive Integrands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian optimization algorithm for objective functions that are\nsums or integrals of expensive-to-evaluate functions, allowing noisy\nevaluations. These objective functions arise in multi-task Bayesian\noptimization for tuning machine learning hyperparameters, optimization via\nsimulation, and sequential design of experiments with random environmental\nconditions. Our method is average-case optimal by construction when a single\nevaluation of the integrand remains within our evaluation budget. Achieving\nthis one-step optimality requires solving a challenging value of information\noptimization problem, for which we provide a novel efficient\ndiscretization-free computational method. We also provide consistency proofs\nfor our method in both continuum and discrete finite domains for objective\nfunctions that are sums. In numerical experiments comparing against previous\nstate-of-the-art methods, including those that also leverage sum or integral\nstructure, our method performs as well or better across a wide range of\nproblems and offers significant improvements when evaluations are noisy or the\nintegrand varies smoothly in the integrated variables.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 05:53:26 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Toscano-Palmerin", "Saul", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1803.08667", "submitter": "Pramudita Satria Palar Dr.", "authors": "Pramudita Satria Palar, Koji Shimoyama", "title": "On efficient global optimization via universal Kriging surrogate models", "comments": null, "journal-ref": "Palar, Pramudita Satria, and Koji Shimoyama. \"On efficient global\n  optimization via universal Kriging surrogate models.\" Structural and\n  Multidisciplinary Optimization (2017): 1-21", "doi": "10.1007/s00158-017-1867-1", "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the capability of the universal Kriging (UK)\nmodel for single-objective global optimization applied within an efficient\nglobal optimization (EGO) framework. We implemented this combined UK-EGO\nframework and studied four variants of the UK methods, that is, a UK with a\nfirst-order polynomial, a UK with a second-order polynomial, a blind Kriging\n(BK) implementation from the ooDACE toolbox, and a polynomial-chaos Kriging\n(PCK) implementation. The UK-EGO framework with automatic trend function\nselection derived from the BK and PCK models works by building a UK surrogate\nmodel and then performing optimizations via expected improvement criteria on\nthe Kriging model with the lowest leave-one-out cross-validation error. Next,\nwe studied and compared the UK-EGO variants and standard EGO using five\nsynthetic test functions and one aerodynamic problem. Our results show that the\nproper choice for the trend function through automatic feature selection can\nimprove the optimization performance of UK-EGO relative to EGO. From our\nresults, we found that PCK-EGO was the best variant, as it had more robust\nperformance as compared to the rest of the UK-EGO schemes; however, total-order\nexpansion should be used to generate the candidate trend function set for\nhigh-dimensional problems. Note that, for some test functions, the UK with\npredetermined polynomial trend functions performed better than that of BK and\nPCK, indicating that the use of automatic trend function selection does not\nalways lead to the best quality solutions. We also found that although some\nvariants of UK are not as globally accurate as the ordinary Kriging (OK), they\ncan still identify better-optimized solutions due to the addition of the trend\nfunction, which helps the optimizer locate the global optimum.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 06:25:23 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Palar", "Pramudita Satria", ""], ["Shimoyama", "Koji", ""]]}, {"id": "1803.08680", "submitter": "Daniel Jakubovitz", "authors": "Daniel Jakubovitz, Raja Giryes", "title": "Improving DNN Robustness to Adversarial Attacks using Jacobian\n  Regularization", "comments": "ECCV 2018 Conference Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have lately shown tremendous performance in various\napplications including vision and speech processing tasks. However, alongside\ntheir ability to perform these tasks with such high accuracy, it has been shown\nthat they are highly susceptible to adversarial attacks: a small change in the\ninput would cause the network to err with high confidence. This phenomenon\nexposes an inherent fault in these networks and their ability to generalize\nwell. For this reason, providing robustness to adversarial attacks is an\nimportant challenge in networks training, which has led to extensive research.\nIn this work, we suggest a theoretically inspired novel approach to improve the\nnetworks' robustness. Our method applies regularization using the Frobenius\nnorm of the Jacobian of the network, which is applied as post-processing, after\nregular training has finished. We demonstrate empirically that it leads to\nenhanced robustness results with a minimal change in the original network's\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 07:57:04 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 16:02:08 GMT"}, {"version": "v3", "created": "Sun, 26 Aug 2018 16:43:36 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 09:48:05 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Jakubovitz", "Daniel", ""], ["Giryes", "Raja", ""]]}, {"id": "1803.08700", "submitter": "Nicolas Tremblay", "authors": "Nicolas Tremblay, Simon Barthelm\\'e, Pierre-Olivier Amblard", "title": "Determinantal Point Processes for Coresets", "comments": null, "journal-ref": "Journal of Machine Learning Research 20 (2019) 1-70", "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When faced with a data set too large to be processed all at once, an obvious\nsolution is to retain only part of it. In practice this takes a wide variety of\ndifferent forms, and among them \"coresets\" are especially appealing. A coreset\nis a (small) weighted sample of the original data that comes with the following\nguarantee: a cost function can be evaluated on the smaller set instead of the\nlarger one, with low relative error. For some classes of problems, and via a\ncareful choice of sampling distribution (based on the so-called \"sensitivity\"\nmetric), iid random sampling has turned to be one of the most successful\nmethods for building coresets efficiently. However, independent samples are\nsometimes overly redundant, and one could hope that enforcing diversity would\nlead to better performance. The difficulty lies in proving coreset properties\nin non-iid samples. We show that the coreset property holds for samples formed\nwith determinantal point processes (DPP). DPPs are interesting because they are\na rare example of repulsive point processes with tractable theoretical\nproperties, enabling us to prove general coreset theorems. We apply our results\nto both the k-means and the linear regression problems, and give extensive\nempirical evidence that the small additional computational cost of DPP sampling\ncomes with superior performance over its iid counterpart. Of independent\ninterest, we also provide analytical formulas for the sensitivity in the linear\nregression and 1-means cases.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 09:17:48 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 15:58:34 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 08:18:36 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Tremblay", "Nicolas", ""], ["Barthelm\u00e9", "Simon", ""], ["Amblard", "Pierre-Olivier", ""]]}, {"id": "1803.08773", "submitter": "Chiliang Zhang", "authors": "Chiliang Zhang, Zhimou Yang, Zuochang Ye", "title": "Detecting Adversarial Perturbations with Saliency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel method for detecting adversarial examples by\ntraining a binary classifier with both origin data and saliency data. In the\ncase of image classification model, saliency simply explain how the model make\ndecisions by identifying significant pixels for prediction. A model shows wrong\nclassification output always learns wrong features and shows wrong saliency as\nwell. Our approach shows good performance on detecting adversarial\nperturbations. We quantitatively evaluate generalization ability of the\ndetector, showing that detectors trained with strong adversaries perform well\non weak adversaries.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 12:52:28 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Zhang", "Chiliang", ""], ["Yang", "Zhimou", ""], ["Ye", "Zuochang", ""]]}, {"id": "1803.08784", "submitter": "Stephan Bongers", "authors": "Stephan Bongers, Joris M. Mooij", "title": "From Random Differential Equations to Structural Causal Models: the\n  stochastic case", "comments": "Submitted to UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Differential Equations provide a natural extension of Ordinary\nDifferential Equations to the stochastic setting. We show how, and under which\nconditions, every equilibrium state of a Random Differential Equation (RDE) can\nbe described by a Structural Causal Model (SCM), while pertaining the causal\nsemantics. This provides an SCM that captures the stochastic and causal\nbehavior of the RDE, which can model both cycles and confounders. This enables\nthe study of the equilibrium states of the RDE by applying the theory and\nstatistical tools available for SCMs, for example, marginalizations and Markov\nproperties, as we illustrate by means of an example. Our work thus provides a\ndirect connection between two fields that so far have been developing in\nisolation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 13:20:56 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 09:09:52 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Bongers", "Stephan", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1803.08823", "submitter": "Marin Bukov Dr.", "authors": "Pankaj Mehta, Marin Bukov, Ching-Hao Wang, Alexandre G.R. Day, Clint\n  Richardson, Charles K. Fisher, and David J. Schwab", "title": "A high-bias, low-variance introduction to Machine Learning for\n  physicists", "comments": "Notebooks have been updated. 122 pages, 78 figures, 20 Python\n  notebooks", "journal-ref": "Phyics Reports 810 (2019) 1-124", "doi": "10.1016/j.physrep.2019.03.001", "report-no": null, "categories": "physics.comp-ph cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is one of the most exciting and dynamic areas of modern\nresearch and application. The purpose of this review is to provide an\nintroduction to the core concepts and tools of machine learning in a manner\neasily understood and intuitive to physicists. The review begins by covering\nfundamental concepts in ML and modern statistics such as the bias-variance\ntradeoff, overfitting, regularization, generalization, and gradient descent\nbefore moving on to more advanced topics in both supervised and unsupervised\nlearning. Topics covered in the review include ensemble models, deep learning\nand neural networks, clustering and data visualization, energy-based models\n(including MaxEnt models and Restricted Boltzmann Machines), and variational\nmethods. Throughout, we emphasize the many natural connections between ML and\nstatistical physics. A notable aspect of the review is the use of Python\nJupyter notebooks to introduce modern ML/statistical packages to readers using\nphysics-inspired datasets (the Ising Model and Monte-Carlo simulations of\nsupersymmetric decays of proton-proton collisions). We conclude with an\nextended outlook discussing possible uses of machine learning for furthering\nour understanding of the physical world as well as open problems in ML where\nphysicists may be able to contribute. (Notebooks are available at\nhttps://physics.bu.edu/~pankajm/MLnotebooks.html )\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 14:53:05 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 23:39:08 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 16:51:57 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Mehta", "Pankaj", ""], ["Bukov", "Marin", ""], ["Wang", "Ching-Hao", ""], ["Day", "Alexandre G. R.", ""], ["Richardson", "Clint", ""], ["Fisher", "Charles K.", ""], ["Schwab", "David J.", ""]]}, {"id": "1803.08841", "submitter": "Nikola Konstantinov", "authors": "Dan Alistarh, Christopher De Sa, Nikola Konstantinov", "title": "The Convergence of Stochastic Gradient Descent in Asynchronous Shared\n  Memory", "comments": "To be published in PoDC 2018; 18 pages, 1 figure; Changes: added\n  pseudocode for Algorithm 2, some references and corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is a fundamental algorithm in machine\nlearning, representing the optimization backbone for training several classic\nmodels, from regression to neural networks. Given the recent practical focus on\ndistributed machine learning, significant work has been dedicated to the\nconvergence properties of this algorithm under the inconsistent and noisy\nupdates arising from execution in a distributed environment. However,\nsurprisingly, the convergence properties of this classic algorithm in the\nstandard shared-memory model are still not well-understood.\n  In this work, we address this gap, and provide new convergence bounds for\nlock-free concurrent stochastic gradient descent, executing in the classic\nasynchronous shared memory model, against a strong adaptive adversary. Our\nresults give improved upper and lower bounds on the \"price of asynchrony\" when\nexecuting the fundamental SGD algorithm in a concurrent setting. They show that\nthis classic optimization tool can converge faster and with a wider range of\nparameters than previously known under asynchronous iterations. At the same\ntime, we exhibit a fundamental trade-off between the maximum delay in the\nsystem and the rate at which SGD can converge, which governs the set of\nparameters under which this algorithm can still work efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 15:32:42 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 16:14:39 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Alistarh", "Dan", ""], ["De Sa", "Christopher", ""], ["Konstantinov", "Nikola", ""]]}, {"id": "1803.08882", "submitter": "Alexander B\\\"ottcher", "authors": "Alexander B\\\"ottcher, Wieland Brendel, Bernhard Englitz, Matthias\n  Bethge", "title": "Trace your sources in large-scale data: one ring to find them all", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important preprocessing step in most data analysis pipelines aims to\nextract a small set of sources that explain most of the data. Currently used\nalgorithms for blind source separation (BSS), however, often fail to extract\nthe desired sources and need extensive cross-validation. In contrast, their\nrarely used probabilistic counterparts can get away with little\ncross-validation and are more accurate and reliable but no simple and scalable\nimplementations are available. Here we present a novel probabilistic BSS\nframework (DECOMPOSE) that can be flexibly adjusted to the data, is extensible\nand easy to use, adapts to individual sources and handles large-scale data\nthrough algorithmic efficiency. DECOMPOSE encompasses and generalises many\ntraditional BSS algorithms such as PCA, ICA and NMF and we demonstrate\nsubstantial improvements in accuracy and robustness on artificial and real\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 16:56:13 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["B\u00f6ttcher", "Alexander", ""], ["Brendel", "Wieland", ""], ["Englitz", "Bernhard", ""], ["Bethge", "Matthias", ""]]}, {"id": "1803.08917", "submitter": "Zeyuan Allen-Zhu", "authors": "Dan Alistarh, Zeyuan Allen-Zhu, Jerry Li", "title": "Byzantine Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of distributed stochastic optimization in an\nadversarial setting where, out of the $m$ machines which allegedly compute\nstochastic gradients every iteration, an $\\alpha$-fraction are Byzantine, and\ncan behave arbitrarily and adversarially. Our main result is a variant of\nstochastic gradient descent (SGD) which finds $\\varepsilon$-approximate\nminimizers of convex functions in $T = \\tilde{O}\\big( \\frac{1}{\\varepsilon^2 m}\n+ \\frac{\\alpha^2}{\\varepsilon^2} \\big)$ iterations. In contrast, traditional\nmini-batch SGD needs $T = O\\big( \\frac{1}{\\varepsilon^2 m} \\big)$ iterations,\nbut cannot tolerate Byzantine failures. Further, we provide a lower bound\nshowing that, up to logarithmic factors, our algorithm is\ninformation-theoretically optimal both in terms of sampling complexity and time\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 17:58:54 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Alistarh", "Dan", ""], ["Allen-Zhu", "Zeyuan", ""], ["Li", "Jerry", ""]]}, {"id": "1803.08978", "submitter": "Bokai Cao", "authors": "Bokai Cao", "title": "Broad Learning for Healthcare", "comments": "PhD Thesis, University of Illinois at Chicago, March 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A broad spectrum of data from different modalities are generated in the\nhealthcare domain every day, including scalar data (e.g., clinical measures\ncollected at hospitals), tensor data (e.g., neuroimages analyzed by research\ninstitutes), graph data (e.g., brain connectivity networks), and sequence data\n(e.g., digital footprints recorded on smart sensors). Capability for modeling\ninformation from these heterogeneous data sources is potentially transformative\nfor investigating disease mechanisms and for informing therapeutic\ninterventions.\n  Our works in this thesis attempt to facilitate healthcare applications in the\nsetting of broad learning which focuses on fusing heterogeneous data sources\nfor a variety of synergistic knowledge discovery and machine learning tasks. We\nare generally interested in computer-aided diagnosis, precision medicine, and\nmobile health by creating accurate user profiles which include important\nbiomarkers, brain connectivity patterns, and latent representations. In\nparticular, our works involve four different data mining problems with\napplication to the healthcare domain: multi-view feature selection, subgraph\npattern mining, brain network embedding, and multi-view sequence prediction.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:01:20 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Cao", "Bokai", ""]]}, {"id": "1803.08979", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "From Shannon's Channel to Semantic Channel via New Bayes' Formulas for\n  Machine Learning", "comments": "17 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A group of transition probability functions form a Shannon's channel whereas\na group of truth functions form a semantic channel. By the third kind of Bayes'\ntheorem, we can directly convert a Shannon's channel into an optimized semantic\nchannel. When a sample is not big enough, we can use a truth function with\nparameters to produce the likelihood function, then train the truth function by\nthe conditional sampling distribution. The third kind of Bayes' theorem is\nproved. A semantic information theory is simply introduced. The semantic\ninformation measure reflects Popper's hypothesis-testing thought. The Semantic\nInformation Method (SIM) adheres to maximum semantic information criterion\nwhich is compatible with maximum likelihood criterion and Regularized Least\nSquares criterion. It supports Wittgenstein's view: the meaning of a word lies\nin its use. Letting the two channels mutually match, we obtain the Channels'\nMatching (CM) algorithm for machine learning. The CM algorithm is used to\nexplain the evolution of the semantic meaning of natural language, such as \"Old\nage\". The semantic channel for medical tests and the confirmation measures of\ntest-positive and test-negative are discussed. The applications of the CM\nalgorithm to semi-supervised learning and non-supervised learning are simply\nintroduced. As a predictive model, the semantic channel fits variable sources\nand hence can overcome class-imbalance problem. The SIM strictly distinguishes\nstatistical probability and logical probability and uses both at the same time.\nThis method is compatible with the thoughts of Bayes, Fisher, Shannon, Zadeh,\nTarski, Davidson, Wittgenstein, and Popper.It is a competitive alternative to\nBayesian inference.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 05:15:49 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1803.08993", "submitter": "Joseph Gomes", "authors": "Amir Barati Farimani, Joseph Gomes, Rishi Sharma, Franklin L. Lee,\n  Vijay S. Pande", "title": "Deep Learning Phase Segregation", "comments": "arXiv admin note: text overlap with arXiv:1709.02432", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase segregation, the process by which the components of a binary mixture\nspontaneously separate, is a key process in the evolution and design of many\nchemical, mechanical, and biological systems. In this work, we present a\ndata-driven approach for the learning, modeling, and prediction of phase\nsegregation. A direct mapping between an initially dispersed, immiscible binary\nfluid and the equilibrium concentration field is learned by conditional\ngenerative convolutional neural networks. Concentration field predictions by\nthe deep learning model conserve phase fraction, correctly predict phase\ntransition, and reproduce area, perimeter, and total free energy distributions\nup to 98% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:59:01 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Farimani", "Amir Barati", ""], ["Gomes", "Joseph", ""], ["Sharma", "Rishi", ""], ["Lee", "Franklin L.", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1803.08996", "submitter": "David Friedlander", "authors": "David Friedlander", "title": "Pattern Analysis with Layered Self-Organizing Maps", "comments": "16 pages, 21 color figures, DRAFT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a new learning architecture, Layered Self-Organizing Maps\n(LSOMs), that uses the SOM and supervised-SOM learning algorithms. The\narchitecture is validated with the MNIST database of hand-written digit images.\nLSOMs are similar to convolutional neural nets (covnets) in the way they sample\ndata, but different in the way they represent features and learn. LSOMs analyze\n(or generate) image patches with maps of exemplars determined by the SOM\nlearning algorithm rather than feature maps from filter-banks learned via\nbackprop.\n  LSOMs provide an alternative to features derived from covnets. Multi-layer\nLSOMs are trained bottom-up, without the use of backprop and therefore may be\nof interest as a model of the visual cortex. The results show organization at\nmultiple levels. The algorithm appears to be resource efficient in learning,\nclassifying and generating images. Although LSOMs can be used for\nclassification, their validation accuracy for these exploratory runs was well\nbelow the state of the art. The goal of this article is to define the\narchitecture and display the structures resulting from its application to the\nMNIST images.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 22:07:52 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 17:07:18 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Friedlander", "David", ""]]}, {"id": "1803.09001", "submitter": "Craig Sherstan", "authors": "Craig Sherstan, Marlos C. Machado, Patrick M. Pilarski", "title": "Accelerating Learning in Constructive Predictive Frameworks with the\n  Successor Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we propose using the successor representation (SR) to accelerate\nlearning in a constructive knowledge system based on general value functions\n(GVFs). In real-world settings like robotics for unstructured and dynamic\nenvironments, it is infeasible to model all meaningful aspects of a system and\nits environment by hand due to both complexity and size. Instead, robots must\nbe capable of learning and adapting to changes in their environment and task,\nincrementally constructing models from their own experience. GVFs, taken from\nthe field of reinforcement learning (RL), are a way of modeling the world as\npredictive questions. One approach to such models proposes a massive network of\ninterconnected and interdependent GVFs, which are incrementally added over\ntime. It is reasonable to expect that new, incrementally added predictions can\nbe learned more swiftly if the learning process leverages knowledge gained from\npast experience. The SR provides such a means of separating the dynamics of the\nworld from the prediction targets and thus capturing regularities that can be\nreused across multiple GVFs. As a primary contribution of this work, we show\nthat using SR-based predictions can improve sample efficiency and learning\nspeed in a continual learning setting where new predictions are incrementally\nadded and learned over time. We analyze our approach in a grid-world and then\ndemonstrate its potential on data from a physical robot arm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 22:40:22 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sherstan", "Craig", ""], ["Machado", "Marlos C.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1803.09018", "submitter": "Abraham Nunes", "authors": "Abraham Nunes and Alexander Rudiuk", "title": "The Importance of Constraint Smoothness for Parameter Estimation in\n  Computational Cognitive Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychiatric neuroscience is increasingly aware of the need to define\npsychopathology in terms of abnormal neural computation. The central tool in\nthis endeavour is the fitting of computational models to behavioural data. The\nmost prominent example of this procedure is fitting reinforcement learning (RL)\nmodels to decision-making data collected from mentally ill and healthy subject\npopulations. These models are generative models of the decision-making data\nthemselves, and the parameters we seek to infer can be psychologically and\nneurobiologically meaningful. Currently, the gold standard approach to this\ninference procedure involves Monte-Carlo sampling, which is robust but\ncomputationally intensive---rendering additional procedures, such as\ncross-validation, impractical. Searching for point estimates of model\nparameters using optimization procedures remains a popular and interesting\noption. On a novel testbed simulating parameter estimation from a common RL\ntask, we investigated the effects of smooth vs. boundary constraints on\nparameter estimation using interior point and deterministic direct search\nalgorithms for optimization. Ultimately, we show that the use of boundary\nconstraints can lead to substantial truncation effects. Our results discourage\nthe use of boundary constraints for these applications.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 00:25:20 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Nunes", "Abraham", ""], ["Rudiuk", "Alexander", ""]]}, {"id": "1803.09050", "submitter": "Mengye Ren", "authors": "Mengye Ren, Wenyuan Zeng, Bin Yang, Raquel Urtasun", "title": "Learning to Reweight Examples for Robust Deep Learning", "comments": "13 pages; Published at ICML 2018; Code released at:\n  https://github.com/uber-research/learning-to-reweight-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be very powerful modeling tools for\nmany supervised learning tasks involving complex input patterns. However, they\ncan also easily overfit to training set biases and label noises. In addition to\nvarious regularizers, example reweighting algorithms are popular solutions to\nthese problems, but they require careful tuning of additional hyperparameters,\nsuch as example mining schedules and regularization hyperparameters. In\ncontrast to past reweighting methods, which typically consist of functions of\nthe cost value of each example, in this work we propose a novel meta-learning\nalgorithm that learns to assign weights to training examples based on their\ngradient directions. To determine the example weights, our method performs a\nmeta gradient descent step on the current mini-batch example weights (which are\ninitialized from zero) to minimize the loss on a clean unbiased validation set.\nOur proposed method can be easily implemented on any type of deep network, does\nnot require any additional hyperparameter tuning, and achieves impressive\nperformance on class imbalance and corrupted label problems where only a small\namount of clean validation data is available.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 03:41:59 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 15:29:31 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 15:21:40 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Ren", "Mengye", ""], ["Zeng", "Wenyuan", ""], ["Yang", "Bin", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1803.09080", "submitter": "Lei Sang", "authors": "Lei Sang and Min Xu and Shengsheng Qian and Xindong Wu", "title": "AAANE: Attention-based Adversarial Autoencoder for Multi-scale Network\n  Embedding", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding represents nodes in a continuous vector space and preserves\nstructure information from the Network. Existing methods usually adopt a\n\"one-size-fits-all\" approach when concerning multi-scale structure information,\nsuch as first- and second-order proximity of nodes, ignoring the fact that\ndifferent scales play different roles in the embedding learning. In this paper,\nwe propose an Attention-based Adversarial Autoencoder Network Embedding(AAANE)\nframework, which promotes the collaboration of different scales and lets them\nvote for robust representations. The proposed AAANE consists of two components:\n1) Attention-based autoencoder effectively capture the highly non-linear\nnetwork structure, which can de-emphasize irrelevant scales during training. 2)\nAn adversarial regularization guides the autoencoder learn robust\nrepresentations by matching the posterior distribution of the latent embeddings\nto given prior distribution. This is the first attempt to introduce attention\nmechanisms to multi-scale network embedding. Experimental results on real-world\nnetworks show that our learned attention parameters are different for every\nnetwork and the proposed approach outperforms existing state-of-the-art\napproaches for network embedding.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 09:15:05 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sang", "Lei", ""], ["Xu", "Min", ""], ["Qian", "Shengsheng", ""], ["Wu", "Xindong", ""]]}, {"id": "1803.09082", "submitter": "Tim Tsz-Kit Lau", "authors": "Tim Tsz-Kit Lau, Jinshan Zeng, Baoyuan Wu, Yuan Yao", "title": "A Proximal Block Coordinate Descent Algorithm for Deep Neural Network\n  Training", "comments": "The 6th International Conference on Learning Representations (ICLR\n  2018), Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks (DNNs) efficiently is a challenge due to the\nassociated highly nonconvex optimization. The backpropagation (backprop)\nalgorithm has long been the most widely used algorithm for gradient computation\nof parameters of DNNs and is used along with gradient descent-type algorithms\nfor this optimization task. Recent work have shown the efficiency of block\ncoordinate descent (BCD) type methods empirically for training DNNs. In view of\nthis, we propose a novel algorithm based on the BCD method for training DNNs\nand provide its global convergence results built upon the powerful framework of\nthe Kurdyka-Lojasiewicz (KL) property. Numerical experiments on standard\ndatasets demonstrate its competitive efficiency against standard optimizers\nwith backprop.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 09:17:27 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Lau", "Tim Tsz-Kit", ""], ["Zeng", "Jinshan", ""], ["Wu", "Baoyuan", ""], ["Yao", "Yuan", ""]]}, {"id": "1803.09093", "submitter": "Mathijs Pieters", "authors": "Mathijs Pieters and Marco Wiering", "title": "Comparing Generative Adversarial Network Techniques for Image Creation\n  and Modification", "comments": "20 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have demonstrated to be successful at\ngenerating realistic real-world images. In this paper we compare various GAN\ntechniques, both supervised and unsupervised. The effects on training stability\nof different objective functions are compared. We add an encoder to the\nnetwork, making it possible to encode images to the latent space of the GAN.\nThe generator, discriminator and encoder are parameterized by deep\nconvolutional neural networks. For the discriminator network we experimented\nwith using the novel Capsule Network, a state-of-the-art technique for\ndetecting global features in images. Experiments are performed using a digit\nand face dataset, with various visualizations illustrating the results. The\nresults show that using the encoder network it is possible to reconstruct\nimages. With the conditional GAN we can alter visual attributes of generated or\nencoded images. The experiments with the Capsule Network as discriminator\nresult in generated images of a lower quality, compared to a standard\nconvolutional neural network.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 11:19:07 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Pieters", "Mathijs", ""], ["Wiering", "Marco", ""]]}, {"id": "1803.09111", "submitter": "Yuhan Liu", "authors": "Yuhan Liu, Xiao Zhang, Maciej Lewenstein, and Shi-Ju Ran", "title": "Entanglement-guided architectures of machine learning by quantum tensor\n  network", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.str-el cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a fundamental, but still elusive question whether the schemes based on\nquantum mechanics, in particular on quantum entanglement, can be used for\nclassical information processing and machine learning. Even partial answer to\nthis question would bring important insights to both fields of machine learning\nand quantum mechanics. In this work, we implement simple numerical experiments,\nrelated to pattern/images classification, in which we represent the classifiers\nby many-qubit quantum states written in the matrix product states (MPS).\nClassical machine learning algorithm is applied to these quantum states to\nlearn the classical data. We explicitly show how quantum entanglement (i.e.,\nsingle-site and bipartite entanglement) can emerge in such represented images.\nEntanglement characterizes here the importance of data, and such information\nare practically used to guide the architecture of MPS, and improve the\nefficiency. The number of needed qubits can be reduced to less than 1/10 of the\noriginal number, which is within the access of the state-of-the-art quantum\ncomputers. We expect such numerical experiments could open new paths in\ncharactering classical machine learning algorithms, and at the same time shed\nlights on the generic quantum simulations/computations of machine learning\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 13:48:33 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 14:07:34 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 01:29:25 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Liu", "Yuhan", ""], ["Zhang", "Xiao", ""], ["Lewenstein", "Maciej", ""], ["Ran", "Shi-Ju", ""]]}, {"id": "1803.09119", "submitter": "Stefan Zohren", "authors": "Mariano Chouza, Stephen Roberts, Stefan Zohren", "title": "Gradient descent in Gaussian random fields as a toy model for\n  high-dimensional optimisation in deep learning", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we model the loss function of high-dimensional optimization\nproblems by a Gaussian random field, or equivalently a Gaussian process. Our\naim is to study gradient descent in such loss functions or energy landscapes\nand compare it to results obtained from real high-dimensional optimization\nproblems such as encountered in deep learning. In particular, we analyze the\ndistribution of the improved loss function after a step of gradient descent,\nprovide analytic expressions for the moments as well as prove asymptotic\nnormality as the dimension of the parameter space becomes large. Moreover, we\ncompare this with the expectation of the global minimum of the landscape\nobtained by means of the Euler characteristic of excursion sets. Besides\ncomplementing our analytical findings with numerical results from simulated\nGaussian random fields, we also compare it to loss functions obtained from\noptimisation problems on synthetic and real data sets by proposing a \"black\nbox\" random field toy-model for a deep neural network loss function.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 14:22:36 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Chouza", "Mariano", ""], ["Roberts", "Stephen", ""], ["Zohren", "Stefan", ""]]}, {"id": "1803.09123", "submitter": "Kriste Krstovski", "authors": "Kriste Krstovski and David M. Blei", "title": "Equation Embeddings", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised approach for discovering semantic representations\nof mathematical equations. Equations are challenging to analyze because each is\nunique, or nearly unique. Our method, which we call equation embeddings, finds\ngood representations of equations by using the representations of their\nsurrounding words. We used equation embeddings to analyze four collections of\nscientific articles from the arXiv, covering four computer science domains\n(NLP, IR, AI, and ML) and $\\sim$98.5k equations. Quantitatively, we found that\nequation embeddings provide better models when compared to existing word\nembedding approaches. Qualitatively, we found that equation embeddings provide\ncoherent semantic representations of equations and can capture semantic\nsimilarity to other equations and to words.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 15:04:17 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Krstovski", "Kriste", ""], ["Blei", "David M.", ""]]}, {"id": "1803.09133", "submitter": "Amir Karami", "authors": "Matthew Collins, Amir Karami", "title": "Social Media Analysis For Organizations: Us Northeastern Public And\n  State Libraries Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networking sites such as Twitter have provided a great opportunity for\norganizations such as public libraries to disseminate information for public\nrelations purposes. However, there is a need to analyze vast amounts of social\nmedia data. This study presents a computational approach to explore the content\nof tweets posted by nine public libraries in the northeastern United States of\nAmerica. In December 2017, this study extracted more than 19,000 tweets from\nthe Twitter accounts of seven state libraries and two urban public libraries.\nComputational methods were applied to collect the tweets and discover\nmeaningful themes. This paper shows how the libraries have used Twitter to\nrepresent their services and provides a starting point for different\norganizations to evaluate the themes of their public tweets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 17:23:41 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Collins", "Matthew", ""], ["Karami", "Amir", ""]]}, {"id": "1803.09134", "submitter": "Amir Karami", "authors": "Frank Webb, Amir Karami, Vanessa Kitzie", "title": "Characterizing Diseases and disorders in Gay Users' tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lack of information exists about the health issues of lesbian, gay,\nbisexual, transgender, and queer (LGBTQ) people who are often excluded from\nnational demographic assessments, health studies, and clinical trials. As a\nresult, medical experts and researchers lack a holistic understanding of the\nhealth disparities facing these populations. Fortunately, publicly available\nsocial media data such as Twitter data can be utilized to support the decisions\nof public health policy makers and managers with respect to LGBTQ people. This\nresearch employs a computational approach to collect tweets from gay users on\nhealth-related topics and model these topics. To determine the nature of\nhealth-related information shared by men who have sex with men on Twitter, we\ncollected thousands of tweets from 177 active users. We sampled these tweets\nusing a framework that can be applied to other LGBTQ sub-populations in future\nresearch. We found 11 diseases in 7 categories based on ICD 10 that are in line\nwith the published studies and official reports.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 17:27:37 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Webb", "Frank", ""], ["Karami", "Amir", ""], ["Kitzie", "Vanessa", ""]]}, {"id": "1803.09138", "submitter": "Veronika Rockova", "authors": "Nicholas Polson and Veronika Rockova", "title": "Posterior Concentration for Sparse Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-and-Slab Deep Learning (SS-DL) is a fully Bayesian alternative to\nDropout for improving generalizability of deep ReLU networks. This new type of\nregularization enables provable recovery of smooth input-output maps with\nunknown levels of smoothness. Indeed, we show that the posterior distribution\nconcentrates at the near minimax rate for $\\alpha$-H\\\"older smooth maps,\nperforming as well as if we knew the smoothness level $\\alpha$ ahead of time.\nOur result sheds light on architecture design for deep neural networks, namely\nthe choice of depth, width and sparsity level. These network attributes\ntypically depend on unknown smoothness in order to be optimal. We obviate this\nconstraint with the fully Bayes construction. As an aside, we show that SS-DL\ndoes not overfit in the sense that the posterior concentrates on smaller\nnetworks with fewer (up to the optimal number of) nodes and links. Our results\nprovide new theoretical justifications for deep ReLU networks from a Bayesian\npoint of view.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 17:51:15 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Polson", "Nicholas", ""], ["Rockova", "Veronika", ""]]}, {"id": "1803.09151", "submitter": "Stefanos Eleftheriadis PhD", "authors": "Hugh Salimbeni, Stefanos Eleftheriadis, James Hensman", "title": "Natural Gradients in Practice: Non-Conjugate Variational Inference in\n  Gaussian Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The natural gradient method has been used effectively in conjugate Gaussian\nprocess models, but the non-conjugate case has been largely unexplored. We\nexamine how natural gradients can be used in non-conjugate stochastic settings,\ntogether with hyperparameter learning. We conclude that the natural gradient\ncan significantly improve performance in terms of wall-clock time. For\nill-conditioned posteriors the benefit of the natural gradient method is\nespecially pronounced, and we demonstrate a practical setting where ordinary\ngradients are unusable. We show how natural gradients can be computed\nefficiently and automatically in any parameterization, using automatic\ndifferentiation. Our code is integrated into the GPflow package.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 19:11:43 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Salimbeni", "Hugh", ""], ["Eleftheriadis", "Stefanos", ""], ["Hensman", "James", ""]]}, {"id": "1803.09153", "submitter": "Niko Br\\\"ummer", "authors": "Anna Silnova and Niko Brummer and Daniel Garcia-Romero and David\n  Snyder and Lukas Burget", "title": "Fast variational Bayes for heavy-tailed PLDA applied to i-vectors and\n  x-vectors", "comments": "Submittted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard state-of-the-art backend for text-independent speaker\nrecognizers that use i-vectors or x-vectors, is Gaussian PLDA (G-PLDA),\nassisted by a Gaussianization step involving length normalization. G-PLDA can\nbe trained with both generative or discriminative methods. It has long been\nknown that heavy-tailed PLDA (HT-PLDA), applied without length normalization,\ngives similar accuracy, but at considerable extra computational cost. We have\nrecently introduced a fast scoring algorithm for a discriminatively trained\nHT-PLDA backend. This paper extends that work by introducing a fast,\nvariational Bayes, generative training algorithm. We compare old and new\nbackends, with and without length-normalization, with i-vectors and x-vectors,\non SRE'10, SRE'16 and SITW.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 19:19:32 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Silnova", "Anna", ""], ["Brummer", "Niko", ""], ["Garcia-Romero", "Daniel", ""], ["Snyder", "David", ""], ["Burget", "Lukas", ""]]}, {"id": "1803.09159", "submitter": "Edward McFowland Iii", "authors": "Edward McFowland III, Sriram Somanchi, Daniel B. Neill", "title": "Efficient Discovery of Heterogeneous Treatment Effects in Randomized\n  Experiments via Anomalous Pattern Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent literature on estimating heterogeneous treatment effects, each\nproposed method makes its own set of restrictive assumptions about the\nintervention's effects and which subpopulations to explicitly estimate.\nMoreover, the majority of the literature provides no mechanism to identify\nwhich subpopulations are the most affected--beyond manual inspection--and\nprovides little guarantee on the correctness of the identified subpopulations.\nTherefore, we propose Treatment Effect Subset Scan (TESS), a new method for\ndiscovering which subpopulation in a randomized experiment is most\nsignificantly affected by a treatment. We frame this challenge as a pattern\ndetection problem where we efficiently maximize a nonparametric scan statistic\nover subpopulations. Furthermore, we identify the subpopulation which\nexperiences the largest distributional change as a result of the intervention,\nwhile making minimal assumptions about the intervention's effects or the\nunderlying data generating process. In addition to the algorithm, we\ndemonstrate that the asymptotic Type I and II error can be controlled, and\nprovide sufficient conditions for detection consistency--i.e., exact\nidentification of the affected subpopulation. Finally, we validate the efficacy\nof the method by discovering heterogeneous treatment effects in simulations and\nin real-world data from a well-known program evaluation study.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 20:21:06 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 22:05:16 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["McFowland", "Edward", "III"], ["Somanchi", "Sriram", ""], ["Neill", "Daniel B.", ""]]}, {"id": "1803.09160", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic", "title": "Handling Adversarial Concept Drift in Streaming Data", "comments": "Journal paper", "journal-ref": "Expert Systems with Applications 97 (2018): 18-40", "doi": "10.1016/j.eswa.2017.12.022", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers operating in a dynamic, real world environment, are vulnerable to\nadversarial activity, which causes the data distribution to change over time.\nThese changes are traditionally referred to as concept drift, and several\napproaches have been developed in literature to deal with the problem of drift\nhandling and detection. However, most concept drift handling techniques,\napproach it as a domain independent task, to make them applicable to a wide\ngamut of reactive systems. These techniques were developed from an adversarial\nagnostic perspective, where they are naive and assume that drift is a benign\nchange, which can be fixed by updating the model. However, this is not the case\nwhen an active adversary is trying to evade the deployed classification system.\nIn such an environment, the properties of concept drift are unique, as the\ndrift is intended to degrade the system and at the same time designed to avoid\ndetection by traditional concept drift detection techniques. This special\ncategory of drift is termed as adversarial drift, and this paper analyzes its\ncharacteristics and impact, in a streaming environment. A novel framework for\ndealing with adversarial concept drift is proposed, called the Predict-Detect\nstreaming framework. Experimental evaluation of the framework, on generated\nadversarial drifting data streams, demonstrates that this framework is able to\nprovide reliable unsupervised indication of drift, and is able to recover from\ndrifts swiftly. While traditional partially labeled concept drift detection\nmethodologies fail to detect adversarial drifts, the proposed framework is able\nto detect such drifts and operates with <6% labeled data, on average. Also, the\nframework provides benefits for active learning over imbalanced data streams,\nby innately providing for feature space honeypots, where minority class\nadversarial samples may be captured.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 20:30:50 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""]]}, {"id": "1803.09162", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic, Lingyu Lyua, Jiashun Chen", "title": "A Dynamic-Adversarial Mining Approach to the Security of Machine\n  Learning", "comments": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery.\n  2018", "journal-ref": null, "doi": "10.1002/widm.1245", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating in a dynamic real world environment requires a forward thinking and\nadversarial aware design for classifiers, beyond fitting the model to the\ntraining data. In such scenarios, it is necessary to make classifiers - a)\nharder to evade, b) easier to detect changes in the data distribution over\ntime, and c) be able to retrain and recover from model degradation. While most\nworks in the security of machine learning has concentrated on the evasion\nresistance (a) problem, there is little work in the areas of reacting to\nattacks (b and c). Additionally, while streaming data research concentrates on\nthe ability to react to changes to the data distribution, they often take an\nadversarial agnostic view of the security problem. This makes them vulnerable\nto adversarial activity, which is aimed towards evading the concept drift\ndetection mechanism itself. In this paper, we analyze the security of machine\nlearning, from a dynamic and adversarial aware perspective. The existing\ntechniques of Restrictive one class classifier models, Complex learning models\nand Randomization based ensembles, are shown to be myopic as they approach\nsecurity as a static task. These methodologies are ill suited for a dynamic\nenvironment, as they leak excessive information to an adversary, who can\nsubsequently launch attacks which are indistinguishable from the benign data.\nBased on empirical vulnerability analysis against a sophisticated adversary, a\nnovel feature importance hiding approach for classifier design, is proposed.\nThe proposed design ensures that future attacks on classifiers can be detected\nand recovered from. The proposed work presents motivation, by serving as a\nblueprint, for future work in the area of Dynamic-Adversarial mining, which\ncombines lessons learned from Streaming data mining, Adversarial learning and\nCybersecurity.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 20:55:20 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""], ["Lyua", "Lingyu", ""], ["Chen", "Jiashun", ""]]}, {"id": "1803.09163", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic, Joung Woo Ryu", "title": "Security Theater: On the Vulnerability of Classifiers to Exploratory\n  Attacks", "comments": "Pacific-Asia Workshop on Intelligence and Security Informatics.\n  Springer, Cham, 2017", "journal-ref": null, "doi": "10.1007/978-3-319-57463-9_4", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing scale and sophistication of cyberattacks has led to the\nadoption of machine learning based classification techniques, at the core of\ncybersecurity systems. These techniques promise scale and accuracy, which\ntraditional rule or signature based methods cannot. However, classifiers\noperating in adversarial domains are vulnerable to evasion attacks by an\nadversary, who is capable of learning the behavior of the system by employing\nintelligently crafted probes. Classification accuracy in such domains provides\na false sense of security, as detection can easily be evaded by carefully\nperturbing the input samples. In this paper, a generic data driven framework is\npresented, to analyze the vulnerability of classification systems to black box\nprobing based attacks. The framework uses an exploration exploitation based\nstrategy, to understand an adversary's point of view of the attack defense\ncycle. The adversary assumes a black box model of the defender's classifier and\ncan launch indiscriminate attacks on it, without information of the defender's\nmodel type, training data or the domain of application. Experimental evaluation\non 10 real world datasets demonstrates that even models having high perceived\naccuracy (>90%), by a defender, can be effectively circumvented with a high\nevasion rate (>95%, on average). The detailed attack algorithms, adversarial\nmodel and empirical evaluation, serve.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 21:10:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""], ["Ryu", "Joung Woo", ""]]}, {"id": "1803.09177", "submitter": "Kahkashan Afrin", "authors": "Kahkashan Afrin, Gurudev Illangovan, Sanjay S. Srivatsa, and Satish T.\n  S. Bukkapatnam", "title": "Balanced Random Survival Forests for Extremely Unbalanced, Right\n  Censored Data", "comments": "27 pages, 10 figures, to be submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accuracies of survival models for life expectancy prediction as well as\ncritical-care applications are significantly compromised due to the sparsity of\nsamples and extreme imbalance between the survival (usually, the majority) and\nmortality class sizes. While a recent random survival forest (RSF) model\novercomes the limitations of the proportional hazard assumption, an imbalance\nin the data results in an underestimation (overestimation) of the hazard of the\nmortality (survival) classes. A balanced random survival forests (BRSF) model,\nbased on training the RSF model with data generated from a synthetic minority\nsampling scheme is presented to address this gap. Theoretical results on the\neffect of balancing on prediction accuracies in BRSF are reported. Benchmarking\nstudies were conducted using five datasets with different levels of class\nimbalance from public repositories and an imbalanced dataset of 267 acute\ncardiac patients, collected at the Heart, Artery, and Vein Center of Fresno,\nCA. Investigations suggest that BRSF provides an improved discriminatory\nstrength between the survival and the mortality classes. It outperformed both\noptimized Cox (without and with balancing) and RSF with an average reduction of\n55\\% in the prediction error over the next best alternative.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 22:58:41 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 19:57:58 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Afrin", "Kahkashan", ""], ["Illangovan", "Gurudev", ""], ["Srivatsa", "Sanjay S.", ""], ["Bukkapatnam", "Satish T. S.", ""]]}, {"id": "1803.09180", "submitter": "Sicheng Zhao Dr.", "authors": "Sicheng Zhao, Bichen Wu, Joseph Gonzalez, Sanjit A. Seshia, Kurt\n  Keutzer", "title": "Unsupervised Domain Adaptation: from Simulation Engine to the RealWorld", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale labeled training datasets have enabled deep neural networks to\nexcel on a wide range of benchmark vision tasks. However, in many applications\nit is prohibitively expensive or time-consuming to obtain large quantities of\nlabeled data. To cope with limited labeled training data, many have attempted\nto directly apply models trained on a large-scale labeled source domain to\nanother sparsely labeled target domain. Unfortunately, direct transfer across\ndomains often performs poorly due to domain shift and dataset bias. Domain\nadaptation is the machine learning paradigm that aims to learn a model from a\nsource domain that can perform well on a different (but related) target domain.\nIn this paper, we summarize and compare the latest unsupervised domain\nadaptation methods in computer vision applications. We classify the non-deep\napproaches into sample re-weighting and intermediate subspace transformation\ncategories, while the deep strategy includes discrepancy-based methods,\nadversarial generative models, adversarial discriminative models and\nreconstruction-based methods. We also discuss some potential directions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 23:34:06 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhao", "Sicheng", ""], ["Wu", "Bichen", ""], ["Gonzalez", "Joseph", ""], ["Seshia", "Sanjit A.", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1803.09191", "submitter": "Jean-Gabriel Young", "authors": "Jean-Gabriel Young, Guillaume St-Onge, Edward Laurence, Charles\n  Murphy, Laurent H\\'ebert-Dufresne, Patrick Desrosiers", "title": "Phase transition in the recoverability of network history", "comments": "18 pages, 10 figures. Supplemental Material available online at\n  https://journals.aps.org/prx/supplemental/10.1103/PhysRevX.9.041056/jgy2019_prx_SM.pdf", "journal-ref": "Phys. Rev. X 9, 041056 (2019)", "doi": "10.1103/PhysRevX.9.041056", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network growth processes can be understood as generative models of the\nstructure and history of complex networks. This point of view naturally leads\nto the problem of network archaeology: reconstructing all the past states of a\nnetwork from its structure---a difficult permutation inference problem. In this\npaper, we introduce a Bayesian formulation of network archaeology, with a\ngeneralization of preferential attachment as our generative mechanism. We\ndevelop a sequential Monte Carlo algorithm to evaluate the posterior averages\nof this model, as well as an efficient heuristic that uncovers a history well\ncorrelated with the true one, in polynomial time. We use these methods to\nidentify and characterize a phase transition in the quality of the\nreconstructed history, when they are applied to artificial networks generated\nby the model itself. Despite the existence of a no-recovery phase, we find that\nnontrivial inference is possible in a large portion of the parameter space as\nwell as on empirical data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 02:09:10 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 20:35:29 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 17:31:02 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Young", "Jean-Gabriel", ""], ["St-Onge", "Guillaume", ""], ["Laurence", "Edward", ""], ["Murphy", "Charles", ""], ["H\u00e9bert-Dufresne", "Laurent", ""], ["Desrosiers", "Patrick", ""]]}, {"id": "1803.09202", "submitter": "Sina Honari", "authors": "Joel Ruben Antony Moniz, Christopher Beckham, Simon Rajotte, Sina\n  Honari, Christopher Pal", "title": "Unsupervised Depth Estimation, 3D Face Rotation and Replacement", "comments": "Depth Estimation, Face Rotation, Face Swap, 32nd Conference on Neural\n  Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised approach for learning to estimate three\ndimensional (3D) facial structure from a single image while also predicting 3D\nviewpoint transformations that match a desired pose and facial geometry. We\nachieve this by inferring the depth of facial keypoints of an input image in an\nunsupervised manner, without using any form of ground-truth depth information.\nWe show how it is possible to use these depths as intermediate computations\nwithin a new backpropable loss to predict the parameters of a 3D affine\ntransformation matrix that maps inferred 3D keypoints of an input face to the\ncorresponding 2D keypoints on a desired target facial geometry or pose. Our\nresulting approach, called DepthNets, can therefore be used to infer plausible\n3D transformations from one face pose to another, allowing faces to be\nfrontalized, transformed into 3D models or even warped to another pose and\nfacial geometry. Lastly, we identify certain shortcomings with our formulation,\nand explore adversarial image translation techniques as a post-processing step\nto re-synthesize complete head shots for faces re-targeted to different poses\nor identities.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 05:07:11 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 23:03:13 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 21:44:48 GMT"}, {"version": "v4", "created": "Tue, 6 Nov 2018 23:07:43 GMT"}, {"version": "v5", "created": "Mon, 24 Dec 2018 01:51:13 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Moniz", "Joel Ruben Antony", ""], ["Beckham", "Christopher", ""], ["Rajotte", "Simon", ""], ["Honari", "Sina", ""], ["Pal", "Christopher", ""]]}, {"id": "1803.09211", "submitter": "Sumit Bhatia", "authors": "Vinith Misra and Sumit Bhatia", "title": "Bernoulli Embeddings for Graphs", "comments": "The Thirty-Second AAAI Conference on Artificial Intelligence\n  (AAAI-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Just as semantic hashing can accelerate information retrieval, binary valued\nembeddings can significantly reduce latency in the retrieval of graphical data.\nWe introduce a simple but effective model for learning such binary vectors for\nnodes in a graph. By imagining the embeddings as independent coin flips of\nvarying bias, continuous optimization techniques can be applied to the\napproximate expected loss. Embeddings optimized in this fashion consistently\noutperform the quantization of both spectral graph embeddings and various\nlearned real-valued embeddings, on both ranking and pre-ranking tasks for a\nvariety of datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 07:19:47 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Misra", "Vinith", ""], ["Bhatia", "Sumit", ""]]}, {"id": "1803.09237", "submitter": "Amos Azaria", "authors": "Avigail Stekel, Merav Chkroun and Amos Azaria", "title": "Goldbach's Function Approximation Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goldbach conjecture is one of the most famous open mathematical problems. It\nstates that every even number, bigger than two, can be presented as a sum of 2\nprime numbers. % In this work we present a deep learning based model that\npredicts the number of Goldbach partitions for a given even number.\nSurprisingly, our model outperforms all state-of-the-art analytically derived\nestimations for the number of couples, while not requiring prime factorization\nof the given number. We believe that building a model that can accurately\npredict the number of couples brings us one step closer to solving one of the\nworld most famous open problems. To the best of our knowledge, this is the\nfirst attempt to consider machine learning based data-driven methods to\napproximate open mathematical problems in the field of number theory, and hope\nthat this work will encourage such attempts.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 12:09:43 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Stekel", "Avigail", ""], ["Chkroun", "Merav", ""], ["Azaria", "Amos", ""]]}, {"id": "1803.09318", "submitter": "Shaowu Pan", "authors": "Shaowu Pan, Karthik Duraisamy", "title": "Data-driven Discovery of Closure Models", "comments": "33 pages", "journal-ref": "SIAM Journal on Applied Dynamical Systems, 17(4), 2381-2413", "doi": "10.1137/18M1177263", "report-no": null, "categories": "math.DS nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Derivation of reduced order representations of dynamical systems requires the\nmodeling of the truncated dynamics on the retained dynamics. In its most\ngeneral form, this so-called closure model has to account for memory effects.\nIn this work, we present a framework of operator inference to extract the\ngoverning dynamics of closure from data in a compact, non-Markovian form. We\nemploy sparse polynomial regression and artificial neural networks to extract\nthe underlying operator. For a special class of non-linear systems,\nobservability of the closure in terms of the resolved dynamics is analyzed and\ntheoretical results are presented on the compactness of the memory. The\nproposed framework is evaluated on examples consisting of linear to nonlinear\nsystems with and without chaotic dynamics, with an emphasis on predictive\nperformance on unseen data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 19:24:52 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 16:00:26 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 19:08:59 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Pan", "Shaowu", ""], ["Duraisamy", "Karthik", ""]]}, {"id": "1803.09319", "submitter": "Soledad Villar", "authors": "Dustin G. Mixon, Soledad Villar", "title": "SUNLayer: Stable denoising with generative networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been experimentally established that deep neural networks can be used\nto produce good generative models for real world data. It has also been\nestablished that such generative models can be exploited to solve classical\ninverse problems like compressed sensing and super resolution. In this work we\nfocus on the classical signal processing problem of image denoising. We propose\na theoretical setting that uses spherical harmonics to identify what\nmathematical properties of the activation functions will allow signal denoising\nwith local methods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 19:33:04 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Mixon", "Dustin G.", ""], ["Villar", "Soledad", ""]]}, {"id": "1803.09327", "submitter": "Jiong Zhang", "authors": "Jiong Zhang, Qi Lei, Inderjit S. Dhillon", "title": "Stabilizing Gradients for Deep Neural Networks via Efficient SVD\n  Parameterization", "comments": "main text 13 pages, 22 pages including reference and appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vanishing and exploding gradients are two of the main obstacles in training\ndeep neural networks, especially in capturing long range dependencies in\nrecurrent neural networks~(RNNs). In this paper, we present an efficient\nparametrization of the transition matrix of an RNN that allows us to stabilize\nthe gradients that arise in its training. Specifically, we parameterize the\ntransition matrix by its singular value decomposition(SVD), which allows us to\nexplicitly track and control its singular values. We attain efficiency by using\ntools that are common in numerical linear algebra, namely Householder\nreflectors for representing the orthogonal matrices that arise in the SVD. By\nexplicitly controlling the singular values, our proposed Spectral-RNN method\nallows us to easily solve the exploding gradient problem and we observe that it\nempirically solves the vanishing gradient issue to a large extent. We note that\nthe SVD parameterization can be used for any rectangular weight matrix, hence\nit can be easily extended to any deep neural network, such as a multi-layer\nperceptron. Theoretically, we demonstrate that our parameterization does not\nlose any expressive power, and show how it controls generalization of RNN for\nthe classification task. %, and show how it potentially makes the optimization\nprocess easier. Our extensive experimental results also demonstrate that the\nproposed framework converges faster, and has good generalization, especially in\ncapturing long range dependencies, as shown on the synthetic addition and copy\ntasks, as well as on MNIST and Penn Tree Bank data sets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 20:12:18 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhang", "Jiong", ""], ["Lei", "Qi", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1803.09349", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Satyen Kale, Haipeng Luo, Mehryar Mohri, Karthik\n  Sridharan", "title": "Logistic Regression: The Importance of Being Improper", "comments": "Appeared at COLT 2018. V2 changes: Updated to match conference\n  version, added discussion of Bayesian model averaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning linear predictors with the logistic loss---both in stochastic and\nonline settings---is a fundamental task in machine learning and statistics,\nwith direct connections to classification and boosting. Existing \"fast rates\"\nfor this setting exhibit exponential dependence on the predictor norm, and\nHazan et al. (2014) showed that this is unfortunately unimprovable. Starting\nwith the simple observation that the logistic loss is $1$-mixable, we design a\nnew efficient improper learning algorithm for online logistic regression that\ncircumvents the aforementioned lower bound with a regret bound exhibiting a\ndoubly-exponential improvement in dependence on the predictor norm. This\nprovides a positive resolution to a variant of the COLT 2012 open problem of\nMcMahan and Streeter (2012) when improper learning is allowed. This improvement\nis obtained both in the online setting and, with some extra work, in the batch\nstatistical setting with high probability. We also show that the improved\ndependence on predictor norm is near-optimal.\n  Leveraging this improved dependency on the predictor norm yields the\nfollowing applications: (a) we give algorithms for online bandit multiclass\nlearning with the logistic loss with an $\\tilde{O}(\\sqrt{n})$ relative mistake\nbound across essentially all parameter ranges, thus providing a solution to the\nCOLT 2009 open problem of Abernethy and Rakhlin (2009), and (b) we give an\nadaptive algorithm for online multiclass boosting with optimal sample\ncomplexity, thus partially resolving an open problem of Beygelzimer et al.\n(2015) and Jung et al. (2017). Finally, we give information-theoretic bounds on\nthe optimal rates for improper logistic regression with general function\nclasses, thereby characterizing the extent to which our improvement for linear\nclasses extends to other parametric and even nonparametric settings.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 21:37:08 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 03:07:19 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Foster", "Dylan J.", ""], ["Kale", "Satyen", ""], ["Luo", "Haipeng", ""], ["Mohri", "Mehryar", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1803.09353", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Vahab Mirrokni, Renato Paes Leme", "title": "Stochastic bandits robust to adversarial corruptions", "comments": "To appear in STOC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model of stochastic bandits with adversarial corruptions\nwhich aims to capture settings where most of the input follows a stochastic\npattern but some fraction of it can be adversarially changed to trick the\nalgorithm, e.g., click fraud, fake reviews and email spam. The goal of this\nmodel is to encourage the design of bandit algorithms that (i) work well in\nmixed adversarial and stochastic models, and (ii) whose performance\ndeteriorates gracefully as we move from fully stochastic to fully adversarial\nmodels.\n  In our model, the rewards for all arms are initially drawn from a\ndistribution and are then altered by an adaptive adversary. We provide a simple\nalgorithm whose performance gracefully degrades with the total corruption the\nadversary injected in the data, measured by the sum across rounds of the\nbiggest alteration the adversary made in the data in that round; this total\ncorruption is denoted by $C$. Our algorithm provides a guarantee that retains\nthe optimal guarantee (up to a logarithmic term) if the input is stochastic and\nwhose performance degrades linearly to the amount of corruption $C$, while\ncrucially being agnostic to it. We also provide a lower bound showing that this\nlinear degradation is necessary if the algorithm achieves optimal performance\nin the stochastic setting (the lower bound works even for a known amount of\ncorruption, a special case in which our algorithm achieves optimal performance\nwithout the extra logarithm).\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 21:48:53 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Mirrokni", "Vahab", ""], ["Leme", "Renato Paes", ""]]}, {"id": "1803.09357", "submitter": "Lydia T. Liu", "authors": "Chi Jin, Lydia T. Liu, Rong Ge, Michael I. Jordan", "title": "On the Local Minima of the Empirical Risk", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population risk is always of primary interest in machine learning; however,\nlearning algorithms only have access to the empirical risk. Even for\napplications with nonconvex nonsmooth losses (such as modern deep networks),\nthe population risk is generally significantly more well-behaved from an\noptimization point of view than the empirical risk. In particular, sampling can\ncreate many spurious local minima. We consider a general framework which aims\nto optimize a smooth nonconvex function $F$ (population risk) given only access\nto an approximation $f$ (empirical risk) that is pointwise close to $F$ (i.e.,\n$\\|F-f\\|_{\\infty} \\le \\nu$). Our objective is to find the\n$\\epsilon$-approximate local minima of the underlying function $F$ while\navoiding the shallow local minima---arising because of the tolerance\n$\\nu$---which exist only in $f$. We propose a simple algorithm based on\nstochastic gradient descent (SGD) on a smoothed version of $f$ that is\nguaranteed to achieve our goal as long as $\\nu \\le O(\\epsilon^{1.5}/d)$. We\nalso provide an almost matching lower bound showing that our algorithm achieves\noptimal error tolerance $\\nu$ among all algorithms making a polynomial number\nof queries of $f$. As a concrete example, we show that our results can be\ndirectly used to give sample complexities for learning a ReLU unit.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 22:18:04 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 22:55:49 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Jin", "Chi", ""], ["Liu", "Lydia T.", ""], ["Ge", "Rong", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1803.09374", "submitter": "Brendan Duke", "authors": "Brendan Duke and Graham W. Taylor", "title": "Generalized Hadamard-Product Fusion Operators for Visual Question\n  Answering", "comments": "8 pages, 3 figures. To appear in CRV, 2018, 15th Canadian Conference\n  on Computer and Robot Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalized class of multimodal fusion operators for the task of\nvisual question answering (VQA). We identify generalizations of existing\nmultimodal fusion operators based on the Hadamard product, and show that\nspecific non-trivial instantiations of this generalized fusion operator exhibit\nsuperior performance in terms of OpenEnded accuracy on the VQA task. In\nparticular, we introduce Nonlinearity Ensembling, Feature Gating, and\npost-fusion neural network layers as fusion operator components, culminating in\nan absolute percentage point improvement of $1.1\\%$ on the VQA 2.0 test-dev set\nover baseline fusion operators, which use the same features as input. We use\nour findings as evidence that our generalized class of fusion operators could\nlead to the discovery of even superior task-specific operators when used as a\nsearch space in an architecture search over fusion operators.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 00:30:34 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 15:18:26 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Duke", "Brendan", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1803.09383", "submitter": "Xi-Lin Li", "authors": "Xi-Lin Li", "title": "Online Second Order Methods for Non-Convex Stochastic Optimizations", "comments": "Supplement: Tensorflow implementation at\n  https://github.com/lixilinx/psgd_tf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a family of online second order methods for possibly\nnon-convex stochastic optimizations based on the theory of preconditioned\nstochastic gradient descent (PSGD), which can be regarded as an enhance\nstochastic Newton method with the ability to handle gradient noise and\nnon-convexity simultaneously. We have improved the implementations of the\noriginal PSGD in several ways, e.g., new forms of preconditioners, more\naccurate Hessian vector product calculations, and better numerical stability\nwith vanishing or ill-conditioned Hessian, etc.. We also have unrevealed the\nrelationship between feature normalization and PSGD with Kronecker product\npreconditioners, which explains the excellent performance of Kronecker product\npreconditioners in deep neural network learning. A software package\n(https://github.com/lixilinx/psgd_tf) implemented in Tensorflow is provided to\ncompare variations of stochastic gradient descent (SGD) and PSGD with five\ndifferent preconditioners on a wide range of benchmark problems with commonly\nused neural network architectures, e.g., convolutional and recurrent neural\nnetworks. Experimental results clearly demonstrate the advantages of PSGD in\nterms of generalization performance and convergence speed.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 01:39:27 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 01:50:29 GMT"}, {"version": "v3", "created": "Sun, 29 Apr 2018 05:04:45 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Li", "Xi-Lin", ""]]}, {"id": "1803.09386", "submitter": "Michael Teti", "authors": "Michael Teti, William Edward Hahn, Shawn Martin, Christopher Teti, and\n  Elan Barenholtz", "title": "A Systematic Comparison of Deep Learning Architectures in an Autonomous\n  Vehicle", "comments": "16 pages, 14 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving technology is advancing rapidly --- albeit with significant\nchallenges and limitations. This progress is largely due to recent developments\nin deep learning algorithms. To date, however, there has been no systematic\ncomparison of how different deep learning architectures perform at such tasks,\nor an attempt to determine a correlation between classification performance and\nperformance in an actual vehicle, a potentially critical factor in developing\nself-driving systems. Here, we introduce the first controlled comparison of\nmultiple deep-learning architectures in an end-to-end autonomous driving task\nacross multiple testing conditions. We compared performance, under identical\ndriving conditions, across seven architectures including a fully-connected\nnetwork, a simple 2 layer CNN, AlexNet, VGG-16, Inception-V3, ResNet, and an\nLSTM by assessing the number of laps each model was able to successfully\ncomplete without crashing while traversing an indoor racetrack. We compared\nperformance across models when the conditions exactly matched those in training\nas well as when the local environment and track were configured differently and\nobjects that were not included in the training dataset were placed on the track\nin various positions. In addition, we considered performance using several\ndifferent data types for training and testing including single grayscale and\ncolor frames, and multiple grayscale frames stacked together in sequence. With\nthe exception of a fully-connected network, all models performed reasonably\nwell (around or above 80\\%) and most very well (~95\\%) on at least one input\ntype but with considerable variation across models and inputs. Overall,\nAlexNet, operating on single color frames as input, achieved the best level of\nperformance (100\\% success rate in phase one and 55\\% in phase two) while\nVGG-16 performed well most consistently across image types.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 01:58:07 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2018 00:04:29 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Teti", "Michael", ""], ["Hahn", "William Edward", ""], ["Martin", "Shawn", ""], ["Teti", "Christopher", ""], ["Barenholtz", "Elan", ""]]}, {"id": "1803.09460", "submitter": "Giacomo Zanella", "authors": "Omiros Papaspiliopoulos, Gareth O. Roberts and Giacomo Zanella", "title": "Scalable inference for crossed random effects models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the complexity of Gibbs samplers for inference in crossed random\neffect models used in modern analysis of variance. We demonstrate that for\ncertain designs the plain vanilla Gibbs sampler is not scalable, in the sense\nthat its complexity is worse than proportional to the number of parameters and\ndata. We thus propose a simple modification leading to a collapsed Gibbs\nsampler that is provably scalable. Although our theory requires some\nbalancedness assumptions on the data designs, we demonstrate in simulated and\nreal datasets that the rates it predicts match remarkably the correct rates in\ncases where the assumptions are violated. We also show that the collapsed Gibbs\nsampler, extended to sample further unknown hyperparameters, outperforms\nsignificantly alternative state of the art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 08:15:54 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Papaspiliopoulos", "Omiros", ""], ["Roberts", "Gareth O.", ""], ["Zanella", "Giacomo", ""]]}, {"id": "1803.09468", "submitter": "Boussad Addad", "authors": "Boussad Addad, Jerome Kodjabachian, and Christophe Meyer", "title": "Clipping free attacks against artificial neural networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last years, a remarkable breakthrough has been made in AI domain\nthanks to artificial deep neural networks that achieved a great success in many\nmachine learning tasks in computer vision, natural language processing, speech\nrecognition, malware detection and so on. However, they are highly vulnerable\nto easily crafted adversarial examples. Many investigations have pointed out\nthis fact and different approaches have been proposed to generate attacks while\nadding a limited perturbation to the original data. The most robust known\nmethod so far is the so called C&W attack [1]. Nonetheless, a countermeasure\nknown as feature squeezing coupled with ensemble defense showed that most of\nthese attacks can be destroyed [6]. In this paper, we present a new method we\ncall Centered Initial Attack (CIA) whose advantage is twofold : first, it\ninsures by construction the maximum perturbation to be smaller than a threshold\nfixed beforehand, without the clipping process that degrades the quality of\nattacks. Second, it is robust against recently introduced defenses such as\nfeature squeezing, JPEG encoding and even against a voting ensemble of\ndefenses. While its application is not limited to images, we illustrate this\nusing five of the current best classifiers on ImageNet dataset among which two\nare adversarialy retrained on purpose to be robust against attacks. With a\nfixed maximum perturbation of only 1.5% on any pixel, around 80% of attacks\n(targeted) fool the voting ensemble defense and nearly 100% when the\nperturbation is only 6%. While this shows how it is difficult to defend against\nCIA attacks, the last section of the paper gives some guidelines to limit their\nimpact.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 08:39:15 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 07:44:38 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Addad", "Boussad", ""], ["Kodjabachian", "Jerome", ""], ["Meyer", "Christophe", ""]]}, {"id": "1803.09473", "submitter": "Uri Alon", "authors": "Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav", "title": "code2vec: Learning Distributed Representations of Code", "comments": "Accepted in POPL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural model for representing snippets of code as continuous\ndistributed vectors (\"code embeddings\"). The main idea is to represent a code\nsnippet as a single fixed-length $\\textit{code vector}$, which can be used to\npredict semantic properties of the snippet. This is performed by decomposing\ncode to a collection of paths in its abstract syntax tree, and learning the\natomic representation of each path $\\textit{simultaneously}$ with learning how\nto aggregate a set of them. We demonstrate the effectiveness of our approach by\nusing it to predict a method's name from the vector representation of its body.\nWe evaluate our approach by training a model on a dataset of 14M methods. We\nshow that code vectors trained on this dataset can predict method names from\nfiles that were completely unobserved during training. Furthermore, we show\nthat our model learns useful method name vectors that capture semantic\nsimilarities, combinations, and analogies. Comparing previous techniques over\nthe same data set, our approach obtains a relative improvement of over 75%,\nbeing the first to successfully predict method names based on a large,\ncross-project, corpus. Our trained model, visualizations and vector\nsimilarities are available as an interactive online demo at\nhttp://code2vec.org. The code, data, and trained models are available at\nhttps://github.com/tech-srl/code2vec.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 09:05:30 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 11:57:57 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 10:00:14 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 09:38:16 GMT"}, {"version": "v5", "created": "Tue, 30 Oct 2018 09:45:07 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Alon", "Uri", ""], ["Zilberstein", "Meital", ""], ["Levy", "Omer", ""], ["Yahav", "Eran", ""]]}, {"id": "1803.09518", "submitter": "Kristina Preuer", "authors": "Kristina Preuer and Philipp Renz and Thomas Unterthiner and Sepp\n  Hochreiter and G\\\"unter Klambauer", "title": "Fr\\'echet ChemNet Distance: A metric for generative models for molecules\n  in drug discovery", "comments": "Implementations are available at:\n  https://www.github.com/bioinf-jku/FCD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new wave of successful generative models in machine learning has\nincreased the interest in deep learning driven de novo drug design. However,\nassessing the performance of such generative models is notoriously difficult.\nMetrics that are typically used to assess the performance of such generative\nmodels are the percentage of chemically valid molecules or the similarity to\nreal molecules in terms of particular descriptors, such as the partition\ncoefficient (logP) or druglikeness. However, method comparison is difficult\nbecause of the inconsistent use of evaluation metrics, the necessity for\nmultiple metrics, and the fact that some of these measures can easily be\ntricked by simple rule-based systems. We propose a novel distance measure\nbetween two sets of molecules, called Fr\\'echet ChemNet distance (FCD), that\ncan be used as an evaluation metric for generative models. The FCD is similar\nto a recently established performance metric for comparing image generation\nmethods, the Fr\\'echet Inception Distance (FID). Whereas the FID uses one of\nthe hidden layers of InceptionNet, the FCD utilizes the penultimate layer of a\ndeep neural network called ChemNet, which was trained to predict drug\nactivities. Thus, the FCD metric takes into account chemically and biologically\nrelevant information about molecules, and also measures the diversity of the\nset via the distribution of generated molecules. The FCD's advantage over\nprevious metrics is that it can detect if generated molecules are a) diverse\nand have similar b) chemical and c) biological properties as real molecules. We\nfurther provide an easy-to-use implementation that only requires the SMILES\nrepresentation of the generated molecules as input to calculate the FCD.\nImplementations are available at: https://www.github.com/bioinf-jku/FCD\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 11:36:24 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 06:57:03 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 14:20:53 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Preuer", "Kristina", ""], ["Renz", "Philipp", ""], ["Unterthiner", "Thomas", ""], ["Hochreiter", "Sepp", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "1803.09522", "submitter": "Eran Malach", "authors": "Eran Malach, Shai Shalev-Shwartz", "title": "A Provably Correct Algorithm for Deep Learning that Actually Works", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a layer-by-layer algorithm for training deep convolutional\nnetworks, where each step involves gradient updates for a two layer network\nfollowed by a simple clustering algorithm. Our algorithm stems from a deep\ngenerative model that generates mages level by level, where lower resolution\nimages correspond to latent semantic classes. We analyze the convergence rate\nof our algorithm assuming that the data is indeed generated according to this\nmodel (as well as additional assumptions). While we do not pretend to claim\nthat the assumptions are realistic for natural images, we do believe that they\ncapture some true properties of real data. Furthermore, we show that our\nalgorithm actually works in practice (on the CIFAR dataset), achieving results\nin the same ballpark as that of vanilla convolutional neural networks that are\nbeing trained by stochastic gradient descent. Finally, our proof techniques may\nbe of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 11:48:14 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 13:55:48 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1803.09533", "submitter": "Marc Lelarge", "authors": "Jean-Baptiste Escudi\\'e, Alaa Saade, Alice Coucke, Marc Lelarge", "title": "Deep Representation for Patient Visits from Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to learn low-dimensional representations (embeddings) of patient\nvisits from the corresponding electronic health record (EHR) where\nInternational Classification of Diseases (ICD) diagnosis codes are removed. We\nexpect that these embeddings will be useful for the construction of predictive\nstatistical models anticipated to drive personalized medicine and improve\nhealthcare quality. These embeddings are learned using a deep neural network\ntrained to predict ICD diagnosis categories. We show that our embeddings\ncapture relevant clinical informations and can be used directly as input to\nstandard machine learning algorithms like multi-output classifiers for ICD code\nprediction. We also show that important medical informations correspond to\nparticular directions in our embedding space.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:02:48 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Escudi\u00e9", "Jean-Baptiste", ""], ["Saade", "Alaa", ""], ["Coucke", "Alice", ""], ["Lelarge", "Marc", ""]]}, {"id": "1803.09539", "submitter": "Sai Praneeth Karimireddy", "authors": "Francesco Locatello, Anant Raj, Sai Praneeth Karimireddy, Gunnar\n  R\\\"atsch, Bernhard Sch\\\"olkopf, Sebastian U. Stich, Martin Jaggi", "title": "On Matching Pursuit and Coordinate Descent", "comments": null, "journal-ref": "ICML 2018 - Proceedings of the 35th International Conference on\n  Machine Learning", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two popular examples of first-order optimization methods over linear spaces\nare coordinate descent and matching pursuit algorithms, with their randomized\nvariants. While the former targets the optimization by moving along\ncoordinates, the latter considers a generalized notion of directions.\nExploiting the connection between the two algorithms, we present a unified\nanalysis of both, providing affine invariant sublinear $\\mathcal{O}(1/t)$ rates\non smooth objectives and linear convergence on strongly convex objectives. As a\nbyproduct of our affine invariant analysis of matching pursuit, our rates for\nsteepest coordinate descent are the tightest known. Furthermore, we show the\nfirst accelerated convergence rate $\\mathcal{O}(1/t^2)$ for matching pursuit\nand steepest coordinate descent on convex objectives.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:15:21 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 07:33:05 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 17:39:04 GMT"}, {"version": "v4", "created": "Fri, 8 Jun 2018 07:31:49 GMT"}, {"version": "v5", "created": "Mon, 2 Jul 2018 14:00:23 GMT"}, {"version": "v6", "created": "Tue, 26 Feb 2019 08:40:16 GMT"}, {"version": "v7", "created": "Fri, 31 May 2019 17:33:52 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Locatello", "Francesco", ""], ["Raj", "Anant", ""], ["Karimireddy", "Sai Praneeth", ""], ["R\u00e4tsch", "Gunnar", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Stich", "Sebastian U.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1803.09546", "submitter": "Gil Keren", "authors": "Gil Keren, Nicholas Cummins, Bj\\\"orn Schuller", "title": "Calibrated Prediction Intervals for Neural Network Regressors", "comments": null, "journal-ref": "IEEE Access (Volume 6), 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ongoing developments in neural network models are continually advancing the\nstate of the art in terms of system accuracy. However, the predicted labels\nshould not be regarded as the only core output; also important is a\nwell-calibrated estimate of the prediction uncertainty. Such estimates and\ntheir calibration are critical in many practical applications. Despite their\nobvious aforementioned advantage in relation to accuracy, contemporary neural\nnetworks can, generally, be regarded as poorly calibrated and as such do not\nproduce reliable output probability estimates. Further, while post-processing\ncalibration solutions can be found in the relevant literature, these tend to be\nfor systems performing classification. In this regard, we herein present two\nnovel methods for acquiring calibrated predictions intervals for neural network\nregressors: empirical calibration and temperature scaling. In experiments using\ndifferent regression tasks from the audio and computer vision domains, we find\nthat both our proposed methods are indeed capable of producing calibrated\nprediction intervals for neural network regressors with any desired confidence\nlevel, a finding that is consistent across all datasets and neural network\narchitectures we experimented with. In addition, we derive an additional\npractical recommendation for producing more accurate calibrated prediction\nintervals. We release the source code implementing our proposed methods for\ncomputing calibrated predicted intervals. The code for computing calibrated\npredicted intervals is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:35:12 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 12:58:45 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 15:56:34 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Keren", "Gil", ""], ["Cummins", "Nicholas", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1803.09578", "submitter": "Nils Reimers", "authors": "Nils Reimers, Iryna Gurevych", "title": "Why Comparing Single Performance Scores Does Not Allow to Draw\n  Conclusions About Machine Learning Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Developing state-of-the-art approaches for specific tasks is a major driving\nforce in our research community. Depending on the prestige of the task,\npublishing it can come along with a lot of visibility. The question arises how\nreliable are our evaluation methodologies to compare approaches?\n  One common methodology to identify the state-of-the-art is to partition data\ninto a train, a development and a test set. Researchers can train and tune\ntheir approach on some part of the dataset and then select the model that\nworked best on the development set for a final evaluation on unseen test data.\nTest scores from different approaches are compared, and performance differences\nare tested for statistical significance.\n  In this publication, we show that there is a high risk that a statistical\nsignificance in this type of evaluation is not due to a superior learning\napproach. Instead, there is a high risk that the difference is due to chance.\nFor example for the CoNLL 2003 NER dataset we observed in up to 26% of the\ncases type I errors (false positives) with a threshold of p < 0.05, i.e.,\nfalsely concluding a statistically significant difference between two identical\napproaches.\n  We prove that this evaluation setup is unsuitable to compare learning\napproaches. We formalize alternative evaluation setups based on score\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:35:14 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Reimers", "Nils", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1803.09621", "submitter": "Yoav Kaempfer", "authors": "Yoav Kaempfer and Lior Wolf", "title": "Learning the Multiple Traveling Salesmen Problem with Permutation\n  Invariant Pooling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there are optimal TSP solvers, as well as recent learning-based\napproaches, the generalization of the TSP to the Multiple Traveling Salesmen\nProblem is much less studied. Here, we design a neural network solution that\ntreats the salesmen, cities and depot as three different sets of varying\ncardinalities. We apply a novel technique that combines elements from recent\narchitectures that were developed for sets, as well as elements from graph\nnetworks. Coupled with new constraint enforcing output layers, a dedicated\nloss, and a search method, our solution is shown to outperform all the\nmeta-heuristics of the leading solver in the field.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 14:29:42 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 14:24:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Kaempfer", "Yoav", ""], ["Wolf", "Lior", ""]]}, {"id": "1803.09638", "submitter": "Pin-Yu Chen", "authors": "Pei-Hsuan Lu, Pin-Yu Chen, Chia-Mu Yu", "title": "On the Limitation of Local Intrinsic Dimensionality for Characterizing\n  the Subspaces of Adversarial Examples", "comments": "Accepted to ICLR 2018 Worshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and characterizing the subspaces of adversarial examples aid in\nstudying the robustness of deep neural networks (DNNs) to adversarial\nperturbations. Very recently, Ma et al. (ICLR 2018) proposed to use local\nintrinsic dimensionality (LID) in layer-wise hidden representations of DNNs to\nstudy adversarial subspaces. It was demonstrated that LID can be used to\ncharacterize the adversarial subspaces associated with different attack\nmethods, e.g., the Carlini and Wagner's (C&W) attack and the fast gradient sign\nattack.\n  In this paper, we use MNIST and CIFAR-10 to conduct two new sets of\nexperiments that are absent in existing LID analysis and report the limitation\nof LID in characterizing the corresponding adversarial subspaces, which are (i)\noblivious attacks and LID analysis using adversarial examples with different\nconfidence levels; and (ii) black-box transfer attacks. For (i), we find that\nthe performance of LID is very sensitive to the confidence parameter deployed\nby an attack, and the LID learned from ensembles of adversarial examples with\nvarying confidence levels surprisingly gives poor performance. For (ii), we\nfind that when adversarial examples are crafted from another DNN model, LID is\nineffective in characterizing their adversarial subspaces. These two findings\ntogether suggest the limited capability of LID in characterizing the subspaces\nof adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 14:56:28 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Lu", "Pei-Hsuan", ""], ["Chen", "Pin-Yu", ""], ["Yu", "Chia-Mu", ""]]}, {"id": "1803.09655", "submitter": "Giovanni Mariani", "authors": "Giovanni Mariani, Florian Scheidegger, Roxana Istrate, Costas Bekas,\n  Cristiano Malossi", "title": "BAGAN: Data Augmentation with Balancing GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification datasets are often imbalanced, characteristic that\nnegatively affects the accuracy of deep-learning classifiers. In this work we\npropose balancing GAN (BAGAN) as an augmentation tool to restore balance in\nimbalanced datasets. This is challenging because the few minority-class images\nmay not be enough to train a GAN. We overcome this issue by including during\nthe adversarial training all available images of majority and minority classes.\nThe generative model learns useful features from majority classes and uses\nthese to generate images for minority classes. We apply class conditioning in\nthe latent space to drive the generation process towards a target class. The\ngenerator in the GAN is initialized with the encoder module of an autoencoder\nthat enables us to learn an accurate class-conditioning in the latent space. We\ncompare the proposed methodology with state-of-the-art GANs and demonstrate\nthat BAGAN generates images of superior quality when trained with an imbalanced\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 15:20:56 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 08:07:30 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Mariani", "Giovanni", ""], ["Scheidegger", "Florian", ""], ["Istrate", "Roxana", ""], ["Bekas", "Costas", ""], ["Malossi", "Cristiano", ""]]}, {"id": "1803.09672", "submitter": "Vishnu Naresh Boddeti", "authors": "Sixue Gong, Vishnu Naresh Boddeti and Anil K. Jain", "title": "On the Intrinsic Dimensionality of Image Representations", "comments": "Accepted for publication at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the following questions pertaining to the intrinsic\ndimensionality of any given image representation: (i) estimate its intrinsic\ndimensionality, (ii) develop a deep neural network based non-linear mapping,\ndubbed DeepMDS, that transforms the ambient representation to the minimal\nintrinsic space, and (iii) validate the veracity of the mapping through image\nmatching in the intrinsic space. Experiments on benchmark image datasets (LFW,\nIJB-C and ImageNet-100) reveal that the intrinsic dimensionality of deep neural\nnetwork representations is significantly lower than the dimensionality of the\nambient features. For instance, SphereFace's 512-dim face representation and\nResNet's 512-dim image representation have an intrinsic dimensionality of 16\nand 19 respectively. Further, the DeepMDS mapping is able to obtain a\nrepresentation of significantly lower dimensionality while maintaining\ndiscriminative ability to a large extent, 59.75% TAR @ 0.1% FAR in 16-dim vs\n71.26% TAR in 512-dim on IJB-C and a Top-1 accuracy of 77.0% at 19-dim vs 83.4%\nat 512-dim on ImageNet-100.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 15:38:27 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 01:04:41 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Gong", "Sixue", ""], ["Boddeti", "Vishnu Naresh", ""], ["Jain", "Anil K.", ""]]}, {"id": "1803.09689", "submitter": "Cem Eteke", "authors": "Cem Eteke, Hayati Havlucu, Nisa \\.Irem K{\\i}rba\\c{c}, Mehmet Cengiz\n  Onba\\c{s}l{\\i}, Aykut Co\\c{s}kun, Terry Eskenazi, O\\u{g}uzhan \\\"Ozcan,\n  Bar{\\i}\\c{s} Akg\\\"un", "title": "Flow From Motion: A Deep Learning Approach", "comments": "7 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable devices have the potential to enhance sports performance, yet they\nare not fulfilling this promise. Our previous studies with 6 professional\ntennis coaches and 20 players indicate that this could be due the lack of\npsychological or mental state feedback, which the coaches claim to provide.\nTowards this end, we propose to detect the flow state, mental state of optimal\nperformance, using wearables data to be later used in training. We performed a\nstudy with a professional tennis coach and two players. The coach provided\nlabels about the players' flow state while each player had a wearable device on\ntheir racket holding wrist. We trained multiple models using the wearables data\nand the coach labels. Our deep neural network models achieved around 98%\ntesting accuracy for a variety of conditions. This suggests that the flow state\nor what coaches recognize as flow, can be detected using wearables data in\ntennis which is a novel result. The implication for the HCI community is that\nhaving access to such information would allow for design of novel hardware and\ninteraction paradigms that would be helpful in professional athlete training.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:12:48 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Eteke", "Cem", ""], ["Havlucu", "Hayati", ""], ["K\u0131rba\u00e7", "Nisa \u0130rem", ""], ["Onba\u015fl\u0131", "Mehmet Cengiz", ""], ["Co\u015fkun", "Aykut", ""], ["Eskenazi", "Terry", ""], ["\u00d6zcan", "O\u011fuzhan", ""], ["Akg\u00fcn", "Bar\u0131\u015f", ""]]}, {"id": "1803.09702", "submitter": "Olivier Deiss", "authors": "Olivier Deiss, Siddharth Biswal, Jing Jin, Haoqi Sun, M. Brandon\n  Westover, Jimeng Sun", "title": "HAMLET: Interpretable Human And Machine co-LEarning Technique", "comments": "Removed KDD template", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient label acquisition processes are key to obtaining robust\nclassifiers. However, data labeling is often challenging and subject to high\nlevels of label noise. This can arise even when classification targets are well\ndefined, if instances to be labeled are more difficult than the prototypes used\nto define the class, leading to disagreements among the expert community. Here,\nwe enable efficient training of deep neural networks. From low-confidence\nlabels, we iteratively improve their quality by simultaneous learning of\nmachines and experts. We call it Human And Machine co-LEarning Technique\n(HAMLET). Throughout the process, experts become more consistent, while the\nalgorithm provides them with explainable feedback for confirmation. HAMLET uses\na neural embedding function and a memory module filled with diverse reference\nembeddings from different classes. Its output includes classification labels\nand highly relevant reference embeddings as explanation. We took the study of\nbrain monitoring at intensive care unit (ICU) as an application of HAMLET on\ncontinuous electroencephalography (cEEG) data. Although cEEG monitoring yields\nlarge volumes of data, labeling costs and difficulty make it hard to build a\nclassifier. Additionally, while experts agree on the labels of clear-cut\nexamples of cEEG patterns, labeling many real-world cEEG data can be extremely\nchallenging. Thus, a large minority of sequences might be mislabeled. HAMLET\nhas shown significant performance gain against deep learning and other\nbaselines, increasing accuracy from 7.03% to 68.75% on challenging inputs.\nBesides improved performance, clinical experts confirmed the interpretability\nof those reference embeddings in helping explaining the classification results\nby HAMLET.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:29:03 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 13:28:50 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 05:41:09 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Deiss", "Olivier", ""], ["Biswal", "Siddharth", ""], ["Jin", "Jing", ""], ["Sun", "Haoqi", ""], ["Westover", "M. Brandon", ""], ["Sun", "Jimeng", ""]]}, {"id": "1803.09704", "submitter": "Bernardo P\\'erez Orozco", "authors": "Bernardo P\\'erez Orozco, Gabriele Abbati, Stephen Roberts", "title": "MOrdReD: Memory-based Ordinal Regression Deep Neural Networks for Time\n  Series Forecasting", "comments": "30 pages, 12 figures * This version expands on the literature review;\n  presents appendices in a graphical manner (as opposed to the previous\n  tables); adds a mapping between dataset descriptions and shorthands; expands\n  on results analysis and conclusions; corrects a few typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is ubiquitous in the modern world. Applications range\nfrom health care to astronomy, and include climate modelling, financial trading\nand monitoring of critical engineering equipment. To offer value over this\nrange of activities, models must not only provide accurate forecasts, but also\nquantify and adjust their uncertainty over time. In this work, we directly\ntackle this task with a novel, fully end-to-end deep learning method for time\nseries forecasting. By recasting time series forecasting as an ordinal\nregression task, we develop a principled methodology to assess long-term\npredictive uncertainty and describe rich multimodal, non-Gaussian behaviour,\nwhich arises regularly in applied settings.\n  Notably, our framework is a wholly general-purpose approach that requires\nlittle to no user intervention to be used. We showcase this key feature in a\nlarge-scale benchmark test with 45 datasets drawn from both, a wide range of\nreal-world application domains, as well as a comprehensive list of synthetic\nmaps. This wide comparison encompasses state-of-the-art methods in both the\nMachine Learning and Statistics modelling literature, such as the Gaussian\nProcess. We find that our approach does not only provide excellent predictive\nforecasts, shadowing true future values, but also allows us to infer valuable\ninformation, such as the predictive distribution of the occurrence of critical\nevents of interest, accurately and reliably even over long time horizons.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:36:37 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 15:20:24 GMT"}, {"version": "v3", "created": "Sat, 11 Aug 2018 14:24:07 GMT"}, {"version": "v4", "created": "Wed, 24 Oct 2018 23:51:41 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Orozco", "Bernardo P\u00e9rez", ""], ["Abbati", "Gabriele", ""], ["Roberts", "Stephen", ""]]}, {"id": "1803.09730", "submitter": "Brent Schlotfeldt", "authors": "Brent Schlotfeldt, Vasileios Tzoumas, Dinesh Thakur, George J. Pappas", "title": "Resilient Active Information Gathering with Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA math.OC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of safety, security, and rescue in robotics, such as multi-robot\ntarget tracking, involve the execution of information acquisition tasks by\nteams of mobile robots. However, in failure-prone or adversarial environments,\nrobots get attacked, their communication channels get jammed, and their sensors\nmay fail, resulting in the withdrawal of robots from the collective task, and\nconsequently the inability of the remaining active robots to coordinate with\neach other. As a result, traditional design paradigms become insufficient and,\nin contrast, resilient designs against system-wide failures and attacks become\nimportant. In general, resilient design problems are hard, and even though they\noften involve objective functions that are monotone or submodular, scalable\napproximation algorithms for their solution have been hitherto unknown. In this\npaper, we provide the first algorithm, enabling the following capabilities:\nminimal communication, i.e., the algorithm is executed by the robots based only\non minimal communication between them; system-wide resiliency, i.e., the\nalgorithm is valid for any number of denial-of-service attacks and failures;\nand provable approximation performance, i.e., the algorithm ensures for all\nmonotone (and not necessarily submodular) objective functions a solution that\nis finitely close to the optimal. We quantify our algorithm's approximation\nperformance using a notion of curvature for monotone set functions. We support\nour theoretical analyses with simulated and real-world experiments, by\nconsidering an active information gathering scenario, namely, multi-robot\ntarget tracking.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 17:41:05 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 03:32:18 GMT"}, {"version": "v3", "created": "Sun, 2 Sep 2018 14:59:22 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Schlotfeldt", "Brent", ""], ["Tzoumas", "Vasileios", ""], ["Thakur", "Dinesh", ""], ["Pappas", "George J.", ""]]}, {"id": "1803.09733", "submitter": "Fang Su", "authors": "Fang Su, Jing-Yan Wang", "title": "Domain transfer convolutional attribute embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of transfer learning with the attribute\ndata. In the transfer learning problem, we want to leverage the data of the\nauxiliary and the target domains to build an effective model for the\nclassification problem in the target domain. Meanwhile, the attributes are\nnaturally stable cross different domains. This strongly motives us to learn\neffective domain transfer attribute representations. To this end, we proposed\nto embed the attributes of the data to a common space by using the powerful\nconvolutional neural network (CNN) model. The convolutional representations of\nthe data points are mapped to the corresponding attributes so that they can be\neffective embedding of the attributes. We also represent the data of different\ndomains by a domain-independent CNN, ant a domain-specific CNN, and combine\ntheir outputs with the attribute embedding to build the classification model.\nAn joint learning framework is constructed to minimize the classification\nerrors, the attribute mapping error, the mismatching of the domain-independent\nrepresentations cross different domains, and to encourage the the neighborhood\nsmoothness of representations in the target domain. The minimization problem is\nsolved by an iterative algorithm based on gradient descent. Experiments over\nbenchmark data sets of person re-identification, bankruptcy prediction, and\nspam email detection, show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 17:44:45 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 17:20:03 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Su", "Fang", ""], ["Wang", "Jing-Yan", ""]]}, {"id": "1803.09737", "submitter": "In\\^es Almeida", "authors": "In\\^es Almeida and Jo\\~ao Xavier", "title": "DJAM: distributed Jacobi asynchronous method for learning personal\n  models", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": "10.1109/LSP.2018.2859596", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing data collected by a network of agents often boils down to solving\nan optimization problem. The distributed nature of these problems calls for\nmethods that are, themselves, distributed. While most collaborative learning\nproblems require agents to reach a common (or consensus) model, there are\nsituations in which the consensus solution may not be optimal. For instance,\nagents may want to reach a compromise between agreeing with their neighbors and\nminimizing a personal loss function. We present DJAM, a Jacobi-like distributed\nalgorithm for learning personalized models. This method is\nimplementation-friendly: it has no hyperparameters that need tuning, it is\nasynchronous, and its updates only require single-neighbor interactions. We\nprove that DJAM converges with probability one to the solution, provided that\nthe personal loss functions are strongly convex and have Lipschitz gradient. We\nthen give evidence that DJAM is on par with state-of-the-art methods: our\nmethod reaches a solution with error similar to the error of a carefully tuned\nADMM in about the same number of single-neighbor interactions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 17:53:56 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 16:54:17 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Almeida", "In\u00eas", ""], ["Xavier", "Jo\u00e3o", ""]]}, {"id": "1803.09791", "submitter": "Mustafa Haider", "authors": "Adnan Haider", "title": "A Common Framework for Natural Gradient and Taylor based Optimisation\n  using Manifold Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report constructs a theoretical framework to relate standard\nTaylor approximation based optimisation methods with Natural Gradient (NG), a\nmethod which is Fisher efficient with probabilistic models. Such a framework\nwill be shown to also provide mathematical justification to combine higher\norder methods with the method of NG.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:54:36 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 21:45:59 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 13:44:05 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Haider", "Adnan", ""]]}, {"id": "1803.09820", "submitter": "Leslie Smith", "authors": "Leslie N. Smith", "title": "A disciplined approach to neural network hyper-parameters: Part 1 --\n  learning rate, batch size, momentum, and weight decay", "comments": "Files to help replicate the results reported here are available on\n  Github", "journal-ref": null, "doi": null, "report-no": "US Naval Research Laboratory Technical Report 5510-026", "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has produced dazzling successes for applications of\nimage, speech, and video processing in the past few years, most trainings are\nwith suboptimal hyper-parameters, requiring unnecessarily long training times.\nSetting the hyper-parameters remains a black art that requires years of\nexperience to acquire. This report proposes several efficient ways to set the\nhyper-parameters that significantly reduce training time and improves\nperformance. Specifically, this report shows how to examine the training\nvalidation/test loss function for subtle clues of underfitting and overfitting\nand suggests guidelines for moving toward the optimal balance point. Then it\ndiscusses how to increase/decrease the learning rate/momentum to speed up\ntraining. Our experiments show that it is crucial to balance every manner of\nregularization for each dataset and architecture. Weight decay is used as a\nsample regularizer to show how its optimal value is tightly coupled with the\nlearning rates and momentums. Files to help replicate the results reported here\nare available.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 20:05:59 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 17:43:51 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Smith", "Leslie N.", ""]]}, {"id": "1803.09862", "submitter": "Timothy Graham", "authors": "Senuri Wijenayake, Timothy Graham, Peter Christen", "title": "A Decision Tree Approach to Predicting Recidivism in Domestic Violence", "comments": "12 pages; Accepted at The 2018 Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domestic violence (DV) is a global social and public health issue that is\nhighly gendered. Being able to accurately predict DV recidivism, i.e.,\nre-offending of a previously convicted offender, can speed up and improve risk\nassessment procedures for police and front-line agencies, better protect\nvictims of DV, and potentially prevent future re-occurrences of DV. Previous\nwork in DV recidivism has employed different classification techniques,\nincluding decision tree (DT) induction and logistic regression, where the main\nfocus was on achieving high prediction accuracy. As a result, even the diagrams\nof trained DTs were often too difficult to interpret due to their size and\ncomplexity, making decision-making challenging. Given there is often a\ntrade-off between model accuracy and interpretability, in this work our aim is\nto employ DT induction to obtain both interpretable trees as well as high\nprediction accuracy. Specifically, we implement and evaluate different\napproaches to deal with class imbalance as well as feature selection. Compared\nto previous work in DV recidivism prediction that employed logistic regression,\nour approach can achieve comparable area under the ROC curve results by using\nonly 3 of 11 available features and generating understandable decision trees\nthat contain only 4 leaf nodes.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:03:26 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Wijenayake", "Senuri", ""], ["Graham", "Timothy", ""], ["Christen", "Peter", ""]]}, {"id": "1803.09868", "submitter": "Yash Sharma", "authors": "Yash Sharma and Pin-Yu Chen", "title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Squeezing is a recently proposed defense method which reduces the\nsearch space available to an adversary by coalescing samples that correspond to\nmany different feature vectors in the original space into a single sample. It\nhas been shown that feature squeezing defenses can be combined in a joint\ndetection framework to achieve high detection rates against state-of-the-art\nattacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by\nincreasing the adversary strength of said state-of-the-art attacks, one can\nbypass the detection framework with adversarial examples of minimal visual\ndistortion. These results suggest for proposed defenses to validate against\nstronger attack configurations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:08:39 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sharma", "Yash", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "1803.09877", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen and Hongyi Wang and Zachary Charles and Dimitris\n  Papailiopoulos", "title": "DRACO: Byzantine-resilient Distributed Training via Redundant Gradients", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed model training is vulnerable to byzantine system failures and\nadversarial compute nodes, i.e., nodes that use malicious updates to corrupt\nthe global model stored at a parameter server (PS). To guarantee some form of\nrobustness, recent work suggests using variants of the geometric median as an\naggregation rule, in place of gradient averaging. Unfortunately, median-based\nrules can incur a prohibitive computational overhead in large-scale settings,\nand their convergence guarantees often require strong assumptions. In this\nwork, we present DRACO, a scalable framework for robust distributed training\nthat uses ideas from coding theory. In DRACO, each compute node evaluates\nredundant gradients that are used by the parameter server to eliminate the\neffects of adversarial updates. DRACO comes with problem-independent robustness\nguarantees, and the model that it trains is identical to the one trained in the\nadversary-free setup. We provide extensive experiments on real datasets and\ndistributed setups across a variety of large-scale models, where we show that\nDRACO is several times, to orders of magnitude faster than median-based\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:34:25 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 05:38:33 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 02:10:56 GMT"}, {"version": "v4", "created": "Fri, 22 Jun 2018 02:47:53 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Chen", "Lingjiao", ""], ["Wang", "Hongyi", ""], ["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1803.09887", "submitter": "Jie Liu", "authors": "Jie Liu, Hao Zheng", "title": "MLE-induced Likelihood for Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the intractable partition function, the exact likelihood function for\na Markov random field (MRF), in many situations, can only be approximated.\nMajor approximation approaches include pseudolikelihood and Laplace\napproximation. In this paper, we propose a novel way of approximating the\nlikelihood function through first approximating the marginal likelihood\nfunctions of individual parameters and then reconstructing the joint likelihood\nfunction from these marginal likelihood functions. For approximating the\nmarginal likelihood functions, we derive a particular likelihood function from\na modified scenario of coin tossing which is useful for capturing how one\nparameter interacts with the remaining parameters in the likelihood function.\nFor reconstructing the joint likelihood function, we use an appropriate copula\nto link up these marginal likelihood functions. Numerical investigation\nsuggests the superior performance of our approach. Especially as the size of\nthe MRF increases, both the numerical performance and the computational cost of\nour approach remain consistently satisfactory, whereas Laplace approximation\ndeteriorates and pseudolikelihood becomes computationally unbearable.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 04:05:44 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Liu", "Jie", ""], ["Zheng", "Hao", ""]]}, {"id": "1803.09928", "submitter": "Tanvi Verma", "authors": "Tanvi Verma, Pradeep Varakantham and Hoong Chuin Lau", "title": "Entropy based Independent Learning in Anonymous Multi-Agent Settings", "comments": null, "journal-ref": "Vol 29 (2019): Proceedings of the Twenty-Ninth International\n  Conference on Automated Planning and Scheduling", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Efficient sequential matching of supply and demand is a problem of interest\nin many online to offline services. For instance, Uber, Lyft, Grab for matching\ntaxis to customers; Ubereats, Deliveroo, FoodPanda etc for matching restaurants\nto customers. In these online to offline service problems, individuals who are\nresponsible for supply (e.g., taxi drivers, delivery bikes or delivery van\ndrivers) earn more by being at the \"right\" place at the \"right\" time. We are\ninterested in developing approaches that learn to guide individuals to be in\nthe \"right\" place at the \"right\" time (to maximize revenue) in the presence of\nother similar \"learning\" individuals and only local aggregated observation of\nother agents states (e.g., only number of other taxis in same zone as current\nagent).\n  A key characteristic of the domains of interest is that the interactions\nbetween individuals are anonymous, i.e., the outcome of an interaction\n(competing for demand) is dependent only on the number and not on the identity\nof the agents. We model these problems using the Anonymous MARL (AyMARL) model.\nThe key contribution of this paper is in employing principle of maximum entropy\nto provide a general framework of independent learning that is both empirically\neffective (even with only local aggregated information of agent population\ndistribution) and theoretically justified.\n  Finally, our approaches provide a significant improvement with respect to\njoint and individual revenue on a generic simulator for online to offline\nservices and a real world taxi problem over existing approaches. More\nimportantly, this is achieved while having the least variance in revenues\nearned by the learning individuals, an indicator of fairness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 07:10:20 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 08:21:10 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 09:07:50 GMT"}, {"version": "v4", "created": "Mon, 3 Feb 2020 06:25:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Verma", "Tanvi", ""], ["Varakantham", "Pradeep", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1803.09946", "submitter": "Toru Nakashika", "authors": "Toru Nakashika, Shinji Takaki, Junichi Yamagishi", "title": "Complex-Valued Restricted Boltzmann Machine for Direct Speech\n  Parameterization from Complex Spectra", "comments": "Under the IEEE T-ASLP Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a novel energy-based probabilistic distribution that\nrepresents complex-valued data and explains how to apply it to direct feature\nextraction from complex-valued spectra. The proposed model, the complex-valued\nrestricted Boltzmann machine (CRBM), is designed to deal with complex-valued\nvisible units as an extension of the well-known restricted Boltzmann machine\n(RBM). Like the RBM, the CRBM learns the relationships between visible and\nhidden units without having connections between units in the same layer, which\ndramatically improves training efficiency by using Gibbs sampling or\ncontrastive divergence (CD). Another important characteristic is that the CRBM\nalso has connections between real and imaginary parts of each of the\ncomplex-valued visible units that help represent the data distribution in the\ncomplex domain. In speech signal processing, classification and generation\nfeatures are often based on amplitude spectra (e.g., MFCC, cepstra, and\nmel-cepstra) even if they are calculated from complex spectra, and they ignore\nphase information. In contrast, the proposed feature extractor using the CRBM\ndirectly encodes the complex spectra (or another complex-valued representation\nof the complex spectra) into binary-valued latent features (hidden units).\nSince the visible-hidden connections are undirected, we can also recover\n(decode) the complex spectra from the latent features directly. Our speech\ncoding experiments demonstrated that the CRBM outperformed other speech coding\nmethods, such as methods using the conventional RBM, the mel-log spectrum\napproximate (MLSA) decoder, etc.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 08:07:20 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Nakashika", "Toru", ""], ["Takaki", "Shinji", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1803.09956", "submitter": "Andy Zeng", "authors": "Andy Zeng, Shuran Song, Stefan Welker, Johnny Lee, Alberto Rodriguez,\n  Thomas Funkhouser", "title": "Learning Synergies between Pushing and Grasping with Self-supervised\n  Deep Reinforcement Learning", "comments": "To appear at the International Conference On Intelligent Robots and\n  Systems (IROS) 2018. Project webpage: http://vpg.cs.princeton.edu Summary\n  video: https://youtu.be/-OkyX7ZlhiU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skilled robotic manipulation benefits from complex synergies between\nnon-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing\ncan help rearrange cluttered objects to make space for arms and fingers;\nlikewise, grasping can help displace objects to make pushing movements more\nprecise and collision-free. In this work, we demonstrate that it is possible to\ndiscover and learn these synergies from scratch through model-free deep\nreinforcement learning. Our method involves training two fully convolutional\nnetworks that map from visual observations to actions: one infers the utility\nof pushes for a dense pixel-wise sampling of end effector orientations and\nlocations, while the other does the same for grasping. Both networks are\ntrained jointly in a Q-learning framework and are entirely self-supervised by\ntrial and error, where rewards are provided from successful grasps. In this\nway, our policy learns pushing motions that enable future grasps, while\nlearning grasps that can leverage past pushes. During picking experiments in\nboth simulation and real-world scenarios, we find that our system quickly\nlearns complex behaviors amid challenging cases of clutter, and achieves better\ngrasping success rates and picking efficiencies than baseline alternatives\nafter only a few hours of training. We further demonstrate that our method is\ncapable of generalizing to novel objects. Qualitative results (videos), code,\npre-trained models, and simulation environments are available at\nhttp://vpg.cs.princeton.edu\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 08:31:28 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 03:39:11 GMT"}, {"version": "v3", "created": "Sun, 30 Sep 2018 20:34:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zeng", "Andy", ""], ["Song", "Shuran", ""], ["Welker", "Stefan", ""], ["Lee", "Johnny", ""], ["Rodriguez", "Alberto", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "1803.09967", "submitter": "Juan Duque Rodriguez", "authors": "Roberto Maestre, Juan Duque, Alberto Rubio, Juan Ar\\'evalo", "title": "Reinforcement Learning for Fair Dynamic Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unfair pricing policies have been shown to be one of the most negative\nperceptions customers can have concerning pricing, and may result in long-term\nlosses for a company. Despite the fact that dynamic pricing models help\ncompanies maximize revenue, fairness and equality should be taken into account\nin order to avoid unfair price differences between groups of customers. This\npaper shows how to solve dynamic pricing by using Reinforcement Learning (RL)\ntechniques so that prices are maximized while keeping a balance between revenue\nand fairness. We demonstrate that RL provides two main features to support\nfairness in dynamic pricing: on the one hand, RL is able to learn from recent\nexperience, adapting the pricing policy to complex market environments; on the\nother hand, it provides a trade-off between short and long-term objectives,\nhence integrating fairness into the model's core. Considering these two\nfeatures, we propose the application of RL for revenue optimization, with the\nadditional integration of fairness as part of the learning procedure by using\nJain's index as a metric. Results in a simulated environment show a significant\nimprovement in fairness while at the same time maintaining optimisation of\nrevenue.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 09:00:48 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Maestre", "Roberto", ""], ["Duque", "Juan", ""], ["Rubio", "Alberto", ""], ["Ar\u00e9valo", "Juan", ""]]}, {"id": "1803.09974", "submitter": "Dimitra Maoutsa", "authors": "Jose Casadiego, Dimitra Maoutsa, Marc Timme", "title": "Inferring network connectivity from event timing patterns", "comments": "6 pages, 5 figures, The first two authors contributed equally to this\n  paper, and should be regarded as co-first authors. [v2: metadata update]", "journal-ref": "Phys. Rev. Lett. 121, 054101 (2018)", "doi": "10.1103/PhysRevLett.121.054101", "report-no": null, "categories": "q-bio.NC nlin.CD physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing network connectivity from the collective dynamics of a system\ntypically requires access to its complete continuous-time evolution although\nthese are often experimentally inaccessible. Here we propose a theory for\nrevealing physical connectivity of networked systems only from the event time\nseries their intrinsic collective dynamics generate. Representing the patterns\nof event timings in an event space spanned by inter-event and cross-event\nintervals, we reveal which other units directly influence the inter-event times\nof any given unit. For illustration, we linearize an event space mapping\nconstructed from the spiking patterns in model neural circuits to reveal the\npresence or absence of synapses between any pair of neurons as well as whether\nthe coupling acts in an inhibiting or activating (excitatory) manner. The\nproposed model-independent reconstruction theory is scalable to larger networks\nand may thus play an important role in the reconstruction of networks from\nbiology to social science and engineering.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 09:15:04 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 12:56:06 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Casadiego", "Jose", ""], ["Maoutsa", "Dimitra", ""], ["Timme", "Marc", ""]]}, {"id": "1803.09984", "submitter": "Aur\\'elien Bellet", "authors": "Pierre Dellenbach, Aur\\'elien Bellet, Jan Ramon", "title": "Hiding in the Crowd: A Massively Distributed Algorithm for Private\n  Averaging with Malicious Adversaries", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of personal data collected in our everyday interactions with\nconnected devices offers great opportunities for innovative services fueled by\nmachine learning, as well as raises serious concerns for the privacy of\nindividuals. In this paper, we propose a massively distributed protocol for a\nlarge set of users to privately compute averages over their joint data, which\ncan then be used to learn predictive models. Our protocol can find a solution\nof arbitrary accuracy, does not rely on a third party and preserves the privacy\nof users throughout the execution in both the honest-but-curious and malicious\nadversary models. Specifically, we prove that the information observed by the\nadversary (the set of maliciours users) does not significantly reduce the\nuncertainty in its prediction of private values compared to its prior belief.\nThe level of privacy protection depends on a quantity related to the Laplacian\nmatrix of the network graph and generally improves with the size of the graph.\nFurthermore, we design a verification procedure which offers protection against\nmalicious users joining the service with the goal of manipulating the outcome\nof the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 09:35:29 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Dellenbach", "Pierre", ""], ["Bellet", "Aur\u00e9lien", ""], ["Ramon", "Jan", ""]]}, {"id": "1803.10016", "submitter": "Matthias Treder", "authors": "Matthias S. Treder", "title": "Cross-validation in high-dimensional spaces: a lifeline for\n  least-squares models and multi-class LDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least-squares models such as linear regression and Linear Discriminant\nAnalysis (LDA) are amongst the most popular statistical learning techniques.\nHowever, since their computation time increases cubically with the number of\nfeatures, they are inefficient in high-dimensional neuroimaging datasets.\nFortunately, for k-fold cross-validation, an analytical approach has been\ndeveloped that yields the exact cross-validated predictions in least-squares\nmodels without explicitly training the model. Its computation time grows with\nthe number of test samples. Here, this approach is systematically investigated\nin the context of cross-validation and permutation testing. LDA is used\nexemplarily but results hold for all other least-squares methods. Furthermore,\na non-trivial extension to multi-class LDA is formally derived. The analytical\napproach is evaluated using complexity calculations, simulations, and\npermutation testing of an EEG/MEG dataset. Depending on the ratio between\nfeatures and samples, the analytical approach is up to 10,000x faster than the\nstandard approach (retraining the model on each training set). This allows for\na fast cross-validation of least-squares models and multi-class LDA in\nhigh-dimensional data, with obvious applications in multi-dimensional datasets,\nRepresentational Similarity Analysis, and permutation testing.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 11:20:10 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Treder", "Matthias S.", ""]]}, {"id": "1803.10045", "submitter": "Michele Scipioni", "authors": "Michele Scipioni (1 and 3), Maria F. Santarelli (2), Luigi Landini (1\n  and 2), Ciprian Catana (3 and 4), Douglas N. Greve (3 and 4), Julie C. Price\n  (3 and 4) and Stefano Pedemonte (3, 4 and 5) ((1) DII, University of Pisa,\n  (2) IFC-CNR, Pisa, (3) Martinos Center for Biomedical Imaging, Boston, (4)\n  Harvard Medical School, Boston, (5) MGH Center for Clinical Data Science,\n  Boston)", "title": "Kinetic Compressive Sensing", "comments": "5 pages, 6 figures, Submitted to the Conference Record of \"IEEE\n  Nuclear Science Symposium and Medical Imaging Conference (IEEE NSS-MIC) 2017\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric images provide insight into the spatial distribution of\nphysiological parameters, but they are often extremely noisy, due to low SNR of\ntomographic data. Direct estimation from projections allows accurate noise\nmodeling, improving the results of post-reconstruction fitting. We propose a\nmethod, which we name kinetic compressive sensing (KCS), based on a\nhierarchical Bayesian model and on a novel reconstruction algorithm, that\nencodes sparsity of kinetic parameters. Parametric maps are reconstructed by\nmaximizing the joint probability, with an Iterated Conditional Modes (ICM)\napproach, alternating the optimization of activity time series (OS-MAP-OSL),\nand kinetic parameters (MAP-LM). We evaluated the proposed algorithm on a\nsimulated dynamic phantom: a bias/variance study confirmed how direct estimates\ncan improve the quality of parametric maps over a post-reconstruction fitting,\nand showed how the novel sparsity prior can further reduce their variance,\nwithout affecting bias. Real FDG PET human brain data (Siemens mMR, 40min)\nimages were also processed. Results enforced how the proposed KCS-regularized\ndirect method can produce spatially coherent images and parametric maps, with\nlower spatial noise and better tissue contrast. A GPU-based open source\nimplementation of the algorithm is provided.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 12:46:57 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Scipioni", "Michele", "", "1 and 3"], ["Santarelli", "Maria F.", "", "1\n  and 2"], ["Landini", "Luigi", "", "1\n  and 2"], ["Catana", "Ciprian", "", "3 and 4"], ["Greve", "Douglas N.", "", "3 and 4"], ["Price", "Julie C.", "", "3 and 4"], ["Pedemonte", "Stefano", "", "3, 4 and 5"]]}, {"id": "1803.10049", "submitter": "Jack Rae", "authors": "Jack W Rae, Chris Dyer, Peter Dayan, Timothy P Lillicrap", "title": "Fast Parametric Learning with Activation Memorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks trained with backpropagation often struggle to identify\nclasses that have been observed a small number of times. In applications where\nmost class labels are rare, such as language modelling, this can become a\nperformance bottleneck. One potential remedy is to augment the network with a\nfast-learning non-parametric model which stores recent activations and class\nlabels into an external memory. We explore a simplified architecture where we\ntreat a subset of the model parameters as fast memory stores. This can help\nretain information over longer time intervals than a traditional memory, and\ndoes not require additional space or compute. In the case of image\nclassification, we display faster binding of novel classes on an Omniglot image\ncurriculum task. We also show improved performance for word-based language\nmodels on news reports (GigaWord), books (Project Gutenberg) and Wikipedia\narticles (WikiText-103) --- the latter achieving a state-of-the-art perplexity\nof 29.2.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 12:53:24 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Rae", "Jack W", ""], ["Dyer", "Chris", ""], ["Dayan", "Peter", ""], ["Lillicrap", "Timothy P", ""]]}, {"id": "1803.10082", "submitter": "Sylvestre-Alvise Rebuffi", "authors": "Sylvestre-Alvise Rebuffi, Hakan Bilen, Andrea Vedaldi", "title": "Efficient parametrization of multi-domain deep neural networks", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A practical limitation of deep neural networks is their high degree of\nspecialization to a single task and visual domain. Recently, inspired by the\nsuccesses of transfer learning, several authors have proposed to learn instead\nuniversal, fixed feature extractors that, used as the first stage of any deep\nnetwork, work well for several tasks and domains simultaneously. Nevertheless,\nsuch universal features are still somewhat inferior to specialized networks.\n  To overcome this limitation, in this paper we propose to consider instead\nuniversal parametric families of neural networks, which still contain\nspecialized problem-specific models, but differing only by a small number of\nparameters. We study different designs for such parametrizations, including\nseries and parallel residual adapters, joint adapter compression, and parameter\nallocations, and empirically identify the ones that yield the highest\ncompression. We show that, in order to maximize performance, it is necessary to\nadapt both shallow and deep layers of a deep network, but the required changes\nare very small. We also show that these universal parametrization are very\neffective for transfer learning, where they outperform traditional fine-tuning\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 13:55:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Rebuffi", "Sylvestre-Alvise", ""], ["Bilen", "Hakan", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1803.10122", "submitter": "David Ha", "authors": "David Ha and J\\\"urgen Schmidhuber", "title": "World Models", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.1207631", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore building generative neural network models of popular reinforcement\nlearning environments. Our world model can be trained quickly in an\nunsupervised manner to learn a compressed spatial and temporal representation\nof the environment. By using features extracted from the world model as inputs\nto an agent, we can train a very compact and simple policy that can solve the\nrequired task. We can even train our agent entirely inside of its own\nhallucinated dream generated by its world model, and transfer this policy back\ninto the actual environment.\n  An interactive version of this paper is available at\nhttps://worldmodels.github.io/\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:08:55 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 05:20:40 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 07:33:20 GMT"}, {"version": "v4", "created": "Wed, 9 May 2018 09:06:27 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Ha", "David", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1803.10123", "submitter": "Chen Zeno", "authors": "Chen Zeno, Itay Golan, Elad Hoffer, Daniel Soudry", "title": "Task Agnostic Continual Learning Using Online Variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is the notorious vulnerability of neural networks to\nthe change of the data distribution while learning. This phenomenon has long\nbeen considered a major obstacle for allowing the use of learning agents in\nrealistic continual learning settings. A large body of continual learning\nresearch assumes that task boundaries are known during training. However,\nresearch for scenarios in which task boundaries are unknown during training has\nbeen lacking. In this paper we present, for the first time, a method for\npreventing catastrophic forgetting (BGD) for scenarios with task boundaries\nthat are unknown during training --- task-agnostic continual learning. Code of\nour algorithm is available at https://github.com/igolan/bgd.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:11:08 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 09:03:30 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 12:21:07 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Zeno", "Chen", ""], ["Golan", "Itay", ""], ["Hoffer", "Elad", ""], ["Soudry", "Daniel", ""]]}, {"id": "1803.10161", "submitter": "Wilson Ye Chen", "authors": "Wilson Ye Chen, Lester Mackey, Jackson Gorham, Fran\\c{c}ois-Xavier\n  Briol, Chris J. Oates", "title": "Stein Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task in computational statistics and machine learning is to\napproximate a posterior distribution $p(x)$ with an empirical measure supported\non a set of representative points $\\{x_i\\}_{i=1}^n$. This paper focuses on\nmethods where the selection of points is essentially deterministic, with an\nemphasis on achieving accurate approximation when $n$ is small. To this end, we\npresent `Stein Points'. The idea is to exploit either a greedy or a conditional\ngradient method to iteratively minimise a kernel Stein discrepancy between the\nempirical measure and $p(x)$. Our empirical results demonstrate that Stein\nPoints enable accurate approximation of the posterior at modest computational\ncost. In addition, theoretical results are provided to establish convergence of\nthe method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 16:12:33 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 13:14:22 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 18:34:04 GMT"}, {"version": "v4", "created": "Tue, 19 Jun 2018 16:30:55 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Chen", "Wilson Ye", ""], ["Mackey", "Lester", ""], ["Gorham", "Jackson", ""], ["Briol", "Fran\u00e7ois-Xavier", ""], ["Oates", "Chris J.", ""]]}, {"id": "1803.10172", "submitter": "Daniele Calandriello", "authors": "Daniele Calandriello, Alessandro Lazaric and Michal Valko", "title": "Distributed Adaptive Sampling for Kernel Matrix Approximation", "comments": "Presented at AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most kernel-based methods, such as kernel or Gaussian process regression,\nkernel PCA, ICA, or $k$-means clustering, do not scale to large datasets,\nbecause constructing and storing the kernel matrix $\\mathbf{K}_n$ requires at\nleast $\\mathcal{O}(n^2)$ time and space for $n$ samples. Recent works show that\nsampling points with replacement according to their ridge leverage scores (RLS)\ngenerates small dictionaries of relevant points with strong spectral\napproximation guarantees for $\\mathbf{K}_n$. The drawback of RLS-based methods\nis that computing exact RLS requires constructing and storing the whole kernel\nmatrix. In this paper, we introduce SQUEAK, a new algorithm for kernel\napproximation based on RLS sampling that sequentially processes the dataset,\nstoring a dictionary which creates accurate kernel matrix approximations with a\nnumber of points that only depends on the effective dimension $d_{eff}(\\gamma)$\nof the dataset. Moreover since all the RLS estimations are efficiently\nperformed using only the small dictionary, SQUEAK is the first RLS sampling\nalgorithm that never constructs the whole matrix $\\mathbf{K}_n$, runs in linear\ntime $\\widetilde{\\mathcal{O}}(nd_{eff}(\\gamma)^3)$ w.r.t. $n$, and requires\nonly a single pass over the dataset. We also propose a parallel and distributed\nversion of SQUEAK that linearly scales across multiple machines, achieving\nsimilar accuracy in as little as\n$\\widetilde{\\mathcal{O}}(\\log(n)d_{eff}(\\gamma)^3)$ time.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 16:39:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Calandriello", "Daniele", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""]]}, {"id": "1803.10227", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Laura Downs, James C. Davidson", "title": "Forward-Backward Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goals for reinforcement learning problems are typically defined through\nhand-specified rewards. To design such problems, developers of learning\nalgorithms must inherently be aware of what the task goals are, yet we often\nrequire agents to discover them on their own without any supervision beyond\nthese sparse rewards. While much of the power of reinforcement learning derives\nfrom the concept that agents can learn with little guidance, this requirement\ngreatly burdens the training process. If we relax this one restriction and\nendow the agent with knowledge of the reward function, and in particular of the\ngoal, we can leverage backwards induction to accelerate training. To achieve\nthis, we propose training a model to learn to take imagined reversal steps from\nknown goal states. Rather than training an agent exclusively to determine how\nto reach a goal while moving forwards in time, our approach travels backwards\nto jointly predict how we got there. We evaluate our work in Gridworld and\nTowers of Hanoi and empirically demonstrate that it yields better performance\nthan standard DDQN.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 04:33:08 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Downs", "Laura", ""], ["Davidson", "James C.", ""]]}, {"id": "1803.10228", "submitter": "Fei Wang", "authors": "Fei Wang, Daniel Zheng, James Decker, Xilun Wu, Gr\\'egory M. Essertel,\n  and Tiark Rompf", "title": "Demystifying Differentiable Programming: Shift/Reset the Penultimate\n  Backpropagator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has seen tremendous success over the past decade in computer\nvision, machine translation, and gameplay. This success rests in crucial ways\non gradient-descent optimization and the ability to learn parameters of a\nneural network by backpropagating observed errors. However, neural network\narchitectures are growing increasingly sophisticated and diverse, which\nmotivates an emerging quest for even more general forms of differentiable\nprogramming, where arbitrary parameterized computations can be trained by\ngradient descent. In this paper, we take a fresh look at automatic\ndifferentiation (AD) techniques, and especially aim to demystify the\nreverse-mode form of AD that generalizes backpropagation in neural networks.\n  We uncover a tight connection between reverse-mode AD and delimited\ncontinuations, which permits implementing reverse-mode AD purely via operator\noverloading and without any auxiliary data structures. We further show how this\nformulation of AD can be fruitfully combined with multi-stage programming\n(staging), leading to a highly efficient implementation that combines the\nperformance benefits of deep learning frameworks based on explicit reified\ncomputation graphs (e.g., TensorFlow) with the expressiveness of pure library\napproaches (e.g., PyTorch).\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 04:43:12 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 16:28:41 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 03:09:03 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Wang", "Fei", ""], ["Zheng", "Daniel", ""], ["Decker", "James", ""], ["Wu", "Xilun", ""], ["Essertel", "Gr\u00e9gory M.", ""], ["Rompf", "Tiark", ""]]}, {"id": "1803.10231", "submitter": "Kamil Saigol", "authors": "Keuntaek Lee, Kamil Saigol, Evangelos A. Theodorou", "title": "Safe end-to-end imitation learning for model predictive control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of Bayesian networks, which provide both a mean value and\nan uncertainty estimate as output, to enhance the safety of learned control\npolicies under circumstances in which a test-time input differs significantly\nfrom the training set. Our algorithm combines reinforcement learning and\nend-to-end imitation learning to simultaneously learn a control policy as well\nas a threshold over the predictive uncertainty of the learned model, with no\nhand-tuning required. Corrective action, such as a return of control to the\nmodel predictive controller or human expert, is taken when the uncertainty\nthreshold is exceeded. We validate our method on fully-observable and\nvision-based partially-observable systems using cart-pole and autonomous\ndriving simulations using deep convolutional Bayesian neural networks. We\ndemonstrate that our method is robust to uncertainty resulting from varying\nsystem dynamics as well as from partial state observability.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:47:29 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 00:46:27 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 03:37:16 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Lee", "Keuntaek", ""], ["Saigol", "Kamil", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "1803.10232", "submitter": "Roxana Istrate Rox", "authors": "Roxana Istrate, Adelmo Cristiano Innocenza Malossi, Costas Bekas,\n  Dimitrios Nikolopoulos", "title": "Incremental Training of Deep Convolutional Neural Networks", "comments": null, "journal-ref": "http://ceur-ws.org/Vol-1998", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an incremental training method that partitions the original\nnetwork into sub-networks, which are then gradually incorporated in the running\nnetwork during the training process. To allow for a smooth dynamic growth of\nthe network, we introduce a look-ahead initialization that outperforms the\nrandom initialization. We demonstrate that our incremental approach reaches the\nreference network baseline accuracy. Additionally, it allows to identify\nsmaller partitions of the original state-of-the-art network, that deliver the\nsame final accuracy, by using only a fraction of the global number of\nparameters. This allows for a potential speedup of the training time of several\nfactors. We report training results on CIFAR-10 for ResNet and VGGNet.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 16:05:34 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Istrate", "Roxana", ""], ["Malossi", "Adelmo Cristiano Innocenza", ""], ["Bekas", "Costas", ""], ["Nikolopoulos", "Dimitrios", ""]]}, {"id": "1803.10254", "submitter": "Bryan Lim", "authors": "Bryan Lim and Mihaela van der Schaar", "title": "Disease-Atlas: Navigating Disease Trajectories with Deep Learning", "comments": "Accepted for publication in proceedings of the 3rd Machine Learning\n  for Healthcare Conference (MLHC 2018)", "journal-ref": "Proceedings of the 3rd Machine Learning for Healthcare Conference,\n  PMLR 85:137-160, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint models for longitudinal and time-to-event data are commonly used in\nlongitudinal studies to forecast disease trajectories over time. While there\nare many advantages to joint modeling, the standard forms suffer from\nlimitations that arise from a fixed model specification, and computational\ndifficulties when applied to high-dimensional datasets. In this paper, we\npropose a deep learning approach to address these limitations, enhancing\nexisting methods with the inherent flexibility and scalability of deep neural\nnetworks, while retaining the benefits of joint modeling. Using longitudinal\ndata from a real-world medical dataset, we demonstrate improvements in\nperformance and scalability, as well as robustness in the presence of\nirregularly sampled data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 18:03:02 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 19:27:13 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 17:10:33 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Lim", "Bryan", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1803.10266", "submitter": "Vitaly Feldman", "authors": "Cynthia Dwork and Vitaly Feldman", "title": "Privacy-preserving Prediction", "comments": "Accepted for presentation at Conference on Learning Theory (COLT)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring differential privacy of models learned from sensitive user data is\nan important goal that has been studied extensively in recent years. It is now\nknown that for some basic learning problems, especially those involving\nhigh-dimensional data, producing an accurate private model requires much more\ndata than learning without privacy. At the same time, in many applications it\nis not necessary to expose the model itself. Instead users may be allowed to\nquery the prediction model on their inputs only through an appropriate\ninterface. Here we formulate the problem of ensuring privacy of individual\npredictions and investigate the overheads required to achieve it in several\nstandard models of classification and regression.\n  We first describe a simple baseline approach based on training several models\non disjoint subsets of data and using standard private aggregation techniques\nto predict. We show that this approach has nearly optimal sample complexity for\n(realizable) PAC learning of any class of Boolean functions. At the same time,\nwithout strong assumptions on the data distribution, the aggregation step\nintroduces a substantial overhead. We demonstrate that this overhead can be\navoided for the well-studied class of thresholds on a line and for a number of\nstandard settings of convex regression. The analysis of our algorithm for\nlearning thresholds relies crucially on strong generalization guarantees that\nwe establish for all differentially private prediction algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 18:40:05 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 00:36:56 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Dwork", "Cynthia", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1803.10274", "submitter": "Gustavo Ch\\'avez", "authors": "Elizaveta Rebrova, Gustavo Chavez, Yang Liu, Pieter Ghysels, Xiaoye\n  Sherry Li", "title": "A Study of Clustering Techniques and Hierarchical Matrix Formats for\n  Kernel Ridge Regression", "comments": "10 pages, 8 figures", "journal-ref": "IPDPS workshops 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present memory-efficient and scalable algorithms for kernel methods used\nin machine learning. Using hierarchical matrix approximations for the kernel\nmatrix the memory requirements, the number of floating point operations, and\nthe execution time are drastically reduced compared to standard dense linear\nalgebra routines. We consider both the general $\\mathcal{H}$ matrix\nhierarchical format as well as Hierarchically Semi-Separable (HSS) matrices.\nFurthermore, we investigate the impact of several preprocessing and clustering\ntechniques on the hierarchical matrix compression. Effective clustering of the\ninput leads to a ten-fold increase in efficiency of the compression. The\nalgorithms are implemented using the STRUMPACK solver library. These results\nconfirm that --- with correct tuning of the hyperparameters --- classification\nusing kernel ridge regression with the compressed matrix does not lose\nprediction accuracy compared to the exact --- not compressed --- kernel matrix\nand that our approach can be extended to $\\mathcal{O}(1M)$ datasets, for which\ncomputation with the full kernel matrix becomes prohibitively expensive. We\npresent numerical experiments in a distributed memory environment up to 1,024\nprocessors of the NERSC's Cori supercomputer using well-known datasets to the\nmachine learning community that range from dimension 8 up to 784.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 19:04:52 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Rebrova", "Elizaveta", ""], ["Chavez", "Gustavo", ""], ["Liu", "Yang", ""], ["Ghysels", "Pieter", ""], ["Li", "Xiaoye Sherry", ""]]}, {"id": "1803.10309", "submitter": "Jia Chen", "authors": "Jia Chen, Gang Wang, Yanning Shen, Georgios B. Giannakis", "title": "Canonical Correlation Analysis of Datasets with a Common Source Graph", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": "10.1109/TSP.2018.2853130", "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis (CCA) is a powerful technique for discovering\nwhether or not hidden sources are commonly present in two (or more) datasets.\nIts well-appreciated merits include dimensionality reduction, clustering,\nclassification, feature selection, and data fusion. The standard CCA however,\ndoes not exploit the geometry of the common sources, which may be available\nfrom the given data or can be deduced from (cross-) correlations. In this\npaper, this extra information provided by the common sources generating the\ndata is encoded in a graph, and is invoked as a graph regularizer. This leads\nto a novel graph-regularized CCA approach, that is termed graph (g) CCA. The\nnovel gCCA accounts for the graph-induced knowledge of common sources, while\nminimizing the distance between the wanted canonical variables. Tailored for\ndiverse practical settings where the number of data is smaller than the data\nvector dimensions, the dual formulation of gCCA is also developed. One such\nsetting includes kernels that are incorporated to account for nonlinear data\ndependencies. The resultant graph-kernel (gk) CCA is also obtained in closed\nform. Finally, corroborating image classification tests over several real\ndatasets are presented to showcase the merits of the novel linear, dual, and\nkernel approaches relative to competing alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:36:26 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Chen", "Jia", ""], ["Wang", "Gang", ""], ["Shen", "Yanning", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1803.10311", "submitter": "Doris Xin", "authors": "Doris Xin, Litian Ma, Shuchen Song, Aditya Parameswaran", "title": "How Developers Iterate on Machine Learning Workflows -- A Survey of the\n  Applied Machine Learning Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning workflow development is anecdotally regarded to be an\niterative process of trial-and-error with humans-in-the-loop. However, we are\nnot aware of quantitative evidence corroborating this popular belief. A\nquantitative characterization of iteration can serve as a benchmark for machine\nlearning workflow development in practice, and can aid the development of\nhuman-in-the-loop machine learning systems. To this end, we conduct a\nsmall-scale survey of the applied machine learning literature from five\ndistinct application domains. We collect and distill statistics on the role of\niteration within machine learning workflow development, and report preliminary\ntrends and insights from our investigation, as a starting point towards this\nbenchmark. Based on our findings, we finally describe desiderata for effective\nand versatile human-in-the-loop machine learning systems that can cater to\nusers in diverse domains.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:38:05 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 22:16:31 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Xin", "Doris", ""], ["Ma", "Litian", ""], ["Song", "Shuchen", ""], ["Parameswaran", "Aditya", ""]]}, {"id": "1803.10342", "submitter": "Patrick Charbonneau", "authors": "Andrew E. Bruno, Patrick Charbonneau, Janet Newman, Edward H. Snell,\n  David R. So, Vincent Vanhoucke, Christopher J. Watkins, Shawn Williams, Julie\n  Wilson", "title": "Classification of crystallization outcomes using deep convolutional\n  neural networks", "comments": "11 pages, 4 figures, minor text and figure updates", "journal-ref": null, "doi": "10.1371/journal.pone.0198883", "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Machine Recognition of Crystallization Outcomes (MARCO) initiative has\nassembled roughly half a million annotated images of macromolecular\ncrystallization experiments from various sources and setups. Here,\nstate-of-the-art machine learning algorithms are trained and tested on\ndifferent parts of this data set. We find that more than 94% of the test images\ncan be correctly labeled, irrespective of their experimental origin. Because\ncrystal recognition is key to high-density screening and the systematic\nanalysis of crystallization experiments, this approach opens the door to both\nindustrial and fundamental research applications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 22:03:20 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 02:28:35 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Bruno", "Andrew E.", ""], ["Charbonneau", "Patrick", ""], ["Newman", "Janet", ""], ["Snell", "Edward H.", ""], ["So", "David R.", ""], ["Vanhoucke", "Vincent", ""], ["Watkins", "Christopher J.", ""], ["Williams", "Shawn", ""], ["Wilson", "Julie", ""]]}, {"id": "1803.10366", "submitter": "Gautam Goel", "authors": "Niangjun Chen, Gautam Goel, and Adam Wierman", "title": "Smoothed Online Convex Optimization in High Dimensions via Online\n  Balanced Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Smoothed Online Convex Optimization, a version of online convex\noptimization where the learner incurs a penalty for changing her actions\nbetween rounds. Given a $\\Omega(\\sqrt{d})$ lower bound on the competitive ratio\nof any online algorithm, where $d$ is the dimension of the action space, we ask\nunder what conditions this bound can be beaten. We introduce a novel\nalgorithmic framework for this problem, Online Balanced Descent (OBD), which\nworks by iteratively projecting the previous point onto a carefully chosen\nlevel set of the current cost function so as to balance the switching costs and\nhitting costs. We demonstrate the generality of the OBD framework by showing\nhow, with different choices of \"balance,\" OBD can improve upon state-of-the-art\nperformance guarantees for both competitive ratio and regret, in particular,\nOBD is the first algorithm to achieve a dimension-free competitive ratio, $3 +\nO(1/\\alpha)$, for locally polyhedral costs, where $\\alpha$ measures the\n\"steepness\" of the costs. We also prove bounds on the dynamic regret of OBD\nwhen the balance is performed in the dual space that are dimension-free and\nimply that OBD has sublinear static regret.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 00:39:33 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 13:14:17 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Chen", "Niangjun", ""], ["Goel", "Gautam", ""], ["Wierman", "Adam", ""]]}, {"id": "1803.10397", "submitter": "Takeshi Inagaki", "authors": "Takeshi Inagaki", "title": "Supervising Unsupervised Learning with Evolutionary Algorithm in Deep\n  Neural Network", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to control results of gradient descent unsupervised learning in a\ndeep neural network by using evolutionary algorithm is proposed. To process\ncrossover of unsupervisedly trained models, the algorithm evaluates pointwise\nfitness of individual nodes in neural network. Labeled training data is\nrandomly sampled and breeding process selects nodes by calculating degree of\ntheir consistency on different sets of sampled data. This method supervises\nunsupervised training by evolutionary process. We also introduce modified\nRestricted Boltzmann Machine which contains repulsive force among nodes in a\nneural network and it contributes to isolate network nodes each other to avoid\naccidental degeneration of nodes by evolutionary process. These new methods are\napplied to document classification problem and it results better accuracy than\na traditional fully supervised classifier implemented with linear regression\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 03:20:18 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Inagaki", "Takeshi", ""]]}, {"id": "1803.10415", "submitter": "Yuval Dagan", "authors": "Yuval Dagan and Koby Crammer", "title": "A Better Resource Allocation Algorithm with Semi-Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a sequential resource allocation problem between a fixed number of\narms. On each iteration the algorithm distributes a resource among the arms in\norder to maximize the expected success rate. Allocating more of the resource to\na given arm increases the probability that it succeeds, yet with a cut-off. We\nfollow Lattimore et al. (2014) and assume that the probability increases\nlinearly until it equals one, after which allocating more of the resource is\nwasteful. These cut-off values are fixed and unknown to the learner. We present\nan algorithm for this problem and prove a regret upper bound of $O(\\log n)$\nimproving over the best known bound of $O(\\log^2 n)$. Lower bounds we prove\nshow that our upper bound is tight. Simulations demonstrate the superiority of\nour algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 05:05:24 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Dagan", "Yuval", ""], ["Crammer", "Koby", ""]]}, {"id": "1803.10459", "submitter": "Aditya Grover", "authors": "Aditya Grover, Aaron Zweig, Stefano Ermon", "title": "Graphite: Iterative Generative Modeling of Graphs", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are a fundamental abstraction for modeling relational data. However,\ngraphs are discrete and combinatorial in nature, and learning representations\nsuitable for machine learning tasks poses statistical and computational\nchallenges. In this work, we propose Graphite, an algorithmic framework for\nunsupervised learning of representations over nodes in large graphs using deep\nlatent variable generative models. Our model parameterizes variational\nautoencoders (VAE) with graph neural networks, and uses a novel iterative graph\nrefinement strategy inspired by low-rank approximations for decoding. On a wide\nvariety of synthetic and benchmark datasets, Graphite outperforms competing\napproaches for the tasks of density estimation, link prediction, and node\nclassification. Finally, we derive a theoretical connection between message\npassing in graph neural networks and mean-field variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 08:37:25 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 08:15:20 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 06:02:17 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 07:13:30 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Grover", "Aditya", ""], ["Zweig", "Aaron", ""], ["Ermon", "Stefano", ""]]}, {"id": "1803.10520", "submitter": "Joseph Fitzsimons", "authors": "Zhikuan Zhao, Jack K. Fitzsimons, Michael A. Osborne, Stephen J.\n  Roberts and Joseph F. Fitzsimons", "title": "Quantum algorithms for training Gaussian Processes", "comments": "5 pages. Comments welcome", "journal-ref": "Phys. Rev. A 100, 012304 (2019)", "doi": "10.1103/PhysRevA.100.012304", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are important models in supervised machine learning.\nTraining in Gaussian processes refers to selecting the covariance functions and\nthe associated parameters in order to improve the outcome of predictions, the\ncore of which amounts to evaluating the logarithm of the marginal likelihood\n(LML) of a given model. LML gives a concrete measure of the quality of\nprediction that a GP model is expected to achieve. The classical computation of\nLML typically carries a polynomial time overhead with respect to the input\nsize. We propose a quantum algorithm that computes the logarithm of the\ndeterminant of a Hermitian matrix, which runs in logarithmic time for sparse\nmatrices. This is applied in conjunction with a variant of the quantum linear\nsystem algorithm that allows for logarithmic time computation of the form\n$\\mathbf{y}^TA^{-1}\\mathbf{y}$, where $\\mathbf{y}$ is a dense vector and $A$ is\nthe covariance matrix. We hence show that quantum computing can be used to\nestimate the LML of a GP with exponentially improved efficiency under certain\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 10:53:37 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Zhao", "Zhikuan", ""], ["Fitzsimons", "Jack K.", ""], ["Osborne", "Michael A.", ""], ["Roberts", "Stephen J.", ""], ["Fitzsimons", "Joseph F.", ""]]}, {"id": "1803.10535", "submitter": "Vahe Asvatourian Msc", "authors": "Vah\\'e Asvatourian, Cl\\'elia Coutzac, Nathalie Chaput, Caroline\n  Robert, Stefan Michiels, Emilie Lanoy", "title": "Estimating causal effects of time-dependent exposures on a binary\n  endpoint in a high-dimensional setting", "comments": "16 pages + 20 pages of appendices, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the intervention calculus when the DAG is absent (IDA) method was\ndeveloped to estimate lower bounds of causal effects from observational\nhigh-dimensional data. Originally it was introduced to assess the effect of\nbaseline biomarkers which do not vary over time. However, in many clinical\nsettings, measurements of biomarkers are repeated at fixed time points during\ntreatment exposure and, therefore, this method need to be extended. The purpose\nof this paper is then to extend the first step of the IDA, the Peter Clarks\n(PC)-algorithm, to a time-dependent exposure in the context of a binary\noutcome. We generalised the PC-algorithm for taking into account the\nchronological order of repeated measurements of the exposure and propose to\napply the IDA with our new version, the chronologically ordered PC-algorithm\n(COPC-algorithm). A simulation study has been performed before applying the\nmethod for estimating causal effects of time-dependent immunological biomarkers\non toxicity, death and progression in patients with metastatic melanoma. The\nsimulation study showed that the completed partially directed acyclic graphs\n(CPDAGs) obtained using COPC-algorithm were structurally closer to the true\nCPDAG than CPDAGs obtained using PC-algorithm. Also, causal effects were more\naccurate when they were estimated based on CPDAGs obtained using\nCOPC-algorithm. Moreover, CPDAGs obtained by COPC-algorithm allowed removing\nnon-chronologic arrows with a variable measured at a time t pointing to a\nvariable measured at a time t' where t'< t. Bidirected edges were less present\nin CPDAGs obtained with the COPC-algorithm, supporting the fact that there was\nless variability in causal effects estimated from these CPDAGs. The\nCOPC-algorithm provided CPDAGs that keep the chronological structure present in\nthe data, thus allowed to estimate lower bounds of the causal effect of\ntime-dependent biomarkers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 11:34:41 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 09:52:04 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Asvatourian", "Vah\u00e9", ""], ["Coutzac", "Cl\u00e9lia", ""], ["Chaput", "Nathalie", ""], ["Robert", "Caroline", ""], ["Michiels", "Stefan", ""], ["Lanoy", "Emilie", ""]]}, {"id": "1803.10554", "submitter": "Luciana Ferrer", "authors": "Luciana Ferrer and Mitchell McLaren", "title": "Joint PLDA for Simultaneous Modeling of Two Factors", "comments": "Submitted to Journal of Machine Learning Research", "journal-ref": "Journal of Machine Learning Research, January, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic linear discriminant analysis (PLDA) is a method used for\nbiometric problems like speaker or face recognition that models the variability\nof the samples using two latent variables, one that depends on the class of the\nsample and another one that is assumed independent across samples and models\nthe within-class variability. In this work, we propose a generalization of PLDA\nthat enables joint modeling of two sample-dependent factors: the class of\ninterest and a nuisance condition. The approach does not change the basic form\nof PLDA but rather modifies the training procedure to consider the dependency\nacross samples of the latent variable that models within-class variability.\nWhile the identity of the nuisance condition is needed during training, it is\nnot needed during testing since we propose a scoring procedure that\nmarginalizes over the corresponding latent variable. We show results on a\nmultilingual speaker-verification task, where the language spoken is considered\na nuisance condition. We show that the proposed joint PLDA approach leads to\nsignificant performance gains in this task for two different datasets, in\nparticular when the training data contains mostly or only monolingual speakers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 12:11:56 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Ferrer", "Luciana", ""], ["McLaren", "Mitchell", ""]]}, {"id": "1803.10560", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov, Boris Flach", "title": "Normalization of Neural Networks using Analytic Variance Propagation", "comments": null, "journal-ref": "In Proceedings of Computer Vision Winter Workshop 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of estimating statistics of hidden units in a neural\nnetwork using a method of analytic moment propagation. These statistics are\nuseful for approximate whitening of the inputs in front of saturating\nnon-linearities such as a sigmoid function. This is important for\ninitialization of training and for reducing the accumulated scale and bias\ndependencies (compensating covariate shift), which presumably eases the\nlearning. In batch normalization, which is currently a very widely applied\ntechnique, sample estimates of statistics of hidden units over a batch are\nused. The proposed estimation uses an analytic propagation of mean and variance\nof the training set through the network. The result depends on the network\nstructure and its current weights but not on the specific batch input. The\nestimates are suitable for initialization and normalization, efficient to\ncompute and independent of the batch size. The experimental verification well\nsupports these claims. However, the method does not share the generalization\nproperties of BN, to which our experiments give some additional insight.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 12:37:27 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""]]}, {"id": "1803.10586", "submitter": "Tobias Pl\\\"otz", "authors": "Tobias Pl\\\"otz, Anne S. Wannenwetsch, Stefan Roth", "title": "Stochastic Variational Inference with Gradient Linearization", "comments": "To appear at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference has experienced a recent surge in popularity owing to\nstochastic approaches, which have yielded practical tools for a wide range of\nmodel classes. A key benefit is that stochastic variational inference obviates\nthe tedious process of deriving analytical expressions for closed-form variable\nupdates. Instead, one simply needs to derive the gradient of the log-posterior,\nwhich is often much easier. Yet for certain model classes, the log-posterior\nitself is difficult to optimize using standard gradient techniques. One such\nexample are random field models, where optimization based on gradient\nlinearization has proven popular, since it speeds up convergence significantly\nand can avoid poor local optima. In this paper we propose stochastic\nvariational inference with gradient linearization (SVIGL). It is similarly\nconvenient as standard stochastic variational inference - all that is required\nis a local linearization of the energy gradient. Its benefit over stochastic\nvariational inference with conventional gradient methods is a clear improvement\nin convergence speed, while yielding comparable or even better variational\napproximations in terms of KL divergence. We demonstrate the benefits of SVIGL\nin three applications: Optical flow estimation, Poisson-Gaussian denoising, and\n3D surface reconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 13:22:57 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Pl\u00f6tz", "Tobias", ""], ["Wannenwetsch", "Anne S.", ""], ["Roth", "Stefan", ""]]}, {"id": "1803.10590", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov and Boris Flach and Michal Busta", "title": "Feed-forward Uncertainty Propagation in Belief and Neural Networks", "comments": "error corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a feed-forward inference method applicable to belief and neural\nnetworks. In a belief network, the method estimates an approximate factorized\nposterior of all hidden units given the input. In neural networks the method\npropagates uncertainty of the input through all the layers. In neural networks\nwith injected noise, the method analytically takes into account uncertainties\nresulting from this noise. Such feed-forward analytic propagation is\ndifferentiable in parameters and can be trained end-to-end. Compared to\nstandard NN, which can be viewed as propagating only the means, we propagate\nthe mean and variance. The method can be useful in all scenarios that require\nknowledge of the neuron statistics, e.g. when dealing with uncertain inputs,\nconsidering sigmoid activations as probabilities of Bernoulli units, training\nthe models regularized by injected noise (dropout) or estimating activation\nstatistics over the dataset (as needed for normalization methods). In the\nexperiments we show the possible utility of the method in all these tasks as\nwell as its current limitations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 13:26:47 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 17:02:02 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""], ["Busta", "Michal", ""]]}, {"id": "1803.10639", "submitter": "Hasan Abasi", "authors": "Hasan Abasi, Nader H. Bshouty", "title": "On Learning Graphs with Edge-Detecting Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a general graph $G=(V,E)$ using\nedge-detecting queries, where the number of vertices $|V|=n$ is given to the\nlearner. The information theoretic lower bound gives $m\\log n$ for the number\nof queries, where $m=|E|$ is the number of edges. In case the number of edges\n$m$ is also given to the learner, Angluin-Chen's Las Vegas algorithm\n\\cite{AC08} runs in $4$ rounds and detects the edges in $O(m\\log n)$ queries.\nIn the other harder case where the number of edges $m$ is unknown, their\nalgorithm runs in $5$ rounds and asks $O(m\\log n+\\sqrt{m}\\log^2 n)$ queries.\nThere have been two open problems: \\emph{(i)} can the number of queries be\nreduced to $O(m\\log n)$ in the second case, and, \\emph{(ii)} can the number of\nrounds be reduced without substantially increasing the number of queries (in\nboth cases). For the first open problem (when $m$ is unknown) we give two\nalgorithms. The first is an $O(1)$-round Las Vegas algorithm that asks $m\\log\nn+\\sqrt{m}(\\log^{[k]}n)\\log n$ queries for any constant $k$ where\n$\\log^{[k]}n=\\log \\stackrel{k}{\\cdots} \\log n$. The second is an\n$O(\\log^*n)$-round Las Vegas algorithm that asks $O(m\\log n)$ queries. This\nsolves the first open problem for any practical $n$, for example,\n$n<2^{65536}$. We also show that no deterministic algorithm can solve this\nproblem in a constant number of rounds. To solve the second problem we study\nthe case when $m$ is known. We first show that any non-adaptive Monte Carlo\nalgorithm (one-round) must ask at least $\\Omega(m^2\\log n)$ queries, and any\ntwo-round Las Vegas algorithm must ask at least $m^{4/3-o(1)}\\log n$ queries on\naverage. We then give two two-round Monte Carlo algorithms, the first asks\n$O(m^{4/3}\\log n)$ queries for any $n$ and $m$, and the second asks $O(m\\log\nn)$ queries when $n>2^m$. Finally, we give a $3$-round Monte Carlo algorithm\nthat asks $O(m\\log n)$ queries for any $n$ and $m$.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:20:17 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Abasi", "Hasan", ""], ["Bshouty", "Nader H.", ""]]}, {"id": "1803.10647", "submitter": "Martin Tak\\'a\\v{c}", "authors": "Krishnan Kumaran, Dimitri Papageorgiou, Yutong Chang, Minhan Li,\n  Martin Tak\\'a\\v{c}", "title": "Active Metric Learning for Supervised Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering and classification critically rely on distance metrics that\nprovide meaningful comparisons between data points. We present mixed-integer\noptimization approaches to find optimal distance metrics that generalize the\nMahalanobis metric extensively studied in the literature. Additionally, we\ngeneralize and improve upon leading methods by removing reliance on\npre-designated \"target neighbors,\" \"triplets,\" and \"similarity pairs.\" Another\nsalient feature of our method is its ability to enable active learning by\nrecommending precise regions to sample after an optimal metric is computed to\nimprove classification performance. This targeted acquisition can significantly\nreduce computational burden by ensuring training data completeness,\nrepresentativeness, and economy. We demonstrate classification and\ncomputational performance of the algorithms through several simple and\nintuitive examples, followed by results on real image and medical datasets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:36:37 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Kumaran", "Krishnan", ""], ["Papageorgiou", "Dimitri", ""], ["Chang", "Yutong", ""], ["Li", "Minhan", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1803.10705", "submitter": "Djordje Gligorijevic", "authors": "Jelena Stojanovic, Milos Jovanovic, Djordje Gligorijevic and Zoran\n  Obradovic", "title": "Semi-supervised learning for structured regression on partially observed\n  attributed graphs", "comments": "Proceedings of the 2015 SIAM International Conference on Data Mining\n  (SDM 2015) Vancouver, Canada, April 30 - May 02, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional probabilistic graphical models provide a powerful framework for\nstructured regression in spatio-temporal datasets with complex correlation\npatterns. However, in real-life applications a large fraction of observations\nis often missing, which can severely limit the representational power of these\nmodels. In this paper we propose a Marginalized Gaussian Conditional Random\nFields (m-GCRF) structured regression model for dealing with missing labels in\npartially observed temporal attributed graphs. This method is aimed at learning\nwith both labeled and unlabeled parts and effectively predicting future values\nin a graph. The method is even capable of learning from nodes for which the\nresponse variable is never observed in history, which poses problems for many\nstate-of-the-art models that can handle missing data. The proposed model is\ncharacterized for various missingness mechanisms on 500 synthetic graphs. The\nbenefits of the new method are also demonstrated on a challenging application\nfor predicting precipitation based on partial observations of climate variables\nin a temporal graph that spans the entire continental US. We also show that the\nmethod can be useful for optimizing the costs of data collection in climate\napplications via active reduction of the number of weather stations to\nconsider. In experiments on these real-world and synthetic datasets we show\nthat the proposed model is consistently more accurate than alternative\nsemi-supervised structured models, as well as models that either use imputation\nto deal with missing values or simply ignore them altogether.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 16:16:14 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Stojanovic", "Jelena", ""], ["Jovanovic", "Milos", ""], ["Gligorijevic", "Djordje", ""], ["Obradovic", "Zoran", ""]]}, {"id": "1803.10743", "submitter": "Taco Cohen", "authors": "Taco S. Cohen and Mario Geiger and Maurice Weiler", "title": "Intertwiners between Induced Representations (with Applications to the\n  Theory of Equivariant Neural Networks)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group equivariant and steerable convolutional neural networks (regular and\nsteerable G-CNNs) have recently emerged as a very effective model class for\nlearning from signal data such as 2D and 3D images, video, and other data where\nsymmetries are present. In geometrical terms, regular G-CNNs represent data in\nterms of scalar fields (\"feature channels\"), whereas the steerable G-CNN can\nalso use vector or tensor fields (\"capsules\") to represent data. In algebraic\nterms, the feature spaces in regular G-CNNs transform according to a regular\nrepresentation of the group G, whereas the feature spaces in Steerable G-CNNs\ntransform according to the more general induced representations of G. In order\nto make the network equivariant, each layer in a G-CNN is required to\nintertwine between the induced representations associated with its input and\noutput space.\n  In this paper we present a general mathematical framework for G-CNNs on\nhomogeneous spaces like Euclidean space or the sphere. We show, using\nelementary methods, that the layers of an equivariant network are convolutional\nif and only if the input and output feature spaces transform according to an\ninduced representation. This result, which follows from G.W. Mackey's abstract\ntheory on induced representations, establishes G-CNNs as a universal class of\nequivariant network architectures, and generalizes the important recent work of\nKondor & Trivedi on the intertwiners between regular representations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:30:26 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 09:27:16 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Cohen", "Taco S.", ""], ["Geiger", "Mario", ""], ["Weiler", "Maurice", ""]]}, {"id": "1803.10746", "submitter": "Charles Gadd", "authors": "Charles Gadd, Sara Wade, Akeel Shah, Dimitris Grammatopoulos", "title": "Pseudo-marginal Bayesian inference for supervised Gaussian process\n  latent variable models", "comments": "9 pages, 2 figures, working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian framework for inference with a supervised version of\nthe Gaussian process latent variable model. The framework overcomes the high\ncorrelations between latent variables and hyperparameters by using an unbiased\npseudo estimate for the marginal likelihood that approximately integrates over\nthe latent variables. This is used to construct a Markov Chain to explore the\nposterior of the hyperparameters. We demonstrate the procedure on simulated and\nreal examples, showing its ability to capture uncertainty and multimodality of\nthe hyperparameters and improved uncertainty quantification in predictions when\ncompared with variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:31:12 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gadd", "Charles", ""], ["Wade", "Sara", ""], ["Shah", "Akeel", ""], ["Grammatopoulos", "Dimitris", ""]]}, {"id": "1803.10760", "submitter": "Greg Wayne", "authors": "Greg Wayne, Chia-Chun Hung, David Amos, Mehdi Mirza, Arun Ahuja,\n  Agnieszka Grabska-Barwinska, Jack Rae, Piotr Mirowski, Joel Z. Leibo, Adam\n  Santoro, Mevlana Gemici, Malcolm Reynolds, Tim Harley, Josh Abramson, Shakir\n  Mohamed, Danilo Rezende, David Saxton, Adam Cain, Chloe Hillier, David\n  Silver, Koray Kavukcuoglu, Matt Botvinick, Demis Hassabis, Timothy Lillicrap", "title": "Unsupervised Predictive Memory in a Goal-Directed Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals execute goal-directed behaviours despite the limited range and scope\nof their sensors. To cope, they explore environments and store memories\nmaintaining estimates of important information that is not presently available.\nRecently, progress has been made with artificial intelligence (AI) agents that\nlearn to perform tasks from sensory input, even at a human level, by merging\nreinforcement learning (RL) algorithms with deep neural networks, and the\nexcitement surrounding these results has led to the pursuit of related ideas as\nexplanations of non-human animal learning. However, we demonstrate that\ncontemporary RL algorithms struggle to solve simple tasks when enough\ninformation is concealed from the sensors of the agent, a property called\n\"partial observability\". An obvious requirement for handling partially observed\ntasks is access to extensive memory, but we show memory is not enough; it is\ncritical that the right information be stored in the right format. We develop a\nmodel, the Memory, RL, and Inference Network (MERLIN), in which memory\nformation is guided by a process of predictive modeling. MERLIN facilitates the\nsolution of tasks in 3D virtual reality environments for which partial\nobservability is severe and memories must be maintained over long durations.\nOur model demonstrates a single learning agent architecture that can solve\ncanonical behavioural tasks in psychology and neurobiology without strong\nsimplifying assumptions about the dimensionality of sensory input or the\nduration of experiences.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:54:01 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Wayne", "Greg", ""], ["Hung", "Chia-Chun", ""], ["Amos", "David", ""], ["Mirza", "Mehdi", ""], ["Ahuja", "Arun", ""], ["Grabska-Barwinska", "Agnieszka", ""], ["Rae", "Jack", ""], ["Mirowski", "Piotr", ""], ["Leibo", "Joel Z.", ""], ["Santoro", "Adam", ""], ["Gemici", "Mevlana", ""], ["Reynolds", "Malcolm", ""], ["Harley", "Tim", ""], ["Abramson", "Josh", ""], ["Mohamed", "Shakir", ""], ["Rezende", "Danilo", ""], ["Saxton", "David", ""], ["Cain", "Adam", ""], ["Hillier", "Chloe", ""], ["Silver", "David", ""], ["Kavukcuoglu", "Koray", ""], ["Botvinick", "Matt", ""], ["Hassabis", "Demis", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1803.10768", "submitter": "Finn Macleod Dr", "authors": "Finn Macleod", "title": "Unreasonable Effectivness of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how well known rules of back propagation arise from a weighted\ncombination of finite automata. By redefining a finite automata as a predictor\nwe combine the set of all $k$-state finite automata using a weighted majority\nalgorithm. This aggregated prediction algorithm can be simplified using\nsymmetry, and we prove the equivalence of an algorithm that does this. We\ndemonstrate that this algorithm is equivalent to a form of a back propagation\nacting in a completely connected $k$-node neural network. Thus the use of the\nweighted majority algorithm allows a bound on the general performance of deep\nlearning approaches to prediction via known results from online statistics. The\npresented framework opens more detailed questions about network topology; it is\na bridge to the well studied techniques of semigroup theory and applying these\ntechniques to answer what specific network topologies are capable of\npredicting. This informs both the design of artificial networks and the\nexploration of neuroscience models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:29:30 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Macleod", "Finn", ""]]}, {"id": "1803.10799", "submitter": "Djordje Gligorijevic", "authors": "Jelena Stojanovic, Djordje Gligorijevic and Zoran Obradovic", "title": "Modeling Customer Engagement from Partial Observations", "comments": "Proceedings of the 25th ACM International Conference on Information\n  and Knowledge Management (CIKM 2016), Indianapolis, United States October 24\n  - 28, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of high interest for a company to identify customers expected to bring\nthe largest profit in the upcoming period. Knowing as much as possible about\neach customer is crucial for such predictions. However, their demographic data,\npreferences, and other information that might be useful for building loyalty\nprograms is often missing. Additionally, modeling relations among different\ncustomers as a network can be beneficial for predictions at an individual\nlevel, as similar customers tend to have similar purchasing patterns. We\naddress this problem by proposing a robust framework for structured regression\non deficient data in evolving networks with a supervised representation\nlearning based on neural features embedding. The new method is compared to\nseveral unstructured and structured alternatives for predicting customer\nbehavior (e.g. purchasing frequency and customer ticket) on user networks\ngenerated from customer databases of two companies from different industries.\nThe obtained results show $4\\%$ to $130\\%$ improvement in accuracy over\nalternatives when all customer information is known. Additionally, the\nrobustness of our method is demonstrated when up to $80\\%$ of demographic\ninformation was missing where it was up to several folds more accurate as\ncompared to alternatives that are either ignoring cases with missing values or\nlearn their feature representation in an unsupervised manner.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 18:49:07 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Stojanovic", "Jelena", ""], ["Gligorijevic", "Djordje", ""], ["Obradovic", "Zoran", ""]]}, {"id": "1803.10806", "submitter": "Louis-\\'Emile Robitaille", "authors": "Louis-\\'Emile Robitaille, Audrey Durand, Marc-Andr\\'e Gardner,\n  Christian Gagn\\'e, Paul De Koninck, Flavie Lavoie-Cardinal", "title": "Learning to Become an Expert: Deep Networks Applied To Super-Resolution\n  Microscopy", "comments": "Accepted to the Thirtieth Innovative Applications of Artificial\n  Intelligence Conference (IAAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With super-resolution optical microscopy, it is now possible to observe\nmolecular interactions in living cells. The obtained images have a very high\nspatial precision but their overall quality can vary a lot depending on the\nstructure of interest and the imaging parameters. Moreover, evaluating this\nquality is often difficult for non-expert users. In this work, we tackle the\nproblem of learning the quality function of super- resolution images from\nscores provided by experts. More specifically, we are proposing a system based\non a deep neural network that can provide a quantitative quality measure of a\nSTED image of neuronal structures given as input. We conduct a user study in\norder to evaluate the quality of the predictions of the neural network against\nthose of a human expert. Results show the potential while highlighting some of\nthe limits of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 19:01:45 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Robitaille", "Louis-\u00c9mile", ""], ["Durand", "Audrey", ""], ["Gardner", "Marc-Andr\u00e9", ""], ["Gagn\u00e9", "Christian", ""], ["De Koninck", "Paul", ""], ["Lavoie-Cardinal", "Flavie", ""]]}, {"id": "1803.10815", "submitter": "Piotr Mardziel", "authors": "Shayak Sen and Piotr Mardziel and Anupam Datta and Matthew Fredrikson", "title": "Supervising Feature Influence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal influence measures for machine learnt classifiers shed light on the\nreasons behind classification, and aid in identifying influential input\nfeatures and revealing their biases. However, such analyses involve evaluating\nthe classifier using datapoints that may be atypical of its training\ndistribution. Standard methods for training classifiers that minimize empirical\nrisk do not constrain the behavior of the classifier on such datapoints. As a\nresult, training to minimize empirical risk does not distinguish among\nclassifiers that agree on predictions in the training distribution but have\nwildly different causal influences. We term this problem covariate shift in\ncausal testing and formally characterize conditions under which it arises. As a\nsolution to this problem, we propose a novel active learning algorithm that\nconstrains the influence measures of the trained model. We prove that any two\npredictors whose errors are close on both the original training distribution\nand the distribution of atypical points are guaranteed to have causal\ninfluences that are also close. Further, we empirically demonstrate with\nsynthetic labelers that our algorithm trains models that (i) have similar\ncausal influences as the labeler's model, and (ii) generalize better to\nout-of-distribution points while (iii) retaining their accuracy on\nin-distribution points.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 19:16:39 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 23:46:15 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Sen", "Shayak", ""], ["Mardziel", "Piotr", ""], ["Datta", "Anupam", ""], ["Fredrikson", "Matthew", ""]]}, {"id": "1803.10837", "submitter": "Nikolaos Passalis", "authors": "Nikolaos Passalis and Anastasios Tefas", "title": "Learning Deep Representations with Probabilistic Knowledge Transfer", "comments": "Accepted at ECCV2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Transfer (KT) techniques tackle the problem of transferring the\nknowledge from a large and complex neural network into a smaller and faster\none. However, existing KT methods are tailored towards classification tasks and\nthey cannot be used efficiently for other representation learning tasks. In\nthis paper a novel knowledge transfer technique, that is capable of training a\nstudent model that maintains the same amount of mutual information between the\nlearned representation and a set of (possible unknown) labels as the teacher\nmodel, is proposed. Apart from outperforming existing KT techniques, the\nproposed method allows for overcoming several limitations of existing methods\nproviding new insight into KT as well as novel KT applications, ranging from\nknowledge transfer from handcrafted feature extractors to {cross-modal} KT from\nthe textual modality into the representation extracted from the visual modality\nof the data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 20:14:08 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 19:03:32 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 07:45:15 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""]]}, {"id": "1803.10840", "submitter": "Uri Shaham", "authors": "Uri Shaham, James Garritano, Yutaro Yamada, Ethan Weinberger, Alex\n  Cloninger, Xiuyuan Cheng, Kelly Stanton, Yuval Kluger", "title": "Defending against Adversarial Images using Basis Functions\n  Transformations", "comments": "added link to GitHub repository", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effectiveness of various approaches that defend against\nadversarial attacks on deep networks via manipulations based on basis function\nrepresentations of images. Specifically, we experiment with low-pass filtering,\nPCA, JPEG compression, low resolution wavelet approximation, and\nsoft-thresholding. We evaluate these defense techniques using three types of\npopular attacks in black, gray and white-box settings. Our results show JPEG\ncompression tends to outperform the other tested defenses in most of the\nsettings considered, in addition to soft-thresholding, which performs well in\nspecific cases, and yields a more mild decrease in accuracy on benign examples.\nIn addition, we also mathematically derive a novel white-box attack in which\nthe adversarial perturbation is composed only of terms corresponding a to\npre-determined subset of the basis functions, of which a \"low frequency attack\"\nis a special case.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 20:27:58 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 22:14:16 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 18:44:46 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Shaham", "Uri", ""], ["Garritano", "James", ""], ["Yamada", "Yutaro", ""], ["Weinberger", "Ethan", ""], ["Cloninger", "Alex", ""], ["Cheng", "Xiuyuan", ""], ["Stanton", "Kelly", ""], ["Kluger", "Yuval", ""]]}, {"id": "1803.10846", "submitter": "Yu Cheng", "authors": "Yu Cheng, Rong Ge", "title": "Non-Convex Matrix Completion Against a Semi-Random Adversary", "comments": "added references and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a well-studied problem with many machine learning\napplications. In practice, the problem is often solved by non-convex\noptimization algorithms. However, the current theoretical analysis for\nnon-convex algorithms relies heavily on the assumption that every entry is\nobserved with exactly the same probability $p$, which is not realistic in\npractice.\n  In this paper, we investigate a more realistic semi-random model, where the\nprobability of observing each entry is at least $p$. Even with this mild\nsemi-random perturbation, we can construct counter-examples where existing\nnon-convex algorithms get stuck in bad local optima.\n  In light of the negative results, we propose a pre-processing step that tries\nto re-weight the semi-random input, so that it becomes \"similar\" to a random\ninput. We give a nearly-linear time algorithm for this problem, and show that\nafter our pre-processing, all the local minima of the non-convex objective can\nbe used to approximately recover the underlying ground-truth matrix.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 20:46:27 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 19:11:49 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Cheng", "Yu", ""], ["Ge", "Rong", ""]]}, {"id": "1803.10884", "submitter": "Adam Gustafson", "authors": "Adam Gustafson, Matthew Hirn, Kitty Mohammed, Hariharan Narayanan, and\n  Jason Xu", "title": "Structural Risk Minimization for $C^{1,1}(\\mathbb{R}^d)$ Regression", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One means of fitting functions to high-dimensional data is by providing\nsmoothness constraints. Recently, the following smooth function approximation\nproblem was proposed: given a finite set $E \\subset \\mathbb{R}^d$ and a\nfunction $f: E \\rightarrow \\mathbb{R}$, interpolate the given information with\na function $\\widehat{f} \\in \\dot{C}^{1, 1}(\\mathbb{R}^d)$ (the class of\nfirst-order differentiable functions with Lipschitz gradients) such that\n$\\widehat{f}(a) = f(a)$ for all $a \\in E$, and the value of\n$\\mathrm{Lip}(\\nabla \\widehat{f})$ is minimal. An algorithm is provided that\nconstructs such an approximating function $\\widehat{f}$ and estimates the\noptimal Lipschitz constant $\\mathrm{Lip}(\\nabla \\widehat{f})$ in the noiseless\nsetting.\n  We address statistical aspects of reconstructing the approximating function\n$\\widehat{f}$ from a closely-related class $C^{1, 1}(\\mathbb{R}^d)$ given\nsamples from noisy data. We observe independent and identically distributed\nsamples $y(a) = f(a) + \\xi(a)$ for $a \\in E$, where $\\xi(a)$ is a noise term\nand the set $E \\subset \\mathbb{R}^d$ is fixed and known. We obtain uniform\nbounds relating the empirical risk and true risk over the class\n$\\mathcal{F}_{\\widetilde{M}} = \\{f \\in C^{1, 1}(\\mathbb{R}^d) \\mid\n\\mathrm{Lip}(\\nabla f) \\leq \\widetilde{M}\\}$, where the quantity\n$\\widetilde{M}$ grows with the number of samples at a rate governed by the\nmetric entropy of the class $C^{1, 1}(\\mathbb{R}^d)$. Finally, we provide an\nimplementation using Vaidya's algorithm, supporting our results via numerical\nexperiments on simulated data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 00:19:45 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 00:49:35 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Gustafson", "Adam", ""], ["Hirn", "Matthew", ""], ["Mohammed", "Kitty", ""], ["Narayanan", "Hariharan", ""], ["Xu", "Jason", ""]]}, {"id": "1803.10888", "submitter": "Kostas Hatalis", "authors": "Kostas Hatalis, Shalinee Kishore, Katya Scheinberg, Alberto Lamadrid", "title": "An Empirical Analysis of Constrained Support Vector Quantile Regression\n  for Nonparametric Probabilistic Forecasting of Wind Power", "comments": "Originally published at The AAAI-17 Workshop on Artificial\n  Intelligence for Smart Grids and Smart Buildings", "journal-ref": "Thirty-First AAAI Conference on Artificial Intelligence, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty analysis in the form of probabilistic forecasting can provide\nsignificant improvements in decision-making processes in the smart power grid\nfor better integrating renewable energies such as wind. Whereas point\nforecasting provides a single expected value, probabilistic forecasts provide\nmore information in the form of quantiles, prediction intervals, or full\npredictive densities. This paper analyzes the effectiveness of an approach for\nnonparametric probabilistic forecasting of wind power that combines support\nvector machines and nonlinear quantile regression with non-crossing\nconstraints. A numerical case study is conducted using publicly available wind\ndata from the Global Energy Forecasting Competition 2014. Multiple quantiles\nare estimated to form 20%, 40%, 60% and 80% prediction intervals which are\nevaluated using the pinball loss function and reliability measures. Three\nbenchmark models are used for comparison where results demonstrate the proposed\napproach leads to significantly better performance while preventing the problem\nof overlapping quantile estimates.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 01:05:54 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Hatalis", "Kostas", ""], ["Kishore", "Shalinee", ""], ["Scheinberg", "Katya", ""], ["Lamadrid", "Alberto", ""]]}, {"id": "1803.10927", "submitter": "Amir Hossein Akhavan Rahnama", "authors": "Amir Hossein Akhavan Rahnama, Mehdi Toloo, Nezer Jacob Zaidenberg", "title": "An LP-based hyperparameter optimization model for language modeling", "comments": null, "journal-ref": "The Journal of Supercomputing (2018)", "doi": "10.1007/s11227-018-2236-6", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to find hyperparameters for a machine learning model, algorithms\nsuch as grid search or random search are used over the space of possible values\nof the models hyperparameters. These search algorithms opt the solution that\nminimizes a specific cost function. In language models, perplexity is one of\nthe most popular cost functions. In this study, we propose a fractional\nnonlinear programming model that finds the optimal perplexity value. The\nspecial structure of the model allows us to approximate it by a linear\nprogramming model that can be solved using the well-known simplex algorithm. To\nthe best of our knowledge, this is the first attempt to use optimization\ntechniques to find perplexity values in the language modeling literature. We\napply our model to find hyperparameters of a language model and compare it to\nthe grid search algorithm. Furthermore, we illustrating that it results in\nlower perplexity values. We perform this experiment on a real-world dataset\nfrom SwiftKey to validate our proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 05:15:36 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Rahnama", "Amir Hossein Akhavan", ""], ["Toloo", "Mehdi", ""], ["Zaidenberg", "Nezer Jacob", ""]]}, {"id": "1803.10937", "submitter": "Aditya Grover", "authors": "Aditya Grover, Todor Markov, Peter Attia, Norman Jin, Nicholas\n  Perkins, Bryan Cheong, Michael Chen, Zi Yang, Stephen Harris, William Chueh,\n  Stefano Ermon", "title": "Best arm identification in multi-armed bandits with delayed feedback", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalization of the best arm identification problem in\nstochastic multi-armed bandits (MAB) to the setting where every pull of an arm\nis associated with delayed feedback. The delay in feedback increases the\neffective sample complexity of standard algorithms, but can be offset if we\nhave access to partial feedback received before a pull is completed. We propose\na general framework to model the relationship between partial and delayed\nfeedback, and as a special case we introduce efficient algorithms for settings\nwhere the partial feedback are biased or unbiased estimators of the delayed\nfeedback. Additionally, we propose a novel extension of the algorithms to the\nparallel MAB setting where an agent can control a batch of arms. Our\nexperiments in real-world settings, involving policy search and hyperparameter\noptimization in computational sustainability domains for fast charging of\nbatteries and wildlife corridor construction, demonstrate that exploiting the\nstructure of partial feedback can lead to significant improvements over\nbaselines in both sequential and parallel MAB.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 06:46:38 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Grover", "Aditya", ""], ["Markov", "Todor", ""], ["Attia", "Peter", ""], ["Jin", "Norman", ""], ["Perkins", "Nicholas", ""], ["Cheong", "Bryan", ""], ["Chen", "Michael", ""], ["Yang", "Zi", ""], ["Harris", "Stephen", ""], ["Chueh", "William", ""], ["Ermon", "Stefano", ""]]}, {"id": "1803.10986", "submitter": "Barbara Barabasz", "authors": "Barbara Barabasz, Andrew Anderson, Kirk M. Soodhalter and David Gregg", "title": "Error Analysis and Improving the Accuracy of Winograd Convolution for\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular deep neural networks (DNNs) spend the majority of their execution\ntime computing convolutions. The Winograd family of algorithms can greatly\nreduce the number of arithmetic operations required and is present in many DNN\nsoftware frameworks. However, the performance gain is at the expense of a\nreduction in floating point (FP) numerical accuracy. In this paper, we analyse\nthe worst case FP error and prove the estimation of norm and conditioning of\nthe algorithm. We show that the bound grows exponentially with the size of the\nconvolution, but the error bound of the \\textit{modified} algorithm is smaller\nthan the original one. We propose several methods for reducing FP error. We\npropose a canonical evaluation ordering based on Huffman coding that reduces\nsummation error. We study the selection of sampling \"points\" experimentally and\nfind empirically good points for the most important sizes. We identify the main\nfactors associated with good points. In addition, we explore other methods to\nreduce FP error, including mixed-precision convolution, and pairwise summation\nacross DNN channels. Using our methods we can significantly reduce FP error for\na given block size, which allows larger block sizes and reduced computation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 09:48:02 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 17:32:05 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 19:38:11 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Barabasz", "Barbara", ""], ["Anderson", "Andrew", ""], ["Soodhalter", "Kirk M.", ""], ["Gregg", "David", ""]]}, {"id": "1803.10995", "submitter": "Richard Kenway", "authors": "Richard Kenway", "title": "Protection against Cloning for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The susceptibility of deep learning to adversarial attack can be understood\nin the framework of the Renormalisation Group (RG) and the vulnerability of a\nspecific network may be diagnosed provided the weights in each layer are known.\nAn adversary with access to the inputs and outputs could train a second network\nto clone these weights and, having identified a weakness, use them to compute\nthe perturbation of the input data which exploits it. However, the RG framework\nalso provides a means to poison the outputs of the network imperceptibly,\nwithout affecting their legitimate use, so as to prevent such cloning of its\nweights and thereby foil the generation of adversarial data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:02:09 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Kenway", "Richard", ""]]}, {"id": "1803.10996", "submitter": "Hyeongki Kim", "authors": "Hyeongki Kim", "title": "Dihedral angle prediction using generative adversarial networks", "comments": "72 pages, MSc thesis under the supervision of Assoc. Prof. Thomas\n  Hamelryck and Asst. Prof. Wouter Boomsma", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several dihedral angles prediction methods were developed for protein\nstructure prediction and their other applications. However, distribution of\npredicted angles would not be similar to that of real angles. To address this\nwe employed generative adversarial networks (GAN). Generative adversarial\nnetworks are composed of two adversarially trained networks: a discriminator\nand a generator. A discriminator distinguishes samples from a dataset and\ngenerated samples while a generator generates realistic samples. Although the\ndiscriminator of GANs is trained to estimate density, GAN model is intractable.\nOn the other hand, noise-contrastive estimation (NCE) was introduced to\nestimate a normalization constant of an unnormalized statistical model and thus\nthe density function. In this thesis, we introduce noise-contrastive estimation\ngenerative adversarial networks (NCE-GAN) which enables explicit density\nestimation of a GAN model. And a new loss for the generator is proposed. We\nalso propose residue-wise variants of auxiliary classifier GAN (AC-GAN) and\nSemi-supervised GAN to handle sequence information in a window. In our\nexperiment, the conditional generative adversarial network (C-GAN), AC-GAN and\nSemi-supervised GAN were compared. And experiments done with improved\nconditions were invested. We identified a phenomenon of AC-GAN that\ndistribution of its predicted angles is composed of unusual clusters. The\ndistribution of the predicted angles of Semi-supervised GAN was most similar to\nthe Ramachandran plot. We found that adding the output of the NCE as an\nadditional input of the discriminator is helpful to stabilize the training of\nthe GANs and to capture the detailed structures. Adding regression loss and\nusing predicted angles by regression loss only model could improve the\nconditional generation performance of the C-GAN and AC-GAN.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:02:14 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Kim", "Hyeongki", ""]]}, {"id": "1803.10998", "submitter": "Viet Hung Tran", "authors": "Viet Hung Tran", "title": "Copula Variational Bayes inference via information geometry", "comments": "IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayes (VB), also known as independent mean-field approximation,\nhas become a popular method for Bayesian network inference in recent years. Its\napplication is vast, e.g. in neural network, compressed sensing, clustering,\netc. to name just a few. In this paper, the independence constraint in VB will\nbe relaxed to a conditional constraint class, called copula in statistics.\nSince a joint probability distribution always belongs to a copula class, the\nnovel copula VB (CVB) approximation is a generalized form of VB. Via\ninformation geometry, we will see that CVB algorithm iteratively projects the\noriginal joint distribution to a copula constraint space until it reaches a\nlocal minimum Kullback-Leibler (KL) divergence. By this way, all mean-field\napproximations, e.g. iterative VB, Expectation-Maximization (EM), Iterated\nConditional Mode (ICM) and k-means algorithms, are special cases of CVB\napproximation.\n  For a generic Bayesian network, an augmented hierarchy form of CVB will also\nbe designed. While mean-field algorithms can only return a locally optimal\napproximation for a correlated network, the augmented CVB network, which is an\noptimally weighted average of a mixture of simpler network structures, can\npotentially achieve the globally optimal approximation for the first time. Via\nsimulations of Gaussian mixture clustering, the classification's accuracy of\nCVB will be shown to be far superior to that of state-of-the-art VB, EM and\nk-means algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:10:35 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Tran", "Viet Hung", ""]]}, {"id": "1803.11002", "submitter": "Mehdi Ghatee Dr.", "authors": "Sima Sharifirad and Azra Nazari and Mehdi Ghatee", "title": "Modified SMOTE Using Mutual Information and Different Sorts of Entropies", "comments": "10 Pages, 4 Tables, 8 Figures, Extracted from an MSc project with\n  Department of Computer Science, Amirkabir University of Technology, Tehran,\n  Iran", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SMOTE is one of the oversampling techniques for balancing the datasets and it\nis considered as a pre-processing step in learning algorithms. In this paper,\nfour new enhanced SMOTE are proposed that include an improved version of KNN in\nwhich the attribute weights are defined by mutual information firstly and then\nthey are replaced by maximum entropy, Renyi entropy and Tsallis entropy. These\nfour pre-processing methods are combined with 1NN and J48 classifiers and their\nperformance are compared with the previous methods on 11 imbalanced datasets\nfrom KEEL repository. The results show that these pre-processing methods\nimproves the accuracy compared with the previous stablished works. In addition,\nas a case study, the first pre-processing method is applied on transportation\ndata of Tehran-Bazargan Highway in Iran with IR equal to 36.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:41:19 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Sharifirad", "Sima", ""], ["Nazari", "Azra", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "1803.11008", "submitter": "Mattes Mollenhauer", "authors": "Luzie Helfmann, Johannes von Lindheim, Mattes Mollenhauer, Ralf\n  Banisch", "title": "On Hyperparameter Search in Cluster Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quality assessments of models in unsupervised learning and clustering\nverification in particular have been a long-standing problem in the machine\nlearning research. The lack of robust and universally applicable cluster\nvalidity scores often makes the algorithm selection and hyperparameter\nevaluation a tough guess. In this paper, we show that cluster ensemble\naggregation techniques such as consensus clustering may be used to evaluate\nclusterings and their hyperparameter configurations. We use normalized mutual\ninformation to compare individual objects of a clustering ensemble to the\nconstructed consensus of the whole ensemble and show, that the resulting score\ncan serve as an overall quality measure for clustering problems. This method is\ncapable of highlighting the standout clustering and hyperparameter\nconfiguration in the ensemble even in the case of a distorted consensus. We\napply this very general framework to various data sets and give possible\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 11:11:10 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Helfmann", "Luzie", ""], ["von Lindheim", "Johannes", ""], ["Mollenhauer", "Mattes", ""], ["Banisch", "Ralf", ""]]}, {"id": "1803.11060", "submitter": "Toon Van Craenendonck", "authors": "Toon Van Craenendonck, Sebastijan Duman\\v{c}i\\'c, Elia Van Wolputte\n  and Hendrik Blockeel", "title": "COBRAS: Fast, Iterative, Active Clustering with Pairwise Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based clustering algorithms exploit background knowledge to\nconstruct clusterings that are aligned with the interests of a particular user.\nThis background knowledge is often obtained by allowing the clustering system\nto pose pairwise queries to the user: should these two elements be in the same\ncluster or not? Active clustering methods aim to minimize the number of queries\nneeded to obtain a good clustering by querying the most informative pairs\nfirst. Ideally, a user should be able to answer a couple of these queries,\ninspect the resulting clustering, and repeat these two steps until a\nsatisfactory result is obtained. We present COBRAS, an approach to active\nclustering with pairwise constraints that is suited for such an interactive\nclustering process. A core concept in COBRAS is that of a super-instance: a\nlocal region in the data in which all instances are assumed to belong to the\nsame cluster. COBRAS constructs such super-instances in a top-down manner to\nproduce high-quality results early on in the clustering process, and keeps\nrefining these super-instances as more pairwise queries are given to get more\ndetailed clusterings later on. We experimentally demonstrate that COBRAS\nproduces good clusterings at fast run times, making it an excellent candidate\nfor the iterative clustering scenario outlined above.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 13:52:59 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Van Craenendonck", "Toon", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Van Wolputte", "Elia", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1803.11115", "submitter": "Xiaoyuan Liang", "authors": "Xiaoyuan Liang, Xunsheng Du, Guiling Wang, Zhu Han", "title": "Deep Reinforcement Learning for Traffic Light Control in Vehicular\n  Networks", "comments": null, "journal-ref": "IEEE Transactions on Vehicular Technology ( Volume: 68 , Issue: 2\n  , Feb. 2019 )", "doi": "10.1109/TVT.2018.2890726", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing inefficient traffic light control causes numerous problems, such as\nlong delay and waste of energy. To improve efficiency, taking real-time traffic\ninformation as an input and dynamically adjusting the traffic light duration\naccordingly is a must. In terms of how to dynamically adjust traffic signals'\nduration, existing works either split the traffic signal into equal duration or\nextract limited traffic information from the real data. In this paper, we study\nhow to decide the traffic signals' duration based on the collected data from\ndifferent sensors and vehicular networks. We propose a deep reinforcement\nlearning model to control the traffic light. In the model, we quantify the\ncomplex traffic scenario as states by collecting data and dividing the whole\nintersection into small grids. The timing changes of a traffic light are the\nactions, which are modeled as a high-dimension Markov decision process. The\nreward is the cumulative waiting time difference between two cycles. To solve\nthe model, a convolutional neural network is employed to map the states to\nrewards. The proposed model is composed of several components to improve the\nperformance, such as dueling network, target network, double Q-learning\nnetwork, and prioritized experience replay. We evaluate our model via\nsimulation in the Simulation of Urban MObility (SUMO) in a vehicular network,\nand the simulation results show the efficiency of our model in controlling\ntraffic lights.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 15:24:28 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Liang", "Xiaoyuan", ""], ["Du", "Xunsheng", ""], ["Wang", "Guiling", ""], ["Han", "Zhu", ""]]}, {"id": "1803.11132", "submitter": "Alexander Wein", "authors": "Afonso S. Bandeira, Amelia Perry, Alexander S. Wein", "title": "Notes on computational-to-statistical gaps: predictions using\n  statistical physics", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In these notes we describe heuristics to predict computational-to-statistical\ngaps in certain statistical problems. These are regimes in which the underlying\nstatistical problem is information-theoretically possible although no efficient\nalgorithm exists, rendering the problem essentially unsolvable for large\ninstances. The methods we describe here are based on mature, albeit\nnon-rigorous, tools from statistical physics.\n  These notes are based on a lecture series given by the authors at the Courant\nInstitute of Mathematical Sciences in New York City, on May 16th, 2017.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 16:10:04 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 04:10:11 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Bandeira", "Afonso S.", ""], ["Perry", "Amelia", ""], ["Wein", "Alexander S.", ""]]}, {"id": "1803.11136", "submitter": "Niharika Gauraha", "authors": "Niharika Gauraha, Lars Carlsson and Ola Spjuth", "title": "Conformal Prediction in Learning Under Privileged Information Paradigm\n  with Applications in Drug Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores conformal prediction in the learning under privileged\ninformation (LUPI) paradigm. We use the SVM+ realization of LUPI in an\ninductive conformal predictor, and apply it to the MNIST benchmark dataset and\nthree datasets in drug discovery. The results show that using privileged\ninformation produces valid models and improves efficiency compared to standard\nSVM, however the improvement varies between the tested datasets and is not\nsubstantial in the drug discovery applications. More importantly, using SVM+ in\na conformal prediction framework enables valid prediction intervals at\nspecified significance levels.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 16:21:10 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 10:38:12 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Gauraha", "Niharika", ""], ["Carlsson", "Lars", ""], ["Spjuth", "Ola", ""]]}, {"id": "1803.11157", "submitter": "Pengpeng Yang", "authors": "Wei Zhao and Pengpeng Yang and Rongrong Ni and Yao Zhao and Haorui Wu", "title": "Security Consideration For Deep Learning-Based Image Forensics", "comments": null, "journal-ref": null, "doi": "10.1587/transinf.2018EDL8091", "report-no": null, "categories": "cs.CV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, image forensics community has paied attention to the research on\nthe design of effective algorithms based on deep learning technology and facts\nproved that combining the domain knowledge of image forensics and deep learning\nwould achieve more robust and better performance than the traditional schemes.\nInstead of improving it, in this paper, the safety of deep learning based\nmethods in the field of image forensics is taken into account. To the best of\nour knowledge, this is a first work focusing on this topic. Specifically, we\nexperimentally find that the method using deep learning would fail when adding\nthe slight noise into the images (adversarial images). Furthermore, two kinds\nof strategys are proposed to enforce security of deep learning-based method.\nFirstly, an extra penalty term to the loss function is added, which is referred\nto the 2-norm of the gradient of the loss with respect to the input images, and\nthen an novel training method are adopt to train the model by fusing the normal\nand adversarial images. Experimental results show that the proposed algorithm\ncan achieve good performance even in the case of adversarial images and provide\na safety consideration for deep learning-based image forensics\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 17:06:00 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 09:54:20 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Zhao", "Wei", ""], ["Yang", "Pengpeng", ""], ["Ni", "Rongrong", ""], ["Zhao", "Yao", ""], ["Wu", "Haorui", ""]]}, {"id": "1803.11159", "submitter": "Zhize Li", "authors": "Zhize Li, Tianyi Zhang, Shuyu Cheng, Jun Zhu, Jian Li", "title": "Stochastic Gradient Hamiltonian Monte Carlo with Variance Reduction for\n  Bayesian Inference", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based Monte Carlo sampling algorithms, like Langevin dynamics and\nHamiltonian Monte Carlo, are important methods for Bayesian inference. In\nlarge-scale settings, full-gradients are not affordable and thus stochastic\ngradients evaluated on mini-batches are used as a replacement. In order to\nreduce the high variance of noisy stochastic gradients, Dubey et al. [2016]\napplied the standard variance reduction technique on stochastic gradient\nLangevin dynamics and obtained both theoretical and experimental improvements.\nIn this paper, we apply the variance reduction tricks on Hamiltonian Monte\nCarlo and achieve better theoretical convergence results compared with the\nvariance-reduced Langevin dynamics. Moreover, we apply the symmetric splitting\nscheme in our variance-reduced Hamiltonian Monte Carlo algorithms to further\nimprove the theoretical results. The experimental results are also consistent\nwith the theoretical results. As our experiment shows, variance-reduced\nHamiltonian Monte Carlo demonstrates better performance than variance-reduced\nLangevin dynamics in Bayesian regression and classification tasks on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 17:06:26 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 19:03:50 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 18:47:35 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Li", "Zhize", ""], ["Zhang", "Tianyi", ""], ["Cheng", "Shuyu", ""], ["Zhu", "Jun", ""], ["Li", "Jian", ""]]}, {"id": "1803.11261", "submitter": "Kush Varshney", "authors": "Kush R. Varshney", "title": "How an Electrical Engineer Became an Artificial Intelligence Researcher,\n  a Multiphase Active Contours Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This essay examines how what is considered to be artificial intelligence (AI)\nhas changed over time and come to intersect with the expertise of the author.\nInitially, AI developed on a separate trajectory, both topically and\ninstitutionally, from pattern recognition, neural information processing,\ndecision and control systems, and allied topics by focusing on symbolic systems\nwithin computer science departments rather than on continuous systems in\nelectrical engineering departments. The separate evolutions continued\nthroughout the author's lifetime, with some crossover in reinforcement learning\nand graphical models, but were shocked into converging by the virality of deep\nlearning, thus making an electrical engineer into an AI researcher. Now that\nthis convergence has happened, opportunity exists to pursue an agenda that\ncombines learning and reasoning bridged by interpretable machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 21:11:32 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Varshney", "Kush R.", ""]]}, {"id": "1803.11262", "submitter": "Dmitrii Ostrovskii", "authors": "Dmitrii Ostrovskii, Zaid Harchaoui", "title": "Efficient First-Order Algorithms for Adaptive Signal Denoising", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of discrete-time signal denoising, focusing on a\nspecific family of non-linear convolution-type estimators. Each such estimator\nis associated with a time-invariant filter which is obtained adaptively, by\nsolving a certain convex optimization problem. Adaptive convolution-type\nestimators were demonstrated to have favorable statistical properties. However,\nthe question of their computational complexity remains largely unexplored, and\nin fact we are not aware of any publicly available implementation of these\nestimators. Our first contribution is an efficient implementation of these\nestimators via some known first-order proximal algorithms. Our second\ncontribution is a computational complexity analysis of the proposed procedures,\nwhich takes into account their statistical nature and the related notion of\nstatistical accuracy. The proposed procedures and their analysis are\nillustrated on a simulated data benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 21:11:48 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 14:42:58 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 13:48:40 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Ostrovskii", "Dmitrii", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "1803.11266", "submitter": "Patrick Schratz", "authors": "Patrick Schratz, Jannes Muenchow, Eugenia Iturritxa, Jakob Richter,\n  Alexander Brenning", "title": "Performance evaluation and hyperparameter tuning of statistical and\n  machine-learning models using spatial data", "comments": null, "journal-ref": "Ecological Modelling Volume 406, 24 August 2019, Pages 109-120", "doi": "10.1016/j.ecolmodel.2019.06.002", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine-learning algorithms have gained popularity in recent years in the\nfield of ecological modeling due to their promising results in predictive\nperformance of classification problems. While the application of such\nalgorithms has been highly simplified in the last years due to their\nwell-documented integration in commonly used statistical programming languages\nsuch as R, there are several practical challenges in the field of ecological\nmodeling related to unbiased performance estimation, optimization of algorithms\nusing hyperparameter tuning and spatial autocorrelation. We address these\nissues in the comparison of several widely used machine-learning algorithms\nsuch as Boosted Regression Trees (BRT), k-Nearest Neighbor (WKNN), Random\nForest (RF) and Support Vector Machine (SVM) to traditional parametric\nalgorithms such as logistic regression (GLM) and semi-parametric ones like\ngeneralized additive models (GAM). Different nested cross-validation methods\nincluding hyperparameter tuning methods are used to evaluate model performances\nwith the aim to receive bias-reduced performance estimates. As a case study the\nspatial distribution of forest disease Diplodia sapinea in the Basque Country\nin Spain is investigated using common environmental variables such as\ntemperature, precipitation, soil or lithology as predictors. Results show that\nGAM and RF (mean AUROC estimates 0.708 and 0.699) outperform all other methods\nin predictive accuracy. The effect of hyperparameter tuning saturates at around\n50 iterations for this data set. The AUROC differences between the bias-reduced\n(spatial cross-validation) and overoptimistic (non-spatial cross-validation)\nperformance estimates of the GAM and RF are 0.167 (24%) and 0.213 (30%),\nrespectively. It is recommended to also use spatial partitioning for\ncross-validation hyperparameter tuning of spatial data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 21:48:11 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Schratz", "Patrick", ""], ["Muenchow", "Jannes", ""], ["Iturritxa", "Eugenia", ""], ["Richter", "Jakob", ""], ["Brenning", "Alexander", ""]]}, {"id": "1803.11274", "submitter": "Matteo Manica", "authors": "Matteo Manica, Joris Cadow, Roland Mathis and Mar\\'ia Rodr\\'iguez\n  Mart\\'inez", "title": "PIMKL: Pathway Induced Multiple Kernel Learning", "comments": null, "journal-ref": "npj Systems Biology and Applications (2019)", "doi": "10.1038/s41540-019-0086-3", "report-no": null, "categories": "q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable identification of molecular biomarkers is essential for accurate\npatient stratification. While state-of-the-art machine learning approaches for\nsample classification continue to push boundaries in terms of performance, most\nof these methods are not able to integrate different data types and lack\ngeneralization power, limiting their application in a clinical setting.\nFurthermore, many methods behave as black boxes, and we have very little\nunderstanding about the mechanisms that lead to the prediction. While\nopaqueness concerning machine behaviour might not be a problem in deterministic\ndomains, in health care, providing explanations about the molecular factors and\nphenotypes that are driving the classification is crucial to build trust in the\nperformance of the predictive system. We propose Pathway Induced Multiple\nKernel Learning (PIMKL), a novel methodology to reliably classify samples that\ncan also help gain insights into the molecular mechanisms that underlie the\nclassification. PIMKL exploits prior knowledge in the form of a molecular\ninteraction network and annotated gene sets, by optimizing a mixture of\npathway-induced kernels using a Multiple Kernel Learning (MKL) algorithm, an\napproach that has demonstrated excellent performance in different machine\nlearning applications. After optimizing the combination of kernels for\nprediction of a specific phenotype, the model provides a stable molecular\nsignature that can be interpreted in the light of the ingested prior knowledge\nand that can be used in transfer learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 22:28:51 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 13:20:51 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 14:29:15 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Manica", "Matteo", ""], ["Cadow", "Joris", ""], ["Mathis", "Roland", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""]]}, {"id": "1803.11287", "submitter": "Biyi Fang", "authors": "Biyi Fang and Diego Klabjan", "title": "A Stochastic Large-scale Machine Learning Algorithm for Distributed\n  Features and Observations", "comments": "11 figures, 41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size of modern data sets exceeds the disk and memory capacities of a\nsingle computer, machine learning practitioners have resorted to parallel and\ndistributed computing. Given that optimization is one of the pillars of machine\nlearning and predictive modeling, distributed optimization methods have\nrecently garnered ample attention, in particular when either observations or\nfeatures are distributed, but not both. We propose a general stochastic\nalgorithm where observations, features, and gradient components can be sampled\nin a double distributed setting, i.e., with both features and observations\ndistributed. Very technical analyses establish convergence properties of the\nalgorithm under different conditions on the learning rate (diminishing to zero\nor constant). Computational experiments in Spark demonstrate a superior\nperformance of our algorithm versus a benchmark in early iterations of the\nalgorithm, which is due to the stochastic components of the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 23:26:00 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 21:20:24 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Fang", "Biyi", ""], ["Klabjan", "Diego", ""]]}, {"id": "1803.11347", "submitter": "Anusha Nagabandi", "authors": "Anusha Nagabandi, Ignasi Clavera, Simin Liu, Ronald S. Fearing, Pieter\n  Abbeel, Sergey Levine, Chelsea Finn", "title": "Learning to Adapt in Dynamic, Real-World Environments Through\n  Meta-Reinforcement Learning", "comments": "First 2 authors contributed equally. Website:\n  https://sites.google.com/berkeley.edu/metaadaptivecontrol", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although reinforcement learning methods can achieve impressive results in\nsimulation, the real world presents two major challenges: generating samples is\nexceedingly expensive, and unexpected perturbations or unseen situations cause\nproficient but specialized policies to fail at test time. Given that it is\nimpractical to train separate policies to accommodate all situations the agent\nmay see in the real world, this work proposes to learn how to quickly and\neffectively adapt online to new tasks. To enable sample-efficient learning, we\nconsider learning online adaptation in the context of model-based reinforcement\nlearning. Our approach uses meta-learning to train a dynamics model prior such\nthat, when combined with recent data, this prior can be rapidly adapted to the\nlocal context. Our experiments demonstrate online adaptation for continuous\ncontrol tasks on both simulated and real-world agents. We first show simulated\nagents adapting their behavior online to novel terrains, crippled body parts,\nand highly-dynamic environments. We also illustrate the importance of\nincorporating online adaptation into autonomous agents that operate in the real\nworld by applying our method to a real dynamic legged millirobot. We\ndemonstrate the agent's learned ability to quickly adapt online to a missing\nleg, adjust to novel terrains and slopes, account for miscalibration or errors\nin pose estimation, and compensate for pulling payloads.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 05:47:11 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 07:57:30 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 23:44:09 GMT"}, {"version": "v4", "created": "Thu, 6 Dec 2018 20:26:09 GMT"}, {"version": "v5", "created": "Tue, 18 Dec 2018 21:55:30 GMT"}, {"version": "v6", "created": "Wed, 27 Feb 2019 19:23:41 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Nagabandi", "Anusha", ""], ["Clavera", "Ignasi", ""], ["Liu", "Simin", ""], ["Fearing", "Ronald S.", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1803.11364", "submitter": "Daiki Tanaka", "authors": "Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, Kiyoharu Aizawa", "title": "Joint Optimization Framework for Learning with Noisy Labels", "comments": "To appear at CVPR 2018 (poster), including supplementary material", "journal-ref": "CVPR 2018, pp.5552--5550", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) trained on large-scale datasets have exhibited\nsignificant performance in image classification. Many large-scale datasets are\ncollected from websites, however they tend to contain inaccurate labels that\nare termed as noisy labels. Training on such noisy labeled datasets causes\nperformance degradation because DNNs easily overfit to noisy labels. To\novercome this problem, we propose a joint optimization framework of learning\nDNN parameters and estimating true labels. Our framework can correct labels\nduring training by alternating update of network parameters and labels. We\nconduct experiments on the noisy CIFAR-10 datasets and the Clothing1M dataset.\nThe results indicate that our approach significantly outperforms other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 06:53:40 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Tanaka", "Daiki", ""], ["Ikami", "Daiki", ""], ["Yamasaki", "Toshihiko", ""], ["Aizawa", "Kiyoharu", ""]]}, {"id": "1803.11373", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg, Ryota Kanai", "title": "Learning to generate classifiers", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a network to generate mappings between training sets and\nclassification policies (a 'classifier generator') by conditioning on the\nentire training set via an attentional mechanism. The network is directly\noptimized for test set performance on an training set of related tasks, which\nis then transferred to unseen 'test' tasks. We use this to optimize for\nperformance in the low-data and unsupervised learning regimes, and obtain\nsignificantly better performance in the 10-50 datapoint regime than support\nvector classifiers, random forests, XGBoost, and k-nearest neighbors on a range\nof small datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 07:43:35 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Guttenberg", "Nicholas", ""], ["Kanai", "Ryota", ""]]}, {"id": "1803.11395", "submitter": "Guanbin Li", "authors": "Guanbin Li and Yizhou Yu", "title": "Contrast-Oriented Deep Neural Networks for Salient Object Detection", "comments": "Accept to TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have become a key element in the recent\nbreakthrough of salient object detection. However, existing CNN-based methods\nare based on either patch-wise (region-wise) training and inference or fully\nconvolutional networks. Methods in the former category are generally\ntime-consuming due to severe storage and computational redundancies among\noverlapping patches. To overcome this deficiency, methods in the second\ncategory attempt to directly map a raw input image to a predicted dense\nsaliency map in a single network forward pass. Though being very efficient, it\nis arduous for these methods to detect salient objects of different scales or\nsalient regions with weak semantic information. In this paper, we develop\nhybrid contrast-oriented deep neural networks to overcome the aforementioned\nlimitations. Each of our deep networks is composed of two complementary\ncomponents, including a fully convolutional stream for dense prediction and a\nsegment-level spatial pooling stream for sparse saliency inference. We further\npropose an attentional module that learns weight maps for fusing the two\nsaliency predictions from these two streams. A tailored alternate scheme is\ndesigned to train these deep networks by fine-tuning pre-trained baseline\nmodels. Finally, a customized fully connected CRF model incorporating a salient\ncontour feature embedding can be optionally applied as a post-processing step\nto improve spatial coherence and contour positioning in the fused result from\nthese two streams. Extensive experiments on six benchmark datasets demonstrate\nthat our proposed model can significantly outperform the state of the art in\nterms of all popular evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 09:51:04 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Li", "Guanbin", ""], ["Yu", "Yizhou", ""]]}, {"id": "1803.11410", "submitter": "Amnon Drory", "authors": "Amnon Drory, Oria Ratzon, Shai Avidan, Raja Giryes", "title": "The Resistance to Label Noise in K-NN and DNN Depends on its\n  Concentration", "comments": "None", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the classification performance of K-nearest neighbors (K-NN)\nand deep neural networks (DNNs) in the presence of label noise. We first show\nempirically that a DNN's prediction for a given test example depends on the\nlabels of the training examples in its local neighborhood. This motivates us to\nderive a realizable analytic expression that approximates the multi-class K-NN\nclassification error in the presence of label noise, which is of independent\nimportance. We then suggest that the expression for K-NN may serve as a\nfirst-order approximation for the DNN error. Finally, we demonstrate\nempirically the proximity of the developed expression to the observed\nperformance of K-NN and DNN classifiers. Our result may explain the already\nobserved surprising resistance of DNN to some types of label noise. It also\ncharacterizes an important factor of it showing that the more concentrated the\nnoise the greater is the degradation in performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 11:06:43 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 13:49:57 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 09:18:17 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Drory", "Amnon", ""], ["Ratzon", "Oria", ""], ["Avidan", "Shai", ""], ["Giryes", "Raja", ""]]}, {"id": "1803.11451", "submitter": "Shashank Singh", "authors": "Shashank Singh, Bharath K. Sriperumbudur, Barnab\\'as P\\'oczos", "title": "Minimax Estimation of Quadratic Fourier Functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study estimation of (semi-)inner products between two nonparametric\nprobability distributions, given IID samples from each distribution. These\nproducts include relatively well-studied classical $\\mathcal{L}^2$ and Sobolev\ninner products, as well as those induced by translation-invariant reproducing\nkernels, for which we believe our results are the first. We first propose\nestimators for these quantities, and the induced (semi)norms and\n(pseudo)metrics. We then prove non-asymptotic upper bounds on their mean\nsquared error, in terms of weights both of the inner product and of the two\ndistributions, in the Fourier basis. Finally, we prove minimax lower bounds\nthat imply rate-optimality of the proposed estimators over Fourier ellipsoids.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 13:41:42 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 10:48:41 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Singh", "Shashank", ""], ["Sriperumbudur", "Bharath K.", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1803.11462", "submitter": "Djordje Gligorijevic", "authors": "Djordje Gligorijevic, Jelena Stojanovic and Zoran Obradovic", "title": "Improving confidence while predicting trends in temporal disease\n  networks", "comments": "Proceedings of the 4th Workshop on Data Mining for Medicine and\n  Healthcare, 2015 SIAM International Conference on Data Mining, Vancouver,\n  Canada, April 30 - May 02, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For highly sensitive real-world predictive analytic applications such as\nhealthcare and medicine, having good prediction accuracy alone is often not\nenough. These kinds of applications require a decision making process which\nuses uncertainty estimation as input whenever possible. Quality of uncertainty\nestimation is a subject of over or under confident prediction, which is often\nnot addressed in many models. In this paper we show several extensions to the\nGaussian Conditional Random Fields model, which aim to provide higher quality\nuncertainty estimation. These extensions are applied to the temporal disease\ngraph built from the State Inpatient Database (SID) of California, acquired\nfrom the HCUP. Our experiments demonstrate benefits of using graph information\nin modeling temporal disease properties as well as improvements in uncertainty\nestimation provided by given extensions of the Gaussian Conditional Random\nFields method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 15:53:39 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Gligorijevic", "Djordje", ""], ["Stojanovic", "Jelena", ""], ["Obradovic", "Zoran", ""]]}, {"id": "1803.11485", "submitter": "Mikayel Samvelyan", "authors": "Tabish Rashid, Mikayel Samvelyan, Christian Schroeder de Witt, Gregory\n  Farquhar, Jakob Foerster, Shimon Whiteson", "title": "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent\n  Reinforcement Learning", "comments": "Camera-ready version, International Conference of Machine Learning\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world settings, a team of agents must coordinate their behaviour\nwhile acting in a decentralised way. At the same time, it is often possible to\ntrain the agents in a centralised fashion in a simulated or laboratory setting,\nwhere global state information is available and communication constraints are\nlifted. Learning joint action-values conditioned on extra state information is\nan attractive way to exploit centralised learning, but the best strategy for\nthen extracting decentralised policies is unclear. Our solution is QMIX, a\nnovel value-based method that can train decentralised policies in a centralised\nend-to-end fashion. QMIX employs a network that estimates joint action-values\nas a complex non-linear combination of per-agent values that condition only on\nlocal observations. We structurally enforce that the joint-action value is\nmonotonic in the per-agent values, which allows tractable maximisation of the\njoint action-value in off-policy learning, and guarantees consistency between\nthe centralised and decentralised policies. We evaluate QMIX on a challenging\nset of StarCraft II micromanagement tasks, and show that QMIX significantly\noutperforms existing value-based multi-agent reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 14:23:39 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 17:58:09 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Rashid", "Tabish", ""], ["Samvelyan", "Mikayel", ""], ["de Witt", "Christian Schroeder", ""], ["Farquhar", "Gregory", ""], ["Foerster", "Jakob", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1803.11521", "submitter": "Mingyuan Wang", "authors": "Lizhe Sun, Mingyuan Wang, Yangzi Guo, Adrian Barbu", "title": "A Novel Framework for Online Supervised Learning with Feature Selection", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current online learning methods suffer issues such as lower convergence rates\nand limited capability to recover the support of the true features compared to\ntheir offline counterparts. In this paper, we present a novel framework for\nonline learning based on running averages and introduce a series of online\nversions of some popular existing offline methods such as Elastic Net, Minimax\nConcave Penalty and Feature Selection with Annealing. The framework can handle\nan arbitrarily large number of observations with the restriction that the data\ndimension is not too large, e.g. p<50,000. We prove the equivalence between our\nonline methods and their offline counterparts and give theoretical true feature\nrecovery and convergence guarantees for some of them. In contrast to the\nexisting online methods, the proposed methods can extract models with any\ndesired sparsity level at any time. Numerical experiments indicate that our new\nmethods enjoy high accuracy of true feature recovery and a fast convergence\nrate, compared with standard online and offline algorithms. We also show how\nthe running averages framework can be used for model adaptation in the presence\nof model drift. Finally, we present some applications to large datasets where\nagain the proposed framework shows competitive results compared to popular\nonline and offline algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 15:52:10 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 14:41:55 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 00:47:49 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 19:14:20 GMT"}, {"version": "v5", "created": "Sun, 4 Aug 2019 17:12:52 GMT"}, {"version": "v6", "created": "Mon, 16 Sep 2019 14:21:01 GMT"}, {"version": "v7", "created": "Wed, 17 Jun 2020 21:10:02 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Sun", "Lizhe", ""], ["Wang", "Mingyuan", ""], ["Guo", "Yangzi", ""], ["Barbu", "Adrian", ""]]}, {"id": "1803.11551", "submitter": "Minh Tang", "authors": "Minh Tang", "title": "The eigenvalues of stochastic blockmodel graphs", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the limiting distribution for the largest eigenvalues of the\nadjacency matrix for a stochastic blockmodel graph when the number of vertices\ntends to infinity. We show that, in the limit, these eigenvalues are jointly\nmultivariate normal with bounded covariances. Our result extends the classic\nresult of F\\\"{u}redi and Koml\\'{o}s on the fluctuation of the largest\neigenvalue for Erd\\H{o}s-R\\'{e}nyi graphs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 17:43:16 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Tang", "Minh", ""]]}]