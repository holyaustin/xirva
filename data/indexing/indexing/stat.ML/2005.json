[{"id": "2005.00010", "submitter": "Gautam Kamath", "authors": "Gautam Kamath, Jonathan Ullman", "title": "A Primer on Private Statistics", "comments": "20 pages. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private statistical estimation has seen a flurry of\ndevelopments over the last several years. Study has been divided into two\nschools of thought, focusing on empirical statistics versus population\nstatistics. We suggest that these two lines of work are more similar than\ndifferent by giving examples of methods that were initially framed for\nempirical statistics, but can be applied just as well to population statistics.\nWe also provide a thorough coverage of recent work in this area.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 18:00:00 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Kamath", "Gautam", ""], ["Ullman", "Jonathan", ""]]}, {"id": "2005.00054", "submitter": "Shuyang Dai", "authors": "Shuyang Dai, Zhe Gan, Yu Cheng, Chenyang Tao, Lawrence Carin, Jingjing\n  Liu", "title": "APo-VAE: Text Generation in Hyperbolic Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language often exhibits inherent hierarchical structure ingrained\nwith complex syntax and semantics. However, most state-of-the-art deep\ngenerative models learn embeddings only in Euclidean vector space, without\naccounting for this structural property of language. In this paper, we\ninvestigate text generation in a hyperbolic latent space to learn continuous\nhierarchical representations. An Adversarial Poincare Variational Autoencoder\n(APo-VAE) is presented, where both the prior and variational posterior of\nlatent variables are defined over a Poincare ball via wrapped normal\ndistributions. By adopting the primal-dual formulation of KL divergence, an\nadversarial learning procedure is introduced to empower robust model training.\nExtensive experiments in language modeling and dialog-response generation tasks\ndemonstrate the winning effectiveness of the proposed APo-VAE model over VAEs\nin Euclidean latent space, thanks to its superb capabilities in capturing\nlatent language hierarchies in hyperbolic space.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:05:41 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 03:56:43 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 22:41:30 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Dai", "Shuyang", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Tao", "Chenyang", ""], ["Carin", "Lawrence", ""], ["Liu", "Jingjing", ""]]}, {"id": "2005.00060", "submitter": "Pu Zhao", "authors": "Pu Zhao, Pin-Yu Chen, Payel Das, Karthikeyan Natesan Ramamurthy, Xue\n  Lin", "title": "Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness", "comments": "accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mode connectivity provides novel geometric insights on analyzing loss\nlandscapes and enables building high-accuracy pathways between well-trained\nneural networks. In this work, we propose to employ mode connectivity in loss\nlandscapes to study the adversarial robustness of deep neural networks, and\nprovide novel methods for improving this robustness. Our experiments cover\nvarious types of adversarial attacks applied to different network architectures\nand datasets. When network models are tampered with backdoor or error-injection\nattacks, our results demonstrate that the path connection learned using limited\namount of bonafide data can effectively mitigate adversarial effects while\nmaintaining the original accuracy on clean data. Therefore, mode connectivity\nprovides users with the power to repair backdoored or error-injected models. We\nalso use mode connectivity to investigate the loss landscapes of regular and\nrobust models against evasion attacks. Experiments show that there exists a\nbarrier in adversarial robustness loss on the path connecting regular and\nadversarially-trained models. A high correlation is observed between the\nadversarial robustness loss and the largest eigenvalue of the input Hessian\nmatrix, for which theoretical justifications are provided. Our results suggest\nthat mode connectivity offers a holistic tool and practical means for\nevaluating and improving adversarial robustness.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:12:50 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 03:49:28 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Zhao", "Pu", ""], ["Chen", "Pin-Yu", ""], ["Das", "Payel", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Lin", "Xue", ""]]}, {"id": "2005.00061", "submitter": "Su Jiang", "authors": "Su Jiang, Louis J. Durlofsky", "title": "Data-Space Inversion Using a Recurrent Autoencoder for Time-Series\n  Parameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-space inversion (DSI) and related procedures represent a family of\nmethods applicable for data assimilation in subsurface flow settings. These\nmethods differ from model-based techniques in that they provide only posterior\npredictions for quantities (time series) of interest, not posterior models with\ncalibrated parameters. DSI methods require a large number of flow simulations\nto first be performed on prior geological realizations. Given observed data,\nposterior predictions can then be generated directly. DSI operates in a\nBayesian setting and provides posterior samples of the data vector. In this\nwork we develop and evaluate a new approach for data parameterization in DSI.\nParameterization reduces the number of variables to determine in the inversion,\nand it maintains the physical character of the data variables. The new\nparameterization uses a recurrent autoencoder (RAE) for dimension reduction,\nand a long-short-term memory (LSTM) network to represent flow-rate time series.\nThe RAE-based parameterization is combined with an ensemble smoother with\nmultiple data assimilation (ESMDA) for posterior generation. Results are\npresented for two- and three-phase flow in a 2D channelized system and a 3D\nmulti-Gaussian model. The RAE procedure, along with existing DSI treatments,\nare assessed through comparison to reference rejection sampling (RS) results.\nThe new DSI methodology is shown to consistently outperform existing\napproaches, in terms of statistical agreement with RS results. The method is\nalso shown to accurately capture derived quantities, which are computed from\nvariables considered directly in DSI. This requires correlation and covariance\nbetween variables to be properly captured, and accuracy in these relationships\nis demonstrated. The RAE-based parameterization developed here is clearly\nuseful in DSI, and it may also find application in other subsurface flow\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:17:58 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 17:55:27 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Jiang", "Su", ""], ["Durlofsky", "Louis J.", ""]]}, {"id": "2005.00065", "submitter": "Divya Saxena", "authors": "Divya Saxena, Jiannong Cao", "title": "Generative Adversarial Networks (GANs): Challenges, Solutions, and\n  Future Directions", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) is a novel class of deep generative\nmodels which has recently gained significant attention. GANs learns complex and\nhigh-dimensional distributions implicitly over images, audio, and data.\nHowever, there exists major challenges in training of GANs, i.e., mode\ncollapse, non-convergence and instability, due to inappropriate design of\nnetwork architecture, use of objective function and selection of optimization\nalgorithm. Recently, to address these challenges, several solutions for better\ndesign and optimization of GANs have been investigated based on techniques of\nre-engineered network architectures, new objective functions and alternative\noptimization algorithms. To the best of our knowledge, there is no existing\nsurvey that has particularly focused on broad and systematic developments of\nthese solutions. In this study, we perform a comprehensive survey of the\nadvancements in GANs design and optimization solutions proposed to handle GANs\nchallenges. We first identify key research issues within each design and\noptimization technique and then propose a new taxonomy to structure solutions\nby key research issues. In accordance with the taxonomy, we provide a detailed\ndiscussion on different GANs variants proposed within each solution and their\nrelationships. Finally, based on the insights gained, we present the promising\nresearch directions in this rapidly growing field.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:26:46 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 18:06:37 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 09:07:20 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Saxena", "Divya", ""], ["Cao", "Jiannong", ""]]}, {"id": "2005.00107", "submitter": "Karush Suri", "authors": "Rinki Gupta, Karush Suri", "title": "Activity Detection from Wearable Electromyogram Sensors using Hidden\n  Markov Model", "comments": null, "journal-ref": null, "doi": "10.1109/ICCMC.2018.8488070", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface electromyography (sEMG) has gained significant importance during\nrecent advancements in consumer electronics for healthcare systems, gesture\nanalysis and recognition and sign language communication. For such a system, it\nis imperative to determine the regions of activity in a continuously recorded\nsEMG signal. The proposed work provides a novel activity detection approach\nbased on Hidden Markov Models (HMM) using sEMG signals recorded when various\nhand gestures are performed. Detection procedure is designed based on a\nprobabilistic outlook by making use of mathematical models. The requirement of\na threshold for activity detection is obviated making it subject and activity\nindependent. Correctness of the predicted outputs is asserted by classifying\nthe signal segments around the detected transition regions as activity or rest.\nClassified outputs are compared with the transition regions in a stimulus given\nto the subject to perform the activity. The activity onsets are detected with\nan average of 96.25% accuracy whereas the activity termination regions with an\naverage of 87.5% accuracy with the considered set of six activities and four\nsubjects.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:14:02 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Gupta", "Rinki", ""], ["Suri", "Karush", ""]]}, {"id": "2005.00113", "submitter": "Vinicius Souza", "authors": "Vinicius M. A. Souza, Denis M. dos Reis, Andre G. Maletzke, Gustavo E.\n  A. P. A. Batista", "title": "Challenges in Benchmarking Stream Learning Algorithms with Real-world\n  Data", "comments": "Preprint of article accepted for publication in the journal Data\n  Mining and Knowledge Discovery", "journal-ref": null, "doi": "10.1007/s10618-020-00698-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming data are increasingly present in real-world applications such as\nsensor measurements, satellite data feed, stock market, and financial data. The\nmain characteristics of these applications are the online arrival of data\nobservations at high speed and the susceptibility to changes in the data\ndistributions due to the dynamic nature of real environments. The data stream\nmining community still faces some primary challenges and difficulties related\nto the comparison and evaluation of new proposals, mainly due to the lack of\npublicly available non-stationary real-world datasets. The comparison of stream\nalgorithms proposed in the literature is not an easy task, as authors do not\nalways follow the same recommendations, experimental evaluation procedures,\ndatasets, and assumptions. In this paper, we mitigate problems related to the\nchoice of datasets in the experimental evaluation of stream classifiers and\ndrift detectors. To that end, we propose a new public data repository for\nbenchmarking stream algorithms with real-world data. This repository contains\nthe most popular datasets from literature and new datasets related to a highly\nrelevant public health problem that involves the recognition of disease vector\ninsects using optical sensors. The main advantage of these new datasets is the\nprior knowledge of their characteristics and patterns of changes to evaluate\nnew adaptive algorithm proposals adequately. We also present an in-depth\ndiscussion about the characteristics, reasons, and issues that lead to\ndifferent types of changes in data distribution, as well as a critical review\nof common problems concerning the current benchmark datasets available in the\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:31:34 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:41:10 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Souza", "Vinicius M. A.", ""], ["Reis", "Denis M. dos", ""], ["Maletzke", "Andre G.", ""], ["Batista", "Gustavo E. A. P. A.", ""]]}, {"id": "2005.00123", "submitter": "Dinesh Raghu", "authors": "Dinesh Raghu, Nikhil Gupta, Mausam", "title": "Unsupervised Learning of KB Queries in Task-Oriented Dialogs", "comments": "Presented at ACL 2021", "journal-ref": "Transactions of the Association for Computational Linguistics\n  (2021) 9: 374-390", "doi": "10.1162/tacl_a_00372", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog (TOD) systems often need to formulate knowledge base\n(KB) queries corresponding to the user intent and use the query results to\ngenerate system responses. Existing approaches require dialog datasets to\nexplicitly annotate these KB queries -- these annotations can be time\nconsuming, and expensive. In response, we define the novel problems of\npredicting the KB query and training the dialog agent, without explicit KB\nquery annotation. For query prediction, we propose a reinforcement learning\n(RL) baseline, which rewards the generation of those queries whose KB results\ncover the entities mentioned in subsequent dialog. Further analysis reveals\nthat correlation among query attributes in KB can significantly confuse memory\naugmented policy optimization (MAPO), an existing state of the art RL agent. To\naddress this, we improve the MAPO baseline with simple but important\nmodifications suited to our task. To train the full TOD system for our setting,\nwe propose a pipelined approach: it independently predicts when to make a KB\nquery (query position predictor), then predicts a KB query at the predicted\nposition (query predictor), and uses the results of predicted query in\nsubsequent dialog (next response predictor). Overall, our work proposes first\nsolutions to our novel problem, and our analysis highlights the research\nchallenges in training TOD systems without query annotation.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 22:10:00 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 04:27:47 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Raghu", "Dinesh", ""], ["Gupta", "Nikhil", ""], ["Mausam", "", ""]]}, {"id": "2005.00130", "submitter": "Thanos Tagaris", "authors": "Thanos Tagaris, Andreas Stafylopatis", "title": "Hide-and-Seek: A Template for Explainable AI", "comments": "24 pages, 14 figures. Submitted on a special issue for Explainable\n  AI, on Elsevier's \"Artificial Intelligence\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Lack of transparency has been the Achilles heal of Neural Networks and their\nwider adoption in industry. Despite significant interest this shortcoming has\nnot been adequately addressed. This study proposes a novel framework called\nHide-and-Seek (HnS) for training Interpretable Neural Networks and establishes\na theoretical foundation for exploring and comparing similar ideas. Extensive\nexperimentation indicates that a high degree of interpretability can be imputed\ninto Neural Networks, without sacrificing their predictive power.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 22:34:37 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Tagaris", "Thanos", ""], ["Stafylopatis", "Andreas", ""]]}, {"id": "2005.00146", "submitter": "Pauching Yap", "authors": "Pauching Yap, Hippolyt Ritter and David Barber", "title": "Addressing Catastrophic Forgetting in Few-Shot Problems", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to suffer from catastrophic forgetting when trained\non sequential datasets. While there have been numerous attempts to solve this\nproblem in large-scale supervised classification, little has been done to\novercome catastrophic forgetting in few-shot classification problems. We\ndemonstrate that the popular gradient-based model-agnostic meta-learning\nalgorithm (MAML) indeed suffers from catastrophic forgetting and introduce a\nBayesian online meta-learning framework that tackles this problem. Our\nframework utilises Bayesian online learning and meta-learning along with\nLaplace approximation and variational inference to overcome catastrophic\nforgetting in few-shot classification problems. The experimental evaluations\ndemonstrate that our framework can effectively achieve this goal in comparison\nwith various baselines. As an additional utility, we also demonstrate\nempirically that our framework is capable of meta-learning on sequentially\narriving few-shot tasks from a stationary task distribution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 23:56:18 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 15:05:21 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 10:15:20 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yap", "Pauching", ""], ["Ritter", "Hippolyt", ""], ["Barber", "David", ""]]}, {"id": "2005.00178", "submitter": "Clare Lyle", "authors": "Clare Lyle, Mark van der Wilk, Marta Kwiatkowska, Yarin Gal, Benjamin\n  Bloem-Reddy", "title": "On the Benefits of Invariance in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world data analysis problems exhibit invariant structure, and\nmodels that take advantage of this structure have shown impressive empirical\nperformance, particularly in deep learning. While the literature contains a\nvariety of methods to incorporate invariance into models, theoretical\nunderstanding is poor and there is no way to assess when one method should be\npreferred over another. In this work, we analyze the benefits and limitations\nof two widely used approaches in deep learning in the presence of invariance:\ndata augmentation and feature averaging. We prove that training with data\naugmentation leads to better estimates of risk and gradients thereof, and we\nprovide a PAC-Bayes generalization bound for models trained with data\naugmentation. We also show that compared to data augmentation, feature\naveraging reduces generalization error when used with convex losses, and\ntightens PAC-Bayes bounds. We provide empirical support of these theoretical\nresults, including a demonstration of why generalization may not improve by\ntraining with data augmentation: the `learned invariance' fails outside of the\ntraining distribution.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 02:08:58 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Lyle", "Clare", ""], ["van der Wilk", "Mark", ""], ["Kwiatkowska", "Marta", ""], ["Gal", "Yarin", ""], ["Bloem-Reddy", "Benjamin", ""]]}, {"id": "2005.00180", "submitter": "Melikasadat Emami", "authors": "Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Sundeep\n  Rangan, Alyson K. Fletcher", "title": "Generalization Error of Generalized Linear Models in High Dimensions", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of machine learning lies the question of generalizability of\nlearned rules over previously unseen data. While over-parameterized models\nbased on neural networks are now ubiquitous in machine learning applications,\nour understanding of their generalization capabilities is incomplete. This task\nis made harder by the non-convexity of the underlying learning problems. We\nprovide a general framework to characterize the asymptotic generalization error\nfor single-layer neural networks (i.e., generalized linear models) with\narbitrary non-linearities, making it applicable to regression as well as\nclassification problems. This framework enables analyzing the effect of (i)\nover-parameterization and non-linearity during modeling; and (ii) choices of\nloss function, initialization, and regularizer during learning. Our model also\ncaptures mismatch between training and test distributions. As examples, we\nanalyze a few special cases, namely linear regression and logistic regression.\nWe are also able to rigorously and analytically explain the \\emph{double\ndescent} phenomenon in generalized linear models.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 02:17:47 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Emami", "Melikasadat", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Pandit", "Parthe", ""], ["Rangan", "Sundeep", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "2005.00191", "submitter": "Hojjat Aghakhani", "authors": "Hojjat Aghakhani, Dongyu Meng, Yu-Xiang Wang, Christopher Kruegel, and\n  Giovanni Vigna", "title": "Bullseye Polytope: A Scalable Clean-Label Poisoning Attack with Improved\n  Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent source of concern for the security of neural networks is the\nemergence of clean-label dataset poisoning attacks, wherein correctly labeled\npoison samples are injected into the training dataset. While these poison\nsamples look legitimate to the human observer, they contain malicious\ncharacteristics that trigger a targeted misclassification during inference. We\npropose a scalable and transferable clean-label poisoning attack against\ntransfer learning, which creates poison images with their center close to the\ntarget image in the feature space. Our attack, Bullseye Polytope, improves the\nattack success rate of the current state-of-the-art by 26.75% in end-to-end\ntransfer learning, while increasing attack speed by a factor of 12. We further\nextend Bullseye Polytope to a more practical attack model by including multiple\nimages of the same object (e.g., from different angles) when crafting the\npoison samples. We demonstrate that this extension improves attack\ntransferability by over 16% to unseen images (of the same object) without using\nextra poison samples.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 03:22:36 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 19:30:08 GMT"}, {"version": "v3", "created": "Sun, 14 Mar 2021 01:33:47 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Aghakhani", "Hojjat", ""], ["Meng", "Dongyu", ""], ["Wang", "Yu-Xiang", ""], ["Kruegel", "Christopher", ""], ["Vigna", "Giovanni", ""]]}, {"id": "2005.00218", "submitter": "Zhicong Liang", "authors": "Zhicong Liang, Bao Wang, Quanquan Gu, Stanley Osher, Yuan Yao", "title": "Exploring Private Federated Learning with Laplacian Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning aims to protect data privacy by collaboratively learning a\nmodel without sharing private data among users. However, an adversary may still\nbe able to infer the private training data by attacking the released model.\nDifferential privacy(DP) provides a statistical guarantee against such attacks,\nat a privacy of possibly degenerating the accuracy or utility of the trained\nmodels. In this paper, we apply a utility enhancement scheme based on Laplacian\nsmoothing for differentially-private federated learning (DP-Fed-LS), where the\nparameter aggregation with injected Gaussian noise is improved in statistical\nprecision. We provide tight closed-form privacy bounds for both uniform and\nPoisson subsampling and derive corresponding DP guarantees for differential\nprivate federated learning, with or without Laplacian smoothing. Experiments\nover MNIST, SVHN and Shakespeare datasets show that the proposed method can\nimprove model accuracy with DP-guarantee under both subsampling mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:28:38 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Liang", "Zhicong", ""], ["Wang", "Bao", ""], ["Gu", "Quanquan", ""], ["Osher", "Stanley", ""], ["Yao", "Yuan", ""]]}, {"id": "2005.00220", "submitter": "Juan Cabral", "authors": "Juan B. Cabral, Felipe Ramos, Sebasti\\'an Gurovich and Pablo Granitto", "title": "Automatic Catalog of RRLyrae from $\\sim$ 14 million VVV Light Curves:\n  How far can we go with traditional machine-learning?", "comments": null, "journal-ref": "A&A 642, A58 (2020)", "doi": "10.1051/0004-6361/202038314", "report-no": null, "categories": "astro-ph.IM astro-ph.SR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The creation of a 3D map of the bulge using RRLyrae (RRL) is one of the main\ngoals of the VVV(X) surveys. The overwhelming number of sources under analysis\nrequest the use of automatic procedures. In this context, previous works\nintroduced the use of Machine Learning (ML) methods for the variable star\nclassification. Our goal is the development and analysis of an automatic\nprocedure, based on ML, for the identification of RRLs in the VVV Survey. This\nprocedure will be use to generate reliable catalogs integrated over several\ntiles in the survey. After the reconstruction of light-curves, we extract a set\nof period and intensity-based features. We use for the first time a new subset\nof pseudo color features. We discuss all the appropriate steps needed to define\nour automatic pipeline: selection of quality measures; sampling procedures;\nclassifier setup and model selection. As final result, we construct an ensemble\nclassifier with an average Recall of 0.48 and average Precision of 0.86 over 15\ntiles. We also make available our processed datasets and a catalog of candidate\nRRLs. Perhaps most interestingly, from a classification perspective based on\nphotometric broad-band data, is that our results indicate that Color is an\ninformative feature type of the RRL that should be considered for automatic\nclassification methods via ML. We also argue that Recall and Precision in both\ntables and curves are high quality metrics for this highly imbalanced problem.\nFurthermore, we show for our VVV data-set that to have good estimates it is\nimportant to use the original distribution more than reduced samples with an\nartificial balance. Finally, we show that the use of ensemble classifiers helps\nresolve the crucial model selection step, and that most errors in the\nidentification of RRLs are related to low quality observations of some sources\nor to the difficulty to resolve the RRL-C type given the date.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:35:57 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 19:29:32 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Cabral", "Juan B.", ""], ["Ramos", "Felipe", ""], ["Gurovich", "Sebasti\u00e1n", ""], ["Granitto", "Pablo", ""]]}, {"id": "2005.00259", "submitter": "Shuchu Han", "authors": "Shuchu Han, Alexandru Niculescu-Mizil", "title": "Supervised Feature Subset Selection and Feature Ranking for Multivariate\n  Time Series without Feature Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce supervised feature ranking and feature subset selection\nalgorithms for multivariate time series (MTS) classification. Unlike most\nexisting supervised/unsupervised feature selection algorithms for MTS our\ntechniques do not require a feature extraction step to generate a\none-dimensional feature vector from the time series. Instead it is based on\ndirectly computing similarity between individual time series and assessing how\nwell the resulting cluster structure matches the labels. The techniques are\namenable to heterogeneous MTS data, where the time series measurements may have\ndifferent sampling resolutions, and to multi-modal data.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 07:46:29 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Han", "Shuchu", ""], ["Niculescu-Mizil", "Alexandru", ""]]}, {"id": "2005.00341", "submitter": "Prafulla Dhariwal", "authors": "Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec\n  Radford, Ilya Sutskever", "title": "Jukebox: A Generative Model for Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Jukebox, a model that generates music with singing in the raw\naudio domain. We tackle the long context of raw audio using a multi-scale\nVQ-VAE to compress it to discrete codes, and modeling those using\nautoregressive Transformers. We show that the combined model at scale can\ngenerate high-fidelity and diverse songs with coherence up to multiple minutes.\nWe can condition on artist and genre to steer the musical and vocal style, and\non unaligned lyrics to make the singing more controllable. We are releasing\nthousands of non cherry-picked samples at https://jukebox.openai.com, along\nwith model weights and code at https://github.com/openai/jukebox\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 09:02:45 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Dhariwal", "Prafulla", ""], ["Jun", "Heewoo", ""], ["Payne", "Christine", ""], ["Kim", "Jong Wook", ""], ["Radford", "Alec", ""], ["Sutskever", "Ilya", ""]]}, {"id": "2005.00386", "submitter": "Matthias Katzfuss", "authors": "Matthias Katzfuss, Joseph Guinness, Earl Lawrence", "title": "Scaled Vecchia approximation for fast computer-model emulation", "comments": "R code available at https://github.com/katzfuss-group/scaledVecchia", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientific phenomena are studied using computer experiments consisting\nof multiple runs of a computer model while varying the input settings. Gaussian\nprocesses (GPs) are a popular tool for the analysis of computer experiments,\nenabling interpolation between input settings, but direct GP inference is\ncomputationally infeasible for large datasets. We adapt and extend a powerful\nclass of GP methods from spatial statistics to enable the scalable analysis and\nemulation of large computer experiments. Specifically, we apply Vecchia's\nordered conditional approximation in a transformed input space, with each input\nscaled according to how strongly it relates to the computer-model response. The\nscaling is learned from the data, by estimating parameters in the GP covariance\nfunction using Fisher scoring. Our methods are highly scalable, enabling\nestimation, joint prediction and simulation in near-linear time in the number\nof model runs. In several numerical examples, our approach substantially\noutperformed existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 14:08:31 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 16:03:08 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 21:07:03 GMT"}, {"version": "v4", "created": "Tue, 20 Jul 2021 15:43:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Katzfuss", "Matthias", ""], ["Guinness", "Joseph", ""], ["Lawrence", "Earl", ""]]}, {"id": "2005.00393", "submitter": "Nicola Landro", "authors": "Nicola Landro and Ignazio Gallo and Riccardo La Grassa", "title": "Can a powerful neural network be a teacher for a weaker neural network?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transfer learning technique is widely used to learning in one context and\napplying it to another, i.e. the capacity to apply acquired knowledge and\nskills to new situations. But is it possible to transfer the learning from a\ndeep neural network to a weaker neural network? Is it possible to improve the\nperformance of a weak neural network using the knowledge acquired by a more\npowerful neural network? In this work, during the training process of a weak\nnetwork, we add a loss function that minimizes the distance between the\nfeatures previously learned from a strong neural network with the features that\nthe weak network must try to learn. To demonstrate the effectiveness and\nrobustness of our approach, we conducted a large number of experiments using\nthree known datasets and demonstrated that a weak neural network can increase\nits performance if its learning process is driven by a more powerful neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 14:19:40 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 07:47:00 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Landro", "Nicola", ""], ["Gallo", "Ignazio", ""], ["La Grassa", "Riccardo", ""]]}, {"id": "2005.00397", "submitter": "Brighter Agyemang", "authors": "Brighter Agyemang and Wei-Ping Wu and Michael Yelpengne Kpiebaareh and\n  Zhihua Lei and Ebenezer Nanor and Lei Chen", "title": "Multi-View Self-Attention for Interpretable Drug-Target Interaction\n  Prediction", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2020.103547", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The drug discovery stage is a vital aspect of the drug development process\nand forms part of the initial stages of the development pipeline. In recent\ntimes, machine learning-based methods are actively being used to model\ndrug-target interactions for rational drug discovery due to the successful\napplication of these methods in other domains. In machine learning approaches,\nthe numerical representation of molecules is critical to the performance of the\nmodel. While significant progress has been made in molecular representation\nengineering, this has resulted in several descriptors for both targets and\ncompounds. Also, the interpretability of model predictions is a vital feature\nthat could have several pharmacological applications. In this study, we propose\na self-attention-based multi-view representation learning approach for modeling\ndrug-target interactions. We evaluated our approach using three benchmark\nkinase datasets and compared the proposed method to some baseline models. Our\nexperimental results demonstrate the ability of our method to achieve\ncompetitive prediction performance and offer biologically plausible drug-target\ninteraction interpretations.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 14:28:17 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 14:49:47 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Agyemang", "Brighter", ""], ["Wu", "Wei-Ping", ""], ["Kpiebaareh", "Michael Yelpengne", ""], ["Lei", "Zhihua", ""], ["Nanor", "Ebenezer", ""], ["Chen", "Lei", ""]]}, {"id": "2005.00409", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Continuous sign language recognition from wearable IMUs using deep\n  capsule networks and game theory", "comments": null, "journal-ref": null, "doi": "10.1016/j.compeleceng.2019.08.006", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign Language is used by the deaf community all over world. The work\npresented here proposes a novel one-dimensional deep capsule network (CapsNet)\narchitecture for continuous Indian Sign Language recognition by means of\nsignals obtained from a custom designed wearable IMU system. The performance of\nthe proposed CapsNet architecture is assessed by altering dynamic routing\nbetween capsule layers. The proposed CapsNet yields improved accuracy values of\n94% for 3 routings and 92.50% for 5 routings in comparison with the\nconvolutional neural network (CNN) that yields an accuracy of 87.99%. Improved\nlearning of the proposed architecture is also validated by spatial activations\ndepicting excited units at the predictive layer. Finally, a novel\nnon-cooperative pick-and-predict competition is designed between CapsNet and\nCNN. Higher value of Nash equilibrium for CapsNet as compared to CNN indicates\nthe suitability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:21:16 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.00410", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Classification of Hand Gestures from Wearable IMUs using Deep Neural\n  Network", "comments": null, "journal-ref": null, "doi": "10.1109/ICICCT.2018.8473301", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IMUs are gaining significant importance in the field of hand gesture\nanalysis, trajectory detection and kinematic functional study. An Inertial\nMeasurement Unit (IMU) consists of tri-axial accelerometers and gyroscopes\nwhich can together be used for formation analysis. The paper presents a novel\nclassification approach using a Deep Neural Network (DNN) for classifying hand\ngestures obtained from wearable IMU sensors. An optimization objective is set\nfor the classifier in order to reduce correlation between the activities and\nfit the signal-set with best performance parameters. Training of the network is\ncarried out by feed-forward computation of the input features followed by the\nback-propagation of errors. The predicted outputs are analyzed in the form of\nclassification accuracies which are then compared to the conventional\nclassification schemes of SVM and kNN. A 3-5% improvement in accuracies is\nobserved in the case of DNN classification. Results are presented for the\nrecorded accelerometer and gyroscope signals and the considered classification\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:08:33 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.00447", "submitter": "Snigdha Bhagat Ms", "authors": "Snigdha Bhagat, S. D. Joshi, Brejesh Lall", "title": "Image fusion using symmetric skip autoencodervia an Adversarial\n  Regulariser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a challenging task to extract the best of both worlds by combining the\nspatial characteristics of a visible image and the spectral content of an\ninfrared image. In this work, we propose a spatially constrained adversarial\nautoencoder that extracts deep features from the infrared and visible images to\nobtain a more exhaustive and global representation. In this paper, we propose a\nresidual autoencoder architecture, regularised by a residual adversarial\nnetwork, to generate a more realistic fused image. The residual module serves\nas primary building for the encoder, decoder and adversarial network, as an add\non the symmetric skip connections perform the functionality of embedding the\nspatial characteristics directly from the initial layers of encoder structure\nto the decoder part of the network. The spectral information in the infrared\nimage is incorporated by adding the feature maps over several layers in the\nencoder part of the fusion structure, which makes inference on both the visual\nand infrared images separately. In order to efficiently optimize the parameters\nof the network, we propose an adversarial regulariser network which would\nperform supervised learning on the fused image and the original visual image.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 15:31:45 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 07:33:25 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Bhagat", "Snigdha", ""], ["Joshi", "S. D.", ""], ["Lall", "Brejesh", ""]]}, {"id": "2005.00466", "submitter": "Mike Laszkiewicz", "authors": "Mike Laszkiewicz, Asja Fischer, Johannes Lederer", "title": "Thresholded Adaptive Validation: Tuning the Graphical Lasso for Graph\n  Recovery", "comments": "To appear in the proceedings of Artificial Intelligence and\n  Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Machine Learning algorithms are formulated as regularized optimization\nproblems, but their performance hinges on a regularization parameter that needs\nto be calibrated to each application at hand. In this paper, we propose a\ngeneral calibration scheme for regularized optimization problems and apply it\nto the graphical lasso, which is a method for Gaussian graphical modeling. The\nscheme is equipped with theoretical guarantees and motivates a thresholding\npipeline that can improve graph recovery. Moreover, requiring at most one line\nsearch over the regularization path, the calibration scheme is computationally\nmore efficient than competing schemes that are based on resampling. Finally, we\nshow in simulations that our approach can improve on the graph recovery of\nother approaches considerably.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 15:59:47 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 09:35:43 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Laszkiewicz", "Mike", ""], ["Fischer", "Asja", ""], ["Lederer", "Johannes", ""]]}, {"id": "2005.00478", "submitter": "Sayan Putatunda PhD", "authors": "Sayan Putatunda, Dayananda Ubrangala, Kiran Rama, Ravi Kondapalli", "title": "DriveML: An R Package for Driverless Machine Learning", "comments": "9 pages, 6 figures, Paper selected for presentation at the 2nd\n  International Workshop on Data Quality Assessment for Machine Learning @\n  Special Interest Group on Knowledge Discovery and Data Mining (SIGKDD), 14-18\n  August, 2021, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the concept of automated machine learning has become very\npopular. Automated Machine Learning (AutoML) mainly refers to the automated\nmethods for model selection and hyper-parameter optimization of various\nalgorithms such as random forests, gradient boosting, neural networks, etc. In\nthis paper, we introduce a new package i.e. DriveML for automated machine\nlearning. DriveML helps in implementing some of the pillars of an automated\nmachine learning pipeline such as automated data preparation, feature\nengineering, model building and model explanation by running the function\ninstead of writing lengthy R codes. The DriveML package is available in CRAN.\nWe compare the DriveML package with other relevant packages in CRAN/Github and\nfind that DriveML performs the best across different parameters. We also\nprovide an illustration by applying the DriveML package with default\nconfiguration on a real world dataset. Overall, the main benefits of DriveML\nare in development time savings, reduce developer's errors, optimal tuning of\nmachine learning models and reproducibility.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 16:40:25 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 05:45:23 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Putatunda", "Sayan", ""], ["Ubrangala", "Dayananda", ""], ["Rama", "Kiran", ""], ["Kondapalli", "Ravi", ""]]}, {"id": "2005.00497", "submitter": "Hubert Baniecki", "authors": "Hubert Baniecki, Przemyslaw Biecek", "title": "The Grammar of Interactive Explanatory Model Analysis", "comments": "17 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing need for in-depth analysis of predictive models leads to a series\nof new methods for explaining their local and global properties. Which of these\nmethods is the best? It turns out that this is an ill-posed question. One\ncannot sufficiently explain a black-box machine learning model using a single\nmethod that gives only one perspective. Isolated explanations are prone to\nmisunderstanding, which inevitably leads to wrong or simplistic reasoning. This\nproblem is known as the Rashomon effect and refers to diverse, even\ncontradictory interpretations of the same phenomenon. Surprisingly, the\nmajority of methods developed for explainable machine learning focus on a\nsingle aspect of the model behavior. In contrast, we showcase the problem of\nexplainability as an interactive and sequential analysis of a model. This paper\npresents how different Explanatory Model Analysis (EMA) methods complement each\nother and why it is essential to juxtapose them together. The introduced\nprocess of Interactive EMA (IEMA) derives from the algorithmic side of\nexplainable machine learning and aims to embrace ideas developed in cognitive\nsciences. We formalize the grammar of IEMA to describe potential human-model\ndialogues. IEMA is implemented in the human-centered framework that adopts\ninteractivity, customizability and automation as its main traits. Combined,\nthese methods enhance the responsible approach to predictive modeling.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:12:22 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 17:55:17 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 16:10:54 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Baniecki", "Hubert", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2005.00502", "submitter": "Liyuan Liu", "authors": "Shi Zhi and Liyuan Liu and Yu Zhang and Shiyin Wang and Qi Li and Chao\n  Zhang and Jiawei Han", "title": "Partially-Typed NER Datasets Integration: Connecting Practice to Theory", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While typical named entity recognition (NER) models require the training set\nto be annotated with all target types, each available datasets may only cover a\npart of them. Instead of relying on fully-typed NER datasets, many efforts have\nbeen made to leverage multiple partially-typed ones for training and allow the\nresulting model to cover a full type set. However, there is neither guarantee\non the quality of integrated datasets, nor guidance on the design of training\nalgorithms. Here, we conduct a systematic analysis and comparison between\npartially-typed NER datasets and fully-typed ones, in both theoretical and\nempirical manner. Firstly, we derive a bound to establish that models trained\nwith partially-typed annotations can reach a similar performance with the ones\ntrained with fully-typed annotations, which also provides guidance on the\nalgorithm design. Moreover, we conduct controlled experiments, which shows\npartially-typed datasets leads to similar performance with the model trained\nwith the same amount of fully-typed annotations\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:16:18 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhi", "Shi", ""], ["Liu", "Liyuan", ""], ["Zhang", "Yu", ""], ["Wang", "Shiyin", ""], ["Li", "Qi", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""]]}, {"id": "2005.00527", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Simon S. Du, Lin F. Yang, Sham M. Kakade", "title": "Is Long Horizon Reinforcement Learning More Difficult Than Short Horizon\n  Reinforcement Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to plan for long horizons is a central challenge in episodic\nreinforcement learning problems. A fundamental question is to understand how\nthe difficulty of the problem scales as the horizon increases. Here the natural\nmeasure of sample complexity is a normalized one: we are interested in the\nnumber of episodes it takes to provably discover a policy whose value is\n$\\varepsilon$ near to that of the optimal value, where the value is measured by\nthe normalized cumulative reward in each episode. In a COLT 2018 open problem,\nJiang and Agarwal conjectured that, for tabular, episodic reinforcement\nlearning problems, there exists a sample complexity lower bound which exhibits\na polynomial dependence on the horizon -- a conjecture which is consistent with\nall known sample complexity upper bounds. This work refutes this conjecture,\nproving that tabular, episodic reinforcement learning is possible with a sample\ncomplexity that scales only logarithmically with the planning horizon. In other\nwords, when the values are appropriately normalized (to lie in the unit\ninterval), this results shows that long horizon RL is no more difficult than\nshort horizon RL, at least in a minimax sense. Our analysis introduces two\nideas: (i) the construction of an $\\varepsilon$-net for optimal policies whose\nlog-covering number scales only logarithmically with the planning horizon, and\n(ii) the Online Trajectory Synthesis algorithm, which adaptively evaluates all\npolicies in a given policy class using sample complexity that scales with the\nlog-covering number of the given policy class. Both may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:56:38 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 16:20:06 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Wang", "Ruosong", ""], ["Du", "Simon S.", ""], ["Yang", "Lin F.", ""], ["Kakade", "Sham M.", ""]]}, {"id": "2005.00545", "submitter": "Ines Chami", "authors": "Ines Chami, Adva Wolf, Da-Cheng Juan, Frederic Sala, Sujith Ravi and\n  Christopher R\\'e", "title": "Low-Dimensional Hyperbolic Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) embeddings learn low-dimensional representations of\nentities and relations to predict missing facts. KGs often exhibit hierarchical\nand logical patterns which must be preserved in the embedding space. For\nhierarchical data, hyperbolic embedding methods have shown promise for\nhigh-fidelity and parsimonious representations. However, existing hyperbolic\nembedding methods do not account for the rich logical patterns in KGs. In this\nwork, we introduce a class of hyperbolic KG embedding models that\nsimultaneously capture hierarchical and logical patterns. Our approach combines\nhyperbolic reflections and rotations with attention to model complex relational\npatterns. Experimental results on standard KG benchmarks show that our method\nimproves over previous Euclidean- and hyperbolic-based efforts by up to 6.1% in\nmean reciprocal rank (MRR) in low dimensions. Furthermore, we observe that\ndifferent geometric transformations capture different types of relations while\nattention-based transformations generalize to multiple relations. In high\ndimensions, our approach yields new state-of-the-art MRRs of 49.6% on WN18RR\nand 57.7% on YAGO3-10.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:00:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chami", "Ines", ""], ["Wolf", "Adva", ""], ["Juan", "Da-Cheng", ""], ["Sala", "Frederic", ""], ["Ravi", "Sujith", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2005.00568", "submitter": "Judith Katzy", "authors": "Jose M. Clavijo and Paul Glaysher and Judith M. Katzy", "title": "Adversarial domain adaptation to reduce sample bias of a high energy\n  physics classifier", "comments": "15 pages, 8 figures, to be submitted to JINST", "journal-ref": null, "doi": null, "report-no": "Report Number: DESY 20-073", "categories": "stat.ML cs.LG hep-ex hep-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We apply adversarial domain adaptation to reduce sample bias in a\nclassification machine learning algorithm. We add a gradient reversal layer to\na neural network to simultaneously classify signal versus background events,\nwhile minimising the difference of the classifier response to a background\nsample using an alternative MC model. We show this on the example of simulated\nevents at the LHC with $t\\bar{t}H$ signal versus $t\\bar{t}b\\bar{b}$ background\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:46:12 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Clavijo", "Jose M.", ""], ["Glaysher", "Paul", ""], ["Katzy", "Judith M.", ""]]}, {"id": "2005.00570", "submitter": "Boqing Gong", "authors": "Dan Kondratyuk, Mingxing Tan, Matthew Brown, and Boqing Gong", "title": "When Ensembling Smaller Models is More Efficient than Single Large\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembling is a simple and popular technique for boosting evaluation\nperformance by training multiple models (e.g., with different initializations)\nand aggregating their predictions. This approach is commonly reserved for the\nlargest models, as it is commonly held that increasing the model size provides\na more substantial reduction in error than ensembling smaller models. However,\nwe show results from experiments on CIFAR-10 and ImageNet that ensembles can\noutperform single models with both higher accuracy and requiring fewer total\nFLOPs to compute, even when those individual models' weights and\nhyperparameters are highly optimized. Furthermore, this gap in improvement\nwidens as models become large. This presents an interesting observation that\noutput diversity in ensembling can often be more efficient than training larger\nmodels, especially when the models approach the size of what their dataset can\nfoster. Instead of using the common practice of tuning a single large model,\none can use ensembles as a more flexible trade-off between a model's inference\nspeed and accuracy. This also potentially eases hardware design, e.g., an\neasier way to parallelize the model across multiple workers for real-time or\ndistributed inference.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:56:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kondratyuk", "Dan", ""], ["Tan", "Mingxing", ""], ["Brown", "Matthew", ""], ["Gong", "Boqing", ""]]}, {"id": "2005.00585", "submitter": "Rahul Singh", "authors": "Rahul Singh, Qinsheng Zhang, Yongxin Chen", "title": "Improving Robustness via Risk Averse Distributional Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major obstacle that precludes the success of reinforcement learning in\nreal-world applications is the lack of robustness, either to model\nuncertainties or external disturbances, of the trained policies. Robustness is\ncritical when the policies are trained in simulations instead of real world\nenvironment. In this work, we propose a risk-aware algorithm to learn robust\npolicies in order to bridge the gap between simulation training and real-world\nimplementation. Our algorithm is based on recently discovered distributional RL\nframework. We incorporate CVaR risk measure in sample based distributional\npolicy gradients (SDPG) for learning risk-averse policies to achieve robustness\nagainst a range of system disturbances. We validate the robustness of\nrisk-aware SDPG on multiple environments.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:03:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Singh", "Rahul", ""], ["Zhang", "Qinsheng", ""], ["Chen", "Yongxin", ""]]}, {"id": "2005.00592", "submitter": "Mogens Graf Plessen", "authors": "Mogens Graf Plessen", "title": "Integrated Time Series Summarization and Prediction Algorithm and its\n  Application to COVID-19 Data Mining", "comments": "10 pages double column, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple method to extract from a set of multiple related\ntime series a compressed representation for each time series based on\nstatistics for the entire set of all time series. This is achieved by a\nhierarchical algorithm that first generates an alphabet of shapelets based on\nthe segmentation of centroids for clustered data, before labels of these\nshapelets are assigned to the segmentation of each single time series via\nnearest neighbor search using unconstrained dynamic time warping as distance\nmeasure to deal with non-uniform time series lenghts. Thereby, a sequence of\nlabels is assigned for each time series. Completion of the last label sequence\npermits prediction of individual time series. Proposed method is evaluated on\ntwo global COVID-19 datasets, first, for the number of daily net cases (daily\nnew infections minus daily recoveries), and, second, for the number of daily\ndeaths attributed to COVID-19 as of April 27, 2020. The first dataset involves\n249 time series for different countries, each of length 96. The second dataset\ninvolves 264 time series, each of length 96. Based on detected anomalies in\navailable data a decentralized exit strategy from lockdowns is advocated.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:16:39 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Plessen", "Mogens Graf", ""]]}, {"id": "2005.00596", "submitter": "Zhuolin Jiang", "authors": "Zhuolin Jiang, Jan Silovsky, Man-Hung Siu, William Hartmann, Herbert\n  Gish, Sancar Adali", "title": "Learning from Noisy Labels with Noise Modeling Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label image classification has generated significant interest in recent\nyears and the performance of such systems often suffers from the not so\ninfrequent occurrence of incorrect or missing labels in the training data. In\nthis paper, we extend the state-of the-art of training classifiers to jointly\ndeal with both forms of errorful data. We accomplish this by modeling noisy and\nmissing labels in multi-label images with a new Noise Modeling Network (NMN)\nthat follows our convolutional neural network (CNN), integrates with it,\nforming an end-to-end deep learning system, which can jointly learn the noise\ndistribution and CNN parameters. The NMN learns the distribution of noise\npatterns directly from the noisy data without the need for any clean training\ndata. The NMN can model label noise that depends only on the true label or is\nalso dependent on the image features. We show that the integrated NMN/CNN\nlearning system consistently improves the classification performance, for\ndifferent levels of label noise, on the MSR-COCO dataset and MSR-VTT dataset.\nWe also show that noise performance improvements are obtained when multiple\ninstance learning methods are used.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:32:22 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jiang", "Zhuolin", ""], ["Silovsky", "Jan", ""], ["Siu", "Man-Hung", ""], ["Hartmann", "William", ""], ["Gish", "Herbert", ""], ["Adali", "Sancar", ""]]}, {"id": "2005.00605", "submitter": "Aliaksandr Hubin", "authors": "Aliaksandr Hubin, Geir Storvik, Florian Frommlet", "title": "Rejoinder for the discussion of the paper \"A novel algorithmic approach\n  to Bayesian Logic Regression\"", "comments": "published in Bayesian Analysis, Volume 15, Number 1 (2020)", "journal-ref": "Bayesian Analysis, Volume 15, Number 1 (2020)", "doi": null, "report-no": null, "categories": "stat.ME math.LO stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this rejoinder we summarize the comments, questions and remarks on the\npaper \"A novel algorithmic approach to Bayesian Logic Regression\" from the\ndiscussants. We then respond to those comments, questions and remarks, provide\nseveral extensions of the original model and give a tutorial on our R-package\nEMJMCMC (http://aliaksah.github.io/EMJMCMC2016/)\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:59:56 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Hubin", "Aliaksandr", ""], ["Storvik", "Geir", ""], ["Frommlet", "Florian", ""]]}, {"id": "2005.00611", "submitter": "Ya-Chien Chang", "authors": "Ya-Chien Chang, Nima Roohi, Sicun Gao", "title": "Neural Lyapunov Control", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new methods for learning control policies and neural network\nLyapunov functions for nonlinear control problems, with provable guarantee of\nstability. The framework consists of a learner that attempts to find the\ncontrol and Lyapunov functions, and a falsifier that finds counterexamples to\nquickly guide the learner towards solutions. The procedure terminates when no\ncounterexample is found by the falsifier, in which case the controlled\nnonlinear system is provably stable. The approach significantly simplifies the\nprocess of Lyapunov control design, provides end-to-end correctness guarantee,\nand can obtain much larger regions of attraction than existing methods such as\nLQR and SOS/SDP. We show experiments on how the new methods obtain high-quality\nsolutions for challenging control problems.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:18:39 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 20:41:39 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 21:35:49 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Chang", "Ya-Chien", ""], ["Roohi", "Nima", ""], ["Gao", "Sicun", ""]]}, {"id": "2005.00615", "submitter": "Dehao Liu", "authors": "Dehao Liu, Yan Wang", "title": "A Dual-Dimer Method for Training Physics-Constrained Neural Networks\n  with Minimax Architecture", "comments": "34 pages, 5 figures, accepted by neural networks", "journal-ref": null, "doi": "10.1016/j.neunet.2020.12.028", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sparsity is a common issue to train machine learning tools such as\nneural networks for engineering and scientific applications, where experiments\nand simulations are expensive. Recently physics-constrained neural networks\n(PCNNs) were developed to reduce the required amount of training data. However,\nthe weights of different losses from data and physical constraints are adjusted\nempirically in PCNNs. In this paper, a new physics-constrained neural network\nwith the minimax architecture (PCNN-MM) is proposed so that the weights of\ndifferent losses can be adjusted systematically. The training of the PCNN-MM is\nsearching the high-order saddle points of the objective function. A novel\nsaddle point search algorithm called Dual-Dimer method is developed. It is\ndemonstrated that the Dual-Dimer method is computationally more efficient than\nthe gradient descent ascent method for nonconvex-nonconcave functions and\nprovides additional eigenvalue information to verify search results. A heat\ntransfer example also shows that the convergence of PCNN-MMs is faster than\nthat of traditional PCNNs.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:26:04 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 19:25:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Liu", "Dehao", ""], ["Wang", "Yan", ""]]}, {"id": "2005.00616", "submitter": "Jacob Seidman", "authors": "Jacob H. Seidman, Mahyar Fazlyab, Victor M. Preciado, George J. Pappas", "title": "Robust Deep Learning as Optimal Control: Insights and Convergence\n  Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fragility of deep neural networks to adversarially-chosen inputs has\nmotivated the need to revisit deep learning algorithms. Including adversarial\nexamples during training is a popular defense mechanism against adversarial\nattacks. This mechanism can be formulated as a min-max optimization problem,\nwhere the adversary seeks to maximize the loss function using an iterative\nfirst-order algorithm while the learner attempts to minimize it. However,\nfinding adversarial examples in this way causes excessive computational\noverhead during training. By interpreting the min-max problem as an optimal\ncontrol problem, it has recently been shown that one can exploit the\ncompositional structure of neural networks in the optimization problem to\nimprove the training time significantly. In this paper, we provide the first\nconvergence analysis of this adversarial training algorithm by combining\ntechniques from robust optimal control and inexact oracle methods in\noptimization. Our analysis sheds light on how the hyperparameters of the\nalgorithm affect the its stability and convergence. We support our insights\nwith experiments on a robust classification problem.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:26:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Seidman", "Jacob H.", ""], ["Fazlyab", "Mahyar", ""], ["Preciado", "Victor M.", ""], ["Pappas", "George J.", ""]]}, {"id": "2005.00631", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Adrian Weller, and Jos\\'e M. F. Moura", "title": "Evaluating and Aggregating Feature-based Model Explanations", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A feature-based model explanation denotes how much each input feature\ncontributes to a model's output for a given data point. As the number of\nproposed explanation functions grows, we lack quantitative evaluation criteria\nto help practitioners know when to use which explanation function. This paper\nproposes quantitative evaluation criteria for feature-based explanations: low\nsensitivity, high faithfulness, and low complexity. We devise a framework for\naggregating explanation functions. We develop a procedure for learning an\naggregate explanation function with lower complexity and then derive a new\naggregate Shapley value explanation function that minimizes sensitivity.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:56:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bhatt", "Umang", ""], ["Weller", "Adrian", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "2005.00653", "submitter": "Wasi Ahmad", "authors": "Wasi Uddin Ahmad and Saikat Chakraborty and Baishakhi Ray and Kai-Wei\n  Chang", "title": "A Transformer-based Approach for Source Code Summarization", "comments": "This paper is accepted at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a readable summary that describes the functionality of a program\nis known as source code summarization. In this task, learning code\nrepresentation by modeling the pairwise relationship between code tokens to\ncapture their long-range dependencies is crucial. To learn code representation\nfor summarization, we explore the Transformer model that uses a self-attention\nmechanism and has shown to be effective in capturing long-range dependencies.\nIn this work, we show that despite the approach is simple, it outperforms the\nstate-of-the-art techniques by a significant margin. We perform extensive\nanalysis and ablation studies that reveal several important findings, e.g., the\nabsolute encoding of source code tokens' position hinders, while relative\nencoding significantly improves the summarization performance. We have made our\ncode publicly available to facilitate future research.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 23:29:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ahmad", "Wasi Uddin", ""], ["Chakraborty", "Saikat", ""], ["Ray", "Baishakhi", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2005.00670", "submitter": "Morihiro Mizutani", "authors": "Morihiro Mizutani, Akifumi Okuno, Geewook Kim, Hidetoshi Shimodaira", "title": "Stochastic Neighbor Embedding of Multimodal Relational Data for\n  Image-Text Simultaneous Visualization", "comments": "20 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal relational data analysis has become of increasing importance in\nrecent years, for exploring across different domains of data, such as images\nand their text tags obtained from social networking services (e.g., Flickr). A\nvariety of data analysis methods have been developed for visualization; to give\nan example, t-Stochastic Neighbor Embedding (t-SNE) computes low-dimensional\nfeature vectors so that their similarities keep those of the observed data\nvectors. However, t-SNE is designed only for a single domain of data but not\nfor multimodal data; this paper aims at visualizing multimodal relational data\nconsisting of data vectors in multiple domains with relations across these\nvectors. By extending t-SNE, we herein propose Multimodal Relational Stochastic\nNeighbor Embedding (MR-SNE), that (1) first computes augmented relations, where\nwe observe the relations across domains and compute those within each of\ndomains via the observed data vectors, and (2) jointly embeds the augmented\nrelations to a low-dimensional space. Through visualization of Flickr and\nAnimal with Attributes 2 datasets, proposed MR-SNE is compared with other graph\nembedding-based approaches; MR-SNE demonstrates the promising performance.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 00:39:29 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mizutani", "Morihiro", ""], ["Okuno", "Akifumi", ""], ["Kim", "Geewook", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "2005.00687", "submitter": "Weihua Hu", "authors": "Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren,\n  Bowen Liu, Michele Catasta, Jure Leskovec", "title": "Open Graph Benchmark: Datasets for Machine Learning on Graphs", "comments": "Fix dataset bug in ogbg-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Open Graph Benchmark (OGB), a diverse set of challenging and\nrealistic benchmark datasets to facilitate scalable, robust, and reproducible\ngraph machine learning (ML) research. OGB datasets are large-scale, encompass\nmultiple important graph ML tasks, and cover a diverse range of domains,\nranging from social and information networks to biological networks, molecular\ngraphs, source code ASTs, and knowledge graphs. For each dataset, we provide a\nunified evaluation protocol using meaningful application-specific data splits\nand evaluation metrics. In addition to building the datasets, we also perform\nextensive benchmark experiments for each dataset. Our experiments suggest that\nOGB datasets present significant challenges of scalability to large-scale\ngraphs and out-of-distribution generalization under realistic data splits,\nindicating fruitful opportunities for future research. Finally, OGB provides an\nautomated end-to-end graph ML pipeline that simplifies and standardizes the\nprocess of graph data loading, experimental setup, and model evaluation. OGB\nwill be regularly updated and welcomes inputs from the community. OGB datasets\nas well as data loaders, evaluation scripts, baseline code, and leaderboards\nare publicly available at https://ogb.stanford.edu .\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 03:09:50 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 05:34:27 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 06:04:02 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 07:32:14 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 22:10:44 GMT"}, {"version": "v6", "created": "Sat, 23 Jan 2021 20:06:50 GMT"}, {"version": "v7", "created": "Thu, 25 Feb 2021 02:06:27 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Hu", "Weihua", ""], ["Fey", "Matthias", ""], ["Zitnik", "Marinka", ""], ["Dong", "Yuxiao", ""], ["Ren", "Hongyu", ""], ["Liu", "Bowen", ""], ["Catasta", "Michele", ""], ["Leskovec", "Jure", ""]]}, {"id": "2005.00695", "submitter": "Hongyang Zhang", "authors": "Sen Wu, Hongyang R. Zhang, Gregory Valiant, Christopher R\\'e", "title": "On the Generalization Effects of Linear Transformations in Data\n  Augmentation", "comments": "International Conference on Machine learning (ICML) 2020. Added\n  experimental results on ImageNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations which preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations which mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms RandAugment by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR datasets.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:10:21 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 06:00:23 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wu", "Sen", ""], ["Zhang", "Hongyang R.", ""], ["Valiant", "Gregory", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2005.00718", "submitter": "Zebang Zhang", "authors": "Zebang Zhang, Kui Zhao, Kai Huang, Quanhui Jia, Yanming Fang, Quan Yu", "title": "Large-scale Uncertainty Estimation and Its Application in Revenue\n  Forecast of SMEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The economic and banking importance of the small and medium enterprise (SME)\nsector is well recognized in contemporary society. Business credit loans are\nvery important for the operation of SMEs, and the revenue is a key indicator of\ncredit limit management. Therefore, it is very beneficial to construct a\nreliable revenue forecasting model. If the uncertainty of an enterprise's\nrevenue forecasting can be estimated, a more proper credit limit can be\ngranted. Natural gradient boosting approach, which estimates the uncertainty of\nprediction by a multi-parameter boosting algorithm based on the natural\ngradient. However, its original implementation is not easy to scale into big\ndata scenarios, and computationally expensive compared to state-of-the-art\ntree-based models (such as XGBoost). In this paper, we propose a Scalable\nNatural Gradient Boosting Machines that is simple to implement, readily\nparallelizable, interpretable and yields high-quality predictive uncertainty\nestimates. According to the characteristics of revenue distribution, we derive\nan uncertainty quantification function. We demonstrate that our method can\ndistinguish between samples that are accurate and inaccurate on revenue\nforecasting of SMEs. What's more, interpretability can be naturally obtained\nfrom the model, satisfying the financial needs.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 06:17:44 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhang", "Zebang", ""], ["Zhao", "Kui", ""], ["Huang", "Kai", ""], ["Jia", "Quanhui", ""], ["Fang", "Yanming", ""], ["Yu", "Quan", ""]]}, {"id": "2005.00783", "submitter": "Justus Tilmann Caspar Schwabedal", "authors": "Justus T. C. Schwabedal and Pascal Michel and Mario S. Riontino", "title": "Differentially Private Generation of Small Images", "comments": "11 pages, 3 figures. Revised criticism of Beaulieu-Jones et al\n  (2017): their results are likely correct", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the training of generative adversarial networks with differential\nprivacy to anonymize image data sets. On MNIST, we numerically measure the\nprivacy-utility trade-off using parameters from $\\epsilon$-$\\delta$\ndifferential privacy and the inception score. Our experiments uncover a\nsaturated training regime where an increasing privacy budget adds little to the\nquality of generated images. We also explain analytically why differentially\nprivate Adam optimization is independent of the gradient clipping parameter.\nFurthermore, we highlight common errors in previous works on differentially\nprivate deep learning, which we uncovered in recent literature. Throughout the\ntreatment of the subject, we hope to prevent erroneous estimates of anonymity\nin the future.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:37:46 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 09:38:10 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Schwabedal", "Justus T. C.", ""], ["Michel", "Pascal", ""], ["Riontino", "Mario S.", ""]]}, {"id": "2005.00784", "submitter": "Shuyin Xia", "authors": "Shuyin Xia, Daowan Peng, Deyu Meng, Changqing Zhang, Guoyin Wang,\n  Zizhong Chen, Wei Wei", "title": "Ball k-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel accelerated exact k-means algorithm called the\nBall k-means algorithm, which uses a ball to describe a cluster, focusing on\nreducing the point-centroid distance computation. The Ball k-means can\naccurately find the neighbor clusters for each cluster resulting distance\ncomputations only between a point and its neighbor clusters' centroids instead\nof all centroids. Moreover, each cluster can be divided into a stable area and\nan active area, and the later one can be further divided into annulus areas.\nThe assigned cluster of the points in the stable area is not changed in the\ncurrent iteration while the points in the annulus area will be adjusted within\na few neighbor clusters in the current iteration. Also, there are no upper or\nlower bounds in the proposed Ball k-means. Furthermore, reducing\ncentroid-centroid distance computation between iterations makes it efficient\nfor large k clustering. The fast speed, no extra parameters and simple design\nof the Ball k-means make it an all-around replacement of the naive k-means\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:39:26 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Xia", "Shuyin", ""], ["Peng", "Daowan", ""], ["Meng", "Deyu", ""], ["Zhang", "Changqing", ""], ["Wang", "Guoyin", ""], ["Chen", "Zizhong", ""], ["Wei", "Wei", ""]]}, {"id": "2005.00792", "submitter": "Woojeong Jin", "authors": "Woojeong Jin, Rahul Khanna, Suji Kim, Dong-Ho Lee, Fred Morstatter,\n  Aram Galstyan, Xiang Ren", "title": "ForecastQA: A Question Answering Challenge for Event Forecasting with\n  Temporal Text Data", "comments": "Accepted to ACL 2021. Project page:\n  https://inklab.usc.edu/ForecastQA/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event forecasting is a challenging, yet important task, as humans seek to\nconstantly plan for the future. Existing automated forecasting studies rely\nmostly on structured data, such as time-series or event-based knowledge graphs,\nto help predict future events. In this work, we aim to formulate a task,\nconstruct a dataset, and provide benchmarks for developing methods for event\nforecasting with large volumes of unstructured text data. To simulate the\nforecasting scenario on temporal news documents, we formulate the problem as a\nrestricted-domain, multiple-choice, question-answering (QA) task. Unlike\nexisting QA tasks, our task limits accessible information, and thus a model has\nto make a forecasting judgement. To showcase the usefulness of this task\nformulation, we introduce ForecastQA, a question-answering dataset consisting\nof 10,392 event forecasting questions, which have been collected and verified\nvia crowdsourcing efforts. We present our experiments on ForecastQA using\nBERT-based models and find that our best model achieves 60.1% accuracy on the\ndataset, which still lags behind human performance by about 19%. We hope\nForecastQA will support future research efforts in bridging this gap.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:03:40 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 23:56:35 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 09:16:31 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 02:54:15 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Jin", "Woojeong", ""], ["Khanna", "Rahul", ""], ["Kim", "Suji", ""], ["Lee", "Dong-Ho", ""], ["Morstatter", "Fred", ""], ["Galstyan", "Aram", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00797", "submitter": "Haishan Ye", "authors": "Haishan Ye, Luo Luo, Ziang Zhou, Tong Zhang", "title": "Multi-consensus Decentralized Accelerated Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the decentralized optimization problem, which has\napplications in large scale machine learning, sensor networks, and control\ntheory. We propose a novel algorithm that can achieve near optimal\ncommunication complexity, matching the known lower bound up to a logarithmic\nfactor of the condition number of the problem. Our theoretical results give\naffirmative answers to the open problem on whether there exists an algorithm\nthat can achieve a communication complexity (nearly) matching the lower bound\ndepending on the global condition number instead of the local one. Moreover,\nthe proposed algorithm achieves the optimal computation complexity matching the\nlower bound up to universal constants. Furthermore, to achieve a linear\nconvergence rate, our algorithm \\emph{doesn't} require the individual functions\nto be (strongly) convex. Our method relies on a novel combination of known\ntechniques including Nesterov's accelerated gradient descent, multi-consensus\nand gradient-tracking. The analysis is new, and may be applied to other related\nproblems. Empirical studies demonstrate the effectiveness of our method for\nmachine learning applications.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:10:32 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ye", "Haishan", ""], ["Luo", "Luo", ""], ["Zhou", "Ziang", ""], ["Zhang", "Tong", ""]]}, {"id": "2005.00817", "submitter": "Andrea Apicella", "authors": "Andrea Apicella, Francesco Donnarumma, Francesco Isgr\\`o and Roberto\n  Prevete", "title": "A survey on modern trainable activation functions", "comments": "Published in \"Neural Networks\" journal (Elsevier)", "journal-ref": "Neural Networks Volume 138, June 2021, Pages 14-32", "doi": "10.1016/j.neunet.2021.01.026", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural networks literature, there is a strong interest in identifying and\ndefining activation functions which can improve neural network performance. In\nrecent years there has been a renovated interest of the scientific community in\ninvestigating activation functions which can be trained during the learning\nprocess, usually referred to as \"trainable\", \"learnable\" or \"adaptable\"\nactivation functions. They appear to lead to better network performance.\nDiverse and heterogeneous models of trainable activation function have been\nproposed in the literature. In this paper, we present a survey of these models.\nStarting from a discussion on the use of the term \"activation function\" in\nliterature, we propose a taxonomy of trainable activation functions, highlight\ncommon and distinctive proprieties of recent and past models, and discuss main\nadvantages and limitations of this type of approach. We show that many of the\nproposed approaches are equivalent to adding neuron layers which use fixed\n(non-trainable) activation functions and some simple local rule that\nconstraints the corresponding weight layers.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:38:43 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 22:11:55 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 12:55:51 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 21:34:34 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Apicella", "Andrea", ""], ["Donnarumma", "Francesco", ""], ["Isgr\u00f2", "Francesco", ""], ["Prevete", "Roberto", ""]]}, {"id": "2005.00826", "submitter": "Lukas Brunke", "authors": "Lukas Brunke", "title": "Learning Model Predictive Control for Competitive Autonomous Racing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this thesis is to design a learning model predictive controller\n(LMPC) that allows multiple agents to race competitively on a predefined race\ntrack in real-time. This thesis addresses two major shortcomings in the already\nexisting single-agent formulation. Previously, the agent determines a locally\noptimal trajectory but does not explore the state space, which may be necessary\nfor overtaking maneuvers. Additionally, obstacle avoidance for LMPC has been\nachieved in the past by using a non-convex terminal set, which increases the\ncomplexity for determining a solution to the optimization problem. The proposed\nalgorithm for multi-agent racing explores the state space by executing the LMPC\nfor multiple different initializations, which yields a richer terminal safe\nset. Furthermore, a new method for selecting states in the terminal set is\ndeveloped, which keeps the convexity for the terminal safe set and allows for\ntaking suboptimal states.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 13:05:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Brunke", "Lukas", ""]]}, {"id": "2005.00845", "submitter": "Pierre G. B. Moutounet-Cartan", "authors": "Pierre G. B. Moutounet-Cartan", "title": "Deep Convolutional Neural Networks to Diagnose COVID-19 and other\n  Pneumonia Diseases from Posteroanterior Chest X-Rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article explores different deep convolutional neural network\narchitectures trained and tested on posteroanterior chest X-rays of 327\npatients who are healthy (152 patients), diagnosed with COVID-19 (125), and\nother types of pneumonia (48). In particular, this paper looks at the deep\nconvolutional neural networks VGG16 and VGG19, InceptionResNetV2 and\nInceptionV3, as well as Xception, all followed by a flat multi-layer perceptron\nand a final 30% drop-out. The paper has found that the best performing network\nis VGG16 with a final $30$% drop-out trained over 3 classes (COVID-19, No\nFinding, Other Pneumonia). It has an internal cross-validated accuracy of\n$93.9(\\pm3.4)$%, a COVID-19 sensitivity of $87.7(-1.9,+2)$%, and a No Finding\nsensitivity of $96.8(\\pm0.8)$%. The respective external cross-validated values\nare $84.1(\\pm13.5)$%, $87.7(-1.9,2)$%, and $96.8(\\pm0.8)$%. The model optimizer\nwas Adam with a 1e-4 learning rate, and categorical cross-entropy loss. It is\nhoped that, once this research will be put to practice in hospitals, healthcare\nprofessionals will be able in the medium to long-term to diagnosing through\nmachine learning tools possible pneumonia, and if detected, whether it is\nlinked to a COVID-19 infection, allowing the detection of new possible COVID-19\nfoyers after the end of possible \"stop-and-go\" lockdowns as expected by until a\nvaccine is found and widespread. Furthermore, in the short-term, it is hoped\npractitioners can compare the diagnosis from the deep convolutional neural\nnetworks with possible RT-PCR testing results, and if clashing, a Computed\nTomography could be performed as they are more accurate in showing COVID-19\npneumonia.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 14:42:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Moutounet-Cartan", "Pierre G. B.", ""]]}, {"id": "2005.00865", "submitter": "Teven Le Scao", "authors": "Teven Le Scao", "title": "Neural Differential Equations for Single Image Super-resolution", "comments": "7 pages, 5 figures, ICLR 2020 Workshop on Integration of Deep Neural\n  Models and Differential Equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although Neural Differential Equations have shown promise on toy problems\nsuch as MNIST, they have yet to be successfully applied to more challenging\ntasks. Inspired by variational methods for image restoration relying on partial\ndifferential equations, we choose to benchmark several forms of Neural DEs and\nbackpropagation methods on single image super-resolution. The adjoint method\npreviously proposed for gradient estimation has no theoretical stability\nguarantees; we find a practical case where this makes it unusable, and show\nthat discrete sensitivity analysis has better stability. In our experiments,\ndifferential models match the performance of a state-of-the art\nsuper-resolution model.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:46:45 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Scao", "Teven Le", ""]]}, {"id": "2005.00935", "submitter": "Yasin Yilmaz", "authors": "Ammar Haydari, Yasin Yilmaz", "title": "Deep Reinforcement Learning for Intelligent Transportation Systems: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest technological improvements increased the quality of transportation.\nNew data-driven approaches bring out a new research direction for all\ncontrol-based systems, e.g., in transportation, robotics, IoT and power\nsystems. Combining data-driven applications with transportation systems plays a\nkey role in recent transportation applications. In this paper, the latest deep\nreinforcement learning (RL) based traffic control applications are surveyed.\nSpecifically, traffic signal control (TSC) applications based on (deep) RL,\nwhich have been studied extensively in the literature, are discussed in detail.\nDifferent problem formulations, RL parameters, and simulation environments for\nTSC are discussed comprehensively. In the literature, there are also several\nautonomous driving applications studied with deep RL models. Our survey\nextensively summarizes existing works in this field by categorizing them with\nrespect to application types, control models and studied algorithms. In the\nend, we discuss the challenges and open questions regarding deep RL-based\ntransportation applications.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 22:44:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Haydari", "Ammar", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2005.00959", "submitter": "Tom Tirer", "authors": "Tom Tirer, Raja Giryes", "title": "On the Convergence Rate of Projected Gradient Descent for a\n  Back-Projection based Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ill-posed linear inverse problems appear in many scientific setups, and are\ntypically addressed by solving optimization problems, which are composed of\ndata fidelity and prior terms. Recently, several works have considered a\nback-projection (BP) based fidelity term as an alternative to the common least\nsquares (LS), and demonstrated excellent results for popular inverse problems.\nThese works have also empirically shown that using the BP term, rather than the\nLS term, requires fewer iterations of optimization algorithms. In this paper,\nwe examine the convergence rate of the projected gradient descent (PGD)\nalgorithm for the BP objective. Our analysis allows to identify an inherent\nsource for its faster convergence compared to using the LS objective, while\nmaking only mild assumptions. We also analyze the more general proximal\ngradient method under a relaxed contraction condition on the proximal mapping\nof the prior. This analysis further highlights the advantage of BP when the\nlinear measurement operator is badly conditioned. Numerical experiments with\nboth $\\ell_1$-norm and GAN-based priors corroborate our theoretical results.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 00:58:23 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 18:04:47 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Tirer", "Tom", ""], ["Giryes", "Raja", ""]]}, {"id": "2005.01026", "submitter": "Guodong Long Dr", "authors": "Ming Xie, Guodong Long, Tao Shen, Tianyi Zhou, Xianzhi Wang, Jing\n  Jiang", "title": "Multi-Center Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has received great attention for its capability to train a\nlarge-scale model in a decentralized manner without needing to access user data\ndirectly. It helps protect the users' private data from centralized collecting.\nUnlike distributed machine learning, federated learning aims to tackle non-IID\ndata from heterogeneous sources in various real-world applications, such as\nthose on smartphones. Existing federated learning approaches usually adopt a\nsingle global model to capture the shared knowledge of all users by aggregating\ntheir gradients, regardless of the discrepancy between their data\ndistributions. However, due to the diverse nature of user behaviors, assigning\nusers' gradients to different global models (i.e., centers) can better capture\nthe heterogeneity of data distributions across users. Our paper proposes a\nnovel multi-center aggregation mechanism for federated learning, which learns\nmultiple global models from the non-IID user data and simultaneously derives\nthe optimal matching between users and centers. We formulate the problem as a\njoint optimization that can be efficiently solved by a stochastic expectation\nmaximization (EM) algorithm. Our experimental results on benchmark datasets\nshow that our method outperforms several popular federated learning methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 09:14:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Xie", "Ming", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Wang", "Xianzhi", ""], ["Jiang", "Jing", ""]]}, {"id": "2005.01095", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Kun Zhang, Yingzhen Li", "title": "A Causal View on Robustness of Neural Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a causal view on the robustness of neural networks against input\nmanipulations, which applies not only to traditional classification tasks but\nalso to general measurement data. Based on this view, we design a deep causal\nmanipulation augmented model (deep CAMA) which explicitly models possible\nmanipulations on certain causes leading to changes in the observed effect. We\nfurther develop data augmentation and test-time fine-tuning methods to improve\ndeep CAMA's robustness. When compared with discriminative deep neural networks,\nour proposed model shows superior robustness against unseen manipulations. As a\nby-product, our model achieves disentangled representation which separates the\nrepresentation of manipulations from those of other latent causes.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 14:20:05 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 21:12:11 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 16:36:42 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Zhang", "Cheng", ""], ["Zhang", "Kun", ""], ["Li", "Yingzhen", ""]]}, {"id": "2005.01097", "submitter": "Motasem Alfarra Alfarra M", "authors": "Motasem Alfarra, Slavomir Hanzely, Alyazeed Albasyoni, Bernard Ghanem\n  and Peter Richtarik", "title": "Adaptive Learning of the Optimal Mini-Batch Size of SGD", "comments": "17 pages, 45 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the theoretical understandingof SGD (Qian et al., 2019)\nled to a formula for the optimal mini-batch size minimizing the number of\neffective data passes, i.e., the number of iterations times the mini-batch\nsize. However, this formula is of no practical value as it depends on the\nknowledge of the variance of the stochastic gradients evaluated at the optimum.\nIn this paper we design a practical SGD method capable of learning the optimal\nmini-batch size adaptively throughout its iterations. Our method does this\nprovably, and in our experiments with synthetic and real data robustly exhibits\nnearly optimal behaviour; that is, it works as if the optimal mini-batch size\nwas known a-priori. Further, we generalize our method to several new mini-batch\nstrategies not considered in the literature before, including a sampling\nsuitable for distributed implementations.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 14:28:32 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Alfarra", "Motasem", ""], ["Hanzely", "Slavomir", ""], ["Albasyoni", "Alyazeed", ""], ["Ghanem", "Bernard", ""], ["Richtarik", "Peter", ""]]}, {"id": "2005.01123", "submitter": "Liangjian Wen PhD.", "authors": "Liangjian Wen, Yiji Zhou, Lirong He, Mingyuan Zhou, Zenglin Xu", "title": "Mutual Information Gradient Estimation for Representation Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual Information (MI) plays an important role in representation learning.\nHowever, MI is unfortunately intractable in continuous and high-dimensional\nsettings. Recent advances establish tractable and scalable MI estimators to\ndiscover useful representation. However, most of the existing methods are not\ncapable of providing an accurate estimation of MI with low-variance when the MI\nis large. We argue that directly estimating the gradients of MI is more\nappealing for representation learning than estimating MI in itself. To this\nend, we propose the Mutual Information Gradient Estimator (MIGE) for\nrepresentation learning based on the score estimation of implicit\ndistributions. MIGE exhibits a tight and smooth gradient estimation of MI in\nthe high-dimensional and large-MI settings. We expand the applications of MIGE\nin both unsupervised learning of deep representations based on InfoMax and the\nInformation Bottleneck method. Experimental results have indicated significant\nperformance improvement in learning useful representation.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:05:58 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wen", "Liangjian", ""], ["Zhou", "Yiji", ""], ["He", "Lirong", ""], ["Zhou", "Mingyuan", ""], ["Xu", "Zenglin", ""]]}, {"id": "2005.01138", "submitter": "Samin Yeasar Arnob", "authors": "Samin Yeasar Arnob", "title": "Off-Policy Adversarial Inverse Reinforcement Learning", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Imitation Learning (AIL) is a class of algorithms in\nReinforcement learning (RL), which tries to imitate an expert without taking\nany reward from the environment and does not provide expert behavior directly\nto the policy training. Rather, an agent learns a policy distribution that\nminimizes the difference from expert behavior in an adversarial setting.\nAdversarial Inverse Reinforcement Learning (AIRL) leverages the idea of AIL,\nintegrates a reward function approximation along with learning the policy, and\nshows the utility of IRL in the transfer learning setting. But the reward\nfunction approximator that enables transfer learning does not perform well in\nimitation tasks. We propose an Off-Policy Adversarial Inverse Reinforcement\nLearning (Off-policy-AIRL) algorithm which is sample efficient as well as gives\ngood imitation performance compared to the state-of-the-art AIL algorithm in\nthe continuous control tasks. For the same reward function approximator, we\nshow the utility of learning our algorithm over AIL by using the learned reward\nfunction to retrain the policy over a task under significant variation where\nexpert demonstrations are absent.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:51:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Arnob", "Samin Yeasar", ""]]}, {"id": "2005.01209", "submitter": "Shiqian Ma", "authors": "Bokun Wang, Shiqian Ma, Lingzhou Xue", "title": "Riemannian Stochastic Proximal Gradient Methods for Nonsmooth\n  Optimization over the Stiefel Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Riemannian optimization has drawn a lot of attention due to its wide\napplications in practice. Riemannian stochastic first-order algorithms have\nbeen studied in the literature to solve large-scale machine learning problems\nover Riemannian manifolds. However, most of the existing Riemannian stochastic\nalgorithms require the objective function to be differentiable, and they do not\napply to the case where the objective function is nonsmooth. In this paper, we\npresent two Riemannian stochastic proximal gradient methods for minimizing\nnonsmooth function over the Stiefel manifold. The two methods, named R-ProxSGD\nand R-ProxSPB, are generalizations of proximal SGD and proximal SpiderBoost in\nEuclidean setting to the Riemannian setting. Analysis on the incremental\nfirst-order oracle (IFO) complexity of the proposed algorithms is provided.\nSpecifically, the R-ProxSPB algorithm finds an $\\epsilon$-stationary point with\n$\\mathcal{O}(\\epsilon^{-3})$ IFOs in the online case, and\n$\\mathcal{O}(n+\\sqrt{n}\\epsilon^{-3})$ IFOs in the finite-sum case with $n$\nbeing the number of summands in the objective. Experimental results on online\nsparse PCA and robust low-rank matrix completion show that our proposed methods\nsignificantly outperform the existing methods that uses Riemannian subgradient\ninformation.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 23:41:35 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Bokun", ""], ["Ma", "Shiqian", ""], ["Xue", "Lingzhou", ""]]}, {"id": "2005.01214", "submitter": "Hoang Nt", "authors": "Hoang NT, Takanori Maehara", "title": "Graph Homomorphism Convolution", "comments": "37th International Conference on Machine Learning (ICML 2020)", "journal-ref": "PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the graph classification problem from the graph\nhomomorphism perspective. We consider the homomorphisms from $F$ to $G$, where\n$G$ is a graph of interest (e.g. molecules or social networks) and $F$ belongs\nto some family of graphs (e.g. paths or non-isomorphic trees). We show that\ngraph homomorphism numbers provide a natural invariant (isomorphism invariant\nand $\\mathcal{F}$-invariant) embedding maps which can be used for graph\nclassification. Viewing the expressive power of a graph classifier by the\n$\\mathcal{F}$-indistinguishable concept, we prove the universality property of\ngraph homomorphism vectors in approximating $\\mathcal{F}$-invariant functions.\nIn practice, by choosing $\\mathcal{F}$ whose elements have bounded tree-width,\nwe show that the homomorphism method is efficient compared with other methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 23:56:20 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 01:10:37 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["NT", "Hoang", ""], ["Maehara", "Takanori", ""]]}, {"id": "2005.01246", "submitter": "Raviteja Anantha", "authors": "Raviteja Anantha, Stephen Pulman, and Srinivas Chappidi", "title": "Generalized Reinforcement Meta Learning for Few-Shot Optimization", "comments": "10 pages, 4 figures, 4 tables, 2 algorithms, ICML conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic and flexible Reinforcement Learning (RL) based\nmeta-learning framework for the problem of few-shot learning. During training,\nit learns the best optimization algorithm to produce a learner\n(ranker/classifier, etc) by exploiting stable patterns in loss surfaces. Our\nmethod implicitly estimates the gradients of a scaled loss function while\nretaining the general properties intact for parameter updates. Besides\nproviding improved performance on few-shot tasks, our framework could be easily\nextended to do network architecture search. We further propose a novel dual\nencoder, affinity-score based decoder topology that achieves additional\nimprovements to performance. Experiments on an internal dataset, MQ2007, and\nAwA2 show our approach outperforms existing alternative approaches by 21%, 8%,\nand 4% respectively on accuracy and NDCG metrics. On Mini-ImageNet dataset our\napproach achieves comparable results with Prototypical Networks. Empirical\nevaluations demonstrate that our approach provides a unified and effective\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 03:21:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Anantha", "Raviteja", ""], ["Pulman", "Stephen", ""], ["Chappidi", "Srinivas", ""]]}, {"id": "2005.01285", "submitter": "Tore Selland Kleppe", "authors": "Tore Selland Kleppe", "title": "Connecting the Dots: Towards Continuous Time Hamiltonian Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous time Hamiltonian Monte Carlo is introduced, as a powerful\nalternative to Markov chain Monte Carlo methods for continuous target\ndistributions. The method is constructed in two steps: First Hamiltonian\ndynamics are chosen as the deterministic dynamics in a continuous time\npiecewise deterministic Markov process. Under very mild restrictions, such a\nprocess will have the desired target distribution as an invariant distribution.\nSecondly, the numerical implementation of such processes, based on adaptive\nnumerical integration of second order ordinary differential equations is\nconsidered. The numerical implementation yields an approximate, yet highly\nrobust algorithm that, unlike conventional Hamiltonian Monte Carlo, enables the\nexploitation of the complete Hamiltonian trajectories (hence the title). The\nproposed algorithm may yield large speedups and improvements in stability\nrelative to relevant benchmarks, while incurring numerical errors that are\nnegligible relative to the overall Monte Carlo errors.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 06:23:13 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 14:00:54 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kleppe", "Tore Selland", ""]]}, {"id": "2005.01297", "submitter": "Tomas Pevny", "authors": "Tomas Pevny, Vasek Smidl, Martin Trapp, Ondrej Polacek, Tomas\n  Oberhuber", "title": "Sum-Product-Transform Networks: Exploiting Symmetries using Invertible\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose Sum-Product-Transform Networks (SPTN), an extension\nof sum-product networks that uses invertible transformations as additional\ninternal nodes. The type and placement of transformations determine properties\nof the resulting SPTN with many interesting special cases. Importantly, SPTN\nwith Gaussian leaves and affine transformations pose the same inference task\ntractable that can be computed efficiently in SPNs. We propose to store affine\ntransformations in their SVD decompositions using an efficient parametrization\nof unitary matrices by a set of Givens rotations. Last but not least, we\ndemonstrate that G-SPTNs achieve state-of-the-art results on the density\nestimation task and are competitive with state-of-the-art methods for anomaly\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 07:05:51 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Pevny", "Tomas", ""], ["Smidl", "Vasek", ""], ["Trapp", "Martin", ""], ["Polacek", "Ondrej", ""], ["Oberhuber", "Tomas", ""]]}, {"id": "2005.01302", "submitter": "Souvik Chakraborty", "authors": "Souvik Chakraborty", "title": "Simulation free reliability analysis: A physics-informed deep learning\n  based approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simulation free framework for solving reliability\nanalysis problems. The method proposed is rooted in a recently developed deep\nlearning approach, referred to as the physics-informed neural network. The\nprimary idea is to learn the neural network parameters directly from the\nphysics of the problem. With this, the need for running simulation and\ngenerating data is completely eliminated. Additionally, the proposed approach\nalso satisfies physical laws such as invariance properties and conservation\nlaws associated with the problem. The proposed approach is used for solving\nthree benchmark reliability analysis problems. Results obtained illustrates\nthat the proposed approach is highly accurate. Moreover, the primary bottleneck\nof solving reliability analysis problems, i.e., running expensive simulations\nto generate data, is eliminated with this method.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 07:19:50 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 11:05:17 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 05:22:59 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chakraborty", "Souvik", ""]]}, {"id": "2005.01309", "submitter": "Bruno Sudret", "authors": "X. Zhu and B. Sudret", "title": "Global sensitivity analysis for stochastic simulators based on\n  generalized lambda surrogate models", "comments": null, "journal-ref": "Reliability Engineering and System Safety, #107815, 2021", "doi": "10.1016/j.ress.2021.107815", "report-no": "RSUQ-2020-004D", "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global sensitivity analysis aims at quantifying the impact of input\nvariability onto the variation of the response of a computational model. It has\nbeen widely applied to deterministic simulators, for which a set of input\nparameters has a unique corresponding output value. Stochastic simulators,\nhowever, have intrinsic randomness due to their use of (pseudo)random numbers,\nso they give different results when run twice with the same input parameters\nbut non-common random numbers. Due to this random nature, conventional Sobol'\nindices, used in global sensitivity analysis, can be extended to stochastic\nsimulators in different ways. In this paper, we discuss three possible\nextensions and focus on those that depend only on the statistical dependence\nbetween input and output. This choice ignores the detailed data generating\nprocess involving the internal randomness, and can thus be applied to a wider\nclass of problems. We propose to use the generalized lambda model to emulate\nthe response distribution of stochastic simulators. Such a surrogate can be\nconstructed without the need for replications. The proposed method is applied\nto three examples including two case studies in finance and epidemiology. The\nresults confirm the convergence of the approach for estimating the sensitivity\nindices even with the presence of strong heteroskedasticity and small\nsignal-to-noise ratio.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 08:03:31 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 16:45:43 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 13:32:39 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 09:56:02 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhu", "X.", ""], ["Sudret", "B.", ""]]}, {"id": "2005.01317", "submitter": "Jicong Fan", "authors": "Jicong Fan, Chengrun Yang, Madeleine Udell", "title": "Robust Non-Linear Matrix Factorization for Dictionary Learning,\n  Denoising, and Clustering", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing 69, 1755-1770 (2021)", "doi": "10.1109/TSP.2021.3062988", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low dimensional nonlinear structure abounds in datasets across computer\nvision and machine learning. Kernelized matrix factorization techniques have\nrecently been proposed to learn these nonlinear structures for denoising,\nclassification, dictionary learning, and missing data imputation, by observing\nthat the image of the matrix in a sufficiently large feature space is low-rank.\nHowever, these nonlinear methods fail in the presence of sparse noise or\noutliers. In this work, we propose a new robust nonlinear factorization method\ncalled Robust Non-Linear Matrix Factorization (RNLMF). RNLMF constructs a\ndictionary for the data space by factoring a kernelized feature space; a noisy\nmatrix can then be decomposed as the sum of a sparse noise matrix and a clean\ndata matrix that lies in a low dimensional nonlinear manifold. RNLMF is robust\nto sparse noise and outliers and scales to matrices with thousands of rows and\ncolumns. Empirically, RNLMF achieves noticeable improvements over baseline\nmethods in denoising and clustering.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 08:32:21 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 08:51:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Fan", "Jicong", ""], ["Yang", "Chengrun", ""], ["Udell", "Madeleine", ""]]}, {"id": "2005.01350", "submitter": "Quanquan Gu", "authors": "Yue Wu and Weitong Zhang and Pan Xu and Quanquan Gu", "title": "A Finite Time Analysis of Two Time-Scale Actor Critic Methods", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor-critic (AC) methods have exhibited great empirical success compared\nwith other reinforcement learning algorithms, where the actor uses the policy\ngradient to improve the learning policy and the critic uses temporal difference\nlearning to estimate the policy gradient. Under the two time-scale learning\nrate schedule, the asymptotic convergence of AC has been well studied in the\nliterature. However, the non-asymptotic convergence and finite sample\ncomplexity of actor-critic methods are largely open. In this work, we provide a\nnon-asymptotic analysis for two time-scale actor-critic methods under\nnon-i.i.d. setting. We prove that the actor-critic method is guaranteed to find\na first-order stationary point (i.e., $\\|\\nabla J(\\boldsymbol{\\theta})\\|_2^2\n\\le \\epsilon$) of the non-concave performance function\n$J(\\boldsymbol{\\theta})$, with $\\mathcal{\\tilde{O}}(\\epsilon^{-2.5})$ sample\ncomplexity. To the best of our knowledge, this is the first work providing\nfinite-time analysis and sample complexity bound for two time-scale\nactor-critic methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 09:45:18 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 01:18:58 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Wu", "Yue", ""], ["Zhang", "Weitong", ""], ["Xu", "Pan", ""], ["Gu", "Quanquan", ""]]}, {"id": "2005.01378", "submitter": "Yu Cheng", "authors": "Yu Cheng, Ilias Diakonikolas, Rong Ge, Mahdi Soltanolkotabi", "title": "High-Dimensional Robust Mean Estimation via Gradient Descent", "comments": "Under submission to ICML'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of high-dimensional robust mean estimation in the\npresence of a constant fraction of adversarial outliers. A recent line of work\nhas provided sophisticated polynomial-time algorithms for this problem with\ndimension-independent error guarantees for a range of natural distribution\nfamilies.\n  In this work, we show that a natural non-convex formulation of the problem\ncan be solved directly by gradient descent. Our approach leverages a novel\nstructural lemma, roughly showing that any approximate stationary point of our\nnon-convex objective gives a near-optimal solution to the underlying robust\nestimation task. Our work establishes an intriguing connection between\nalgorithmic high-dimensional robust statistics and non-convex optimization,\nwhich may have broader applications to other robust estimation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 10:48:04 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Cheng", "Yu", ""], ["Diakonikolas", "Ilias", ""], ["Ge", "Rong", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2005.01404", "submitter": "Christian Alexander Schroth", "authors": "Christian A. Schroth and Michael Muma", "title": "Robust M-Estimation Based Bayesian Cluster Enumeration for Real\n  Elliptically Symmetric Distributions", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3072482", "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustly determining the optimal number of clusters in a data set is an\nessential factor in a wide range of applications. Cluster enumeration becomes\nchallenging when the true underlying structure in the observed data is\ncorrupted by heavy-tailed noise and outliers. Recently, Bayesian cluster\nenumeration criteria have been derived by formulating cluster enumeration as\nmaximization of the posterior probability of candidate models. This article\ngeneralizes robust Bayesian cluster enumeration so that it can be used with any\narbitrary Real Elliptically Symmetric (RES) distributed mixture model. Our\nframework also covers the case of M-estimators that allow for mixture models,\nwhich are decoupled from a specific probability distribution. Examples of\nHuber's and Tukey's M-estimators are discussed. We derive a robust criterion\nfor data sets with finite sample size, and also provide an asymptotic\napproximation to reduce the computational cost at large sample sizes. The\nalgorithms are applied to simulated and real-world data sets, including\nradar-based person identification, and show a significant robustness\nimprovement in comparison to existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 11:44:49 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 09:32:57 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 09:53:12 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Schroth", "Christian A.", ""], ["Muma", "Michael", ""]]}, {"id": "2005.01427", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "LIMEtree: Interactively Customisable Explanations Based on Local\n  Surrogate Multi-output Regression Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems based on artificial intelligence and machine learning models should\nbe transparent, in the sense of being capable of explaining their decisions to\ngain humans' approval and trust. While there are a number of explainability\ntechniques that can be used to this end, many of them are only capable of\noutputting a single one-size-fits-all explanation that simply cannot address\nall of the explainees' diverse needs. In this work we introduce a\nmodel-agnostic and post-hoc local explainability technique for black-box\npredictions called LIMEtree, which employs surrogate multi-output regression\ntrees. We validate our algorithm on a deep neural network trained for object\ndetection in images and compare it against Local Interpretable Model-agnostic\nExplanations (LIME). Our method comes with local fidelity guarantees and can\nproduce a range of diverse explanation types, including contrastive and\ncounterfactual explanations praised in the literature. Some of these\nexplanations can be interactively personalised to create bespoke, meaningful\nand actionable insights into the model's behaviour. While other methods may\ngive an illusion of customisability by wrapping, otherwise static, explanations\nin an interactive interface, our explanations are truly interactive, in the\nsense of allowing the user to \"interrogate\" a black-box model. LIMEtree can\ntherefore produce consistent explanations on which an interactive exploratory\nprocess can be built.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 12:31:29 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2005.01432", "submitter": "Hany Abdulsamad", "authors": "Hany Abdulsamad and Jan Peters", "title": "Hierarchical Decomposition of Nonlinear Dynamics and Control for System\n  Identification and Policy Distillation", "comments": "2nd Annual Conference on Learning for Dynamics and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control of nonlinear dynamical systems remains a major challenge for\nautonomous agents. Current trends in reinforcement learning (RL) focus on\ncomplex representations of dynamics and policies, which have yielded impressive\nresults in solving a variety of hard control tasks. However, this new\nsophistication and extremely over-parameterized models have come with the cost\nof an overall reduction in our ability to interpret the resulting policies. In\nthis paper, we take inspiration from the control community and apply the\nprinciples of hybrid switching systems in order to break down complex dynamics\ninto simpler components. We exploit the rich representational power of\nprobabilistic graphical models and derive an expectation-maximization (EM)\nalgorithm for learning a sequence model to capture the temporal structure of\nthe data and automatically decompose nonlinear dynamics into stochastic\nswitching linear dynamical systems. Moreover, we show how this framework of\nswitching models enables extracting hierarchies of Markovian and\nauto-regressive locally linear controllers from nonlinear experts in an\nimitation learning scenario.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 12:40:59 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:54:33 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Abdulsamad", "Hany", ""], ["Peters", "Jan", ""]]}, {"id": "2005.01446", "submitter": "Aly El Gamal", "authors": "Abu Shafin Mohammad Mahdee Jameel, Ahmed P. Mohamed, Xiwen Zhang, Aly\n  El Gamal", "title": "Deep Learning for Frame Error Prediction using a DARPA Spectrum\n  Collaboration Challenge (SC2) Dataset", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a first example for employing deep learning in predicting\nframe errors for a Collaborative Intelligent Radio Network (CIRN) using a\ndataset collected during participation in the final scrimmages of the DARPA SC2\nchallenge. Four scenarios are considered based on randomizing or fixing the\nstrategy for bandwidth and channel allocation, and either training and testing\nwith different links or using a pilot phase for each link to train the deep\nneural network. We also investigate the effect of latency constraints, and\nuncover interesting characteristics of the predictor over different Signal to\nNoise Ratio (SNR) ranges. The obtained insights open the door for implementing\na deep-learning-based strategy that is scalable to large heterogeneous\nnetworks, generalizable to diverse wireless environments, and suitable for\npredicting frame error instances and rates within a congested shared spectrum.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 04:53:38 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 01:32:56 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jameel", "Abu Shafin Mohammad Mahdee", ""], ["Mohamed", "Ahmed P.", ""], ["Zhang", "Xiwen", ""], ["Gamal", "Aly El", ""]]}, {"id": "2005.01449", "submitter": "Chun-Guang Li", "authors": "Ying Chen, Chun-Guang Li, and Chong You", "title": "Stochastic Sparse Subspace Clustering", "comments": "16 pages, 9 figures and 8 tables. This work is accepted by IEEE\n  Conference on Computer Vision and Pattern Recognition (CVPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art subspace clustering methods are based on self-expressive\nmodel, which represents each data point as a linear combination of other data\npoints. By enforcing such representation to be sparse, sparse subspace\nclustering is guaranteed to produce a subspace-preserving data affinity where\ntwo points are connected only if they are from the same subspace. On the other\nhand, however, data points from the same subspace may not be well-connected,\nleading to the issue of over-segmentation. We introduce dropout to address the\nissue of over-segmentation, which is based on randomly dropping out data points\nin self-expressive model. In particular, we show that dropout is equivalent to\nadding a squared $\\ell_2$ norm regularization on the representation\ncoefficients, therefore induces denser solutions. Then, we reformulate the\noptimization problem as a consensus problem over a set of small-scale\nsubproblems. This leads to a scalable and flexible sparse subspace clustering\napproach, termed Stochastic Sparse Subspace Clustering, which can effectively\nhandle large scale datasets. Extensive experiments on synthetic data and real\nworld datasets validate the efficiency and effectiveness of our proposal.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:09:17 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chen", "Ying", ""], ["Li", "Chun-Guang", ""], ["You", "Chong", ""]]}, {"id": "2005.01452", "submitter": "Marco Melis", "authors": "Marco Melis, Michele Scalas, Ambra Demontis, Davide Maiorca, Battista\n  Biggio, Giorgio Giacinto, Fabio Roli", "title": "Do Gradient-based Explanations Tell Anything About Adversarial\n  Robustness to Android Malware?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine-learning algorithms have demonstrated a strong ability in\ndetecting Android malware, they can be evaded by sparse evasion attacks crafted\nby injecting a small set of fake components, e.g., permissions and system\ncalls, without compromising intrusive functionality. Previous work has shown\nthat, to improve robustness against such attacks, learning algorithms should\navoid overemphasizing few discriminant features, providing instead decisions\nthat rely upon a large subset of components. In this work, we investigate\nwhether gradient-based attribution methods, used to explain classifiers'\ndecisions by identifying the most relevant features, can be used to help\nidentify and select more robust algorithms. To this end, we propose to exploit\ntwo different metrics that represent the evenness of explanations, and a new\ncompact security measure called Adversarial Robustness Metric. Our experiments\nconducted on two different datasets and five classification algorithms for\nAndroid malware detection show that a strong connection exists between the\nuniformity of explanations and adversarial robustness. In particular, we found\nthat popular techniques like Gradient*Input and Integrated Gradients are\nstrongly correlated to security when applied to both linear and nonlinear\ndetectors, while more elementary explanation techniques like the simple\nGradient do not provide reliable information about the robustness of such\nclassifiers.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:12:31 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 15:58:04 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Melis", "Marco", ""], ["Scalas", "Michele", ""], ["Demontis", "Ambra", ""], ["Maiorca", "Davide", ""], ["Biggio", "Battista", ""], ["Giacinto", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "2005.01463", "submitter": "Chiyu Jiang", "authors": "Chiyu Max Jiang, Soheil Esmaeilzadeh, Kamyar Azizzadenesheli, Karthik\n  Kashinath, Mustafa Mustafa, Hamdi A. Tchelepi, Philip Marcus, Prabhat, Anima\n  Anandkumar", "title": "MeshfreeFlowNet: A Physics-Constrained Deep Continuous Space-Time\n  Super-Resolution Framework", "comments": "Supplementary Video: https://youtu.be/mjqwPch9gDo. Accepted to SC20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose MeshfreeFlowNet, a novel deep learning-based super-resolution\nframework to generate continuous (grid-free) spatio-temporal solutions from the\nlow-resolution inputs. While being computationally efficient, MeshfreeFlowNet\naccurately recovers the fine-scale quantities of interest. MeshfreeFlowNet\nallows for: (i) the output to be sampled at all spatio-temporal resolutions,\n(ii) a set of Partial Differential Equation (PDE) constraints to be imposed,\nand (iii) training on fixed-size inputs on arbitrarily sized spatio-temporal\ndomains owing to its fully convolutional encoder. We empirically study the\nperformance of MeshfreeFlowNet on the task of super-resolution of turbulent\nflows in the Rayleigh-Benard convection problem. Across a diverse set of\nevaluation metrics, we show that MeshfreeFlowNet significantly outperforms\nexisting baselines. Furthermore, we provide a large scale implementation of\nMeshfreeFlowNet and show that it efficiently scales across large clusters,\nachieving 96.80% scaling efficiency on up to 128 GPUs and a training time of\nless than 4 minutes.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 05:29:25 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 04:08:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Jiang", "Chiyu Max", ""], ["Esmaeilzadeh", "Soheil", ""], ["Azizzadenesheli", "Kamyar", ""], ["Kashinath", "Karthik", ""], ["Mustafa", "Mustafa", ""], ["Tchelepi", "Hamdi A.", ""], ["Marcus", "Philip", ""], ["Prabhat", "", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2005.01492", "submitter": "Xiancai Tian", "authors": "Xiancai Tian, Baihua Zheng, Yazhe Wang, Hsiao-Ting Huang, Chih-Chieh\n  Hung", "title": "TRIPDECODER: Study Travel Time Attributes and Route Preferences of Metro\n  Systems from Smart Card Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we target at recovering the exact routes taken by commuters\ninside a metro system that arenot captured by an Automated Fare Collection\n(AFC) system and hence remain unknown. We strategicallypropose two inference\ntasks to handle the recovering, one to infer the travel time of each travel\nlink thatcontributes to the total duration of any trip inside a metro network\nand the other to infer the route preferencesbased on historical trip records\nand the travel time of each travel link inferred in the previous inferencetask.\nAs these two inference tasks have interrelationship, most of existing works\nperform these two taskssimultaneously. However, our solutionTripDecoderadopts a\ntotally different approach. To the best of ourknowledge,TripDecoderis the first\nmodel that points out and fully utilizes the fact that there are some\ntripsinside a metro system with only one practical route available. It\nstrategically decouples these two inferencetasks by only taking those trip\nrecords with only one practical route as the input for the first inference\ntaskof travel time and feeding the inferred travel time to the second inference\ntask as an additional input whichnot only improves the accuracy but also\neffectively reduces the complexity of both inference tasks. Twocase studies\nhave been performed based on the city-scale real trip records captured by the\nAFC systems inSingapore and Taipei to compare the accuracy and efficiency\nofTripDecoderand its competitors. As expected,TripDecoderhas achieved the best\naccuracy in both datasets, and it also demonstrates its superior efficiencyand\nscalability.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 08:39:48 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Tian", "Xiancai", ""], ["Zheng", "Baihua", ""], ["Wang", "Yazhe", ""], ["Huang", "Hsiao-Ting", ""], ["Hung", "Chih-Chieh", ""]]}, {"id": "2005.01538", "submitter": "Sandor Szedmak", "authors": "Sandor Szedmak (1), Anna Cichonska (1), Heli Julkunen (1), Tapio\n  Pahikkala (2), Juho Rousu (1), ((1) Aalto University, (2) University of\n  Turku)", "title": "A Solution for Large Scale Nonlinear Regression with High Rank and\n  Degree at Constant Memory Complexity via Latent Tensor Reconstruction", "comments": "14 pages, 8 figures, uses arxiv.sty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel method for learning highly nonlinear,\nmultivariate functions from examples. Our method takes advantage of the\nproperty that continuous functions can be approximated by polynomials, which in\nturn are representable by tensors. Hence the function learning problem is\ntransformed into a tensor reconstruction problem, an inverse problem of the\ntensor decomposition. Our method incrementally builds up the unknown tensor\nfrom rank-one terms, which lets us control the complexity of the learned model\nand reduce the chance of overfitting. For learning the models, we present an\nefficient gradient-based algorithm that can be implemented in linear time in\nthe sample size, order, rank of the tensor and the dimension of the input. In\naddition to regression, we present extensions to classification, multi-view\nlearning and vector-valued output as well as a multi-layered formulation. The\nmethod can work in an online fashion via processing mini-batches of the data\nwith constant memory complexity. Consequently, it can fit into systems equipped\nonly with limited resources such as embedded systems or mobile phones. Our\nexperiments demonstrate a favorable accuracy and running time compared to\ncompeting methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:49:14 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Szedmak", "Sandor", ""], ["Cichonska", "Anna", ""], ["Julkunen", "Heli", ""], ["Pahikkala", "Tapio", ""], ["Rousu", "Juho", ""]]}, {"id": "2005.01557", "submitter": "Rama K Vasudevan", "authors": "Rama K. Vasudevan, Maxim Ziatdinov, Lukas Vlcek, Sergei V. Kalinin", "title": "Off-the-shelf deep learning is not enough: parsimony, Bayes and\n  causality", "comments": "3 figures, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (\"deep learning\") have emerged as a technology of choice\nto tackle problems in natural language processing, computer vision, speech\nrecognition and gameplay, and in just a few years has led to superhuman level\nperformance and ushered in a new wave of \"AI.\" Buoyed by these successes,\nresearchers in the physical sciences have made steady progress in incorporating\ndeep learning into their respective domains. However, such adoption brings\nsubstantial challenges that need to be recognized and confronted. Here, we\ndiscuss both opportunities and roadblocks to implementation of deep learning\nwithin materials science, focusing on the relationship between correlative\nnature of machine learning and causal hypothesis driven nature of physical\nsciences. We argue that deep learning and AI are now well positioned to\nrevolutionize fields where causal links are known, as is the case for\napplications in theory. When confounding factors are frozen or change only\nweakly, this leaves open the pathway for effective deep learning solutions in\nexperimental domains. Similarly, these methods offer a pathway towards\nunderstanding the physics of real-world systems, either via deriving reduced\nrepresentations, deducing algorithmic complexity, or recovering generative\nphysical models. However, extending deep learning and \"AI\" for models with\nunclear causal relationship can produce misleading and potentially incorrect\nresults. Here, we argue the broad adoption of Bayesian methods incorporating\nprior knowledge, development of DL solutions with incorporated physical\nconstraints, and ultimately adoption of causal models, offers a path forward\nfor fundamental and applied research. Most notably, while these advances can\nchange the way science is carried out in ways we cannot imagine, machine\nlearning is not going to substitute science any time soon.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:16:30 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Vasudevan", "Rama K.", ""], ["Ziatdinov", "Maxim", ""], ["Vlcek", "Lukas", ""], ["Kalinin", "Sergei V.", ""]]}, {"id": "2005.01560", "submitter": "Burak \\c{C}akmak", "authors": "Burak \\c{C}akmak and Manfred Opper", "title": "A Dynamical Mean-Field Theory for Learning in Restricted Boltzmann\n  Machines", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": "10.1088/1742-5468/abb8c9", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a message-passing algorithm for computing magnetizations in\nRestricted Boltzmann machines, which are Ising models on bipartite graphs\nintroduced as neural network models for probability distributions over spin\nconfigurations. To model nontrivial statistical dependencies between the spins'\ncouplings, we assume that the rectangular coupling matrix is drawn from an\narbitrary bi-rotation invariant random matrix ensemble. Using the dynamical\nfunctional method of statistical mechanics we exactly analyze the dynamics of\nthe algorithm in the large system limit. We prove the global convergence of the\nalgorithm under a stability criterion and compute asymptotic convergence rates\nshowing excellent agreement with numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:19:31 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["\u00c7akmak", "Burak", ""], ["Opper", "Manfred", ""]]}, {"id": "2005.01566", "submitter": "Amitabha Bagchi", "authors": "Amitabha Bagchi", "title": "Lecture notes: Efficient approximation of kernel functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These lecture notes endeavour to collect in one place the mathematical\nbackground required to understand the properties of kernels in general and the\nRandom Fourier Features approximation of Rahimi and Recht (NIPS 2007) in\nparticular. We briefly motivate the use of kernels in Machine Learning with the\nexample of the support vector machine. We discuss positive definite and\nconditionally negative definite kernels in some detail. After a brief\ndiscussion of Hilbert spaces, including the Reproducing Kernel Hilbert Space\nconstruction, we present Mercer's theorem. We discuss the Random Fourier\nFeatures technique and then present, with proofs, scalar and matrix\nconcentration results that help us estimate the error incurred by the\ntechnique. These notes are the transcription of 10 lectures given at IIT Delhi\nbetween January and April 2020.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:30:06 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bagchi", "Amitabha", ""]]}, {"id": "2005.01571", "submitter": "Qingyun Wu", "authors": "Qingyun Wu, Chi Wang, Silu Huang", "title": "Frugal Optimization for Cost-related Hyperparameters", "comments": "29 pages (including supplementary appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing demand for democratizing machine learning algorithms calls for\nhyperparameter optimization (HPO) solutions at low cost. Many machine learning\nalgorithms have hyperparameters which can cause a large variation in the\ntraining cost. But this effect is largely ignored in existing HPO methods,\nwhich are incapable to properly control cost during the optimization process.\nTo address this problem, we develop a new cost-frugal HPO solution. The core of\nour solution is a simple but new randomized direct-search method, for which we\nprove a convergence rate of $O(\\frac{\\sqrt{d}}{\\sqrt{K}})$ and an\n$O(d\\epsilon^{-2})$-approximation guarantee on the total cost. We provide\nstrong empirical results in comparison with state-of-the-art HPO methods on\nlarge AutoML benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:40:44 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 04:47:31 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 20:48:40 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Wu", "Qingyun", ""], ["Wang", "Chi", ""], ["Huang", "Silu", ""]]}, {"id": "2005.01573", "submitter": "Fei Mi", "authors": "Fei Mi, Boi Faltings", "title": "Memory Augmented Neural Model for Incremental Session-based\n  Recommendation", "comments": "Accepted as a full paper at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing concerns with privacy have stimulated interests in Session-based\nRecommendation (SR) using no personal data other than what is observed in the\ncurrent browser session. Existing methods are evaluated in static settings\nwhich rarely occur in real-world applications. To better address the dynamic\nnature of SR tasks, we study an incremental SR scenario, where new items and\npreferences appear continuously. We show that existing neural recommenders can\nbe used in incremental SR scenarios with small incremental updates to alleviate\ncomputation overhead and catastrophic forgetting. More importantly, we propose\na general framework called Memory Augmented Neural model (MAN). MAN augments a\nbase neural recommender with a continuously queried and updated nonparametric\nmemory, and the predictions from the neural and the memory components are\ncombined through another lightweight gating network. We empirically show that\nMAN is well-suited for the incremental SR task, and it consistently outperforms\nstate-of-the-art neural and nonparametric methods. We analyze the results and\ndemonstrate that it is particularly good at incrementally learning preferences\non new and infrequent items.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 19:07:20 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mi", "Fei", ""], ["Faltings", "Boi", ""]]}, {"id": "2005.01575", "submitter": "Angelos Chatzimparmpas", "authors": "Angelos Chatzimparmpas, Rafael M. Martins, Kostiantyn Kucher, Andreas\n  Kerren", "title": "StackGenVis: Alignment of Data, Algorithms, and Models for Stacking\n  Ensemble Learning Using Performance Metrics", "comments": "This manuscript is accepted for publication in a special issue of\n  IEEE Transactions on Visualization and Computer Graphics Journal (IEEE TVCG)", "journal-ref": "IEEE TVCG 2021, 27(2), 1547-1557", "doi": "10.1109/TVCG.2020.3030352", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning (ML), ensemble methods such as bagging, boosting, and\nstacking are widely-established approaches that regularly achieve top-notch\npredictive performance. Stacking (also called \"stacked generalization\") is an\nensemble method that combines heterogeneous base models, arranged in at least\none layer, and then employs another metamodel to summarize the predictions of\nthose models. Although it may be a highly-effective approach for increasing the\npredictive performance of ML, generating a stack of models from scratch can be\na cumbersome trial-and-error process. This challenge stems from the enormous\nspace of available solutions, with different sets of data instances and\nfeatures that could be used for training, several algorithms to choose from,\nand instantiations of these algorithms using diverse parameters (i.e., models)\nthat perform differently according to various metrics. In this work, we present\na knowledge generation model, which supports ensemble learning with the use of\nvisualization, and a visual analytics system for stacked generalization. Our\nsystem, StackGenVis, assists users in dynamically adapting performance metrics,\nmanaging data instances, selecting the most important features for a given data\nset, choosing a set of top-performant and diverse algorithms, and measuring the\npredictive performance. In consequence, our proposed tool helps users to decide\nbetween distinct models and to reduce the complexity of the resulting stack by\nremoving overpromising and underperforming models. The applicability and\neffectiveness of StackGenVis are demonstrated with two use cases: a real-world\nhealthcare data set and a collection of data related to sentiment/stance\ndetection in texts. Finally, the tool has been evaluated through interviews\nwith three ML experts.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:43:55 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 11:24:33 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 23:11:02 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 13:31:01 GMT"}, {"version": "v5", "created": "Mon, 24 Aug 2020 20:12:29 GMT"}, {"version": "v6", "created": "Fri, 28 Aug 2020 13:25:32 GMT"}, {"version": "v7", "created": "Thu, 17 Sep 2020 05:09:01 GMT"}, {"version": "v8", "created": "Tue, 1 Dec 2020 20:44:22 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chatzimparmpas", "Angelos", ""], ["Martins", "Rafael M.", ""], ["Kucher", "Kostiantyn", ""], ["Kerren", "Andreas", ""]]}, {"id": "2005.01609", "submitter": "Xingyu Li", "authors": "Xingyu Li, Konstantinos N. Plataniotis", "title": "How Much Off-The-Shelf Knowledge Is Transferable From Natural Images To\n  Pathology Images?", "comments": "Experimentation data correction", "journal-ref": null, "doi": "10.1371/journal.pone.0240530", "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved a great success in natural image classification.\nTo overcome data-scarcity in computational pathology, recent studies exploit\ntransfer learning to reuse knowledge gained from natural images in pathology\nimage analysis, aiming to build effective pathology image diagnosis models.\nSince transferability of knowledge heavily depends on the similarity of the\noriginal and target tasks, significant differences in image content and\nstatistics between pathology images and natural images raise the questions: how\nmuch knowledge is transferable? Is the transferred information equally\ncontributed by pre-trained layers? To answer these questions, this paper\nproposes a framework to quantify knowledge gain by a particular layer, conducts\nan empirical investigation in pathology image centered transfer learning, and\nreports some interesting observations. Particularly, compared to the\nperformance baseline obtained by random-weight model, though transferability of\noff-the-shelf representations from deep layers heavily depend on specific\npathology image sets, the general representation generated by early layers does\nconvey transferred knowledge in various image classification applications. The\nobservation in this study encourages further investigation of specific metric\nand tools to quantify effectiveness and feasibility of transfer learning in\nfuture.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 21:29:10 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 15:31:03 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 01:44:42 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Li", "Xingyu", ""], ["Plataniotis", "Konstantinos N.", ""]]}, {"id": "2005.01643", "submitter": "Sergey Levine", "authors": "Sergey Levine, Aviral Kumar, George Tucker, Justin Fu", "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on\n  Open Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial article, we aim to provide the reader with the conceptual\ntools needed to get started on research on offline reinforcement learning\nalgorithms: reinforcement learning algorithms that utilize previously collected\ndata, without additional online data collection. Offline reinforcement learning\nalgorithms hold tremendous promise for making it possible to turn large\ndatasets into powerful decision making engines. Effective offline reinforcement\nlearning methods would be able to extract policies with the maximum possible\nutility out of the available data, thereby allowing automation of a wide range\nof decision-making domains, from healthcare and education to robotics. However,\nthe limitations of current algorithms make this difficult. We will aim to\nprovide the reader with an understanding of these challenges, particularly in\nthe context of modern deep reinforcement learning methods, and describe some\npotential solutions that have been explored in recent work to mitigate these\nchallenges, along with recent applications, and a discussion of perspectives on\nopen problems in the field.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:00:15 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 17:37:01 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 23:50:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Levine", "Sergey", ""], ["Kumar", "Aviral", ""], ["Tucker", "George", ""], ["Fu", "Justin", ""]]}, {"id": "2005.01656", "submitter": "Matthieu Jedor", "authors": "Matthieu Jedor, Jonathan Louedec, Vianney Perchet", "title": "Categorized Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new stochastic multi-armed bandit setting where arms are\ngrouped inside ``ordered'' categories. The motivating example comes from\ne-commerce, where a customer typically has a greater appetence for items of a\nspecific well-identified but unknown category than any other one. We introduce\nthree concepts of ordering between categories, inspired by stochastic dominance\nbetween random variables, which are gradually weaker so that more and more\nbandit scenarios satisfy at least one of them. We first prove\ninstance-dependent lower bounds on the cumulative regret for each of these\nmodels, indicating how the complexity of the bandit problems increases with the\ngenerality of the ordering concept considered. We also provide algorithms that\nfully leverage the structure of the model with their associated theoretical\nguarantees. Finally, we have conducted an analysis on real data to highlight\nthat those ordered categories actually exist in practice.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:09:22 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jedor", "Matthieu", ""], ["Louedec", "Jonathan", ""], ["Perchet", "Vianney", ""]]}, {"id": "2005.01698", "submitter": "Fredrik K. Gustafsson", "authors": "Fredrik K. Gustafsson, Martin Danelljan, Radu Timofte, Thomas B.\n  Sch\\\"on", "title": "How to Train Your Energy-Based Model for Regression", "comments": "BMVC 2020. Code is available at\n  https://github.com/fregu856/ebms_regression", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs) have become increasingly popular within computer\nvision in recent years. While they are commonly employed for generative image\nmodeling, recent work has applied EBMs also for regression tasks, achieving\nstate-of-the-art performance on object detection and visual tracking. Training\nEBMs is however known to be challenging. While a variety of different\ntechniques have been explored for generative modeling, the application of EBMs\nto regression is not a well-studied problem. How EBMs should be trained for\nbest possible regression performance is thus currently unclear. We therefore\naccept the task of providing the first detailed study of this problem. To that\nend, we propose a simple yet highly effective extension of noise contrastive\nestimation, and carefully compare its performance to six popular methods from\nliterature on the tasks of 1D regression and object detection. The results of\nthis comparison suggest that our training method should be considered the go-to\napproach. We also apply our method to the visual tracking task, achieving\nstate-of-the-art performance on five datasets. Notably, our tracker achieves\n63.7% AUC on LaSOT and 78.7% Success on TrackingNet. Code is available at\nhttps://github.com/fregu856/ebms_regression.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:55:01 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 10:08:52 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Gustafsson", "Fredrik K.", ""], ["Danelljan", "Martin", ""], ["Timofte", "Radu", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "2005.01699", "submitter": "Anirbit Mukherjee", "authors": "Anirbit Mukherjee and Ramchandran Muthukumar", "title": "Guarantees on learning depth-2 neural networks under a data-poisoning\n  attack", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times many state-of-the-art machine learning models have been shown\nto be fragile to adversarial attacks. In this work we attempt to build our\ntheoretical understanding of adversarially robust learning with neural nets. We\ndemonstrate a specific class of neural networks of finite size and a\nnon-gradient stochastic algorithm which tries to recover the weights of the net\ngenerating the realizable true labels in the presence of an oracle doing a\nbounded amount of malicious additive distortion to the labels. We prove (nearly\noptimal) trade-offs among the magnitude of the adversarial attack, the accuracy\nand the confidence achieved by the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:56:15 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mukherjee", "Anirbit", ""], ["Muthukumar", "Ramchandran", ""]]}, {"id": "2005.01711", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Dual Stage Classification of Hand Gestures using Surface Electromyogram", "comments": "arXiv admin note: text overlap with arXiv:2005.00410", "journal-ref": null, "doi": "10.1109/SPIN.2018.8474145", "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface electromyography (sEMG) is becoming exceeding useful in applications\ninvolving analysis of human motion such as in human-machine interface,\nassistive technology, healthcare and prosthetic development. The proposed work\npresents a novel dual stage classification approach for classification of\ngrasping gestures from sEMG signals. A statistical assessment of these\nactivities is presented to determine the similar characteristics between the\nconsidered activities. Similar activities are grouped together. In the first\nstage of classification, an activity is identified as belonging to a group,\nwhich is then further classified as one of the activities within the group in\nthe second stage of classification. The performance of the proposed approach is\ncompared to the conventional single stage classification approach in terms of\nclassification accuracies. The classification accuracies obtained using the\nproposed dual stage classification are significantly higher as compared to that\nfor single stage classification.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:11:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.01752", "submitter": "Jonathan Tuck", "authors": "Jonathan Tuck, Stephen Boyd", "title": "Fitting Laplacian Regularized Stratified Gaussian Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of jointly estimating multiple related zero-mean\nGaussian distributions from data. We propose to jointly estimate these\ncovariance matrices using Laplacian regularized stratified model fitting, which\nincludes loss and regularization terms for each covariance matrix, and also a\nterm that encourages the different covariances matrices to be close. This\nmethod `borrows strength' from the neighboring covariances, to improve its\nestimate. With well chosen hyper-parameters, such models can perform very well,\nespecially in the low data regime. We propose a distributed method that scales\nto large problems, and illustrate the efficacy of the method with examples in\nfinance, radar signal processing, and weather forecasting.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 18:00:59 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 16:22:53 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Tuck", "Jonathan", ""], ["Boyd", "Stephen", ""]]}, {"id": "2005.01757", "submitter": "Lee Cohen", "authors": "Eliran Shabat, Lee Cohen and Yishay Mansour", "title": "Sample Complexity of Uniform Convergence for Multicalibration", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in societal concerns in machine learning systems,\nespecially in fairness. Multicalibration gives a comprehensive methodology to\naddress group fairness. In this work, we address the multicalibration error and\ndecouple it from the prediction error. The importance of decoupling the\nfairness metric (multicalibration) and the accuracy (prediction error) is due\nto the inherent trade-off between the two, and the societal decision regarding\nthe \"right tradeoff\" (as imposed many times by regulators). Our work gives\nsample complexity bounds for uniform convergence guarantees of multicalibration\nerror, which implies that regardless of the accuracy, we can guarantee that the\nempirical and (true) multicalibration errors are close. We emphasize that our\nresults: (1) are more general than previous bounds, as they apply to both\nagnostic and realizable settings, and do not rely on a specific type of\nalgorithm (such as deferentially private), (2) improve over previous\nmulticalibration sample complexity bounds and (3) implies uniform convergence\nguarantees for the classical calibration error.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 18:01:38 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:28:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shabat", "Eliran", ""], ["Cohen", "Lee", ""], ["Mansour", "Yishay", ""]]}, {"id": "2005.01795", "submitter": "Kundan Krishna", "authors": "Kundan Krishna, Sopan Khosla, Jeffrey P. Bigham, Zachary C. Lipton", "title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular\n  Summarization Techniques", "comments": "Published at ACL 2021 Main Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following each patient visit, physicians draft long semi-structured clinical\nsummaries called SOAP notes. While invaluable to clinicians and researchers,\ncreating digital SOAP notes is burdensome, contributing to physician burnout.\nIn this paper, we introduce the first complete pipelines to leverage deep\nsummarization models to generate these notes based on transcripts of\nconversations between physicians and patients. After exploring a spectrum of\nmethods across the extractive-abstractive spectrum, we propose Cluster2Sent, an\nalgorithm that (i) extracts important utterances relevant to each summary\nsection; (ii) clusters together related utterances; and then (iii) generates\none summary sentence per cluster. Cluster2Sent outperforms its purely\nabstractive counterpart by 8 ROUGE-1 points, and produces significantly more\nfactual and coherent sentences as assessed by expert human evaluators. For\nreproducibility, we demonstrate similar benefits on the publicly available AMI\ndataset. Our results speak to the benefits of structuring summaries into\nsections and annotating supporting evidence when constructing summarization\ncorpora.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:10:26 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 04:09:10 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 14:48:09 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Krishna", "Kundan", ""], ["Khosla", "Sopan", ""], ["Bigham", "Jeffrey P.", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2005.01798", "submitter": "Vasundhra Iyengar", "authors": "Vasundhra Iyengar, Azra Bihorac, Parisa Rashidi", "title": "Automated Detection of Rest Disruptions in Critically Ill Patients", "comments": null, "journal-ref": "2020 42nd Annual International Conference of the IEEE Engineering\n  in Medicine & Biology Society (EMBC), Montreal, QC, Canada, 2020, pp.\n  5450-5454", "doi": "10.1109/EMBC44109.2020.9175252", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep has been shown to be an indispensable and important component of\npatients recovery process. Nonetheless, sleep quality of patients in the\nIntensive Care Unit (ICU) is often low, due to factors such as noise, pain, and\nfrequent nursing care activities. Frequent sleep disruptions by the medical\nstaff and/or visitors at certain times might lead to disruption of patient\nsleep-wake cycle and can also impact the severity of pain. Examining the\nassociation between sleep quality and frequent visitation has been difficult,\ndue to lack of automated methods for visitation detection. In this study, we\nrecruited 38 patients to automatically assess visitation frequency from\ncaptured video frames. We used the DensePose R-CNN (ResNet-101) model to\ncalculate the number of people in the room in a video frame. We examined when\npatients are interrupted the most, and we examined the association between\nfrequent disruptions and patient outcomes on pain and length of stay.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:22:24 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 19:31:02 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Iyengar", "Vasundhra", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2005.01800", "submitter": "Michael Smith", "authors": "Michael R. Smith, Nicholas T. Johnson, Joe B. Ingram, Armida J.\n  Carbajal, Ramyaa Ramyaa, Evelyn Domschot, Christopher C. Lamb, Stephen J.\n  Verzi, W. Philip Kegelmeyer", "title": "Mind the Gap: On Bridging the Semantic Gap between Machine Learning and\n  Information Security", "comments": "14 pages, 2 Figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the potential of Machine learning (ML) to learn the behavior of\nmalware, detect novel malware samples, and significantly improve information\nsecurity (InfoSec) we see few, if any, high-impact ML techniques in deployed\nsystems, notwithstanding multiple reported successes in open literature. We\nhypothesize that the failure of ML in making high-impacts in InfoSec are rooted\nin a disconnect between the two communities as evidenced by a semantic gap---a\ndifference in how executables are described (e.g. the data and features\nextracted from the data). Specifically, current datasets and representations\nused by ML are not suitable for learning the behaviors of an executable and\ndiffer significantly from those used by the InfoSec community. In this paper,\nwe survey existing datasets used for classifying malware by ML algorithms and\nthe features that are extracted from the data. We observe that: 1) the current\nset of extracted features are primarily syntactic, not behavioral, 2) datasets\ngenerally contain extreme exemplars producing a dataset in which it is easy to\ndiscriminate classes, and 3) the datasets provide significantly different\nrepresentations of the data encountered in real-world systems. For ML to make\nmore of an impact in the InfoSec community requires a change in the data\n(including the features and labels) that is used to bridge the current semantic\ngap. As a first step in enabling more behavioral analyses, we label existing\nmalware datasets with behavioral features using open-source threat reports\nassociated with malware families. This behavioral labeling alters the analysis\nfrom identifying intent (e.g. good vs bad) or malware family membership to an\nanalysis of which behaviors are exhibited by an executable. We offer the\nannotations with the hope of inspiring future improvements in the data that\nwill further bridge the semantic gap between the ML and InfoSec communities.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:19:32 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Smith", "Michael R.", ""], ["Johnson", "Nicholas T.", ""], ["Ingram", "Joe B.", ""], ["Carbajal", "Armida J.", ""], ["Ramyaa", "Ramyaa", ""], ["Domschot", "Evelyn", ""], ["Lamb", "Christopher C.", ""], ["Verzi", "Stephen J.", ""], ["Kegelmeyer", "W. Philip", ""]]}, {"id": "2005.01807", "submitter": "Nitin Rathi", "authors": "Nitin Rathi, Gopalakrishnan Srinivasan, Priyadarshini Panda, Kaushik\n  Roy", "title": "Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike\n  Timing Dependent Backpropagation", "comments": "International Conference on Learning Representations (ICLR), 2020\n  https://openreview.net/forum?id=B1xSperKvH&noteId=B1xSperKvH", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) operate with asynchronous discrete events (or\nspikes) which can potentially lead to higher energy-efficiency in neuromorphic\nhardware implementations. Many works have shown that an SNN for inference can\nbe formed by copying the weights from a trained Artificial Neural Network (ANN)\nand setting the firing threshold for each layer as the maximum input received\nin that layer. These type of converted SNNs require a large number of time\nsteps to achieve competitive accuracy which diminishes the energy savings. The\nnumber of time steps can be reduced by training SNNs with spike-based\nbackpropagation from scratch, but that is computationally expensive and slow.\nTo address these challenges, we present a computationally-efficient training\ntechnique for deep SNNs. We propose a hybrid training methodology: 1) take a\nconverted SNN and use its weights and thresholds as an initialization step for\nspike-based backpropagation, and 2) perform incremental spike-timing dependent\nbackpropagation (STDB) on this carefully initialized network to obtain an SNN\nthat converges within few epochs and requires fewer time steps for input\nprocessing. STDB is performed with a novel surrogate gradient function defined\nusing neuron's spike time. The proposed training methodology converges in less\nthan 20 epochs of spike-based backpropagation for most standard image\nclassification datasets, thereby greatly reducing the training complexity\ncompared to training SNNs from scratch. We perform experiments on CIFAR-10,\nCIFAR-100, and ImageNet datasets for both VGG and ResNet architectures. We\nachieve top-1 accuracy of 65.19% for ImageNet dataset on SNN with 250 time\nsteps, which is 10X faster compared to converted SNNs with similar accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:30:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Rathi", "Nitin", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "2005.01851", "submitter": "Cecilia Clementi", "authors": "Jiang Wang, Stefan Chmiela, Klaus-Robert M\\\"uller, Frank No\\`e,\n  Cecilia Clementi", "title": "Ensemble Learning of Coarse-Grained Molecular Dynamics Force Fields with\n  a Kernel Approach", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": "10.1063/5.0007276", "report-no": null, "categories": "physics.comp-ph physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-domain machine learning (GDML) is an accurate and efficient approach\nto learn a molecular potential and associated force field based on the kernel\nridge regression algorithm. Here, we demonstrate its application to learn an\neffective coarse-grained (CG) model from all-atom simulation data in a sample\nefficient manner. The coarse-grained force field is learned by following the\nthermodynamic consistency principle, here by minimizing the error between the\npredicted coarse-grained force and the all-atom mean force in the\ncoarse-grained coordinates. Solving this problem by GDML directly is impossible\nbecause coarse-graining requires averaging over many training data points,\nresulting in impractical memory requirements for storing the kernel matrices.\nIn this work, we propose a data-efficient and memory-saving alternative. Using\nensemble learning and stratified sampling, we propose a 2-layer training scheme\nthat enables GDML to learn an effective coarse-grained model. We illustrate our\nmethod on a simple biomolecular system, alanine dipeptide, by reconstructing\nthe free energy landscape of a coarse-grained variant of this molecule. Our\nnovel GDML training scheme yields a smaller free energy error than neural\nnetworks when the training set is small, and a comparably high accuracy when\nthe training set is sufficiently large.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:20:01 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Wang", "Jiang", ""], ["Chmiela", "Stefan", ""], ["M\u00fcller", "Klaus-Robert", ""], ["No\u00e8", "Frank", ""], ["Clementi", "Cecilia", ""]]}, {"id": "2005.01856", "submitter": "Maximilian Ilse", "authors": "Maximilian Ilse, Jakub M. Tomczak, Patrick Forr\\'e", "title": "Selecting Data Augmentation for Simulating Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models trained with purely observational data and the\nprinciple of empirical risk minimization \\citep{vapnik_principles_1992} can\nfail to generalize to unseen domains. In this paper, we focus on the case where\nthe problem arises through spurious correlation between the observed domains\nand the actual task labels. We find that many domain generalization methods do\nnot explicitly take this spurious correlation into account. Instead, especially\nin more application-oriented research areas like medical imaging or robotics,\ndata augmentation techniques that are based on heuristics are used to learn\ndomain invariant features. To bridge the gap between theory and practice, we\ndevelop a causal perspective on the problem of domain generalization. We argue\nthat causal concepts can be used to explain the success of data augmentation by\ndescribing how they can weaken the spurious correlation between the observed\ndomains and the task labels. We demonstrate that data augmentation can serve as\na tool for simulating interventional data. We use these theoretical insights to\nderive a simple algorithm that is able to select data augmentation techniques\nthat will lead to better domain generalization.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:33:29 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 14:59:40 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 13:16:20 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 10:52:21 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ilse", "Maximilian", ""], ["Tomczak", "Jakub M.", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2005.01862", "submitter": "Zengyi Li", "authors": "Zengyi Li, Friedrich T. Sommer", "title": "Complex Amplitude-Phase Boltzmann Machines", "comments": "Short Technical Note", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework of Boltzmann machines to a network of complex-valued\nneurons with variable amplitudes, referred to as Complex Amplitude-Phase\nBoltzmann machine (CAP-BM). The model is capable of performing unsupervised\nlearning on the amplitude and relative phase distribution in complex data. The\nsampling rule of the Gibbs distribution and the learning rules of the model are\npresented. Learning in a Complex Amplitude-Phase restricted Boltzmann machine\n(CAP-RBM) is demonstrated on synthetic complex-valued images, and handwritten\nMNIST digits transformed by a complex wavelet transform. Specifically, we show\nthe necessity of a new amplitude-amplitude coupling term in our model. The\nproposed model is potentially valuable for machine learning tasks involving\ncomplex-valued data with amplitude variation, and for developing algorithms for\nnovel computation hardware, such as coupled oscillators and neuromorphic\nhardware, on which Boltzmann sampling can be executed in the complex domain.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:44:59 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Li", "Zengyi", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2005.01886", "submitter": "Vladimir Pestov", "authors": "Vladimir G. Pestov", "title": "A learning problem whose consistency is equivalent to the non-existence\n  of real-valued measurable cardinals", "comments": "16 pp., journal macros", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the $k$-nearest neighbour learning rule is universally\nconsistent in a metric space $X$ if and only if it is universally consistent in\nevery separable subspace of $X$ and the density of $X$ is less than every\nreal-measurable cardinal. In particular, the $k$-NN classifier is universally\nconsistent in every metric space whose separable subspaces are sigma-finite\ndimensional in the sense of Nagata and Preiss if and only if there are no\nreal-valued measurable cardinals. The latter assumption is relatively\nconsistent with ZFC, however the consistency of the existence of such cardinals\ncannot be proved within ZFC. Our results were inspired by an example sketched\nby C\\'erou and Guyader in 2006 at an intuitive level of rigour.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 23:40:28 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Pestov", "Vladimir G.", ""]]}, {"id": "2005.01889", "submitter": "Seonho Park", "authors": "Seonho Park, George Adosoglou, Panos M. Pardalos", "title": "Interpreting Rate-Distortion of Variational Autoencoder and Using Model\n  Uncertainty for Anomaly Detection", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a scalable machine learning system for unsupervised anomaly\ndetection via representation learning is highly desirable. One of the prevalent\nmethods is using a reconstruction error from variational autoencoder (VAE) via\nmaximizing the evidence lower bound. We revisit VAE from the perspective of\ninformation theory to provide some theoretical foundations on using the\nreconstruction error, and finally arrive at a simpler and more effective model\nfor anomaly detection. In addition, to enhance the effectiveness of detecting\nanomalies, we incorporate a practical model uncertainty measure into the\nmetric. We show empirically the competitive performance of our approach on\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 00:03:48 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 16:59:36 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Park", "Seonho", ""], ["Adosoglou", "George", ""], ["Pardalos", "Panos M.", ""]]}, {"id": "2005.01906", "submitter": "Jared Quincy Davis", "authors": "Jared Quincy Davis, Krzysztof Choromanski, Jake Varley, Honglak Lee,\n  Jean-Jacques Slotine, Valerii Likhosterov, Adrian Weller, Ameesh Makadia,\n  Vikas Sindhwani", "title": "Time Dependence in Non-Autonomous Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Ordinary Differential Equations (ODEs) are elegant reinterpretations\nof deep networks where continuous time can replace the discrete notion of\ndepth, ODE solvers perform forward propagation, and the adjoint method enables\nefficient, constant memory backpropagation. Neural ODEs are universal\napproximators only when they are non-autonomous, that is, the dynamics depends\nexplicitly on time. We propose a novel family of Neural ODEs with time-varying\nweights, where time-dependence is non-parametric, and the smoothness of weight\ntrajectories can be explicitly controlled to allow a tradeoff between\nexpressiveness and efficiency. Using this enhanced expressiveness, we\noutperform previous Neural ODE variants in both speed and representational\ncapacity, ultimately outperforming standard ResNet and CNN models on select\nimage classification and video prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 01:41:46 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:40:50 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Davis", "Jared Quincy", ""], ["Choromanski", "Krzysztof", ""], ["Varley", "Jake", ""], ["Lee", "Honglak", ""], ["Slotine", "Jean-Jacques", ""], ["Likhosterov", "Valerii", ""], ["Weller", "Adrian", ""], ["Makadia", "Ameesh", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "2005.01917", "submitter": "Dylan Peifer", "authors": "Dylan Peifer, Michael Stillman, Daniel Halpern-Leistner", "title": "Learning selection strategies in Buchberger's algorithm", "comments": "14 pages, minor typo and format fixes, to appear in Proceedings of\n  the 37th International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SC math.AC math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the set of exact solutions of a system of polynomial equations\nlargely depends on a single iterative algorithm, known as Buchberger's\nalgorithm. Optimized versions of this algorithm are crucial for many computer\nalgebra systems (e.g., Mathematica, Maple, Sage). We introduce a new approach\nto Buchberger's algorithm that uses reinforcement learning agents to perform\nS-pair selection, a key step in the algorithm. We then study how the difficulty\nof the problem depends on the choices of domain and distribution of\npolynomials, about which little is known. Finally, we train a policy model\nusing proximal policy optimization (PPO) to learn S-pair selection strategies\nfor random systems of binomial equations. In certain domains, the trained model\noutperforms state-of-the-art selection heuristics in total number of polynomial\nadditions performed, which provides a proof-of-concept that recent developments\nin machine learning have the potential to improve performance of algorithms in\nsymbolic computation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 02:27:00 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 16:43:30 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 22:01:54 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Peifer", "Dylan", ""], ["Stillman", "Michael", ""], ["Halpern-Leistner", "Daniel", ""]]}, {"id": "2005.01923", "submitter": "Muhammad Ali Farooq", "authors": "Muhammad Ali Farooq and Peter Corcoran", "title": "Generating Thermal Image Data Samples using 3D Facial Modelling\n  Techniques and Deep Learning Methodologies", "comments": "Paper accpeted in QOMEX IEEE 2020 Conference copyright submitted to\n  IEEE", "journal-ref": null, "doi": "10.1109/QoMEX48832.2020.9123079", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for generating synthetic data have become of increasing importance to\nbuild large datasets required for Convolution Neural Networks (CNN) based deep\nlearning techniques for a wide range of computer vision applications. In this\nwork, we extend existing methodologies to show how 2D thermal facial data can\nbe mapped to provide 3D facial models. For the proposed research work we have\nused tufts datasets for generating 3D varying face poses by using a single\nfrontal face pose. The system works by refining the existing image quality by\nperforming fusion based image preprocessing operations. The refined outputs\nhave better contrast adjustments, decreased noise level and higher exposedness\nof the dark regions. It makes the facial landmarks and temperature patterns on\nthe human face more discernible and visible when compared to original raw data.\nDifferent image quality metrics are used to compare the refined version of\nimages with original images. In the next phase of the proposed study, the\nrefined version of images is used to create 3D facial geometry structures by\nusing Convolution Neural Networks (CNN). The generated outputs are then\nimported in blender software to finally extract the 3D thermal facial outputs\nof both males and females. The same technique is also used on our thermal face\ndata acquired using prototype thermal camera (developed under Heliaus EU\nproject) in an indoor lab environment which is then used for generating\nsynthetic 3D face data along with varying yaw face angles and lastly facial\ndepth map is generated.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 02:55:14 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 11:02:04 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Farooq", "Muhammad Ali", ""], ["Corcoran", "Peter", ""]]}, {"id": "2005.01932", "submitter": "Pang Wei Koh", "authors": "Shikhar Murty, Pang Wei Koh, and Percy Liang", "title": "ExpBERT: Representation Engineering with Natural Language Explanations", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we want to specify the inductive bias that married couples typically\ngo on honeymoons for the task of extracting pairs of spouses from text. In this\npaper, we allow model developers to specify these types of inductive biases as\nnatural language explanations. We use BERT fine-tuned on MultiNLI to\n``interpret'' these explanations with respect to the input sentence, producing\nexplanation-guided representations of the input. Across three relation\nextraction tasks, our method, ExpBERT, matches a BERT baseline but with 3--20x\nless labeled data and improves on the baseline by 3--10 F1 points with the same\namount of labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 03:40:23 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Murty", "Shikhar", ""], ["Koh", "Pang Wei", ""], ["Liang", "Percy", ""]]}, {"id": "2005.01936", "submitter": "Sanae Amani", "authors": "Sanae Amani, Mahnoosh Alizadeh, Christos Thrampoulidis", "title": "Regret Bounds for Safe Gaussian Process Bandit Optimization", "comments": "22 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require a learner to make sequential decisions given\nuncertainty regarding both the system's payoff function and safety constraints.\nIn safety-critical systems, it is paramount that the learner's actions do not\nviolate the safety constraints at any stage of the learning process. In this\npaper, we study a stochastic bandit optimization problem where the unknown\npayoff and constraint functions are sampled from Gaussian Processes (GPs) first\nconsidered in [Srinivas et al., 2010]. We develop a safe variant of GP-UCB\ncalled SGP-UCB, with necessary modifications to respect safety constraints at\nevery round. The algorithm has two distinct phases. The first phase seeks to\nestimate the set of safe actions in the decision set, while the second phase\nfollows the GP-UCB decision rule. Our main contribution is to derive the first\nsub-linear regret bounds for this problem. We numerically compare SGP-UCB\nagainst existing safe Bayesian GP optimization algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 03:54:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Amani", "Sanae", ""], ["Alizadeh", "Mahnoosh", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2005.01979", "submitter": "Joash Lee", "authors": "Joash Lee, Wenbo Wang, Dusit Niyato", "title": "Demand-Side Scheduling Based on Deep Actor-Critic Learning for Smart\n  Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of demand-side energy management, where each\nhousehold is equipped with a smart meter that is able to schedule home\nappliances online. The goal is to minimise the overall cost under a real-time\npricing scheme. While previous works have introduced centralised approaches, we\nformulate the smart grid environment as a Markov game, where each household is\na decentralised agent, and the grid operator produces a price signal that\nadapts to the energy demand. The main challenge addressed in our approach is\npartial observability and perceived non-stationarity of the environment from\nthe viewpoint of each agent. We propose a multi-agent extension of a deep\nactor-critic algorithm that shows success in learning in this environment. This\nalgorithm learns a centralised critic that coordinates training of all agents.\nOur approach thus uses centralised learning but decentralised execution.\nSimulation results show that our online deep reinforcement learning method can\nreduce both the peak-to-average ratio of total energy consumed and the cost of\nelectricity for all households based purely on instantaneous observations and a\nprice signal.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 07:32:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lee", "Joash", ""], ["Wang", "Wenbo", ""], ["Niyato", "Dusit", ""]]}, {"id": "2005.01988", "submitter": "Zhong Sun", "authors": "Zhong Sun, Giacomo Pedretti, Alessandro Bricalli, Daniele Ielmini", "title": "One-step regression and classification with crosspoint resistive memory\n  arrays", "comments": "24 pages, 4 figures", "journal-ref": "Science Advances: Vol. 6, no. 5, eaay2378 (2020)", "doi": "10.1126/sciadv.aay2378", "report-no": null, "categories": "cs.LG cs.ET stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning has been getting a large attention in the recent years, as a\ntool to process big data generated by ubiquitous sensors in our daily life.\nHigh speed, low energy computing machines are in demand to enable real-time\nartificial intelligence at the edge, i.e., without the support of a remote\nframe server in the cloud. Such requirements challenge the complementary\nmetal-oxide-semiconductor (CMOS) technology, which is limited by the Moore's\nlaw approaching its end and the communication bottleneck in conventional\ncomputing architecture. Novel computing concepts, architectures and devices are\nthus strongly needed to accelerate data-intensive applications. Here we show a\ncrosspoint resistive memory circuit with feedback configuration can execute\nlinear regression and logistic regression in just one step by computing the\npseudoinverse matrix of the data within the memory. The most elementary\nlearning operation, that is the regression of a sequence of data and the\nclassification of a set of data, can thus be executed in one single\ncomputational step by the novel technology. One-step learning is further\nsupported by simulations of the prediction of the cost of a house in Boston and\nthe training of a 2-layer neural network for MNIST digit recognition. The\nresults are all obtained in one computational step, thanks to the physical,\nparallel, and analog computing within the crosspoint array.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:00:07 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Sun", "Zhong", ""], ["Pedretti", "Giacomo", ""], ["Bricalli", "Alessandro", ""], ["Ielmini", "Daniele", ""]]}, {"id": "2005.01995", "submitter": "Mehdi Ghatee Dr.", "authors": "Mohammad Mahdi Bejani, Mehdi Ghatee", "title": "Adaptive Low-Rank Factorization to regularize shallow and deep neural\n  networks", "comments": "11 pages, 5 figures, 3 Tables,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overfitting is one of the cursing subjects in the deep learning field. To\nsolve this challenge, many approaches were proposed to regularize the learning\nmodels. They add some hyper-parameters to the model to extend the\ngeneralization; however, it is a hard task to determine these hyper-parameters\nand a bad setting diverges the training process. In addition, most of the\nregularization schemes decrease the learning speed. Recently, Tai et al. [1]\nproposed low-rank tensor decomposition as a constrained filter for removing the\nredundancy in the convolution kernels of CNN. With a different viewpoint, we\nuse Low-Rank matrix Factorization (LRF) to drop out some parameters of the\nlearning model along the training process. However, this scheme similar to [1]\nprobably decreases the training accuracy when it tries to decrease the number\nof operations. Instead, we use this regularization scheme adaptively when the\ncomplexity of a layer is high. The complexity of any layer can be evaluated by\nthe nonlinear condition numbers of its learning system. The resulted method\nentitled \"AdaptiveLRF\" neither decreases the training speed nor vanishes the\naccuracy of the layer. The behavior of AdaptiveLRF is visualized on a noisy\ndataset. Then, the improvements are presented on some small-size and\nlarge-scale datasets. The preference of AdaptiveLRF on famous dropout\nregularizers on shallow networks is demonstrated. Also, AdaptiveLRF competes\nwith dropout and adaptive dropout on the various deep networks including\nMobileNet V2, ResNet V2, DenseNet, and Xception. The best results of\nAdaptiveLRF on SVHN and CIFAR-10 datasets are 98%, 94.1% F-measure, and 97.9%,\n94% accuracy. Finally, we state the usage of the LRF-based loss function to\nimprove the quality of the learning model.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:13:30 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Bejani", "Mohammad Mahdi", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "2005.02000", "submitter": "Adriano Lucieri", "authors": "Adriano Lucieri, Muhammad Naseer Bajwa, Stephan Alexander Braun,\n  Muhammad Imran Malik, Andreas Dengel and Sheraz Ahmed", "title": "On Interpretability of Deep Learning based Skin Lesion Classifiers using\n  Concept Activation Vectors", "comments": "Accepted for the IEEE International Joint Conference on Neural\n  Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based medical image classifiers have shown remarkable prowess\nin various application areas like ophthalmology, dermatology, pathology, and\nradiology. However, the acceptance of these Computer-Aided Diagnosis (CAD)\nsystems in real clinical setups is severely limited primarily because their\ndecision-making process remains largely obscure. This work aims at elucidating\na deep learning based medical image classifier by verifying that the model\nlearns and utilizes similar disease-related concepts as described and employed\nby dermatologists. We used a well-trained and high performing neural network\ndeveloped by REasoning for COmplex Data (RECOD) Lab for classification of three\nskin tumours, i.e. Melanocytic Naevi, Melanoma and Seborrheic Keratosis and\nperformed a detailed analysis on its latent space. Two well established and\npublicly available skin disease datasets, PH2 and derm7pt, are used for\nexperimentation. Human understandable concepts are mapped to RECOD image\nclassification model with the help of Concept Activation Vectors (CAVs),\nintroducing a novel training and significance testing paradigm for CAVs. Our\nresults on an independent evaluation set clearly shows that the classifier\nlearns and encodes human understandable concepts in its latent representation.\nAdditionally, TCAV scores (Testing with CAVs) suggest that the neural network\nindeed makes use of disease-related concepts in the correct way when making\npredictions. We anticipate that this work can not only increase confidence of\nmedical practitioners on CAD but also serve as a stepping stone for further\ndevelopment of CAV-based neural network interpretation methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:27:16 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lucieri", "Adriano", ""], ["Bajwa", "Muhammad Naseer", ""], ["Braun", "Stephan Alexander", ""], ["Malik", "Muhammad Imran", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.02057", "submitter": "Budi Kurniawan", "authors": "Budi Kurniawan, Peter Vamplew, Michael Papasimeon, Richard Dazeley,\n  Cameron Foale", "title": "Discrete-to-Deep Supervised Policy Learning", "comments": "9 pages, 9 figures. Adaptive and Learning Agents Workshop at AAMAS\n  2020, Auckland, New Zealand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are effective function approximators, but hard to train in\nthe reinforcement learning (RL) context mainly because samples are correlated.\nFor years, scholars have got around this by employing experience replay or an\nasynchronous parallel-agent system. This paper proposes Discrete-to-Deep\nSupervised Policy Learning (D2D-SPL) for training neural networks in RL.\nD2D-SPL discretises the continuous state space into discrete states and uses\nactor-critic to learn a policy. It then selects from each discrete state an\ninput value and the action with the highest numerical preference as an\ninput/target pair. Finally it uses input/target pairs from all discrete states\nto train a classifier. D2D-SPL uses a single agent, needs no experience replay\nand learns much faster than state-of-the-art methods. We test our method with\ntwo RL environments, the Cartpole and an aircraft manoeuvring simulator.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 10:49:00 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Kurniawan", "Budi", ""], ["Vamplew", "Peter", ""], ["Papasimeon", "Michael", ""], ["Dazeley", "Richard", ""], ["Foale", "Cameron", ""]]}, {"id": "2005.02123", "submitter": "Yu-Kai Huang", "authors": "Yu-Kai Huang, Yueh-Cheng Liu, Tsung-Han Wu, Hung-Ting Su and Winston\n  H. Hsu", "title": "Expanding Sparse Guidance for Stereo Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of image based stereo estimation suffers from lighting\nvariations, repetitive patterns and homogeneous appearance. Moreover, to\nachieve good performance, stereo supervision requires sufficient\ndensely-labeled data, which are hard to obtain. In this work, we leverage small\namount of data with very sparse but accurate disparity cues from LiDAR to\nbridge the gap. We propose a novel sparsity expansion technique to expand the\nsparse cues concerning RGB images for local feature enhancement. The feature\nenhancement method can be easily applied to any stereo estimation algorithms\nwith cost volume at the test stage. Extensive experiments on stereo datasets\ndemonstrate the effectiveness and robustness across different backbones on\ndomain adaption and self-supervision scenario. Our sparsity expansion method\noutperforms previous methods in terms of disparity by more than 2 pixel error\non KITTI Stereo 2012 and 3 pixel error on KITTI Stereo 2015. Our approach\nsignificantly boosts the existing state-of-the-art stereo algorithms with\nextremely sparse cues.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 06:41:11 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Huang", "Yu-Kai", ""], ["Liu", "Yueh-Cheng", ""], ["Wu", "Tsung-Han", ""], ["Su", "Hung-Ting", ""], ["Hsu", "Winston H.", ""]]}, {"id": "2005.02133", "submitter": "Uche Osahor", "authors": "Uche Osahor, Hadi Kazemi, Ali Dabouei, Nasser Nasrabadi", "title": "Quality Guided Sketch-to-Photo Image Synthesis", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Facial sketches drawn by artists are widely used for visual identification\napplications and mostly by law enforcement agencies, but the quality of these\nsketches depend on the ability of the artist to clearly replicate all the key\nfacial features that could aid in capturing the true identity of a subject.\nRecent works have attempted to synthesize these sketches into plausible visual\nimages to improve visual recognition and identification. However, synthesizing\nphoto-realistic images from sketches proves to be an even more challenging\ntask, especially for sensitive applications such as suspect identification. In\nthis work, we propose a novel approach that adopts a generative adversarial\nnetwork that synthesizes a single sketch into multiple synthetic images with\nunique attributes like hair color, sex, etc. We incorporate a hybrid\ndiscriminator which performs attribute classification of multiple target\nattributes, a quality guided encoder that minimizes the perceptual\ndissimilarity of the latent space embedding of the synthesized and real image\nat different layers in the network and an identity preserving network that\nmaintains the identity of the synthesised image throughout the training\nprocess. Our approach is aimed at improving the visual appeal of the\nsynthesised images while incorporating multiple attribute assignment to the\ngenerator without compromising the identity of the synthesised image. We\nsynthesised sketches using XDOG filter for the CelebA, WVU Multi-modal and\nCelebA-HQ datasets and from an auxiliary generator trained on sketches from\nCUHK, IIT-D and FERET datasets. Our results are impressive compared to current\nstate of the art.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:00:01 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Osahor", "Uche", ""], ["Kazemi", "Hadi", ""], ["Dabouei", "Ali", ""], ["Nasrabadi", "Nasser", ""]]}, {"id": "2005.02138", "submitter": "Nicholas Sharp", "authors": "Nicholas Sharp, Maks Ovsjanikov", "title": "PointTriNet: Learned Triangulation of 3D Point Sets", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers a new task in geometric deep learning: generating a\ntriangulation among a set of points in 3D space. We present PointTriNet, a\ndifferentiable and scalable approach enabling point set triangulation as a\nlayer in 3D learning pipelines. The method iteratively applies two neural\nnetworks: a classification network predicts whether a candidate triangle should\nappear in the triangulation, while a proposal network suggests additional\ncandidates. Both networks are structured as PointNets over nearby points and\ntriangles, using a novel triangle-relative input encoding. Since these learning\nproblems operate on local geometric data, our method is efficient and scalable,\nand generalizes to unseen shape categories. Our networks are trained in an\nunsupervised manner from a collection of shapes represented as point clouds. We\ndemonstrate the effectiveness of this approach for classical meshing tasks,\nrobustness to outliers, and as a component in end-to-end learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 01:58:35 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 12:37:01 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Sharp", "Nicholas", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "2005.02140", "submitter": "Tomislav Ivek", "authors": "Tomislav Ivek, Domagoj Vlah", "title": "BlackBox: Generalizable Reconstruction of Extremal Values from\n  Incomplete Spatio-Temporal Data", "comments": "3 figures; accepted in Extremes; 2nd place entry at the Extreme Value\n  Analysis 2019 Data Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our submission to the Extreme Value Analysis 2019 Data Challenge\nin which teams were asked to predict extremes of sea surface temperature\nanomaly within spatio-temporal regions of missing data. We present a\ncomputational framework which reconstructs missing data using convolutional\ndeep neural networks. Conditioned on incomplete data, we employ\nautoencoder-like models as multivariate conditional distributions from which\npossible reconstructions of the complete dataset are sampled using imputed\nnoise. In order to mitigate bias introduced by any one particular model, a\nprediction ensemble is constructed to create the final distribution of extremal\nvalues. Our method does not rely on expert knowledge in order to accurately\nreproduce dynamic features of a complex oceanographic system with minimal\nassumptions. The obtained results promise reusability and generalization to\nother domains.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:33:46 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 18:01:17 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 16:36:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ivek", "Tomislav", ""], ["Vlah", "Domagoj", ""]]}, {"id": "2005.02151", "submitter": "Vince Lyzinski", "authors": "Keith Levin, Carey E. Priebe, Vince Lyzinski", "title": "On the role of features in vertex nomination: Content and context\n  together are better (sometimes)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertex nomination is a lightly-supervised network information retrieval (IR)\ntask in which vertices of interest in one graph are used to query a second\ngraph to discover vertices of interest in the second graph. Similar to other IR\ntasks, the output of a vertex nomination scheme is a ranked list of the\nvertices in the second graph, with the heretofore unknown vertices of interest\nideally concentrating at the top of the list. Vertex nomination schemes provide\na useful suite of tools for efficiently mining complex networks for pertinent\ninformation. In this paper, we explore, both theoretically and practically, the\ndual roles of content (i.e., edge and vertex attributes) and context (i.e.,\nnetwork topology) in vertex nomination. We provide necessary and sufficient\nconditions under which vertex nomination schemes that leverage both content and\ncontext outperform schemes that leverage only content or context separately.\nWhile the joint utility of both content and context has been demonstrated\nempirically in the literature, the framework presented in this paper provides a\nnovel theoretical basis for understanding the potential complementary roles of\nnetwork features and topology.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 15:13:24 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 13:01:43 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Levin", "Keith", ""], ["Priebe", "Carey E.", ""], ["Lyzinski", "Vince", ""]]}, {"id": "2005.02153", "submitter": "Yunlian Lv", "authors": "Yunlian Lv, Ning Xie, Yimin Shi, Zijiao Wang, and Heng Tao Shen", "title": "Improving Target-driven Visual Navigation with Attention on 3D Spatial\n  Relationships", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied artificial intelligence (AI) tasks shift from tasks focusing on\ninternet images to active settings involving embodied agents that perceive and\nact within 3D environments. In this paper, we investigate the target-driven\nvisual navigation using deep reinforcement learning (DRL) in 3D indoor scenes,\nwhose navigation task aims to train an agent that can intelligently make a\nseries of decisions to arrive at a pre-specified target location from any\npossible starting positions only based on egocentric views. However, most\nnavigation methods currently struggle against several challenging problems,\nsuch as data efficiency, automatic obstacle avoidance, and generalization.\nGeneralization problem means that agent does not have the ability to transfer\nnavigation skills learned from previous experience to unseen targets and\nscenes. To address these issues, we incorporate two designs into classic DRL\nframework: attention on 3D knowledge graph (KG) and target skill extension\n(TSE) module. On the one hand, our proposed method combines visual features and\n3D spatial representations to learn navigation policy. On the other hand, TSE\nmodule is used to generate sub-targets which allow agent to learn from\nfailures. Specifically, our 3D spatial relationships are encoded through\nrecently popular graph convolutional network (GCN). Considering the real world\nsettings, our work also considers open action and adds actionable targets into\nconventional navigation situations. Those more difficult settings are applied\nto test whether DRL agent really understand its task, navigating environment,\nand can carry out reasoning. Our experiments, performed in the AI2-THOR, show\nthat our model outperforms the baselines in both SR and SPL metrics, and\nimproves generalization ability across targets and scenes.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:46:38 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lv", "Yunlian", ""], ["Xie", "Ning", ""], ["Shi", "Yimin", ""], ["Wang", "Zijiao", ""], ["Shen", "Heng Tao", ""]]}, {"id": "2005.02157", "submitter": "Mohammadhossein Toutiaee", "authors": "Mohammadhossein Toutiaee, Soheyla Amirian, John A. Miller, Sheng Li", "title": "Stereotype-Free Classification of Fictitious Faces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equal Opportunity and Fairness are receiving increasing attention in\nartificial intelligence. Stereotyping is another source of discrimination,\nwhich yet has been unstudied in literature. GAN-made faces would be exposed to\nsuch discrimination, if they are classified by human perception. It is possible\nto eliminate the human impact on fictitious faces classification task by the\nuse of statistical approaches. We present a novel approach through penalized\nregression to label stereotype-free GAN-generated synthetic unlabeled images.\nThe proposed approach aids labeling new data (fictitious output images) by\nminimizing a penalized version of the least squares cost function between\nrealistic pictures and target pictures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 04:37:54 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Toutiaee", "Mohammadhossein", ""], ["Amirian", "Soheyla", ""], ["Miller", "John A.", ""], ["Li", "Sheng", ""]]}, {"id": "2005.02158", "submitter": "Jie Wang", "authors": "Hao Zhang, Jie Wang", "title": "An Unsupervised Semantic Sentence Ranking Scheme for Text Documents", "comments": "To appear in Integrated Computer-Aided Engineering (ICAE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Semantic SentenceRank (SSR), an unsupervised scheme for\nautomatically ranking sentences in a single document according to their\nrelative importance. In particular, SSR extracts essential words and phrases\nfrom a text document, and uses semantic measures to construct, respectively, a\nsemantic phrase graph over phrases and words, and a semantic sentence graph\nover sentences. It applies two variants of article-structure-biased PageRank to\nscore phrases and words on the first graph and sentences on the second graph.\nIt then combines these scores to generate the final score for each sentence.\nFinally, SSR solves a multi-objective optimization problem for ranking\nsentences based on their final scores and topic diversity through semantic\nsubtopic clustering. An implementation of SSR that runs in quadratic time is\npresented, and it outperforms, on the SummBank benchmarks, each individual\njudge's ranking and compares favorably with the combined ranking of all judges.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 20:17:51 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Zhang", "Hao", ""], ["Wang", "Jie", ""]]}, {"id": "2005.02160", "submitter": "Hailey James", "authors": "Hailey James, Otkrist Gupta, Dan Raviv", "title": "Printing and Scanning Attack for Image Counter Forensics", "comments": "10 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Examining the authenticity of images has become increasingly important as\nmanipulation tools become more accessible and advanced. Recent work has shown\nthat while CNN-based image manipulation detectors can successfully identify\nmanipulations, they are also vulnerable to adversarial attacks, ranging from\nsimple double JPEG compression to advanced pixel-based perturbation. In this\npaper we explore another method of highly plausible attack: printing and\nscanning. We demonstrate the vulnerability of two state-of-the-art models to\nthis type of attack. We also propose a new machine learning model that performs\ncomparably to these state-of-the-art models when trained and validated on\nprinted and scanned images. Of the three models, our proposed model outperforms\nthe others when trained and validated on images from a single printer. To\nfacilitate this exploration, we create a dataset of over 6,000 printed and\nscanned image blocks. Further analysis suggests that variation between images\nproduced from different printers is significant, large enough that good\nvalidation accuracy on images from one printer does not imply similar\nvalidation accuracy on identical images from a different printer.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 00:32:15 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 17:01:59 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["James", "Hailey", ""], ["Gupta", "Otkrist", ""], ["Raviv", "Dan", ""]]}, {"id": "2005.02161", "submitter": "Jiayi Wei", "authors": "Jiayi Wei, Maruth Goyal, Greg Durrett, Isil Dillig", "title": "LambdaNet: Probabilistic Type Inference using Graph Neural Networks", "comments": "Accepted as a poster at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As gradual typing becomes increasingly popular in languages like Python and\nTypeScript, there is a growing need to infer type annotations automatically.\nWhile type annotations help with tasks like code completion and static error\ncatching, these annotations cannot be fully determined by compilers and are\ntedious to annotate by hand. This paper proposes a probabilistic type inference\nscheme for TypeScript based on a graph neural network. Our approach first uses\nlightweight source code analysis to generate a program abstraction called a\ntype dependency graph, which links type variables with logical constraints as\nwell as name and usage information. Given this program abstraction, we then use\na graph neural network to propagate information between related type variables\nand eventually make type predictions. Our neural architecture can predict both\nstandard types, like number or string, as well as user-defined types that have\nnot been encountered during training. Our experimental results show that our\napproach outperforms prior work in this space by $14\\%$ (absolute) on library\ntypes, while having the ability to make type predictions that are out of scope\nfor existing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:48:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Wei", "Jiayi", ""], ["Goyal", "Maruth", ""], ["Durrett", "Greg", ""], ["Dillig", "Isil", ""]]}, {"id": "2005.02162", "submitter": "Etienne David", "authors": "E. David, S. Madec, P. Sadeghi-Tehran, H. Aasen, B. Zheng, S. Liu, N.\n  Kirchgessner, G. Ishikawa, K. Nagasawa, M.A. Badhon, C. Pozniak, B. de Solan,\n  A. Hund, S.C. Chapman, F. Baret, I. Stavness, W. Guo", "title": "Global Wheat Head Detection (GWHD) dataset: a large and diverse dataset\n  of high resolution RGB labelled images to develop and benchmark wheat head\n  detection methods", "comments": "16 pages, 7 figures, Dataset paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of wheat heads is an important task allowing to estimate pertinent\ntraits including head population density and head characteristics such as\nsanitary state, size, maturity stage and the presence of awns. Several studies\ndeveloped methods for wheat head detection from high-resolution RGB imagery.\nThey are based on computer vision and machine learning and are generally\ncalibrated and validated on limited datasets. However, variability in\nobservational conditions, genotypic differences, development stages, head\norientation represents a challenge in computer vision. Further, possible\nblurring due to motion or wind and overlap between heads for dense populations\nmake this task even more complex. Through a joint international collaborative\neffort, we have built a large, diverse and well-labelled dataset, the Global\nWheat Head detection (GWHD) dataset. It contains 4,700 high-resolution RGB\nimages and 190,000 labelled wheat heads collected from several countries around\nthe world at different growth stages with a wide range of genotypes. Guidelines\nfor image acquisition, associating minimum metadata to respect FAIR principles\nand consistent head labelling methods are proposed when developing new head\ndetection datasets. The GWHD is publicly available at\nhttp://www.global-wheat.com/ and aimed at developing and benchmarking methods\nfor wheat head detection.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:20:26 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 07:34:36 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["David", "E.", ""], ["Madec", "S.", ""], ["Sadeghi-Tehran", "P.", ""], ["Aasen", "H.", ""], ["Zheng", "B.", ""], ["Liu", "S.", ""], ["Kirchgessner", "N.", ""], ["Ishikawa", "G.", ""], ["Nagasawa", "K.", ""], ["Badhon", "M. A.", ""], ["Pozniak", "C.", ""], ["de Solan", "B.", ""], ["Hund", "A.", ""], ["Chapman", "S. C.", ""], ["Baret", "F.", ""], ["Stavness", "I.", ""], ["Guo", "W.", ""]]}, {"id": "2005.02163", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, Paul Southam, James Large and Richard Harvey", "title": "Detecting Electric Devices in 3D Images of Bags", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aviation and transport security industries face the challenge of\nscreening high volumes of baggage for threats and contraband in the minimum\ntime possible. Automation and semi-automation of this procedure offers the\npotential to increase security by detecting more threats and improve the\ncustomer experience by speeding up the process. Traditional 2D x-ray images are\noften extremely difficult to examine due to the fact that they are tightly\npacked and contain a wide variety of cluttered and occluded objects. Because of\nthese limitations, major airports are introducing 3D x-ray Computed Tomography\n(CT) baggage scanning. We investigate whether we can automate the process of\ndetecting electric devices in these 3D images of luggage. Detecting electrical\ndevices is of particular concern as they can be used to conceal explosives.\nGiven the massive volume of luggage that needs to be screened for this threat,\nthe best way to automate the detection is to first filter whether a bag\ncontains an electric device or not, and if it does, to identify the number of\ndevices and their location. We present an algorithm, Unpack, Predict, eXtract,\nRepack (UXPR), which involves unpacking through segmenting the data at a range\nof scales using an algorithm known as the Sieve, predicting whether a segment\nis electrical or not based on the histogram of voxel intensities, then\nrepacking the bag by ensembling the segments and predictions to identify the\ndevices in bags. Through a range of experiments using data provided by ALERT\n(Awareness and Localization of Explosives-Related Threats) we show that this\nsystem can find a high proportion of devices with unsupervised segmentation if\na similar device has been seen before, and shows promising results for\ndetecting devices not seen at all based on the properties of its constituent\nparts.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 11:30:42 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Bagnall", "Anthony", ""], ["Southam", "Paul", ""], ["Large", "James", ""], ["Harvey", "Richard", ""]]}, {"id": "2005.02191", "submitter": "Alexandre Capone", "authors": "Alexandre Capone, Jonas Umlauft, Thomas Beckers, Armin Lederer, Sandra\n  Hirche", "title": "Localized active learning of Gaussian process state space models", "comments": "Submitted to Learning for Dynamics and Control (L4DC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of learning-based control techniques crucially depends on how\neffectively the system is explored. While most exploration techniques aim to\nachieve a globally accurate model, such approaches are generally unsuited for\nsystems with unbounded state spaces. Furthermore, a globally accurate model is\nnot required to achieve good performance in many common control applications,\ne.g., local stabilization tasks. In this paper, we propose an active learning\nstrategy for Gaussian process state space models that aims to obtain an\naccurate model on a bounded subset of the state-action space. Our approach aims\nto maximize the mutual information of the exploration trajectories with respect\nto a discretization of the region of interest. By employing model predictive\ncontrol, the proposed technique integrates information collected during\nexploration and adaptively improves its exploration strategy. To enable\ncomputational tractability, we decouple the choice of most informative data\npoints from the model predictive control optimization step. This yields two\noptimization problems that can be solved in parallel. We apply the proposed\nmethod to explore the state space of various dynamical systems and compare our\napproach to a commonly used entropy-based exploration strategy. In all\nexperiments, our method yields a better model within the region of interest\nthan the entropy-based method.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 05:35:02 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 08:54:09 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 19:57:11 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Capone", "Alexandre", ""], ["Umlauft", "Jonas", ""], ["Beckers", "Thomas", ""], ["Lederer", "Armin", ""], ["Hirche", "Sandra", ""]]}, {"id": "2005.02196", "submitter": "Shujian Yu", "authors": "Shujian Yu, Ammar Shaker, Francesco Alesiani, Jose C. Principe", "title": "Measuring the Discrepancy between Conditional Distributions: Methods,\n  Properties and Applications", "comments": "manuscript accepted at IJCAI 20; added additional notes on\n  computational complexity and auto-differentiable property; code is available\n  at https://github.com/SJYuCNEL/Bregman-Correntropy-Conditional-Divergence", "journal-ref": null, "doi": "10.24963/ijcai.2020/385", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet powerful test statistic to quantify the discrepancy\nbetween two conditional distributions. The new statistic avoids the explicit\nestimation of the underlying distributions in highdimensional space and it\noperates on the cone of symmetric positive semidefinite (SPS) matrix using the\nBregman matrix divergence. Moreover, it inherits the merits of the correntropy\nfunction to explicitly incorporate high-order statistics in the data. We\npresent the properties of our new statistic and illustrate its connections to\nprior art. We finally show the applications of our new statistic on three\ndifferent machine learning problems, namely the multi-task learning over\ngraphs, the concept drift detection, and the information-theoretic feature\nselection, to demonstrate its utility and advantage. Code of our statistic is\navailable at https://bit.ly/BregmanCorrentropy.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:03:55 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 00:32:02 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yu", "Shujian", ""], ["Shaker", "Ammar", ""], ["Alesiani", "Francesco", ""], ["Principe", "Jose C.", ""]]}, {"id": "2005.02205", "submitter": "Min Chen", "authors": "Min Chen and Zhikun Zhang and Tianhao Wang and Michael Backes and\n  Mathias Humbert and Yang Zhang", "title": "When Machine Unlearning Jeopardizes Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right to be forgotten states that a data owner has the right to erase her\ndata from an entity storing it. In the context of machine learning (ML), the\nright to be forgotten requires an ML model owner to remove the data owner's\ndata from the training set used to build the ML model, a process known as\nmachine unlearning. While originally designed to protect the privacy of the\ndata owner, we argue that machine unlearning may leave some imprint of the data\nin the ML model and thus create unintended privacy risks.\n  In this paper, we perform the first study on investigating the unintended\ninformation leakage caused by machine unlearning. We propose a novel membership\ninference attack which leverages the different outputs of an ML model's two\nversions to infer whether the deleted sample is part of the training set. Our\nexperiments over five different datasets demonstrate that the proposed\nmembership inference attack achieves strong performance. More importantly, we\nshow that our attack in multiple cases outperforms the classical membership\ninference attack on the original ML model, which indicates that machine\nunlearning can have counterproductive effects on privacy. We notice that the\nprivacy degradation is especially significant for well-generalized ML models\nwhere classical membership inference does not perform well. We further\ninvestigate two mechanisms to mitigate the newly discovered privacy risks and\nshow that the only effective mechanism is to release the predicted label only.\nWe believe that our results can help improve privacy in practical\nimplementation of machine unlearning.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:11:52 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Chen", "Min", ""], ["Zhang", "Zhikun", ""], ["Wang", "Tianhao", ""], ["Backes", "Michael", ""], ["Humbert", "Mathias", ""], ["Zhang", "Yang", ""]]}, {"id": "2005.02209", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf and Emmanuelle Claeys", "title": "Hyper-parameter Tuning for the Contextual Bandit", "comments": "arXiv admin note: text overlap with arXiv:1705.03821", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study here the problem of learning the exploration exploitation trade-off\nin the contextual bandit problem with linear reward function setting. In the\ntraditional algorithms that solve the contextual bandit problem, the\nexploration is a parameter that is tuned by the user. However, our proposed\nalgorithm learn to choose the right exploration parameters in an online manner\nbased on the observed context, and the immediate reward received for the chosen\naction. We have presented here two algorithms that uses a bandit to find the\noptimal exploration of the contextual bandit algorithm, which we hope is the\nfirst step toward the automation of the multi-armed bandit algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:20:19 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Bouneffouf", "Djallel", ""], ["Claeys", "Emmanuelle", ""]]}, {"id": "2005.02249", "submitter": "Lev Utkin", "authors": "Maxim S. Kovalev and Lev V. Utkin", "title": "A robust algorithm for explaining unreliable machine learning survival\n  models using the Kolmogorov-Smirnov bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new robust algorithm based of the explanation method SurvLIME called\nSurvLIME-KS is proposed for explaining machine learning survival models. The\nalgorithm is developed to ensure robustness to cases of a small amount of\ntraining data or outliers of survival data. The first idea behind SurvLIME-KS\nis to apply the Cox proportional hazards model to approximate the black-box\nsurvival model at the local area around a test example due to the linear\nrelationship of covariates in the model. The second idea is to incorporate the\nwell-known Kolmogorov-Smirnov bounds for constructing sets of predicted\ncumulative hazard functions. As a result, the robust maximin strategy is used,\nwhich aims to minimize the average distance between cumulative hazard functions\nof the explained black-box model and of the approximating Cox model, and to\nmaximize the distance over all cumulative hazard functions in the interval\nproduced by the Kolmogorov-Smirnov bounds. The maximin optimization problem is\nreduced to the quadratic program. Various numerical experiments with synthetic\nand real datasets demonstrate the SurvLIME-KS efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:47:35 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Kovalev", "Maxim S.", ""], ["Utkin", "Lev V.", ""]]}, {"id": "2005.02251", "submitter": "Vladislav Goncharenko", "authors": "V. Goncharenko, R. Grigoryan, A. Samokhina", "title": "Raccoons vs Demons: multiclass labeled P300 dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We publish dataset of visual P300 BCI performed in Virtual Reality (VR) game\nRaccoons versus Demons (RvD). Data contains reach labels incorporating\ninformation about stimulus chosen enabling us to estimate model's confidence at\neach stimulus prediction stage. Data and experiments code are available at\nhttps://gitlab.com/impulse-neiry_public/raccoons-vs-demons\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 20:10:31 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 15:47:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Goncharenko", "V.", ""], ["Grigoryan", "R.", ""], ["Samokhina", "A.", ""]]}, {"id": "2005.02269", "submitter": "Agnieszka Miko{\\l}ajczyk", "authors": "Agnieszka Miko{\\l}ajczyk, Micha{\\l} Grochowski, Arkadiusz Kwasigroch", "title": "Towards explainable classifiers using the counterfactual approach --\n  global explanations for discovering bias in data", "comments": "Accepted for publication in Journal of Artificial Intelligence and\n  Soft Computing Research; 12 pages, 4 figures, code available, 8-pages\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes summarized attribution-based post-hoc explanations for the\ndetection and identification of bias in data. A global explanation is proposed,\nand a step-by-step framework on how to detect and test bias is introduced.\nSince removing unwanted bias is often a complicated and tremendous task, it is\nautomatically inserted, instead. Then, the bias is evaluated with the proposed\ncounterfactual approach. The obtained results are validated on a sample skin\nlesion dataset. Using the proposed method, a number of possible bias causing\nartifacts are successfully identified and confirmed in dermoscopy images. In\nparticular, it is confirmed that black frames have a strong influence on\nConvolutional Neural Network's prediction: 22% of them changed the prediction\nfrom benign to malignant.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:05:33 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 11:47:07 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Miko\u0142ajczyk", "Agnieszka", ""], ["Grochowski", "Micha\u0142", ""], ["Kwasigroch", "Arkadiusz", ""]]}, {"id": "2005.02313", "submitter": "Sukrut Rao", "authors": "Sukrut Rao, David Stutz, Bernt Schiele", "title": "Adversarial Training against Location-Optimized Adversarial Patches", "comments": "20 pages, 6 tables, 4 figures, 2 algorithms, European Conference on\n  Computer Vision Workshops 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be susceptible to adversarial\nexamples -- small, imperceptible changes constructed to cause\nmis-classification in otherwise highly accurate image classifiers. As a\npractical alternative, recent work proposed so-called adversarial patches:\nclearly visible, but adversarially crafted rectangular patches in images. These\npatches can easily be printed and applied in the physical world. While defenses\nagainst imperceptible adversarial examples have been studied extensively,\nrobustness against adversarial patches is poorly understood. In this work, we\nfirst devise a practical approach to obtain adversarial patches while actively\noptimizing their location within the image. Then, we apply adversarial training\non these location-optimized adversarial patches and demonstrate significantly\nimproved robustness on CIFAR10 and GTSRB. Additionally, in contrast to\nadversarial training on imperceptible adversarial examples, our adversarial\npatch training does not reduce accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 16:17:00 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 08:00:26 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Rao", "Sukrut", ""], ["Stutz", "David", ""], ["Schiele", "Bernt", ""]]}, {"id": "2005.02328", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Bindya Venkatesh, Rushil Anirudh, Peer-Timo\n  Bremer, Jim Gaffney, Gemma Anderson, Brian Spears", "title": "Designing Accurate Emulators for Scientific Processes using\n  Calibration-Driven Deep Models", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-19448-8", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models that accurately emulate complex scientific processes can\nachieve exponential speed-ups over numerical simulators or experiments, and at\nthe same time provide surrogates for improving the subsequent analysis.\nConsequently, there is a recent surge in utilizing modern machine learning (ML)\nmethods, such as deep neural networks, to build data-driven emulators. While\nthe majority of existing efforts has focused on tailoring off-the-shelf ML\nsolutions to better suit the scientific problem at hand, we study an often\noverlooked, yet important, problem of choosing loss functions to measure the\ndiscrepancy between observed data and the predictions from a model. Due to lack\nof better priors on the expected residual structure, in practice, simple\nchoices such as the mean squared error and the mean absolute error are made.\nHowever, the inherent symmetric noise assumption made by these loss functions\nmakes them inappropriate in cases where the data is heterogeneous or when the\nnoise distribution is asymmetric. We propose Learn-by-Calibrating (LbC), a\nnovel deep learning approach based on interval calibration for designing\nemulators in scientific applications, that are effective even with\nheterogeneous data and are robust to outliers. Using a large suite of\nuse-cases, we show that LbC provides significant improvements in generalization\nerror over widely-adopted loss function choices, achieves high-quality\nemulators even in small data regimes and more importantly, recovers the\ninherent noise structure without any explicit priors.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 16:54:11 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Venkatesh", "Bindya", ""], ["Anirudh", "Rushil", ""], ["Bremer", "Peer-Timo", ""], ["Gaffney", "Jim", ""], ["Anderson", "Gemma", ""], ["Spears", "Brian", ""]]}, {"id": "2005.02356", "submitter": "Shiqian Ma", "authors": "Shixiang Chen, Zengde Deng, Shiqian Ma, Anthony Man-Cho So", "title": "Manifold Proximal Point Algorithms for Dual Principal Component Pursuit\n  and Orthogonal Dictionary Learning", "comments": "Accepted in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing the $\\ell_1$ norm of a linear map over\nthe sphere, which arises in various machine learning applications such as\northogonal dictionary learning (ODL) and robust subspace recovery (RSR). The\nproblem is numerically challenging due to its nonsmooth objective and nonconvex\nconstraint, and its algorithmic aspects have not been well explored. In this\npaper, we show how the manifold structure of the sphere can be exploited to\ndesign fast algorithms for tackling this problem. Specifically, our\ncontribution is threefold. First, we present a manifold proximal point\nalgorithm (ManPPA) for the problem and show that it converges at a sublinear\nrate. Furthermore, we show that ManPPA can achieve a quadratic convergence rate\nwhen applied to the ODL and RSR problems. Second, we propose a stochastic\nvariant of ManPPA called StManPPA, which is well suited for large-scale\ncomputation, and establish its sublinear convergence rate. Both ManPPA and\nStManPPA have provably faster convergence rates than existing subgradient-type\nmethods. Third, using ManPPA as a building block, we propose a new approach to\nsolving a matrix analog of the problem, in which the sphere is replaced by the\nStiefel manifold. The results from our extensive numerical experiments on the\nODL and RSR problems demonstrate the efficiency and efficacy of our proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:40:03 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 13:40:06 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Shixiang", ""], ["Deng", "Zengde", ""], ["Ma", "Shiqian", ""], ["So", "Anthony Man-Cho", ""]]}, {"id": "2005.02359", "submitter": "Yedid Hoshen", "authors": "Liron Bergman and Yedid Hoshen", "title": "Classification-Based Anomaly Detection for General Data", "comments": "ICLR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection, finding patterns that substantially deviate from those\nseen previously, is one of the fundamental problems of artificial intelligence.\nRecently, classification-based methods were shown to achieve superior results\non this task. In this work, we present a unifying view and propose an open-set\nmethod, GOAD, to relax current generalization assumptions. Furthermore, we\nextend the applicability of transformation-based methods to non-image data\nusing random affine transformations. Our method is shown to obtain\nstate-of-the-art accuracy and is applicable to broad data types. The strong\nperformance of our method is extensively validated on multiple datasets from\ndifferent domains.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:44:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Bergman", "Liron", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2005.02372", "submitter": "Deepak Bhaskar Acharya", "authors": "Deepak Bhaskar Acharya, Huaming Zhang", "title": "Community Detection Clustering via Gumbel Softmax", "comments": "9 Pages, previous title was Clustering for Graph Datasets via Gumbel\n  Softmax", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, in many systems such as speech recognition and visual processing,\ndeep learning has been widely implemented. In this research, we are exploring\nthe possibility of using deep learning in community detection among the graph\ndatasets. Graphs have gained growing traction in different fields, including\nsocial networks, information graphs, the recommender system, and also life\nsciences. In this paper, we propose a method of community detection clustering\nthe nodes of various graph datasets. We cluster different category datasets\nthat belong to Affiliation networks, Animal networks, Human contact networks,\nHuman social networks, Miscellaneous networks. The deep learning role in\nmodeling the interaction between nodes in a network allows a revolution in the\nfield of science relevant to graph network analysis. In this paper, we extend\nthe gumbel softmax approach to graph network clustering. The experimental\nfindings on specific graph datasets reveal that the new approach outperforms\ntraditional clustering significantly, which strongly shows the efficacy of deep\nlearning in graph community detection clustering. We do a series of experiments\non our graph clustering algorithm, using various datasets: Zachary karate club,\nHighland Tribe, Train bombing, American Revolution, Dolphins, Zebra,\nWindsurfers, Les Mis\\'erables, Political books.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:55:31 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 03:04:35 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Acharya", "Deepak Bhaskar", ""], ["Zhang", "Huaming", ""]]}, {"id": "2005.02387", "submitter": "Lev Utkin", "authors": "Lev V. Utkin, Maxim S. Kovalev and Ernest M. Kasimov", "title": "SurvLIME-Inf: A simplified modification of SurvLIME for explanation of\n  machine learning survival models", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.08371,\n  arXiv:2005.02249", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new modification of the explanation method SurvLIME called SurvLIME-Inf for\nexplaining machine learning survival models is proposed. The basic idea behind\nSurvLIME as well as SurvLIME-Inf is to apply the Cox proportional hazards model\nto approximate the black-box survival model at the local area around a test\nexample. The Cox model is used due to the linear relationship of covariates. In\ncontrast to SurvLIME, the proposed modification uses $L_{\\infty }$-norm for\ndefining distances between approximating and approximated cumulative hazard\nfunctions. This leads to a simple linear programming problem for determining\nimportant features and for explaining the black-box model prediction. Moreover,\nSurvLIME-Inf outperforms SurvLIME when the training set is very small.\nNumerical experiments with synthetic and real datasets demonstrate the\nSurvLIME-Inf efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:34:46 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Utkin", "Lev V.", ""], ["Kovalev", "Maxim S.", ""], ["Kasimov", "Ernest M.", ""]]}, {"id": "2005.02392", "submitter": "Matteo Tiezzi", "authors": "Matteo Tiezzi, Giuseppe Marra, Stefano Melacci and Marco Maggini", "title": "Deep Constraint-based Propagation in Graph Neural Networks", "comments": "Published in: IEEE Transactions on Pattern Analysis and Machine\n  Intelligence. arXiv admin note: text overlap with arXiv:2002.07684", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3073504", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of deep learning techniques renewed the interest in neural\narchitectures able to process complex structures that can be represented using\ngraphs, inspired by Graph Neural Networks (GNNs). We focus our attention on the\noriginally proposed GNN model of Scarselli et al. 2009, which encodes the state\nof the nodes of the graph by means of an iterative diffusion procedure that,\nduring the learning stage, must be computed at every epoch, until the fixed\npoint of a learnable state transition function is reached, propagating the\ninformation among the neighbouring nodes. We propose a novel approach to\nlearning in GNNs, based on constrained optimization in the Lagrangian\nframework. Learning both the transition function and the node states is the\noutcome of a joint process, in which the state convergence procedure is\nimplicitly expressed by a constraint satisfaction mechanism, avoiding iterative\nepoch-wise procedures and the network unfolding. Our computational structure\nsearches for saddle points of the Lagrangian in the adjoint space composed of\nweights, nodes state variables and Lagrange multipliers. This process is\nfurther enhanced by multiple layers of constraints that accelerate the\ndiffusion process. An experimental analysis shows that the proposed approach\ncompares favourably with popular models on several benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 16:50:59 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 08:35:58 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 11:18:14 GMT"}, {"version": "v4", "created": "Mon, 19 Apr 2021 19:21:06 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 13:51:55 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Tiezzi", "Matteo", ""], ["Marra", "Giuseppe", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""]]}, {"id": "2005.02426", "submitter": "Zhishuai Guo", "authors": "Zhishuai Guo, Mingrui Liu, Zhuoning Yuan, Li Shen, Wei Liu, Tianbao\n  Yang", "title": "Communication-Efficient Distributed Stochastic AUC Maximization with\n  Deep Neural Networks", "comments": null, "journal-ref": "37th International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study distributed algorithms for large-scale AUC\nmaximization with a deep neural network as a predictive model. Although\ndistributed learning techniques have been investigated extensively in deep\nlearning, they are not directly applicable to stochastic AUC maximization with\ndeep neural networks due to its striking differences from standard loss\nminimization problems (e.g., cross-entropy). Towards addressing this challenge,\nwe propose and analyze a communication-efficient distributed optimization\nalgorithm based on a {\\it non-convex concave} reformulation of the AUC\nmaximization, in which the communication of both the primal variable and the\ndual variable between each worker and the parameter server only occurs after\nmultiple steps of gradient-based updates in each worker. Compared with the\nnaive parallel version of an existing algorithm that computes stochastic\ngradients at individual machines and averages them for updating the model\nparameters, our algorithm requires a much less number of communication rounds\nand still achieves a linear speedup in theory. To the best of our knowledge,\nthis is the \\textbf{first} work that solves the {\\it non-convex concave\nmin-max} problem for AUC maximization with deep neural networks in a\ncommunication-efficient distributed manner while still maintaining the linear\nspeedup property in theory. Our experiments on several benchmark datasets show\nthe effectiveness of our algorithm and also confirm our theory.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:08:23 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 06:54:36 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Guo", "Zhishuai", ""], ["Liu", "Mingrui", ""], ["Yuan", "Zhuoning", ""], ["Shen", "Li", ""], ["Liu", "Wei", ""], ["Yang", "Tianbao", ""]]}, {"id": "2005.02433", "submitter": "David Demeter", "authors": "David Demeter, Gregory Kimmel and Doug Downey", "title": "Stolen Probability: A Structural Weakness of Neural Language Models", "comments": "Preprint of paper accepted for ACL-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Network Language Models (NNLMs) generate probability distributions by\napplying a softmax function to a distance metric formed by taking the dot\nproduct of a prediction vector with all word vectors in a high-dimensional\nembedding space. The dot-product distance metric forms part of the inductive\nbias of NNLMs. Although NNLMs optimize well with this inductive bias, we show\nthat this results in a sub-optimal ordering of the embedding space that\nstructurally impoverishes some words at the expense of others when assigning\nprobability. We present numerical, theoretical and empirical analyses showing\nthat words on the interior of the convex hull in the embedding space have their\nprobability bounded by the probabilities of the words on the hull.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:40:32 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Demeter", "David", ""], ["Kimmel", "Gregory", ""], ["Downey", "Doug", ""]]}, {"id": "2005.02435", "submitter": "Aravind Jayendran", "authors": "Deepak Mishra, Aravind Jayendran, Prathosh A. P", "title": "Effect of The Latent Structure on Clustering with GANs", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.2996935", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have shown remarkable success in\ngeneration of data from natural data manifolds such as images. In several\nscenarios, it is desirable that generated data is well-clustered, especially\nwhen there is severe class imbalance. In this paper, we focus on the problem of\nclustering in generated space of GANs and uncover its relationship with the\ncharacteristics of the latent space. We derive from first principles, the\nnecessary and sufficient conditions needed to achieve faithful clustering in\nthe GAN framework: (i) presence of a multimodal latent space with adjustable\npriors, (ii) existence of a latent space inversion mechanism and (iii)\nimposition of the desired cluster priors on the latent space. We also identify\nthe GAN models in the literature that partially satisfy these conditions and\ndemonstrate the importance of all the components required, through ablative\nstudies on multiple real world image datasets. Additionally, we describe a\nprocedure to construct a multimodal latent space which facilitates learning of\ncluster priors with sparse supervision.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:52:49 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Mishra", "Deepak", ""], ["Jayendran", "Aravind", ""], ["P", "Prathosh A.", ""]]}, {"id": "2005.02480", "submitter": "Maxime Peyrard", "authors": "Maxime Peyrard and Robert West", "title": "A Ladder of Causal Distances", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal discovery, the task of automatically constructing a causal model from\ndata, is of major significance across the sciences. Evaluating the performance\nof causal discovery algorithms should ideally involve comparing the inferred\nmodels to ground-truth models available for benchmark datasets, which in turn\nrequires a notion of distance between causal models. While such distances have\nbeen proposed previously, they are limited by focusing on graphical properties\nof the causal models being compared. Here, we overcome this limitation by\ndefining distances derived from the causal distributions induced by the models,\nrather than exclusively from their graphical structure. Pearl and Mackenzie\n(2018) have arranged the properties of causal models in a hierarchy called the\n\"ladder of causation\" spanning three rungs: observational, interventional, and\ncounterfactual. Following this organization, we introduce a hierarchy of three\ndistances, one for each rung of the ladder. Our definitions are intuitively\nappealing as well as efficient to compute approximately. We put our causal\ndistances to use by benchmarking standard causal discovery systems on both\nsynthetic and real-world datasets for which ground-truth causal models are\navailable. Finally, we highlight the usefulness of our causal distances by\nbriefly discussing further applications beyond the evaluation of causal\ndiscovery techniques.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:39:07 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Peyrard", "Maxime", ""], ["West", "Robert", ""]]}, {"id": "2005.02503", "submitter": "Semih Yagli", "authors": "Semih Yagli, Alex Dytso, H. Vincent Poor", "title": "Information-Theoretic Bounds on the Generalization Error and Privacy\n  Leakage in Federated Learning", "comments": "Accepted for publication in Proceedings of 21st IEEE International\n  Workshop on Signal Processing Advances in Wireless Communications (SPAWC),\n  2020. arXiv version is 10pt font, 6 Pages. This is the same document as the\n  SPAWC version, except that the conference version is written with 9pt font to\n  meet the strict page margin requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms operating on mobile networks can be characterized\ninto three different categories. First is the classical situation in which the\nend-user devices send their data to a central server where this data is used to\ntrain a model. Second is the distributed setting in which each device trains\nits own model and send its model parameters to a central server where these\nmodel parameters are aggregated to create one final model. Third is the\nfederated learning setting in which, at any given time $t$, a certain number of\nactive end users train with their own local data along with feedback provided\nby the central server and then send their newly estimated model parameters to\nthe central server. The server, then, aggregates these new parameters, updates\nits own model, and feeds the updated parameters back to all the end users,\ncontinuing this process until it converges.\n  The main objective of this work is to provide an information-theoretic\nframework for all of the aforementioned learning paradigms. Moreover, using the\nprovided framework, we develop upper and lower bounds on the generalization\nerror together with bounds on the privacy leakage in the classical, distributed\nand federated learning settings.\n  Keywords: Federated Learning, Distributed Learning, Machine Learning, Model\nAggregation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 21:23:45 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Yagli", "Semih", ""], ["Dytso", "Alex", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2005.02505", "submitter": "Wahid Khosrawi", "authors": "Christa Cuchiero and Wahid Khosrawi and Josef Teichmann", "title": "A generative adversarial network approach to calibration of local\n  stochastic volatility models", "comments": "Replacement for previous version: Major update of previous version to\n  match the content of the published version", "journal-ref": "Risks 2020, 8, 101", "doi": "10.3390/risks8040101", "report-no": null, "categories": "q-fin.CP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fully data-driven approach to calibrate local stochastic\nvolatility (LSV) models, circumventing in particular the ad hoc interpolation\nof the volatility surface. To achieve this, we parametrize the leverage\nfunction by a family of feed-forward neural networks and learn their parameters\ndirectly from the available market option prices. This should be seen in the\ncontext of neural SDEs and (causal) generative adversarial networks: we\ngenerate volatility surfaces by specific neural SDEs, whose quality is assessed\nby quantifying, possibly in an adversarial manner, distances to market prices.\nThe minimization of the calibration functional relies strongly on a variance\nreduction technique based on hedging and deep hedging, which is interesting in\nits own right: it allows the calculation of model prices and model implied\nvolatilities in an accurate way using only small sets of sample paths. For\nnumerical illustration we implement a SABR-type LSV model and conduct a\nthorough statistical performance analysis on many samples of implied volatility\nsmiles, showing the accuracy and stability of the method.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 21:26:20 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 11:02:18 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 09:53:10 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Cuchiero", "Christa", ""], ["Khosrawi", "Wahid", ""], ["Teichmann", "Josef", ""]]}, {"id": "2005.02515", "submitter": "Myrl Marmarelis", "authors": "Myrl G. Marmarelis, Greg Ver Steeg, Aram Galstyan", "title": "Latent Embeddings of Point Process Excitations", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When specific events seem to spur others in their wake, marked Hawkes\nprocesses enable us to reckon with their statistics. The underdetermined\nempirical nature of these event-triggering mechanisms hinders estimation in the\nmultivariate setting. Spatiotemporal applications alleviate this obstacle by\nallowing relationships to depend only on relative distances in real Euclidean\nspace; we employ the framework as a vessel for embedding arbitrary event types\nin a new latent space. By performing synthetic experiments on short records as\nwell as an investigation into options markets and pathogens, we demonstrate\nthat learning the embedding alongside a point process model uncovers the\ncoherent, rather than spurious, interactions.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 21:54:22 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 22:23:37 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 00:45:44 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Marmarelis", "Myrl G.", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "2005.02525", "submitter": "Henrique Lemos", "authors": "Henrique Lemos and Pedro Avelar and Marcelo Prates and Lu\\'is Lamb and\n  Artur Garcez", "title": "Neural-Symbolic Relational Reasoning on Graph Models: Effective Link\n  Inference and Computation from Knowledge Bases", "comments": "Under review: ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent developments and growing interest in neural-symbolic models has\nshown that hybrid approaches can offer richer models for Artificial\nIntelligence. The integration of effective relational learning and reasoning\nmethods is one of the key challenges in this direction, as neural learning and\nsymbolic reasoning offer complementary characteristics that can benefit the\ndevelopment of AI systems. Relational labelling or link prediction on knowledge\ngraphs has become one of the main problems in deep learning-based natural\nlanguage processing research. Moreover, other fields which make use of\nneural-symbolic techniques may also benefit from such research endeavours.\nThere have been several efforts towards the identification of missing facts\nfrom existing ones in knowledge graphs. Two lines of research try and predict\nknowledge relations between two entities by considering all known facts\nconnecting them or several paths of facts connecting them. We propose a\nneural-symbolic graph neural network which applies learning over all the paths\nby feeding the model with the embedding of the minimal subset of the knowledge\ngraph containing such paths. By learning to produce representations for\nentities and facts corresponding to word embeddings, we show how the model can\nbe trained end-to-end to decode these representations and infer relations\nbetween entities in a multitask approach. Our contribution is two-fold: a\nneural-symbolic methodology leverages the resolution of relational inference in\nlarge graphs, and we also demonstrate that such neural-symbolic model is shown\nmore effective than path-based approaches\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 22:46:39 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Lemos", "Henrique", ""], ["Avelar", "Pedro", ""], ["Prates", "Marcelo", ""], ["Lamb", "Lu\u00eds", ""], ["Garcez", "Artur", ""]]}, {"id": "2005.02540", "submitter": "Hyeongji Kim", "authors": "Hyeongji Kim, Pekka Parviainen, Ketil Malde", "title": "Measuring Adversarial Robustness using a Voronoi-Epsilon Adversary", "comments": "10 pages. Published at ICLR 2021 Workshop on Security and Safety in\n  Machine Learning Systems. Some definitions (names) are changed from the\n  previous versions. Some sections are also removed. This paper supersedes the\n  paper \"Finding a human-like classifier\".\n  (https://openreview.net/forum?id=BJeGFs9FsH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies on robustness have argued that there is a tradeoff between\naccuracy and adversarial accuracy. The tradeoff can be inevitable even when we\nneglect generalization. We argue that the tradeoff is inherent to the commonly\nused definition of adversarial accuracy, which uses an adversary that can\nconstruct adversarial points constrained by $\\epsilon$-balls around data\npoints. As $\\epsilon$ gets large, the adversary may use real data points from\nother classes as adversarial examples. We propose a Voronoi-epsilon adversary\nwhich is constrained both by Voronoi cells and by $\\epsilon$-balls. This\nadversary balances between two notions of perturbation. As a result,\nadversarial accuracy based on this adversary avoids a tradeoff between accuracy\nand adversarial accuracy on training data even when $\\epsilon$ is large.\nFinally, we show that a nearest neighbor classifier is the maximally robust\nclassifier against the proposed adversary on the training data.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 00:09:28 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 12:07:29 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 15:20:35 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Kim", "Hyeongji", ""], ["Parviainen", "Pekka", ""], ["Malde", "Ketil", ""]]}, {"id": "2005.02552", "submitter": "Shuya Ding", "authors": "Guanlin Li, Shuya Ding, Jun Luo, Chang Liu", "title": "Enhancing Intrinsic Adversarial Robustness via Feature Pyramid Decoder", "comments": null, "journal-ref": "CVPR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas adversarial training is employed as the main defence strategy against\nspecific adversarial samples, it has limited generalization capability and\nincurs excessive time complexity. In this paper, we propose an attack-agnostic\ndefence framework to enhance the intrinsic robustness of neural networks,\nwithout jeopardizing the ability of generalizing clean samples. Our Feature\nPyramid Decoder (FPD) framework applies to all block-based convolutional neural\nnetworks (CNNs). It implants denoising and image restoration modules into a\ntargeted CNN, and it also constraints the Lipschitz constant of the\nclassification layer. Moreover, we propose a two-phase strategy to train the\nFPD-enhanced CNN, utilizing $\\epsilon$-neighbourhood noisy images with\nmulti-task and self-supervised learning. Evaluated against a variety of\nwhite-box and black-box attacks, we demonstrate that FPD-enhanced CNNs gain\nsufficient robustness against general adversarial samples on MNIST, SVHN and\nCALTECH. In addition, if we further conduct adversarial training, the\nFPD-enhanced CNNs perform better than their non-enhanced versions.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 01:40:26 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Li", "Guanlin", ""], ["Ding", "Shuya", ""], ["Luo", "Jun", ""], ["Liu", "Chang", ""]]}, {"id": "2005.02553", "submitter": "Honglei Zhuang", "authors": "Honglei Zhuang, Xuanhui Wang, Michael Bendersky, Alexander Grushetsky,\n  Yonghui Wu, Petr Mitrichev, Ethan Sterling, Nathan Bell, Walker Ravina, Hai\n  Qian", "title": "Interpretable Learning-to-Rank with Generalized Additive Models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of learning-to-rank models is a crucial yet relatively\nunder-examined research area. Recent progress on interpretable ranking models\nlargely focuses on generating post-hoc explanations for existing black-box\nranking models, whereas the alternative option of building an intrinsically\ninterpretable ranking model with transparent and self-explainable structure\nremains unexplored. Developing fully-understandable ranking models is necessary\nin some scenarios (e.g., due to legal or policy constraints) where post-hoc\nmethods cannot provide sufficiently accurate explanations. In this paper, we\nlay the groundwork for intrinsically interpretable learning-to-rank by\nintroducing generalized additive models (GAMs) into ranking tasks. Generalized\nadditive models (GAMs) are intrinsically interpretable machine learning models\nand have been extensively studied on regression and classification tasks. We\nstudy how to extend GAMs into ranking models which can handle both item-level\nand list-level features and propose a novel formulation of ranking GAMs. To\ninstantiate ranking GAMs, we employ neural networks instead of traditional\nsplines or regression trees. We also show that our neural ranking GAMs can be\ndistilled into a set of simple and compact piece-wise linear functions that are\nmuch more efficient to evaluate with little accuracy loss. We conduct\nexperiments on three data sets and show that our proposed neural ranking GAMs\ncan achieve significantly better performance than other traditional GAM\nbaselines while maintaining similar interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 01:51:30 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 18:44:23 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Zhuang", "Honglei", ""], ["Wang", "Xuanhui", ""], ["Bendersky", "Michael", ""], ["Grushetsky", "Alexander", ""], ["Wu", "Yonghui", ""], ["Mitrichev", "Petr", ""], ["Sterling", "Ethan", ""], ["Bell", "Nathan", ""], ["Ravina", "Walker", ""], ["Qian", "Hai", ""]]}, {"id": "2005.02589", "submitter": "Anirudh Som", "authors": "Anirudh Som, Narayanan Krishnamurthi, Matthew Buman and Pavan Turaga", "title": "Unsupervised Pre-trained Models from Healthy ADLs Improve Parkinson's\n  Disease Classification of Gait Patterns", "comments": "Accepted in the 42nd Annual International Conferences of the IEEE\n  Engineering in Medicine and Biology Society (EMBC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application and use of deep learning algorithms for different healthcare\napplications is gaining interest at a steady pace. However, use of such\nalgorithms can prove to be challenging as they require large amounts of\ntraining data that capture different possible variations. This makes it\ndifficult to use them in a clinical setting since in most health applications\nresearchers often have to work with limited data. Less data can cause the deep\nlearning model to over-fit. In this paper, we ask how can we use data from a\ndifferent environment, different use-case, with widely differing data\ndistributions. We exemplify this use case by using single-sensor accelerometer\ndata from healthy subjects performing activities of daily living - ADLs (source\ndataset), to extract features relevant to multi-sensor accelerometer gait data\n(target dataset) for Parkinson's disease classification. We train the\npre-trained model using the source dataset and use it as a feature extractor.\nWe show that the features extracted for the target dataset can be used to train\nan effective classification model. Our pre-trained source model consists of a\nconvolutional autoencoder, and the target classification model is a simple\nmulti-layer perceptron model. We explore two different pre-trained source\nmodels, trained using different activity groups, and analyze the influence the\nchoice of pre-trained model has over the task of Parkinson's disease\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 04:08:19 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 00:56:01 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Som", "Anirudh", ""], ["Krishnamurthi", "Narayanan", ""], ["Buman", "Matthew", ""], ["Turaga", "Pavan", ""]]}, {"id": "2005.02593", "submitter": "Yinqiao Li", "authors": "Yinqiao Li, Chi Hu, Yuhao Zhang, Nuo Xu, Yufan Jiang, Tong Xiao,\n  Jingbo Zhu, Tongran Liu, Changliang Li", "title": "Learning Architectures from an Extended Search Space for Language\n  Modeling", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has advanced significantly in recent years\nbut most NAS systems restrict search to learning architectures of a recurrent\nor convolutional cell. In this paper, we extend the search space of NAS. In\nparticular, we present a general approach to learn both intra-cell and\ninter-cell architectures (call it ESS). For a better search result, we design a\njoint learning method to perform intra-cell and inter-cell NAS simultaneously.\nWe implement our model in a differentiable architecture search system. For\nrecurrent neural language modeling, it outperforms a strong baseline\nsignificantly on the PTB and WikiText data, with a new state-of-the-art on PTB.\nMoreover, the learned architectures show good transferability to other systems.\nE.g., they improve state-of-the-art systems on the CoNLL and WNUT named entity\nrecognition (NER) tasks and CoNLL chunking task, indicating a promising line of\nresearch on large-scale pre-learned architectures.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:02:33 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 06:23:49 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Li", "Yinqiao", ""], ["Hu", "Chi", ""], ["Zhang", "Yuhao", ""], ["Xu", "Nuo", ""], ["Jiang", "Yufan", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""], ["Liu", "Tongran", ""], ["Li", "Changliang", ""]]}, {"id": "2005.02595", "submitter": "Ashish Gupta", "authors": "Ashish Gupta, Hari Prabhat Gupta, Bhaskar Biswas, Tanima Dutta", "title": "Approaches and Applications of Early Classification of Time Series: A\n  Review", "comments": "15 pages, 6 figures, 6 tables", "journal-ref": "IEEE Transactions on Artificial Intelligence (2020)", "doi": "10.1109/TAI.2020.3027279", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Early classification of time series has been extensively studied for\nminimizing class prediction delay in time-sensitive applications such as\nhealthcare and finance. A primary task of an early classification approach is\nto classify an incomplete time series as soon as possible with some desired\nlevel of accuracy. Recent years have witnessed several approaches for early\nclassification of time series. As most of the approaches have solved the early\nclassification problem with different aspects, it becomes very important to\nmake a thorough review of the existing solutions to know the current status of\nthe area. These solutions have demonstrated reasonable performance in a wide\nrange of applications including human activity recognition, gene expression\nbased health diagnostic, industrial monitoring, and so on. In this paper, we\npresent a systematic review of current literature on early classification\napproaches for both univariate and multivariate time series. We divide various\nexisting approaches into four exclusive categories based on their proposed\nsolution strategies. The four categories include prefix based, shapelet based,\nmodel based, and miscellaneous approaches. The authors also discuss the\napplications of early classification in many areas including industrial\nmonitoring, intelligent transportation, and medical. Finally, we provide a\nquick summary of the current literature with future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:12:22 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 18:06:28 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Gupta", "Ashish", ""], ["Gupta", "Hari Prabhat", ""], ["Biswas", "Bhaskar", ""], ["Dutta", "Tanima", ""]]}, {"id": "2005.02612", "submitter": "Kubra Cilingir", "authors": "Kubra Cilingir, Rachel Manzelli, Brian Kulis", "title": "Deep Divergence Learning", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical linear metric learning methods have recently been extended along\ntwo distinct lines: deep metric learning methods for learning embeddings of the\ndata using neural networks, and Bregman divergence learning approaches for\nextending learning Euclidean distances to more general divergence measures such\nas divergences over distributions. In this paper, we introduce deep Bregman\ndivergences, which are based on learning and parameterizing functional Bregman\ndivergences using neural networks, and which unify and extend these existing\nlines of work. We show in particular how deep metric learning formulations,\nkernel metric learning, Mahalanobis metric learning, and moment-matching\nfunctions for comparing distributions arise as special cases of these\ndivergences in the symmetric setting. We then describe a deep learning\nframework for learning general functional Bregman divergences, and show in\nexperiments that this method yields superior performance on benchmark datasets\nas compared to existing deep metric learning approaches. We also discuss novel\napplications, including a semi-supervised distributional clustering problem,\nand a new loss function for unsupervised data generation.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 06:43:25 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Cilingir", "Kubra", ""], ["Manzelli", "Rachel", ""], ["Kulis", "Brian", ""]]}, {"id": "2005.02637", "submitter": "Durgesh Samariya", "authors": "Durgesh Samariya and Jiangang Ma and Sunil Aryal", "title": "A Comprehensive Survey on Outlying Aspect Mining Methods", "comments": "12 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, researchers have become increasingly interested in outlying\naspect mining. Outlying aspect mining is the task of finding a set of\nfeature(s), where a given data object is different from the rest of the data\nobjects. Remarkably few studies have been designed to address the problem of\noutlying aspect mining; therefore, little is known about outlying aspect mining\napproaches and their strengths and weaknesses among researchers. In this work,\nwe have grouped existing outlying aspect mining approaches in three different\ncategories. For each category, we have provided existing work that falls in\nthat category and then provided their strengths and weaknesses in those\ncategories. We also offer time complexity comparison of the current techniques\nsince it is a crucial issue in the real-world scenario. The motive behind this\npaper is to give a better understanding of the existing outlying aspect mining\ntechniques and how these techniques have been developed.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 07:48:34 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 04:39:51 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Samariya", "Durgesh", ""], ["Ma", "Jiangang", ""], ["Aryal", "Sunil", ""]]}, {"id": "2005.02649", "submitter": "EPTCS", "authors": "Tuomas Halvari, Jukka K. Nurminen, Tommi Mikkonen", "title": "Testing the Robustness of AutoML Systems", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 103-116", "doi": "10.4204/EPTCS.319.8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning (AutoML) systems aim at finding the best machine\nlearning (ML) pipeline that automatically matches the task and data at hand. We\ninvestigate the robustness of machine learning pipelines generated with three\nAutoML systems, TPOT, H2O, and AutoKeras. In particular, we study the influence\nof dirty data on accuracy, and consider how using dirty training data may help\ncreate more robust solutions. Furthermore, we also analyze how the structure of\nthe generated pipelines differs in different cases.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 08:20:03 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 01:32:38 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Halvari", "Tuomas", ""], ["Nurminen", "Jukka K.", ""], ["Mikkonen", "Tommi", ""]]}, {"id": "2005.02664", "submitter": "Fan He", "authors": "Fan He, Kexin Lv, Jie Yang, Xiaolin Huang", "title": "One-shot Distibuted Algorithm for PCA with RBF Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes a one-shot algorithm for feature-distributed kernel PCA.\nOur algorithm is inspired by the dual relationship between sample-distributed\nand feature-distributed scenario. This interesting relationship makes it\npossible to establish distributed kernel PCA for feature-distributed cases from\nideas in distributed PCA in sample-distributed scenario. In theoretical part,\nwe analyze the approximation error for both linear and RBF kernels. The result\nsuggests that when eigenvalues decay fast, the proposed algorithm gives high\nquality results with low communication cost. This result is also verified by\nnumerical experiments, showing the effectiveness of our algorithm in practice.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 09:07:50 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 02:17:46 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 07:11:47 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["He", "Fan", ""], ["Lv", "Kexin", ""], ["Yang", "Jie", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2005.02773", "submitter": "Topi Paananen", "authors": "Topi Paananen, Alejandro Catalina, Paul-Christian B\\\"urkner, Aki\n  Vehtari", "title": "Group Heterogeneity Assessment for Multilevel Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many data sets contain an inherent multilevel structure, for example, because\nof repeated measurements of the same observational units. Taking this structure\ninto account is critical for the accuracy and calibration of any statistical\nanalysis performed on such data. However, the large number of possible model\nconfigurations hinders the use of multilevel models in practice. In this work,\nwe propose a flexible framework for efficiently assessing differences between\nthe levels of given grouping variables in the data. The assessed group\nheterogeneity is valuable in choosing the relevant group coefficients to\nconsider in a multilevel model. Our empirical evaluations demonstrate that the\nframework can reliably identify relevant multilevel components in both\nsimulated and real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 12:42:04 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Paananen", "Topi", ""], ["Catalina", "Alejandro", ""], ["B\u00fcrkner", "Paul-Christian", ""], ["Vehtari", "Aki", ""]]}, {"id": "2005.02791", "submitter": "Nathan Kallus", "authors": "Yichun Hu and Nathan Kallus", "title": "DTR Bandit: Learning to Make Response-Adaptive Decisions With Low Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic treatment regimes (DTRs) are personalized, adaptive, multi-stage\ntreatment plans that adapt treatment decisions both to an individual's initial\nfeatures and to intermediate outcomes and features at each subsequent stage,\nwhich are affected by decisions in prior stages. Examples include personalized\nfirst- and second-line treatments of chronic conditions like diabetes, cancer,\nand depression, which adapt to patient response to first-line treatment,\ndisease progression, and individual characteristics. While existing literature\nmostly focuses on estimating the optimal DTR from offline data such as from\nsequentially randomized trials, we study the problem of developing the optimal\nDTR in an online manner, where the interaction with each individual affect both\nour cumulative reward and our data collection for future learning. We term this\nthe DTR bandit problem. We propose a novel algorithm that, by carefully\nbalancing exploration and exploitation, is guaranteed to achieve rate-optimal\nregret when the transition and reward models are linear. We demonstrate our\nalgorithm and its benefits both in synthetic experiments and in a case study of\nadaptive treatment of major depressive disorder using real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:03:42 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 17:34:53 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Hu", "Yichun", ""], ["Kallus", "Nathan", ""]]}, {"id": "2005.02794", "submitter": "Deajin Jo", "authors": "DaeJin Jo", "title": "Token Manipulation Generative Adversarial Network for Text Generation", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MaskGAN opens the query for the conditional language model by filling in the\nblanks between the given tokens. In this paper, we focus on addressing the\nlimitations caused by having to specify blanks to be filled. We decompose\nconditional text generation problem into two tasks, make-a-blank and\nfill-in-the-blank, and extend the former to handle more complex manipulations\non the given tokens. We cast these tasks as a hierarchical multi agent RL\nproblem and introduce a conditional adversarial learning that allows the agents\nto reach a goal, producing realistic texts, in cooperative setting. We show\nthat the proposed model not only addresses the limitations but also provides\ngood results without compromising the performance in terms of quality and\ndiversity.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:10:43 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 12:17:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Jo", "DaeJin", ""]]}, {"id": "2005.02817", "submitter": "Saswata Sahoo Dr", "authors": "Saswata Sahoo and Souradip Chakraborty", "title": "Graph Spectral Feature Learning for Mixed Data of Categorical and\n  Numerical Type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature learning in the presence of a mixed type of variables, numerical and\ncategorical types, is an important issue for related modeling problems. For\nsimple neighborhood queries under mixed data space, standard practice is to\nconsider numerical and categorical variables separately and combining them\nbased on some suitable distance functions. Alternatives, such as Kernel\nlearning or Principal Component do not explicitly consider the inter-dependence\nstructure among the mixed type of variables. In this work, we propose a novel\nstrategy to explicitly model the probabilistic dependence structure among the\nmixed type of variables by an undirected graph. Spectral decomposition of the\ngraph Laplacian provides the desired feature transformation. The Eigen spectrum\nof the transformed feature space shows increased separability and more\nprominent clusterability among the observations. The main novelty of our paper\nlies in capturing interactions of the mixed feature type in an unsupervised\nframework using a graphical model. We numerically validate the implications of\nthe feature learning strategy\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:36:59 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Sahoo", "Saswata", ""], ["Chakraborty", "Souradip", ""]]}, {"id": "2005.02870", "submitter": "Toshiaki Koike-Akino", "authors": "Toshiaki Koike-Akino and Ye Wang", "title": "Stochastic Bottleneck: Rateless Auto-Encoder for Flexible Dimensionality\n  Reduction", "comments": "14 pages, 12 figures, ISIT 2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new concept of rateless auto-encoders (RL-AEs) that enable a\nflexible latent dimensionality, which can be seamlessly adjusted for varying\ndistortion and dimensionality requirements. In the proposed RL-AEs, instead of\na deterministic bottleneck architecture, we use an over-complete representation\nthat is stochastically regularized with weighted dropouts, in a manner\nanalogous to sparse AE (SAE). Unlike SAEs, our RL-AEs employ monotonically\nincreasing dropout rates across the latent representation nodes such that the\nlatent variables become sorted by importance like in principal component\nanalysis (PCA). This is motivated by the rateless property of conventional PCA,\nwhere the least important principal components can be discarded to realize\nvariable rate dimensionality reduction that gracefully degrades the distortion.\nIn contrast, since the latent variables of conventional AEs are equally\nimportant for data reconstruction, they cannot be simply discarded to further\nreduce the dimensionality after the AE model is trained. Our proposed\nstochastic bottleneck framework enables seamless rate adaptation with high\nreconstruction performance, without requiring predetermined latent\ndimensionality at training. We experimentally demonstrate that the proposed\nRL-AEs can achieve variable dimensionality reduction while achieving low\ndistortion compared to conventional AEs.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 14:47:42 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Koike-Akino", "Toshiaki", ""], ["Wang", "Ye", ""]]}, {"id": "2005.02921", "submitter": "Tom Michoel", "authors": "Muhammad Ammar Malik and Tom Michoel", "title": "Restricted maximum-likelihood method for learning latent variance\n  components in gene expression data with known and unknown confounders", "comments": "13 pages, 4 figures, plus 16 pages supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG q-bio.GN q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear mixed modelling is a popular approach for detecting and correcting\nspurious sample correlations due to hidden confounders in genome-wide gene\nexpression data. In applications where some confounding factors are known,\nestimating simultaneously the contribution of known and latent variance\ncomponents in linear mixed models is a challenge that has so far relied on\nnumerical gradient-based optimizers to maximize the likelihood function. This\nis unsatisfactory because the resulting solution is poorly characterized and\nthe efficiency of the method may be suboptimal. Here we prove analytically that\nmaximum-likelihood latent variables can always be chosen orthogonal to the\nknown confounding factors, in other words, that maximum-likelihood latent\nvariables explain sample covariances not already explained by known factors.\nBased on this result we propose a restricted maximum-likelihood method which\nestimates the latent variables by maximizing the likelihood on the restricted\nsubspace orthogonal to the known confounding factors, and show that this\nreduces to probabilistic PCA on that subspace. The method then estimates the\nvariance-covariance parameters by maximizing the remaining terms in the\nlikelihood function given the latent variables, using a newly derived analytic\nsolution for this problem. Compared to gradient-based optimizers, our method\nattains equal or higher likelihood values, can be computed using standard\nmatrix operations, results in latent factors that don't overlap with any known\nfactors, and has a runtime reduced by several orders of magnitude. We\nanticipate that the restricted maximum-likelihood method will facilitate the\napplication of linear mixed modelling strategies for learning latent variance\ncomponents to much larger gene expression datasets than currently possible.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 15:53:17 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Malik", "Muhammad Ammar", ""], ["Michoel", "Tom", ""]]}, {"id": "2005.02929", "submitter": "Patricia Pauli", "authors": "Patricia Pauli, Anne Koch, Julian Berberich, Paul Kohler, Frank\n  Allg\\\"ower", "title": "Training robust neural networks using Lipschitz bounds", "comments": null, "journal-ref": null, "doi": "10.1109/LCSYS.2021.3050444", "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their susceptibility to adversarial perturbations, neural networks\n(NNs) are hardly used in safety-critical applications. One measure of\nrobustness to such perturbations in the input is the Lipschitz constant of the\ninput-output map defined by an NN. In this work, we propose a framework to\ntrain multi-layer NNs while at the same time encouraging robustness by keeping\ntheir Lipschitz constant small, thus addressing the robustness issue. More\nspecifically, we design an optimization scheme based on the Alternating\nDirection Method of Multipliers that minimizes not only the training loss of an\nNN but also its Lipschitz constant resulting in a semidefinite programming\nbased training procedure that promotes robustness. We design two versions of\nthis training procedure. The first one includes a regularizer that penalizes an\naccurate upper bound on the Lipschitz constant. The second one allows to\nenforce a desired Lipschitz bound on the NN at all times during training.\nFinally, we provide two examples to show that the proposed framework\nsuccessfully increases the robustness of NNs.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:07:46 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 09:07:11 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Pauli", "Patricia", ""], ["Koch", "Anne", ""], ["Berberich", "Julian", ""], ["Kohler", "Paul", ""], ["Allg\u00f6wer", "Frank", ""]]}, {"id": "2005.02934", "submitter": "Pierre-Alexandre Kamienny Mr", "authors": "Pierre-Alexandre Kamienny, Matteo Pirotta, Alessandro Lazaric,\n  Thibault Lavril, Nicolas Usunier, Ludovic Denoyer", "title": "Learning Adaptive Exploration Strategies in Dynamic Environments Through\n  Informed Policy Regularization", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning exploration-exploitation strategies that\neffectively adapt to dynamic environments, where the task may change over time.\nWhile RNN-based policies could in principle represent such strategies, in\npractice their training time is prohibitive and the learning process often\nconverges to poor solutions. In this paper, we consider the case where the\nagent has access to a description of the task (e.g., a task id or task\nparameters) at training time, but not at test time. We propose a novel\nalgorithm that regularizes the training of an RNN-based policy using informed\npolicies trained to maximize the reward in each task. This dramatically reduces\nthe sample complexity of training RNN-based policies, without losing their\nrepresentational power. As a result, our method learns exploration strategies\nthat efficiently balance between gathering information about the unknown and\nchanging task and maximizing the reward over time. We test the performance of\nour algorithm in a variety of environments where tasks may vary within each\nepisode.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:14:48 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Kamienny", "Pierre-Alexandre", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""], ["Lavril", "Thibault", ""], ["Usunier", "Nicolas", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "2005.02960", "submitter": "Colin White", "authors": "Colin White, Sam Nolen, Yash Savani", "title": "Exploring the Loss Landscape in Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has seen a steep rise in interest over the\nlast few years. Many algorithms for NAS consist of searching through a space of\narchitectures by iteratively choosing an architecture, evaluating its\nperformance by training it, and using all prior evaluations to come up with the\nnext choice. The evaluation step is noisy - the final accuracy varies based on\nthe random initialization of the weights. Prior work has focused on devising\nnew search algorithms to handle this noise, rather than quantifying or\nunderstanding the level of noise in architecture evaluations. In this work, we\nshow that (1) the simplest hill-climbing algorithm is a powerful baseline for\nNAS, and (2), when the noise in popular NAS benchmark datasets is reduced to a\nminimum, hill-climbing to outperforms many popular state-of-the-art algorithms.\nWe further back up this observation by showing that the number of local minima\nis substantially reduced as the noise decreases, and by giving a theoretical\ncharacterization of the performance of local search in NAS. Based on our\nfindings, for NAS research we suggest (1) using local search as a baseline, and\n(2) denoising the training pipeline when possible.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:09:16 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 17:41:43 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 17:41:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["White", "Colin", ""], ["Nolen", "Sam", ""], ["Savani", "Yash", ""]]}, {"id": "2005.02970", "submitter": "Pravesh K Kothari", "authors": "Ainesh Bakshi and Pravesh Kothari", "title": "Outlier-Robust Clustering of Non-Spherical Mixtures", "comments": "This version fixes a few typos and includes detailed proofs of the\n  certifiable bounded variance property in Section 8 for natural distributions\n  classes (fixing an issue with a generic lemma that proved such a property for\n  a class of distributions in the previous version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first outlier-robust efficient algorithm for clustering a mixture\nof $k$ statistically separated d-dimensional Gaussians (k-GMMs). Concretely,\nour algorithm takes input an $\\epsilon$-corrupted sample from a $k$-GMM and whp\nin $d^{\\text{poly}(k/\\eta)}$ time, outputs an approximate clustering that\nmisclassifies at most $k^{O(k)}(\\epsilon+\\eta)$ fraction of the points whenever\nevery pair of mixture components are separated by\n$1-\\exp(-\\text{poly}(k/\\eta)^k)$ in total variation (TV) distance. Such a\nresult was not previously known even for $k=2$. TV separation is the\nstatistically weakest possible notion of separation and captures important\nspecial cases such as mixed linear regression and subspace clustering.\n  Our main conceptual contribution is to distill simple analytic properties -\n(certifiable) hypercontractivity and bounded variance of degree 2 polynomials\nand anti-concentration of linear projections - that are necessary and\nsufficient for mixture models to be (efficiently) clusterable. As a\nconsequence, our results extend to clustering mixtures of arbitrary affine\ntransforms of the uniform distribution on the $d$-dimensional unit sphere. Even\nthe information-theoretic clusterability of separated distributions satisfying\nthese two analytic assumptions was not known prior to our work and is likely to\nbe of independent interest.\n  Our algorithms build on the recent sequence of works relying on certifiable\nanti-concentration first introduced in the works of Karmarkar, Klivans, and\nKothari and Raghavendra, and Yau in 2019. Our techniques expand the\nsum-of-squares toolkit to show robust certifiability of TV-separated Gaussian\nclusters in data. This involves giving a low-degree sum-of-squares proof of\nstatements that relate parameter (i.e. mean and covariances) distance to total\nvariation distance by relying only on hypercontractivity and\nanti-concentration.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:24:27 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 17:37:14 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 18:00:59 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bakshi", "Ainesh", ""], ["Kothari", "Pravesh", ""]]}, {"id": "2005.02971", "submitter": "Gianluigi Pillonetto Dr.", "authors": "Mauro Bisiacco and Gianluigi Pillonetto", "title": "Mathematical foundations of stable RKHSs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducing kernel Hilbert spaces (RKHSs) are key spaces for machine learning\nthat are becoming popular also for linear system identification. In particular,\nthe so-called stable RKHSs can be used to model absolutely summable impulse\nresponses. In combination e.g. with regularized least squares they can then be\nused to reconstruct dynamic systems from input-output data. In this paper we\nprovide new structural properties of stable RKHSs. The relation between stable\nkernels and other fundamental classes, like those containing absolutely\nsummable or finite-trace kernels, is elucidated. These insights are then\nbrought into the feature space context. First, it is proved that any stable\nkernel admits feature maps induced by a basis of orthogonal eigenvectors in l2.\nThe exact connection with classical system identification approaches that\nexploit such kind of functions to model impulse responses is also provided.\nThen, the necessary and sufficient stability condition for RKHSs designed by\nformulating kernel eigenvectors and eigenvalues is obtained. Overall, our new\nresults provide novel mathematical foundations of stable RKHSs with impact on\nstability tests, impulse responses modeling and computational efficiency of\nregularized schemes for linear system identification.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:25:23 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Bisiacco", "Mauro", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "2005.02979", "submitter": "Anthony Corso", "authors": "Anthony Corso, Robert J. Moss, Mark Koren, Ritchie Lee, Mykel J.\n  Kochenderfer", "title": "A Survey of Algorithms for Black-Box Safety Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous and semi-autonomous systems for safety-critical applications\nrequire rigorous testing before deployment. Due to the complexity of these\nsystems, formal verification may be impossible and real-world testing may be\ndangerous during development. Therefore, simulation-based techniques have been\ndeveloped that treat the system under test as a black box during testing.\nSafety validation tasks include finding disturbances to the system that cause\nit to fail (falsification), finding the most-likely failure, and estimating the\nprobability that the system fails. Motivated by the prevalence of\nsafety-critical artificial intelligence, this work provides a survey of\nstate-of-the-art safety validation techniques with a focus on applied\nalgorithms and their modifications for the safety validation problem. We\npresent and discuss algorithms in the domains of optimization, path planning,\nreinforcement learning, and importance sampling. Problem decomposition\ntechniques are presented to help scale algorithms to large state spaces, and a\nbrief overview of safety-critical applications is given, including autonomous\nvehicles and aircraft collision avoidance systems. Finally, we present a survey\nof existing academic and commercially available safety validation tools.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:31:51 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 16:18:28 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Corso", "Anthony", ""], ["Moss", "Robert J.", ""], ["Koren", "Mark", ""], ["Lee", "Ritchie", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2005.03004", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Adaptive Invariance for Molecule Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective property prediction methods can help accelerate the search for\nCOVID-19 antivirals either through accurate in-silico screens or by effectively\nguiding on-going at-scale experimental efforts. However, existing prediction\ntools have limited ability to accommodate scarce or fragmented training data\ncurrently available. In this paper, we introduce a novel approach to learn\npredictors that can generalize or extrapolate beyond the heterogeneous data.\nOur method builds on and extends recently proposed invariant risk minimization,\nadaptively forcing the predictor to avoid nuisance variation. We achieve this\nby continually exercising and manipulating latent representations of molecules\nto highlight undesirable variation to the predictor. To test the method we use\na combination of three data sources: SARS-CoV-2 antiviral screening data,\nmolecular fragments that bind to SARS-CoV-2 main protease and large screening\ndata for SARS-CoV-1. Our predictor outperforms state-of-the-art transfer\nlearning methods by significant margin. We also report the top 20 predictions\nof our model on Broad drug repurposing hub.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 19:47:20 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2005.03117", "submitter": "Anil Ramakrishna", "authors": "Anil Ramakrishna, Rahul Gupta, Shrikanth Narayanan", "title": "Joint Multi-Dimensional Model for Global and Time-Series Annotations", "comments": "17 pages, 11 figures, currently in final rounds of review at IEEE\n  Transactions of Affective Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is a popular approach to collect annotations for unlabeled data\ninstances. It involves collecting a large number of annotations from several,\noften naive untrained annotators for each data instance which are then combined\nto estimate the ground truth. Further, annotations for constructs such as\naffect are often multi-dimensional with annotators rating multiple dimensions,\nsuch as valence and arousal, for each instance. Most annotation fusion schemes\nhowever ignore this aspect and model each dimension separately. In this work we\naddress this by proposing a generative model for multi-dimensional annotation\nfusion, which models the dimensions jointly leading to more accurate ground\ntruth estimates. The model we propose is applicable to both global and time\nseries annotation fusion problems and treats the ground truth as a latent\nvariable distorted by the annotators. The model parameters are estimated using\nthe Expectation-Maximization algorithm and we evaluate its performance using\nsynthetic data and real emotion corpora as well as on an artificial task with\nhuman annotations\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 20:08:46 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ramakrishna", "Anil", ""], ["Gupta", "Rahul", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2005.03141", "submitter": "Zifan Wang", "authors": "Zifan Wang, Yilin Yang, Ankit Shrivastava, Varun Rawal and Zihao Ding", "title": "Towards Frequency-Based Explanation for Robust CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current explanation techniques towards a transparent Convolutional Neural\nNetwork (CNN) mainly focuses on building connections between the\nhuman-understandable input features with models' prediction, overlooking an\nalternative representation of the input, the frequency components\ndecomposition. In this work, we present an analysis of the connection between\nthe distribution of frequency components in the input dataset and the reasoning\nprocess the model learns from the data. We further provide quantification\nanalysis about the contribution of different frequency components toward the\nmodel's prediction. We show that the vulnerability of the model against tiny\ndistortions is a result of the model is relying on the high-frequency features,\nthe target features of the adversarial (black and white-box) attackers, to make\nthe prediction. We further show that if the model develops stronger association\nbetween the low-frequency component with true labels, the model is more robust,\nwhich is the explanation of why adversarially trained models are more robust\nagainst tiny distortions.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 21:22:35 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Wang", "Zifan", ""], ["Yang", "Yilin", ""], ["Shrivastava", "Ankit", ""], ["Rawal", "Varun", ""], ["Ding", "Zihao", ""]]}, {"id": "2005.03151", "submitter": "Nathan Kallus", "authors": "Nathan Kallus", "title": "On the Optimality of Randomization in Experimental Design: How to\n  Randomize for Minimax Variance and Design-Based Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I study the minimax-optimal design for a two-arm controlled experiment where\nconditional mean outcomes may vary in a given set. When this set is permutation\nsymmetric, the optimal design is complete randomization, and using a single\npartition (i.e., the design that only randomizes the treatment labels for each\nside of the partition) has minimax risk larger by a factor of $n-1$. More\ngenerally, the optimal design is shown to be the mixed-strategy optimal design\n(MSOD) of Kallus (2018). Notably, even when the set of conditional mean\noutcomes has structure (i.e., is not permutation symmetric), being\nminimax-optimal for variance still requires randomization beyond a single\npartition. Nonetheless, since this targets precision, it may still not ensure\nsufficient uniformity in randomization to enable randomization (i.e.,\ndesign-based) inference by Fisher's exact test to appropriately detect\nviolations of null. I therefore propose the inference-constrained MSOD, which\nis minimax-optimal among all designs subject to such uniformity constraints. On\nthe way, I discuss Johansson et al. (2020) who recently compared\nrerandomization of Morgan and Rubin (2012) and the pure-strategy optimal design\n(PSOD) of Kallus (2018). I point out some errors therein and set straight that\nrandomization is minimax-optimal and that the \"no free lunch\" theorem and\nexample in Kallus (2018) are correct.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 21:43:50 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Kallus", "Nathan", ""]]}, {"id": "2005.03161", "submitter": "Sanjay Kariyappa", "authors": "Sanjay Kariyappa, Atul Prakash, Moinuddin Qureshi", "title": "MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model Stealing (MS) attacks allow an adversary with black-box access to a\nMachine Learning model to replicate its functionality, compromising the\nconfidentiality of the model. Such attacks train a clone model by using the\npredictions of the target model for different inputs. The effectiveness of such\nattacks relies heavily on the availability of data necessary to query the\ntarget model. Existing attacks either assume partial access to the dataset of\nthe target model or availability of an alternate dataset with semantic\nsimilarities.\n  This paper proposes MAZE -- a data-free model stealing attack using\nzeroth-order gradient estimation. In contrast to prior works, MAZE does not\nrequire any data and instead creates synthetic data using a generative model.\nInspired by recent works in data-free Knowledge Distillation (KD), we train the\ngenerative model using a disagreement objective to produce inputs that maximize\ndisagreement between the clone and the target model. However, unlike the\nwhite-box setting of KD, where the gradient information is available, training\na generator for model stealing requires performing black-box optimization, as\nit involves accessing the target model under attack. MAZE relies on\nzeroth-order gradient estimation to perform this optimization and enables a\nhighly accurate MS attack.\n  Our evaluation with four datasets shows that MAZE provides a normalized clone\naccuracy in the range of 0.91x to 0.99x, and outperforms even the recent\nattacks that rely on partial data (JBDA, clone accuracy 0.13x to 0.69x) and\nsurrogate data (KnockoffNets, clone accuracy 0.52x to 0.97x). We also study an\nextension of MAZE in the partial-data setting and develop MAZE-PD, which\ngenerates synthetic data closer to the target distribution. MAZE-PD further\nimproves the clone accuracy (0.97x to 1.0x) and reduces the query required for\nthe attack by 2x-24x.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 22:26:18 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Kariyappa", "Sanjay", ""], ["Prakash", "Atul", ""], ["Qureshi", "Moinuddin", ""]]}, {"id": "2005.03180", "submitter": "Nikola Kovachki", "authors": "Kaushik Bhattacharya, Bamdad Hosseini, Nikola B. Kovachki, Andrew M.\n  Stuart", "title": "Model Reduction and Neural Networks for Parametric PDEs", "comments": "39 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general framework for data-driven approximation of input-output\nmaps between infinite-dimensional spaces. The proposed approach is motivated by\nthe recent successes of neural networks and deep learning, in combination with\nideas from model reduction. This combination results in a neural network\napproximation which, in principle, is defined on infinite-dimensional spaces\nand, in practice, is robust to the dimension of finite-dimensional\napproximations of these spaces required for computation. For a class of\ninput-output maps, and suitably chosen probability measures on the inputs, we\nprove convergence of the proposed approximation methodology. We also include\nnumerical experiments which demonstrate the effectiveness of the method,\nshowing convergence and robustness of the approximation scheme with respect to\nthe size of the discretization, and compare it with existing algorithms from\nthe literature; our examples include the mapping from coefficient to solution\nin a divergence form elliptic partial differential equation (PDE) problem, and\nthe solution operator for viscous Burgers' equation.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 00:09:27 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 18:45:06 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Bhattacharya", "Kaushik", ""], ["Hosseini", "Bamdad", ""], ["Kovachki", "Nikola B.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "2005.03188", "submitter": "Jeongmin Chae", "authors": "Songnam Hong and Jeongmin Chae", "title": "Active Learning with Multiple Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online multiple kernel learning (OMKL) has provided an attractive performance\nin nonlinear function learning tasks. Leveraging a random feature\napproximation, the major drawback of OMKL, known as the curse of\ndimensionality, has been recently alleviated. In this paper, we introduce a new\nresearch problem, termed (stream-based) active multiple kernel learning (AMKL),\nin which a learner is allowed to label selected data from an oracle according\nto a selection criterion. This is necessary in many real-world applications as\nacquiring true labels is costly or time-consuming. We prove that AMKL achieves\nan optimal sublinear regret, implying that the proposed selection criterion\nindeed avoids unuseful label-requests. Furthermore, we propose AMKL with an\nadaptive kernel selection (AMKL-AKS) in which irrelevant kernels can be\nexcluded from a kernel dictionary 'on the fly'. This approach can improve the\nefficiency of active learning as well as the accuracy of a function\napproximation. Via numerical tests with various real datasets, it is\ndemonstrated that AMKL-AKS yields a similar or better performance than the\nbest-known OMKL, with a smaller number of labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 00:48:13 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Hong", "Songnam", ""], ["Chae", "Jeongmin", ""]]}, {"id": "2005.03197", "submitter": "Anshuman Chhabra", "authors": "Anshuman Chhabra, Vidushi Vashishth, Prasant Mohapatra", "title": "Fair Algorithms for Hierarchical Agglomerative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Agglomerative Clustering (HAC) algorithms are extensively\nutilized in modern data science, and seek to partition the dataset into\nclusters while generating a hierarchical relationship between the data samples.\nHAC algorithms are employed in many applications, such as biology, natural\nlanguage processing, and recommender systems. Thus, it is imperative to ensure\nthat these algorithms are fair -- even if the dataset contains biases against\ncertain protected groups, the cluster outputs generated should not discriminate\nagainst samples from any of these groups. However, recent work in clustering\nfairness has mostly focused on center-based clustering algorithms, such as\nk-median and k-means clustering. In this paper, we propose fair algorithms for\nperforming HAC that enforce fairness constraints 1) irrespective of the\ndistance linkage criteria used, 2) generalize to any natural measures of\nclustering fairness for HAC, 3) work for multiple protected groups, and 4) have\ncompetitive running times to vanilla HAC. Through extensive experiments on\nmultiple real-world UCI datasets, we show that our proposed algorithm finds\nfairer clusterings compared to vanilla HAC as well as other state-of-the-art\nfair clustering approaches.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 01:41:56 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 01:36:37 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 08:49:39 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chhabra", "Anshuman", ""], ["Vashishth", "Vidushi", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2005.03213", "submitter": "Kai Zhou", "authors": "Kai Zhou, Jiong Tang", "title": "Efficient Characterization of Dynamic Response Variation Using\n  Multi-Fidelity Data Fusion through Composite Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainties in a structure is inevitable, which generally lead to variation\nin dynamic response predictions. For a complex structure, brute force Monte\nCarlo simulation for response variation analysis is infeasible since one single\nrun may already be computationally costly. Data driven meta-modeling approaches\nhave thus been explored to facilitate efficient emulation and statistical\ninference. The performance of a meta-model hinges upon both the quality and\nquantity of training dataset. In actual practice, however, high-fidelity data\nacquired from high-dimensional finite element simulation or experiment are\ngenerally scarce, which poses significant challenge to meta-model\nestablishment. In this research, we take advantage of the multi-level response\nprediction opportunity in structural dynamic analysis, i.e., acquiring rapidly\na large amount of low-fidelity data from reduced-order modeling, and acquiring\naccurately a small amount of high-fidelity data from full-scale finite element\nanalysis. Specifically, we formulate a composite neural network fusion approach\nthat can fully utilize the multi-level, heterogeneous datasets obtained. It\nimplicitly identifies the correlation of the low- and high-fidelity datasets,\nwhich yields improved accuracy when compared with the state-of-the-art.\nComprehensive investigations using frequency response variation\ncharacterization as case example are carried out to demonstrate the\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 02:44:03 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zhou", "Kai", ""], ["Tang", "Jiong", ""]]}, {"id": "2005.03220", "submitter": "Ariel Rokem", "authors": "Ariel Rokem, Kendrick Kay", "title": "Fractional ridge regression: a fast, interpretable reparameterization of\n  ridge regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ridge regression (RR) is a regularization technique that penalizes the\nL2-norm of the coefficients in linear regression. One of the challenges of\nusing RR is the need to set a hyperparameter ($\\alpha$) that controls the\namount of regularization. Cross-validation is typically used to select the best\n$\\alpha$ from a set of candidates. However, efficient and appropriate selection\nof $\\alpha$ can be challenging, particularly where large amounts of data are\nanalyzed. Because the selected $\\alpha$ depends on the scale of the data and\npredictors, it is not straightforwardly interpretable. Here, we propose to\nreparameterize RR in terms of the ratio $\\gamma$ between the L2-norms of the\nregularized and unregularized coefficients. This approach, called fractional RR\n(FRR), has several benefits: the solutions obtained for different $\\gamma$ are\nguaranteed to vary, guarding against wasted calculations, and automatically\nspan the relevant range of regularization, avoiding the need for arduous manual\nexploration. We provide an algorithm to solve FRR, as well as open-source\nsoftware implementations in Python and MATLAB\n(https://github.com/nrdg/fracridge). We show that the proposed method is fast\nand scalable for large-scale data problems, and delivers results that are\nstraightforward to interpret and compare across models and datasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 03:12:23 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Rokem", "Ariel", ""], ["Kay", "Kendrick", ""]]}, {"id": "2005.03228", "submitter": "Chenhao Xie", "authors": "Chenhao Xie, Qiao Cheng, Jiaqing Liang, Lihan Chen, Yanghua Xiao", "title": "Collective Loss Function for Positive and Unlabeled Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People learn to discriminate between classes without explicit exposure to\nnegative examples. On the contrary, traditional machine learning algorithms\noften rely on negative examples, otherwise the model would be prone to collapse\nand always-true predictions. Therefore, it is crucial to design the learning\nobjective which leads the model to converge and to perform predictions\nunbiasedly without explicit negative signals. In this paper, we propose a\nCollectively loss function to learn from only Positive and Unlabeled data\n(cPU). We theoretically elicit the loss function from the setting of PU\nlearning. We perform intensive experiments on the benchmark and real-world\ndatasets. The results show that cPU consistently outperforms the current\nstate-of-the-art PU learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 03:30:22 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Xie", "Chenhao", ""], ["Cheng", "Qiao", ""], ["Liang", "Jiaqing", ""], ["Chen", "Lihan", ""], ["Xiao", "Yanghua", ""]]}, {"id": "2005.03229", "submitter": "Pengfei Wei Dr.", "authors": "Pengfei Wei, Yiping Ke, Xinghua Qu, Tze-Yun Leong", "title": "Subdomain Adaptation with Manifolds Discrepancy Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing domain divergence is a key step in transfer learning problems.\nExisting works focus on the minimization of global domain divergence. However,\ntwo domains may consist of several shared subdomains, and differ from each\nother in each subdomain. In this paper, we take the local divergence of\nsubdomains into account in transfer. Specifically, we propose to use\nlow-dimensional manifold to represent subdomain, and align the local data\ndistribution discrepancy in each manifold across domains. A Manifold Maximum\nMean Discrepancy (M3D) is developed to measure the local distribution\ndiscrepancy in each manifold. We then propose a general framework, called\nTransfer with Manifolds Discrepancy Alignment (TMDA), to couple the discovery\nof data manifolds with the minimization of M3D. We instantiate TMDA in the\nsubspace learning case considering both the linear and nonlinear mappings. We\nalso instantiate TMDA in the deep learning framework. Extensive experimental\nstudies demonstrate that TMDA is a promising method for various transfer\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 04:18:47 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Wei", "Pengfei", ""], ["Ke", "Yiping", ""], ["Qu", "Xinghua", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "2005.03240", "submitter": "Bin Liu", "authors": "Bin Liu, Konstantinos Blekas, and Grigorios Tsoumakas", "title": "Multi-Label Sampling based on Local Label Imbalance", "comments": "arXiv admin note: text overlap with arXiv:1905.00609", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is an inherent characteristic of multi-label data that\nhinders most multi-label learning methods. One efficient and flexible strategy\nto deal with this problem is to employ sampling techniques before training a\nmulti-label learning model. Although existing multi-label sampling approaches\nalleviate the global imbalance of multi-label datasets, it is actually the\nimbalance level within the local neighbourhood of minority class examples that\nplays a key role in performance degradation. To address this issue, we propose\na novel measure to assess the local label imbalance of multi-label datasets, as\nwell as two multi-label sampling approaches based on the local label imbalance,\nnamely MLSOL and MLUL. By considering all informative labels, MLSOL creates\nmore diverse and better labeled synthetic instances for difficult examples,\nwhile MLUL eliminates instances that are harmful to their local region.\nExperimental results on 13 multi-label datasets demonstrate the effectiveness\nof the proposed measure and sampling approaches for a variety of evaluation\nmetrics, particularly in the case of an ensemble of classifiers trained on\nrepeated samples of the original data.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 04:14:23 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 10:53:43 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Bin", ""], ["Blekas", "Konstantinos", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "2005.03247", "submitter": "Vivek Dixit", "authors": "Vivek Dixit, Raja Selvarajan, Muhammad A. Alam, Travis S. Humble, and\n  Sabre Kais", "title": "Training and Classification using a Restricted Boltzmann Machine on the\n  D-Wave 2000Q", "comments": "Front. Phys., 29 June 2021", "journal-ref": null, "doi": "10.3389/fphy.2021.589626", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machine (RBM) is an energy based, undirected graphical\nmodel. It is commonly used for unsupervised and supervised machine learning.\nTypically, RBM is trained using contrastive divergence (CD). However, training\nwith CD is slow and does not estimate exact gradient of log-likelihood cost\nfunction. In this work, the model expectation of gradient learning for RBM has\nbeen calculated using a quantum annealer (D-Wave 2000Q), which is much faster\nthan Markov chain Monte Carlo (MCMC) used in CD. Training and classification\nresults are compared with CD. The classification accuracy results indicate\nsimilar performance of both methods. Image reconstruction as well as\nlog-likelihood calculations are used to compare the performance of quantum and\nclassical algorithms for RBM training. It is shown that the samples obtained\nfrom quantum annealer can be used to train a RBM on a 64-bit `bars and stripes'\ndata set with classification performance similar to a RBM trained with CD.\nThough training based on CD showed improved learning performance, training\nusing a quantum annealer eliminates computationally expensive MCMC steps of CD.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 04:43:04 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dixit", "Vivek", ""], ["Selvarajan", "Raja", ""], ["Alam", "Muhammad A.", ""], ["Humble", "Travis S.", ""], ["Kais", "Sabre", ""]]}, {"id": "2005.03266", "submitter": "Ritajit Majumdar", "authors": "Shovik Ganguly, Atrayee Chatterjee, Debasmita Bhoumik, Ritajit\n  Majumdar", "title": "An Empirical Study of Incremental Learning in Neural Network with Noisy\n  Training Set", "comments": "Oral Presentation delivered at the 7th International Conference on\n  Computers and Devices for Communication (CODEC) 2019. To appear in Lecture\n  Notes in Networks and Systems (LNSS Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of incremental learning is to train an ANN algorithm in stages, as\nand when newer training data arrives. Incremental learning is becoming\nwidespread in recent times with the advent of deep learning. Noise in the\ntraining data reduces the accuracy of the algorithm. In this paper, we make an\nempirical study of the effect of noise in the training phase. We numerically\nshow that the accuracy of the algorithm is dependent more on the location of\nthe error than the percentage of error. Using Perceptron, Feed Forward Neural\nNetwork and Radial Basis Function Neural Network, we show that for the same\npercentage of error, the accuracy of the algorithm significantly varies with\nthe location of error. Furthermore, our results show that the dependence of the\naccuracy with the location of error is independent of the algorithm. However,\nthe slope of the degradation curve decreases with more sophisticated algorithms\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 06:09:31 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ganguly", "Shovik", ""], ["Chatterjee", "Atrayee", ""], ["Bhoumik", "Debasmita", ""], ["Majumdar", "Ritajit", ""]]}, {"id": "2005.03288", "submitter": "Trista Chen", "authors": "Ying-Sheng Luo (1), Jonathan Hans Soeseno (1), Trista Pei-Chun Chen\n  (1), Wei-Chao Chen (1, 2) ((1) Inventec Corp. (2) Skywatch Innovation Inc.)", "title": "CARL: Controllable Agent with Reinforcement Learning for Quadruped\n  Locomotion", "comments": "Project page available at\n  https://inventec-ai-center.github.io/projects/CARL/index.html", "journal-ref": "ACM Transactions on Graphics (2020), Volume 39, Issue 4, Article\n  38", "doi": "10.1145/3386569.3392433", "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion synthesis in a dynamic environment has been a long-standing problem\nfor character animation. Methods using motion capture data tend to scale poorly\nin complex environments because of their larger capturing and labeling\nrequirement. Physics-based controllers are effective in this regard, albeit\nless controllable. In this paper, we present CARL, a quadruped agent that can\nbe controlled with high-level directives and react naturally to dynamic\nenvironments. Starting with an agent that can imitate individual animation\nclips, we use Generative Adversarial Networks to adapt high-level controls,\nsuch as speed and heading, to action distributions that correspond to the\noriginal animations. Further fine-tuning through the deep reinforcement\nlearning enables the agent to recover from unseen external perturbations while\nproducing smooth transitions. It then becomes straightforward to create\nautonomous agents in dynamic environments by adding navigation modules over the\nentire process. We evaluate our approach by measuring the agent's ability to\nfollow user control and provide a visual analysis of the generated motion to\nshow its effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:18:57 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 03:20:42 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 05:10:27 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Luo", "Ying-Sheng", "", "Inventec Corp"], ["Soeseno", "Jonathan Hans", "", "Inventec Corp"], ["Chen", "Trista Pei-Chun", "", "Inventec Corp"], ["Chen", "Wei-Chao", "", "Inventec Corp"]]}, {"id": "2005.03300", "submitter": "Aydin Buluc", "authors": "Alok Tripathy, Katherine Yelick, Aydin Buluc", "title": "Reducing Communication in Graph Neural Network Training", "comments": "To appear in International Conference for High Performance Computing,\n  Networking, Storage, and Analysis (SC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are powerful and flexible neural networks that\nuse the naturally sparse connectivity information of the data. GNNs represent\nthis connectivity as sparse matrices, which have lower arithmetic intensity and\nthus higher communication costs compared to dense matrices, making GNNs harder\nto scale to high concurrencies than convolutional or fully-connected neural\nnetworks.\n  We introduce a family of parallel algorithms for training GNNs and show that\nthey can asymptotically reduce communication compared to previous parallel GNN\ntraining methods. We implement these algorithms, which are based on 1D, 1.5D,\n2D, and 3D sparse-dense matrix multiplication, using torch.distributed on\nGPU-equipped clusters. Our algorithms optimize communication across the full\nGNN training pipeline. We train GNNs on over a hundred GPUs on multiple\ndatasets, including a protein network with over a billion edges.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:45:09 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 06:33:01 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 20:35:32 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Tripathy", "Alok", ""], ["Yelick", "Katherine", ""], ["Buluc", "Aydin", ""]]}, {"id": "2005.03350", "submitter": "Lkhagvadorj Munkhdalai", "authors": "Lkhagvadorj Munkhdalai, Tsendsuren Munkhdalai and Keun Ho Ryu", "title": "A Locally Adaptive Interpretable Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models with both good predictability and high\ninterpretability are crucial for decision support systems. Linear regression is\none of the most interpretable prediction models. However, the linearity in a\nsimple linear regression worsens its predictability. In this work, we introduce\na locally adaptive interpretable regression (LoAIR). In LoAIR, a metamodel\nparameterized by neural networks predicts percentile of a Gaussian distribution\nfor the regression coefficients for a rapid adaptation. Our experimental\nresults on public benchmark datasets show that our model not only achieves\ncomparable or better predictive performance than the other state-of-the-art\nbaselines but also discovers some interesting relationships between input and\ntarget variables such as a parabolic relationship between CO2 emissions and\nGross National Product (GNP). Therefore, LoAIR is a step towards bridging the\ngap between econometrics, statistics, and machine learning by improving the\npredictive ability of linear regression without depreciating its\ninterpretability.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:26:14 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 01:42:57 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Munkhdalai", "Lkhagvadorj", ""], ["Munkhdalai", "Tsendsuren", ""], ["Ryu", "Keun Ho", ""]]}, {"id": "2005.03353", "submitter": "Martin Emil Jakobsen", "authors": "Martin Emil Jakobsen and Jonas Peters", "title": "Distributional Robustness of K-class Estimators and the PULSE", "comments": "85 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, in causal discovery, invariance properties such as the moment\ncriterion which two-stage least square estimator leverage have been exploited\nfor causal structure learning: e.g., in cases, where the causal parameter is\nnot identifiable, some structure of the non-zero components may be identified,\nand coverage guarantees are available. Subsequently, anchor regression has been\nproposed to trade-off invariance and predictability. The resulting estimator is\nshown to have optimal predictive performance under bounded shift interventions.\nIn this paper, we show that the concepts of anchor regression and K-class\nestimators are closely related. Establishing this connection comes with two\nbenefits: (1) It enables us to prove robustness properties for existing K-class\nestimators when considering distributional shifts. And, (2), we propose a novel\nestimator in instrumental variable settings by minimizing the mean squared\nprediction error subject to the constraint that the estimator lies in an\nasymptotically valid confidence region of the causal parameter. We call this\nestimator PULSE (p-uncorrelated least squares estimator) and show that it can\nbe computed efficiently, even though the underlying optimization problem is\nnon-convex. We further prove that it is consistent. We perform simulation\nexperiments illustrating that there are several settings including weak\ninstrument settings, where PULSE outperforms other estimators and suffers from\nless variability.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:39:07 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 17:27:21 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Jakobsen", "Martin Emil", ""], ["Peters", "Jonas", ""]]}, {"id": "2005.03403", "submitter": "Yang Zhao", "authors": "Yang Zhao, Xiaohan Chen, Yue Wang, Chaojian Li, Haoran You, Yonggan\n  Fu, Yuan Xie, Zhangyang Wang, Yingyan Lin", "title": "SmartExchange: Trading Higher-cost Memory Storage/Access for Lower-cost\n  Computation", "comments": "Accepted by 47th International Symposium on Computer Architecture\n  (ISCA'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SmartExchange, an algorithm-hardware co-design framework to trade\nhigher-cost memory storage/access for lower-cost computation, for\nenergy-efficient inference of deep neural networks (DNNs). We develop a novel\nalgorithm to enforce a specially favorable DNN weight structure, where each\nlayerwise weight matrix can be stored as the product of a small basis matrix\nand a large sparse coefficient matrix whose non-zero elements are all\npower-of-2. To our best knowledge, this algorithm is the first formulation that\nintegrates three mainstream model compression ideas: sparsification or pruning,\ndecomposition, and quantization, into one unified framework. The resulting\nsparse and readily-quantized DNN thus enjoys greatly reduced energy consumption\nin data movement as well as weight storage. On top of that, we further design a\ndedicated accelerator to fully utilize the SmartExchange-enforced weights to\nimprove both energy efficiency and latency performance. Extensive experiments\nshow that 1) on the algorithm level, SmartExchange outperforms state-of-the-art\ncompression techniques, including merely sparsification or pruning,\ndecomposition, and quantization, in various ablation studies based on nine DNN\nmodels and four datasets; and 2) on the hardware level, the proposed\nSmartExchange based accelerator can improve the energy efficiency by up to\n6.7$\\times$ and the speedup by up to 19.2$\\times$ over four state-of-the-art\nDNN accelerators, when benchmarked on seven DNN models (including four standard\nDNNs, two compact DNN models, and one segmentation model) and three datasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:12:49 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 07:35:09 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Zhao", "Yang", ""], ["Chen", "Xiaohan", ""], ["Wang", "Yue", ""], ["Li", "Chaojian", ""], ["You", "Haoran", ""], ["Fu", "Yonggan", ""], ["Xie", "Yuan", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "2005.03419", "submitter": "Kazuaki Murayama", "authors": "Kazuaki. Murayama and Shuichi. Kawano", "title": "Relevance Vector Machine with Weakly Informative Hyperprior and Extended\n  Predictive Information Criterion", "comments": "29 pages, 12 captioned figures, 23 files of non-captioned figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the variational relevance vector machine, the gamma distribution is\nrepresentative as a hyperprior over the noise precision of automatic relevance\ndetermination prior. Instead of the gamma hyperprior, we propose to use the\ninverse gamma hyperprior with a shape parameter close to zero and a scale\nparameter not necessary close to zero. This hyperprior is associated with the\nconcept of a weakly informative prior. The effect of this hyperprior is\ninvestigated through regression to non-homogeneous data. Because it is\ndifficult to capture the structure of such data with a single kernel function,\nwe apply the multiple kernel method, in which multiple kernel functions with\ndifferent widths are arranged for input data. We confirm that the degrees of\nfreedom in a model is controlled by adjusting the scale parameter and keeping\nthe shape parameter close to zero. A candidate for selecting the scale\nparameter is the predictive information criterion. However the estimated model\nusing this criterion seems to cause over-fitting. This is because the multiple\nkernel method makes the model a situation where the dimension of the model is\nlarger than the data size. To select an appropriate scale parameter even in\nsuch a situation, we also propose an extended prediction information criterion.\nIt is confirmed that a multiple kernel relevance vector regression model with\ngood predictive accuracy can be obtained by selecting the scale parameter\nminimizing extended prediction information criterion.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:37:19 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Murayama", "Kazuaki.", ""], ["Kawano", "Shuichi.", ""]]}, {"id": "2005.03420", "submitter": "Frank R\\\"oder", "authors": "Frank R\\\"oder, Manfred Eppe, Phuong D.H. Nguyen and Stefan Wermter", "title": "Curious Hierarchical Actor-Critic Reinforcement Learning", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical abstraction and curiosity-driven exploration are two common\nparadigms in current reinforcement learning approaches to break down difficult\nproblems into a sequence of simpler ones and to overcome reward sparsity.\nHowever, there is a lack of approaches that combine these paradigms, and it is\ncurrently unknown whether curiosity also helps to perform the hierarchical\nabstraction. As a novelty and scientific contribution, we tackle this issue and\ndevelop a method that combines hierarchical reinforcement learning with\ncuriosity. Herein, we extend a contemporary hierarchical actor-critic approach\nwith a forward model to develop a hierarchical notion of curiosity. We\ndemonstrate in several continuous-space environments that curiosity can more\nthan double the learning performance and success rates for most of the\ninvestigated benchmarking problems. We also provide our source code and a\nsupplementary video.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:44:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 18:25:33 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 08:45:36 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["R\u00f6der", "Frank", ""], ["Eppe", "Manfred", ""], ["Nguyen", "Phuong D. H.", ""], ["Wermter", "Stefan", ""]]}, {"id": "2005.03442", "submitter": "Dominique Mercier", "authors": "Dominique Mercier, Shoaib Ahmed Siddiqui, Andreas Dengel, Sheraz Ahmed", "title": "Interpreting Deep Models through the Lens of Data", "comments": "8 pages, 11 figures, Accepted for the IEEE International Joint\n  Conference on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207704", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of input data points relevant for the classifier (i.e. serve\nas the support vector) has recently spurred the interest of researchers for\nboth interpretability as well as dataset debugging. This paper presents an\nin-depth analysis of the methods which attempt to identify the influence of\nthese data points on the resulting classifier. To quantify the quality of the\ninfluence, we curated a set of experiments where we debugged and pruned the\ndataset based on the influence information obtained from different methods. To\ndo so, we provided the classifier with mislabeled examples that hampered the\noverall performance. Since the classifier is a combination of both the data and\nthe model, therefore, it is essential to also analyze these influences for the\ninterpretability of deep learning models. Analysis of the results shows that\nsome interpretability methods can detect mislabels better than using a random\napproach, however, contrary to the claim of these methods, the sample selection\nbased on the training loss showed a superior performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 07:59:37 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:21:43 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mercier", "Dominique", ""], ["Siddiqui", "Shoaib Ahmed", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.03447", "submitter": "Zhenyu Zhao", "authors": "Zhenyu Zhao, Yumin Zhang, Totte Harinen, Mike Yung", "title": "Feature Selection Methods for Uplift Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling is a predictive modeling technique that estimates the\nuser-level incremental effect of a treatment using machine learning models. It\nis often used for targeting promotions and advertisements, as well as for the\npersonalization of product offerings. In these applications, there are often\nhundreds of features available to build such models. Keeping all the features\nin a model can be costly and inefficient. Feature selection is an essential\nstep in the modeling process for multiple reasons: improving the estimation\naccuracy by eliminating irrelevant features, accelerating model training and\nprediction speed, reducing the monitoring and maintenance workload for feature\ndata pipeline, and providing better model interpretation and diagnostics\ncapability. However, feature selection methods for uplift modeling have been\nrarely discussed in the literature. Although there are various feature\nselection methods for standard machine learning models, we will demonstrate\nthat those methods are sub-optimal for solving the feature selection problem\nfor uplift modeling. To address this problem, we introduce a set of feature\nselection methods designed specifically for uplift modeling, including both\nfilter methods and embedded methods. To evaluate the effectiveness of the\nproposed feature selection methods, we use different uplift models and measure\nthe accuracy of each model with a different number of selected features. We use\nboth synthetic and real data to conduct these experiments. We also implemented\nthe proposed filter methods in an open source Python package (CausalML).\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 00:28:18 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zhao", "Zhenyu", ""], ["Zhang", "Yumin", ""], ["Harinen", "Totte", ""], ["Yung", "Mike", ""]]}, {"id": "2005.03448", "submitter": "Hao Sun", "authors": "Zhao Chen, Yang Liu and Hao Sun", "title": "Physics-informed learning of governing equations from scarce data", "comments": "46 pages; 1 table, 6 figures and 3 extended data figures in main\n  text; 2 tables and 12 figures in supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Harnessing data to discover the underlying governing laws or equations that\ndescribe the behavior of complex physical systems can significantly advance our\nmodeling, simulation and understanding of such systems in various science and\nengineering disciplines. This work introduces a novel physics-informed deep\nlearning framework to discover governing partial differential equations (PDEs)\nfrom scarce and noisy data for nonlinear spatiotemporal systems. In particular,\nthis approach seamlessly integrates the strengths of deep neural networks for\nrich representation learning, physics embedding, automatic differentiation and\nsparse regression to (1) approximate the solution of system variables, (2)\ncompute essential derivatives, as well as (3) identify the key derivative terms\nand parameters that form the structure and explicit expression of the PDEs. The\nefficacy and robustness of this method are demonstrated, both numerically and\nexperimentally, on discovering a variety of PDE systems with different levels\nof data scarcity and noise accounting for different initial/boundary\nconditions. The resulting computational framework shows the potential for\nclosed-form model discovery in practical applications where large and accurate\ndatasets are intractable to capture.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 22:13:22 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 23:28:48 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 21:26:27 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Chen", "Zhao", ""], ["Liu", "Yang", ""], ["Sun", "Hao", ""]]}, {"id": "2005.03460", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Transfer Learning for sEMG-based Hand Gesture Classification using Deep\n  Learning in a Master-Slave Architecture", "comments": null, "journal-ref": null, "doi": "10.1109/IC3I44769.2018.9007304", "report-no": null, "categories": "eess.SP cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in diagnostic learning and development of gesture-based\nhuman machine interfaces have driven surface electromyography (sEMG) towards\nsignificant importance. Analysis of hand gestures requires an accurate\nassessment of sEMG signals. The proposed work presents a novel sequential\nmaster-slave architecture consisting of deep neural networks (DNNs) for\nclassification of signs from the Indian sign language using signals recorded\nfrom multiple sEMG channels. The performance of the master-slave network is\naugmented by leveraging additional synthetic feature data generated by long\nshort term memory networks. Performance of the proposed network is compared to\nthat of a conventional DNN prior to and after the addition of synthetic data.\nUp to 14% improvement is observed in the conventional DNN and up to 9%\nimprovement in master-slave network on addition of synthetic data with an\naverage accuracy value of 93.5% asserting the suitability of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:16:17 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.03490", "submitter": "Gehui Shen", "authors": "Gehui Shen, Song Zhang, Xiang Chen and Zhi-Hong Deng", "title": "Generative Feature Replay with Orthogonal Weight Modification for\n  Continual Learning", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of intelligent agents to learn and remember multiple tasks\nsequentially is crucial to achieving artificial general intelligence. Many\ncontinual learning (CL) methods have been proposed to overcome catastrophic\nforgetting which results from non i.i.d data in the sequential learning of\nneural networks. In this paper we focus on class incremental learning, a\nchallenging CL scenario. For this scenario, generative replay is a promising\nstrategy which generates and replays pseudo data for previous tasks to\nalleviate catastrophic forgetting. However, it is hard to train a generative\nmodel continually for relatively complex data. Based on recently proposed\northogonal weight modification (OWM) algorithm which can approximately keep\npreviously learned feature invariant when learning new tasks, we propose to 1)\nreplay penultimate layer feature with a generative model; 2) leverage a\nself-supervised auxiliary task to further enhance the stability of feature.\nEmpirical results on several datasets show our method always achieves\nsubstantial improvement over powerful OWM while conventional generative replay\nalways results in a negative effect. Meanwhile our method beats several strong\nbaselines including one based on real data storage. In addition, we conduct\nexperiments to study why our method is effective.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 13:56:22 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 03:18:23 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 03:35:24 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shen", "Gehui", ""], ["Zhang", "Song", ""], ["Chen", "Xiang", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "2005.03510", "submitter": "Dongyub Lee", "authors": "Dongyub Lee, Myeongcheol Shin, Taesun Whang, Seungwoo Cho, Byeongil\n  Ko, Daniel Lee, Eunggyun Kim, Jaechoon Jo", "title": "Reference and Document Aware Semantic Evaluation Methods for Korean\n  Language Summarization", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization refers to the process that generates a shorter form of\ntext from the source document preserving salient information. Many existing\nworks for text summarization are generally evaluated by using recall-oriented\nunderstudy for gisting evaluation (ROUGE) scores. However, as ROUGE scores are\ncomputed based on n-gram overlap, they do not reflect semantic meaning\ncorrespondences between generated and reference summaries. Because Korean is an\nagglutinative language that combines various morphemes into a word that express\nseveral meanings, ROUGE is not suitable for Korean summarization. In this\npaper, we propose evaluation metrics that reflect semantic meanings of a\nreference summary and the original document, Reference and Document Aware\nSemantic Score (RDASS). We then propose a method for improving the correlation\nof the metrics with human judgment. Evaluation results show that the\ncorrelation with human judgment is significantly higher for our evaluation\nmetrics than for ROUGE scores.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:26:30 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:40:58 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lee", "Dongyub", ""], ["Shin", "Myeongcheol", ""], ["Whang", "Taesun", ""], ["Cho", "Seungwoo", ""], ["Ko", "Byeongil", ""], ["Lee", "Daniel", ""], ["Kim", "Eunggyun", ""], ["Jo", "Jaechoon", ""]]}, {"id": "2005.03540", "submitter": "Micha\\\"el Zamo", "authors": "Micha\\\"el Zamo, Liliane Bel, Olivier Mestre", "title": "Sequential Aggregation of Probabilistic Forecasts -- Applicaton to Wind\n  Speed Ensemble Forecasts", "comments": "38 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the field of numerical weather prediction (NWP), the probabilistic\ndistribution of the future state of the atmosphere is sampled with\nMonte-Carlo-like simulations, called ensembles. These ensembles have\ndeficiencies (such as conditional biases) that can be corrected thanks to\nstatistical post-processing methods. Several ensembles exist and may be\ncorrected with different statistiscal methods. A further step is to combine\nthese raw or post-processed ensembles. The theory of prediction with expert\nadvice allows us to build combination algorithms with theoretical guarantees on\nthe forecast performance. This article adapts this theory to the case of\nprobabilistic forecasts issued as step-wise cumulative distribution functions\n(CDF). The theory is applied to wind speed forecasting, by combining several\nraw or post-processed ensembles, considered as CDFs. The second goal of this\nstudy is to explore the use of two forecast performance criteria: the Continous\nranked probability score (CRPS) and the Jolliffe-Primo test. Comparing the\nresults obtained with both criteria leads to reconsidering the usual way to\nbuild skillful probabilistic forecasts, based on the minimization of the CRPS.\nMinimizing the CRPS does not necessarily produce reliable forecasts according\nto the Jolliffe-Primo test. The Jolliffe-Primo test generally selects reliable\nforecasts, but could lead to issuing suboptimal forecasts in terms of CRPS. It\nis proposed to use both criterion to achieve reliable and skillful\nprobabilistic forecasts.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:07:43 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zamo", "Micha\u00ebl", ""], ["Bel", "Liliane", ""], ["Mestre", "Olivier", ""]]}, {"id": "2005.03557", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhe Wang, Yingbin Liang", "title": "Non-asymptotic Convergence Analysis of Two Time-scale (Natural)\n  Actor-Critic Algorithms", "comments": "The results of this paper were initially submitted for publication in\n  February 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important type of reinforcement learning algorithms, actor-critic (AC)\nand natural actor-critic (NAC) algorithms are often executed in two ways for\nfinding optimal policies. In the first nested-loop design, actor's one update\nof policy is followed by an entire loop of critic's updates of the value\nfunction, and the finite-sample analysis of such AC and NAC algorithms have\nbeen recently well established. The second two time-scale design, in which\nactor and critic update simultaneously but with different learning rates, has\nmuch fewer tuning parameters than the nested-loop design and is hence\nsubstantially easier to implement. Although two time-scale AC and NAC have been\nshown to converge in the literature, the finite-sample convergence rate has not\nbeen established. In this paper, we provide the first such non-asymptotic\nconvergence rate for two time-scale AC and NAC under Markovian sampling and\nwith actor having general policy class approximation. We show that two\ntime-scale AC requires the overall sample complexity at the order of\n$\\mathcal{O}(\\epsilon^{-2.5}\\log^3(\\epsilon^{-1}))$ to attain an\n$\\epsilon$-accurate stationary point, and two time-scale NAC requires the\noverall sample complexity at the order of\n$\\mathcal{O}(\\epsilon^{-4}\\log^2(\\epsilon^{-1}))$ to attain an\n$\\epsilon$-accurate global optimal point. We develop novel techniques for\nbounding the bias error of the actor due to dynamically changing Markovian\nsampling and for analyzing the convergence rate of the linear critic with\ndynamically changing base functions and transition kernel.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:42:31 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 02:06:12 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Xu", "Tengyu", ""], ["Wang", "Zhe", ""], ["Liang", "Yingbin", ""]]}, {"id": "2005.03566", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Bo Zhang and Xudong Li", "title": "Noisy Differentiable Architecture Search", "comments": "Make use of noise to address collapse from excessive skip connections\n  in DARTS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplicity is the ultimate sophistication. Differentiable Architecture Search\n(DARTS) has now become one of the mainstream paradigms of neural architecture\nsearch. However, it largely suffers from several disturbing factors of\noptimization process whose results are unstable to reproduce. FairDARTS points\nout that skip connections natively have an unfair advantage in exclusive\ncompetition which primarily leads to dramatic performance collapse. While\nFairDARTS turns the unfair competition into a collaborative one, we instead\nimpede such unfair advantage by injecting unbiased random noise into skip\noperations' output. In effect, the optimizer should perceive this difficulty at\neach training step and refrain from overshooting on skip connections, but in a\nlong run it still converges to the right solution area since no bias is added\nto the gradient. We name this novel approach as NoisyDARTS. Our experiments on\nCIFAR-10 and ImageNet attest that it can effectively break the skip\nconnection's unfair advantage and yield better performance. It generates a\nseries of models that achieve state-of-the-art results on both datasets. Code\nwill be made available at https://github.com/xiaomi-automl/NoisyDARTS.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:53:52 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 14:42:33 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Li", "Xudong", ""]]}, {"id": "2005.03582", "submitter": "Mar\\'ia N. Moreno Garc\\'ia", "authors": "Fernando S\\'anchez-Hern\\'andez, Juan Carlos Ballesteros-Herr\\'aez,\n  Mohamed S. Kraiem, Mercedes S\\'anchez-Barba and Mar\\'ia N. Moreno-Garc\\'ia", "title": "Predictive Modeling of ICU Healthcare-Associated Infections from\n  Imbalanced Data. Using Ensembles and a Clustering-Based Undersampling\n  Approach", "comments": null, "journal-ref": "Applied Sciences 9(24),5287,2019", "doi": "10.3390/app9245287", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Early detection of patients vulnerable to infections acquired in the hospital\nenvironment is a challenge in current health systems given the impact that such\ninfections have on patient mortality and healthcare costs. This work is focused\non both the identification of risk factors and the prediction of\nhealthcare-associated infections in intensive-care units by means of\nmachine-learning methods. The aim is to support decision making addressed at\nreducing the incidence rate of infections. In this field, it is necessary to\ndeal with the problem of building reliable classifiers from imbalanced\ndatasets. We propose a clustering-based undersampling strategy to be used in\ncombination with ensemble classifiers. A comparative study with data from 4616\npatients was conducted in order to validate our proposal. We applied several\nsingle and ensemble classifiers both to the original dataset and to data\npreprocessed by means of different resampling methods. The results were\nanalyzed by means of classic and recent metrics specifically designed for\nimbalanced data classification. They revealed that the proposal is more\nefficient in comparison with other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:13:12 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["S\u00e1nchez-Hern\u00e1ndez", "Fernando", ""], ["Ballesteros-Herr\u00e1ez", "Juan Carlos", ""], ["Kraiem", "Mohamed S.", ""], ["S\u00e1nchez-Barba", "Mercedes", ""], ["Moreno-Garc\u00eda", "Mar\u00eda N.", ""]]}, {"id": "2005.03585", "submitter": "Ran Ber", "authors": "Ran Ilan Ber and Tom Haramaty", "title": "Domain Adaptation in Highly Imbalanced and Overlapping Datasets", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning domains, datasets are characterized by highly\nimbalanced and overlapping classes. Particularly in the medical domain, a\nspecific list of symptoms can be labeled as one of various different\nconditions. Some of these conditions may be more prevalent than others by\nseveral orders of magnitude. Here we present a novel unsupervised domain\nadaptation scheme for such datasets. The scheme, based on a specific type of\nQuantification, is designed to work under both label and conditional shifts. It\nis demonstrated on datasets generated from electronic health records and\nprovides high quality results for both Quantification and Domain Adaptation in\nvery challenging scenarios. Potential benefits of using this scheme in the\ncurrent COVID-19 outbreak, for estimation of prevalence and probability of\ninfection are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:15:45 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 10:23:16 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ber", "Ran Ilan", ""], ["Haramaty", "Tom", ""]]}, {"id": "2005.03596", "submitter": "Khemraj Shukla", "authors": "Khemraj Shukla, Patricio Clark Di Leoni, James Blackshire, Daniel\n  Sparkman and George Em Karniadakis", "title": "Physics-informed neural network for ultrasound nondestructive\n  quantification of surface breaking cracks", "comments": "19 pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an optimized physics-informed neural network (PINN) trained to\nsolve the problem of identifying and characterizing a surface breaking crack in\na metal plate. PINNs are neural networks that can combine data and physics in\nthe learning process by adding the residuals of a system of Partial\nDifferential Equations to the loss function. Our PINN is supervised with\nrealistic ultrasonic surface acoustic wave data acquired at a frequency of 5\nMHz. The ultrasonic surface wave data is represented as a surface deformation\non the top surface of a metal plate, measured by using the method of laser\nvibrometry. The PINN is physically informed by the acoustic wave equation and\nits convergence is sped up using adaptive activation functions. The adaptive\nactivation function uses a scalable hyperparameter in the activation function,\nwhich is optimized to achieve best performance of the network as it changes\ndynamically the topology of the loss function involved in the optimization\nprocess. The usage of adaptive activation function significantly improves the\nconvergence, notably observed in the current study. We use PINNs to estimate\nthe speed of sound of the metal plate, which we do with an error of 1\\%, and\nthen, by allowing the speed of sound to be space dependent, we identify and\ncharacterize the crack as the positions where the speed of sound has decreased.\nOur study also shows the effect of sub-sampling of the data on the sensitivity\nof sound speed estimates. More broadly, the resulting model shows a promising\ndeep neural network model for ill-posed inverse problems.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:32:11 GMT"}], "update_date": "2020-05-09", "authors_parsed": [["Shukla", "Khemraj", ""], ["Di Leoni", "Patricio Clark", ""], ["Blackshire", "James", ""], ["Sparkman", "Daniel", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2005.03622", "submitter": "Alex Dytso", "authors": "Wei Cao, Alex Dytso, Michael Fau{\\ss}, H. Vincent Poor, and Gang Feng", "title": "Nonparametric Estimation of the Fisher Information and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimation of the Fisher information for\nlocation from a random sample of size $n$. First, an estimator proposed by\nBhattacharya is revisited and improved convergence rates are derived. Second, a\nnew estimator, termed a clipped estimator, is proposed. Superior upper bounds\non the rates of convergence can be shown for the new estimator compared to the\nBhattacharya estimator, albeit with different regularity conditions. Third,\nboth of the estimators are evaluated for the practically relevant case of a\nrandom variable contaminated by Gaussian noise. Moreover, using Brown's\nidentity, which relates the Fisher information and the minimum mean squared\nerror (MMSE) in Gaussian noise, two corresponding consistent estimators for the\nMMSE are proposed. Simulation examples for the Bhattacharya estimator and the\nclipped estimator as well as the MMSE estimators are presented. The examples\ndemonstrate that the clipped estimator can significantly reduce the required\nsample size to guarantee a specific confidence interval compared to the\nBhattacharya estimator.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:21:56 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Cao", "Wei", ""], ["Dytso", "Alex", ""], ["Fau\u00df", "Michael", ""], ["Poor", "H. Vincent", ""], ["Feng", "Gang", ""]]}, {"id": "2005.03625", "submitter": "John R.J. Thompson", "authors": "John R.J. Thompson, Longlong Feng, R. Mark Reesor, Chuck Grace", "title": "Know Your Clients' behaviours: a cluster analysis of financial\n  transactions", "comments": "38 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Canada, financial advisors and dealers are required by provincial\nsecurities commissions and self-regulatory organizations--charged with direct\nregulation over investment dealers and mutual fund dealers--to respectively\ncollect and maintain Know Your Client (KYC) information, such as their age or\nrisk tolerance, for investor accounts. With this information, investors, under\ntheir advisor's guidance, make decisions on their investments which are\npresumed to be beneficial to their investment goals. Our unique dataset is\nprovided by a financial investment dealer with over 50,000 accounts for over\n23,000 clients. We use a modified behavioural finance recency, frequency,\nmonetary model for engineering features that quantify investor behaviours, and\nmachine learning clustering algorithms to find groups of investors that behave\nsimilarly. We show that the KYC information collected does not explain client\nbehaviours, whereas trade and transaction frequency and volume are most\ninformative. We believe the results shown herein encourage financial regulators\nand advisors to use more advanced metrics to better understand and predict\ninvestor behaviours.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:22:40 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 14:29:13 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Thompson", "John R. J.", ""], ["Feng", "Longlong", ""], ["Reesor", "R. Mark", ""], ["Grace", "Chuck", ""]]}, {"id": "2005.03632", "submitter": "Sreejita Ghosh", "authors": "Sreejita Ghosh, Peter Tino, Kerstin Bunte", "title": "Visualisation and knowledge discovery from interpretable models", "comments": "Accepted for proceedings of the International Joint Conference on\n  Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing number of sectors which affect human lives, are using Machine\nLearning (ML) tools. Hence the need for understanding their working mechanism\nand evaluating their fairness in decision-making, are becoming paramount,\nushering in the era of Explainable AI (XAI). In this contribution we introduced\na few intrinsically interpretable models which are also capable of dealing with\nmissing values, in addition to extracting knowledge from the dataset and about\nthe problem. These models are also capable of visualisation of the classifier\nand decision boundaries: they are the angle based variants of Learning Vector\nQuantization. We have demonstrated the algorithms on a synthetic dataset and a\nreal-world one (heart disease dataset from the UCI repository). The newly\ndeveloped classifiers helped in investigating the complexities of the UCI\ndataset as a multiclass problem. The performance of the developed classifiers\nwere comparable to those reported in literature for this dataset, with\nadditional value of interpretability, when the dataset was treated as a binary\nclass problem.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:37:06 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 08:22:02 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ghosh", "Sreejita", ""], ["Tino", "Peter", ""], ["Bunte", "Kerstin", ""]]}, {"id": "2005.03645", "submitter": "Kevin Fauvel", "authors": "Kevin Fauvel, \\'Elisa Fromont, V\\'eronique Masson, Philippe Faverdin,\n  Alexandre Termier", "title": "XEM: An Explainable Ensemble Method for Multivariate Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present XEM, an eXplainable Ensemble method for Multivariate time series\nclassification. XEM relies on a new hybrid ensemble method that combines an\nexplicit boosting-bagging approach to handle the bias-variance trade-off faced\nby machine learning models and an implicit divide-and-conquer approach to\nindividualize classifier errors on different parts of the training data. Our\nevaluation shows that XEM outperforms the state-of-the-art MTS classifiers on\nthe UEA datasets. Furthermore, XEM provides faithful explainability by design\nand manifests robust performance when faced with challenges arising from\ncontinuous data collection (different MTS length, missing data and noise).\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:50:18 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 10:09:47 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 09:09:51 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 07:55:40 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Fauvel", "Kevin", ""], ["Fromont", "\u00c9lisa", ""], ["Masson", "V\u00e9ronique", ""], ["Faverdin", "Philippe", ""], ["Termier", "Alexandre", ""]]}, {"id": "2005.03648", "submitter": "Ge Yang", "authors": "Ge Yang, Amy Zhang, Ari S. Morcos, Joelle Pineau, Pieter Abbeel,\n  Roberto Calandra", "title": "Plan2Vec: Unsupervised Representation Learning by Latent Plans", "comments": "code available at https://geyang.github.io/plan2vec", "journal-ref": "Proceedings of Machine Learning Research, the 2nd Annual\n  Conference on Learning for Dynamics and Control (2020) Volume 120, 1-12", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce plan2vec, an unsupervised representation learning\napproach that is inspired by reinforcement learning. Plan2vec constructs a\nweighted graph on an image dataset using near-neighbor distances, and then\nextrapolates this local metric to a global embedding by distilling\npath-integral over planned path. When applied to control, plan2vec offers a way\nto learn goal-conditioned value estimates that are accurate over long horizons\nthat is both compute and sample efficient. We demonstrate the effectiveness of\nplan2vec on one simulated and two challenging real-world image datasets.\nExperimental results show that plan2vec successfully amortizes the planning\ncost, enabling reactive planning that is linear in memory and computation\ncomplexity rather than exhaustive over the entire state space.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:52:23 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Yang", "Ge", ""], ["Zhang", "Amy", ""], ["Morcos", "Ari S.", ""], ["Pineau", "Joelle", ""], ["Abbeel", "Pieter", ""], ["Calandra", "Roberto", ""]]}, {"id": "2005.03654", "submitter": "Elena Ericheva", "authors": "Ivan Drokin, Elena Ericheva", "title": "Deep Learning on Point Clouds for False Positive Reduction at Nodule\n  Detection in Chest CT Scans", "comments": null, "journal-ref": "In: van der Aalst W.M.P. et al. (eds) Analysis of Images, Social\n  Networks and Texts. AIST 2020. Lecture Notes in Computer Science, vol 12602.\n  Springer, Cham", "doi": "10.1007/978-3-030-72610-2_15", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a novel approach for false-positive reduction (FPR) of\nnodule candidates in Computer-aided detection (CADe) systems following the\nsuspicious lesions detection stage. Contrary to typical decisions in medical\nimage analysis, the proposed approach considers input data not as a 2D or 3D\nimage, but rather as a point cloud, and uses deep learning models for point\nclouds. We discovered that point cloud models require less memory and are\nfaster both in training and inference compared to traditional CNN 3D, they\nachieve better performance and do not impose restrictions on the size of the\ninput image, i.e. no restrictions on the size of the nodule candidate. We\npropose an algorithm for transforming 3D CT scan data to point cloud. In some\ncases, the volume of the nodule candidate can be much smaller than the\nsurrounding context, for example, in the case of subpleural localization of the\nnodule. Therefore, we developed an algorithm for sampling points from a point\ncloud constructed from a 3D image of the candidate region. The algorithm is\nable to guarantee the capture of both context and candidate information as part\nof the point cloud of the nodule candidate. We designed and set up an\nexperiment in creating a dataset from an open LIDC-IDRI database for a feature\nof the FPR task, and is herein described in detail. Data augmentation was\napplied both to avoid overfitting and as an upsampling method. Experiments were\nconducted with PointNet, PointNet++, and DGCNN. We show that the proposed\napproach outperforms baseline CNN 3D models and resulted in 85.98 FROC versus\n77.26 FROC for baseline models. We compare our algorithm with published SOTA\nand demonstrate that even without significant modifications it works at the\nappropriate performance level on LUNA2016 and shows SOTA on LIDC-IDRI.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:59:54 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 08:31:26 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Drokin", "Ivan", ""], ["Ericheva", "Elena", ""]]}, {"id": "2005.03675", "submitter": "Ines Chami", "authors": "Ines Chami, Sami Abu-El-Haija, Bryan Perozzi, Christopher R\\'e, Kevin\n  Murphy", "title": "Machine Learning on Graphs: A Model and Comprehensive Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a surge of recent interest in learning representations for\ngraph-structured data. Graph representation learning methods have generally\nfallen into three main categories, based on the availability of labeled data.\nThe first, network embedding (such as shallow graph embedding or graph\nauto-encoders), focuses on learning unsupervised representations of relational\nstructure. The second, graph regularized neural networks, leverages graphs to\naugment neural network losses with a regularization objective for\nsemi-supervised learning. The third, graph neural networks, aims to learn\ndifferentiable functions over discrete topologies with arbitrary structure.\nHowever, despite the popularity of these areas there has been surprisingly\nlittle work on unifying the three paradigms. Here, we aim to bridge the gap\nbetween graph neural networks, network embedding and graph regularization\nmodels. We propose a comprehensive taxonomy of representation learning methods\nfor graph-structured data, aiming to unify several disparate bodies of work.\nSpecifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which\ngeneralizes popular algorithms for semi-supervised learning on graphs (e.g.\nGraphSage, Graph Convolutional Networks, Graph Attention Networks), and\nunsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc)\ninto a single consistent approach. To illustrate the generality of this\napproach, we fit over thirty existing methods into this framework. We believe\nthat this unifying view both provides a solid foundation for understanding the\nintuition behind these methods, and enables future research in the area.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 18:00:02 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 15:41:03 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chami", "Ines", ""], ["Abu-El-Haija", "Sami", ""], ["Perozzi", "Bryan", ""], ["R\u00e9", "Christopher", ""], ["Murphy", "Kevin", ""]]}, {"id": "2005.03687", "submitter": "Rajiv Ratn Shah", "authors": "Vishaal Udandarao, Abhishek Maiti, Deepak Srivatsav, Suryatej Reddy\n  Vyalla, Yifang Yin, Rajiv Ratn Shah", "title": "COBRA: Contrastive Bi-Modal Representation Algorithm", "comments": "13 Pages, 6 Figures and 10 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a wide range of applications that involve multi-modal data, such as\ncross-modal retrieval, visual question-answering, and image captioning. Such\napplications are primarily dependent on aligned distributions of the different\nconstituent modalities. Existing approaches generate latent embeddings for each\nmodality in a joint fashion by representing them in a common manifold. However\nthese joint embedding spaces fail to sufficiently reduce the modality gap,\nwhich affects the performance in downstream tasks. We hypothesize that these\nembeddings retain the intra-class relationships but are unable to preserve the\ninter-class dynamics. In this paper, we present a novel framework COBRA that\naims to train two modalities (image and text) in a joint fashion inspired by\nthe Contrastive Predictive Coding (CPC) and Noise Contrastive Estimation (NCE)\nparadigms which preserve both inter and intra-class relationships. We\nempirically show that this framework reduces the modality gap significantly and\ngenerates a robust and task agnostic joint-embedding space. We outperform\nexisting work on four diverse downstream tasks spanning across seven benchmark\ncross-modal datasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 18:20:12 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 20:07:52 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Udandarao", "Vishaal", ""], ["Maiti", "Abhishek", ""], ["Srivatsav", "Deepak", ""], ["Vyalla", "Suryatej Reddy", ""], ["Yin", "Yifang", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2005.03718", "submitter": "Sami Khairy", "authors": "Sami Khairy, Prasanna Balaprakash, Lin X. Cai", "title": "A Gradient-Aware Search Algorithm for Constrained Markov Decision\n  Processes", "comments": "Submitted as a brief paper to the IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The canonical solution methodology for finite constrained Markov decision\nprocesses (CMDPs), where the objective is to maximize the expected\ninfinite-horizon discounted rewards subject to the expected infinite-horizon\ndiscounted costs constraints, is based on convex linear programming. In this\nbrief, we first prove that the optimization objective in the dual linear\nprogram of a finite CMDP is a piece-wise linear convex function (PWLC) with\nrespect to the Lagrange penalty multipliers. Next, we propose a novel two-level\nGradient-Aware Search (GAS) algorithm which exploits the PWLC structure to find\nthe optimal state-value function and Lagrange penalty multipliers of a finite\nCMDP. The proposed algorithm is applied in two stochastic control problems with\nconstraints: robot navigation in a grid world and solar-powered unmanned aerial\nvehicle (UAV)-based wireless network management. We empirically compare the\nconvergence performance of the proposed GAS algorithm with binary search (BS),\nLagrangian primal-dual optimization (PDO), and Linear Programming (LP).\nCompared with benchmark algorithms, it is shown that the proposed GAS algorithm\nconverges to the optimal solution faster, does not require hyper-parameter\ntuning, and is not sensitive to initialization of the Lagrange penalty\nmultiplier.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 19:38:09 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Khairy", "Sami", ""], ["Balaprakash", "Prasanna", ""], ["Cai", "Lin X.", ""]]}, {"id": "2005.03725", "submitter": "Martin Wainwright", "authors": "Max Rabinovich and Michael I. Jordan and Martin J. Wainwright", "title": "Lower bounds in multiple testing: A framework based on derandomized\n  proxies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large bulk of work in multiple testing has focused on specifying\nprocedures that control the false discovery rate (FDR), with relatively less\nattention being paid to the corresponding Type II error known as the false\nnon-discovery rate (FNR). A line of more recent work in multiple testing has\nbegun to investigate the tradeoffs between the FDR and FNR and to provide lower\nbounds on the performance of procedures that depend on the model structure.\nLacking thus far, however, has been a general approach to obtaining lower\nbounds for a broad class of models. This paper introduces an analysis strategy\nbased on derandomization, illustrated by applications to various concrete\nmodels. Our main result is meta-theorem that gives a general recipe for\nobtaining lower bounds on the combination of FDR and FNR. We illustrate this\nmeta-theorem by deriving explicit bounds for several models, including\ninstances with dependence, scale-transformed alternatives, and\nnon-Gaussian-like distributions. We provide numerical simulations of some of\nthese lower bounds, and show a close relation to the actual performance of the\nBenjamini-Hochberg (BH) algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 19:59:51 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Rabinovich", "Max", ""], ["Jordan", "Michael I.", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "2005.03730", "submitter": "Johan Larsson", "authors": "Johan Larsson, Ma{\\l}gorzata Bogdan, Jonas Wallin", "title": "The Strong Screening Rule for SLOPE", "comments": "15 pages, 5 figures", "journal-ref": "Advances in Neural Information Processing Systems 33, 2020, p.\n  14592-14603", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting relevant features from data sets where the number of observations\n($n$) is much smaller then the number of predictors ($p$) is a major challenge\nin modern statistics. Sorted L-One Penalized Estimation (SLOPE), a\ngeneralization of the lasso, is a promising method within this setting. Current\nnumerical procedures for SLOPE, however, lack the efficiency that respective\ntools for the lasso enjoy, particularly in the context of estimating a complete\nregularization path. A key component in the efficiency of the lasso is\npredictor screening rules: rules that allow predictors to be discarded before\nestimating the model. This is the first paper to establish such a rule for\nSLOPE. We develop a screening rule for SLOPE by examining its subdifferential\nand show that this rule is a generalization of the strong rule for the lasso.\nOur rule is heuristic, which means that it may discard predictors erroneously.\nWe present conditions under which this may happen and show that such situations\nare rare and easily safeguarded against by a simple check of the optimality\nconditions. Our numerical experiments show that the rule performs well in\npractice, leading to improvements by orders of magnitude for data in the $p \\gg\nn$ domain, as well as incurring no additional computational overhead when $n\n\\gg p$. We also examine the effect of correlation structures in the design\nmatrix on the rule and discuss algorithmic strategies for employing the rule.\nFinally, we provide an efficient implementation of the rule in our R package\nSLOPE.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 20:14:20 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 18:17:19 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Larsson", "Johan", ""], ["Bogdan", "Ma\u0142gorzata", ""], ["Wallin", "Jonas", ""]]}, {"id": "2005.03750", "submitter": "James P. Crutchfield", "authors": "S. E. Marzen and J. P. Crutchfield", "title": "Inference, Prediction, and Entropy-Rate Estimation of Continuous-time,\n  Discrete-event Processes", "comments": "11 pages, 5 figures;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/ctbsi.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.IT cs.LG math.IT nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring models, predicting the future, and estimating the entropy rate of\ndiscrete-time, discrete-event processes is well-worn ground. However, a much\nbroader class of discrete-event processes operates in continuous-time. Here, we\nprovide new methods for inferring, predicting, and estimating them. The methods\nrely on an extension of Bayesian structural inference that takes advantage of\nneural network's universal approximation power. Based on experiments with\ncomplex synthetic data, the methods are competitive with the state-of-the-art\nfor prediction and entropy-rate estimation.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 20:54:19 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Marzen", "S. E.", ""], ["Crutchfield", "J. P.", ""]]}, {"id": "2005.03769", "submitter": "Yang Li", "authors": "Yang Li and Jinqiao Duan", "title": "A Data-Driven Approach for Discovering Stochastic Dynamical Systems with\n  Non-Gaussian Levy Noise", "comments": "36 pages", "journal-ref": null, "doi": "10.1016/j.physd.2020.132830", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase of valuable observational, experimental and\nsimulating data for complex systems, great efforts are being devoted to\ndiscovering governing laws underlying the evolution of these systems. However,\nthe existing techniques are limited to extract governing laws from data as\neither deterministic differential equations or stochastic differential\nequations with Gaussian noise. In the present work, we develop a new\ndata-driven approach to extract stochastic dynamical systems with non-Gaussian\nsymmetric L\\'evy noise, as well as Gaussian noise. First, we establish a\nfeasible theoretical framework, by expressing the drift coefficient, diffusion\ncoefficient and jump measure (i.e., anomalous diffusion) for the underlying\nstochastic dynamical system in terms of sample paths data. We then design a\nnumerical algorithm to compute the drift, diffusion coefficient and jump\nmeasure, and thus extract a governing stochastic differential equation with\nGaussian and non-Gaussian noise. Finally, we demonstrate the efficacy and\naccuracy of our approach by applying to several prototypical one-, two- and\nthree-dimensional systems. This new approach will become a tool in discovering\ngoverning dynamical laws from noisy data sets, from observing or simulating\ncomplex phenomena, such as rare events triggered by random fluctuations with\nheavy as well as light tail statistical features.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:29:17 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 02:18:17 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Li", "Yang", ""], ["Duan", "Jinqiao", ""]]}, {"id": "2005.03770", "submitter": "Jan Achterhold", "authors": "Nathanael Bosch, Jan Achterhold, Laura Leal-Taix\\'e, J\\\"org St\\\"uckler", "title": "Planning from Images with Deep Latent Gaussian Process Dynamics", "comments": "Accepted for publication at the 2nd Annual Conference on Learning for\n  Dynamics and Control (L4DC) 2020, with supplementary material. First two\n  authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is a powerful approach to control problems with known environment\ndynamics. In unknown environments the agent needs to learn a model of the\nsystem dynamics to make planning applicable. This is particularly challenging\nwhen the underlying states are only indirectly observable through images. We\npropose to learn a deep latent Gaussian process dynamics (DLGPD) model that\nlearns low-dimensional system dynamics from environment interactions with\nvisual observations. The method infers latent state representations from\nobservations using neural networks and models the system dynamics in the\nlearned latent space with Gaussian processes. All parts of the model can be\ntrained jointly by optimizing a lower bound on the likelihood of transitions in\nimage space. We evaluate the proposed approach on the pendulum swing-up task\nwhile using the learned dynamics model for planning in latent space in order to\nsolve the control problem. We also demonstrate that our method can quickly\nadapt a trained agent to changes in the system dynamics from just a few\nrollouts. We compare our approach to a state-of-the-art purely deep learning\nbased method and demonstrate the advantages of combining Gaussian processes\nwith deep learning for data efficiency and transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:29:45 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Bosch", "Nathanael", ""], ["Achterhold", "Jan", ""], ["Leal-Taix\u00e9", "Laura", ""], ["St\u00fcckler", "J\u00f6rg", ""]]}, {"id": "2005.03773", "submitter": "Ramiro Camino", "authors": "Ramiro Camino, Christian Hammerschmidt, Radu State", "title": "Minority Class Oversampling for Tabular Data with Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, machine learning experts are often confronted with imbalanced\ndata. Without accounting for the imbalance, common classifiers perform poorly\nand standard evaluation metrics mislead the practitioners on the model's\nperformance. A common method to treat imbalanced datasets is under- and\noversampling. In this process, samples are either removed from the majority\nclass or synthetic samples are added to the minority class. In this paper, we\nfollow up on recent developments in deep learning. We take proposals of deep\ngenerative models, including our own, and study the ability of these approaches\nto provide realistic samples that improve performance on imbalanced\nclassification tasks via oversampling.\n  Across 160K+ experiments, we show that all of the new methods tend to perform\nbetter than simple baseline methods such as SMOTE, but require different under-\nand oversampling ratios to do so. Our experiments show that the way the method\nof sampling does not affect quality, but runtime varies widely. We also observe\nthat the improvements in terms of performance metric, while shown to be\nsignificant when ranking the methods, often are minor in absolute terms,\nespecially compared to the required effort. Furthermore, we notice that a large\npart of the improvement is due to undersampling, not oversampling. We make our\ncode and testing framework available.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:35:57 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 13:59:10 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Camino", "Ramiro", ""], ["Hammerschmidt", "Christian", ""], ["State", "Radu", ""]]}, {"id": "2005.03780", "submitter": "Steven Reeves", "authors": "Steven I Reeves, Dongwook Lee, Anurag Singh, and Kunal Verma", "title": "A Gaussian Process Upsampling Model for Improvements in Optical\n  Character Recognition", "comments": "12 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Character Recognition and extraction is a key tool in the automatic\nevaluation of documents in a financial context. However, the image data\nprovided to automated systems can have unreliable quality, and can be\ninherently low-resolution or downsampled and compressed by a transmitting\nprogram. In this paper, we illustrate the efficacy of a Gaussian Process\nupsampling model for the purposes of improving OCR and extraction through\nupsampling low resolution documents.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 22:13:22 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Reeves", "Steven I", ""], ["Lee", "Dongwook", ""], ["Singh", "Anurag", ""], ["Verma", "Kunal", ""]]}, {"id": "2005.03788", "submitter": "Xinshao Wang Dr", "authors": "Xinshao Wang, Yang Hua, Elyor Kodirov, David A. Clifton, Neil M.\n  Robertson", "title": "ProSelfLC: Progressive Self Label Correction for Training Robust Deep\n  Neural Networks", "comments": "ProSelfLC is the first method to trust self knowledge progressively\n  and adaptively. ProSelfLC redirects and promotes entropy minimisation, which\n  is in marked contrast to recent practices of confidence penalty [42, 33, 6]", "journal-ref": "CVPR 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To train robust deep neural networks (DNNs), we systematically study several\ntarget modification approaches, which include output regularisation, self and\nnon-self label correction (LC). Two key issues are discovered: (1) Self LC is\nthe most appealing as it exploits its own knowledge and requires no extra\nmodels. However, how to automatically decide the trust degree of a learner as\ntraining goes is not well answered in the literature? (2) Some methods penalise\nwhile the others reward low-entropy predictions, prompting us to ask which one\nis better?\n  To resolve the first issue, taking two well-accepted propositions--deep\nneural networks learn meaningful patterns before fitting noise [3] and minimum\nentropy regularisation principle [10]--we propose a novel end-to-end method\nnamed ProSelfLC, which is designed according to learning time and entropy.\nSpecifically, given a data point, we progressively increase trust in its\npredicted label distribution versus its annotated one if a model has been\ntrained for enough time and the prediction is of low entropy (high confidence).\nFor the second issue, according to ProSelfLC, we empirically prove that it is\nbetter to redefine a meaningful low-entropy status and optimise the learner\ntoward it. This serves as a defence of entropy minimisation.\n  We demonstrate the effectiveness of ProSelfLC through extensive experiments\nin both clean and noisy settings. The source code is available at\nhttps://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021.\n  Keywords: entropy minimisation, maximum entropy, confidence penalty, self\nknowledge distillation, label correction, label noise, semi-supervised\nlearning, output regularisation\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 22:35:04 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 22:10:17 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 13:36:09 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 11:04:32 GMT"}, {"version": "v5", "created": "Fri, 9 Oct 2020 12:45:28 GMT"}, {"version": "v6", "created": "Wed, 2 Jun 2021 12:27:53 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Xinshao", ""], ["Hua", "Yang", ""], ["Kodirov", "Elyor", ""], ["Clifton", "David A.", ""], ["Robertson", "Neil M.", ""]]}, {"id": "2005.03789", "submitter": "Christoph Dann", "authors": "Christoph Dann, Yishay Mansour, Mehryar Mohri, Ayush Sekhari, Karthik\n  Sridharan", "title": "Reinforcement Learning with Feedback Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study episodic reinforcement learning in Markov decision processes when\nthe agent receives additional feedback per step in the form of several\ntransition observations. Such additional observations are available in a range\nof tasks through extended sensors or prior knowledge about the environment\n(e.g., when certain actions yield similar outcome). We formalize this setting\nusing a feedback graph over state-action pairs and show that model-based\nalgorithms can leverage the additional feedback for more sample-efficient\nlearning. We give a regret bound that, ignoring logarithmic factors and\nlower-order terms, depends only on the size of the maximum acyclic subgraph of\nthe feedback graph, in contrast with a polynomial dependency on the number of\nstates and actions in the absence of a feedback graph. Finally, we highlight\nchallenges when leveraging a small dominating set of the feedback graph as\ncompared to the bandit setting and propose a new algorithm that can use\nknowledge of such a dominating set for more sample-efficient learning of a\nnear-optimal policy.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 22:35:37 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Dann", "Christoph", ""], ["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""], ["Sekhari", "Ayush", ""], ["Sridharan", "Karthik", ""]]}, {"id": "2005.03807", "submitter": "Daniel Braithwaite", "authors": "D. T. Braithwaite, M. O'Connor, W. B. Kleijn", "title": "Variance Constrained Autoencoding", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art autoencoder based generative models have an\nencoder-decoder structure and learn a latent representation with a pre-defined\ndistribution that can be sampled from. Implementing the encoder networks of\nthese models in a stochastic manner provides a natural and common approach to\navoid overfitting and enforce a smooth decoder function. However, we show that\nfor stochastic encoders, simultaneously attempting to enforce a distribution\nconstraint and minimising an output distortion leads to a reduction in\ngenerative and reconstruction quality. In addition, attempting to enforce a\nlatent distribution constraint is not reasonable when performing\ndisentanglement. Hence, we propose the variance-constrained autoencoder (VCAE),\nwhich only enforces a variance constraint on the latent distribution. Our\nexperiments show that VCAE improves upon Wasserstein Autoencoder and the\nVariational Autoencoder in both reconstruction and generative quality on MNIST\nand CelebA. Moreover, we show that VCAE equipped with a total correlation\npenalty term performs equivalently to FactorVAE at learning disentangled\nrepresentations on 3D-Shapes while being a more principled approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 00:50:50 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Braithwaite", "D. T.", ""], ["O'Connor", "M.", ""], ["Kleijn", "W. B.", ""]]}, {"id": "2005.03810", "submitter": "Govind Ramnarayan", "authors": "Younhun Kim, Elchanan Mossel, Govind Ramnarayan, Paxton Turner", "title": "Efficient Reconstruction of Stochastic Pedigrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG q-bio.PE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algorithm called {\\sc Rec-Gen} for reconstructing the\ngenealogy or \\textit{pedigree} of an extant population purely from its genetic\ndata. We justify our approach by giving a mathematical proof of the\neffectiveness of {\\sc Rec-Gen} when applied to pedigrees from an idealized\ngenerative model that replicates some of the features of real-world pedigrees.\nOur algorithm is iterative and provides an accurate reconstruction of a large\nfraction of the pedigree while having relatively low \\emph{sample complexity},\nmeasured in terms of the length of the genetic sequences of the population. We\npropose our approach as a prototype for further investigation of the pedigree\nreconstruction problem toward the goal of applications to real-world examples.\nAs such, our results have some conceptual bearing on the increasingly important\nissue of genomic privacy.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 01:08:36 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Kim", "Younhun", ""], ["Mossel", "Elchanan", ""], ["Ramnarayan", "Govind", ""], ["Turner", "Paxton", ""]]}, {"id": "2005.03825", "submitter": "Xikai Yang", "authors": "Xikai Yang, Xuehang Zheng, Yong Long, Saiprasad Ravishankar", "title": "Learned Multi-layer Residual Sparsifying Transform Model for Low-dose CT\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal models based on sparse representation have received considerable\nattention in recent years. Compared to synthesis dictionary learning,\nsparsifying transform learning involves highly efficient sparse coding and\noperator update steps. In this work, we propose a Multi-layer Residual\nSparsifying Transform (MRST) learning model wherein the transform domain\nresiduals are jointly sparsified over layers. In particular, the transforms for\nthe deeper layers exploit the more intricate properties of the residual maps.\nWe investigate the application of the learned MRST model for low-dose CT\nreconstruction using Penalized Weighted Least Squares (PWLS) optimization.\nExperimental results on Mayo Clinic data show that the MRST model outperforms\nconventional methods such as FBP and PWLS methods based on edge-preserving (EP)\nregularizer and single-layer transform (ST) model, especially for maintaining\nsome subtle details.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 02:36:50 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Yang", "Xikai", ""], ["Zheng", "Xuehang", ""], ["Long", "Yong", ""], ["Ravishankar", "Saiprasad", ""]]}, {"id": "2005.03842", "submitter": "Ali Hadi Zadeh", "authors": "Ali Hadi Zadeh, Isak Edo, Omar Mohamed Awad, and Andreas Moshovos", "title": "GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy\n  Efficient Inference", "comments": "Accepted at the 53rd IEEE/ACM International Symposium on\n  Microarchitecture - MICRO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models have demonstrated remarkable success in various\nnatural language understanding tasks. However, efficient execution remains a\nchallenge for these models which are memory-bound due to their massive number\nof parameters. We present GOBO, a model quantization technique that compresses\nthe vast majority (typically 99.9%) of the 32-bit floating-point parameters of\nstate-of-the-art BERT models and their variants to 3 bits while maintaining\ntheir accuracy. Unlike other quantization methods, GOBO does not require\nfine-tuning nor retraining to compensate for the quantization error. We present\ntwo practical hardware applications of GOBO. In the first GOBO reduces memory\nstorage and traffic and as a result inference latency and energy consumption.\nThis GOBO memory compression mechanism is plug-in compatible with many\narchitectures; we demonstrate it with the TPU, Eyeriss, and an architecture\nusing Tensor Cores-like units. Second, we present a co-designed hardware\narchitecture that also reduces computation. Uniquely, the GOBO architecture\nmaintains most of the weights in 3b even during computation, a property that:\n(1) makes the processing elements area efficient, allowing us to pack more\ncompute power per unit area, (2) replaces most multiply-accumulations with\nadditions, and (3) reduces the off-chip traffic by amplifying on-chip memory\ncapacity.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 03:59:53 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 00:09:30 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zadeh", "Ali Hadi", ""], ["Edo", "Isak", ""], ["Awad", "Omar Mohamed", ""], ["Moshovos", "Andreas", ""]]}, {"id": "2005.03847", "submitter": "Rishi Sonthalia", "authors": "Rishi Sonthalia, Anna C. Gilbert", "title": "Tree! I am no Tree! I am a Low Dimensional Hyperbolic Embedding", "comments": "Code available at https://github.com/rsonthal/TreeRep", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.MG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given data, finding a faithful low-dimensional hyperbolic embedding of the\ndata is a key method by which we can extract hierarchical information or learn\nrepresentative geometric features of the data. In this paper, we explore a new\nmethod for learning hyperbolic representations by taking a metric-first\napproach. Rather than determining the low-dimensional hyperbolic embedding\ndirectly, we learn a tree structure on the data. This tree structure can then\nbe used directly to extract hierarchical information, embedded into a\nhyperbolic manifold using Sarkar's construction \\cite{sarkar}, or used as a\ntree approximation of the original metric. To this end, we present a novel fast\nalgorithm \\textsc{TreeRep} such that, given a $\\delta$-hyperbolic metric (for\nany $\\delta \\geq 0$), the algorithm learns a tree structure that approximates\nthe original metric. In the case when $\\delta = 0$, we show analytically that\n\\textsc{TreeRep} exactly recovers the original tree structure. We show\nempirically that \\textsc{TreeRep} is not only many orders of magnitude faster\nthan previously known algorithms, but also produces metrics with lower average\ndistortion and higher mean average precision than most previous algorithms for\nlearning hyperbolic embeddings, extracting hierarchical information, and\napproximating metrics via tree metrics.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 04:30:21 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 19:24:44 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 13:51:12 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 01:37:28 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sonthalia", "Rishi", ""], ["Gilbert", "Anna C.", ""]]}, {"id": "2005.03853", "submitter": "Rishi Sonthalia", "authors": "Rishi Sonthalia, Anna C. Gilbert", "title": "Project and Forget: Solving Large-Scale Metric Constrained Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of dissimilarity measurements amongst data points, determining\nwhat metric representation is most \"consistent\" with the input measurements or\nthe metric that best captures the relevant geometric features of the data is a\nkey step in many machine learning algorithms. Existing methods are restricted\nto specific kinds of metrics or small problem sizes because of the large number\nof metric constraints in such problems. In this paper, we provide an active set\nalgorithm, Project and Forget, that uses Bregman projections, to solve metric\nconstrained problems with many (possibly exponentially) inequality constraints.\nWe provide a theoretical analysis of \\textsc{Project and Forget} and prove that\nour algorithm converges to the global optimal solution and that the $L_2$\ndistance of the current iterate to the optimal solution decays asymptotically\nat an exponential rate. We demonstrate that using our method we can solve large\nproblem instances of three types of metric constrained problems: general weight\ncorrelation clustering, metric nearness, and metric learning; in each case,\nout-performing the state of the art methods with respect to CPU times and\nproblem sizes.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 04:50:54 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Sonthalia", "Rishi", ""], ["Gilbert", "Anna C.", ""]]}, {"id": "2005.03857", "submitter": "Jianlei Yang", "authors": "Xiaotao Jia, Jianlei Yang, Runze Liu, Xueyan Wang, Sorin Dan Cotofana,\n  Weisheng Zhao", "title": "Efficient Computation Reduction in Bayesian Neural Networks Through\n  Feature Decomposition and Memorization", "comments": "accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bayesian method is capable of capturing real world\nuncertainties/incompleteness and properly addressing the over-fitting issue\nfaced by deep neural networks. In recent years, Bayesian Neural Networks (BNNs)\nhave drawn tremendous attentions of AI researchers and proved to be successful\nin many applications. However, the required high computation complexity makes\nBNNs difficult to be deployed in computing systems with limited power budget.\nIn this paper, an efficient BNN inference flow is proposed to reduce the\ncomputation cost then is evaluated by means of both software and hardware\nimplementations. A feature decomposition and memorization (\\texttt{DM})\nstrategy is utilized to reform the BNN inference flow in a reduced manner.\nAbout half of the computations could be eliminated compared to the traditional\napproach that has been proved by theoretical analysis and software validations.\nSubsequently, in order to resolve the hardware resource limitations, a\nmemory-friendly computing framework is further deployed to reduce the memory\noverhead introduced by \\texttt{DM} strategy. Finally, we implement our approach\nin Verilog and synthesise it with 45 $nm$ FreePDK technology. Hardware\nsimulation results on multi-layer BNNs demonstrate that, when compared with the\ntraditional BNN inference method, it provides an energy consumption reduction\nof 73\\% and a 4$\\times$ speedup at the expense of 14\\% area overhead.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 05:03:04 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Jia", "Xiaotao", ""], ["Yang", "Jianlei", ""], ["Liu", "Runze", ""], ["Wang", "Xueyan", ""], ["Cotofana", "Sorin Dan", ""], ["Zhao", "Weisheng", ""]]}, {"id": "2005.03858", "submitter": "Alexander Lapanowski", "authors": "Alexander F. Lapanowski, Irina Gaynanova", "title": "Compressing Large Sample Data for Discriminant Analysis", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-sample data became prevalent as data acquisition became cheaper and\neasier. While a large sample size has theoretical advantages for many\nstatistical methods, it presents computational challenges. Sketching, or\ncompression, is a well-studied approach to address these issues in regression\nsettings, but considerably less is known about its performance in\nclassification settings. Here we consider the computational issues due to large\nsample size within the discriminant analysis framework. We propose a new\ncompression approach for reducing the number of training samples for linear and\nquadratic discriminant analysis, in contrast to existing compression methods\nwhich focus on reducing the number of features. We support our approach with a\ntheoretical bound on the misclassification error rate compared to the Bayes\nclassifier. Empirical studies confirm the significant computational gains of\nthe proposed method and its superior predictive ability compared to random\nsub-sampling.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 05:09:08 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lapanowski", "Alexander F.", ""], ["Gaynanova", "Irina", ""]]}, {"id": "2005.03868", "submitter": "Rasoul Sali", "authors": "Rasoul Sali, Sodiq Adewole, Lubaina Ehsan, Lee A. Denson, Paul Kelly,\n  Beatrice C. Amadi, Lori Holtz, Syed Asad Ali, Sean R. Moore, Sana Syed,\n  Donald E. Brown", "title": "Hierarchical Deep Convolutional Neural Networks for Multi-category\n  Diagnosis of Gastrointestinal Disorders on Histopathological Images", "comments": "accepted at IEEE International Conference on Healthcare Informatics\n  (ICHI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks(CNNs) have been successful for a wide\nrange of computer vision tasks, including image classification. A specific area\nof the application lies in digital pathology for pattern recognition in the\ntissue-based diagnosis of gastrointestinal(GI) diseases. This domain can\nutilize CNNs to translate histopathological images into precise diagnostics.\nThis is challenging since these complex biopsies are heterogeneous and require\nmultiple levels of assessment. This is mainly due to structural similarities in\ndifferent parts of the GI tract and shared features among different gut\ndiseases. Addressing this problem with a flat model that assumes all classes\n(parts of the gut and their diseases) are equally difficult to distinguish\nleads to an inadequate assessment of each class. Since the hierarchical model\nrestricts classification error to each sub-class, it leads to a more\ninformative model than a flat model. In this paper, we propose to apply the\nhierarchical classification of biopsy images from different parts of the GI\ntract and the receptive diseases within each. We embedded a class hierarchy\ninto the plain VGGNet to take advantage of its layers' hierarchical structure.\nThe proposed model was evaluated using an independent set of image patches from\n373 whole slide images. The results indicate that the hierarchical model can\nachieve better results than the flat model for multi-category diagnosis of GI\ndisorders using histopathological images.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 06:05:09 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 01:28:59 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Sali", "Rasoul", ""], ["Adewole", "Sodiq", ""], ["Ehsan", "Lubaina", ""], ["Denson", "Lee A.", ""], ["Kelly", "Paul", ""], ["Amadi", "Beatrice C.", ""], ["Holtz", "Lori", ""], ["Ali", "Syed Asad", ""], ["Moore", "Sean R.", ""], ["Syed", "Sana", ""], ["Brown", "Donald E.", ""]]}, {"id": "2005.03888", "submitter": "Chong You", "authors": "Chong You and Chun-Guang Li and Daniel P. Robinson and Rene Vidal", "title": "Is an Affine Constraint Needed for Affine Subspace Clustering?", "comments": "ICCV 2019. Including proofs that are omitted in the conference\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering methods based on expressing each data point as a linear\ncombination of other data points have achieved great success in computer vision\napplications such as motion segmentation, face and digit clustering. In face\nclustering, the subspaces are linear and subspace clustering methods can be\napplied directly. In motion segmentation, the subspaces are affine and an\nadditional affine constraint on the coefficients is often enforced. However,\nsince affine subspaces can always be embedded into linear subspaces of one\nextra dimension, it is unclear if the affine constraint is really necessary.\nThis paper shows, both theoretically and empirically, that when the dimension\nof the ambient space is high relative to the sum of the dimensions of the\naffine subspaces, the affine constraint has a negligible effect on clustering\nperformance. Specifically, our analysis provides conditions that guarantee the\ncorrectness of affine subspace clustering methods both with and without the\naffine constraint, and shows that these conditions are satisfied for\nhigh-dimensional data. Underlying our analysis is the notion of affinely\nindependent subspaces, which not only provides geometrically interpretable\ncorrectness conditions, but also clarifies the relationships between existing\nresults for affine subspace clustering.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 07:52:17 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["You", "Chong", ""], ["Li", "Chun-Guang", ""], ["Robinson", "Daniel P.", ""], ["Vidal", "Rene", ""]]}, {"id": "2005.03899", "submitter": "Stefan Radev T.", "authors": "Stefan T. Radev, Andreas Voss, Eva Marie Wieschen, Paul-Christian\n  B\\\"urkner", "title": "Amortized Bayesian Inference for Models of Cognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As models of cognition grow in complexity and number of parameters, Bayesian\ninference with standard methods can become intractable, especially when the\ndata-generating model is of unknown analytic form. Recent advances in\nsimulation-based inference using specialized neural network architectures\ncircumvent many previous problems of approximate Bayesian computation.\nMoreover, due to the properties of these special neural network estimators, the\neffort of training the networks via simulations amortizes over subsequent\nevaluations which can re-use the same network for multiple datasets and across\nmultiple researchers. However, these methods have been largely underutilized in\ncognitive science and psychology so far, even though they are well suited for\ntackling a wide variety of modeling problems. With this work, we provide a\ngeneral introduction to amortized Bayesian parameter estimation and model\ncomparison and demonstrate the applicability of the proposed methods on a\nwell-known class of intractable response-time models.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:12:15 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 10:33:49 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 05:55:02 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Radev", "Stefan T.", ""], ["Voss", "Andreas", ""], ["Wieschen", "Eva Marie", ""], ["B\u00fcrkner", "Paul-Christian", ""]]}, {"id": "2005.03912", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, Debesh Jha, Hugo Lewi Hammer, H{\\aa}vard D.\n  Johansen, Dag Johansen, P{\\aa}l Halvorsen, Michael A. Riegler", "title": "An Extensive Study on Cross-Dataset Bias and Evaluation Metrics\n  Interpretation for Machine Learning applied to Gastrointestinal Tract\n  Abnormality Classification", "comments": "30 pages, 12 figures, 8 tables, Accepted for ACM Transactions on\n  Computing for Healthcare", "journal-ref": null, "doi": "10.1145/3386295", "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise and efficient automated identification of Gastrointestinal (GI) tract\ndiseases can help doctors treat more patients and improve the rate of disease\ndetection and identification. Currently, automatic analysis of diseases in the\nGI tract is a hot topic in both computer science and medical-related journals.\nNevertheless, the evaluation of such an automatic analysis is often incomplete\nor simply wrong. Algorithms are often only tested on small and biased datasets,\nand cross-dataset evaluations are rarely performed. A clear understanding of\nevaluation metrics and machine learning models with cross datasets is crucial\nto bring research in the field to a new quality level. Towards this goal, we\npresent comprehensive evaluations of five distinct machine learning models\nusing Global Features and Deep Neural Networks that can classify 16 different\nkey types of GI tract conditions, including pathological findings, anatomical\nlandmarks, polyp removal conditions, and normal findings from images captured\nby common GI tract examination instruments. In our evaluation, we introduce\nperformance hexagons using six performance metrics such as recall, precision,\nspecificity, accuracy, F1-score, and Matthews Correlation Coefficient to\ndemonstrate how to determine the real capabilities of models rather than\nevaluating them shallowly. Furthermore, we perform cross-dataset evaluations\nusing different datasets for training and testing. With these cross-dataset\nevaluations, we demonstrate the challenge of actually building a generalizable\nmodel that could be used across different hospitals. Our experiments clearly\nshow that more sophisticated performance metrics and evaluation methods need to\nbe applied to get reliable models rather than depending on evaluations of the\nsplits of the same dataset, i.e., the performance metrics should always be\ninterpreted together rather than relying on a single metric.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:59:31 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Thambawita", "Vajira", ""], ["Jha", "Debesh", ""], ["Hammer", "Hugo Lewi", ""], ["Johansen", "H\u00e5vard D.", ""], ["Johansen", "Dag", ""], ["Halvorsen", "P\u00e5l", ""], ["Riegler", "Michael A.", ""]]}, {"id": "2005.03952", "submitter": "Chris Oates", "authors": "Marina Riabiz, Wilson Chen, Jon Cockayne, Pawel Swietach, Steven A.\n  Niederer, Lester Mackey, Chris. J. Oates", "title": "Optimal Thinning of MCMC Output", "comments": "To appear in the Journal of the Royal Statistical Society, Series B,\n  2021+", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of heuristics to assess the convergence and compress the output of\nMarkov chain Monte Carlo can be sub-optimal in terms of the empirical\napproximations that are produced. Typically a number of the initial states are\nattributed to \"burn in\" and removed, whilst the remainder of the chain is\n\"thinned\" if compression is also required. In this paper we consider the\nproblem of retrospectively selecting a subset of states, of fixed cardinality,\nfrom the sample path such that the approximation provided by their empirical\ndistribution is close to optimal. A novel method is proposed, based on greedy\nminimisation of a kernel Stein discrepancy, that is suitable for problems where\nheavy compression is required. Theoretical results guarantee consistency of the\nmethod and its effectiveness is demonstrated in the challenging context of\nparameter inference for ordinary differential equations. Software is available\nin the Stein Thinning package in Python, R and MATLAB.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 10:54:25 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:48:04 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 14:58:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Riabiz", "Marina", ""], ["Chen", "Wilson", ""], ["Cockayne", "Jon", ""], ["Swietach", "Pawel", ""], ["Niederer", "Steven A.", ""], ["Mackey", "Lester", ""], ["Oates", "Chris. J.", ""]]}, {"id": "2005.03961", "submitter": "Ramin Hasibi", "authors": "Ramin Hasibi, Tom Michoel", "title": "A Graph Feature Auto-Encoder for the Prediction of Unobserved Node\n  Features on Biological Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Molecular interaction networks summarize complex biological\nprocesses as graphs, whose structure is informative of biological function at\nmultiple scales. Simultaneously, omics technologies measure the variation or\nactivity of genes, proteins, or metabolites across individuals or experimental\nconditions. Integrating the complementary viewpoints of biological networks and\nomics data is an important task in bioinformatics, but existing methods treat\nnetworks as discrete structures, which are intrinsically difficult to integrate\nwith continuous node features or activity measures. Graph neural networks map\ngraph nodes into a low-dimensional vector space representation, and can be\ntrained to preserve both the local graph structure and the similarity between\nnode features.\n  Results: We studied the representation of transcriptional, protein-protein\nand genetic interaction networks in E. Coli and mouse using graph neural\nnetworks. We found that such representations explain a large proportion of\nvariation in gene expression data, and that using gene expression data as node\nfeatures improves the reconstruction of the graph from the embedding. We\nfurther proposed a new end-to-end graph feature auto-encoder which is trained\non the feature reconstruction task, and showed that it performs better at\npredicting unobserved node features than auto-encoders that are trained on the\ngraph reconstruction task before learning to predict node features. When\napplied to the problem of imputing missing data in single-cell RNAseq data, our\ngraph feature auto-encoder outperformed a state-of-the-art imputation method\nthat does not use protein interaction information, showing the benefit of\nintegrating biological networks and omics data using graph representation\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 11:23:04 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 09:18:25 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Hasibi", "Ramin", ""], ["Michoel", "Tom", ""]]}, {"id": "2005.03991", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Mahdi Soltanolkotabi", "title": "Compressive sensing with un-trained neural networks: Gradient descent\n  finds the smoothest approximation", "comments": "arXiv admin note: text overlap with arXiv:1910.14634", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Un-trained convolutional neural networks have emerged as highly successful\ntools for image recovery and restoration. They are capable of solving standard\ninverse problems such as denoising and compressive sensing with excellent\nresults by simply fitting a neural network model to measurements from a single\nimage or signal without the need for any additional training data. For some\napplications, this critically requires additional regularization in the form of\nearly stopping the optimization. For signal recovery from a few measurements,\nhowever, un-trained convolutional networks have an intriguing self-regularizing\nproperty: Even though the network can perfectly fit any image, the network\nrecovers a natural image from few measurements when trained with gradient\ndescent until convergence. In this paper, we provide numerical evidence for\nthis property and study it theoretically. We show that---without any further\nregularization---an un-trained convolutional neural network can approximately\nreconstruct signals and images that are sufficiently structured, from a near\nminimal number of random measurements.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:57:25 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Heckel", "Reinhard", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2005.03993", "submitter": "Karthik Gopalakrishnan", "authors": "Karthik Gopalakrishnan, Fathi M.Salem", "title": "Sentiment Analysis Using Simplified Long Short-term Memory Recurrent\n  Neural Networks", "comments": "6 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTM or Long Short Term Memory Networks is a specific type of Recurrent\nNeural Network (RNN) that is very effective in dealing with long sequence data\nand learning long term dependencies. In this work, we perform sentiment\nanalysis on a GOP Debate Twitter dataset. To speed up training and reduce the\ncomputational cost and time, six different parameter reduced slim versions of\nthe LSTM model (slim LSTM) are proposed. We evaluate two of these models on the\ndataset. The performance of these two LSTM models along with the standard LSTM\nmodel is compared. The effect of Bidirectional LSTM Layers is also studied. The\nwork also consists of a study to choose the best architecture, apart from\nestablishing the best set of hyper parameters for different LSTM Models.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 12:50:10 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Gopalakrishnan", "Karthik", ""], ["Salem", "Fathi M.", ""]]}, {"id": "2005.04010", "submitter": "Mirrelijn Van Nee", "authors": "Mirrelijn M. van Nee, Lodewyk F.A. Wessels and Mark A. van de Wiel", "title": "Flexible co-data learning for high-dimensional prediction", "comments": "Document consists of main content (20 pages, 10 figures) and\n  supplementary material (14 pages, 13 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical research often focuses on complex traits in which many variables\nplay a role in mechanisms driving, or curing, diseases. Clinical prediction is\nhard when data is high-dimensional, but additional information, like domain\nknowledge and previously published studies, may be helpful to improve\npredictions. Such complementary data, or co-data, provide information on the\ncovariates, such as genomic location or p-values from external studies. Our\nmethod enables exploiting multiple and various co-data sources to improve\npredictions. We use discrete or continuous co-data to define possibly\noverlapping or hierarchically structured groups of covariates. These are then\nused to estimate adaptive multi-group ridge penalties for generalised linear\nand Cox models. We combine empirical Bayes estimation of group penalty\nhyperparameters with an extra level of shrinkage. This renders a uniquely\nflexible framework as any type of shrinkage can be used on the group level. The\nhyperparameter shrinkage learns how relevant a specific co-data source is,\ncounters overfitting of hyperparameters for many groups, and accounts for\nstructured co-data. We describe various types of co-data and propose suitable\nforms of hypershrinkage. The method is very versatile, as it allows for\nintegration and weighting of multiple co-data sets, inclusion of unpenalised\ncovariates and posterior variable selection. We demonstrate it on two cancer\ngenomics applications and show that it may improve the performance of other\ndense and parsimonious prognostic models substantially, and stabilises variable\nselection.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:04:31 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["van Nee", "Mirrelijn M.", ""], ["Wessels", "Lodewyk F. A.", ""], ["van de Wiel", "Mark A.", ""]]}, {"id": "2005.04035", "submitter": "Siu Lun Chau", "authors": "Siu Lun Chau and Mihai Cucuringu and Dino Sejdinovic", "title": "Spectral Ranking with Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider approaches to the classical problem of establishing a statistical\nranking on a given set of items from incomplete and noisy pairwise comparisons,\nand propose spectral algorithms able to leverage available covariate\ninformation about the items. We give a comprehensive study of several ways such\nside information can be useful in spectral ranking. We establish connections of\nthe resulting algorithms to reproducing kernel Hilbert spaces and associated\ndependence measures, along with an extension to fair ranking using statistical\nparity. We present an extensive set of numerical experiments showcasing the\ncompetitiveness of the proposed algorithms with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:32:45 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 15:41:17 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Chau", "Siu Lun", ""], ["Cucuringu", "Mihai", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2005.04048", "submitter": "Lars Hertel", "authors": "Lars Hertel, Julian Collado, Peter Sadowski, Jordan Ott, Pierre Baldi", "title": "Sherpa: Robust Hyperparameter Optimization for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sherpa is a hyperparameter optimization library for machine learning models.\nIt is specifically designed for problems with computationally expensive,\niterative function evaluations, such as the hyperparameter tuning of deep\nneural networks. With Sherpa, scientists can quickly optimize hyperparameters\nusing a variety of powerful and interchangeable algorithms. Sherpa can be run\non either a single machine or in parallel on a cluster. Finally, an interactive\ndashboard enables users to view the progress of models as they are trained,\ncancel trials, and explore which hyperparameter combinations are working best.\nSherpa empowers machine learning practitioners by automating the more tedious\naspects of model tuning. Its source code and documentation are available at\nhttps://github.com/sherpa-ai/sherpa.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:52:49 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Hertel", "Lars", ""], ["Collado", "Julian", ""], ["Sadowski", "Peter", ""], ["Ott", "Jordan", ""], ["Baldi", "Pierre", ""]]}, {"id": "2005.04064", "submitter": "Ties Van Rozendaal", "authors": "Ties van Rozendaal, Guillaume Sauti\\`ere, Taco S. Cohen", "title": "Lossy Compression with Distortion Constrained Optimization", "comments": "Accepted as a CVPR 2020 workshop paper: Workshop and Challenge on\n  Learned Image Compression (CLIC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When training end-to-end learned models for lossy compression, one has to\nbalance the rate and distortion losses. This is typically done by manually\nsetting a tradeoff parameter $\\beta$, an approach called $\\beta$-VAE. Using\nthis approach it is difficult to target a specific rate or distortion value,\nbecause the result can be very sensitive to $\\beta$, and the appropriate value\nfor $\\beta$ depends on the model and problem setup. As a result, model\ncomparison requires extensive per-model $\\beta$-tuning, and producing a whole\nrate-distortion curve (by varying $\\beta$) for each model to be compared. We\nargue that the constrained optimization method of Rezende and Viola, 2018 is a\nlot more appropriate for training lossy compression models because it allows us\nto obtain the best possible rate subject to a distortion constraint. This\nenables pointwise model comparisons, by training two models with the same\ndistortion target and comparing their rate. We show that the method does manage\nto satisfy the constraint on a realistic image compression task, outperforms a\nconstrained optimization method based on a hinge-loss, and is more practical to\nuse for model selection than a $\\beta$-VAE.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:27:01 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["van Rozendaal", "Ties", ""], ["Sauti\u00e8re", "Guillaume", ""], ["Cohen", "Taco S.", ""]]}, {"id": "2005.04073", "submitter": "Ziyuan Zhao", "authors": "Kaixin Xu, Ziyuan Zhao, Jiapan Gu, Zeng Zeng, Chan Wan Ying, Lim Kheng\n  Choon, Thng Choon Hua, Pierce KH Chow", "title": "Multi-Instance Multi-Label Learning for Gene Mutation Prediction in\n  Hepatocellular Carcinoma", "comments": "Accepted version to be published in the 42nd IEEE Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society, EMBC 2020, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene mutation prediction in hepatocellular carcinoma (HCC) is of great\ndiagnostic and prognostic value for personalized treatments and precision\nmedicine. In this paper, we tackle this problem with multi-instance multi-label\nlearning to address the difficulties on label correlations, label\nrepresentations, etc. Furthermore, an effective oversampling strategy is\napplied for data imbalance. Experimental results have shown the superiority of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:47:25 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Xu", "Kaixin", ""], ["Zhao", "Ziyuan", ""], ["Gu", "Jiapan", ""], ["Zeng", "Zeng", ""], ["Ying", "Chan Wan", ""], ["Choon", "Lim Kheng", ""], ["Hua", "Thng Choon", ""], ["Chow", "Pierce KH", ""]]}, {"id": "2005.04074", "submitter": "Moein Khajehnejad", "authors": "Moein Khajehnejad, Ahmad Asgharian Rezaei, Mahmoudreza Babaei, Jessica\n  Hoffmann, Mahdi Jalili and Adrian Weller", "title": "Adversarial Graph Embeddings for Fair Influence Maximization over Social\n  Networks", "comments": "In Proc. of the 29th International Joint Conference on Artificial\n  Intelligence (IJCAI'20), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization is a widely studied topic in network science, where\nthe aim is to reach the maximum possible number of nodes, while only targeting\na small initial set of individuals. It has critical applications in many\nfields, including viral marketing, information propagation, news dissemination,\nand vaccinations. However, the objective does not usually take into account\nwhether the final set of influenced nodes is fair with respect to sensitive\nattributes, such as race or gender. Here we address fair influence\nmaximization, aiming to reach minorities more equitably. We introduce\nAdversarial Graph Embeddings: we co-train an auto-encoder for graph embedding\nand a discriminator to discern sensitive attributes. This leads to embeddings\nwhich are similarly distributed across sensitive attributes. We then find a\ngood initial set by clustering the embeddings. We believe we are the first to\nuse embeddings for the task of fair influence maximization. While there are\ntypically trade-offs between fairness and influence maximization objectives,\nour experiments on synthetic and real-world datasets show that our approach\ndramatically reduces disparity while remaining competitive with\nstate-of-the-art influence maximization methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:50:12 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 01:01:31 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Khajehnejad", "Moein", ""], ["Rezaei", "Ahmad Asgharian", ""], ["Babaei", "Mahmoudreza", ""], ["Hoffmann", "Jessica", ""], ["Jalili", "Mahdi", ""], ["Weller", "Adrian", ""]]}, {"id": "2005.04081", "submitter": "Yifan Qian", "authors": "Yifan Qian, Paul Expert, Pietro Panzarasa, Mauricio Barahona", "title": "Geometric graphs from data to aid classification tasks with graph\n  convolutional networks", "comments": "Published in Patterns; Date of Publication: 09 April 2021", "journal-ref": "Patterns 2.4 (2021): 100237", "doi": "10.1016/j.patter.2021.100237", "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional classification tasks learn to assign samples to given classes\nbased solely on sample features. This paradigm is evolving to include other\nsources of information, such as known relations between samples. Here we show\nthat, even if additional relational information is not available in the data\nset, one can improve classification by constructing geometric graphs from the\nfeatures themselves, and using them within a Graph Convolutional Network. The\nimprovement in classification accuracy is maximized by graphs that capture\nsample similarity with relatively low edge density. We show that such\nfeature-derived graphs increase the alignment of the data to the ground truth\nwhile improving class separation. We also demonstrate that the graphs can be\nmade more efficient using spectral sparsification, which reduces the number of\nedges while still improving classification performance. We illustrate our\nfindings using synthetic and real-world data sets from various scientific\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:00:45 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 11:28:06 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 18:34:23 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Qian", "Yifan", ""], ["Expert", "Paul", ""], ["Panzarasa", "Pietro", ""], ["Barahona", "Mauricio", ""]]}, {"id": "2005.04088", "submitter": "Xinshun Liu", "authors": "Liu Xinshun, He Xin, Mao Hui, Liu Jing, Lai Weizhong, Ye Qingwen", "title": "Automatic Cross-Domain Transfer Learning for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning research attempts to make model induction transferable\nacross different domains. This method assumes that specific information\nregarding to which domain each instance belongs is known. This paper helps to\nextend the capability of transfer learning for linear regression problems to\nsituations where the domain information is uncertain or unknown; in fact, the\nframework can be extended to classification problems. For normal datasets, we\nassume that some latent domain information is available for transfer learning.\nThe instances in each domain can be inferred by different parameters. We obtain\nthis domain information from the distribution of the regression coefficients\ncorresponding to the explanatory variable $x$ as well as the response variable\n$y$ based on a Dirichlet process, which is more reasonable. As a result, we\ntransfer not only variable $x$ as usual but also variable $y$, which is\nchallenging since the testing data have no response value. Previous work mainly\novercomes the problem via pseudo-labelling based on transductive learning,\nwhich introduces serious bias. We provide a novel framework for analysing the\nproblem and considering this general situation: the joint distribution of\nvariable $x$ and variable $y$. Furthermore, our method controls the bias well\ncompared with previous work. We perform linear regression on the new feature\nspace that consists of different latent domains and the target domain, which is\nfrom the testing data. The experimental results show that the proposed model\nperforms well on real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:05:37 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Xinshun", "Liu", ""], ["Xin", "He", ""], ["Hui", "Mao", ""], ["Jing", "Liu", ""], ["Weizhong", "Lai", ""], ["Qingwen", "Ye", ""]]}, {"id": "2005.04112", "submitter": "Arun Venkitaraman", "authors": "Rebecka Winqvist, Arun Venkitaraman, Bo Wahlberg", "title": "On Training and Evaluation of Neural Network Approaches for Model\n  Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of this paper is a framework for training and evaluation of\nModel Predictive Control (MPC) implemented using constrained neural networks.\nRecent studies have proposed to use neural networks with differentiable convex\noptimization layers to implement model predictive controllers. The motivation\nis to replace real-time optimization in safety critical feedback control\nsystems with learnt mappings in the form of neural networks with optimization\nlayers. Such mappings take as the input the state vector and predict the\ncontrol law as the output. The learning takes place using training data\ngenerated from off-line MPC simulations. However, a general framework for\ncharacterization of learning approaches in terms of both model validation and\nefficient training data generation is lacking in literature. In this paper, we\ntake the first steps towards developing such a coherent framework. We discuss\nhow the learning problem has similarities with system identification, in\nparticular input design, model structure selection and model validation. We\nconsider the study of neural network architectures in PyTorch with the explicit\nMPC constraints implemented as a differentiable optimization layer using CVXPY.\nWe propose an efficient approach of generating MPC input samples subject to the\nMPC model constraints using a hit-and-run sampler. The corresponding true\noutputs are generated by solving the MPC offline using OSOP. We propose\ndifferent metrics to validate the resulting approaches. Our study further aims\nto explore the advantages of incorporating domain knowledge into the network\nstructure from a training and evaluation perspective. Different model\nstructures are numerically tested using the proposed framework in order to\nobtain more insights in the properties of constrained neural networks based\nMPC.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:37:55 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Winqvist", "Rebecka", ""], ["Venkitaraman", "Arun", ""], ["Wahlberg", "Bo", ""]]}, {"id": "2005.04139", "submitter": "Nanwei Wang", "authors": "Nanwei Wang, Laurent Briollais, Helene Massam", "title": "The scalable Birth-Death MCMC Algorithm for Mixed Graphical Model\n  Learning with Application to Genomic Data Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in biological research have seen the emergence of\nhigh-throughput technologies with numerous applications that allow the study of\nbiological mechanisms at an unprecedented depth and scale. A large amount of\ngenomic data is now distributed through consortia like The Cancer Genome Atlas\n(TCGA), where specific types of biological information on specific type of\ntissue or cell are available. In cancer research, the challenge is now to\nperform integrative analyses of high-dimensional multi-omic data with the goal\nto better understand genomic processes that correlate with cancer outcomes,\ne.g. elucidate gene networks that discriminate a specific cancer subgroups\n(cancer sub-typing) or discovering gene networks that overlap across different\ncancer types (pan-cancer studies). In this paper, we propose a novel mixed\ngraphical model approach to analyze multi-omic data of different types\n(continuous, discrete and count) and perform model selection by extending the\nBirth-Death MCMC (BDMCMC) algorithm initially proposed by\n\\citet{stephens2000bayesian} and later developed by\n\\cite{mohammadi2015bayesian}. We compare the performance of our method to the\nLASSO method and the standard BDMCMC method using simulations and find that our\nmethod is superior in terms of both computational efficiency and the accuracy\nof the model selection results. Finally, an application to the TCGA breast\ncancer data shows that integrating genomic information at different levels\n(mutation and expression data) leads to better subtyping of breast cancers.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:34:58 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Nanwei", ""], ["Briollais", "Laurent", ""], ["Massam", "Helene", ""]]}, {"id": "2005.04153", "submitter": "Vasco Lopes Ferrinho", "authors": "Vasco Lopes, Paulo Fazendeiro", "title": "A Hybrid Method for Training Convolutional Neural Networks", "comments": "1 figure, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence algorithms have been steadily increasing in\npopularity and usage. Deep Learning, allows neural networks to be trained using\nhuge datasets and also removes the need for human extracted features, as it\nautomates the feature learning process. In the hearth of training deep neural\nnetworks, such as Convolutional Neural Networks, we find backpropagation, that\nby computing the gradient of the loss function with respect to the weights of\nthe network for a given input, it allows the weights of the network to be\nadjusted to better perform in the given task. In this paper, we propose a\nhybrid method that uses both backpropagation and evolutionary strategies to\ntrain Convolutional Neural Networks, where the evolutionary strategies are used\nto help to avoid local minimas and fine-tune the weights, so that the network\nachieves higher accuracy results. We show that the proposed hybrid method is\ncapable of improving upon regular training in the task of image classification\nin CIFAR-10, where a VGG16 model was used and the final test results increased\n0.61%, in average, when compared to using only backpropagation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:52:48 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lopes", "Vasco", ""], ["Fazendeiro", "Paulo", ""]]}, {"id": "2005.04154", "submitter": "Setareh Maghsudi", "authors": "Setareh Maghsudi and Mihaela van der Schaar", "title": "A Non-Stationary Bandit-Learning Approach to Energy-Efficient\n  Femto-Caching with Rateless-Coded Transmission", "comments": null, "journal-ref": null, "doi": "10.1109/TWC.2020.2989179", "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing demand for media streaming together with limited backhaul\ncapacity renders developing efficient file-delivery methods imperative. One\nsuch method is femto-caching, which, despite its great potential, imposes\nseveral challenges such as efficient resource management. We study a resource\nallocation problem for joint caching and transmission in small cell networks,\nwhere the system operates in two consecutive phases: (i) cache placement, and\n(ii) joint file- and transmit power selection followed by broadcasting. We\ndefine the utility of every small base station in terms of the number of\nsuccessful reconstructions per unit of transmission power. We then formulate\nthe problem as to select a file from the cache together with a transmission\npower level for every broadcast round so that the accumulated utility over the\nhorizon is maximized. The former problem boils down to a stochastic knapsack\nproblem, and we cast the latter as a multi-armed bandit problem. We develop a\nsolution to each problem and provide theoretical and numerical evaluations. In\ncontrast to the state-of-the-art research, the proposed approach is especially\nsuitable for networks with time-variant statistical properties. Moreover, it is\napplicable and operates well even when no initial information about the\nstatistical characteristics of the random parameters such as file popularity\nand channel quality is available.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:07:17 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Maghsudi", "Setareh", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2005.04155", "submitter": "Amir Mosavi Prof", "authors": "Saeed Nosratabadi, Felde Imre, Karoly Szell, Sina Ardabili, Bertalan\n  Beszedes, Amir Mosavi", "title": "Hybrid Machine Learning Models for Crop Yield Prediction", "comments": "5 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction of crop yield is essential for food security policymaking,\nplanning, and trade. The objective of the current study is to propose novel\ncrop yield prediction models based on hybrid machine learning methods. In this\nstudy, the performance of the artificial neural networks-imperialist\ncompetitive algorithm (ANN-ICA) and artificial neural networks-gray wolf\noptimizer (ANN-GWO) models for the crop yield prediction are evaluated.\nAccording to the results, ANN-GWO, with R of 0.48, RMSE of 3.19, and MEA of\n26.65, proved a better performance in the crop yield prediction compared to the\nANN-ICA model. The results can be used by either practitioners, researchers or\npolicymakers for food security.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 12:01:27 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Nosratabadi", "Saeed", ""], ["Imre", "Felde", ""], ["Szell", "Karoly", ""], ["Ardabili", "Sina", ""], ["Beszedes", "Bertalan", ""], ["Mosavi", "Amir", ""]]}, {"id": "2005.04156", "submitter": "Daniel Leite", "authors": "Leticia Decker, Daniel Leite, Fabio Viola, Daniele Bonacorsi", "title": "Comparison of Evolving Granular Classifiers applied to Anomaly Detection\n  for Predictive Maintenance in Computing Centers", "comments": "8 pages, 8 figures, IEEE Conference on Evolving and Adaptive\n  Intelligent Systems (EAIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-based predictive maintenance of computing centers is a main concern\nregarding the worldwide computing grid that supports the CERN (European\nOrganization for Nuclear Research) physics experiments. A log, as\nevent-oriented adhoc information, is quite often given as unstructured big\ndata. Log data processing is a time-consuming computational task. The goal is\nto grab essential information from a continuously changeable grid environment\nto construct a classification model. Evolving granular classifiers are suited\nto learn from time-varying log streams and, therefore, perform online\nclassification of the severity of anomalies. We formulated a 4-class online\nanomaly classification problem, and employed time windows between landmarks and\ntwo granular computing methods, namely, Fuzzy-set-Based evolving Modeling\n(FBeM) and evolving Granular Neural Network (eGNN), to model and monitor\nlogging activity rate. The results of classification are of utmost importance\nfor predictive maintenance because priority can be given to specific time\nintervals in which the classifier indicates the existence of high or medium\nseverity anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:08:50 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Decker", "Leticia", ""], ["Leite", "Daniel", ""], ["Viola", "Fabio", ""], ["Bonacorsi", "Daniele", ""]]}, {"id": "2005.04165", "submitter": "Nathan Wycoff", "authors": "Nathan Wycoff, Prasanna Balaprakash, Fangfang Xia", "title": "Towards On-Chip Bayesian Neuromorphic Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If edge devices are to be deployed to critical applications where their\ndecisions could have serious financial, political, or public-health\nconsequences, they will need a way to signal when they are not sure how to\nreact to their environment. For instance, a lost delivery drone could make its\nway back to a distribution center or contact the client if it is confused about\nhow exactly to make its delivery, rather than taking the action which is \"most\nlikely\" correct. This issue is compounded for health care or military\napplications. However, the brain-realistic temporal credit assignment problem\nneuromorphic computing algorithms have to solve is difficult. The double role\nweights play in backpropagation-based-learning, dictating how the network\nreacts to both input and feedback, needs to be decoupled. e-prop 1 is a\npromising learning algorithm that tackles this with Broadcast Alignment (a\ntechnique where network weights are replaced with random weights during\nfeedback) and accumulated local information. We investigate under what\nconditions the Bayesian loss term can be expressed in a similar fashion,\nproposing an algorithm that can be computed with only local information as well\nand which is thus no more difficult to implement on hardware. This algorithm is\nexhibited on a store-recall problem, which suggests that it can learn good\nuncertainty on decisions to be made over time.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:45:03 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wycoff", "Nathan", ""], ["Balaprakash", "Prasanna", ""], ["Xia", "Fangfang", ""]]}, {"id": "2005.04168", "submitter": "Maxence Ernoult", "authors": "Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio,\n  Benjamin Scellier", "title": "Equilibrium Propagation with Continual Weight Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a learning algorithm that bridges Machine\nLearning and Neuroscience, by computing gradients closely matching those of\nBackpropagation Through Time (BPTT), but with a learning rule local in space.\nGiven an input $x$ and associated target $y$, EP proceeds in two phases: in the\nfirst phase neurons evolve freely towards a first steady state; in the second\nphase output neurons are nudged towards $y$ until they reach a second steady\nstate. However, in existing implementations of EP, the learning rule is not\nlocal in time: the weight update is performed after the dynamics of the second\nphase have converged and requires information of the first phase that is no\nlonger available physically. In this work, we propose a version of EP named\nContinual Equilibrium Propagation (C-EP) where neuron and synapse dynamics\noccur simultaneously throughout the second phase, so that the weight update\nbecomes local in time. Such a learning rule local both in space and time opens\nthe possibility of an extremely energy efficient hardware implementation of EP.\nWe prove theoretically that, provided the learning rates are sufficiently\nsmall, at each time step of the second phase the dynamics of neurons and\nsynapses follow the gradients of the loss given by BPTT (Theorem 1). We\ndemonstrate training with C-EP on MNIST and generalize C-EP to neural networks\nwhere neurons are connected by asymmetric connections. We show through\nexperiments that the more the network updates follows the gradients of BPTT,\nthe best it performs in terms of training. These results bring EP a step closer\nto biology by better complying with hardware constraints while maintaining its\nintimate link with backpropagation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:54:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ernoult", "Maxence", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "2005.04169", "submitter": "Maxence Ernoult", "authors": "Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio,\n  Benjamin Scellier", "title": "Continual Weight Updates and Convolutional Architectures for Equilibrium\n  Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a biologically inspired alternative algorithm\nto backpropagation (BP) for training neural networks. It applies to RNNs fed by\na static input x that settle to a steady state, such as Hopfield networks. EP\nis similar to BP in that in the second phase of training, an error signal\npropagates backwards in the layers of the network, but contrary to BP, the\nlearning rule of EP is spatially local. Nonetheless, EP suffers from two major\nlimitations. On the one hand, due to its formulation in terms of real-time\ndynamics, EP entails long simulation times, which limits its applicability to\npractical tasks. On the other hand, the biological plausibility of EP is\nlimited by the fact that its learning rule is not local in time: the synapse\nupdate is performed after the dynamics of the second phase have converged and\nrequires information of the first phase that is no longer available physically.\nOur work addresses these two issues and aims at widening the spectrum of EP\nfrom standard machine learning models to more bio-realistic neural networks.\nFirst, we propose a discrete-time formulation of EP which enables to simplify\nequations, speed up training and extend EP to CNNs. Our CNN model achieves the\nbest performance ever reported on MNIST with EP. Using the same discrete-time\nformulation, we introduce Continual Equilibrium Propagation (C-EP): the weights\nof the network are adjusted continually in the second phase of training using\nlocal information in space and time. We show that in the limit of slow changes\nof synaptic strengths and small nudging, C-EP is equivalent to BPTT (Theorem\n1). We numerically demonstrate Theorem 1 and C-EP training on MNIST and\ngeneralize it to the bio-realistic situation of a neural network with\nasymmetric connections between neurons.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:14:06 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ernoult", "Maxence", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "2005.04170", "submitter": "James Smith", "authors": "James E. Smith", "title": "A Neuromorphic Paradigm for Online Unsupervised Clustering", "comments": "Submitted to 53rd IEEE/ACM International Symposium on\n  Microarchitecture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational paradigm based on neuroscientific concepts is proposed and\nshown to be capable of online unsupervised clustering. Because it is an online\nmethod, it is readily amenable to streaming realtime applications and is\ncapable of dynamically adjusting to macro-level input changes. All operations,\nboth training and inference, are localized and efficient. The paradigm is\nimplemented as a cognitive column that incorporates five key elements: 1)\ntemporal coding, 2) an excitatory neuron model for inference, 3)\nwinner-take-all inhibition, 4) a column architecture that combines excitation\nand inhibition, 5) localized training via spike timing de-pendent plasticity\n(STDP). These elements are described and discussed, and a prototype column is\ngiven. The prototype column is simulated with a semi-synthetic benchmark and is\nshown to have performance characteristics on par with classic k-means.\nSimulations reveal the inner operation and capabilities of the column with\nemphasis on excitatory neuron response functions and STDP implementations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:02:34 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Smith", "James E.", ""]]}, {"id": "2005.04176", "submitter": "Caroline Wang", "authors": "Caroline Wang, Bin Han, Bhrij Patel, Feroze Mohideen, Cynthia Rudin", "title": "In Pursuit of Interpretable, Fair and Accurate Machine Learning for\n  Criminal Recidivism Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, academics and investigative journalists have criticized\ncertain commercial risk assessments for their black-box nature and failure to\nsatisfy competing notions of fairness. Since then, the field of interpretable\nmachine learning has created simple yet effective algorithms, while the field\nof fair machine learning has proposed various mathematical definitions of\nfairness. However, studies from these fields are largely independent, despite\nthe fact that many applications of machine learning to social issues require\nboth fairness and interpretability. We explore the intersection by revisiting\nthe recidivism prediction problem using state-of-the-art tools from\ninterpretable machine learning, and assessing the models for performance,\ninterpretability, and fairness. Unlike previous works, we compare against two\nexisting risk assessments (COMPAS and the Arnold Public Safety Assessment) and\ntrain models that output probabilities rather than binary predictions. We\npresent multiple models that beat these risk assessments in performance, and\nprovide a fairness analysis of these models. Our results imply that machine\nlearning models should be trained separately for separate locations, and\nupdated over time.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:16:31 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Caroline", ""], ["Han", "Bin", ""], ["Patel", "Bhrij", ""], ["Mohideen", "Feroze", ""], ["Rudin", "Cynthia", ""]]}, {"id": "2005.04210", "submitter": "Y Cooper", "authors": "Y. Cooper", "title": "The critical locus of overparameterized neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many aspects of the geometry of loss functions in deep learning remain\nmysterious. In this paper, we work toward a better understanding of the\ngeometry of the loss function $L$ of overparameterized feedforward neural\nnetworks. In this setting, we identify several components of the critical locus\nof $L$ and study their geometric properties. For networks of depth $\\ell \\geq\n4$, we identify a locus of critical points we call the star locus $S$. Within\n$S$ we identify a positive-dimensional sublocus $C$ with the property that for\n$p \\in C$, $p$ is a degenerate critical point, and no existing theoretical\nresult guarantees that gradient descent will not converge to $p$. For very wide\nnetworks, we build on earlier work and show that all critical points of $L$ are\ndegenerate, and give lower bounds on the number of zero eigenvalues of the\nHessian at each critical point. For networks that are both deep and very wide,\nwe compare the growth rates of the zero eigenspaces of the Hessian at all the\ndifferent families of critical points that we identify. The results in this\npaper provide a starting point to a more quantitative understanding of the\nproperties of various components of the critical locus of $L$.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:59:17 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 01:07:12 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cooper", "Y.", ""]]}, {"id": "2005.04211", "submitter": "Anirbit Mukherjee", "authors": "Sayar Karmakar and Anirbit Mukherjee", "title": "A Study of Neural Training with Iterative Non-Gradient Methods", "comments": "34 pages. In version 4, we have given experimental demonstration of\n  the 2 main neural training algorithms presented in this paper in sections 3\n  and 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we demonstrate provable guarantees on the training of depth-$2$\nneural networks in new regimes than previously explored. (1) First we give a\nsimple stochastic algorithm that can train a $\\rm ReLU$ gate in the realizable\nsetting in linear time while using significantly milder conditions on the data\ndistribution than previous results. Leveraging some additional distributional\nassumptions we also show approximate recovery of the true label generating\nparameters when training a $\\rm ReLU$ gate while a probabilistic adversary is\nallowed to corrupt the true labels of the training data. Our guarantee on\nrecovering the true weight degrades gracefully with increasing probability of\nattack and it's nearly optimal in the worst case. Additionally, our analysis\nallows for mini-batching and computes how the convergence time scales with the\nmini-batch size. (2) Secondly, we focus on the question of provable\ninterpolation of arbitrary data by finitely large neural nets. We exhibit a\nnon-gradient iterative algorithm \"${\\rm Neuro{-}Tron}$\" which gives a\nfirst-of-its-kind poly-time approximate solving of a neural regression (here in\nthe $\\ell_\\infty$-norm) problem at finite net widths and for non-realizable\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:59:23 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 05:57:31 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 18:51:02 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 04:31:52 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Karmakar", "Sayar", ""], ["Mukherjee", "Anirbit", ""]]}, {"id": "2005.04232", "submitter": "Keyon Vafa", "authors": "Keyon Vafa, Suresh Naidu, David M. Blei", "title": "Text-Based Ideal Points", "comments": "Appeared in Proceedings of the 2020 Conference of the Association for\n  Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideal point models analyze lawmakers' votes to quantify their political\npositions, or ideal points. But votes are not the only way to express a\npolitical position. Lawmakers also give speeches, release press statements, and\npost tweets. In this paper, we introduce the text-based ideal point model\n(TBIP), an unsupervised probabilistic topic model that analyzes texts to\nquantify the political positions of its authors. We demonstrate the TBIP with\ntwo types of politicized text data: U.S. Senate speeches and senator tweets.\nThough the model does not analyze their votes or political affiliations, the\nTBIP separates lawmakers by party, learns interpretable politicized topics, and\ninfers ideal points close to the classical vote-based ideal points. One benefit\nof analyzing texts, as opposed to votes, is that the TBIP can estimate ideal\npoints of anyone who authors political texts, including non-voting actors. To\nthis end, we use it to study tweets from the 2020 Democratic presidential\ncandidates. Using only the texts of their tweets, it identifies them along an\ninterpretable progressive-to-moderate spectrum.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 21:16:42 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 00:16:52 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Vafa", "Keyon", ""], ["Naidu", "Suresh", ""], ["Blei", "David M.", ""]]}, {"id": "2005.04259", "submitter": "Jiyang Gao", "authors": "Jiyang Gao, Chen Sun, Hang Zhao, Yi Shen, Dragomir Anguelov, Congcong\n  Li, Cordelia Schmid", "title": "VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized\n  Representation", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior prediction in dynamic, multi-agent systems is an important problem\nin the context of self-driving cars, due to the complex representations and\ninteractions of road components, including moving agents (e.g. pedestrians and\nvehicles) and road context information (e.g. lanes, traffic lights). This paper\nintroduces VectorNet, a hierarchical graph neural network that first exploits\nthe spatial locality of individual road components represented by vectors and\nthen models the high-order interactions among all components. In contrast to\nmost recent approaches, which render trajectories of moving agents and road\ncontext information as bird-eye images and encode them with convolutional\nneural networks (ConvNets), our approach operates on a vector representation.\nBy operating on the vectorized high definition (HD) maps and agent\ntrajectories, we avoid lossy rendering and computationally intensive ConvNet\nencoding steps. To further boost VectorNet's capability in learning context\nfeatures, we propose a novel auxiliary task to recover the randomly masked out\nmap entities and agent trajectories based on their context. We evaluate\nVectorNet on our in-house behavior prediction benchmark and the recently\nreleased Argoverse forecasting dataset. Our method achieves on par or better\nperformance than the competitive rendering approach on both benchmarks while\nsaving over 70% of the model parameters with an order of magnitude reduction in\nFLOPs. It also outperforms the state of the art on the Argoverse dataset.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 19:07:03 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gao", "Jiyang", ""], ["Sun", "Chen", ""], ["Zhao", "Hang", ""], ["Shen", "Yi", ""], ["Anguelov", "Dragomir", ""], ["Li", "Congcong", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2005.04269", "submitter": "Pavel Shvechikov", "authors": "Arsenii Kuznetsov, Pavel Shvechikov, Alexander Grishin, Dmitry Vetrov", "title": "Controlling Overestimation Bias with Truncated Mixture of Continuous\n  Distributional Quantile Critics", "comments": "Under review by the International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overestimation bias is one of the major impediments to accurate\noff-policy learning. This paper investigates a novel way to alleviate the\noverestimation bias in a continuous control setting. Our method---Truncated\nQuantile Critics, TQC,---blends three ideas: distributional representation of a\ncritic, truncation of critics prediction, and ensembling of multiple critics.\nDistributional representation and truncation allow for arbitrary granular\noverestimation control, while ensembling provides additional score\nimprovements. TQC outperforms the current state of the art on all environments\nfrom the continuous control benchmark suite, demonstrating 25% improvement on\nthe most challenging Humanoid environment.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 19:52:26 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kuznetsov", "Arsenii", ""], ["Shvechikov", "Pavel", ""], ["Grishin", "Alexander", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2005.04272", "submitter": "Liang Tong", "authors": "Liang Tong, Minzhe Guo, Atul Prakash, Yevgeniy Vorobeychik", "title": "Towards Robustness against Unsuspicious Adversarial Examples", "comments": "v2.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable success of deep neural networks, significant concerns\nhave emerged about their robustness to adversarial perturbations to inputs.\nWhile most attacks aim to ensure that these are imperceptible, physical\nperturbation attacks typically aim for being unsuspicious, even if perceptible.\nHowever, there is no universal notion of what it means for adversarial examples\nto be unsuspicious. We propose an approach for modeling suspiciousness by\nleveraging cognitive salience. Specifically, we split an image into foreground\n(salient region) and background (the rest), and allow significantly larger\nadversarial perturbations in the background, while ensuring that cognitive\nsalience of background remains low. We describe how to compute the resulting\nnon-salience-preserving dual-perturbation attacks on classifiers. We then\nexperimentally demonstrate that our attacks indeed do not significantly change\nperceptual salience of the background, but are highly effective against\nclassifiers robust to conventional attacks. Furthermore, we show that\nadversarial training with dual-perturbation attacks yields classifiers that are\nmore robust to these than state-of-the-art robust learning approaches, and\ncomparable in terms of robustness to conventional attacks.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 20:06:47 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:58:09 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Tong", "Liang", ""], ["Guo", "Minzhe", ""], ["Prakash", "Atul", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2005.04275", "submitter": "Jiayi Liu", "authors": "Jiayi Liu, Samarth Tripathi, Unmesh Kurup, Mohak Shah", "title": "Pruning Algorithms to Accelerate Convolutional Neural Networks for Edge\n  Applications: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the general trend of increasing Convolutional Neural Network (CNN) model\nsizes, model compression and acceleration techniques have become critical for\nthe deployment of these models on edge devices. In this paper, we provide a\ncomprehensive survey on Pruning, a major compression strategy that removes\nnon-critical or redundant neurons from a CNN model. The survey covers the\noverarching motivation for pruning, different strategies and criteria, their\nadvantages and drawbacks, along with a compilation of major pruning techniques.\nWe conclude the survey with a discussion on alternatives to pruning and current\nchallenges for the model compression community.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 20:12:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Liu", "Jiayi", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "2005.04286", "submitter": "Liyao Gao Mr.", "authors": "Liyao Gao, Yifan Du, Hongshan Li, Guang Lin", "title": "RotEqNet: Rotation-Equivariant Network for Fluid Systems with Symmetric\n  High-Order Tensors", "comments": "Preprint submitted to Journal of Computational Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG physics.comp-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent application of scientific modeling, machine learning models are\nlargely applied to facilitate computational simulations of fluid systems.\nRotation symmetry is a general property for most symmetric fluid systems.\nHowever, in general, current machine learning methods have no theoretical way\nto guarantee rotational symmetry. By observing an important property of\ncontraction and rotation operation on high-order symmetric tensors, we prove\nthat the rotation operation is preserved via tensor contraction. Based on this\ntheoretical justification, in this paper, we introduce Rotation-Equivariant\nNetwork (RotEqNet) to guarantee the property of rotation-equivariance for\nhigh-order tensors in fluid systems. We implement RotEqNet and evaluate our\nclaims through four case studies on various fluid systems. The property of\nerror reduction and rotation-equivariance is verified in these case studies.\nResults from the comparative study show that our method outperforms\nconventional methods, which rely on data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 22:33:34 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gao", "Liyao", ""], ["Du", "Yifan", ""], ["Li", "Hongshan", ""], ["Lin", "Guang", ""]]}, {"id": "2005.04288", "submitter": "Li Fu", "authors": "Li Fu, Xiaoxiao Li, Libo Zi", "title": "Incremental Learning for End-to-End Automatic Speech Recognition", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new incremental learning for end-to-end Automatic Speech\nRecognition (ASR) to extend the model's capacity on a new task while retaining\nthe performance on previous ones. The proposed method is effective without\naccessing to the old dataset to address the issues of high retraining cost and\nunavailable old dataset. To achieve this, both attention distillation and\nknowledge distillation are applied to preserve the ability of the old model\nduring the progressive learning. With an ASR model pre-trained on 12,000h\nMandarin speech, we test our proposed method on 300h new scenario task and 1h\nnew named entities task. Experiments show that our method yields 3.25% and\n0.88% absolute Character Error Rate (CER) reduction on the new scenario, when\ncompared with the pre-trained model and the full-data retraining baseline,\nrespectively. It even yields a surprising 0.37% absolute CER reduction on the\nnew scenario than the fine-tuning. For the new named entities task, our method\nsignificantly improves the accuracy compared with the pre-trained model, i.e.\n16.95% absolute CER reduction. For both of the new task adaptions, the new\nmodels still maintain a same accuracy with the retraining baseline on the old\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 08:18:08 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 03:39:18 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Fu", "Li", ""], ["Li", "Xiaoxiao", ""], ["Zi", "Libo", ""]]}, {"id": "2005.04289", "submitter": "Mario Popolin Neto", "authors": "M\\'ario Popolin Neto and Fernando V. Paulovich", "title": "Explainable Matrix -- Visualization for Global and Local\n  Interpretability of Random Forest Classification Ensembles", "comments": "IEEE VIS VAST 2020", "journal-ref": null, "doi": "10.1109/TVCG.2020.3030354", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the past decades, classification models have proven to be essential\nmachine learning tools given their potential and applicability in various\ndomains. In these years, the north of the majority of the researchers had been\nto improve quantitative metrics, notwithstanding the lack of information about\nmodels' decisions such metrics convey. This paradigm has recently shifted, and\nstrategies beyond tables and numbers to assist in interpreting models'\ndecisions are increasing in importance. Part of this trend, visualization\ntechniques have been extensively used to support classification models'\ninterpretability, with a significant focus on rule-based models. Despite the\nadvances, the existing approaches present limitations in terms of visual\nscalability, and the visualization of large and complex models, such as the\nones produced by the Random Forest (RF) technique, remains a challenge. In this\npaper, we propose Explainable Matrix (ExMatrix), a novel visualization method\nfor RF interpretability that can handle models with massive quantities of\nrules. It employs a simple yet powerful matrix-like visual metaphor, where rows\nare rules, columns are features, and cells are rules predicates, enabling the\nanalysis of entire models and auditing classification results. ExMatrix\napplicability is confirmed via different examples, showing how it can be used\nin practice to promote RF models interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 21:03:48 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 13:55:31 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Neto", "M\u00e1rio Popolin", ""], ["Paulovich", "Fernando V.", ""]]}, {"id": "2005.04301", "submitter": "MingYu Lu", "authors": "MingYu Lu and Zachary Shahn and Daby Sow and Finale Doshi-Velez and\n  Li-wei H. Lehman", "title": "Is Deep Reinforcement Learning Ready for Practical Applications in\n  Healthcare? A Sensitivity Analysis of Duel-DDQN for Hemodynamic Management in\n  Sepsis Patients", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential of Reinforcement Learning (RL) has been demonstrated through\nsuccessful applications to games such as Go and Atari. However, while it is\nstraightforward to evaluate the performance of an RL algorithm in a game\nsetting by simply using it to play the game, evaluation is a major challenge in\nclinical settings where it could be unsafe to follow RL policies in practice.\nThus, understanding sensitivity of RL policies to the host of decisions made\nduring implementation is an important step toward building the type of trust in\nRL required for eventual clinical uptake. In this work, we perform a\nsensitivity analysis on a state-of-the-art RL algorithm (Dueling Double Deep\nQ-Networks)applied to hemodynamic stabilization treatment strategies for septic\npatients in the ICU. We consider sensitivity of learned policies to input\nfeatures, embedding model architecture, time discretization, reward function,\nand random seeds. We find that varying these settings can significantly impact\nlearned policies, which suggests a need for caution when interpreting RL agent\noutput.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 22:08:31 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 14:54:03 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Lu", "MingYu", ""], ["Shahn", "Zachary", ""], ["Sow", "Daby", ""], ["Doshi-Velez", "Finale", ""], ["Lehman", "Li-wei H.", ""]]}, {"id": "2005.04305", "submitter": "Danny Hernandez", "authors": "Danny Hernandez, Tom B. Brown", "title": "Measuring the Algorithmic Efficiency of Neural Networks", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three factors drive the advance of AI: algorithmic innovation, data, and the\namount of compute available for training. Algorithmic progress has\ntraditionally been more difficult to quantify than compute and data. In this\nwork, we argue that algorithmic progress has an aspect that is both\nstraightforward to measure and interesting: reductions over time in the compute\nneeded to reach past capabilities. We show that the number of floating-point\noperations required to train a classifier to AlexNet-level performance on\nImageNet has decreased by a factor of 44x between 2012 and 2019. This\ncorresponds to algorithmic efficiency doubling every 16 months over a period of\n7 years. By contrast, Moore's Law would only have yielded an 11x cost\nimprovement. We observe that hardware and algorithmic efficiency gains multiply\nand can be on a similar scale over meaningful horizons, which suggests that a\ngood model of AI progress should integrate measures from both.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 22:26:37 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Hernandez", "Danny", ""], ["Brown", "Tom B.", ""]]}, {"id": "2005.04310", "submitter": "Sara Abdali", "authors": "Sara Abdali, Neil Shah, Evangelos E. Papalexakis", "title": "Semi-Supervised Multi-aspect Detection of Misinformation using\n  Hierarchical Joint Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinguishing between misinformation and real information is one of the most\nchallenging problems in today's interconnected world. The vast majority of the\nstate-of-the-art in detecting misinformation is fully supervised, requiring a\nlarge number of high-quality human annotations. However, the availability of\nsuch annotations cannot be taken for granted, since it is very costly,\ntime-consuming, and challenging to do so in a way that keeps up with the\nproliferation of misinformation. In this work, we are interested in exploring\nscenarios where the number of annotations is limited. In such scenarios, we\ninvestigate how tapping on a diverse number of resources that characterize a\nnews article, henceforth referred to as \"aspects\" can compensate for the lack\nof labels. In particular, our contributions in this paper are twofold: 1) We\npropose the use of three different aspects: article content, context of social\nsharing behaviors, and host website/domain features, and 2) We introduce a\nprincipled tensor based embedding framework that combines all those aspects\neffectively. We propose HiJoD a 2-level decomposition pipeline which not only\noutperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter\nand Politifact datasets respectively but also is an order of magnitude faster\nthan similar ensemble approaches.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 22:41:39 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 22:30:14 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Abdali", "Sara", ""], ["Shah", "Neil", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2005.04318", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen and James L. McClelland", "title": "Transforming task representations to perform novel tasks", "comments": "45 pages", "journal-ref": "PNAS December 29, 2020 117 (52) 32970-32981;", "doi": "10.1073/pnas.2008852117", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important aspect of intelligence is the ability to adapt to a novel task\nwithout any direct experience (zero-shot), based on its relationship to\nprevious tasks. Humans can exhibit this cognitive flexibility. By contrast,\nmodels that achieve superhuman performance in specific tasks often fail to\nadapt to even slight task alterations. To address this, we propose a general\ncomputational framework for adapting to novel tasks based on their relationship\nto prior tasks. We begin by learning vector representations of tasks. To adapt\nto new tasks, we propose meta-mappings, higher-order tasks that transform basic\ntask representations. We demonstrate the effectiveness of this framework across\na wide variety of tasks and computational paradigms, ranging from regression to\nimage classification and reinforcement learning. We compare to both human\nadaptability and language-based approaches to zero-shot learning. Across these\ndomains, meta-mapping is successful, often achieving 80-90% performance,\nwithout any data, on a novel task, even when the new task directly contradicts\nprior experience. We further show that meta-mapping can not only generalize to\nnew tasks via learned relationships, but can also generalize using novel\nrelationships unseen during training. Finally, using meta-mapping as a starting\npoint can dramatically accelerate later learning on a new task, and reduce\nlearning time and cumulative error substantially. Our results provide insight\ninto a possible computational basis of intelligent adaptability and offer a\npossible framework for modeling cognitive flexibility and building more\nflexible artificial intelligence systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 23:41:57 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 22:26:39 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 18:35:56 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["McClelland", "James L.", ""]]}, {"id": "2005.04320", "submitter": "Paul Kent MSc", "authors": "Paul Kent and Juergen Branke", "title": "BOP-Elites, a Bayesian Optimisation algorithm for Quality-Diversity\n  search", "comments": "Submitted to Parallel Problem Solving from Nature (PPSN) April 22nd -\n  2020 (https://ppsn2020.liacs.leidenuniv.nl/calls/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality Diversity (QD) algorithms such as MAP-Elites are a class of\noptimisation techniques that attempt to find a set of high-performing points\nfrom an objective function while enforcing behavioural diversity of the points\nover one or more interpretable, user chosen, feature functions.\n  In this paper we propose the Bayesian Optimisation of Elites (BOP-Elites)\nalgorithm that uses techniques from Bayesian Optimisation to explicitly model\nboth quality and diversity with Gaussian Processes. By considering user defined\nregions of the feature space as 'niches' our task is to find the optimal\nsolution in each niche. We propose a novel acquisition function to\nintelligently choose new points that provide the highest expected improvement\nto the ensemble problem of identifying the best solution in every niche. In\nthis way each function evaluation enriches our modelling and provides insight\nto the whole problem, naturally balancing exploration and exploitation of the\nsearch space. The resulting algorithm is very effective in identifying the\nparts of the search space that belong to a niche in feature space, and finding\nthe optimal solution in each niche. It is also significantly more sample\nefficient than simpler benchmark approaches. BOP-Elites goes further than\nexisting QD algorithms by quantifying the uncertainty around our predictions\nand offering additional illumination of the search space through surrogate\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 23:49:13 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kent", "Paul", ""], ["Branke", "Juergen", ""]]}, {"id": "2005.04342", "submitter": "Demetrius DiMucci", "authors": "Demetrius DiMucci", "title": "JigSaw: A tool for discovering explanatory high-order interactions from\n  random forests", "comments": "15 pages 5 figures 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is revolutionizing biology by facilitating the prediction of\noutcomes from complex patterns found in massive data sets. Large biological\ndata sets, like those generated by transcriptome or microbiome studies,measure\nmany relevant components that interact in vivo with one another in modular\nways.Identifying the high-order interactions that machine learning models use\nto make predictions would facilitate the development of hypotheses linking\ncombinations of measured components to outcome. By using the structure of\nrandom forests, a new algorithmic approach, termed JigSaw,was developed to aid\nin the discovery of patterns that could explain predictions made by the forest.\nBy examining the patterns of individual decision trees JigSaw identifies\nhigh-order interactions between measured features that are strongly associated\nwith a particular outcome and identifies the relevant decision thresholds.\nJigSaw's effectiveness was tested in simulation studies where it was able to\nrecover multiple ground truth patterns;even in the presence of significant\nnoise. It was then used to find patterns associated with outcomes in two real\nworld data sets.It was first used to identify patterns clinical measurements\nassociated with heart disease. It was then used to find patterns associated\nwith breast cancer using metabolites measured in the blood. In heart disease,\nJigSaw identified several three-way interactions that combine to explain most\nof the heart disease records (66%) with high precision (93%). In breast cancer,\nthree two-way interactions were recovered that can be combined to explain\nalmost all records (92%) with good precision (79%). JigSaw is an efficient\nmethod for exploring high-dimensional feature spaces for rules that explain\nstatistical associations with a given outcome and can inspire the generation of\ntestable hypotheses.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:53:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["DiMucci", "Demetrius", ""]]}, {"id": "2005.04345", "submitter": "Shiori Sagawa", "authors": "Shiori Sagawa, Aditi Raghunathan, Pang Wei Koh, Percy Liang", "title": "An Investigation of Why Overparameterization Exacerbates Spurious\n  Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study why overparameterization -- increasing model size well beyond the\npoint of zero training error -- can hurt test error on minority groups despite\nimproving average test error when there are spurious correlations in the data.\nThrough simulations and experiments on two image datasets, we identify two key\nproperties of the training data that drive this behavior: the proportions of\nmajority versus minority groups, and the signal-to-noise ratio of the spurious\ncorrelations. We then analyze a linear setting and theoretically show how the\ninductive bias of models towards \"memorizing\" fewer examples can cause\noverparameterization to hurt. Our analysis leads to a counterintuitive approach\nof subsampling the majority group, which empirically achieves low minority\nerror in the overparameterized regime, even though the standard approach of\nupweighting the minority fails. Overall, our results suggest a tension between\nusing overparameterized models versus using all the training data for achieving\nlow worst-group error.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:59:13 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 22:56:30 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 19:32:58 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Sagawa", "Shiori", ""], ["Raghunathan", "Aditi", ""], ["Koh", "Pang Wei", ""], ["Liang", "Percy", ""]]}, {"id": "2005.04353", "submitter": "Rong Song", "authors": "Sudi Lyu, Anxiang Zhang, Rong Song", "title": "Dual-track Music Generation using Deep Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music generation is always interesting in a sense that there is no formalized\nrecipe. In this work, we propose a novel dual-track architecture for generating\nclassical piano music, which is able to model the inter-dependency of left-hand\nand right-hand piano music. Particularly, we experimented with a lot of\ndifferent models of neural network as well as different representations of\nmusic, and the results show that our proposed model outperforms all other\ntested methods. Besides, we deployed some special policies for model training\nand generation, which contributed to the model performance remarkably. Finally,\nunder two evaluation methods, we compared our models with the MuseGAN project\nand true music.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 02:34:39 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Lyu", "Sudi", ""], ["Zhang", "Anxiang", ""], ["Song", "Rong", ""]]}, {"id": "2005.04354", "submitter": "Anshoo Tandon", "authors": "Anshoo Tandon and Vincent Y. F. Tan and Shiyao Zhu", "title": "Exact Asymptotics for Learning Tree-Structured Graphical Models with\n  Side Information: Noiseless and Noisy Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given side information that an Ising tree-structured graphical model is\nhomogeneous and has no external field, we derive the exact asymptotics of\nlearning its structure from independently drawn samples. Our results, which\nleverage the use of probabilistic tools from the theory of strong large\ndeviations, refine the large deviation (error exponents) results of Tan,\nAnandkumar, Tong, and Willsky [IEEE Trans. on Inform. Th., 57(3):1714--1735,\n2011] and strictly improve those of Bresler and Karzand [Ann. Statist., 2020].\nIn addition, we extend our results to the scenario in which the samples are\nobserved in random noise. In this case, we show that they strictly improve on\nthe recent results of Nikolakakis, Kalogerias, and Sarwate [Proc. AISTATS,\n1771--1782, 2019]. Our theoretical results demonstrate keen agreement with\nexperimental results for sample sizes as small as that in the hundreds.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 02:42:40 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Tandon", "Anshoo", ""], ["Tan", "Vincent Y. F.", ""], ["Zhu", "Shiyao", ""]]}, {"id": "2005.04366", "submitter": "Miao Yin", "authors": "Miao Yin, Siyu Liao, Xiao-Yang Liu, Xiaodong Wang, Bo Yuan", "title": "Compressing Recurrent Neural Networks Using Hierarchical Tucker Tensor\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been widely used in sequence analysis\nand modeling. However, when processing high-dimensional data, RNNs typically\nrequire very large model sizes, thereby bringing a series of deployment\nchallenges. Although the state-of-the-art tensor decomposition approaches can\nprovide good model compression performance, these existing methods are still\nsuffering some inherent limitations, such as restricted representation\ncapability and insufficient model complexity reduction. To overcome these\nlimitations, in this paper we propose to develop compact RNN models using\nHierarchical Tucker (HT) decomposition. HT decomposition brings strong\nhierarchical structure to the decomposed RNN models, which is very useful and\nimportant for enhancing the representation capability. Meanwhile, HT\ndecomposition provides higher storage and computational cost reduction than the\nexisting tensor decomposition approaches for RNN compression. Our experimental\nresults show that, compared with the state-of-the-art compressed RNN models,\nsuch as TT-LSTM, TR-LSTM and BT-LSTM, our proposed HT-based LSTM (HT-LSTM),\nconsistently achieves simultaneous and significant increases in both\ncompression ratio and test accuracy on different datasets.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:15:20 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Yin", "Miao", ""], ["Liao", "Siyu", ""], ["Liu", "Xiao-Yang", ""], ["Wang", "Xiaodong", ""], ["Yuan", "Bo", ""]]}, {"id": "2005.04372", "submitter": "Sharu Theresa Jose", "authors": "Sharu Theresa Jose, Osvaldo Simeone", "title": "Information-Theoretic Generalization Bounds for Meta-Learning and\n  Applications", "comments": "Accepted to Entropy", "journal-ref": null, "doi": "10.3390/e23010126", "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning, or \"learning to learn\", refers to techniques that infer an\ninductive bias from data corresponding to multiple related tasks with the goal\nof improving the sample efficiency for new, previously unobserved, tasks. A key\nperformance measure for meta-learning is the meta-generalization gap, that is,\nthe difference between the average loss measured on the meta-training data and\non a new, randomly selected task. This paper presents novel\ninformation-theoretic upper bounds on the meta-generalization gap. Two broad\nclasses of meta-learning algorithms are considered that uses either separate\nwithin-task training and test sets, like MAML, or joint within-task training\nand test sets, like Reptile. Extending the existing work for conventional\nlearning, an upper bound on the meta-generalization gap is derived for the\nformer class that depends on the mutual information (MI) between the output of\nthe meta-learning algorithm and its input meta-training data. For the latter,\nthe derived bound includes an additional MI between the output of the per-task\nlearning procedure and corresponding data set to capture within-task\nuncertainty. Tighter bounds are then developed, under given technical\nconditions, for the two classes via novel Individual Task MI (ITMI) bounds.\nApplications of the derived bounds are finally discussed, including a broad\nclass of noisy iterative algorithms for meta-learning.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:48:01 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 16:17:24 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 10:56:09 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 12:00:37 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Jose", "Sharu Theresa", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2005.04383", "submitter": "Esa Ollila", "authors": "Muhammad Naveed Tabassum and Esa Ollila", "title": "A Compressive Classification Framework for High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a compressive classification framework for settings where the data\ndimensionality is significantly higher than the sample size. The proposed\nmethod, referred to as compressive regularized discriminant analysis (CRDA) is\nbased on linear discriminant analysis and has the ability to select significant\nfeatures by using joint-sparsity promoting hard thresholding in the\ndiscriminant rule. Since the number of features is larger than the sample size,\nthe method also uses state-of-the-art regularized sample covariance matrix\nestimators. Several analysis examples on real data sets, including image,\nspeech signal and gene expression data illustrate the promising improvements\noffered by the proposed CRDA classifier in practise. Overall, the proposed\nmethod gives fewer misclassification errors than its competitors, while at the\nsame time achieving accurate feature selection results. The open-source R\npackage and MATLAB toolbox of the proposed method (named compressiveRDA) is\nfreely available.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 06:55:00 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 14:14:02 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Tabassum", "Muhammad Naveed", ""], ["Ollila", "Esa", ""]]}, {"id": "2005.04399", "submitter": "Marco Romanelli", "authors": "Marco Romanelli and Konstantinos Chatzikokolakis and Catuscia\n  Palamidessi and Pablo Piantanida", "title": "Estimating g-Leakage via Machine Learning", "comments": "This is the extended version of the paper which will appear in the\n  Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications\n  Security (CCS '20), November 9-13, 2020, Virtual Event, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimating the information leakage of a\nsystem in the black-box scenario. It is assumed that the system's internals are\nunknown to the learner, or anyway too complicated to analyze, and the only\navailable information are pairs of input-output data samples, possibly obtained\nby submitting queries to the system or provided by a third party. Previous\nresearch has mainly focused on counting the frequencies to estimate the\ninput-output conditional probabilities (referred to as frequentist approach),\nhowever this method is not accurate when the domain of possible outputs is\nlarge. To overcome this difficulty, the estimation of the Bayes error of the\nideal classifier was recently investigated using Machine Learning (ML) models\nand it has been shown to be more accurate thanks to the ability of those models\nto learn the input-output correspondence. However, the Bayes vulnerability is\nonly suitable to describe one-try attacks. A more general and flexible measure\nof leakage is the g-vulnerability, which encompasses several different types of\nadversaries, with different goals and capabilities. In this paper, we propose a\nnovel approach to perform black-box estimation of the g-vulnerability using ML.\nA feature of our approach is that it does not require to estimate the\nconditional probabilities, and that it is suitable for a large class of ML\nalgorithms. First, we formally show the learnability for all data\ndistributions. Then, we evaluate the performance via various experiments using\nk-Nearest Neighbors and Neural Networks. Our results outperform the frequentist\napproach when the observables domain is large.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 09:26:36 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:44:33 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Romanelli", "Marco", ""], ["Chatzikokolakis", "Konstantinos", ""], ["Palamidessi", "Catuscia", ""], ["Piantanida", "Pablo", ""]]}, {"id": "2005.04444", "submitter": "Oleh Lukianykhin", "authors": "Oleh Lukianykhin, Tetiana Bogodorova", "title": "Reinforcement Learning for Thermostatically Controlled Loads Control\n  using Modelica and Python", "comments": "accepted for the Asian Modelica Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the project is to investigate and assess opportunities for\napplying reinforcement learning (RL) for power system control. As a proof of\nconcept (PoC), voltage control of thermostatically controlled loads (TCLs) for\npower consumption regulation was developed using Modelica-based pipeline. The\nQ-learning RL algorithm has been validated for deterministic and stochastic\ninitialization of TCLs. The latter modelling is closer to real grid behaviour,\nwhich challenges the control development, considering the stochastic nature of\nload switching. In addition, the paper shows the influence of Q-learning\nparameters, including discretization of state-action space, on the controller\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 13:35:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Lukianykhin", "Oleh", ""], ["Bogodorova", "Tetiana", ""]]}, {"id": "2005.04454", "submitter": "Hendrik Burwinkel", "authors": "Hendrik Burwinkel, Holger Matz, Stefan Saur, Christoph Hauger, Ayse\n  Mine Evren, Nino Hirnschall, Oliver Findl, Nassir Navab, Seyed-Ahmad Ahmadi", "title": "Domain-specific loss design for unsupervised physical training: A new\n  approach to modeling medical ML solutions", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, cataract surgery is the most frequently performed ophthalmic surgery\nin the world. The cataract, a developing opacity of the human eye lens,\nconstitutes the world's most frequent cause for blindness. During surgery, the\nlens is removed and replaced by an artificial intraocular lens (IOL). To\nprevent patients from needing strong visual aids after surgery, a precise\nprediction of the optical properties of the inserted IOL is crucial. There has\nbeen lots of activity towards developing methods to predict these properties\nfrom biometric eye data obtained by OCT devices, recently also by employing\nmachine learning. They consider either only biometric data or physical models,\nbut rarely both, and often neglect the IOL geometry. In this work, we propose\nOpticNet, a novel optical refraction network, loss function, and training\nscheme which is unsupervised, domain-specific, and physically motivated. We\nderive a precise light propagation eye model using single-ray raytracing and\nformulate a differentiable loss function that back-propagates physical\ngradients into the network. Further, we propose a new transfer learning\nprocedure, which allows unsupervised training on the physical model and\nfine-tuning of the network on a cohort of real IOL patient cases. We show that\nour network is not only superior to systems trained with standard procedures\nbut also that our method outperforms the current state of the art in IOL\ncalculation when compared on two biometric data sets.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 14:39:23 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Burwinkel", "Hendrik", ""], ["Matz", "Holger", ""], ["Saur", "Stefan", ""], ["Hauger", "Christoph", ""], ["Evren", "Ayse Mine", ""], ["Hirnschall", "Nino", ""], ["Findl", "Oliver", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "2005.04504", "submitter": "Saeed Saremi", "authors": "Saeed Saremi, Rupesh Srivastava", "title": "Provable Robust Classification via Learned Smoothed Densities", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothing classifiers and probability density functions with Gaussian kernels\nappear unrelated, but in this work, they are unified for the problem of robust\nclassification. The key building block is approximating the $\\textit{energy\nfunction}$ of the random variable $Y=X+N(0,\\sigma^2 I_d)$ with a neural network\nwhich we use to formulate the problem of robust classification in terms of\n$\\widehat{x}(Y)$, the $\\textit{Bayes estimator}$ of $X$ given the noisy\nmeasurements $Y$. We introduce $\\textit{empirical Bayes smoothed classifiers}$\nwithin the framework of $\\textit{randomized smoothing}$ and study it\ntheoretically for the two-class linear classifier, where we show one can\nimprove their robustness above $\\textit{the margin}$. We test the theory on\nMNIST and we show that with a learned smoothed energy function and a linear\nclassifier we can achieve provable $\\ell_2$ robust accuracies that are\ncompetitive with empirical defenses. This setup can be significantly improved\nby $\\textit{learning}$ empirical Bayes smoothed classifiers with adversarial\ntraining and on MNIST we show that we can achieve provable robust accuracies\nhigher than the state-of-the-art empirical defenses in a range of radii. We\ndiscuss some fundamental challenges of randomized smoothing based on a\ngeometric interpretation due to concentration of Gaussians in high dimensions,\nand we finish the paper with a proposal for using walk-jump sampling, itself\nbased on learned smoothed densities, for robust classification.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 19:52:32 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Saremi", "Saeed", ""], ["Srivastava", "Rupesh", ""]]}, {"id": "2005.04522", "submitter": "Jens Kley-Holsteg", "authors": "Jens Kley-Holsteg and Florian Ziel", "title": "Probabilistic Multi-Step-Ahead Short-Term Water Demand Forecasting with\n  Lasso", "comments": "accepted for publication in ASCE's Journal of Water Resources\n  Planning and Management. Kley-Holsteg, J., Ziel, F.. Forthcoming.\n  \"Probabilistic multi-step-ahead short-term water demand forecasting with\n  lasso.\" Journal of Water Resources Planning and Management. DOI:\n  10.1061/(ASCE)WR.1943-5452.0001268", "journal-ref": null, "doi": "10.1061/(ASCE)WR.1943-5452.0001268", "report-no": null, "categories": "stat.AP econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Water demand is a highly important variable for operational control and\ndecision making. Hence, the development of accurate forecasts is a valuable\nfield of research to further improve the efficiency of water utilities.\nFocusing on probabilistic multi-step-ahead forecasting, a time series model is\nintroduced, to capture typical autoregressive, calendar and seasonal effects,\nto account for time-varying variance, and to quantify the uncertainty and\npath-dependency of the water demand process. To deal with the high complexity\nof the water demand process a high-dimensional feature space is applied, which\nis efficiently tuned by an automatic shrinkage and selection operator (lasso).\nIt allows to obtain an accurate, simple interpretable and fast computable\nforecasting model, which is well suited for real-time applications. The\ncomplete probabilistic forecasting framework allows not only for simulating the\nmean and the marginal properties, but also the correlation structure between\nhours within the forecasting horizon. For practitioners, complete probabilistic\nmulti-step-ahead forecasts are of considerable relevance as they provide\nadditional information about the expected aggregated or cumulative water\ndemand, so that a statement can be made about the probability with which a\nwater storage capacity can guarantee the supply over a certain period of time.\nThis information allows to better control storage capacities and to better\nensure the smooth operation of pumps. To appropriately evaluate the forecasting\nperformance of the considered models, the energy score (ES) as a strictly\nproper multidimensional evaluation criterion, is introduced. The methodology is\napplied to the hourly water demand data of a German water supplier.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 22:26:09 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kley-Holsteg", "Jens", ""], ["Ziel", "Florian", ""]]}, {"id": "2005.04544", "submitter": "Baihan Lin", "authors": "Baihan Lin, Guillermo Cecchi, Djallel Bouneffouf, Jenna Reinen, Irina\n  Rish", "title": "An Empirical Study of Human Behavioral Agents in Bandits, Contextual\n  Bandits and Reinforcement Learning", "comments": "This article supersedes and extends our work arXiv:1706.02897 (MAB)\n  and arXiv:1906.11286 (RL) into the Contextual Bandit (CB) framework. It\n  generalized extensively into multi-armed bandits, contextual bandits and RL\n  settings to create a unified framework of human behavioral agents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial behavioral agents are often evaluated based on their consistent\nbehaviors and performance to take sequential actions in an environment to\nmaximize some notion of cumulative reward. However, human decision making in\nreal life usually involves different strategies and behavioral trajectories\nthat lead to the same empirical outcome. Motivated by clinical literature of a\nwide range of neurological and psychiatric disorders, we propose here a more\ngeneral and flexible parametric framework for sequential decision making that\ninvolves a two-stream reward processing mechanism. We demonstrated that this\nframework is flexible and unified enough to incorporate a family of problems\nspanning multi-armed bandits (MAB), contextual bandits (CB) and reinforcement\nlearning (RL), which decompose the sequential decision making process in\ndifferent levels. Inspired by the known reward processing abnormalities of many\nmental disorders, our clinically-inspired agents demonstrated interesting\nbehavioral trajectories and comparable performance on simulated tasks with\nparticular reward distributions, a real-world dataset capturing human\ndecision-making in gambling tasks, and the PacMan game across different reward\nstationarities in a lifelong learning setting.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 01:43:39 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 01:55:54 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 10:14:12 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 15:23:22 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lin", "Baihan", ""], ["Cecchi", "Guillermo", ""], ["Bouneffouf", "Djallel", ""], ["Reinen", "Jenna", ""], ["Rish", "Irina", ""]]}, {"id": "2005.04557", "submitter": "Youzhi Liang", "authors": "Xiaoyu Wu, Zeyu Bai, Jianguo Jia, Youzhi Liang", "title": "A Multi-Variate Triple-Regression Forecasting Algorithm for Long-Term\n  Customized Allergy Season Prediction", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel multi-variate algorithm using a\ntriple-regression methodology to predict the airborne-pollen allergy season\nthat can be customized for each patient in the long term. To improve the\nprediction accuracy, we first perform a pre-processing to integrate the\nhistorical data of pollen concentration and various inferential signals from\nother covariates such as the meteorological data. We then propose a novel\nalgorithm which encompasses three-stage regressions: in Stage 1, a regression\nmodel to predict the start/end date of a airborne-pollen allergy season is\ntrained from a feature matrix extracted from 12 time series of the covariates\nwith a rolling window; in Stage 2, a regression model to predict the\ncorresponding uncertainty is trained based on the feature matrix and the\nprediction result from Stage 1; in Stage 3, a weighted linear regression model\nis built upon prediction results from Stage 1 and 2. It is observed and proved\nthat Stage 3 contributes to the improved forecasting accuracy and the reduced\nuncertainty of the multi-variate triple-regression algorithm. Based on\ndifferent allergy sensitivity level, the triggering concentration of the pollen\n- the definition of the allergy season can be customized individually. In our\nbacktesting, a mean absolute error (MAE) of 4.7 days was achieved using the\nalgorithm. We conclude that this algorithm could be applicable in both generic\nand long-term forecasting problems.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 02:42:12 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 18:58:37 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 01:23:50 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Wu", "Xiaoyu", ""], ["Bai", "Zeyu", ""], ["Jia", "Jianguo", ""], ["Liang", "Youzhi", ""]]}, {"id": "2005.04563", "submitter": "Omobayode Fagbohungbe", "authors": "Omobayode Fagbohungbe, Sheikh Rufsan Reza, Xishuang Dong, Lijun Qian", "title": "Efficient Privacy Preserving Edge Computing Framework for Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to extract knowledge from the large data collected by edge devices,\ntraditional cloud based approach that requires data upload may not be feasible\ndue to communication bandwidth limitation as well as privacy and security\nconcerns of end users. To address these challenges, a novel privacy preserving\nedge computing framework is proposed in this paper for image classification.\nSpecifically, autoencoder will be trained unsupervised at each edge device\nindividually, then the obtained latent vectors will be transmitted to the edge\nserver for the training of a classifier. This framework would reduce the\ncommunications overhead and protect the data of the end users. Comparing to\nfederated learning, the training of the classifier in the proposed framework\ndoes not subject to the constraints of the edge devices, and the autoencoder\ncan be trained independently at each edge device without any server\ninvolvement. Furthermore, the privacy of the end users' data is protected by\ntransmitting latent vectors without additional cost of encryption. Experimental\nresults provide insights on the image classification performance vs. various\ndesign parameters such as the data compression ratio of the autoencoder and the\nmodel complexity.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 03:36:32 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Fagbohungbe", "Omobayode", ""], ["Reza", "Sheikh Rufsan", ""], ["Dong", "Xishuang", ""], ["Qian", "Lijun", ""]]}, {"id": "2005.04586", "submitter": "Aly El Gamal", "authors": "Sharan Ramjee, Shengtai Ju, Diyu Yang, Xiaoyu Liu, Aly El Gamal,\n  Yonina C. Eldar", "title": "Ensemble Wrapper Subsampling for Deep Modulation Classification", "comments": "22 pages, 13 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsampling of received wireless signals is important for relaxing hardware\nrequirements as well as the computational cost of signal processing algorithms\nthat rely on the output samples. We propose a subsampling technique to\nfacilitate the use of deep learning for automatic modulation classification in\nwireless communication systems. Unlike traditional approaches that rely on\npre-designed strategies that are solely based on expert knowledge, the proposed\ndata-driven subsampling strategy employs deep neural network architectures to\nsimulate the effect of removing candidate combinations of samples from each\ntraining input vector, in a manner inspired by how wrapper feature selection\nmodels work. The subsampled data is then processed by another deep learning\nclassifier that recognizes each of the considered 10 modulation types. We show\nthat the proposed subsampling strategy not only introduces drastic reduction in\nthe classifier training time, but can also improve the classification accuracy\nto higher levels than those reached before for the considered dataset. An\nimportant feature herein is exploiting the transferability property of deep\nneural networks to avoid retraining the wrapper models and obtain superior\nperformance through an ensemble of wrappers over that possible through solely\nrelying on any of them.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 06:11:13 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ramjee", "Sharan", ""], ["Ju", "Shengtai", ""], ["Yang", "Diyu", ""], ["Liu", "Xiaoyu", ""], ["Gamal", "Aly El", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2005.04602", "submitter": "Anthony Rhodes", "authors": "Anthony D. Rhodes, Bin Jiang", "title": "Regularized L21-Based Semi-NonNegative Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general-purpose data compression algorithm, Regularized L21\nSemi-NonNegative Matrix Factorization (L21 SNF). L21 SNF provides robust,\nparts-based compression applicable to mixed-sign data for which high fidelity,\nindividualdata point reconstruction is paramount. We derive a rigorous proof of\nconvergenceof our algorithm. Through experiments, we show the use-case\nadvantages presentedby L21 SNF, including application to the compression of\nhighly overdeterminedsystems encountered broadly across many general machine\nlearning processes.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 08:19:51 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Rhodes", "Anthony D.", ""], ["Jiang", "Bin", ""]]}, {"id": "2005.04612", "submitter": "Ritajit Majumdar", "authors": "Aditya Vikram Singhania, Saronyo Lal Mukherjee, Ritajit Majumdar,\n  Akash Mehta, Priyanka Banerjee and Debasmita Bhoumik", "title": "A machine learning based heuristic to predict the efficacy of online\n  sale", "comments": "Paper selected for Oral presentation at the 2nd International\n  Conference on Emerging Technologies in Data Mining and Information Security\n  (IEMIS 2020). Will appear in Springer Advances in Intelligent Systems and\n  Computing (AISC) Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to decide upon the efficacy of an online sale simply from the\ndiscount offered on commodities. Different features have different influence on\nthe price of a product which must be taken into consideration when determining\nthe significance of a discount. In this paper we have proposed a machine\nlearning based heuristic to quantify the \\textit{\"significance\"} of the\ndiscount offered on any commodity. Our proposed technique can quantify the\nsignificance of the discount based on features and the original price, and\nhence can guide a buyer during a sale season by predicting the efficacy of the\nsale. We have applied this technique on the Flipkart Summer Sale dataset using\nSupport Vector Machine, which predicts the efficacy of the sale with an\naccuracy of 91.11\\%. Our result shows that very few mobile phones have a\nsignificant discount during the Flipkart Summer Sale.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 09:31:54 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Singhania", "Aditya Vikram", ""], ["Mukherjee", "Saronyo Lal", ""], ["Majumdar", "Ritajit", ""], ["Mehta", "Akash", ""], ["Banerjee", "Priyanka", ""], ["Bhoumik", "Debasmita", ""]]}, {"id": "2005.04646", "submitter": "Hiroki Matsutani", "authors": "Hirohisa Watanabe, Mineto Tsukada and Hiroki Matsutani", "title": "An FPGA-Based On-Device Reinforcement Learning Approach using Online\n  Sequential Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DQN (Deep Q-Network) is a method to perform Q-learning for reinforcement\nlearning using deep neural networks. DQNs require a large buffer and batch\nprocessing for an experience replay and rely on a backpropagation based\niterative optimization, making them difficult to be implemented on\nresource-limited edge devices. In this paper, we propose a lightweight\non-device reinforcement learning approach for low-cost FPGA devices. It\nexploits a recently proposed neural-network based on-device learning approach\nthat does not rely on the backpropagation method but uses OS-ELM (Online\nSequential Extreme Learning Machine) based training algorithm. In addition, we\npropose a combination of L2 regularization and spectral normalization for the\non-device reinforcement learning so that output values of the neural network\ncan be fit into a certain range and the reinforcement learning becomes stable.\nThe proposed reinforcement learning approach is designed for PYNQ-Z1 board as a\nlow-cost FPGA platform. The evaluation results using OpenAI Gym demonstrate\nthat the proposed algorithm and its FPGA implementation complete a CartPole-v0\ntask 29.77x and 89.40x faster than a conventional DQN-based approach when the\nnumber of hidden-layer nodes is 64.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 12:37:26 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 08:35:11 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 07:09:38 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Watanabe", "Hirohisa", ""], ["Tsukada", "Mineto", ""], ["Matsutani", "Hiroki", ""]]}, {"id": "2005.04679", "submitter": "Erdogan Taskesen", "authors": "Erdogan Taskesen", "title": "HNet: Graphical Hypergeometric Networks", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Real-world data often contain measurements with both continuous\nand discrete values. Despite the availability of many libraries, data sets with\nmixed data types require intensive pre-processing steps, and it remains a\nchallenge to describe the relationships between variables. The data\nunderstanding phase is an important step in the data mining process, however,\nwithout making any assumptions on the data, the search space is\nsuper-exponential in the number of variables. Methods: We propose graphical\nhypergeometric networks (HNet), a method to test associations across variables\nfor significance using statistical inference. The aim is to determine a network\nusing only the significant associations in order to shed light on the complex\nrelationships across variables. HNet processes raw unstructured data sets and\noutputs a network that consists of (partially) directed or undirected edges\nbetween the nodes (i.e., variables). To evaluate the accuracy of HNet, we used\nwell known data sets and in addition generated data sets with known ground\ntruth. The performance of HNet is compared to Bayesian structure learning.\nResults: We demonstrate that HNet showed high accuracy and performance in the\ndetection of node links. In the case of the Alarm data set we can demonstrate\non average an MCC score of 0.33 + 0.0002 (P<1x10-6), whereas Bayesian structure\nlearning resulted in an average MCC score of 0.52 + 0.006 (P<1x10-11), and\nrandomly assigning edges resulted in a MCC score of 0.004 + 0.0003 (P=0.49).\nConclusions: HNet can process raw unstructured data sets, allows analysis of\nmixed data types, it easily scales up in number of variables, and allows\ndetailed examination of the detected associations. Availability:\nhttps://erdogant.github.io/hnet/\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:33:52 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Taskesen", "Erdogan", ""]]}, {"id": "2005.04689", "submitter": "Tien Dung Nguyen", "authors": "Tien-Dung Nguyen", "title": "Improving The Performance Of The K-means Algorithm", "comments": "The graduation thesis submitted to the School of Computer Science and\n  Engineering, International University - Vietnam National University HCMC in\n  partial fulfillment of the requirements for the degree of Master of\n  Information Technology Management", "journal-ref": null, "doi": null, "report-no": "Graduation Thesis (2013)", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Incremental K-means (IKM), an improved version of K-means (KM), was\nintroduced to improve the clustering quality of KM significantly. However, the\nspeed of IKM is slower than KM. My thesis proposes two algorithms to speed up\nIKM while remaining the quality of its clustering result approximately. The\nfirst algorithm, called Divisive K-means, improves the speed of IKM by speeding\nup its splitting process of clusters. Testing with UCI Machine Learning data\nsets, the new algorithm achieves the empirically global optimum as IKM and has\nlower complexity, $O(k*log_{2}k*n)$, than IKM, $O(k^{2}n)$. The second\nalgorithm, called Parallel Two-Phase K-means (Par2PK-means), parallelizes IKM\nby employing the model of Two-Phase K-means. Testing with large data sets, this\nalgorithm attains a good speedup ratio, closing to the linearly speed-up ratio.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 15:09:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Nguyen", "Tien-Dung", ""]]}, {"id": "2005.04692", "submitter": "Tomaso Aste", "authors": "Tomaso Aste", "title": "Topological regularization with information filtering networks", "comments": "16 pages , 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A methodology to perform topological regularization via information filtering\nnetwork is introduced. This methodology can be directly applied to sparse\nmodeling with the vast family of elliptical probability distributions. It can\nalso be directly implemented for $L_0$ norm regularized multicollinear\nregression. In this paper, I describe in detail an application to sparse\nmodeling with multivariate Student-t. A specific $L_0$ norm regularized\nexpectation-maximization likelihood maximization procedure is proposed for this\nsparse Student-t case. Examples with real data from stock prices log-returns\nand from artificially generated data demonstrate applicability, performances,\nand potentials of this methodology.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 15:15:04 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Aste", "Tomaso", ""]]}, {"id": "2005.04763", "submitter": "Tomer Koren", "authors": "Vitaly Feldman, Tomer Koren, Kunal Talwar", "title": "Private Stochastic Convex Optimization: Optimal Rates in Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study differentially private (DP) algorithms for stochastic convex\noptimization: the problem of minimizing the population loss given i.i.d.\nsamples from a distribution over convex loss functions. A recent work of\nBassily et al. (2019) has established the optimal bound on the excess\npopulation loss achievable given $n$ samples. Unfortunately, their algorithm\nachieving this bound is relatively inefficient: it requires $O(\\min\\{n^{3/2},\nn^{5/2}/d\\})$ gradient computations, where $d$ is the dimension of the\noptimization problem.\n  We describe two new techniques for deriving DP convex optimization algorithms\nboth achieving the optimal bound on excess loss and using $O(\\min\\{n, n^2/d\\})$\ngradient computations. In particular, the algorithms match the running time of\nthe optimal non-private algorithms. The first approach relies on the use of\nvariable batch sizes and is analyzed using the privacy amplification by\niteration technique of Feldman et al. (2018). The second approach is based on a\ngeneral reduction to the problem of localizing an approximately optimal\nsolution with differential privacy. Such localization, in turn, can be achieved\nusing existing (non-private) uniformly stable optimization algorithms. As in\nthe earlier work, our algorithms require a mild smoothness assumption. We also\ngive a linear-time algorithm achieving the optimal bound on the excess loss for\nthe strongly convex case, as well as a faster algorithm for the non-smooth\ncase.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 19:52:03 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Feldman", "Vitaly", ""], ["Koren", "Tomer", ""], ["Talwar", "Kunal", ""]]}, {"id": "2005.04774", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Eyad Said, Robert Todd", "title": "PageRank and The K-Means Clustering Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize the PageRank vector to generalize the $k$-means clustering\nalgorithm to directed and undirected graphs. We demonstrate that PageRank and\nother centrality measures can be used in our setting to robustly compute\ncentrality of nodes in a given graph. Furthermore, we show how our method can\nbe generalized to metric spaces and apply it to other domains such as point\nclouds and triangulated meshes\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 20:30:34 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 18:47:40 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 07:23:43 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Hajij", "Mustafa", ""], ["Said", "Eyad", ""], ["Todd", "Robert", ""]]}, {"id": "2005.04788", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, and Ernst Gunnar Gran", "title": "Distributed Fine-Grained Traffic Speed Prediction for Large-Scale\n  Transportation Networks based on Automatic LSTM Customization and Sharing", "comments": "14 pages, 7 figures, 2 tables, Euro-par 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term traffic speed prediction has been an important research topic in\nthe past decade, and many approaches have been introduced. However, providing\nfine-grained, accurate, and efficient traffic-speed prediction for large-scale\ntransportation networks where numerous traffic detectors are deployed has not\nbeen well studied. In this paper, we propose DistPre, which is a distributed\nfine-grained traffic speed prediction scheme for large-scale transportation\nnetworks. To achieve fine-grained and accurate traffic-speed prediction,\nDistPre customizes a Long Short-Term Memory (LSTM) model with an appropriate\nhyperparameter configuration for a detector. To make such customization process\nefficient and applicable for large-scale transportation networks, DistPre\nconducts LSTM customization on a cluster of computation nodes and allows any\ntrained LSTM model to be shared between different detectors. If a detector\nobserves a similar traffic pattern to another one, DistPre directly shares the\nexisting LSTM model between the two detectors rather than customizing an LSTM\nmodel per detector. Experiments based on traffic data collected from freeway\nI5-N in California are conducted to evaluate the performance of DistPre. The\nresults demonstrate that DistPre provides time-efficient LSTM customization and\naccurate fine-grained traffic-speed prediction for large-scale transportation\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 21:24:23 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 13:17:42 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Gran", "Ernst Gunnar", ""]]}, {"id": "2005.04791", "submitter": "Gordon Belot", "authors": "Gordon Belot", "title": "Absolutely No Free Lunches!", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2020.09.013", "report-no": null, "categories": "cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with learners who aim to learn patterns in infinite\nbinary sequences: shown longer and longer initial segments of a binary\nsequence, they either attempt to predict whether the next bit will be a 0 or\nwill be a 1 or they issue forecast probabilities for these events. Several\nvariants of this problem are considered. In each case, a no-free-lunch result\nof the following form is established: the problem of learning is a formidably\ndifficult one, in that no matter what method is pursued, failure is\nincomparably more common that success; and difficult choices must be faced in\nchoosing a method of learning, since no approach dominates all others in its\nrange of success. In the simplest case, the comparison of the set of situations\nin which a method fails and the set of situations in which it succeeds is a\nmatter of cardinality (countable vs. uncountable); in other cases, it is a\ntopological matter (meagre vs. co-meagre) or a hybrid computational-topological\nmatter (effectively meagre vs. effectively co-meagre).\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 21:32:28 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 21:39:34 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Belot", "Gordon", ""]]}, {"id": "2005.04806", "submitter": "Lizhen Shi", "authors": "Lizhen Shi, Bo Chen", "title": "Comparison and Benchmark of Graph Clustering Algorithms", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering is widely used in analysis of biological networks, social\nnetworks and etc. For over a decade many graph clustering algorithms have been\npublished, however a comprehensive and consistent performance comparison is not\navailable. In this paper we benchmarked more than 70 graph clustering programs\nto evaluate their runtime and quality performance for both weighted and\nunweighted graphs. We also analyzed the characteristics of ground truth that\naffects the performance. Our work is capable to not only supply a start point\nfor engineers to select clustering algorithms but also could provide a\nviewpoint for researchers to design new algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 22:54:36 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Shi", "Lizhen", ""], ["Chen", "Bo", ""]]}, {"id": "2005.04809", "submitter": "Novanto Yudistira", "authors": "Novanto Yudistira", "title": "COVID-19 growth prediction using multivariate long short term memory", "comments": null, "journal-ref": "IAENG International Journal of Computer Science, vol. 47, no. 4,\n  pp829-837, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Coronavirus disease (COVID-19) spread forecasting is an important task to\ntrack the growth of the pandemic. Existing predictions are merely based on\nqualitative analyses and mathematical modeling. The use of available big data\nwith machine learning is still limited in COVID-19 growth prediction even\nthough the availability of data is abundance. To make use of big data in the\nprediction using deep learning, we use long short-term memory (LSTM) method to\nlearn the correlation of COVID-19 growth over time. The structure of an LSTM\nlayer is searched heuristically until the best validation score is achieved.\nFirst, we trained training data containing confirmed cases from around the\nglobe. We achieved favorable performance compared with that of the recurrent\nneural network (RNN) method with a comparable low validation error. The\nevaluation is conducted based on graph visualization and root mean squared\nerror (RMSE). We found that it is not easy to achieve the same quantity of\nconfirmed cases over time. However, LSTM provide a similar pattern between the\nactual cases and prediction. In the future, our proposed prediction can be used\nfor anticipating forthcoming pandemics. The code is provided here:\nhttps://github.com/cbasemaster/lstmcorona\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 23:21:19 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 04:07:36 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Yudistira", "Novanto", ""]]}, {"id": "2005.04828", "submitter": "Joel Stremmel", "authors": "Joel Stremmel and Arjun Singh", "title": "Pretraining Federated Text Models for Next Word Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a decentralized approach for training models on\ndistributed devices, by summarizing local changes and sending aggregate\nparameters from local models to the cloud rather than the data itself. In this\nresearch we employ the idea of transfer learning to federated training for next\nword prediction (NWP) and conduct a number of experiments demonstrating\nenhancements to current baselines for which federated NWP models have been\nsuccessful. Specifically, we compare federated training baselines from randomly\ninitialized models to various combinations of pretraining approaches including\npretrained word embeddings and whole model pretraining followed by federated\nfine tuning for NWP on a dataset of Stack Overflow posts. We realize lift in\nperformance using pretrained embeddings without exacerbating the number of\nrequired training rounds or memory footprint. We also observe notable\ndifferences using centrally pretrained networks, especially depending on the\ndatasets used. Our research offers effective, yet inexpensive, improvements to\nfederated NWP and paves the way for more rigorous experimentation of transfer\nlearning techniques for federated learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 01:48:50 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 03:33:13 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 21:51:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Stremmel", "Joel", ""], ["Singh", "Arjun", ""]]}, {"id": "2005.04832", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Tara Javidi", "title": "Multi-Scale Zero-Order Optimization of Smooth Functions in an RKHS", "comments": "20 pages, 2 figures. Preliminary version -- feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to optimize a black-box function $f:\\mathcal{X} \\mapsto \\mathbb{R}$\nunder the assumption that $f$ is H\\\"older smooth and has bounded norm in the\nRKHS associated with a given kernel $K$. This problem is known to have an\nagnostic Gaussian Process (GP) bandit interpretation in which an appropriately\nconstructed GP surrogate model with kernel $K$ is used to obtain an upper\nconfidence bound (UCB) algorithm. In this paper, we propose a new algorithm\n(\\texttt{LP-GP-UCB}) where the usual GP surrogate model is augmented with Local\nPolynomial (LP) estimators of the H\\\"older smooth function $f$ to construct a\nmulti-scale UCB guiding the search for the optimizer. We analyze this algorithm\nand derive high probability bounds on its simple and cumulative regret. We then\nprove that the elements of many common RKHS are H\\\"older smooth and obtain the\ncorresponding H\\\"older smoothness parameters, and hence, specialize our regret\nbounds for several commonly used kernels. When specialized to the Squared\nExponential (SE) kernel, \\texttt{LP-GP-UCB} matches the optimal performance,\nwhile for the case of Mat\\'ern kernels $(K_{\\nu})_{\\nu>0}$, it results in\nuniformly tighter regret bounds for all values of the smoothness parameter\n$\\nu>0$. Most notably, for certain ranges of $\\nu$, the algorithm achieves\nnear-optimal bounds on simple and cumulative regrets, matching the\nalgorithm-independent lower bounds up to polylog factors, and thus closing the\nlarge gap between the existing upper and lower bounds for these values of\n$\\nu$. Additionally, our analysis provides the first explicit regret bounds, in\nterms of the budget $n$, for the Rational-Quadratic (RQ) and Gamma-Exponential\n(GE). Finally, experiments with synthetic functions as well as a CNN\nhyperparameter tuning task demonstrate the practical benefits of our\nmulti-scale partitioning approach over some existing algorithms numerically.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 01:55:39 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Javidi", "Tara", ""]]}, {"id": "2005.04834", "submitter": "Jean Feng", "authors": "Jean Feng and Noah Simon", "title": "Ensembled sparse-input hierarchical networks for high-dimensional\n  datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have seen limited use in prediction for high-dimensional data\nwith small sample sizes, because they tend to overfit and require tuning many\nmore hyperparameters than existing off-the-shelf machine learning methods. With\nsmall modifications to the network architecture and training procedure, we show\nthat dense neural networks can be a practical data analysis tool in these\nsettings. The proposed method, Ensemble by Averaging Sparse-Input Hierarchical\nnetworks (EASIER-net), appropriately prunes the network structure by tuning\nonly two L1-penalty parameters, one that controls the input sparsity and\nanother that controls the number of hidden layers and nodes. The method selects\nvariables from the true support if the irrelevant covariates are only weakly\ncorrelated with the response; otherwise, it exhibits a grouping effect, where\nstrongly correlated covariates are selected at similar rates. On a collection\nof real-world datasets with different sizes, EASIER-net selected network\narchitectures in a data-adaptive manner and achieved higher prediction accuracy\nthan off-the-shelf methods on average.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 02:08:53 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Feng", "Jean", ""], ["Simon", "Noah", ""]]}, {"id": "2005.04837", "submitter": "Lin Qiu", "authors": "Lin Qiu and Vernon M. Chinchilli", "title": "Probabilistic Canonical Correlation Analysis for Sparse Count Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis (CCA) is a classical and important\nmultivariate technique for exploring the relationship between two sets of\ncontinuous variables. CCA has applications in many fields, such as genomics and\nneuroimaging. It can extract meaningful features as well as use these features\nfor subsequent analysis. Although some sparse CCA methods have been developed\nto deal with high-dimensional problems, they are designed specifically for\ncontinuous data and do not consider the integer-valued data from\nnext-generation sequencing platforms that exhibit very low counts for some\nimportant features. We propose a model-based probabilistic approach for\ncorrelation and canonical correlation estimation for two sparse count data sets\n(PSCCA). PSCCA demonstrates that correlations and canonical correlations\nestimated at the natural parameter level are more appropriate than traditional\nestimation methods applied to the raw data. We demonstrate through simulation\nstudies that PSCCA outperforms other standard correlation approaches and sparse\nCCA approaches in estimating the true correlations and canonical correlations\nat the natural parameter level. We further apply the PSCCA method to study the\nassociation of miRNA and mRNA expression data sets from a squamous cell lung\ncancer study, finding that PSCCA can uncover a large number of strongly\ncorrelated pairs than standard correlation and other sparse CCA approaches.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 02:19:57 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Qiu", "Lin", ""], ["Chinchilli", "Vernon M.", ""]]}, {"id": "2005.04843", "submitter": "Chaoqi Yang", "authors": "Chaoqi Yang, Ruijie Wang, Shuochao Yao, Tarek Abdelzaher", "title": "Hypergraph Learning with Line Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous hypergraph expansions are solely carried out on either vertex level\nor hyperedge level, thereby missing the symmetric nature of data co-occurrence,\nand resulting in information loss. To address the problem, this paper treats\nvertices and hyperedges equally and proposes a new hypergraph formulation named\nthe \\emph{line expansion (LE)} for hypergraphs learning. The new expansion\nbijectively induces a homogeneous structure from the hypergraph by treating\nvertex-hyperedge pairs as \"line nodes\". By reducing the hypergraph to a simple\ngraph, the proposed \\emph{line expansion} makes existing graph learning\nalgorithms compatible with the higher-order structure and has been proven as a\nunifying framework for various hypergraph expansions. We evaluate the proposed\nline expansion on five hypergraph datasets, the results show that our method\nbeats SOTA baselines by a significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 03:02:21 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 00:38:09 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 22:25:51 GMT"}, {"version": "v4", "created": "Sun, 24 May 2020 03:22:05 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 20:45:47 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Yang", "Chaoqi", ""], ["Wang", "Ruijie", ""], ["Yao", "Shuochao", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2005.04871", "submitter": "Lu Wang", "authors": "Lu Wang, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, Yuan Jiang", "title": "Spanning Attack: Reinforce Black-box Attacks with Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial black-box attacks aim to craft adversarial perturbations by\nquerying input-output pairs of machine learning models. They are widely used to\nevaluate the robustness of pre-trained models. However, black-box attacks often\nsuffer from the issue of query inefficiency due to the high dimensionality of\nthe input space, and therefore incur a false sense of model robustness. In this\npaper, we relax the conditions of the black-box threat model, and propose a\nnovel technique called the spanning attack. By constraining adversarial\nperturbations in a low-dimensional subspace via spanning an auxiliary unlabeled\ndataset, the spanning attack significantly improves the query efficiency of a\nwide variety of existing black-box attacks. Extensive experiments show that the\nproposed method works favorably in both soft-label and hard-label black-box\nattacks. Our code is available at https://github.com/wangwllu/spanning_attack.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 05:57:15 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 03:54:26 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Lu", ""], ["Zhang", "Huan", ""], ["Yi", "Jinfeng", ""], ["Hsieh", "Cho-Jui", ""], ["Jiang", "Yuan", ""]]}, {"id": "2005.04876", "submitter": "Abhishek Niranjan", "authors": "Abhishek Niranjan, M Ali Basha Shaik, Kushal Verma", "title": "Hierarchical Attention Transformer Architecture For Syntactic Spell\n  Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The attention mechanisms are playing a boosting role in advancements in\nsequence-to-sequence problems. Transformer architecture achieved new state of\nthe art results in machine translation, and it's variants are since being\nintroduced in several other sequence-to-sequence problems. Problems which\ninvolve a shared vocabulary, can benefit from the similar semantic and\nsyntactic structure in the source and target sentences. With the motivation of\nbuilding a reliable and fast post-processing textual module to assist all the\ntext-related use cases in mobile phones, we take on the popular spell\ncorrection problem. In this paper, we propose multi encoder-single decoder\nvariation of conventional transformer. Outputs from the three encoders with\ncharacter level 1-gram, 2-grams and 3-grams inputs are attended in hierarchical\nfashion in the decoder. The context vectors from the encoders clubbed with\nself-attention amplify the n-gram properties at the character level and helps\nin accurate decoding. We demonstrate our model on spell correction dataset from\nSamsung Research, and report significant improvement of 0.11\\%, 0.32\\% and\n0.69\\% in character (CER), word (WER) and sentence (SER) error rates from\nexisting state-of-the-art machine-translation architectures. Our architecture\nis also trains ~7.8 times faster, and is only about 1/3 in size from the next\nmost accurate model.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 06:19:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Niranjan", "Abhishek", ""], ["Shaik", "M Ali Basha", ""], ["Verma", "Kushal", ""]]}, {"id": "2005.04888", "submitter": "Zixiao Shen", "authors": "Zixiao Shen, Xin Chen, Jonathan M. Garibaldi", "title": "Performance Optimization of a Fuzzy Entropy based Feature Selection and\n  Classification Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, based on a fuzzy entropy feature selection framework,\ndifferent methods have been implemented and compared to improve the key\ncomponents of the framework. Those methods include the combinations of three\nideal vector calculations, three maximal similarity classifiers and three fuzzy\nentropy functions. Different feature removal orders based on the fuzzy entropy\nvalues were also compared. The proposed method was evaluated on three publicly\navailable biomedical datasets. From the experiments, we concluded the optimized\ncombination of the ideal vector, similarity classifier and fuzzy entropy\nfunction for feature selection. The optimized framework was also compared with\nother six classical filter-based feature selection methods. The proposed method\nwas ranked as one of the top performers together with the Correlation and\nReliefF methods. More importantly, the proposed method achieved the most stable\nperformance for all three datasets when the features being gradually removed.\nThis indicates a better feature ranking performance than the other compared\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 07:16:50 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 05:49:24 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Shen", "Zixiao", ""], ["Chen", "Xin", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "2005.04975", "submitter": "Xinwang Liu", "authors": "Xinwang Liu, En Zhu, Jiyuan Liu, Timothy Hospedales, Yang Wang, Meng\n  Wang", "title": "SimpleMKKM: Simple Multiple Kernel K-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective multiple kernel clustering algorithm,\ntermed simple multiple kernel k-means (SimpleMKKM). It extends the widely used\nsupervised kernel alignment criterion to multi-kernel clustering. Our criterion\nis given by an intractable minimization-maximization problem in the kernel\ncoefficient and clustering partition matrix. To optimize it, we re-formulate\nthe problem as a smooth minimization one, which can be solved efficiently using\na reduced gradient descent algorithm. We theoretically analyze the performance\nof SimpleMKKM in terms of its clustering generalization error. Comprehensive\nexperiments on 11 benchmark datasets demonstrate that SimpleMKKM outperforms\nstate of the art multi-kernel clustering alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:06:40 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:05:04 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Liu", "Xinwang", ""], ["Zhu", "En", ""], ["Liu", "Jiyuan", ""], ["Hospedales", "Timothy", ""], ["Wang", "Yang", ""], ["Wang", "Meng", ""]]}, {"id": "2005.04987", "submitter": "Daniele Silvestro", "authors": "Daniele Silvestro and Tobias Andermann", "title": "Prior choice affects ability of Bayesian neural networks to identify\n  unknowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Bayesian neural networks (BNNs) are a powerful tool, though\ncomputationally demanding, to perform parameter estimation while jointly\nestimating uncertainty around predictions. BNNs are typically implemented using\narbitrary normal-distributed prior distributions on the model parameters. Here,\nwe explore the effects of different prior distributions on classification tasks\nin BNNs and evaluate the evidence supporting the predictions based on posterior\nprobabilities approximated by Markov Chain Monte Carlo sampling and by\ncomputing Bayes factors. We show that the choice of priors has a substantial\nimpact on the ability of the model to confidently assign data to the correct\nclass (true positive rates). Prior choice also affects significantly the\nability of a BNN to identify out-of-distribution instances as unknown (false\npositive rates). When comparing our results against neural networks (NN) with\nMonte Carlo dropout we found that BNNs generally outperform NNs. Finally, in\nour tests we did not find a single best choice as prior distribution. Instead,\neach dataset yielded the best results under a different prior, indicating that\ntesting alternative options can improve the performance of BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:32:47 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Silvestro", "Daniele", ""], ["Andermann", "Tobias", ""]]}, {"id": "2005.04988", "submitter": "Rachel Prudden", "authors": "Rachel Prudden, Samantha Adams, Dmitry Kangin, Niall Robinson, Suman\n  Ravuri, Shakir Mohamed, Alberto Arribas", "title": "A review of radar-based nowcasting of precipitation and applicable\n  machine learning techniques", "comments": "17 pages This work has been submitted to Monthly Weather Review.\n  Copyright in this work may be transferred without further notice", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A 'nowcast' is a type of weather forecast which makes predictions in the very\nshort term, typically less than two hours - a period in which traditional\nnumerical weather prediction can be limited. This type of weather prediction\nhas important applications for commercial aviation; public and outdoor events;\nand the construction industry, power utilities, and ground transportation\nservices that conduct much of their work outdoors. Importantly, one of the key\nneeds for nowcasting systems is in the provision of accurate warnings of\nadverse weather events, such as heavy rain and flooding, for the protection of\nlife and property in such situations. Typical nowcasting approaches are based\non simple extrapolation models applied to observations, primarily rainfall\nradar. In this paper we review existing techniques to radar-based nowcasting\nfrom environmental sciences, as well as the statistical approaches that are\napplicable from the field of machine learning. Nowcasting continues to be an\nimportant component of operational systems and we believe new advances are\npossible with new partnerships between the environmental science and machine\nlearning communities.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:34:04 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Prudden", "Rachel", ""], ["Adams", "Samantha", ""], ["Kangin", "Dmitry", ""], ["Robinson", "Niall", ""], ["Ravuri", "Suman", ""], ["Mohamed", "Shakir", ""], ["Arribas", "Alberto", ""]]}, {"id": "2005.05003", "submitter": "Zixiao Shen", "authors": "Zixiao Shen, Xin Chen, Jonathan M. Garibaldi", "title": "A Novel Weighted Combination Method for Feature Selection using Fuzzy\n  Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel weighted combination feature selection\nmethod using bootstrap and fuzzy sets. The proposed method mainly consists of\nthree processes, including fuzzy sets generation using bootstrap, weighted\ncombination of fuzzy sets and feature ranking based on defuzzification. We\nimplemented the proposed method by combining four state-of-the-art feature\nselection methods and evaluated the performance based on three publicly\navailable biomedical datasets using five-fold cross validation. Based on the\nfeature selection results, our proposed method produced comparable (if not\nbetter) classification accuracies to the best of the individual feature\nselection methods for all evaluated datasets. More importantly, we also applied\nstandard deviation and Pearson's correlation to measure the stability of the\nmethods. Remarkably, our combination method achieved significantly higher\nstability than the four individual methods when variations and size reductions\nwere introduced to the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 11:30:34 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 06:01:29 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Shen", "Zixiao", ""], ["Chen", "Xin", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "2005.05032", "submitter": "Andr\\'es Marafioti MSc", "authors": "Andres Marafioti, Piotr Majdak, Nicki Holighaus, Nathana\\\"el Perraudin", "title": "GACELA -- A generative adversarial context encoder for long audio\n  inpainting", "comments": null, "journal-ref": "IEEE Journal of Selected Topics in Signal Processing, vol. 15, no.\n  1, pp. 120-131, Jan. 2021", "doi": "10.1109/JSTSP.2020.3037506", "report-no": null, "categories": "cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GACELA, a generative adversarial network (GAN) designed to\nrestore missing musical audio data with a duration ranging between hundreds of\nmilliseconds to a few seconds, i.e., to perform long-gap audio inpainting.\nWhile previous work either addressed shorter gaps or relied on exemplars by\ncopying available information from other signal parts, GACELA addresses the\ninpainting of long gaps in two aspects. First, it considers various time scales\nof audio information by relying on five parallel discriminators with increasing\nresolution of receptive fields. Second, it is conditioned not only on the\navailable information surrounding the gap, i.e., the context, but also on the\nlatent variable of the conditional GAN. This addresses the inherent\nmulti-modality of audio inpainting at such long gaps and provides the option of\nuser-defined inpainting. GACELA was tested in listening tests on music signals\nof varying complexity and gap durations ranging from 375~ms to 1500~ms. While\nour subjects were often able to detect the inpaintings, the severity of the\nartifacts decreased from unacceptable to mildly disturbing. GACELA represents a\nframework capable to integrate future improvements such as processing of more\nauditory-related features or more explicit musical features.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 12:17:26 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Marafioti", "Andres", ""], ["Majdak", "Piotr", ""], ["Holighaus", "Nicki", ""], ["Perraudin", "Nathana\u00ebl", ""]]}, {"id": "2005.05053", "submitter": "Melikasadat Emami", "authors": "Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Alyson K.\n  Fletcher, Sundeep Rangan, Michael Trumpis, Brinnae Bent, Chia-Han Chiang,\n  Jonathan Viventi", "title": "Low-Rank Nonlinear Decoding of $\\mu$-ECoG from the Primary Auditory\n  Cortex", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of neural decoding from parallel neural\nmeasurements systems such as micro-electrocorticography ($\\mu$-ECoG). In\nsystems with large numbers of array elements at very high sampling rates, the\ndimension of the raw measurement data may be large. Learning neural decoders\nfor this high-dimensional data can be challenging, particularly when the number\nof training samples is limited. To address this challenge, this work presents a\nnovel neural network decoder with a low-rank structure in the first hidden\nlayer. The low-rank constraints dramatically reduce the number of parameters in\nthe decoder while still enabling a rich class of nonlinear decoder maps. The\nlow-rank decoder is illustrated on $\\mu$-ECoG data from the primary auditory\ncortex (A1) of awake rats. This decoding problem is particularly challenging\ndue to the complexity of neural responses in the auditory cortex and the\npresence of confounding signals in awake animals. It is shown that the proposed\nlow-rank decoder significantly outperforms models using standard dimensionality\nreduction techniques such as principal component analysis (PCA).\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:51:08 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Emami", "Melikasadat", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Pandit", "Parthe", ""], ["Fletcher", "Alyson K.", ""], ["Rangan", "Sundeep", ""], ["Trumpis", "Michael", ""], ["Bent", "Brinnae", ""], ["Chiang", "Chia-Han", ""], ["Viventi", "Jonathan", ""]]}, {"id": "2005.05057", "submitter": "Anna Guerra", "authors": "Anna Guerra, Francesco Guidi, Davide Dardari, Petar M. Djuric", "title": "Reinforcement Learning for UAV Autonomous Navigation, Mapping and Target\n  Detection", "comments": null, "journal-ref": null, "doi": "10.1109/PLANS46316.2020.9110163", "report-no": null, "categories": "cs.RO cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a joint detection, mapping and navigation problem for\na single unmanned aerial vehicle (UAV) equipped with a low complexity radar and\nflying in an unknown environment. The goal is to optimize its trajectory with\nthe purpose of maximizing the mapping accuracy and, at the same time, to avoid\nareas where measurements might not be sufficiently informative from the\nperspective of a target detection. This problem is formulated as a Markov\ndecision process (MDP) where the UAV is an agent that runs either a state\nestimator for target detection and for environment mapping, and a reinforcement\nlearning (RL) algorithm to infer its own policy of navigation (i.e., the\ncontrol law). Numerical results show the feasibility of the proposed idea,\nhighlighting the UAV's capability of autonomously exploring areas with high\nprobability of target detection while reconstructing the surrounding\nenvironment.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:39:18 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Guerra", "Anna", ""], ["Guidi", "Francesco", ""], ["Dardari", "Davide", ""], ["Djuric", "Petar M.", ""]]}, {"id": "2005.05067", "submitter": "Remy Priem", "authors": "R\\'emy Priem ((1) and (2)), Nathalie Bartoli (1), Youssef Diouane (2),\n  Alessandro Sgueglia ((1) and (2)) ((1) ONERA, DTIS, Universit\\'ee de\n  Toulouse, Toulouse, France, (2) ISAE-SUPAERO, Universit\\'ee de Toulouse,\n  Toulouse, 31055 Cedex 4, France)", "title": "Upper Trust Bound Feasibility Criterion for Mixed Constrained Bayesian\n  Optimization with Application to Aircraft Design", "comments": "59 pages, 27 figures", "journal-ref": null, "doi": "10.1016/j.ast.2020.105980", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bayesian optimization methods have been successfully applied to black box\noptimization problems that are expensive to evaluate. In this paper, we adapt\nthe so-called super effcient global optimization algorithm to solve more\naccurately mixed constrained problems. The proposed approach handles\nconstraints by means of upper trust bound, the latter encourages exploration of\nthe feasible domain by combining the mean prediction and the associated\nuncertainty function given by the Gaussian processes. On top of that, a\nrefinement procedure, based on a learning rate criterion, is introduced to\nenhance the exploitation and exploration trade-off. We show the good potential\nof the approach on a set of numerical experiments. Finally, we present an\napplication to conceptual aircraft configuration upon which we show the\nsuperiority of the proposed approach compared to a set of the state-of-the-art\nblack box optimization solvers. Keywords: Global Optimization, Mixed\nConstrained Optimization, Black box optimization, Bayesian Optimization,\nGaussian Process.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 12:59:09 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 08:59:51 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Priem", "R\u00e9my", ""], ["Bartoli", "Nathalie", ""], ["Diouane", "Youssef", ""], ["Sgueglia", "Alessandro", ""]]}, {"id": "2005.05080", "submitter": "Honglin Li", "authors": "Honglin Li, Payam Barnaghi, Shirin Enshaeifar, Frieder Ganz", "title": "Continual Learning Using Multi-view Task Conditional Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conventional deep learning models have limited capacity in learning multiple\ntasks sequentially. The issue of forgetting the previously learned tasks in\ncontinual learning is known as catastrophic forgetting or interference. When\nthe input data or the goal of learning change, a continual model will learn and\nadapt to the new status. However, the model will not remember or recognise any\nrevisits to the previous states. This causes performance reduction and\nre-training curves in dealing with periodic or irregularly reoccurring changes\nin the data or goals. The changes in goals or data are referred to as new tasks\nin a continual learning model. Most of the continual learning methods have a\ntask-known setup in which the task identities are known in advance to the\nlearning model. We propose Multi-view Task Conditional Neural Networks\n(Mv-TCNN) that does not require to known the reoccurring tasks in advance. We\nevaluate our model on standard datasets using MNIST, CIFAR10, CIFAR100, and\nalso a real-world dataset that we have collected in a remote healthcare\nmonitoring study (i.e. TIHM dataset). The proposed model outperforms the\nstate-of-the-art solutions in continual learning and adapting to new tasks that\nare not defined in advance.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 01:03:30 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 04:58:37 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 09:19:07 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Li", "Honglin", ""], ["Barnaghi", "Payam", ""], ["Enshaeifar", "Shirin", ""], ["Ganz", "Frieder", ""]]}, {"id": "2005.05092", "submitter": "Christopher Arthurs DPhil", "authors": "Christopher J Arthurs and Andrew P King", "title": "Active Training of Physics-Informed Neural Networks to Aggregate and\n  Interpolate Parametric Solutions to the Navier-Stokes Equations", "comments": "16 pages, 9 figures; added missing details from author affiliations", "journal-ref": null, "doi": "10.1016/j.jcp.2021.110364", "report-no": null, "categories": "physics.comp-ph cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to train a neural network which approximates\nsolutions to the Navier-Stokes equations across a region of parameter space, in\nwhich the parameters define physical properties such as domain shape and\nboundary conditions. The contributions of this work are threefold:\n  1) To demonstrate that neural networks can be efficient aggregators of whole\nfamilies of parameteric solutions to physical problems, trained using data\ncreated with traditional, trusted numerical methods such as finite elements.\nAdvantages include extremely fast evaluation of pressure and velocity at any\npoint in physical and parameter space (asymptotically, ~3 $\\mu s$ / query), and\ndata compression (the network requires 99\\% less storage space compared to its\nown training data).\n  2) To demonstrate that the neural networks can accurately interpolate between\nfinite element solutions in parameter space, allowing them to be instantly\nqueried for pressure and velocity field solutions to problems for which\ntraditional simulations have never been performed.\n  3) To introduce an active learning algorithm, so that during training, a\nfinite element solver can automatically be queried to obtain additional\ntraining data in locations where the neural network's predictions are in most\nneed of improvement, thus autonomously acquiring and efficiently distributing\ntraining data throughout parameter space.\n  In addition to the obvious utility of Item 2, above, we demonstrate an\napplication of the network in rapid parameter sweeping, very precisely\npredicting the degree of narrowing in a tube which would result in a 50\\%\nincrease in end-to-end pressure difference at a given flow rate. This\ncapability could have applications in both medical diagnosis of arterial\ndisease, and in computer-aided design.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 21:53:39 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 11:24:36 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Arthurs", "Christopher J", ""], ["King", "Andrew P", ""]]}, {"id": "2005.05097", "submitter": "Daniel Alshamaa", "authors": "Daniel Alshamaa, Farah Chehade, Paul Honeine", "title": "Statistical learning for sensor localization in wireless networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor localization has become an important issue for wireless sensor\nnetworks. This paper presents a zoning-based localization technique that uses\nWiFi signals and works efficiently in indoor environments. The targeted area is\ncomposed of several zones, the objective being to determine the zone of the\nsensor using an observation model based on statistical learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:27:24 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Alshamaa", "Daniel", ""], ["Chehade", "Farah", ""], ["Honeine", "Paul", ""]]}, {"id": "2005.05099", "submitter": "Shonosuke Harada", "authors": "Shonosuke Harada and Hisashi Kashima", "title": "Counterfactual Propagation for Semi-Supervised Individual Treatment\n  Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual treatment effect (ITE) represents the expected improvement in the\noutcome of taking a particular action to a particular target, and plays\nimportant roles in decision making in various domains. However, its estimation\nproblem is difficult because intervention studies to collect information\nregarding the applied treatments (i.e., actions) and their outcomes are often\nquite expensive in terms of time and monetary costs. In this study, we consider\na semi-supervised ITE estimation problem that exploits more easily-available\nunlabeled instances to improve the performance of ITE estimation using small\nlabeled data. We combine two ideas from causal inference and semi-supervised\nlearning, namely, matching and label propagation, respectively, to propose\ncounterfactual propagation, which is the first semi-supervised ITE estimation\nmethod. Experiments using semi-real datasets demonstrate that the proposed\nmethod can successfully mitigate the data scarcity problem in ITE estimation.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:32:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Harada", "Shonosuke", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2005.05113", "submitter": "Jasper Velthoen", "authors": "Jasper Velthoen, Juan-Juan Cai, Geurt Jongbloed", "title": "Interpretable random forest models through forward variable selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forest is a popular prediction approach for handling high dimensional\ncovariates. However, it often becomes infeasible to interpret the obtained high\ndimensional and non-parametric model. Aiming for obtaining an interpretable\npredictive model, we develop a forward variable selection method using the\ncontinuous ranked probability score (CRPS) as the loss function. Our stepwise\nprocedure leads to a smallest set of variables that optimizes the CRPS risk by\nperforming at each step a hypothesis test on a significant decrease in CRPS\nrisk. We provide mathematical motivation for our method by proving that in\npopulation sense the method attains the optimal set. Additionally, we show that\nthe test is consistent provided that the random forest estimator of a quantile\nfunction is consistent.\n  In a simulation study, we compare the performance of our method with an\nexisting variable selection method, for different sample sizes and different\ncorrelation strength of covariates. Our method is observed to have a much lower\nfalse positive rate. We also demonstrate an application of our method to\nstatistical post-processing of daily maximum temperature forecasts in the\nNetherlands. Our method selects about 10% covariates while retaining the same\npredictive power.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:56:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Velthoen", "Jasper", ""], ["Cai", "Juan-Juan", ""], ["Jongbloed", "Geurt", ""]]}, {"id": "2005.05117", "submitter": "Bojan Karla\\v{s}", "authors": "Bojan Karla\\v{s}, Peng Li, Renzhi Wu, Nezihe Merve G\\\"urel, Xu Chu,\n  Wentao Wu, Ce Zhang", "title": "Nearest Neighbor Classifiers over Incomplete Information: From Certain\n  Answers to Certain Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) applications have been thriving recently, largely\nattributed to the increasing availability of data. However, inconsistency and\nincomplete information are ubiquitous in real-world datasets, and their impact\non ML applications remains elusive. In this paper, we present a formal study of\nthis impact by extending the notion of Certain Answers for Codd tables, which\nhas been explored by the database research community for decades, into the\nfield of machine learning. Specifically, we focus on classification problems\nand propose the notion of \"Certain Predictions\" (CP) -- a test data example can\nbe certainly predicted (CP'ed) if all possible classifiers trained on top of\nall possible worlds induced by the incompleteness of data would yield the same\nprediction.\n  We study two fundamental CP queries: (Q1) checking query that determines\nwhether a data example can be CP'ed; and (Q2) counting query that computes the\nnumber of classifiers that support a particular prediction (i.e., label). Given\nthat general solutions to CP queries are, not surprisingly, hard without\nassumption over the type of classifier, we further present a case study in the\ncontext of nearest neighbor (NN) classifiers, where efficient solutions to CP\nqueries can be developed -- we show that it is possible to answer both queries\nin linear or polynomial time over exponentially many possible worlds.\n  We demonstrate one example use case of CP in the important application of\n\"data cleaning for machine learning (DC for ML).\" We show that our proposed\nCPClean approach built based on CP can often significantly outperform existing\ntechniques in terms of classification accuracy with mild manual cleaning\neffort.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:58:52 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 10:46:33 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Karla\u0161", "Bojan", ""], ["Li", "Peng", ""], ["Wu", "Renzhi", ""], ["G\u00fcrel", "Nezihe Merve", ""], ["Chu", "Xu", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""]]}, {"id": "2005.05128", "submitter": "Jichen Wang", "authors": "Jichen Wang, Weiguo Zhu, Yongqi Sun, Chunzi Tian", "title": "An Effective Dynamic Spatio-temporal Framework with Multi-Source\n  Information for Traffic Prediction", "comments": "12pages, 12 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traffic prediction is necessary not only for management departments to\ndispatch vehicles but also for drivers to avoid congested roads. Many traffic\nforecasting methods based on deep learning have been proposed in recent years,\nand their main aim is to solve the problem of spatial dependencies and temporal\ndynamics. In this paper, we propose a useful dynamic model to predict the urban\ntraffic volume by combining fully bidirectional LSTM, the more complex\nattention mechanism, and the external features, including weather conditions\nand events. First, we adopt the bidirectional LSTM to obtain temporal\ndependencies of traffic volume dynamically in each layer, which is different\nfrom the hybrid methods combining bidirectional and unidirectional ones;\nsecond, we use a more elaborate attention mechanism to learn short-term and\nlong-term periodic temporal dependencies; and finally, we collect the weather\nconditions and events as the external features to further improve the\nprediction precision. The experimental results show that the proposed model\nimproves the prediction precision by approximately 3-7 percent on the NYC-Taxi\nand NYC-Bike datasets compared to the most recently developed method, being a\nuseful tool for the urban traffic prediction.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:23:52 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Wang", "Jichen", ""], ["Zhu", "Weiguo", ""], ["Sun", "Yongqi", ""], ["Tian", "Chunzi", ""]]}, {"id": "2005.05158", "submitter": "Antonio Silveti-Falls", "authors": "Antonio Silveti-Falls, Cesare Molinari, Jalal Fadili", "title": "Inexact and Stochastic Generalized Conditional Gradient with Augmented\n  Lagrangian and Proximal Step", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and analyze inexact and stochastic versions of the\nCGALP algorithm developed in the authors' previous paper, which we denote\nICGALP, that allows for errors in the computation of several important\nquantities. In particular this allows one to compute some gradients, proximal\nterms, and/or linear minimization oracles in an inexact fashion that\nfacilitates the practical application of the algorithm to computationally\nintensive settings, e.g. in high (or possibly infinite) dimensional Hilbert\nspaces commonly found in machine learning problems. The algorithm is able to\nsolve composite minimization problems involving the sum of three convex proper\nlower-semicontinuous functions subject to an affine constraint of the form\n$Ax=b$ for some bounded linear operator $A$. Only one of the functions in the\nobjective is assumed to be differentiable, the other two are assumed to have an\naccessible prox operator and a linear minimization oracle. As main results, we\nshow convergence of the Lagrangian to an optimum and asymptotic feasibility of\nthe affine constraint as well as weak convergence of the dual variable to a\nsolution of the dual problem, all in an almost sure sense. Almost sure\nconvergence rates, both pointwise and ergodic, are given for the Lagrangian\nvalues and the feasibility gap. Numerical experiments verifying the predicted\nrates of convergence are shown as well.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 14:52:16 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Silveti-Falls", "Antonio", ""], ["Molinari", "Cesare", ""], ["Fadili", "Jalal", ""]]}, {"id": "2005.05163", "submitter": "Azra Bihorac", "authors": "Yuanfeng Ren (1)(4), Tyler J. Loftus (2)(4), Rahul Sai Kasula (1)(4),\n  Prudhvee Narasimha Sadha (1)(4), Parisa Rashidi (3)(4), Azra Bihorac (1)(4),\n  and Tezcan Ozrazgat-Baslanti (1)(4) ((1) Department of Medicine, College of\n  Medicine, University of Florida, Gainesville, FL, USA, (2) Department of\n  Surgery, College of Medicine, University of Florida, Gainesville, FL, USA,\n  (3) Crayton Pruitt Family Department of Biomedical Engineering, University of\n  Florida, Gainesville, FL, (4) Precision and Intelligent Systems in Medicine\n  (PrismaP), University of Florida, Gainesville, FL, USA)", "title": "Development of Computable Phenotype to Identify and Characterize\n  Transitions in Acuity Status in Intensive Care Unit", "comments": "21 Pages, that include 6 figures, 3 tables and 1 supplemental Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: In the United States, 5.7 million patients are admitted annually\nto intensive care units (ICU), with costs exceeding $82 billion. Although close\nmonitoring and dynamic assessment of patient acuity are key aspects of ICU\ncare, both are limited by the time constraints imposed on healthcare providers.\nMethods: Using the University of Florida Health (UFH) Integrated Data\nRepository as Honest Broker, we created a database with electronic health\nrecords data from a retrospective study cohort of 38,749 adult patients\nadmitted to ICU at UF Health between 06/01/2014 and 08/22/2019. This repository\nincludes demographic information, comorbidities, vital signs, laboratory\nvalues, medications with date and timestamps, and diagnoses and procedure codes\nfor all index admission encounters as well as encounters within 12 months prior\nto index admission and 12 months follow-up. We developed algorithms to identify\nacuity status of the patient every four hours during each ICU stay. Results: We\nhad 383,193 encounters (121,800 unique patients) admitted to the hospital, and\n51,073 encounters (38,749 unique patients) with at least one ICU stay that\nlasted more than four hours. These patients requiring ICU admission had longer\nmedian hospital stay (7 days vs. 1 day) and higher in-hospital mortality (9.6%\nvs. 0.4%) compared with those not admitted to the ICU. Among patients who were\nadmitted to the ICU and expired during hospital admission, more deaths occurred\nin the ICU than on general hospital wards (7.4% vs. 0.8%, respectively).\nConclusions: We developed phenotyping algorithms that determined patient acuity\nstatus every four hours while admitted to the ICU. This approach may be useful\nin developing prognostic and clinical decision-support tools to aid patients,\ncaregivers, and providers in shared decision-making processes regarding\nresource use and escalation of care.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:36:17 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ren", "Yuanfeng", ""], ["Loftus", "Tyler J.", ""], ["Kasula", "Rahul Sai", ""], ["Sadha", "Prudhvee Narasimha", ""], ["Rashidi", "Parisa", ""], ["Bihorac", "Azra", ""], ["Ozrazgat-Baslanti", "Tezcan", ""]]}, {"id": "2005.05178", "submitter": "Trent Weiss", "authors": "Trent Weiss, Madhur Behl", "title": "DeepRacing: Parameterized Trajectories for Autonomous Racing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the challenging problem of high speed autonomous racing in a\nrealistic Formula One environment. DeepRacing is a novel end-to-end framework,\nand a virtual testbed for training and evaluating algorithms for autonomous\nracing. The virtual testbed is implemented using the realistic F1 series of\nvideo games, developed by Codemasters, which many Formula One drivers use for\ntraining. This virtual testbed is released under an open-source license both as\na standalone C++ API and as a binding to the popular Robot Operating System 2\n(ROS2) framework. This open-source API allows anyone to use the high fidelity\nphysics and photo-realistic capabilities of the F1 game as a simulator, and\nwithout hacking any game engine code. We use this framework to evaluate several\nneural network methodologies for autonomous racing. Specifically, we consider\nseveral fully end-to-end models that directly predict steering and acceleration\ncommands for an autonomous race car as well as a model that predicts a list of\nwaypoints to follow in the car's local coordinate system, with the task of\nselecting a steering/throttle angle left to a classical control algorithm. We\nalso present a novel method of autonomous racing by training a deep neural\nnetwork to predict a parameterized representation of a trajectory rather than a\nlist of waypoints. We evaluate these models performance in our open-source\nsimulator and show that trajectory prediction far outperforms end-to-end\ndriving. Additionally, we show that open-loop performance for an end-to-end\nmodel, i.e. root-mean-square error for a model's predicted control values, does\nnot necessarily correlate with increased driving performance in the closed-loop\nsense, i.e. actual ability to race around a track. Finally, we show that our\nproposed model of parameterized trajectory prediction outperforms both\nend-to-end control and waypoint prediction.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 21:35:48 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Weiss", "Trent", ""], ["Behl", "Madhur", ""]]}, {"id": "2005.05206", "submitter": "Thomas Stahlbuhk", "authors": "Thomas Stahlbuhk, Brooke Shrader and Eytan Modiano", "title": "Learning Algorithms for Minimizing Queue Length Regret", "comments": "28 Pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.IT cs.LG cs.SY eess.SY math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system consisting of a single transmitter/receiver pair and $N$\nchannels over which they may communicate. Packets randomly arrive to the\ntransmitter's queue and wait to be successfully sent to the receiver. The\ntransmitter may attempt a frame transmission on one channel at a time, where\neach frame includes a packet if one is in the queue. For each channel, an\nattempted transmission is successful with an unknown probability. The\ntransmitter's objective is to quickly identify the best channel to minimize the\nnumber of packets in the queue over $T$ time slots. To analyze system\nperformance, we introduce queue length regret, which is the expected difference\nbetween the total queue length of a learning policy and a controller that knows\nthe rates, a priori. One approach to designing a transmission policy would be\nto apply algorithms from the literature that solve the closely-related\nstochastic multi-armed bandit problem. These policies would focus on maximizing\nthe number of successful frame transmissions over time. However, we show that\nthese methods have $\\Omega(\\log{T})$ queue length regret. On the other hand, we\nshow that there exists a set of queue-length based policies that can obtain\norder optimal $O(1)$ queue length regret. We use our theoretical analysis to\ndevise heuristic methods that are shown to perform well in simulation.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 15:50:56 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 13:26:02 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Stahlbuhk", "Thomas", ""], ["Shrader", "Brooke", ""], ["Modiano", "Eytan", ""]]}, {"id": "2005.05210", "submitter": "Lin Qiu", "authors": "Lin Qiu, Vernon M. Chinchilli, Lin Lin", "title": "Deep Latent Variable Model for Learning Longitudinal Multi-view Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scientific problems such as video surveillance, modern genomic\nanalysis, and clinical studies, data are often collected from diverse domains\nacross time that exhibit time-dependent heterogeneous properties. It is\nimportant to not only integrate data from multiple sources (called multiview\ndata), but also to incorporate time dependency for deep understanding of the\nunderlying system. Latent factor models are popular tools for exploring\nmulti-view data. However, it is frequently observed that these models do not\nperform well for complex systems and they are not applicable to time-series\ndata. Therefore, we propose a generative model based on variational autoencoder\nand recurrent neural network to infer the latent dynamic factors for\nmultivariate timeseries data. This approach allows us to identify the\ndisentangled latent embeddings across multiple modalities while accounting for\nthe time factor. We invoke our proposed model for analyzing three datasets on\nwhich we demonstrate the effectiveness and the interpretability of the model.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 15:59:06 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 21:23:19 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Qiu", "Lin", ""], ["Chinchilli", "Vernon M.", ""], ["Lin", "Lin", ""]]}, {"id": "2005.05236", "submitter": "Guillermo Jimenez-Perez", "authors": "Guillermo Jimenez-Perez and Alejandro Alcaine and Oscar Camara", "title": "ECG-DelNet: Delineation of Ambulatory Electrocardiograms with Mixed\n  Quality Labeling Using Neural Networks", "comments": "15 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram (ECG) detection and delineation are key steps for numerous\ntasks in clinical practice, as ECG is the most performed non-invasive test for\nassessing cardiac condition. State-of-the-art algorithms employ digital signal\nprocessing (DSP), which require laborious rule adaptation to new morphologies.\nIn contrast, deep learning (DL) algorithms, especially for classification, are\ngaining weight in academic and industrial settings. However, the lack of model\nexplainability and small databases hinder their applicability. We demonstrate\nDL can be successfully applied to low interpretative tasks by embedding ECG\ndetection and delineation onto a segmentation framework. For this purpose, we\nadapted and validated the most used neural network architecture for image\nsegmentation, the U-Net, to one-dimensional data. The model was trained using\nPhysioNet's QT database, comprised of 105 ambulatory ECG recordings, for\nsingle- and multi-lead scenarios. To alleviate data scarcity, data\nregularization techniques such as pre-training with low-quality data labels,\nperforming ECG-based data augmentation and applying strong model regularizers\nto the architecture were attempted. Other variations in the model's capacity\n(U-Net's depth and width), alongside the application of state-of-the-art\nadditions, were evaluated. These variations were exhaustively validated in a\n5-fold cross-validation manner. The best performing configuration reached\nprecisions of 90.12%, 99.14% and 98.25% and recalls of 98.73%, 99.94% and\n99.88% for the P, QRS and T waves, respectively, on par with DSP-based\napproaches. Despite being a data-hungry technique trained on a small dataset,\nDL-based approaches demonstrate to be a viable alternative to traditional\nDSP-based ECG processing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:29:12 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Jimenez-Perez", "Guillermo", ""], ["Alcaine", "Alejandro", ""], ["Camara", "Oscar", ""]]}, {"id": "2005.05238", "submitter": "Reese Pathak", "authors": "Reese Pathak, Martin J. Wainwright", "title": "FedSplit: An algorithmic framework for fast federated optimization", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Motivated by federated learning, we consider the hub-and-spoke model of\ndistributed optimization in which a central authority coordinates the\ncomputation of a solution among many agents while limiting communication. We\nfirst study some past procedures for federated optimization, and show that\ntheir fixed points need not correspond to stationary points of the original\noptimization problem, even in simple convex settings with deterministic\nupdates. In order to remedy these issues, we introduce FedSplit, a class of\nalgorithms based on operator splitting procedures for solving distributed\nconvex minimization with additive structure. We prove that these procedures\nhave the correct fixed points, corresponding to optima of the original\noptimization problem, and we characterize their convergence rates under\ndifferent settings. Our theory shows that these methods are provably robust to\ninexact computation of intermediate local quantities. We complement our theory\nwith some simple experiments that demonstrate the benefits of our methods in\npractice.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:30:09 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pathak", "Reese", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "2005.05276", "submitter": "Raoul Heese", "authors": "Raoul Heese, Lukas Morand, Dirk Helm, Michael Bortz", "title": "CupNet -- Pruning a network for geometric data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using data from a simulated cup drawing process, we demonstrate how the\ninherent geometrical structure of cup meshes can be used to effectively prune\nan artificial neural network in a straightforward way.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:21:23 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Heese", "Raoul", ""], ["Morand", "Lukas", ""], ["Helm", "Dirk", ""], ["Bortz", "Michael", ""]]}, {"id": "2005.05286", "submitter": "Benjamin Guedj", "authors": "Florent Dewez and Benjamin Guedj and Vincent Vandewalle", "title": "From industry-wide parameters to aircraft-centric on-flight inference:\n  improving aeronautics performance prediction with machine learning", "comments": "Published in Data-Centric Engineering", "journal-ref": "Data-Centric Engineering 2020", "doi": "10.1017/dce.2020.12", "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Aircraft performance models play a key role in airline operations, especially\nin planning a fuel-efficient flight. In practice, manufacturers provide\nguidelines which are slightly modified throughout the aircraft life cycle via\nthe tuning of a single factor, enabling better fuel predictions. However this\nhas limitations, in particular they do not reflect the evolution of each\nfeature impacting the aircraft performance. Our goal here is to overcome this\nlimitation. The key contribution of the present article is to foster the use of\nmachine learning to leverage the massive amounts of data continuously recorded\nduring flights performed by an aircraft and provide models reflecting its\nactual and individual performance. We illustrate our approach by focusing on\nthe estimation of the drag and lift coefficients from recorded flight data. As\nthese coefficients are not directly recorded, we resort to aerodynamics\napproximations. As a safety check, we provide bounds to assess the accuracy of\nboth the aerodynamics approximation and the statistical performance of our\napproach. We provide numerical results on a collection of machine learning\nalgorithms. We report excellent accuracy on real-life data and exhibit\nempirical evidence to support our modelling, in coherence with aerodynamics\nprinciples.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:40:17 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 16:42:36 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 10:22:43 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Dewez", "Florent", ""], ["Guedj", "Benjamin", ""], ["Vandewalle", "Vincent", ""]]}, {"id": "2005.05287", "submitter": "Prateek Khandelwal", "authors": "Prateek Khandelwal, Anuj Khandelwal, Snigdha Agarwal, Deep Thomas,\n  Naveen Xavier, Arun Raghuraman (for Group Data and Analytics, Aditya Birla\n  Group)", "title": "Using Computer Vision to enhance Safety of Workforce in Manufacturing in\n  a Post COVID World", "comments": "6 pages, 7 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic forced governments across the world to impose lockdowns\nto prevent virus transmissions. This resulted in the shutdown of all economic\nactivity and accordingly the production at manufacturing plants across most\nsectors was halted. While there is an urgency to resume production, there is an\neven greater need to ensure the safety of the workforce at the plant site.\nReports indicate that maintaining social distancing and wearing face masks\nwhile at work clearly reduces the risk of transmission. We decided to use\ncomputer vision on CCTV feeds to monitor worker activity and detect violations\nwhich trigger real time voice alerts on the shop floor. This paper describes an\nefficient and economic approach of using AI to create a safe environment in a\nmanufacturing setup. We demonstrate our approach to build a robust social\ndistancing measurement algorithm using a mix of modern-day deep learning and\nclassic projective geometry techniques. We have deployed our solution at\nmanufacturing plants across the Aditya Birla Group (ABG). We have also\ndescribed our face mask detection approach which provides a high accuracy\nacross a range of customized masks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:40:58 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 12:16:12 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Khandelwal", "Prateek", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Khandelwal", "Anuj", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Agarwal", "Snigdha", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Thomas", "Deep", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Xavier", "Naveen", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Raghuraman", "Arun", "", "for Group Data and Analytics, Aditya Birla\n  Group"]]}, {"id": "2005.05294", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Ring Reservoir Neural Networks for Graphs", "comments": "Accepted for IJCNN/WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning for graphs is nowadays a research topic of consolidated\nrelevance. Common approaches in the field typically resort to complex deep\nneural network architectures and demanding training algorithms, highlighting\nthe need for more efficient solutions. The class of Reservoir Computing (RC)\nmodels can play an important role in this context, enabling to develop fruitful\ngraph embeddings through untrained recursive architectures. In this paper, we\nstudy progressive simplifications to the design strategy of RC neural networks\nfor graphs. Our core proposal is based on shaping the organization of the\nhidden neurons to follow a ring topology. Experimental results on graph\nclassification tasks indicate that ring-reservoirs architectures enable\nparticularly effective network configurations, showing consistent advantages in\nterms of predictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:51:40 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "2005.05304", "submitter": "Zhuo Ma", "authors": "Zhuzhu Wang, Yilong Yang, Yang Liu, Ximeng Liu, Brij B. Gupta,\n  Jianfeng Ma", "title": "Cloud-based Federated Boosting for Mobile Crowdsensing", "comments": "17 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1907.10218", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of federated extreme gradient boosting to mobile crowdsensing\napps brings several benefits, in particular high performance on efficiency and\nclassification. However, it also brings a new challenge for data and model\nprivacy protection. Besides it being vulnerable to Generative Adversarial\nNetwork (GAN) based user data reconstruction attack, there is not the existing\narchitecture that considers how to preserve model privacy. In this paper, we\npropose a secret sharing based federated learning architecture FedXGB to\nachieve the privacy-preserving extreme gradient boosting for mobile\ncrowdsensing. Specifically, we first build a secure classification and\nregression tree (CART) of XGBoost using secret sharing. Then, we propose a\nsecure prediction protocol to protect the model privacy of XGBoost in mobile\ncrowdsensing. We conduct a comprehensive theoretical analysis and extensive\nexperiments to evaluate the security, effectiveness, and efficiency of FedXGB.\nThe results indicate that FedXGB is secure against the honest-but-curious\nadversaries and attains less than 1% accuracy loss compared with the original\nXGBoost model.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 08:49:01 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Wang", "Zhuzhu", ""], ["Yang", "Yilong", ""], ["Liu", "Yang", ""], ["Liu", "Ximeng", ""], ["Gupta", "Brij B.", ""], ["Ma", "Jianfeng", ""]]}, {"id": "2005.05321", "submitter": "Brian Kim", "authors": "Brian Kim, Yalin E. Sagduyu, Kemal Davaslioglu, Tugba Erpek, Sennur\n  Ulukus", "title": "Channel-Aware Adversarial Attacks Against Deep Learning-Based Wireless\n  Signal Classifiers", "comments": "Submitted for publication. arXiv admin note: substantial text overlap\n  with arXiv:2002.02400", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents channel-aware adversarial attacks against deep\nlearning-based wireless signal classifiers. There is a transmitter that\ntransmits signals with different modulation types. A deep neural network is\nused at each receiver to classify its over-the-air received signals to\nmodulation types. In the meantime, an adversary transmits an adversarial\nperturbation (subject to a power budget) to fool receivers into making errors\nin classifying signals that are received as superpositions of transmitted\nsignals and adversarial perturbations. First, these evasion attacks are shown\nto fail when channels are not considered in designing adversarial\nperturbations. Then, realistic attacks are presented by considering channel\neffects from the adversary to each receiver. After showing that a channel-aware\nattack is selective (i.e., it affects only the receiver whose channel is\nconsidered in the perturbation design), a broadcast adversarial attack is\npresented by crafting a common adversarial perturbation to simultaneously fool\nclassifiers at different receivers. The major vulnerability of modulation\nclassifiers to over-the-air adversarial attacks is shown by accounting for\ndifferent levels of information available about the channel, the transmitter\ninput, and the classifier model. Finally, a certified defense based on\nrandomized smoothing that augments training data with noise is introduced to\nmake the modulation classifier robust to adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 15:42:54 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 20:24:36 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Kim", "Brian", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Erpek", "Tugba", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2005.05385", "submitter": "Murat Yildirim", "authors": "Suleyman Yildirim, Alper Ekrem Murat, Murat Yildirim, Suzan Arslanturk", "title": "Process Knowledge Driven Change Point Detection for Automated\n  Calibration of Discrete Event Simulation Models Using Machine Learning", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initial development and subsequent calibration of discrete event simulation\nmodels for complex systems require accurate identification of dynamically\nchanging process characteristics. Existing data driven change point methods\n(DD-CPD) assume changes are extraneous to the system, thus cannot utilize\navailable process knowledge. This work proposes a unified framework for\nprocess-driven multi-variate change point detection (PD-CPD) by combining\nchange point detection models with machine learning and process-driven\nsimulation modeling. The PD-CPD, after initializing with DD-CPD's change\npoint(s), uses simulation models to generate system level outputs as\ntime-series data streams which are then used to train neural network models to\npredict system characteristics and change points. The accuracy of the\npredictive models measures the likelihood that the actual process data conforms\nto the simulated change points in system characteristics. PD-CPD iteratively\noptimizes change points by repeating simulation and predictive model building\nsteps until the set of change point(s) with the maximum likelihood is\nidentified. Using an emergency department case study, we show that PD-CPD\nsignificantly improves change point detection accuracy over DD-CPD estimates\nand is able to detect actual change points.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 19:07:26 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 04:24:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yildirim", "Suleyman", ""], ["Murat", "Alper Ekrem", ""], ["Yildirim", "Murat", ""], ["Arslanturk", "Suzan", ""]]}, {"id": "2005.05407", "submitter": "Yuhong Guo", "authors": "Yan Yan, Yuhong Guo", "title": "Multi-Level Generative Models for Partial Label Learning with Non-random\n  Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial label (PL) learning tackles the problem where each training instance\nis associated with a set of candidate labels that include both the true label\nand irrelevant noise labels. In this paper, we propose a novel multi-level\ngenerative model for partial label learning (MGPLL), which tackles the problem\nby learning both a label level adversarial generator and a feature level\nadversarial generator under a bi-directional mapping framework between the\nlabel vectors and the data samples. Specifically, MGPLL uses a conditional\nnoise label generation network to model the non-random noise labels and perform\nlabel denoising, and uses a multi-class predictor to map the training instances\nto the denoised label vectors, while a conditional data feature generator is\nused to form an inverse mapping from the denoised label vectors to data\nsamples. Both the noise label generator and the data feature generator are\nlearned in an adversarial manner to match the observed candidate labels and\ndata features respectively. Extensive experiments are conducted on synthesized\nand real-world partial label datasets. The proposed approach demonstrates the\nstate-of-the-art performance for partial label learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:13:19 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Yan", "Yan", ""], ["Guo", "Yuhong", ""]]}, {"id": "2005.05409", "submitter": "Lorenz Richter", "authors": "Nikolas N\\\"usken, Lorenz Richter", "title": "Solving high-dimensional Hamilton-Jacobi-Bellman PDEs using neural\n  networks: perspectives from the theory of controlled diffusions and measures\n  on path space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal control of diffusion processes is intimately connected to the problem\nof solving certain Hamilton-Jacobi-Bellman equations. Building on recent\nmachine learning inspired approaches towards high-dimensional PDEs, we\ninvestigate the potential of iterative diffusion optimisation techniques, in\nparticular considering applications in importance sampling and rare event\nsimulation. The choice of an appropriate loss function being a central element\nin the algorithmic design, we develop a principled framework based on\ndivergences between path measures, encompassing various existing methods.\nMotivated by connections to forward-backward SDEs, we propose and study the\nnovel log-variance divergence, showing favourable properties of corresponding\nMonte Carlo estimators. The promise of the developed approach is exemplified by\na range of high-dimensional and metastable numerical examples.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:14:02 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["N\u00fcsken", "Nikolas", ""], ["Richter", "Lorenz", ""]]}, {"id": "2005.05440", "submitter": "Baiming Chen", "authors": "Baiming Chen, Mengdi Xu, Liang Li, Ding Zhao", "title": "Delay-Aware Model-Based Reinforcement Learning for Continuous Control", "comments": null, "journal-ref": "Neurocomputing Volume 450, 25 August 2021, Pages 119-128", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action delays degrade the performance of reinforcement learning in many\nreal-world systems. This paper proposes a formal definition of delay-aware\nMarkov Decision Process and proves it can be transformed into standard MDP with\naugmented states using the Markov reward process. We develop a delay-aware\nmodel-based reinforcement learning framework that can incorporate the\nmulti-step delay into the learned system models without learning effort.\nExperiments with the Gym and MuJoCo platforms show that the proposed\ndelay-aware model-based algorithm is more efficient in training and\ntransferable between systems with various durations of delay compared with\noff-policy model-free reinforcement learning methods. Codes available at:\nhttps://github.com/baimingc/dambrl.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:13:37 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Chen", "Baiming", ""], ["Xu", "Mengdi", ""], ["Li", "Liang", ""], ["Zhao", "Ding", ""]]}, {"id": "2005.05441", "submitter": "Baiming Chen", "authors": "Baiming Chen, Mengdi Xu, Zuxin Liu, Liang Li, Ding Zhao", "title": "Delay-Aware Multi-Agent Reinforcement Learning for Cooperative and\n  Competitive Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action and observation delays exist prevalently in the real-world\ncyber-physical systems which may pose challenges in reinforcement learning\ndesign. It is particularly an arduous task when handling multi-agent systems\nwhere the delay of one agent could spread to other agents. To resolve this\nproblem, this paper proposes a novel framework to deal with delays as well as\nthe non-stationary training issue of multi-agent tasks with model-free deep\nreinforcement learning. We formally define the Delay-Aware Markov Game that\nincorporates the delays of all agents in the environment. To solve Delay-Aware\nMarkov Games, we apply centralized training and decentralized execution that\nallows agents to use extra information to ease the non-stationarity issue of\nthe multi-agent systems during training, without the need of a centralized\ncontroller during execution. Experiments are conducted in multi-agent particle\nenvironments including cooperative communication, cooperative navigation, and\ncompetitive experiments. We also test the proposed algorithm in traffic\nscenarios that require coordination of all autonomous vehicles to show the\npractical value of delay-awareness. Results show that the proposed delay-aware\nmulti-agent reinforcement learning algorithm greatly alleviates the performance\ndegradation introduced by delay. Codes and demo videos are available at:\nhttps://github.com/baimingc/delay-aware-MARL.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:21:50 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 01:27:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chen", "Baiming", ""], ["Xu", "Mengdi", ""], ["Liu", "Zuxin", ""], ["Li", "Liang", ""], ["Zhao", "Ding", ""]]}, {"id": "2005.05496", "submitter": "Saeid Asgari Taghanaki", "authors": "Saeid Asgari Taghanaki, Mohammad Havaei, Alex Lamb, Aditya Sanghi, Ara\n  Danielyan, Tonya Custis", "title": "Jigsaw-VAE: Towards Balancing Features in Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The latent variables learned by VAEs have seen considerable interest as an\nunsupervised way of extracting features, which can then be used for downstream\ntasks. There is a growing interest in the question of whether features learned\non one environment will generalize across different environments. We\ndemonstrate here that VAE latent variables often focus on some factors of\nvariation at the expense of others - in this case we refer to the features as\n``imbalanced''. Feature imbalance leads to poor generalization when the latent\nvariables are used in an environment where the presence of features changes.\nSimilarly, latent variables trained with imbalanced features induce the VAE to\ngenerate less diverse (i.e. biased towards dominant features) samples. To\naddress this, we propose a regularization scheme for VAEs, which we show\nsubstantially addresses the feature imbalance problem. We also introduce a\nsimple metric to measure the balance of features in generated images.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 00:46:54 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Taghanaki", "Saeid Asgari", ""], ["Havaei", "Mohammad", ""], ["Lamb", "Alex", ""], ["Sanghi", "Aditya", ""], ["Danielyan", "Ara", ""], ["Custis", "Tonya", ""]]}, {"id": "2005.05502", "submitter": "Rui Wang", "authors": "Eliza Huang, Rui Wang, Uma Chandrasekaran, Rose Yu", "title": "Aortic Pressure Forecasting with Deep Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean aortic pressure (MAP) is a major determinant of perfusion in all organs\nsystems. The ability to forecast MAP would enhance the ability of physicians to\nestimate prognosis of the patient and assist in early detection of hemodynamic\ninstability. However, forecasting MAP is challenging because the blood pressure\n(BP) time series is noisy and can be highly non-stationary. The aim of this\nstudy was to forecast the mean aortic pressure five minutes in advance, using\nthe 25 Hz time series data of previous five minutes as input. We provide a\nbenchmark study of different deep learning models for BP forecasting. We\ninvestigate a left ventricular dwelling transvalvular micro-axial device, the\nImpella, in patients undergoing high-risk percutaneous intervention. The\nImpella provides hemodynamic support, thus aiding in native heart function\nrecovery. It is also equipped with pressure sensors to capture high frequency\nMAP measurements at origin, instead of peripherally. Our dataset and the\nclinical application is novel in the BP forecasting field. We performed a\ncomprehensive study on time series with increasing, decreasing, and stationary\ntrends. The experiments show that recurrent neural networks with Legendre\nMemory Unit achieve the best performance with an overall forecasting error of\n1.8 mmHg.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:07:25 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 21:47:58 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 18:53:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Huang", "Eliza", ""], ["Wang", "Rui", ""], ["Chandrasekaran", "Uma", ""], ["Yu", "Rose", ""]]}, {"id": "2005.05506", "submitter": "Eugene Katsevich", "authors": "Eugene Katsevich and Aaditya Ramdas", "title": "On the power of conditional independence testing under model-X", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For testing conditional independence (CI) of a response Y and a predictor X\ngiven covariates Z, the recently introduced model-X (MX) framework has been the\nsubject of active methodological research, especially in the context of MX\nknockoffs and their successful application to genome-wide association studies.\nIn this paper, we study the power of MX CI tests, yielding quantitative\nexplanations for empirically observed phenomena and novel insights to guide the\ndesign of MX methodology. We show that any valid MX CI test must also be valid\nconditionally on Y and Z; this conditioning allows us to reformulate the\nproblem as testing a point null hypothesis involving the conditional\ndistribution of X. The Neyman-Pearson lemma then implies that the conditional\nrandomization test (CRT) based on a likelihood statistic is the most powerful\nMX CI test against a point alternative. We also obtain a related optimality\nresult for MX knockoffs. Switching to an asymptotic framework with arbitrarily\ngrowing covariate dimension, we derive an expression for the limiting power of\nthe CRT against local semiparametric alternatives in terms of the prediction\nerror of the machine learning algorithm on which its test statistic is based.\nFinally, we exhibit a resampling-free test with uniform asymptotic Type-I error\ncontrol under the assumption that only the first two moments of X given Z are\nknown, a significant relaxation of the MX assumption.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:24:25 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 16:06:32 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 20:08:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Katsevich", "Eugene", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2005.05541", "submitter": "Shiyu Duan", "authors": "Shiyu Duan, Shujian Yu, Jose Principe", "title": "Modularizing Deep Learning via Pairwise Learning With Kernels", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By redefining the conventional notions of layers, we present an alternative\nview on finitely wide, fully trainable deep neural networks as stacked linear\nmodels in feature spaces, leading to a kernel machine interpretation. Based on\nthis construction, we then propose a provably optimal modular learning\nframework for classification that does not require between-module\nbackpropagation. This modular approach brings new insights into the label\nrequirement of deep learning: It leverages only implicit pairwise labels (weak\nsupervision) when learning the hidden modules. When training the output module,\non the other hand, it requires full supervision but achieves high label\nefficiency, needing as few as 10 randomly selected labeled examples (one from\neach class) to achieve 94.88% accuracy on CIFAR-10 using a ResNet-18 backbone.\nMoreover, modular training enables fully modularized deep learning workflows,\nwhich then simplify the design and implementation of pipelines and improve the\nmaintainability and reusability of models. To showcase the advantages of such a\nmodularized workflow, we describe a simple yet reliable method for estimating\nreusability of pre-trained modules as well as task transferability in a\ntransfer learning setting. At practically no computation overhead, it precisely\ndescribed the task space structure of 15 binary classification tasks from\nCIFAR-10.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 04:19:37 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 18:09:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Duan", "Shiyu", ""], ["Yu", "Shujian", ""], ["Principe", "Jose", ""]]}, {"id": "2005.05546", "submitter": "Yoonkyung Lee", "authors": "Jiae Kim, Yoonkyung Lee and Zhiyu Liang", "title": "The Geometry of Nonlinear Embeddings in Kernel Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisher's linear discriminant analysis is a classical method for\nclassification, yet it is limited to capturing linear features only. Kernel\ndiscriminant analysis as an extension is known to successfully alleviate the\nlimitation through a nonlinear feature mapping. We study the geometry of\nnonlinear embeddings in discriminant analysis with polynomial kernels and\nGaussian kernel by identifying the population-level discriminant function that\ndepends on the data distribution and the kernel. In order to obtain the\ndiscriminant function, we solve a generalized eigenvalue problem with\nbetween-class and within-class covariance operators. The polynomial\ndiscriminants are shown to capture the class difference through the population\nmoments explicitly. For approximation of the Gaussian discriminant, we use a\nparticular representation of the Gaussian kernel by utilizing the exponential\ngenerating function for Hermite polynomials. We also show that the Gaussian\ndiscriminant can be approximated using randomized projections of the data. Our\nresults illuminate how the data distribution and the kernel interact in\ndetermination of the nonlinear embedding for discrimination, and provide a\nguideline for choice of the kernel and its parameters.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 04:46:31 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Kim", "Jiae", ""], ["Lee", "Yoonkyung", ""], ["Liang", "Zhiyu", ""]]}, {"id": "2005.05556", "submitter": "Zhe Liu", "authors": "Zhe Liu, Yun Li, Lina Yao, Xianzhi Wang and Feiping Nie", "title": "Agglomerative Neural Networks for Multi-view Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional multi-view clustering methods seek for a view consensus through\nminimizing the pairwise discrepancy between the consensus and subviews.\nHowever, the pairwise comparison cannot portray the inter-view relationship\nprecisely if some of the subviews can be further agglomerated. To address the\nabove challenge, we propose the agglomerative analysis to approximate the\noptimal consensus view, thereby describing the subview relationship within a\nview structure. We present Agglomerative Neural Network (ANN) based on\nConstrained Laplacian Rank to cluster multi-view data directly while avoiding a\ndedicated postprocessing step (e.g., using K-means). We further extend ANN with\nlearnable data space to handle data of complex scenarios. Our evaluations\nagainst several state-of-the-art multi-view clustering approaches on four\npopular datasets show the promising view-consensus analysis ability of ANN. We\nfurther demonstrate ANN's capability in analyzing complex view structures and\nextensibility in our case study and explain its robustness and effectiveness of\ndata-driven modifications.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 05:39:10 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Liu", "Zhe", ""], ["Li", "Yun", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Nie", "Feiping", ""]]}, {"id": "2005.05587", "submitter": "Nils Jansen", "authors": "Dennis Gross, Nils Jansen, Guillermo A. P\\'erez, Stephan Raaijmakers", "title": "Robustness Verification for Classifier Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a formal verification procedure that decides whether a classifier\nensemble is robust against arbitrary randomized attacks. Such attacks consist\nof a set of deterministic attacks and a distribution over this set. The\nrobustness-checking problem consists of assessing, given a set of classifiers\nand a labelled data set, whether there exists a randomized attack that induces\na certain expected loss against all classifiers. We show the NP-hardness of the\nproblem and provide an upper bound on the number of attacks that is sufficient\nto form an optimal randomized attack. These results provide an effective way to\nreason about the robustness of a classifier ensemble. We provide SMT and MILP\nencodings to compute optimal randomized attacks or prove that there is no\nattack inducing a certain expected loss. In the latter case, the classifier\nensemble is provably robust. Our prototype implementation verifies multiple\nneural-network ensembles trained for image-classification tasks. The\nexperimental results using the MILP encoding are promising both in terms of\nscalability and the general applicability of our verification procedure.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 07:38:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 07:43:16 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Gross", "Dennis", ""], ["Jansen", "Nils", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raaijmakers", "Stephan", ""]]}, {"id": "2005.05628", "submitter": "Claire Boyer", "authors": "Pascaline Descloux (UNIGE), Claire Boyer (LPSM UMR 8001), Julie Josse\n  (CMAP), Aude Sportisse (LPSM (UMR\\_8001)), Sylvain Sardy", "title": "Robust Lasso-Zero for sparse corruption and model selection with missing\n  covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Robust Lasso-Zero, an extension of the Lasso-Zero methodology\n[Descloux and Sardy, 2018], initially introduced for sparse linear models, to\nthe sparse corruptions problem. We give theoretical guarantees on the sign\nrecovery of the parameters for a slightly simplified version of the estimator,\ncalled Thresholded Justice Pursuit. The use of Robust Lasso-Zero is showcased\nfor variable selection with missing values in the covariates. In addition to\nnot requiring the specification of a model for the covariates, nor estimating\ntheir covariance matrix or the noise variance, the method has the great\nadvantage of handling missing not-at random values without specifying a\nparametric model. Numerical experiments and a medical application underline the\nrelevance of Robust Lasso-Zero in such a context with few available\ncompetitors. The method is easy to use and implemented in the R library lass0.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 09:05:46 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Descloux", "Pascaline", "", "UNIGE"], ["Boyer", "Claire", "", "LPSM UMR 8001"], ["Josse", "Julie", "", "CMAP"], ["Sportisse", "Aude", "", "LPSM"], ["Sardy", "Sylvain", ""]]}, {"id": "2005.05645", "submitter": "Pierre-Yves Masse", "authors": "Pierre-Yves Mass\\'e (CTU), Yann Ollivier (FAIR)", "title": "Convergence of Online Adaptive and Recurrent Optimization Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove local convergence of several notable gradient descent algorithms\nused in machine learning, for which standard stochastic gradient descent theory\ndoes not apply directly. This includes, first, online algorithms for recurrent\nmodels and dynamical systems, such as \\emph{Real-time recurrent learning}\n(RTRL) and its computationally lighter approximations NoBackTrack and UORO;\nsecond, several adaptive algorithms such as RMSProp, online natural gradient,\nand Adam with $\\beta^2\\to 1$.Despite local convergence being a relatively weak\nrequirement for a new optimization algorithm, no local analysis was available\nfor these algorithms, as far as we knew. Analysis of these algorithms does not\nimmediately follow from standard stochastic gradient (SGD) theory. In fact,\nAdam has been proved to lack local convergence in some simple situations\n\\citep{j.2018on}. For recurrent models, online algorithms modify the parameter\nwhile the model is running, which further complicates the analysis with respect\nto simple SGD.Local convergence for these various algorithms results from a\nsingle, more general set of assumptions, in the setup of learning dynamical\nsystems online. Thus, these results can cover other variants of the algorithms\nconsidered.We adopt an \"ergodic\" rather than probabilistic viewpoint, working\nwith empirical time averages instead of probability distributions. This is more\ndata-agnostic and creates differences with respect to standard SGD theory,\nespecially for the range of possible learning rates. For instance, with cycling\nor per-epoch reshuffling over a finite dataset instead of pure i.i.d.\\ sampling\nwith replacement, empirical averages of gradients converge at rate $1/T$\ninstead of $1/\\sqrt{T}$ (cycling acts as a variance reduction method),\ntheoretically allowing for larger learning rates than in SGD.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 09:48:52 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 09:11:45 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Mass\u00e9", "Pierre-Yves", "", "CTU"], ["Ollivier", "Yann", "", "FAIR"]]}, {"id": "2005.05684", "submitter": "Xinting Zhu", "authors": "Xinting Zhu and Lishuai Li", "title": "Flight Time Prediction for Fuel Loading Decisions with a Deep Learning\n  Approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.trc.2021.103179", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under increasing economic and environmental pressure, airlines are constantly\nseeking new technologies and optimizing flight operations to reduce fuel\nconsumption. However, the current practice on fuel loading, which has a\nsignificant impact on aircraft weight and fuel consumption, has yet to be\nthoroughly addressed by existing studies. Excess fuel is loaded by dispatchers\nand (or) pilots to handle fuel consumption uncertainties, primarily caused by\nflight time uncertainties, which cannot be predicted by current Flight Planning\nSystems. In this paper, we develop a novel spatial weighted recurrent neural\nnetwork model to provide better flight time predictions by capturing air\ntraffic information at a national scale based on multiple data sources,\nincluding Automatic Dependent Surveillance-Broadcast, Meteorological Aerodrome\nReports, and airline records. In this model, a spatial weighted layer is\ndesigned to extract spatial dependences among network delay states. Then, a new\ntraining procedure associated with the spatial weighted layer is introduced to\nextract OD-specific spatial weights. Long short-term memory networks are used\nto extract the temporal behavior patterns of network delay states. Finally,\nfeatures from delays, weather, and flight schedules are fed into a fully\nconnected neural network to predict the flight time of a particular flight. The\nproposed model was evaluated using one year of historical data from an\nairline's real operations. Results show that our model can provide more\naccurate flight time predictions than baseline methods, especially for flights\nwith extreme delays. We also show that, with the improved flight time\nprediction, fuel loading can be optimized and resulting in reduced fuel\nconsumption by 0.016%-1.915% without increasing the fuel depletion risk.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 11:05:42 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 07:29:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhu", "Xinting", ""], ["Li", "Lishuai", ""]]}, {"id": "2005.05704", "submitter": "Dania Humaidan", "authors": "Dania Humaidan, Sebastian Otte, Martin V. Butz", "title": "Fostering Event Compression using Gated Surprise", "comments": "submitted to ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our brain receives a dynamically changing stream of sensorimotor data. Yet,\nwe perceive a rather organized world, which we segment into and perceive as\nevents. Computational theories of cognitive science on event-predictive\ncognition suggest that our brain forms generative, event-predictive models by\nsegmenting sensorimotor data into suitable chunks of contextual experiences.\nHere, we introduce a hierarchical, surprise-gated recurrent neural network\narchitecture, which models this process and develops compact compressions of\ndistinct event-like contexts. The architecture contains a contextual LSTM\nlayer, which develops generative compressions of ongoing and subsequent\ncontexts. These compressions are passed into a GRU-like layer, which uses\nsurprise signals to update its recurrent latent state. The latent state is\npassed forward into another LSTM layer, which processes actual dynamic sensory\nflow in the light of the provided latent, contextual compression signals. Our\nmodel shows to develop distinct event compressions and achieves the best\nperformance on multiple event processing tasks. The architecture may be very\nuseful for the further development of resource-efficient learning, hierarchical\nmodel-based reinforcement learning, as well as the development of artificial\nevent-predictive cognition and intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 11:57:46 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Humaidan", "Dania", ""], ["Otte", "Sebastian", ""], ["Butz", "Martin V.", ""]]}, {"id": "2005.05716", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Nika Er\\v{z}en, Shane Sheehan, Saturnino Luz,\n  Marko Robnik-\\v{S}ikonja, Senja Pollak", "title": "AttViz: Online exploration of self-attention for transparent neural\n  language modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models are becoming the prevailing methodology for the tasks\nof query answering, text classification, disambiguation, completion and\ntranslation. Commonly comprised of hundreds of millions of parameters, these\nneural network models offer state-of-the-art performance at the cost of\ninterpretability; humans are no longer capable of tracing and understanding how\ndecisions are being made. The attention mechanism, introduced initially for the\ntask of translation, has been successfully adopted for other language-related\ntasks. We propose AttViz, an online toolkit for exploration of\nself-attention---real values associated with individual text tokens. We show\nhow existing deep learning pipelines can produce outputs suitable for AttViz,\noffering novel visualizations of the attention heads and their aggregations\nwith minimal effort, online. We show on examples of news segments how the\nproposed system can be used to inspect and potentially better understand what a\nmodel has learned (or emphasized).\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:21:40 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Er\u017een", "Nika", ""], ["Sheehan", "Shane", ""], ["Luz", "Saturnino", ""], ["Robnik-\u0160ikonja", "Marko", ""], ["Pollak", "Senja", ""]]}, {"id": "2005.05719", "submitter": "Antonin Raffin", "authors": "Antonin Raffin, Jens Kober, Freek Stulp", "title": "Smooth Exploration for Robotic Reinforcement Learning", "comments": "Code: https://github.com/DLR-RM/stable-baselines3/ Training scripts:\n  https://github.com/DLR-RM/rl-baselines3-zoo/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Reinforcement learning (RL) enables robots to learn skills from interactions\nwith the real world. In practice, the unstructured step-based exploration used\nin Deep RL -- often very successful in simulation -- leads to jerky motion\npatterns on real robots. Consequences of the resulting shaky behavior are poor\nexploration, or even damage to the robot. We address these issues by adapting\nstate-dependent exploration (SDE) to current Deep RL algorithms. To enable this\nadaptation, we propose two extensions to the original SDE, using more general\nfeatures and re-sampling the noise periodically, which leads to a new\nexploration method generalized state-dependent exploration (gSDE). We evaluate\ngSDE both in simulation, on PyBullet continuous control tasks, and directly on\nthree different real robots: a tendon-driven elastic robot, a quadruped and an\nRC car. The noise sampling interval of gSDE permits to have a compromise\nbetween performance and smoothness, which allows training directly on the real\nrobots without loss of performance. The code is available at\nhttps://github.com/DLR-RM/stable-baselines3.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:28:25 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 09:49:35 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Raffin", "Antonin", ""], ["Kober", "Jens", ""], ["Stulp", "Freek", ""]]}, {"id": "2005.05750", "submitter": "George Adam", "authors": "George Adam and Romain Speciel", "title": "Evaluating Ensemble Robustness Against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples, which are slightly perturbed inputs generated with the\naim of fooling a neural network, are known to transfer between models;\nadversaries which are effective on one model will often fool another. This\nconcept of transferability poses grave security concerns as it leads to the\npossibility of attacking models in a black box setting, during which the\ninternal parameters of the target model are unknown. In this paper, we seek to\nanalyze and minimize the transferability of adversaries between models within\nan ensemble. To this end, we introduce a gradient based measure of how\neffectively an ensemble's constituent models collaborate to reduce the space of\nadversarial examples targeting the ensemble itself. Furthermore, we demonstrate\nthat this measure can be utilized during training as to increase an ensemble's\nrobustness to adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:20:54 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Adam", "George", ""], ["Speciel", "Romain", ""]]}, {"id": "2005.05784", "submitter": "Mengjia Xu", "authors": "Mengjia Xu, David Lopez Sanz, Pilar Garces, Fernando Maestu, Quanzheng\n  Li, Dimitrios Pantazis", "title": "A Graph Gaussian Embedding Method for Predicting Alzheimer's Disease\n  Progression with MEG Brain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the subtle changes of functional brain networks associated\nwith the pathological cascade of Alzheimer's disease (AD) is important for\nearly diagnosis and prediction of disease progression prior to clinical\nsymptoms. We developed a new deep learning method, termed multiple graph\nGaussian embedding model (MG2G), which can learn highly informative network\nfeatures by mapping high-dimensional resting-state brain networks into a\nlow-dimensional latent space. These latent distribution-based embeddings enable\na quantitative characterization of subtle and heterogeneous brain connectivity\npatterns at different regions and can be used as input to traditional\nclassifiers for various downstream graph analytic tasks, such as AD early stage\nprediction, and statistical evaluation of between-group significant alterations\nacross brain regions. We used MG2G to detect the intrinsic latent\ndimensionality of MEG brain networks, predict the progression of patients with\nmild cognitive impairment (MCI) to AD, and identify brain regions with network\nalterations related to MCI.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 02:29:24 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 21:00:39 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Xu", "Mengjia", ""], ["Sanz", "David Lopez", ""], ["Garces", "Pilar", ""], ["Maestu", "Fernando", ""], ["Li", "Quanzheng", ""], ["Pantazis", "Dimitrios", ""]]}, {"id": "2005.05802", "submitter": "Rick Mukherjee", "authors": "Rick Mukherjee, Harry Xie, and Florian Mintert", "title": "Bayesian optimal control of GHZ states in Rydberg lattices", "comments": "4+2 pages, 5+2 figures", "journal-ref": "Phys. Rev. Lett. 125, 203603 (2020)", "doi": "10.1103/PhysRevLett.125.203603", "report-no": null, "categories": "quant-ph physics.atom-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to prepare non-classical states in a robust manner is essential\nfor quantum sensors beyond the standard quantum limit. We demonstrate that\nBayesian optimal control is capable of finding control pulses that drive\ntrapped Rydberg atoms into highly entangled GHZ states. The control sequences\nhave a physically intuitive functionality based on the quasi-integrability of\nthe Ising dynamics. They can be constructed in laboratory experiments resulting\nin preparation times that scale very favourably with the system size.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:15:23 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 10:00:57 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Mukherjee", "Rick", ""], ["Xie", "Harry", ""], ["Mintert", "Florian", ""]]}, {"id": "2005.05810", "submitter": "Lucas Baier", "authors": "Lucas Baier, Josua Reimold, Niklas K\\\"uhl", "title": "Handling Concept Drift for Predictions in Business Process Mining", "comments": null, "journal-ref": "Proceedings of 2020 IEEE 22nd Conference on Business Informatics\n  (CBI)", "doi": "10.1109/CBI49978.2020.00016", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive services nowadays play an important role across all business\nsectors. However, deployed machine learning models are challenged by changing\ndata streams over time which is described as concept drift. Prediction quality\nof models can be largely influenced by this phenomenon. Therefore, concept\ndrift is usually handled by retraining of the model. However, current research\nlacks a recommendation which data should be selected for the retraining of the\nmachine learning model. Therefore, we systematically analyze different data\nselection strategies in this work. Subsequently, we instantiate our findings on\na use case in process mining which is strongly affected by concept drift. We\ncan show that we can improve accuracy from 0.5400 to 0.7010 with concept drift\nhandling. Furthermore, we depict the effects of the different data selection\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:22:24 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 13:24:30 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Baier", "Lucas", ""], ["Reimold", "Josua", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2005.05837", "submitter": "Yancey Wang", "authors": "Yu Wang, Rong Ge and Shuang Qiu", "title": "Energy-Aware DNN Graph Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike existing work in deep neural network (DNN) graphs optimization for\ninference performance, we explore DNN graph optimization for energy awareness\nand savings for power- and resource-constrained machine learning devices. We\npresent a method that allows users to optimize energy consumption or balance\nbetween energy and inference performance for DNN graphs. This method\nefficiently searches through the space of equivalent graphs, and identifies a\ngraph and the corresponding algorithms that incur the least cost in execution.\nWe implement the method and evaluate it with multiple DNN models on a GPU-based\nmachine. Results show that our method achieves significant energy savings,\ni.e., 24% with negligible performance impact.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:56:19 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Wang", "Yu", ""], ["Ge", "Rong", ""], ["Qiu", "Shuang", ""]]}, {"id": "2005.05847", "submitter": "Yuan Sun", "authors": "Yuan Sun, Andreas Ernst, Xiaodong Li and Jake Weiner", "title": "Generalization of Machine Learning for Problem Reduction: A Case Study\n  on Travelling Salesman Problems", "comments": "Published as a regular article at OR Spectrum (https://rdcu.be/b6ECv)", "journal-ref": null, "doi": "10.1007/s00291-020-00604-x", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combinatorial optimization plays an important role in real-world problem\nsolving. In the big data era, the dimensionality of a combinatorial\noptimization problem is usually very large, which poses a significant challenge\nto existing solution methods. In this paper, we examine the generalization\ncapability of a machine learning model for problem reduction on the classic\ntravelling salesman problems (TSP). We demonstrate that our method can greedily\nremove decision variables from an optimization problem that are predicted not\nto be part of an optimal solution. More specifically, we investigate our\nmodel's capability to generalize on test instances that have not been seen\nduring the training phase. We consider three scenarios where training and test\ninstances are different in terms of: 1) problem characteristics; 2) problem\nsizes; and 3) problem types. Our experiments show that this machine learning\nbased technique can generalize reasonably well over a wide range of TSP test\ninstances with different characteristics or sizes. While the accuracy of\npredicting unused variables naturally deteriorates as a test instance is\nfurther away from the training set, we observe that even when tested on a\ndifferent TSP problem variant, the machine learning model still makes useful\npredictions about which variables can be eliminated without significantly\nimpacting solution quality.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:09:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 03:13:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Sun", "Yuan", ""], ["Ernst", "Andreas", ""], ["Li", "Xiaodong", ""], ["Weiner", "Jake", ""]]}, {"id": "2005.05862", "submitter": "Souvik Chakraborty", "authors": "Souvik Chakraborty and Sondipon Adhikari", "title": "Machine learning based digital twin for dynamical systems with multiple\n  time-scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital twin technology has a huge potential for widespread applications in\ndifferent industrial sectors such as infrastructure, aerospace, and automotive.\nHowever, practical adoptions of this technology have been slower, mainly due to\na lack of application-specific details. Here we focus on a digital twin\nframework for linear single-degree-of-freedom structural dynamic systems\nevolving in two different operational time scales in addition to its intrinsic\ndynamic time-scale. Our approach strategically separates into two components --\n(a) a physics-based nominal model for data processing and response predictions,\nand (b) a data-driven machine learning model for the time-evolution of the\nsystem parameters. The physics-based nominal model is system-specific and\nselected based on the problem under consideration. On the other hand, the\ndata-driven machine learning model is generic. For tracking the multi-scale\nevolution of the system parameters, we propose to exploit a mixture of experts\nas the data-driven model. Within the mixture of experts model, Gaussian Process\n(GP) is used as the expert model. The primary idea is to let each expert track\nthe evolution of the system parameters at a single time-scale. For learning the\nhyperparameters of the `mixture of experts using GP', an efficient framework\nthe exploits expectation-maximization and sequential Monte Carlo sampler is\nused. Performance of the digital twin is illustrated on a multi-timescale\ndynamical system with stiffness and/or mass variations. The digital twin is\nfound to be robust and yields reasonably accurate results. One exciting feature\nof the proposed digital twin is its capability to provide reasonable\npredictions at future time-steps. Aspects related to the data quality and data\nquantity are also investigated.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:33:25 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 05:12:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chakraborty", "Souvik", ""], ["Adhikari", "Sondipon", ""]]}, {"id": "2005.05865", "submitter": "Selim F{\\i}rat Y{\\i}lmaz", "authors": "Selim F. Yilmaz and Suleyman S. Kozat", "title": "Unsupervised Anomaly Detection via Deep Metric Learning with End-to-End\n  Optimization", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate unsupervised anomaly detection for high-dimensional data and\nintroduce a deep metric learning (DML) based framework. In particular, we learn\na distance metric through a deep neural network. Through this metric, we\nproject the data into the metric space that better separates the anomalies from\nthe normal data and reduces the effect of the curse of dimensionality for\nhigh-dimensional data. We present a novel data distillation method through\nself-supervision to remedy the conventional practice of assuming all data as\nnormal. We also employ the hard mining technique from the DML literature. We\nshow these components improve the performance of our model and significantly\nreduce the running time. Through an extensive set of experiments on the 14\nreal-world datasets, our method demonstrates significant performance gains\ncompared to the state-of-the-art unsupervised anomaly detection methods, e.g.,\nan absolute improvement between 4.44% and 11.74% on the average over the 14\ndatasets. Furthermore, we share the source code of our method on Github to\nfacilitate further research.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:36:21 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Yilmaz", "Selim F.", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2005.05889", "submitter": "Borja Rodr\\'iguez G\\'alvez", "authors": "Borja Rodr\\'iguez-G\\'alvez, Germ\\'an Bassi, and Mikael Skoglund", "title": "Upper Bounds on the Generalization Error of Private Algorithms", "comments": "31 pages, 2 figures, submitted for possible publication (revised)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we study the generalization capability of algorithms from an\ninformation-theoretic perspective. It has been shown that the expected\ngeneralization error of an algorithm is bounded from above by a function of the\nrelative entropy between the conditional probability distribution of the\nalgorithm's output hypothesis, given the dataset with which it was trained, and\nits marginal probability distribution. We build upon this fact and introduce a\nmathematical formulation to obtain upper bounds on this relative entropy. We\nthen develop a strategy using this formulation, based on the method of types\nand typicality, to find explicit upper bounds on the generalization error of\nstable algorithms, i.e., algorithms that produce similar output hypotheses\ngiven similar input datasets. In particular, we show the bounds obtained with\nthis strategy for the case of $\\epsilon$-DP and $\\mu$-GDP algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:05:39 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 17:27:24 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Rodr\u00edguez-G\u00e1lvez", "Borja", ""], ["Bassi", "Germ\u00e1n", ""], ["Skoglund", "Mikael", ""]]}, {"id": "2005.05898", "submitter": "Takayuki Katsuki", "authors": "Takayuki Katsuki, Kun Zhao, Takayuki Yoshizumi", "title": "Learning to Estimate Driver Drowsiness from Car Acceleration Sensors\n  using Weakly Labeled Data", "comments": "Accepted by ICASSP2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053100", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the learning task of estimating driver drowsiness from\nthe signals of car acceleration sensors. Since even drivers themselves cannot\nperceive their own drowsiness in a timely manner unless they use burdensome\ninvasive sensors, obtaining labeled training data for each timestamp is not a\nrealistic goal. To deal with this difficulty, we formulate the task as a weakly\nsupervised learning. We only need to add labels for each complete trip, not for\nevery timestamp independently. By assuming that some aspects of driver\ndrowsiness increase over time due to tiredness, we formulate an algorithm that\ncan learn from such weakly labeled data. We derive a scalable stochastic\noptimization method as a way of implementing the algorithm. Numerical\nexperiments on real driving datasets demonstrate the advantages of our\nalgorithm against baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:20:25 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Katsuki", "Takayuki", ""], ["Zhao", "Kun", ""], ["Yoshizumi", "Takayuki", ""]]}, {"id": "2005.05930", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Arnas Uselis, Mantas Luko\\v{s}evi\\v{c}ius, Lukas Stasytis", "title": "Localized convolutional neural networks for geospatial wind forecasting", "comments": null, "journal-ref": "Energies, 13 (13), pp. 3440, 2020", "doi": "10.3390/en13133440", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) possess many positive qualities when it\ncomes to spatial raster data. Translation invariance enables CNNs to detect\nfeatures regardless of their position in the scene. However, in some domains,\nlike geospatial, not all locations are exactly equal. In this work, we propose\nlocalized convolutional neural networks that enable convolutional architectures\nto learn local features in addition to the global ones. We investigate their\ninstantiations in the form of learnable inputs, local weights, and a more\ngeneral form. They can be added to any convolutional layers, easily end-to-end\ntrained, introduce minimal additional complexity, and let CNNs retain most of\ntheir benefits to the extent that they are needed. In this work we address\nspatio-temporal prediction: test the effectiveness of our methods on a\nsynthetic benchmark dataset and tackle three real-world wind prediction\ndatasets. For one of them, we propose a method to spatially order the unordered\ndata. We compare the recent state-of-the-art spatio-temporal prediction models\non the same data. Models that use convolutional layers can be and are extended\nwith our localizations. In all these cases our extensions improve the results,\nand thus often the state-of-the-art. We share all the code at a public\nrepository.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:14:49 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 14:56:21 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 16:13:17 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Uselis", "Arnas", ""], ["Luko\u0161evi\u010dius", "Mantas", ""], ["Stasytis", "Lukas", ""]]}, {"id": "2005.05941", "submitter": "Sneha Aenugu", "authors": "Sneha Aenugu", "title": "Training spiking neural networks using reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the brain communicate with each other through discrete action\nspikes as opposed to continuous signal transmission in artificial neural\nnetworks. Therefore, the traditional techniques for optimization of parameters\nin neural networks which rely on the assumption of differentiability of\nactivation functions are no longer applicable to modeling the learning\nprocesses in the brain. In this project, we propose biologically-plausible\nalternatives to backpropagation to facilitate the training of spiking neural\nnetworks. We primarily focus on investigating the candidacy of reinforcement\nlearning (RL) rules in solving the spatial and temporal credit assignment\nproblems to enable decision-making in complex tasks. In one approach, we\nconsider each neuron in a multi-layer neural network as an independent RL agent\nforming a different representation of the feature space while the network as a\nwhole forms the representation of the complex policy to solve the task at hand.\nIn other approach, we apply the reparameterization trick to enable\ndifferentiation through stochastic transformations in spiking neural networks.\nWe compare and contrast the two approaches by applying them to traditional RL\ndomains such as gridworld, cartpole and mountain car. Further we also suggest\nvariations and enhancements to enable future research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:40:36 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Aenugu", "Sneha", ""]]}, {"id": "2005.05951", "submitter": "Aravind Rajeswaran", "authors": "Rahul Kidambi, Aravind Rajeswaran, Praneeth Netrapalli, Thorsten\n  Joachims", "title": "MOReL : Model-Based Offline Reinforcement Learning", "comments": "First two authors contributed equally. Published at NeurIPS 2020.\n  After publication at NeurIPS 2020, (1) D4RL benchmark results have been\n  added; (2) hyper-parameter ablation studies have been added; (3) scope of\n  Lemma 3 has been extended", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In offline reinforcement learning (RL), the goal is to learn a highly\nrewarding policy based solely on a dataset of historical interactions with the\nenvironment. The ability to train RL policies offline can greatly expand the\napplicability of RL, its data efficiency, and its experimental velocity. Prior\nwork in offline RL has been confined almost exclusively to model-free RL\napproaches. In this work, we present MOReL, an algorithmic framework for\nmodel-based offline RL. This framework consists of two steps: (a) learning a\npessimistic MDP (P-MDP) using the offline dataset; and (b) learning a\nnear-optimal policy in this P-MDP. The learned P-MDP has the property that for\nany policy, the performance in the real environment is approximately\nlower-bounded by the performance in the P-MDP. This enables it to serve as a\ngood surrogate for purposes of policy evaluation and learning, and overcome\ncommon pitfalls of model-based RL like model exploitation. Theoretically, we\nshow that MOReL is minimax optimal (up to log factors) for offline RL. Through\nexperiments, we show that MOReL matches or exceeds state-of-the-art results in\nwidely studied offline RL benchmarks. Moreover, the modular design of MOReL\nenables future advances in its components (e.g. generative modeling,\nuncertainty estimation, planning etc.) to directly translate into advances for\noffline RL.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:52:43 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 19:00:20 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 04:35:04 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Kidambi", "Rahul", ""], ["Rajeswaran", "Aravind", ""], ["Netrapalli", "Praneeth", ""], ["Joachims", "Thorsten", ""]]}, {"id": "2005.05955", "submitter": "Rohun Tripathi", "authors": "Rohun Tripathi and Bharat Singh", "title": "RSO: A Gradient Free Sampling Based Approach For Training Deep Neural\n  Networks", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose RSO (random search optimization), a gradient free Markov Chain\nMonte Carlo search based approach for training deep neural networks. To this\nend, RSO adds a perturbation to a weight in a deep neural network and tests if\nit reduces the loss on a mini-batch. If this reduces the loss, the weight is\nupdated, otherwise the existing weight is retained. Surprisingly, we find that\nrepeating this process a few times for each weight is sufficient to train a\ndeep neural network. The number of weight updates for RSO is an order of\nmagnitude lesser when compared to backpropagation with SGD. RSO can make\naggressive weight updates in each step as there is no concept of learning rate.\nThe weight update step for individual layers is also not coupled with the\nmagnitude of the loss. RSO is evaluated on classification tasks on MNIST and\nCIFAR-10 datasets with deep neural networks of 6 to 10 layers where it achieves\nan accuracy of 99.1% and 81.8% respectively. We also find that after updating\nthe weights just 5 times, the algorithm obtains a classification accuracy of\n98% on MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:55:16 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Tripathi", "Rohun", ""], ["Singh", "Bharat", ""]]}, {"id": "2005.05960", "submitter": "Deepak Pathak", "authors": "Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar\n  Hafner, Deepak Pathak", "title": "Planning to Explore via Self-Supervised World Models", "comments": "Accepted at ICML 2020. Videos and code at\n  https://ramanans1.github.io/plan2explore/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning allows solving complex tasks, however, the learning\ntends to be task-specific and the sample efficiency remains a challenge. We\npresent Plan2Explore, a self-supervised reinforcement learning agent that\ntackles both these challenges through a new approach to self-supervised\nexploration and fast adaptation to new tasks, which need not be known during\nexploration. During exploration, unlike prior methods which retrospectively\ncompute the novelty of observations after the agent has already reached them,\nour agent acts efficiently by leveraging planning to seek out expected future\nnovelty. After exploration, the agent quickly adapts to multiple downstream\ntasks in a zero or a few-shot manner. We evaluate on challenging control tasks\nfrom high-dimensional image inputs. Without any training supervision or\ntask-specific interaction, Plan2Explore outperforms prior self-supervised\nexploration methods, and in fact, almost matches the performances oracle which\nhas access to rewards. Videos and code at\nhttps://ramanans1.github.io/plan2explore/\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:59:45 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 23:05:50 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Sekar", "Ramanan", ""], ["Rybkin", "Oleh", ""], ["Daniilidis", "Kostas", ""], ["Abbeel", "Pieter", ""], ["Hafner", "Danijar", ""], ["Pathak", "Deepak", ""]]}, {"id": "2005.06001", "submitter": "Greg Ongie", "authors": "Gregory Ongie, Ajil Jalal, Christopher A. Metzler, Richard G.\n  Baraniuk, Alexandros G. Dimakis, Rebecca Willett", "title": "Deep Learning Techniques for Inverse Problems in Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in machine learning shows that deep neural networks can be used\nto solve a wide variety of inverse problems arising in computational imaging.\nWe explore the central prevailing themes of this emerging area and present a\ntaxonomy that can be used to categorize different problems and reconstruction\nmethods. Our taxonomy is organized along two central axes: (1) whether or not a\nforward model is known and to what extent it is used in training and testing,\nand (2) whether or not the learning is supervised or unsupervised, i.e.,\nwhether or not the training relies on access to matched ground truth image and\nmeasurement pairs. We also discuss the trade-offs associated with these\ndifferent reconstruction approaches, caveats and common failure modes, plus\nopen problems and avenues for future work.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 18:35:55 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Ongie", "Gregory", ""], ["Jalal", "Ajil", ""], ["Metzler", "Christopher A.", ""], ["Baraniuk", "Richard G.", ""], ["Dimakis", "Alexandros G.", ""], ["Willett", "Rebecca", ""]]}, {"id": "2005.06038", "submitter": "Krishna Somandepalli", "authors": "Krishna Somandepalli and Shrikanth Narayanan", "title": "Generalized Multi-view Shared Subspace Learning using View Bootstrapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key objective in multi-view learning is to model the information common to\nmultiple parallel views of a class of objects/events to improve downstream\nlearning tasks. In this context, two open research questions remain: How can we\nmodel hundreds of views per event? Can we learn robust multi-view embeddings\nwithout any knowledge of how these views are acquired? We present a neural\nmethod based on multi-view correlation to capture the information shared across\na large number of views by subsampling them in a view-agnostic manner during\ntraining. To provide an upper bound on the number of views to subsample for a\ngiven embedding dimension, we analyze the error of the bootstrapped multi-view\ncorrelation objective using matrix concentration theory. Our experiments on\nspoken word recognition, 3D object classification and pose-invariant face\nrecognition demonstrate the robustness of view bootstrapping to model a large\nnumber of views. Results underscore the applicability of our method for a\nview-agnostic learning setting.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 20:35:14 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Somandepalli", "Krishna", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2005.06041", "submitter": "Brandon Houghton", "authors": "Brandon Houghton, Stephanie Milani, Nicholay Topin, William Guss,\n  Katja Hofmann, Diego Perez-Liebana, Manuela Veloso, Ruslan Salakhutdinov", "title": "Guaranteeing Reproducibility in Deep Learning Competitions", "comments": "Accepted as a poster presentation to the 2019 NeruIPS Challenges in\n  Machine Learning workshop (CiML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To encourage the development of methods with reproducible and robust training\nbehavior, we propose a challenge paradigm where competitors are evaluated\ndirectly on the performance of their learning procedures rather than\npre-trained agents. Since competition organizers re-train proposed methods in a\ncontrolled setting they can guarantee reproducibility, and -- by retraining\nsubmissions using a held-out test set -- help ensure generalization past the\nenvironments on which they were trained.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 20:43:05 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Houghton", "Brandon", ""], ["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Guss", "William", ""], ["Hofmann", "Katja", ""], ["Perez-Liebana", "Diego", ""], ["Veloso", "Manuela", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2005.06057", "submitter": "Joachim Meyer", "authors": "Salomon Eisler, Joachim Meyer", "title": "Visual Analytics and Human Involvement in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly developing AI systems and applications still require human\ninvolvement in practically all parts of the analytics process. Human decisions\nare largely based on visualizations, providing data scientists details of data\nproperties and the results of analytical procedures. Different visualizations\nare used in the different steps of the Machine Learning (ML) process. The\ndecision which visualization to use depends on factors, such as the data\ndomain, the data model and the step in the ML process. In this chapter, we\ndescribe the seven steps in the ML process and review different visualization\ntechniques that are relevant for the different steps for different types of\ndata, models and purposes.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:22:47 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Eisler", "Salomon", ""], ["Meyer", "Joachim", ""]]}, {"id": "2005.06059", "submitter": "Carlo Lipizzi", "authors": "Carlo Lipizzi, Dario Borrelli, Fernanda de Oliveira Capela", "title": "A computational model implementing subjectivity with the 'Room Theory'.\n  The case of detecting Emotion from Text", "comments": "15 pages, 9 figures, 3 Tables - Under second round of review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a new method to consider subjectivity and general\ncontext dependency in text analysis and uses as example the detection of\nemotions conveyed in text. The proposed method takes into account subjectivity\nusing a computational version of the Framework Theory by Marvin Minsky (1974)\nleveraging on the Word2Vec approach to text vectorization by Mikolov et al.\n(2013), used to generate distributed representation of words based on the\ncontext where they appear. Our approach is based on three components: 1. a\nframework/'room' representing the point of view; 2. a benchmark representing\nthe criteria for the analysis - in this case the emotion classification, from a\nstudy of human emotions by Robert Plutchik (1980); and 3. the document to be\nanalyzed. By using similarity measure between words, we are able to extract the\nrelative relevance of the elements in the benchmark - intensities of emotions\nin our case study - for the document to be analyzed. Our method provides a\nmeasure that take into account the point of view of the entity reading the\ndocument. This method could be applied to all the cases where evaluating\nsubjectivity is relevant to understand the relative value or meaning of a text.\nSubjectivity can be not limited to human reactions, but it could be used to\nprovide a text with an interpretation related to a given domain (\"room\"). To\nevaluate our method, we used a test case in the political domain.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:26:04 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Lipizzi", "Carlo", ""], ["Borrelli", "Dario", ""], ["Capela", "Fernanda de Oliveira", ""]]}, {"id": "2005.06061", "submitter": "Zhaoheng Yin", "authors": "Zhao-Heng Yin, Wu-Jun Li", "title": "TOMA: Topological Map Abstraction for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals are able to discover the topological map (graph) of surrounding\nenvironment, which will be used for navigation. Inspired by this biological\nphenomenon, researchers have recently proposed to generate graph representation\nfor Markov decision process (MDP) and use such graphs for planning in\nreinforcement learning (RL). However, existing graph generation methods suffer\nfrom many drawbacks. One drawback is that existing methods do not learn an\nabstraction for graphs, which results in high memory and computation cost. This\ndrawback also makes generated graph non-robust, which degrades the planning\nperformance. Another drawback is that existing methods cannot be used for\nfacilitating exploration which is important in RL. In this paper, we propose a\nnew method, called topological map abstraction (TOMA), for graph generation.\nTOMA can generate an abstract graph representation for MDP, which costs much\nless memory and computation cost than existing methods. Furthermore, TOMA can\nbe used for facilitating exploration. In particular, we propose planning to\nexplore, in which TOMA is used to accelerate exploration by guiding the agent\ntowards unexplored states. A novel experience replay module called vertex\nmemory is also proposed to improve exploration performance. Experimental\nresults show that TOMA can outperform existing methods to achieve the\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 05:24:47 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 11:12:44 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Yin", "Zhao-Heng", ""], ["Li", "Wu-Jun", ""]]}, {"id": "2005.06083", "submitter": "Sinong Geng", "authors": "Sinong Geng, Zhaobin Kuang, Jie Liu, Stephen Wright, David Page", "title": "Stochastic Learning for Sparse Discrete Markov Random Fields with\n  Controlled Gradient Approximation Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $L_1$-regularized maximum likelihood estimator/estimation (MLE)\nproblem for discrete Markov random fields (MRFs), where efficient and scalable\nlearning requires both sparse regularization and approximate inference. To\naddress these challenges, we consider a stochastic learning framework called\nstochastic proximal gradient (SPG; Honorio 2012a, Atchade et al.\n2014,Miasojedow and Rejchel 2016). SPG is an inexact proximal gradient\nalgorithm [Schmidtet al., 2011], whose inexactness stems from the stochastic\noracle (Gibbs sampling) for gradient approximation - exact gradient evaluation\nis infeasible in general due to the NP-hard inference problem for discrete MRFs\n[Koller and Friedman, 2009]. Theoretically, we provide novel verifiable bounds\nto inspect and control the quality of gradient approximation. Empirically, we\npropose the tighten asymptotically (TAY) learning strategy based on the\nverifiable bounds to boost the performance of SPG.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 22:48:42 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Geng", "Sinong", ""], ["Kuang", "Zhaobin", ""], ["Liu", "Jie", ""], ["Wright", "Stephen", ""], ["Page", "David", ""]]}, {"id": "2005.06092", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang, Honglei Zhuang, Shengyu Zhang, Yuan Zhou", "title": "Adaptive Double-Exploration Tradeoff for Outlier Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the thresholding bandit problem (TBP) in the context of\noutlier detection, where the objective is to identify the outliers whose\nrewards are above a threshold. Distinct from the traditional TBP, the threshold\nis defined as a function of the rewards of all the arms, which is motivated by\nthe criterion for identifying outliers. The learner needs to explore the\nrewards of the arms as well as the threshold. We refer to this problem as\n\"double exploration for outlier detection\". We construct an adaptively updated\nconfidence interval for the threshold, based on the estimated value of the\nthreshold in the previous rounds. Furthermore, by automatically trading off\nexploring the individual arms and exploring the outlier threshold, we provide\nan efficient algorithm in terms of the sample complexity. Experimental results\non both synthetic datasets and real-world datasets demonstrate the efficiency\nof our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 00:12:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhang", "Xiaojin", ""], ["Zhuang", "Honglei", ""], ["Zhang", "Shengyu", ""], ["Zhou", "Yuan", ""]]}, {"id": "2005.06095", "submitter": "Arun Kuchibhotla", "authors": "Arun Kumar Kuchibhotla", "title": "Exchangeability, Conformal Prediction, and Rank Tests", "comments": "Added reference to Shi et al. (2020, JASA). Corrected Theorem 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformal prediction has been a very popular method of distribution-free\npredictive inference in recent years in machine learning and statistics. Its\npopularity stems from the fact that it works as a wrapper around any prediction\nalgorithm such as neural networks or random forests. Exchangeability is at the\ncore of the validity of conformal prediction. The concept of exchangeability is\nalso at the core of rank tests widely known in nonparametric statistics. In\nthis paper, we review the concept of exchangeability and discuss the\nimplications for conformal prediction and rank tests. We provide a low-level\nintroduction to these topics, and discuss the similarities between conformal\nprediction and rank tests.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 00:39:45 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 16:12:48 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 01:35:40 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kuchibhotla", "Arun Kumar", ""]]}, {"id": "2005.06149", "submitter": "Yaxin Li", "authors": "Yaxin Li, Wei Jin, Han Xu, Jiliang Tang", "title": "DeepRobust: A PyTorch Library for Adversarial Attacks and Defenses", "comments": "Adversarial attacks and defenses, Pytorch library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepRobust is a PyTorch adversarial learning library which aims to build a\ncomprehensive and easy-to-use platform to foster this research field. It\ncurrently contains more than 10 attack algorithms and 8 defense algorithms in\nimage domain and 9 attack algorithms and 4 defense algorithms in graph domain,\nunder a variety of deep learning architectures. In this manual, we introduce\nthe main contents of DeepRobust with detailed instructions. The library is kept\nupdated and can be found at https://github.com/DSE-MSU/DeepRobust.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 04:43:46 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Li", "Yaxin", ""], ["Jin", "Wei", ""], ["Xu", "Han", ""], ["Tang", "Jiliang", ""]]}, {"id": "2005.06173", "submitter": "Kristian Miok", "authors": "Kristian Miok, Dong Nguyen-Doan, Marko Robnik-\\v{S}ikonja and Daniela\n  Zaharie", "title": "Multiple Imputation for Biomedical Data using Monte Carlo Dropout\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to complex experimental settings, missing values are common in biomedical\ndata. To handle this issue, many methods have been proposed, from ignoring\nincomplete instances to various data imputation approaches. With the recent\nrise of deep neural networks, the field of missing data imputation has oriented\ntowards modelling of the data distribution. This paper presents an approach\nbased on Monte Carlo dropout within (Variational) Autoencoders which offers not\nonly very good adaptation to the distribution of the data but also allows\ngeneration of new data, adapted to each specific instance. The evaluation shows\nthat the imputation error and predictive similarity can be improved with the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 06:28:13 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Miok", "Kristian", ""], ["Nguyen-Doan", "Dong", ""], ["Robnik-\u0160ikonja", "Marko", ""], ["Zaharie", "Daniela", ""]]}, {"id": "2005.06182", "submitter": "Hyuntae Lim", "authors": "Hyuntae Lim and YounJoon Jung", "title": "MLSolv-A: A Novel Machine Learning-Based Prediction of Solvation Free\n  Energies from Pairwise Atomistic Interactions", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.soft cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning and their applications have lead to the\ndevelopment of diverse structure-property relationship models for crucial\nchemical properties, and the solvation free energy is one of them. Here, we\nintroduce a novel ML-based solvation model, which calculates the solvation\nenergy from pairwise atomistic interactions. The novelty of the proposed model\nconsists of a simple architecture: two encoding functions extract atomic\nfeature vectors from the given chemical structure, while the inner product\nbetween two atomistic features calculates their interactions. The results on\n6,493 experimental measurements achieve outstanding performance and\ntransferability for enlarging training data due to its solvent-non-specific\nnature. Analysis of the interaction map shows there is a great potential that\nour model reproduces group contributions on the solvation energy, which makes\nus believe that the model not only provides the predicted target property but\nalso gives us more detailed physicochemical insights.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 06:53:54 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 13:18:02 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Lim", "Hyuntae", ""], ["Jung", "YounJoon", ""]]}, {"id": "2005.06194", "submitter": "Alex Wozniakowski", "authors": "Alex Wozniakowski, Jayne Thompson, Mile Gu, Felix Binder", "title": "Boosting on the shoulders of giants in quantum device calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine learning applications, such as optical character\nrecognition, arose from the inability to explicitly program a computer to\nperform a routine task. In this context, learning algorithms usually derive a\nmodel exclusively from the evidence present in a massive dataset. Yet in some\nscientific disciplines, obtaining an abundance of data is an impractical\nluxury, however; there is an explicit model of the domain based upon previous\nscientific discoveries. Here we introduce a new approach to machine learning\nthat is able to leverage prior scientific discoveries in order to improve\ngeneralizability over a scientific model. We show its efficacy in predicting\nthe entire energy spectrum of a Hamiltonian on a superconducting quantum\ndevice, a key task in present quantum computer calibration. Our accuracy\nsurpasses the current state-of-the-art by over $20\\%.$ Our approach thus\ndemonstrates how artificial intelligence can be further enhanced by \"standing\non the shoulders of giants.\"\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 07:59:57 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Wozniakowski", "Alex", ""], ["Thompson", "Jayne", ""], ["Gu", "Mile", ""], ["Binder", "Felix", ""]]}, {"id": "2005.06195", "submitter": "Isac Arnekvist", "authors": "Isac Arnekvist, J. Frederico Carvalho, Danica Kragic and Johannes A.\n  Stork", "title": "The effect of Target Normalization and Momentum on Dying ReLU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing parameters with momentum, normalizing data values, and using\nrectified linear units (ReLUs) are popular choices in neural network (NN)\nregression. Although ReLUs are popular, they can collapse to a constant\nfunction and \"die\", effectively removing their contribution from the model.\nWhile some mitigations are known, the underlying reasons of ReLUs dying during\noptimization are currently poorly understood. In this paper, we consider the\neffects of target normalization and momentum on dying ReLUs. We find\nempirically that unit variance targets are well motivated and that ReLUs die\nmore easily, when target variance approaches zero. To further investigate this\nmatter, we analyze a discrete-time linear autonomous system, and show\ntheoretically how this relates to a model with a single ReLU and how common\nproperties can result in dying ReLU. We also analyze the gradients of a\nsingle-ReLU model to identify saddle points and regions corresponding to dying\nReLU and how parameters evolve into these regions when momentum is used.\nFinally, we show empirically that this problem persist, and is aggravated, for\ndeeper models including residual networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 08:01:13 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Arnekvist", "Isac", ""], ["Carvalho", "J. Frederico", ""], ["Kragic", "Danica", ""], ["Stork", "Johannes A.", ""]]}, {"id": "2005.06247", "submitter": "Erika Puiutta", "authors": "Erika Puiutta and Eric MSP Veith", "title": "Explainable Reinforcement Learning: A Survey", "comments": "20 pages, 8 figures, 2 tables; submitted to CD-MAKE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI), i.e., the development of more\ntransparent and interpretable AI models, has gained increased traction over the\nlast few years. This is due to the fact that, in conjunction with their growth\ninto powerful and ubiquitous tools, AI models exhibit one detrimential\ncharacteristic: a performance-transparency trade-off. This describes the fact\nthat the more complex a model's inner workings, the less clear it is how its\npredictions or decisions were achieved. But, especially considering Machine\nLearning (ML) methods like Reinforcement Learning (RL) where the system learns\nautonomously, the necessity to understand the underlying reasoning for their\ndecisions becomes apparent. Since, to the best of our knowledge, there exists\nno single work offering an overview of Explainable Reinforcement Learning (XRL)\nmethods, this survey attempts to address this gap. We give a short summary of\nthe problem, a definition of important terms, and offer a classification and\nassessment of current XRL methods. We found that a) the majority of XRL methods\nfunction by mimicking and simplifying a complex model instead of designing an\ninherently simple one, and b) XRL (and XAI) methods often neglect to consider\nthe human side of the equation, not taking into account research from related\nfields like psychology or philosophy. Thus, an interdisciplinary effort is\nneeded to adapt the generated explanations to a (non-expert) human user in\norder to effectively progress in the field of XRL and XAI in general.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 10:52:49 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Puiutta", "Erika", ""], ["Veith", "Eric MSP", ""]]}, {"id": "2005.06251", "submitter": "Tao Meng", "authors": "Shengyu Jia, Tao Meng, Jieyu Zhao and Kai-Wei Chang", "title": "Mitigating Gender Bias Amplification in Distribution by Posterior\n  Regularization", "comments": "7 pages, 3 figures, published in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced machine learning techniques have boosted the performance of natural\nlanguage processing. Nevertheless, recent studies, e.g., Zhao et al. (2017)\nshow that these techniques inadvertently capture the societal bias hidden in\nthe corpus and further amplify it. However, their analysis is conducted only on\nmodels' top predictions. In this paper, we investigate the gender bias\namplification issue from the distribution perspective and demonstrate that the\nbias is amplified in the view of predicted probability distribution over\nlabels. We further propose a bias mitigation approach based on posterior\nregularization. With little performance loss, our method can almost remove the\nbias amplification in the distribution. Our study sheds the light on\nunderstanding the bias amplification.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 11:07:10 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Jia", "Shengyu", ""], ["Meng", "Tao", ""], ["Zhao", "Jieyu", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2005.06255", "submitter": "Periyapattana Narayana Prasad Karthik", "authors": "P. N. Karthik and Rajesh Sundaresan", "title": "Detecting an Odd Restless Markov Arm with a Trembling Hand", "comments": "46 pages, 1 figure, 1 table. Revision to an earlier submitted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a multi-armed bandit in which each arm is a Markov\nprocess evolving on a finite state space. The state space is common across the\narms, and the arms are independent of each other. The transition probability\nmatrix of one of the arms (the odd arm) is different from the common transition\nprobability matrix of all the other arms. A decision maker, who knows these\ntransition probability matrices, wishes to identify the odd arm as quickly as\npossible, while keeping the probability of decision error small. To do so, the\ndecision maker collects observations from the arms by pulling the arms in a\nsequential manner, one at each discrete time instant. However, the decision\nmaker has a trembling hand, and the arm that is actually pulled at any given\ntime differs, with a small probability, from the one he intended to pull. The\nobservation at any given time is the arm that is actually pulled and its\ncurrent state. The Markov processes of the unobserved arms continue to evolve.\nThis makes the arms restless.\n  For the above setting, we derive the first known asymptotic lower bound on\nthe expected time required to identify the odd arm, where the asymptotics is of\nvanishing error probability. The continued evolution of each arm adds a new\ndimension to the problem, leading to a family of Markov decision problems\n(MDPs) on a countable state space. We then stitch together certain\nparameterised solutions to these MDPs and obtain a sequence of strategies whose\nexpected times to identify the odd arm come arbitrarily close to the lower\nbound in the regime of vanishing error probability. Prior works dealt with\nindependent and identically distributed (across time) arms and rested Markov\narms, whereas our work deals with restless Markov arms.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 11:27:14 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 08:17:52 GMT"}, {"version": "v3", "created": "Thu, 31 Dec 2020 10:43:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Karthik", "P. N.", ""], ["Sundaresan", "Rajesh", ""]]}, {"id": "2005.06276", "submitter": "Jie Peng", "authors": "Jie Peng, Weiyu Li, Qing Ling", "title": "Byzantine-Robust Decentralized Stochastic Optimization over Static and\n  Time-Varying Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the Byzantine-robust stochastic optimization\nproblem defined over decentralized static and time-varying networks, where the\nagents collaboratively minimize the summation of expectations of stochastic\nlocal cost functions, but some of the agents are unreliable due to data\ncorruptions, equipment failures or cyber-attacks. The unreliable agents, which\nare called as Byzantine agents thereafter, can send faulty values to their\nneighbors and bias the optimization process. Our key idea to handle the\nByzantine attacks is to formulate a total variation (TV) norm-penalized\napproximation of the Byzantine-free problem, where the penalty term forces the\nlocal models of regular agents to be close, but also allows the existence of\noutliers from the Byzantine agents. A stochastic subgradient method is applied\nto solve the penalized problem. We prove that the proposed method reaches a\nneighborhood of the Byzantine-free optimal solution, and the size of\nneighborhood is determined by the number of Byzantine agents and the network\ntopology. Numerical experiments corroborate the theoretical analysis, as well\nas demonstrate the robustness of the proposed method to Byzantine attacks and\nits superior performance comparing to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 04:18:39 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 04:41:36 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Peng", "Jie", ""], ["Li", "Weiyu", ""], ["Ling", "Qing", ""]]}, {"id": "2005.06284", "submitter": "Evgeny Mirkes", "authors": "Evgeny M Mirkes", "title": "Artificial Neural Network Pruning to Extract Knowledge", "comments": "IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Neural Networks (NN) are widely used for solving complex problems\nfrom medical diagnostics to face recognition. Despite notable successes, the\nmain disadvantages of NN are also well known: the risk of overfitting, lack of\nexplainability (inability to extract algorithms from trained NN), and high\nconsumption of computing resources. Determining the appropriate specific NN\nstructure for each problem can help overcome these difficulties: Too poor NN\ncannot be successfully trained, but too rich NN gives unexplainable results and\nmay have a high chance of overfitting. Reducing precision of NN parameters\nsimplifies the implementation of these NN, saves computing resources, and makes\nthe NN skills more transparent. This paper lists the basic NN simplification\nproblems and controlled pruning procedures to solve these problems. All the\ndescribed pruning procedures can be implemented in one framework. The developed\nprocedures, in particular, find the optimal structure of NN for each task,\nmeasure the influence of each input signal and NN parameter, and provide a\ndetailed verbal description of the algorithms and skills of NN. The described\nmethods are illustrated by a simple example: the generation of explicit\nalgorithms for predicting the results of the US presidential election.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 12:24:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Mirkes", "Evgeny M", ""]]}, {"id": "2005.06316", "submitter": "Masanobu Horie", "authors": "Masanobu Horie, Naoki Morita, Toshiaki Hishinuma, Yu Ihara, Naoto\n  Mitsume", "title": "Isometric Transformation Invariant and Equivariant Graph Convolutional\n  Networks", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are one of the most important data structures for representing\npairwise relations between objects. Specifically, a graph embedded in a\nEuclidean space is essential to solving real problems, such as physical\nsimulations. A crucial requirement for applying graphs in Euclidean spaces to\nphysical simulations is learning and inferring the isometric transformation\ninvariant and equivariant features in a computationally efficient manner. In\nthis paper, we propose a set of transformation invariant and equivariant models\nbased on graph convolutional networks, called IsoGCNs. We demonstrate that the\nproposed model has a competitive performance compared to state-of-the-art\nmethods on tasks related to geometrical and physical simulation data. Moreover,\nthe proposed model can scale up to graphs with 1M vertices and conduct an\ninference faster than a conventional finite element analysis, which the\nexisting equivariant models cannot achieve.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:44:44 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 05:22:12 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 18:30:44 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 12:41:51 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Horie", "Masanobu", ""], ["Morita", "Naoki", ""], ["Hishinuma", "Toshiaki", ""], ["Ihara", "Yu", ""], ["Mitsume", "Naoto", ""]]}, {"id": "2005.06334", "submitter": "Stefan Lenz", "authors": "Stefan Lenz, Maren Hackenberg, Harald Binder", "title": "The JuliaConnectoR: a functionally oriented interface for integrating\n  Julia in R", "comments": "23 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG cs.PL stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like many groups considering the new programming language Julia, we faced the\nchallenge of accessing the algorithms that we develop in Julia from R.\nTherefore, we developed the R package JuliaConnectoR, available from the CRAN\nrepository and GitHub (https://github.com/stefan-m-lenz/JuliaConnectoR), in\nparticular for making advanced deep learning tools available. For\nmaintainability and stability, we decided to base communication between R and\nJulia on TCP, using an optimized binary format for exchanging data. Our package\nalso specifically contains features that allow for a convenient interactive use\nin R. This makes it easy to develop R extensions with Julia or to simply call\nfunctionality from Julia packages in R. Interacting with Julia objects and\ncalling Julia functions becomes user-friendly, as Julia functions and variables\nare made directly available as objects in the R workspace. We illustrate the\nfurther features of our package with code examples, and also discuss advantages\nover the two alternative packages JuliaCall and XRJulia. Finally, we\ndemonstrate the usage of the package with a more extensive example for\nemploying neural ordinary differential equations, a recent deep learning\ntechnique that has received much attention. This example also provides more\ngeneral guidance for integrating deep learning techniques from Julia into R.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 14:18:34 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 19:14:29 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Lenz", "Stefan", ""], ["Hackenberg", "Maren", ""], ["Binder", "Harald", ""]]}, {"id": "2005.06338", "submitter": "Feifan Wang", "authors": "Feifan Wang", "title": "Neural Architecture Search for Gliomas Segmentation on Multimodal\n  Magnetic Resonance Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past few years have witnessed the artificial intelligence inspired evolution\nin various medical fields. The diagnosis and treatment of gliomas -- one of the\nmost commonly seen brain tumors with low survival rate -- rely heavily on the\ncomputer assisted segmentation process undertaken on the magnetic resonance\nimaging (MRI) scans. Although the encoder-decoder shaped deep learning networks\nhave been the de facto standard style for semantic segmentation tasks in\nmedical imaging analysis, enormous effort is still required to be spent on\ndesigning the detailed architecture of the down-sampling and up-sampling\nblocks. In this work, we propose a neural architecture search (NAS) based\nsolution to brain tumor segmentation tasks on multimodal volumetric MRI scans.\nThree sets of candidate operations are composed respectively for three kinds of\nbasic building blocks in which each operation is assigned with a specific\nprobabilistic parameter to be learned. Through alternately updating the weights\nof operations and the other parameters in the network, the searching mechanism\nends up with two optimal structures for the upward and downward blocks.\nMoreover, the developed solution also integrates normalization and patching\nstrategies tailored for brain MRI processing. Extensive comparative experiments\non the BraTS 2019 dataset demonstrate that the proposed algorithm not only\ncould relieve the pressure of fabricating block architectures but also\npossesses competitive feasibility and scalability.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 14:32:00 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 06:00:43 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Wang", "Feifan", ""]]}, {"id": "2005.06369", "submitter": "Mayalen Etcheverry", "authors": "Mayalen Etcheverry, Pierre-Yves Oudeyer, Chris Reinke", "title": "Progressive growing of self-organized hierarchical representations for\n  exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing agent that can autonomously discover and learn a diversity of\nstructures and skills in unknown changing environments is key for lifelong\nmachine learning. A central challenge is how to learn incrementally\nrepresentations in order to progressively build a map of the discovered\nstructures and re-use it to further explore. To address this challenge, we\nidentify and target several key functionalities. First, we aim to build lasting\nrepresentations and avoid catastrophic forgetting throughout the exploration\nprocess. Secondly we aim to learn a diversity of representations allowing to\ndiscover a \"diversity of diversity\" of structures (and associated skills) in\ncomplex high-dimensional environments. Thirdly, we target representations that\ncan structure the agent discoveries in a coarse-to-fine manner. Finally, we\ntarget the reuse of such representations to drive exploration toward an\n\"interesting\" type of diversity, for instance leveraging human guidance.\nCurrent approaches in state representation learning rely generally on\nmonolithic architectures which do not enable all these functionalities.\nTherefore, we present a novel technique to progressively construct a Hierarchy\nof Observation Latent Models for Exploration Stratification, called HOLMES.\nThis technique couples the use of a dynamic modular model architecture for\nrepresentation learning with intrinsically-motivated goal exploration processes\n(IMGEPs). The paper shows results in the domain of automated discovery of\ndiverse self-organized patterns, considering as testbed the experimental\nframework from Reinke et al. (2019).\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:24:42 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Etcheverry", "Mayalen", ""], ["Oudeyer", "Pierre-Yves", ""], ["Reinke", "Chris", ""]]}, {"id": "2005.06376", "submitter": "Petros Stavropoulos", "authors": "Petros Stavropoulos, Dimitris Pappas, Ion Androutsopoulos, Ryan\n  McDonald", "title": "BIOMRC: A Dataset for Biomedical Machine Reading Comprehension", "comments": "10 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care\nwas taken to reduce noise, compared to the previous BIOREAD dataset of Pappas\net al. (2018). Experiments show that simple heuristics do not perform well on\nthe new dataset, and that two neural MRC models that had been tested on BIOREAD\nperform much better on BIOMRC, indicating that the new dataset is indeed less\nnoisy or at least that its task is more feasible. Non-expert human performance\nis also higher on the new dataset compared to BIOREAD, and biomedical experts\nperform even better. We also introduce a new BERT-based MRC model, the best\nversion of which substantially outperforms all other methods tested, reaching\nor surpassing the accuracy of biomedical experts in some experiments. We make\nthe new dataset available in three different sizes, also releasing our code,\nand providing a leaderboard.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:38:12 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Stavropoulos", "Petros", ""], ["Pappas", "Dimitris", ""], ["Androutsopoulos", "Ion", ""], ["McDonald", "Ryan", ""]]}, {"id": "2005.06392", "submitter": "Jincheng Mei", "authors": "Jincheng Mei, Chenjun Xiao, Csaba Szepesvari, Dale Schuurmans", "title": "On the Global Convergence Rates of Softmax Policy Gradient Methods", "comments": "64 pages, 5 figures. Published in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make three contributions toward better understanding policy gradient\nmethods in the tabular setting. First, we show that with the true gradient,\npolicy gradient with a softmax parametrization converges at a $O(1/t)$ rate,\nwith constants depending on the problem and initialization. This result\nsignificantly expands the recent asymptotic convergence results. The analysis\nrelies on two findings: that the softmax policy gradient satisfies a\n\\L{}ojasiewicz inequality, and the minimum probability of an optimal action\nduring optimization can be bounded in terms of its initial value. Second, we\nanalyze entropy regularized policy gradient and show that it enjoys a\nsignificantly faster linear convergence rate $O(e^{-t})$ toward softmax optimal\npolicy. This result resolves an open question in the recent literature.\nFinally, combining the above two results and additional new $\\Omega(1/t)$ lower\nbound results, we explain how entropy regularization improves policy\noptimization, even with the true gradient, from the perspective of convergence\nrate. The separation of rates is further explained using the notion of\nnon-uniform \\L{}ojasiewicz degree. These results provide a theoretical\nunderstanding of the impact of entropy and corroborate existing empirical\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:01:39 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 06:42:59 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Mei", "Jincheng", ""], ["Xiao", "Chenjun", ""], ["Szepesvari", "Csaba", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2005.06394", "submitter": "Minh Tu Hoang", "authors": "Minh Tu Hoang, Brosnan Yuen, Kai Ren, Xiaodai Dong, Tao Lu, Robert\n  Westendorp, Kishore Reddy", "title": "A CNN-LSTM Quantifier for Single Access Point CSI Indoor Localization", "comments": "Channel state information (CSI), WiFi indoor localization,\n  convolutional neural network, long short-term memory, fingerprint-based\n  localization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a combined network structure between convolutional neural\nnetwork (CNN) and long-short term memory (LSTM) quantifier for WiFi\nfingerprinting indoor localization. In contrast to conventional methods that\nutilize only spatial data with classification models, our CNN-LSTM network\nextracts both space and time features of the received channel state information\n(CSI) from a single router. Furthermore, the proposed network builds a\nquantification model rather than a limited classification model as in most of\nthe literature work, which enables the estimation of testing points that are\nnot identical to the reference points. We analyze the instability of CSI and\ndemonstrate a mitigation solution using a comprehensive filter and\nnormalization scheme. The localization accuracy is investigated through\nextensive on-site experiments with several mobile devices including mobile\nphone (Nexus 5) and laptop (Intel 5300 NIC) on hundreds of testing locations.\nUsing only a single WiFi router, our structure achieves an average localization\nerror of 2.5~m with $\\mathrm{80\\%}$ of the errors under 4~m, which outperforms\nthe other reported algorithms by approximately $\\mathrm{50\\%}$ under the same\ntest environment.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:54:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Hoang", "Minh Tu", ""], ["Yuen", "Brosnan", ""], ["Ren", "Kai", ""], ["Dong", "Xiaodai", ""], ["Lu", "Tao", ""], ["Westendorp", "Robert", ""], ["Reddy", "Kishore", ""]]}, {"id": "2005.06398", "submitter": "Noam Razin", "authors": "Noam Razin, Nadav Cohen", "title": "Implicit Regularization in Deep Learning May Not Be Explainable by Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematically characterizing the implicit regularization induced by\ngradient-based optimization is a longstanding pursuit in the theory of deep\nlearning. A widespread hope is that a characterization based on minimization of\nnorms may apply, and a standard test-bed for studying this prospect is matrix\nfactorization (matrix completion via linear neural networks). It is an open\nquestion whether norms can explain the implicit regularization in matrix\nfactorization. The current paper resolves this open question in the negative,\nby proving that there exist natural matrix factorization problems on which the\nimplicit regularization drives all norms (and quasi-norms) towards infinity.\nOur results suggest that, rather than perceiving the implicit regularization\nvia norms, a potentially more useful interpretation is minimization of rank. We\ndemonstrate empirically that this interpretation extends to a certain class of\nnon-linear neural networks, and hypothesize that it may be key to explaining\ngeneralization in deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:13:30 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 16:47:36 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Razin", "Noam", ""], ["Cohen", "Nadav", ""]]}, {"id": "2005.06401", "submitter": "Mathieu Serrurier", "authors": "Gilles Richard and Mathieu Serrurier", "title": "Dyslexia and Dysgraphia prediction: A new machine learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disabilities like dysgraphia, dyslexia, dyspraxia, etc. interfere\nwith academic achievements but have also long terms consequences beyond the\nacademic time. It is widely admitted that between 5% to 10% of the world\npopulation is subject to this kind of disabilities. For assessing such\ndisabilities in early childhood, children have to solve a battery of tests.\nHuman experts score these tests, and decide whether the children require\nspecific education strategy on the basis of their marks. The assessment can be\nlengthy, costly and emotionally painful. In this paper, we investigate how\nArtificial Intelligence can help in automating this assessment. Gathering a\ndataset of handwritten text pictures and audio recordings, both from standard\nchildren and from dyslexic and/or dysgraphic children, we apply machine\nlearning techniques for classification in order to analyze the differences\nbetween dyslexic/dysgraphic and standard readers/writers and to build a model.\nThe model is trained on simple features obtained by analysing the pictures and\nthe audio files. Our preliminary implementation shows relatively high\nperformances on the dataset we have used. This suggests the possibility to\nscreen dyslexia and dysgraphia via non-invasive methods in an accurate way as\nsoon as enough data are available.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:31:51 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Richard", "Gilles", ""], ["Serrurier", "Mathieu", ""]]}, {"id": "2005.06413", "submitter": "Louis Abraham", "authors": "Louis Abraham, Gary B\\'ecigneul, Bernhard Sch\\\"olkopf", "title": "Crackovid: Optimizing Group Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem usually referred to as group testing in the context of\nCOVID-19. Given $n$ samples taken from patients, how should we select mixtures\nof samples to be tested, so as to maximize information and minimize the number\nof tests? We consider both adaptive and non-adaptive strategies, and take a\nBayesian approach with a prior both for infection of patients and test errors.\nWe start by proposing a mathematically principled objective, grounded in\ninformation theory. We then optimize non-adaptive optimization strategies using\ngenetic algorithms, and leverage the mathematical framework of adaptive\nsub-modularity to obtain theoretical guarantees for the greedy-adaptive method.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:40:09 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Abraham", "Louis", ""], ["B\u00e9cigneul", "Gary", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2005.06417", "submitter": "Sushrut Karmalkar", "authors": "Ilias Diakonikolas, Samuel B. Hopkins, Daniel Kane, Sushrut Karmalkar", "title": "Robustly Learning any Clusterable Mixture of Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the efficient learnability of high-dimensional Gaussian mixtures in\nthe outlier-robust setting, where a small constant fraction of the data is\nadversarially corrupted. We resolve the polynomial learnability of this problem\nwhen the components are pairwise separated in total variation distance.\nSpecifically, we provide an algorithm that, for any constant number of\ncomponents $k$, runs in polynomial time and learns the components of an\n$\\epsilon$-corrupted $k$-mixture within information theoretically near-optimal\nerror of $\\tilde{O}(\\epsilon)$, under the assumption that the overlap between\nany pair of components $P_i, P_j$ (i.e., the quantity $1-TV(P_i, P_j)$) is\nbounded by $\\mathrm{poly}(\\epsilon)$.\n  Our separation condition is the qualitatively weakest assumption under which\naccurate clustering of the samples is possible. In particular, it allows for\ncomponents with arbitrary covariances and for components with identical means,\nas long as their covariances differ sufficiently. Ours is the first polynomial\ntime algorithm for this problem, even for $k=2$.\n  Our algorithm follows the Sum-of-Squares based proofs to algorithms approach.\nOur main technical contribution is a new robust identifiability proof of\nclusters from a Gaussian mixture, which can be captured by the constant-degree\nSum of Squares proof system. The key ingredients of this proof are a novel use\nof SoS-certifiable anti-concentration and a new characterization of pairs of\nGaussians with small (dimension-independent) overlap in terms of their\nparameter distance.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:44:12 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Hopkins", "Samuel B.", ""], ["Kane", "Daniel", ""], ["Karmalkar", "Sushrut", ""]]}, {"id": "2005.06434", "submitter": "Mohamed Ghalwash", "authors": "Mohamed Ghalwash, Zijun Yao, Prithwish Chakrabotry, James Codella,\n  Daby Sow", "title": "ODVICE: An Ontology-Driven Visual Analytic Tool for Interactive Cohort\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased availability of electronic health records (EHR) has enabled\nresearchers to study various medical questions. Cohort selection for the\nhypothesis under investigation is one of the main consideration for EHR\nanalysis. For uncommon diseases, cohorts extracted from EHRs contain very\nlimited number of records - hampering the robustness of any analysis. Data\naugmentation methods have been successfully applied in other domains to address\nthis issue mainly using simulated records. In this paper, we present ODVICE, a\ndata augmentation framework that leverages the medical concept ontology to\nsystematically augment records using a novel ontologically guided Monte-Carlo\ngraph spanning algorithm. The tool allows end users to specify a small set of\ninteractive controls to control the augmentation process. We analyze the\nimportance of ODVICE by conducting studies on MIMIC-III dataset for two\nlearning tasks. Our results demonstrate the predictive performance of ODVICE\naugmented cohorts, showing ~30% improvement in area under the curve (AUC) over\nthe non-augmented dataset and other data augmentation strategies.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 17:15:51 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Ghalwash", "Mohamed", ""], ["Yao", "Zijun", ""], ["Chakrabotry", "Prithwish", ""], ["Codella", "James", ""], ["Sow", "Daby", ""]]}, {"id": "2005.06462", "submitter": "Sinong Geng", "authors": "Sinong Geng, Zhaobin Kuang, Peggy Peissig, David Page", "title": "Temporal Poisson Square Root Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose temporal Poisson square root graphical models (TPSQRs), a\ngeneralization of Poisson square root graphical models (PSQRs) specifically\ndesigned for modeling longitudinal event data. By estimating the temporal\nrelationships for all possible pairs of event types, TPSQRs can offer a\nholistic perspective about whether the occurrences of any given event type\ncould excite or inhibit any other type. A TPSQR is learned by estimating a\ncollection of interrelated PSQRs that share the same template parameterization.\nThese PSQRs are estimated jointly in a pseudo-likelihood fashion, where Poisson\npseudo-likelihood is used to approximate the original more\ncomputationally-intensive pseudo-likelihood problem stemming from PSQRs.\nTheoretically, we demonstrate that under mild assumptions, the Poisson\npseudo-likelihood approximation is sparsistent for recovering the underlying\nPSQR. Empirically, we learn TPSQRs from Marshfield Clinic electronic health\nrecords (EHRs) with millions of drug prescription and condition diagnosis\nevents, for adverse drug reaction (ADR) detection. Experimental results\ndemonstrate that the learned TPSQRs can recover ADR signals from the EHR\neffectively and efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 22:49:45 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Geng", "Sinong", ""], ["Kuang", "Zhaobin", ""], ["Peissig", "Peggy", ""], ["Page", "David", ""]]}, {"id": "2005.06509", "submitter": "Sahar Imtiaz", "authors": "Sahar Imtiaz, Sebastian Schiessl, Georgios P. Koudouridis and James\n  Gross", "title": "Coordinates-based Resource Allocation Through Supervised Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appropriate allocation of system resources is essential for meeting the\nincreased user-traffic demands in the next generation wireless technologies.\nTraditionally, the system relies on channel state information (CSI) of the\nusers for optimizing the resource allocation, which becomes costly for\nfast-varying channel conditions. Considering that future wireless technologies\nwill be based on dense network deployment, where the mobile terminals are in\nline-of-sight of the transmitters, the position information of terminals\nprovides an alternative to estimate the channel condition. In this work, we\npropose a coordinates-based resource allocation scheme using supervised machine\nlearning techniques, and investigate how efficiently this scheme performs in\ncomparison to the traditional approach under various propagation conditions. We\nconsider a simplistic system set up as a first step, where a single transmitter\nserves a single mobile user. The performance results show that the\ncoordinates-based resource allocation scheme achieves a performance very close\nto the CSI-based scheme, even when the available coordinates of terminals are\nerroneous. The proposed scheme performs consistently well with realistic-system\nsimulation, requiring only 4 s of training time, and the appropriate resource\nallocation is predicted in less than 90 microseconds with a learnt model of\nsize less than 1 kB.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 18:33:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Imtiaz", "Sahar", ""], ["Schiessl", "Sebastian", ""], ["Koudouridis", "Georgios P.", ""], ["Gross", "James", ""]]}, {"id": "2005.06530", "submitter": "Stefano Gualandi", "authors": "Gennaro Auricchio, Andrea Codegoni, Stefano Gualandi, Giuseppe\n  Toscani, Marco Veneroni", "title": "The Equivalence of Fourier-based and Wasserstein Metrics on Imaging\n  Problems", "comments": "18 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate properties of some extensions of a class of Fourier-based\nprobability metrics, originally introduced to study convergence to equilibrium\nfor the solution to the spatially homogeneous Boltzmann equation. At difference\nwith the original one, the new Fourier-based metrics are well-defined also for\nprobability distributions with different centers of mass, and for discrete\nprobability measures supported over a regular grid. Among other properties, it\nis shown that, in the discrete setting, these new Fourier-based metrics are\nequivalent either to the Euclidean-Wasserstein distance $W_2$, or to the\nKantorovich-Wasserstein distance $W_1$, with explicit constants of equivalence.\nNumerical results then show that in benchmark problems of image processing,\nFourier metrics provide a better runtime with respect to Wasserstein ones.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 19:01:00 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Auricchio", "Gennaro", ""], ["Codegoni", "Andrea", ""], ["Gualandi", "Stefano", ""], ["Toscani", "Giuseppe", ""], ["Veneroni", "Marco", ""]]}, {"id": "2005.06546", "submitter": "Forrest Bao", "authors": "Forrest Sheng Bao, Youbiao He, Jie Liu, Yuanfang Chen, Qian Li,\n  Christina R. Zhang, Lei Han, Baoli Zhu, Yaorong Ge, Shi Chen, Ming Xu, Liu\n  Ouyang", "title": "Triaging moderate COVID-19 and other viral pneumonias from routine blood\n  tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 is sweeping the world with deadly consequences. Its contagious\nnature and clinical similarity to other pneumonias make separating subjects\ncontracted with COVID-19 and non-COVID-19 viral pneumonia a priority and a\nchallenge. However, COVID-19 testing has been greatly limited by the\navailability and cost of existing methods, even in developed countries like the\nUS. Intrigued by the wide availability of routine blood tests, we propose to\nleverage them for COVID-19 testing using the power of machine learning. Two\nproven-robust machine learning model families, random forests (RFs) and support\nvector machines (SVMs), are employed to tackle the challenge. Trained on blood\ndata from 208 moderate COVID-19 subjects and 86 subjects with non-COVID-19\nmoderate viral pneumonia, the best result is obtained in an SVM-based\nclassifier with an accuracy of 84%, a sensitivity of 88%, a specificity of 80%,\nand a precision of 92%. The results are found explainable from both machine\nlearning and medical perspectives. A privacy-protected web portal is set up to\nhelp medical personnel in their practice and the trained models are released\nfor developers to further build other applications. We hope our results can\nhelp the world fight this pandemic and welcome clinical verification of our\napproach on larger populations.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 19:24:07 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Bao", "Forrest Sheng", ""], ["He", "Youbiao", ""], ["Liu", "Jie", ""], ["Chen", "Yuanfang", ""], ["Li", "Qian", ""], ["Zhang", "Christina R.", ""], ["Han", "Lei", ""], ["Zhu", "Baoli", ""], ["Ge", "Yaorong", ""], ["Chen", "Shi", ""], ["Xu", "Ming", ""], ["Ouyang", "Liu", ""]]}, {"id": "2005.06549", "submitter": "Alex Beatson", "authors": "Alex Beatson, Jordan T. Ash, Geoffrey Roeder, Tianju Xue, Ryan P.\n  Adams", "title": "Learning Composable Energy Surrogates for PDE Order Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-materials are an important emerging class of engineered materials in\nwhich complex macroscopic behaviour--whether electromagnetic, thermal, or\nmechanical--arises from modular substructure. Simulation and optimization of\nthese materials are computationally challenging, as rich substructures\nnecessitate high-fidelity finite element meshes to solve the governing PDEs. To\naddress this, we leverage parametric modular structure to learn component-level\nsurrogates, enabling cheaper high-fidelity simulation. We use a neural network\nto model the stored potential energy in a component given boundary conditions.\nThis yields a structured prediction task: macroscopic behavior is determined by\nthe minimizer of the system's total potential energy, which can be approximated\nby composing these surrogate models. Composable energy surrogates thus permit\nsimulation in the reduced basis of component boundaries. Costly ground-truth\nsimulation of the full structure is avoided, as training data are generated by\nperforming finite element analysis with individual components. Using dataset\naggregation to choose training boundary conditions allows us to learn energy\nsurrogates which produce accurate macroscopic behavior when composed,\naccelerating simulation of parametric meta-materials.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 19:41:24 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 12:29:19 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Beatson", "Alex", ""], ["Ash", "Jordan T.", ""], ["Roeder", "Geoffrey", ""], ["Xue", "Tianju", ""], ["Adams", "Ryan P.", ""]]}, {"id": "2005.06613", "submitter": "Charlie Kirkwood", "authors": "Charlie Kirkwood, Theo Economou, Henry Odbert, Nicolas Pugeault", "title": "A framework for probabilistic weather forecast post-processing across\n  models and lead times using machine learning", "comments": "17 pages, 9 figures, to be published in Philosophical Transactions of\n  the Royal Society A", "journal-ref": null, "doi": "10.1098/rsta.2020.0099", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the weather is an increasingly data intensive exercise. Numerical\nWeather Prediction (NWP) models are becoming more complex, with higher\nresolutions, and there are increasing numbers of different models in operation.\nWhile the forecasting skill of NWP models continues to improve, the number and\ncomplexity of these models poses a new challenge for the operational\nmeteorologist: how should the information from all available models, each with\ntheir own unique biases and limitations, be combined in order to provide\nstakeholders with well-calibrated probabilistic forecasts to use in decision\nmaking? In this paper, we use a road surface temperature example to demonstrate\na three-stage framework that uses machine learning to bridge the gap between\nsets of separate forecasts from NWP models and the 'ideal' forecast for\ndecision support: probabilities of future weather outcomes. First, we use\nQuantile Regression Forests to learn the error profile of each numerical model,\nand use these to apply empirically-derived probability distributions to\nforecasts. Second, we combine these probabilistic forecasts using quantile\naveraging. Third, we interpolate between the aggregate quantiles in order to\ngenerate a full predictive distribution, which we demonstrate has properties\nsuitable for decision support. Our results suggest that this approach provides\nan effective and operationally viable framework for the cohesive\npost-processing of weather forecasts across multiple models and lead times to\nproduce a well-calibrated probabilistic output.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:46:02 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 09:45:25 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Kirkwood", "Charlie", ""], ["Economou", "Theo", ""], ["Odbert", "Henry", ""], ["Pugeault", "Nicolas", ""]]}, {"id": "2005.06623", "submitter": "Dmitry Burov", "authors": "Dmitry Burov, Dimitrios Giannakis, Krithika Manohar, Andrew Stuart", "title": "Kernel Analog Forecasting: Multiscale Test Problems", "comments": "30 pages, 14 figures; clarified several ambiguous parts, added\n  references, and a comparison with Lorenz' original method (Sec. 4.5)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DS physics.comp-ph physics.data-an stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven prediction is becoming increasingly widespread as the volume of\ndata available grows and as algorithmic development matches this growth. The\nnature of the predictions made, and the manner in which they should be\ninterpreted, depends crucially on the extent to which the variables chosen for\nprediction are Markovian, or approximately Markovian. Multiscale systems\nprovide a framework in which this issue can be analyzed. In this work kernel\nanalog forecasting methods are studied from the perspective of data generated\nby multiscale dynamical systems. The problems chosen exhibit a variety of\ndifferent Markovian closures, using both averaging and homogenization;\nfurthermore, settings where scale-separation is not present and the predicted\nvariables are non-Markovian, are also considered. The studies provide guidance\nfor the interpretation of data-driven prediction methods when used in practice.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:44:38 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 22:49:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Burov", "Dmitry", ""], ["Giannakis", "Dimitrios", ""], ["Manohar", "Krithika", ""], ["Stuart", "Andrew", ""]]}, {"id": "2005.06630", "submitter": "Ahmed Allam", "authors": "Ahmed Allam, Matthias Dittberner, Anna Sintsova, Dominique Brodbeck,\n  Michael Krauthammer", "title": "Patient Similarity Analysis with Longitudinal Health Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare professionals have long envisioned using the enormous processing\npowers of computers to discover new facts and medical knowledge locked inside\nelectronic health records. These vast medical archives contain time-resolved\ninformation about medical visits, tests and procedures, as well as outcomes,\nwhich together form individual patient journeys. By assessing the similarities\namong these journeys, it is possible to uncover clusters of common disease\ntrajectories with shared health outcomes. The assignment of patient journeys to\nspecific clusters may in turn serve as the basis for personalized outcome\nprediction and treatment selection. This procedure is a non-trivial\ncomputational problem, as it requires the comparison of patient data with\nmulti-dimensional and multi-modal features that are captured at different times\nand resolutions. In this review, we provide a comprehensive overview of the\ntools and methods that are used in patient similarity analysis with\nlongitudinal data and discuss its potential for improving clinical decision\nmaking.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 07:06:02 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Allam", "Ahmed", ""], ["Dittberner", "Matthias", ""], ["Sintsova", "Anna", ""], ["Brodbeck", "Dominique", ""], ["Krauthammer", "Michael", ""]]}, {"id": "2005.06649", "submitter": "Andreas Loukas", "authors": "Andreas Loukas", "title": "How hard is to distinguish graphs with graph neural networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of graph neural networks is their ability to distinguish the\nisomorphism class of their inputs. This study derives hardness results for the\nclassification variant of graph isomorphism in the message-passing model\n(MPNN). MPNN encompasses the majority of graph neural networks used today and\nis universal when nodes are given unique features. The analysis relies on the\nintroduced measure of communication capacity. Capacity measures how much\ninformation the nodes of a network can exchange during the forward pass and\ndepends on the depth, message-size, global state, and width of the\narchitecture. It is shown that the capacity of MPNN needs to grow linearly with\nthe number of nodes so that a network can distinguish trees and quadratically\nfor general connected graphs. The derived bounds concern both worst- and\naverage-case behavior and apply to networks with/without unique features and\nadaptive architecture -- they are also up to two orders of magnitude tighter\nthan those given by simpler arguments. An empirical study involving 12 graph\nclassification tasks and 420 networks reveals strong alignment between actual\nperformance and theoretical predictions.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:28:46 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 12:48:57 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Loukas", "Andreas", ""]]}, {"id": "2005.06706", "submitter": "Yucheng Lu", "authors": "Yucheng Lu, Jack Nash, Christopher De Sa", "title": "MixML: A Unified Analysis of Weakly Consistent Parallel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallelism is a ubiquitous method for accelerating machine learning\nalgorithms. However, theoretical analysis of parallel learning is usually done\nin an algorithm- and protocol-specific setting, giving little insight about how\nchanges in the structure of communication could affect convergence. In this\npaper we propose MixML, a general framework for analyzing convergence of weakly\nconsistent parallel machine learning. Our framework includes: (1) a unified way\nof modeling the communication process among parallel workers; (2) a new\nparameter, the mixing time tmix, that quantifies how the communication process\naffects convergence; and (3) a principled way of converting a convergence proof\nfor a sequential algorithm into one for a parallel version that depends only on\ntmix. We show MixML recovers and improves on known convergence bounds for\nasynchronous and/or decentralized versions of many algorithms, includingSGD and\nAMSGrad. Our experiments substantiate the theory and show the dependency of\nconvergence on the underlying mixing time.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 03:38:20 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 19:12:55 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Lu", "Yucheng", ""], ["Nash", "Jack", ""], ["De Sa", "Christopher", ""]]}, {"id": "2005.06707", "submitter": "Shaoning Zeng", "authors": "Shaoning Zeng and Bob Zhang", "title": "Noise Homogenization via Multi-Channel Wavelet Filtering for\n  High-Fidelity Sample Generation in GANs", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the generator of typical Generative Adversarial Networks (GANs), a noise\nis inputted to generate fake samples via a series of convolutional operations.\nHowever, current noise generation models merely relies on the information from\nthe pixel space, which increases the difficulty to approach the target\ndistribution. Fortunately, the long proven wavelet transformation is able to\ndecompose multiple spectral information from the images. In this work, we\npropose a novel multi-channel wavelet-based filtering method for GANs, to cope\nwith this problem. When embedding a wavelet deconvolution layer in the\ngenerator, the resultant GAN, called WaveletGAN, takes advantage of the wavelet\ndeconvolution to learn a filtering with multiple channels, which can\nefficiently homogenize the generated noise via an averaging operation, so as to\ngenerate high-fidelity samples. We conducted benchmark experiments on the\nFashion-MNIST, KMNIST and SVHN datasets through an open GAN benchmark tool. The\nresults show that WaveletGAN has excellent performance in generating\nhigh-fidelity samples, thanks to the smallest FIDs obtained on these datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 03:40:11 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zeng", "Shaoning", ""], ["Zhang", "Bob", ""]]}, {"id": "2005.06716", "submitter": "Mohsen Imani", "authors": "Behnam Khaleghi, Mohsen Imani, Tajana Rosing", "title": "Prive-HD: Privacy-Preserved Hyperdimensional Computing", "comments": "Accepted in Design Automation Conference (DAC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The privacy of data is a major challenge in machine learning as a trained\nmodel may expose sensitive information of the enclosed dataset. Besides, the\nlimited computation capability and capacity of edge devices have made\ncloud-hosted inference inevitable. Sending private information to remote\nservers makes the privacy of inference also vulnerable because of susceptible\ncommunication channels or even untrustworthy hosts. In this paper, we target\nprivacy-preserving training and inference of brain-inspired Hyperdimensional\n(HD) computing, a new learning algorithm that is gaining traction due to its\nlight-weight computation and robustness particularly appealing for edge devices\nwith tight constraints. Indeed, despite its promising attributes, HD computing\nhas virtually no privacy due to its reversible computation. We present an\naccuracy-privacy trade-off method through meticulous quantization and pruning\nof hypervectors, the building blocks of HD, to realize a differentially private\nmodel as well as to obfuscate the information sent for cloud-hosted inference.\nFinally, we show how the proposed techniques can be also leveraged for\nefficient hardware implementation.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 04:19:34 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Khaleghi", "Behnam", ""], ["Imani", "Mohsen", ""], ["Rosing", "Tajana", ""]]}, {"id": "2005.06725", "submitter": "Zhiming Huang", "authors": "Zhiming Huang, Yifan Xu, Bingshan Hu, Qipeng Wang, Jianping Pan", "title": "Thompson Sampling for Combinatorial Semi-bandits with Sleeping Arms and\n  Long-Term Fairness Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the combinatorial sleeping multi-armed semi-bandit problem with\nlong-term fairness constraints~(CSMAB-F). To address the problem, we adopt\nThompson Sampling~(TS) to maximize the total rewards and use virtual queue\ntechniques to handle the fairness constraints, and design an algorithm called\n\\emph{TS with beta priors and Bernoulli likelihoods for CSMAB-F~(TSCSF-B)}.\nFurther, we prove TSCSF-B can satisfy the fairness constraints, and the\ntime-averaged regret is upper bounded by $\\frac{N}{2\\eta} +\nO\\left(\\frac{\\sqrt{mNT\\ln T}}{T}\\right)$, where $N$ is the total number of\narms, $m$ is the maximum number of arms that can be pulled simultaneously in\neach round~(the cardinality constraint) and $\\eta$ is the parameter trading off\nfairness for rewards. By relaxing the fairness constraints (i.e., let $\\eta\n\\rightarrow \\infty$), the bound boils down to the first problem-independent\nbound of TS algorithms for combinatorial sleeping multi-armed semi-bandit\nproblems. Finally, we perform numerical experiments and use a high-rating movie\nrecommendation application to show the effectiveness and efficiency of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 05:24:53 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Huang", "Zhiming", ""], ["Xu", "Yifan", ""], ["Hu", "Bingshan", ""], ["Wang", "Qipeng", ""], ["Pan", "Jianping", ""]]}, {"id": "2005.06727", "submitter": "Jesmin Jahan Tithi", "authors": "Jesmin Jahan Tithi and Fabrizio Petrini", "title": "An Efficient Shared-memory Parallel Sinkhorn-Knopp Algorithm to Compute\n  the Word Mover's Distance", "comments": "10 pages, 1 page for reference, total 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Word Mover's Distance (WMD) is a metric that measures the semantic\ndissimilarity between two text documents by computing the cost of moving all\nwords of a source/query document to the most similar words of a target document\noptimally. Computing WMD between two documents is costly because it requires\nsolving an optimization problem that costs \\(O(V^3log(V))\\) where \\(V\\) is the\nnumber of unique words in the document. Fortunately, the WMD can be framed as\nthe Earth Mover's Distance (EMD) (also known as the Optimal Transportation\nDistance) for which it has been shown that the algorithmic complexity can be\nreduced to \\(O(V^2)\\) by adding an entropy penalty to the optimization problem\nand a similar idea can be adapted to compute WMD efficiently. Additionally, the\ncomputation can be made highly parallel by computing WMD of a single query\ndocument against multiple target documents at once (e.g., finding whether a\ngiven tweet is similar to any other tweets happened in a day). In this paper,\nwe present a shared-memory parallel Sinkhorn-Knopp Algorithm to compute the WMD\nof one document against many other documents by adopting the \\(O(V^2)\\) EMD\nalgorithm. We used algorithmic transformations to change the original dense\ncompute-heavy kernel to a sparse compute kernel and obtained \\(67\\times\\)\nspeedup using \\(96\\) cores on the state-of-the-art of Intel\\textregistered{}\n4-sockets Cascade Lake machine w.r.t. its sequential run. Our parallel\nalgorithm is over \\(700\\times\\) faster than the naive parallel python code that\ninternally uses optimized matrix library calls.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 05:30:18 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 23:06:41 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 20:35:08 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Tithi", "Jesmin Jahan", ""], ["Petrini", "Fabrizio", ""]]}, {"id": "2005.06731", "submitter": "Yun-Cheng Tsai", "authors": "Chia-Ying Tsao, Jun-Hao Chen, Samuel Yen-Chi Chen, and Yun-Cheng Tsai", "title": "Data Augmentation for Deep Candlestick Learner", "comments": "12 pages, 9 figures, 2 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To successfully build a deep learning model, it will need a large amount of\nlabeled data. However, labeled data are hard to collect in many use cases. To\ntackle this problem, a bunch of data augmentation methods have been introduced\nrecently and have demonstrated successful results in computer vision, natural\nlanguage and so on. For financial trading data, to our best knowledge,\nsuccessful data augmentation framework has rarely been studied. Here we propose\na Modified Local Search Attack Sampling method to augment the candlestick data,\nwhich is a very important tool for professional trader. Our results show that\nthe proposed method can generate high-quality data which are hard to\ndistinguish by human and will open a new way for finance community to employ\nexisting machine learning techniques even if the dataset is small.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 06:02:31 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 06:02:46 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Tsao", "Chia-Ying", ""], ["Chen", "Jun-Hao", ""], ["Chen", "Samuel Yen-Chi", ""], ["Tsai", "Yun-Cheng", ""]]}, {"id": "2005.06800", "submitter": "Younggyo Seo", "authors": "Kimin Lee, Younggyo Seo, Seunghyun Lee, Honglak Lee, Jinwoo Shin", "title": "Context-aware Dynamics Model for Generalization in Model-Based\n  Reinforcement Learning", "comments": "Accepted in ICML2020. First two authors contributed equally, website:\n  https://sites.google.com/view/cadm code: https://github.com/younggyoseo/CaDM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (RL) enjoys several benefits, such as\ndata-efficiency and planning, by learning a model of the environment's\ndynamics. However, learning a global model that can generalize across different\ndynamics is a challenging task. To tackle this problem, we decompose the task\nof learning a global dynamics model into two stages: (a) learning a context\nlatent vector that captures the local dynamics, then (b) predicting the next\nstate conditioned on it. In order to encode dynamics-specific information into\nthe context latent vector, we introduce a novel loss function that encourages\nthe context latent vector to be useful for predicting both forward and backward\ndynamics. The proposed method achieves superior generalization ability across\nvarious simulated robotics and control tasks, compared to existing RL schemes.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 08:10:54 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 05:09:57 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 06:41:27 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lee", "Kimin", ""], ["Seo", "Younggyo", ""], ["Lee", "Seunghyun", ""], ["Lee", "Honglak", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2005.06828", "submitter": "Luo Chunjie", "authors": "Chunjie Luo, Jianfeng Zhan, Lei Wang, Wanling Gao", "title": "Finet: Using Fine-grained Batch Normalization to Train Light-weight\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build light-weight network, we propose a new normalization, Fine-grained\nBatch Normalization (FBN). Different from Batch Normalization (BN), which\nnormalizes the final summation of the weighted inputs, FBN normalizes the\nintermediate state of the summation. We propose a novel light-weight network\nbased on FBN, called Finet. At training time, the convolutional layer with FBN\ncan be seen as an inverted bottleneck mechanism. FBN can be fused into\nconvolution at inference time. After fusion, Finet uses the standard\nconvolution with equal channel width, thus makes the inference more efficient.\nOn ImageNet classification dataset, Finet achieves the state-of-art performance\n(65.706% accuracy with 43M FLOPs, and 73.786% accuracy with 303M FLOPs),\nMoreover, experiments show that Finet is more efficient than other state-of-art\nlight-weight networks.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 09:16:13 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Luo", "Chunjie", ""], ["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Gao", "Wanling", ""]]}, {"id": "2005.06852", "submitter": "Pieter Delobelle", "authors": "Pieter Delobelle and Paul Temple and Gilles Perrouin and Beno\\^it\n  Fr\\'enay and Patrick Heymans and Bettina Berendt", "title": "Ethical Adversaries: Towards Mitigating Unfairness with Adversarial\n  Machine Learning", "comments": "15 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is being integrated into a growing number of critical\nsystems with far-reaching impacts on society. Unexpected behaviour and unfair\ndecision processes are coming under increasing scrutiny due to this widespread\nuse and its theoretical considerations. Individuals, as well as organisations,\nnotice, test, and criticize unfair results to hold model designers and\ndeployers accountable. We offer a framework that assists these groups in\nmitigating unfair representations stemming from the training datasets. Our\nframework relies on two inter-operating adversaries to improve fairness. First,\na model is trained with the goal of preventing the guessing of protected\nattributes' values while limiting utility losses. This first step optimizes the\nmodel's parameters for fairness. Second, the framework leverages evasion\nattacks from adversarial machine learning to generate new examples that will be\nmisclassified. These new examples are then used to retrain and improve the\nmodel in the first step. These two steps are iteratively applied until a\nsignificant improvement in fairness is obtained. We evaluated our framework on\nwell-studied datasets in the fairness literature -- including COMPAS -- where\nit can surpass other approaches concerning demographic parity, equality of\nopportunity and also the model's utility. We also illustrate our findings on\nthe subtle difficulties when mitigating unfairness and highlight how our\nframework can assist model designers.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 10:10:19 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 16:47:17 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Delobelle", "Pieter", ""], ["Temple", "Paul", ""], ["Perrouin", "Gilles", ""], ["Fr\u00e9nay", "Beno\u00eet", ""], ["Heymans", "Patrick", ""], ["Berendt", "Bettina", ""]]}, {"id": "2005.06870", "submitter": "Junjie Liu", "authors": "Junjie Liu, Zhe Xu, Runbin Shi, Ray C. C. Cheung, Hayden K.H. So", "title": "Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With\n  Trainable Masked Layers", "comments": "ICLR 2020, camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel network pruning algorithm called Dynamic Sparse Training\nthat can jointly find the optimal network parameters and sparse network\nstructure in a unified optimization process with trainable pruning thresholds.\nThese thresholds can have fine-grained layer-wise adjustments dynamically via\nbackpropagation. We demonstrate that our dynamic sparse training algorithm can\neasily train very sparse neural network models with little performance loss\nusing the same number of training epochs as dense models. Dynamic Sparse\nTraining achieves the state of the art performance compared with other sparse\ntraining algorithms on various network architectures. Additionally, we have\nseveral surprising observations that provide strong evidence for the\neffectiveness and efficiency of our algorithm. These observations reveal the\nunderlying problems of traditional three-stage pruning algorithms and present\nthe potential guidance provided by our algorithm to the design of more compact\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:05:21 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Liu", "Junjie", ""], ["Xu", "Zhe", ""], ["Shi", "Runbin", ""], ["Cheung", "Ray C. C.", ""], ["So", "Hayden K. H.", ""]]}, {"id": "2005.06897", "submitter": "Daniel Weber", "authors": "Daniel Weber, Clemens G\\\"uhmann and Thomas Seel", "title": "Neural Networks Versus Conventional Filters for Inertial-Sensor-based\n  Attitude Estimation", "comments": "accepted for the 23rd International Conference on Information Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inertial measurement units are commonly used to estimate the attitude of\nmoving objects. Numerous nonlinear filter approaches have been proposed for\nsolving the inherent sensor fusion problem. However, when a large range of\ndifferent dynamic and static rotational and translational motions is\nconsidered, the attainable accuracy is limited by the need for\nsituation-dependent adjustment of accelerometer and gyroscope fusion weights.\nWe investigate to what extent these limitations can be overcome by means of\nartificial neural networks and how much domain-specific optimization of the\nneural network model is required to outperform the conventional filter\nsolution. A diverse set of motion recordings with a marker-based optical ground\ntruth is used for performance evaluation and comparison. The proposed neural\nnetworks are found to outperform the conventional filter across all motions\nonly if domain-specific optimizations are introduced. We conclude that they are\na promising tool for inertial-sensor-based real-time attitude estimation, but\nboth expert knowledge and rich datasets are required to achieve top\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:59:19 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 20:50:55 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Weber", "Daniel", ""], ["G\u00fchmann", "Clemens", ""], ["Seel", "Thomas", ""]]}, {"id": "2005.06928", "submitter": "Christian Berghoff", "authors": "Christian Berghoff", "title": "Protecting the integrity of the training procedure of neural networks", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to significant improvements in performance in recent years, neural\nnetworks are currently used for an ever-increasing number of applications.\nHowever, neural networks have the drawback that their decisions are not readily\ninterpretable and traceable for a human. This creates several problems, for\ninstance in terms of safety and IT security for high-risk applications, where\nassuring these properties is crucial. One of the most striking IT security\nproblems aggravated by the opacity of neural networks is the possibility of\nso-called poisoning attacks during the training phase, where an attacker\ninserts specially crafted data to manipulate the resulting model. We propose an\napproach to this problem which allows provably verifying the integrity of the\ntraining procedure by making use of standard cryptographic mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:57:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Berghoff", "Christian", ""]]}, {"id": "2005.06935", "submitter": "Gerome Vivar", "authors": "Gerome Vivar, Anees Kazi, Hendrik Burwinkel, Andreas Zwergal, Nassir\n  Navab, Seyed-Ahmad Ahmadi", "title": "Simultaneous imputation and disease classification in incomplete medical\n  datasets using Multigraph Geometric Matrix Completion (MGMC)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale population-based studies in medicine are a key resource towards\nbetter diagnosis, monitoring, and treatment of diseases. They also serve as\nenablers of clinical decision support systems, in particular Computer Aided\nDiagnosis (CADx) using machine learning (ML). Numerous ML approaches for CADx\nhave been proposed in literature. However, these approaches assume full data\navailability, which is not always feasible in clinical data. To account for\nmissing data, incomplete data samples are either removed or imputed, which\ncould lead to data bias and may negatively affect classification performance.\nAs a solution, we propose an end-to-end learning of imputation and disease\nprediction of incomplete medical datasets via Multigraph Geometric Matrix\nCompletion (MGMC). MGMC uses multiple recurrent graph convolutional networks,\nwhere each graph represents an independent population model based on a key\nclinical meta-feature like age, sex, or cognitive function. Graph signal\naggregation from local patient neighborhoods, combined with multigraph signal\nfusion via self-attention, has a regularizing effect on both matrix\nreconstruction and classification performance. Our proposed approach is able to\nimpute class relevant features as well as perform accurate classification on\ntwo publicly available medical datasets. We empirically show the superiority of\nour proposed approach in terms of classification and imputation performance\nwhen compared with state-of-the-art approaches. MGMC enables disease prediction\nin multimodal and incomplete medical datasets. These findings could serve as\nbaseline for future CADx approaches which utilize incomplete datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 13:11:35 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Vivar", "Gerome", ""], ["Kazi", "Anees", ""], ["Burwinkel", "Hendrik", ""], ["Zwergal", "Andreas", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "2005.06967", "submitter": "Allen Hart", "authors": "Allen G Hart and James L Hook and Jonathan H P Dawes", "title": "Echo State Networks trained by Tikhonov least squares are L2({\\mu})\n  approximators of ergodic dynamical systems", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.physd.2021.132882", "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Echo State Networks (ESNs) are a class of single-layer recurrent neural\nnetworks with randomly generated internal weights, and a single layer of\ntuneable outer weights, which are usually trained by regularised linear least\nsquares regression. Remarkably, ESNs still enjoy the universal approximation\nproperty despite the training procedure being entirely linear. In this paper,\nwe prove that an ESN trained on a sequence of observations from an ergodic\ndynamical system (with invariant measure $\\mu$) using Tikhonov least squares\nregression against a set of targets, will approximate the target function in\nthe $L^2(\\mu)$ norm. In the special case that the targets are future\nobservations, the ESN is learning the next step map, which allows time series\nforecasting. We demonstrate the theory numerically by training an ESN using\nTikhonov least squares on a sequence of scalar observations of the Lorenz\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 13:39:07 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 16:23:05 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Hart", "Allen G", ""], ["Hook", "James L", ""], ["Dawes", "Jonathan H P", ""]]}, {"id": "2005.06978", "submitter": "Niklas K\\\"uhl", "authors": "Tristan Karb, Niklas K\\\"uhl, Robin Hirt, Varvara Glivici-Cotruta", "title": "A network-based transfer learning approach to improve sales forecasting\n  of new products", "comments": "28th European Conference on Information Systems (ECIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data-driven methods -- such as machine learning and time series forecasting\n-- are widely used for sales forecasting in the food retail domain. However,\nfor newly introduced products insufficient training data is available to train\naccurate models. In this case, human expert systems are implemented to improve\nprediction performance. Human experts rely on their implicit and explicit\ndomain knowledge and transfer knowledge about historical sales of similar\nproducts to forecast new product sales. By applying the concept of Transfer\nLearning, we propose an analytical approach to transfer knowledge between\nlisted stock products and new products. A network-based Transfer Learning\napproach for deep neural networks is designed to investigate the efficiency of\nTransfer Learning in the domain of food sales forecasting. Furthermore, we\nexamine how knowledge can be shared across different products and how to\nidentify the products most suitable for transfer. To test the proposed\napproach, we conduct a comprehensive case study for a newly introduced product,\nbased on data of an Austrian food retailing company. The experimental results\nshow, that the prediction accuracy of deep neural networks for food sales\nforecasting can be effectively increased using the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:08:47 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Karb", "Tristan", ""], ["K\u00fchl", "Niklas", ""], ["Hirt", "Robin", ""], ["Glivici-Cotruta", "Varvara", ""]]}, {"id": "2005.06979", "submitter": "Michael Gastegger", "authors": "M. Gastegger, A. McSloy, M. Luya, K. T. Sch\\\"utt, R. J. Maurer", "title": "A deep neural network for molecular wave functions in quasi-atomic\n  minimal basis representation", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": "10.1063/5.0012911", "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of machine learning methods in quantum chemistry provides new\nmethods to revisit an old problem: Can the predictive accuracy of electronic\nstructure calculations be decoupled from their numerical bottlenecks? Previous\nattempts to answer this question have, among other methods, given rise to\nsemi-empirical quantum chemistry in minimal basis representation. We present an\nadaptation of the recently proposed SchNet for Orbitals (SchNOrb) deep\nconvolutional neural network model [Nature Commun. 10, 5024 (2019)] for\nelectronic wave functions in an optimised quasi-atomic minimal basis\nrepresentation. For five organic molecules ranging from 5 to 13 heavy atoms,\nthe model accurately predicts molecular orbital energies and wavefunctions and\nprovides access to derived properties for chemical bonding analysis.\nParticularly for larger molecules, the model outperforms the original\natomic-orbital-based SchNOrb method in terms of accuracy and scaling. We\nconclude by discussing the future potential of this approach in quantum\nchemical workflows.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 06:55:36 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 07:08:32 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Gastegger", "M.", ""], ["McSloy", "A.", ""], ["Luya", "M.", ""], ["Sch\u00fctt", "K. T.", ""], ["Maurer", "R. J.", ""]]}, {"id": "2005.07031", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Rodriguez Garcia, Gabriel Michau, M\\'elanie Ducoffe, Jayant\n  Sen Gupta, Olga Fink", "title": "Temporal signals to images: Monitoring the condition of industrial\n  assets with deep learning image processing algorithms", "comments": "13 pages, 5 figures, 2 tables", "journal-ref": null, "doi": "10.1177/1748006X21994446", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect anomalies in time series is considered highly valuable\nin numerous application domains. The sequential nature of time series objects\nis responsible for an additional feature complexity, ultimately requiring\nspecialized approaches in order to solve the task. Essential characteristics of\ntime series, situated outside the time domain, are often difficult to capture\nwith state-of-the-art anomaly detection methods when no transformations have\nbeen applied to the time series. Inspired by the success of deep learning\nmethods in computer vision, several studies have proposed transforming time\nseries into image-like representations, used as inputs for deep learning\nmodels, and have led to very promising results in classification tasks. In this\npaper, we first review the signal to image encoding approaches found in the\nliterature. Second, we propose modifications to some of their original\nformulations to make them more robust to the variability in large datasets.\nThird, we compare them on the basis of a common unsupervised task to\ndemonstrate how the choice of the encoding can impact the results when used in\nthe same deep learning architecture. We thus provide a comparison between six\nencoding algorithms with and without the proposed modifications. The selected\nencoding methods are Gramian Angular Field, Markov Transition Field, recurrence\nplot, grey scale encoding, spectrogram, and scalogram. We also compare the\nresults achieved with the raw signal used as input for another deep learning\nmodel. We demonstrate that some encodings have a competitive advantage and\nmight be worth considering within a deep learning framework. The comparison is\nperformed on a dataset collected and released by Airbus SAS, containing highly\ncomplex vibration measurements from real helicopter flight tests. The different\nencodings provide competitive results for anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 14:42:06 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:59:54 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 12:55:08 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 07:47:14 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Garcia", "Gabriel Rodriguez", ""], ["Michau", "Gabriel", ""], ["Ducoffe", "M\u00e9lanie", ""], ["Gupta", "Jayant Sen", ""], ["Fink", "Olga", ""]]}, {"id": "2005.07036", "submitter": "Xuewen Yao", "authors": "Xuewen Yao, Megan Micheletti, Mckensey Johnson, Kaya de Barbaro", "title": "Detection of Infant Crying in Real-World Home Environments Using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of social signal processing, audio event detection is a\npromising avenue for accessing daily behaviors that contribute to health and\nwell-being. However, despite advances in mobile computing and machine learning,\naudio behavior detection models are largely constrained to data collected in\ncontrolled settings, such as call centers. This is problematic as it means\ntheir performance is unlikely to generalize to real-world applications. In this\npaper, we present a novel dataset of infant distress vocalizations compiled\nfrom over 780 hours of real-world audio data, collected via recorders worn by\ninfants. We develop a model that combines deep spectrum and acoustic features\nto detect and classify infant distress vocalizations, which dramatically\noutperforms models trained on equivalent real-world data (F1 score of 0.630 vs\n0.166). We end by discussing how dataset size can facilitate such gains in\naccuracy, critical when considering noisy and complex naturalistic data.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 18:25:44 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 15:19:46 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 04:28:20 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 21:06:18 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yao", "Xuewen", ""], ["Micheletti", "Megan", ""], ["Johnson", "Mckensey", ""], ["de Barbaro", "Kaya", ""]]}, {"id": "2005.07037", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo and Vladimir Vovk", "title": "Training conformal predictors", "comments": "8 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiency criteria for conformal prediction, such as \\emph{observed\nfuzziness} (i.e., the sum of p-values associated with false labels), are\ncommonly used to \\emph{evaluate} the performance of given conformal predictors.\nHere, we investigate whether it is possible to exploit efficiency criteria to\n\\emph{learn} classifiers, both conformal predictors and point classifiers, by\nusing such criteria as training objective functions. The proposed idea is\nimplemented for the problem of binary classification of hand-written digits. By\nchoosing a 1-dimensional model class (with one real-valued free parameter), we\ncan solve the optimization problems through an (approximate) exhaustive search\nover (a discrete version of) the parameter space. Our empirical results suggest\nthat conformal predictors trained by minimizing their observed fuzziness\nperform better than conformal predictors trained in the traditional way by\nminimizing the \\emph{prediction error} of the corresponding point classifier.\nThey also have a reasonable performance in terms of their prediction error on\nthe test set.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 14:47:30 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Colombo", "Nicolo", ""], ["Vovk", "Vladimir", ""]]}, {"id": "2005.07041", "submitter": "Navjot Singh", "authors": "Navjot Singh, Deepesh Data, Jemin George, Suhas Diggavi", "title": "SQuARM-SGD: Communication-Efficient Momentum SGD for Decentralized\n  Optimization", "comments": "50 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1910.14280", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study communication-efficient decentralized training of\nlarge-scale machine learning models over a network. We propose and analyze\nSQuARM-SGD, a decentralized training algorithm, employing momentum and\ncompressed communication between nodes regulated by a locally computable\ntriggering rule. In SQuARM-SGD, each node performs a fixed number of local SGD\n(stochastic gradient descent) steps using Nesterov's momentum and then sends\nsparisified and quantized updates to its neighbors only when there is a\nsignificant change in its model parameters since the last time communication\noccurred. We provide convergence guarantees of our algorithm for\nstrongly-convex and non-convex smooth objectives. We believe that ours is the\nfirst theoretical analysis for compressed decentralized SGD with momentum\nupdates. We show that SQuARM-SGD converges at rate\n$\\mathcal{O}\\left(\\frac{1}{nT}\\right)$ for strongly-convex objectives, while\nfor non-convex objectives it converges at rate\n$\\mathcal{O}\\left(\\frac{1}{\\sqrt{nT}}\\right)$, thus matching the convergence\nrate of \\emph{vanilla} distributed SGD in both these settings. We corroborate\nour theoretical understanding with experiments and compare the performance of\nour algorithm with the state-of-the-art, showing that without sacrificing much\non the accuracy, SQuARM-SGD converges at a similar rate while saving\nsignificantly in total communicated bits.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 02:11:14 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 22:28:32 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Singh", "Navjot", ""], ["Data", "Deepesh", ""], ["George", "Jemin", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2005.07045", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Efficient and Stable Algorithms to Extend Greville's Method to\n  Partitioned Matrices Based on Inverse Cholesky Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greville's method has been utilized in (Broad Learn-ing System) BLS to\npropose an effective and efficient incremental learning system without\nretraining the whole network from the beginning. For a column-partitioned\nmatrix where the second part consists of p columns, Greville's method requires\np iterations to compute the pseudoinverse of the whole matrix from the\npseudoinverse of the first part. The incremental algorithms in BLS extend\nGreville's method to compute the pseudoinverse of the whole matrix from the\npseudoinverse of the first part by just 1 iteration, which have neglected some\npossible cases, and need further improvements in efficiency and numerical\nstability. In this paper, we propose an efficient and numerical stable\nalgorithm from Greville's method, to compute the pseudoinverse of the whole\nmatrix from the pseudoinverse of the first part by just 1 iteration, where all\npossible cases are considered, and the recently proposed inverse Cholesky\nfactorization can be applied to further reduce the computational complexity.\nFinally, we give the whole algorithm for column-partitioned matrices in BLS. On\nthe other hand, we also give the proposed algorithm for row-partitioned\nmatrices in BLS.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 14:53:19 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "2005.07062", "submitter": "Christian Schroeder de Witt", "authors": "Christian Schroeder de Witt, Bradley Gram-Hansen, Nantas Nardelli,\n  Andrew Gambardella, Rob Zinkov, Puneet Dokania, N. Siddharth, Ana Belen\n  Espinosa-Gonzalez, Ara Darzi, Philip Torr, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin", "title": "Simulation-Based Inference for Global Health Decisions", "comments": null, "journal-ref": "ICML Workshop on Machine Learning for Global Health,\n  Thirty-Seventh International Conference on Machine Learning (ICML 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has highlighted the importance of in-silico\nepidemiological modelling in predicting the dynamics of infectious diseases to\ninform health policy and decision makers about suitable prevention and\ncontainment strategies. Work in this setting involves solving challenging\ninference and control problems in individual-based models of ever increasing\ncomplexity. Here we discuss recent breakthroughs in machine learning,\nspecifically in simulation-based inference, and explore its potential as a\nnovel venue for model calibration to support the design and evaluation of\npublic health interventions. To further stimulate research, we are developing\nsoftware interfaces that turn two cornerstone COVID-19 and malaria epidemiology\nmodels COVID-sim, (https://github.com/mrc-ide/covid-sim/) and OpenMalaria\n(https://github.com/SwissTPH/openmalaria) into probabilistic programs, enabling\nefficient interpretable Bayesian inference within those simulators.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:29:45 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["de Witt", "Christian Schroeder", ""], ["Gram-Hansen", "Bradley", ""], ["Nardelli", "Nantas", ""], ["Gambardella", "Andrew", ""], ["Zinkov", "Rob", ""], ["Dokania", "Puneet", ""], ["Siddharth", "N.", ""], ["Espinosa-Gonzalez", "Ana Belen", ""], ["Darzi", "Ara", ""], ["Torr", "Philip", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""]]}, {"id": "2005.07076", "submitter": "Yi\\u{g}it Oktar", "authors": "Yigit Oktar, Mehmet Turkan", "title": "Evolutionary Simplicial Learning as a Generative and Compact Sparse\n  Framework for Classification", "comments": null, "journal-ref": null, "doi": "10.1016/j.sigpro.2020.107634", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning for sparse representations has been successful in many\nreconstruction tasks. Simplicial learning is an adaptation of dictionary\nlearning, where subspaces become clipped and acquire arbitrary offsets, taking\nthe form of simplices. Such adaptation is achieved through additional\nconstraints on sparse codes. Furthermore, an evolutionary approach can be\nchosen to determine the number and the dimensionality of simplices composing\nthe simplicial, in which most generative and compact simplicials are favored.\nThis paper proposes an evolutionary simplicial learning method as a generative\nand compact sparse framework for classification. The proposed approach is first\napplied on a one-class classification task and it appears as the most reliable\nmethod within the considered benchmark. Most surprising results are observed\nwhen evolutionary simplicial learning is considered within a multi-class\nclassification task. Since sparse representations are generative in nature,\nthey bear a fundamental problem of not being capable of distinguishing two\nclasses lying on the same subspace. This claim is validated through synthetic\nexperiments and superiority of simplicial learning even as a generative-only\napproach is demonstrated. Simplicial learning loses its superiority over\ndiscriminative methods in high-dimensional cases but can further be modified\nwith discriminative elements to achieve state-of-the-art performance in\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:44:56 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Oktar", "Yigit", ""], ["Turkan", "Mehmet", ""]]}, {"id": "2005.07078", "submitter": "Gabriel Michau Dr.", "authors": "Oliver Ammann, Gabriel Michau, Olga Fink", "title": "Anomaly Detection And Classification In Time Series With Kervolutional\n  Neural Networks", "comments": "9 pages, 1 figure, 4 tables", "journal-ref": "Proceedings of the 30th European Safety and Reliability Conference\n  and 15th Probabilistic Safety Assessment and Management Conference (ESREL2020\n  PSAM15)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the development of deep learning, end-to-end neural network\narchitectures have been increasingly applied to condition monitoring signals.\nThey have demonstrated superior performance for fault detection and\nclassification, in particular using convolutional neural networks. Even more\nrecently, an extension of the concept of convolution to the concept of\nkervolution has been proposed with some promising results in image\nclassification tasks. In this paper, we explore the potential of kervolutional\nneural networks applied to time series data. We demonstrate that using a\nmixture of convolutional and kervolutional layers improves the model\nperformance. The mixed model is first applied to a classification task in time\nseries, as a benchmark dataset. Subsequently, the proposed mixed architecture\nis used to detect anomalies in time series data recorded by accelerometers on\nhelicopters. We propose a residual-based anomaly detection approach using a\ntemporal auto-encoder. We demonstrate that mixing kervolutional with\nconvolutional layers in the encoder is more sensitive to variations in the\ninput data and is able to detect anomalous time series in a better way.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:45:11 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ammann", "Oliver", ""], ["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "2005.07093", "submitter": "Mart van Baalen", "authors": "Mart van Baalen and Christos Louizos and Markus Nagel and Rana Ali\n  Amjad and Ying Wang and Tijmen Blankevoort and Max Welling", "title": "Bayesian Bits: Unifying Quantization and Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Bayesian Bits, a practical method for joint mixed precision\nquantization and pruning through gradient based optimization. Bayesian Bits\nemploys a novel decomposition of the quantization operation, which sequentially\nconsiders doubling the bit width. At each new bit width, the residual error\nbetween the full precision value and the previously rounded value is quantized.\nWe then decide whether or not to add this quantized residual error for a higher\neffective bit width and lower quantization noise. By starting with a\npower-of-two bit width, this decomposition will always produce\nhardware-friendly configurations, and through an additional 0-bit option,\nserves as a unified view of pruning and quantization. Bayesian Bits then\nintroduces learnable stochastic gates, which collectively control the bit width\nof the given tensor. As a result, we can obtain low bit solutions by performing\napproximate inference over the gates, with prior distributions that encourage\nmost of them to be switched off. We experimentally validate our proposed method\non several benchmark datasets and show that we can learn pruned, mixed\nprecision networks that provide a better trade-off between accuracy and\nefficiency than their static bit width equivalents.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:00:34 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 10:10:46 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 11:27:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["van Baalen", "Mart", ""], ["Louizos", "Christos", ""], ["Nagel", "Markus", ""], ["Amjad", "Rana Ali", ""], ["Wang", "Ying", ""], ["Blankevoort", "Tijmen", ""], ["Welling", "Max", ""]]}, {"id": "2005.07107", "submitter": "Alexey Kutalev", "authors": "Alexey Kutalev", "title": "Natural Way to Overcome the Catastrophic Forgetting in Neural Networks", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": "10.25559/SITITO.16.202002.331-337", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not so long ago, a method was discovered that successfully overcomes the\ncatastrophic forgetting in neural networks. Although we know about the cases of\nusing this method to preserve skills when adapting pre-trained networks to\nparticular tasks, it has not obtained widespread distribution yet. In this\npaper, we would like to propose an alternative method of overcoming\ncatastrophic forgetting based on the total absolute signal passing through each\nconnection in the network. This method has a simple implementation and seems to\nus essentially close to the processes occurring in the brain of animals to\npreserve previously learned skills during subsequent learning. We hope that the\nease of implementation of this method will serve its wide application.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 11:17:57 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 17:44:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kutalev", "Alexey", ""]]}, {"id": "2005.07111", "submitter": "Madhumita Sushil", "authors": "Madhumita Sushil and Simon \\v{S}uster and Walter Daelemans", "title": "Distilling neural networks into skipgram-level decision lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several previous studies on explanation for recurrent neural networks focus\non approaches that find the most important input segments for a network as its\nexplanations. In that case, the manner in which these input segments combine\nwith each other to form an explanatory pattern remains unknown. To overcome\nthis, some previous work tries to find patterns (called rules) in the data that\nexplain neural outputs. However, their explanations are often insensitive to\nmodel parameters, which limits the scalability of text explanations. To\novercome these limitations, we propose a pipeline to explain RNNs by means of\ndecision lists (also called rules) over skipgrams. For evaluation of\nexplanations, we create a synthetic sepsis-identification dataset, as well as\napply our technique on additional clinical and sentiment analysis datasets. We\nfind that our technique persistently achieves high explanation fidelity and\nqualitatively interpretable rules.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:25:42 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 08:43:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Sushil", "Madhumita", ""], ["\u0160uster", "Simon", ""], ["Daelemans", "Walter", ""]]}, {"id": "2005.07114", "submitter": "Harshvardhan Sikka", "authors": "Harshvardhan Sikka", "title": "A Deeper Look at the Unsupervised Learning of Disentangled\n  Representations in $\\beta$-VAE from the Perspective of Core Object\n  Recognition", "comments": "65 Pages, 6 Figures, Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to recognize objects despite there being differences in\nappearance, known as Core Object Recognition, forms a critical part of human\nperception. While it is understood that the brain accomplishes Core Object\nRecognition through feedforward, hierarchical computations through the visual\nstream, the underlying algorithms that allow for invariant representations to\nform downstream is still not well understood. (DiCarlo et al., 2012) Various\ncomputational perceptual models have been built to attempt and tackle the\nobject identification task in an artificial perceptual setting. Artificial\nNeural Networks, computational graphs consisting of weighted edges and\nmathematical operations at vertices, are loosely inspired by neural networks in\nthe brain and have proven effective at various visual perceptual tasks,\nincluding object characterization and identification. (Pinto et al., 2008)\n(DiCarlo et al., 2012) For many data analysis tasks, learning representations\nwhere each dimension is statistically independent and thus disentangled from\nthe others is useful. If the underlying generative factors of the data are also\nstatistically independent, Bayesian inference of latent variables can form\ndisentangled representations. This thesis constitutes a research project\nexploring a generalization of the Variational Autoencoder (VAE), $\\beta$-VAE,\nthat aims to learn disentangled representations using variational inference.\n$\\beta$-VAE incorporates the hyperparameter $\\beta$, and enforces conditional\nindependence of its bottleneck neurons, which is in general not compatible with\nthe statistical independence of latent variables. This text examines this\narchitecture, and provides analytical and numerical arguments, with the goal of\ndemonstrating that this incompatibility leads to a non-monotonic inference\nperformance in $\\beta$-VAE with a finite optimal $\\beta$.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 08:14:03 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Sikka", "Harshvardhan", ""]]}, {"id": "2005.07115", "submitter": "Ziheng Duan", "authors": "Haoyan Xu, Runjian Chen, Yunsheng Bai, Ziheng Duan, Jie Feng, Yizhou\n  Sun, Wei Wang", "title": "CoSimGNN: Towards Large-scale Graph Similarity Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to compute similarity scores between graphs based on metrics such\nas Graph Edit Distance (GED) is important in many real-world applications, such\nas 3D action recognition and biological molecular identification. Computing\nexact GED values is typically an NP-hard problem and traditional algorithms\nusually achieve an unsatisfactory trade-off between accuracy and efficiency.\nRecently, Graph Neural Networks (GNNs) provide a data-driven solution for this\ntask, which is more efficient while maintaining prediction accuracy in small\ngraph (around 10 nodes per graph) similarity computation. Existing GNN-based\nmethods, which either respectively embed two graphs (lack of low-level\ncross-graph interactions) or deploy cross-graph interactions for whole graph\npairs (redundant and time-consuming), are still not able to achieve competitive\nresults when the number of nodes in graphs increases. In this paper, we focus\non similarity computation for large-scale graphs and propose the\n\"embedding-coarsening-matching\" framework, which first embeds and coarsens\nlarge graphs to coarsened graphs with denser local topology and then deploys\nfine-grained interactions on the coarsened graphs for the final similarity\nscores.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:33:13 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 18:06:11 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 11:53:48 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 10:21:57 GMT"}, {"version": "v5", "created": "Mon, 28 Jun 2021 16:48:45 GMT"}, {"version": "v6", "created": "Tue, 29 Jun 2021 15:20:19 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Xu", "Haoyan", ""], ["Chen", "Runjian", ""], ["Bai", "Yunsheng", ""], ["Duan", "Ziheng", ""], ["Feng", "Jie", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "2005.07134", "submitter": "Christos Chatzichristos", "authors": "Christos Chatzichristos, Eleftherios Kofidis, Lieven De Lathauwer,\n  Sergios Theodoridis, Sabine Van Huffel", "title": "Early soft and flexible fusion of EEG and fMRI via tensor decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data fusion refers to the joint analysis of multiple datasets which provide\ncomplementary views of the same task. In this preprint, the problem of jointly\nanalyzing electroencephalography (EEG) and functional Magnetic Resonance\nImaging (fMRI) data is considered. Jointly analyzing EEG and fMRI measurements\nis highly beneficial for studying brain function because these modalities have\ncomplementary spatiotemporal resolution: EEG offers good temporal resolution\nwhile fMRI is better in its spatial resolution. The fusion methods reported so\nfar ignore the underlying multi-way nature of the data in at least one of the\nmodalities and/or rely on very strong assumptions about the relation of the two\ndatasets. In this preprint, these two points are addressed by adopting for the\nfirst time tensor models in the two modalities while also exploring double\ncoupled tensor decompositions and by following soft and flexible coupling\napproaches to implement the multi-modal analysis. To cope with the Event\nRelated Potential (ERP) variability in EEG, the PARAFAC2 model is adopted. The\nresults obtained are compared against those of parallel Independent Component\nAnalysis (ICA) and hard coupling alternatives in both simulated and real data.\nOur results confirm the superiority of tensorial methods over methods based on\nICA. In scenarios that do not meet the assumptions underlying hard coupling,\nthe advantage of soft and flexible coupled decompositions is clearly\ndemonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:57:33 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Chatzichristos", "Christos", ""], ["Kofidis", "Eleftherios", ""], ["De Lathauwer", "Lieven", ""], ["Theodoridis", "Sergios", ""], ["Van Huffel", "Sabine", ""]]}, {"id": "2005.07173", "submitter": "Daniel Fremont", "authors": "Daniel J. Fremont, Johnathan Chiu, Dragos D. Margineantu, Denis\n  Osipychev, and Sanjit A. Seshia", "title": "Formal Analysis and Redesign of a Neural Network-Based Aircraft Taxiing\n  System with VerifAI", "comments": "Full version of a CAV 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a unified approach to rigorous design of safety-critical\nautonomous systems using the VerifAI toolkit for formal analysis of AI-based\nsystems. VerifAI provides an integrated toolchain for tasks spanning the design\nprocess, including modeling, falsification, debugging, and ML component\nretraining. We evaluate all of these applications in an industrial case study\non an experimental autonomous aircraft taxiing system developed by Boeing,\nwhich uses a neural network to track the centerline of a runway. We define\nrunway scenarios using the Scenic probabilistic programming language, and use\nthem to drive tests in the X-Plane flight simulator. We first perform\nfalsification, automatically finding environment conditions causing the system\nto violate its specification by deviating significantly from the centerline (or\neven leaving the runway entirely). Next, we use counterexample analysis to\nidentify distinct failure cases, and confirm their root causes with specialized\ntesting. Finally, we use the results of falsification and debugging to retrain\nthe network, eliminating several failure cases and improving the overall\nperformance of the closed-loop system.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:42:14 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Fremont", "Daniel J.", ""], ["Chiu", "Johnathan", ""], ["Margineantu", "Dragos D.", ""], ["Osipychev", "Denis", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2005.07186", "submitter": "Michael Dusenberry", "authors": "Michael W. Dusenberry, Ghassen Jerfel, Yeming Wen, Yi-An Ma, Jasper\n  Snoek, Katherine Heller, Balaji Lakshminarayanan, Dustin Tran", "title": "Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors", "comments": "Published in the International Conference on Machine Learning (ICML)\n  2020. Code available at https://github.com/google/edward2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) demonstrate promising success in improving\nthe robustness and uncertainty quantification of modern deep learning. However,\nthey generally struggle with underfitting at scale and parameter efficiency. On\nthe other hand, deep ensembles have emerged as alternatives for uncertainty\nquantification that, while outperforming BNNs on certain problems, also suffer\nfrom efficiency issues. It remains unclear how to combine the strengths of\nthese two approaches and remediate their common issues. To tackle this\nchallenge, we propose a rank-1 parameterization of BNNs, where each weight\nmatrix involves only a distribution on a rank-1 subspace. We also revisit the\nuse of mixture approximate posteriors to capture multiple modes, where unlike\ntypical mixtures, this approach admits a significantly smaller memory increase\n(e.g., only a 0.4% increase for a ResNet-50 mixture of size 10). We perform a\nsystematic empirical study on the choices of prior, variational posterior, and\nmethods to improve training. For ResNet-50 on ImageNet, Wide ResNet 28-10 on\nCIFAR-10/100, and an RNN on MIMIC-III, rank-1 BNNs achieve state-of-the-art\nperformance across log-likelihood, accuracy, and calibration on the test sets\nand out-of-distribution variants.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:58:59 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 20:39:11 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Dusenberry", "Michael W.", ""], ["Jerfel", "Ghassen", ""], ["Wen", "Yeming", ""], ["Ma", "Yi-An", ""], ["Snoek", "Jasper", ""], ["Heller", "Katherine", ""], ["Lakshminarayanan", "Balaji", ""], ["Tran", "Dustin", ""]]}, {"id": "2005.07243", "submitter": "Athanasios Davvetas", "authors": "Athanasios Davvetas, Iraklis A. Klampanos", "title": "Unsupervised Severe Weather Detection Via Joint Representation Learning\n  Over Textual and Weather Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observing a phenomenon, severe cases or anomalies are often\ncharacterised by deviation from the expected data distribution. However,\nnon-deviating data samples may also implicitly lead to severe outcomes. In the\ncase of unsupervised severe weather detection, these data samples can lead to\nmispredictions, since the predictors of severe weather are often not directly\nobserved as features. We posit that incorporating external or auxiliary\ninformation, such as the outcome of an external task or an observation, can\nimprove the decision boundaries of an unsupervised detection algorithm. In this\npaper, we increase the effectiveness of a clustering method to detect cases of\nsevere weather by learning augmented and linearly separable latent\nrepresentations.We evaluate our solution against three individual cases of\nsevere weather, namely windstorms, floods and tornado outbreaks.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 20:13:39 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""]]}, {"id": "2005.07275", "submitter": "Tim Barfoot", "authors": "Timothy D. Barfoot and Gabriele M. T. D'Eleuterio", "title": "Variational Inference as Iterative Projection in a Bayesian Hilbert\n  Space", "comments": "28 pages, 7 figures, submitted to Annals of Mathematics and\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian inference is an important machine-learning tool that\nfinds application from statistics to robotics. The goal is to find an\napproximate probability density function (PDF) from a chosen family that is in\nsome sense `closest' to the full Bayesian posterior. Closeness is typically\ndefined through the selection of an appropriate loss functional such as the\nKullback-Leibler (KL) divergence. In this paper, we explore a new formulation\nof variational inference by exploiting the fact that the set of PDFs\nconstitutes a Bayesian Hilbert space under careful definitions of vector\naddition, scalar multiplication and an inner product. We show that variational\ninference based on KL divergence then amounts to an iterative projection of the\nBayesian posterior onto a subspace corresponding to the selected approximation\nfamily. In fact, the inner product chosen for the Bayesian Hilbert space\nsuggests the definition of a new measure of the information contained in a PDF\nand in turn a new divergence is introduced. Each step in the iterative\nprojection is equivalent to a local minimization of this divergence. We present\nan example Bayesian subspace based on exponentiated Hermite polynomials as well\nas work through the details of this general framework for the specific case of\nthe multivariate Gaussian approximation family and show the equivalence to\nanother Gaussian variational inference approach. We furthermore discuss the\nimplications for systems that exhibit sparsity, which is handled naturally in\nBayesian space.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 21:33:31 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Barfoot", "Timothy D.", ""], ["D'Eleuterio", "Gabriele M. T.", ""]]}, {"id": "2005.07292", "submitter": "Ekaterina Lobacheva Ms", "authors": "Nadezhda Chirkova, Ekaterina Lobacheva, Dmitry Vetrov", "title": "Deep Ensembles on a Fixed Memory Budget: One Wide Network or Several\n  Thinner Ones?", "comments": "Under review by the International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the generally accepted views of modern deep learning is that\nincreasing the number of parameters usually leads to better quality. The two\neasiest ways to increase the number of parameters is to increase the size of\nthe network, e.g. width, or to train a deep ensemble; both approaches improve\nthe performance in practice. In this work, we consider a fixed memory budget\nsetting, and investigate, what is more effective: to train a single wide\nnetwork, or to perform a memory split -- to train an ensemble of several\nthinner networks, with the same total number of parameters? We find that, for\nlarge enough budgets, the number of networks in the ensemble, corresponding to\nthe optimal memory split, is usually larger than one. Interestingly, this\neffect holds for the commonly used sizes of the standard architectures. For\nexample, one WideResNet-28-10 achieves significantly worse test accuracy on\nCIFAR-100 than an ensemble of sixteen thinner WideResNets: 80.6% and 82.52%\ncorrespondingly. We call the described effect the Memory Split Advantage and\nshow that it holds for a variety of datasets and model architectures.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 23:08:31 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Chirkova", "Nadezhda", ""], ["Lobacheva", "Ekaterina", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2005.07293", "submitter": "Ninareh Mehrabi", "authors": "Ninareh Mehrabi, Yuzhong Huang, Fred Morstatter", "title": "Statistical Equity: A Fairness Classification Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems have been shown to propagate the societal errors of\nthe past. In light of this, a wealth of research focuses on designing solutions\nthat are \"fair.\" Even with this abundance of work, there is no singular\ndefinition of fairness, mainly because fairness is subjective and context\ndependent. We propose a new fairness definition, motivated by the principle of\nequity, that considers existing biases in the data and attempts to make\nequitable decisions that account for these previous historical biases. We\nformalize our definition of fairness, and motivate it with its appropriate\ncontexts. Next, we operationalize it for equitable classification. We perform\nmultiple automatic and human evaluations to show the effectiveness of our\ndefinition and demonstrate its utility for aspects of fairness, such as the\nfeedback loop.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 23:19:38 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mehrabi", "Ninareh", ""], ["Huang", "Yuzhong", ""], ["Morstatter", "Fred", ""]]}, {"id": "2005.07308", "submitter": "Fl\\'avia Alves", "authors": "Fl\\'avia Alves, Martin Gairing, Frans A. Oliehoek and Thanh-Toan Do", "title": "Sensor Data for Human Activity Recognition: Feature Representation and\n  Benchmarking", "comments": "28 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Human Activity Recognition (HAR) focuses on obtaining and\nanalysing data captured from monitoring devices (e.g. sensors). There is a wide\nrange of applications within the field; for instance, assisted living, security\nsurveillance, and intelligent transportation. In HAR, the development of\nActivity Recognition models is dependent upon the data captured by these\ndevices and the methods used to analyse them, which directly affect performance\nmetrics. In this work, we address the issue of accurately recognising human\nactivities using different Machine Learning (ML) techniques. We propose a new\nfeature representation based on consecutive occurring observations and compare\nit against previously used feature representations using a wide range of\nclassification methods. Experimental results demonstrate that techniques based\non the proposed representation outperform the baselines and a better accuracy\nwas achieved for both highly and less frequent actions. We also investigate how\nthe addition of further features and their pre-processing techniques affect\nperformance results leading to state-of-the-art accuracy on a Human Activity\nRecognition dataset.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 00:46:55 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Alves", "Fl\u00e1via", ""], ["Gairing", "Martin", ""], ["Oliehoek", "Frans A.", ""], ["Do", "Thanh-Toan", ""]]}, {"id": "2005.07342", "submitter": "Kean Ming Tan", "authors": "Jiaying Zhou, Jie Ding, Kean Ming Tan, Vahid Tarokh", "title": "Model Linkage Selection for Cooperative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid developments in data collecting devices and computation platforms\nproduce an emerging number of learners and data modalities in many scientific\ndomains. We consider the setting in which each learner holds a pair of\nparametric statistical model and a specific data source, with the goal of\nintegrating information across a set of learners to enhance the prediction\naccuracy of a specific learner. One natural way to integrate information is to\nbuild a joint model across a set of learners that shares common parameters of\ninterest. However, the parameter sharing patterns across a set of learners are\nnot known a priori. Misspecifying the parameter sharing patterns and the\nparametric statistical model for each learner yields a biased estimator and\ndegrades the prediction accuracy of the joint model. In this paper, we propose\na novel framework for integrating information across a set of learners that is\nrobust against model misspecification and misspecified parameter sharing\npatterns. The main crux is to sequentially incorporates additional learners\nthat can enhance the prediction accuracy of an existing joint model based on a\nuser-specified parameter sharing patterns across a set of learners, starting\nfrom a model with one learner. Theoretically, we show that the proposed method\ncan data-adaptively select the correct parameter sharing patterns based on a\nuser-specified parameter sharing patterns, and thus enhances the prediction\naccuracy of a learner. Extensive numerical studies are performed to evaluate\nthe performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 03:44:01 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 19:09:54 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhou", "Jiaying", ""], ["Ding", "Jie", ""], ["Tan", "Kean Ming", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2005.07347", "submitter": "Tianhang Zheng", "authors": "Tianhang Zheng, Di Wang, Baochun Li, Jinhui Xu", "title": "Towards Assessment of Randomized Smoothing Mechanisms for Certifying\n  Adversarial Robustness", "comments": "Correct the some details of the theorems and proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a certified defensive technique, randomized smoothing has received\nconsiderable attention due to its scalability to large datasets and neural\nnetworks. However, several important questions remain unanswered, such as (i)\nwhether the Gaussian mechanism is an appropriate option for certifying\n$\\ell_2$-norm robustness, and (ii) whether there is an appropriate randomized\n(smoothing) mechanism to certify $\\ell_\\infty$-norm robustness. To shed light\non these questions, we argue that the main difficulty is how to assess the\nappropriateness of each randomized mechanism. In this paper, we propose a\ngeneric framework that connects the existing frameworks in\n\\cite{lecuyer2018certified, li2019certified}, to assess randomized mechanisms.\nUnder our framework, for a randomized mechanism that can certify a certain\nextent of robustness, we define the magnitude of its required additive noise as\nthe metric for assessing its appropriateness. We also prove lower bounds on\nthis metric for the $\\ell_2$-norm and $\\ell_\\infty$-norm cases as the criteria\nfor assessment. Based on our framework, we assess the Gaussian and Exponential\nmechanisms by comparing the magnitude of additive noise required by these\nmechanisms and the lower bounds (criteria). We first conclude that the Gaussian\nmechanism is indeed an appropriate option to certify $\\ell_2$-norm robustness.\nSurprisingly, we show that the Gaussian mechanism is also an appropriate option\nfor certifying $\\ell_\\infty$-norm robustness, instead of the Exponential\nmechanism. Finally, we generalize our framework to $\\ell_p$-norm for any\n$p\\geq2$. Our theoretical findings are verified by evaluations on CIFAR10 and\nImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 03:54:53 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 15:49:06 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 18:39:33 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zheng", "Tianhang", ""], ["Wang", "Di", ""], ["Li", "Baochun", ""], ["Xu", "Jinhui", ""]]}, {"id": "2005.07353", "submitter": "Jacob Montiel", "authors": "Jacob Montiel, Rory Mitchell, Eibe Frank, Bernhard Pfahringer, Talel\n  Abdessalem, Albert Bifet", "title": "Adaptive XGBoost for Evolving Data Streams", "comments": "To be published in Proceedings of the International Joint Conference\n  on Neural Networks (IJCNN) 2020, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is an ensemble method that combines base models in a sequential\nmanner to achieve high predictive accuracy. A popular learning algorithm based\non this ensemble method is eXtreme Gradient Boosting (XGB). We present an\nadaptation of XGB for classification of evolving data streams. In this setting,\nnew data arrives over time and the relationship between the class and the\nfeatures may change in the process, thus exhibiting concept drift. The proposed\nmethod creates new members of the ensemble from mini-batches of data as new\ndata becomes available. The maximum ensemble size is fixed, but learning does\nnot stop when this size is reached because the ensemble is updated on new data\nto ensure consistency with the current concept. We also explore the use of\nconcept drift detection to trigger a mechanism to update the ensemble. We test\nour method on real and synthetic data with concept drift and compare it against\nbatch-incremental and instance-incremental classification methods for data\nstreams.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 04:28:15 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Montiel", "Jacob", ""], ["Mitchell", "Rory", ""], ["Frank", "Eibe", ""], ["Pfahringer", "Bernhard", ""], ["Abdessalem", "Talel", ""], ["Bifet", "Albert", ""]]}, {"id": "2005.07360", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran", "title": "Learning Rate Annealing Can Provably Help Generalization, Even for\n  Convex Problems", "comments": "4 pages plus appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rate schedule can significantly affect generalization performance in\nmodern neural networks, but the reasons for this are not yet understood.\nLi-Wei-Ma (2019) recently proved this behavior can exist in a simplified\nnon-convex neural-network setting. In this note, we show that this phenomenon\ncan exist even for convex learning problems -- in particular, linear regression\nin 2 dimensions.\n  We give a toy convex problem where learning rate annealing (large initial\nlearning rate, followed by small learning rate) can lead gradient descent to\nminima with provably better generalization than using a small learning rate\nthroughout. In our case, this occurs due to a combination of the mismatch\nbetween the test and train loss landscapes, and early-stopping.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 05:16:32 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Nakkiran", "Preetum", ""]]}, {"id": "2005.07385", "submitter": "Mattias Tiger", "authors": "Mattias Tiger, David Bergstr\\\"om, Andreas Norrstig, Fredrik Heintz", "title": "Enhancing Lattice-based Motion Planning with Introspective Learning and\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice-based motion planning is a hybrid planning method where a plan made\nup of discrete actions simultaneously is a physically feasible trajectory. The\nplanning takes both discrete and continuous aspects into account, for example\naction pre-conditions and collision-free action-duration in the configuration\nspace. Safe motion planing rely on well-calibrated safety-margins for collision\nchecking. The trajectory tracking controller must further be able to reliably\nexecute the motions within this safety margin for the execution to be safe. In\nthis work we are concerned with introspective learning and reasoning about\ncontroller performance over time. Normal controller execution of the different\nactions is learned using reliable and uncertainty-aware machine learning\ntechniques. By correcting for execution bias we manage to substantially reduce\nthe safety margin of motion actions. Reasoning takes place to both verify that\nthe learned models stays safe and to improve collision checking effectiveness\nin the motion planner by the use of more accurate execution predictions with a\nsmaller safety margin. The presented approach allows for explicit awareness of\ncontroller performance under normal circumstances, and timely detection of\nincorrect performance in abnormal circumstances. Evaluation is made on the\nnonlinear dynamics of a quadcopter in 3D using simulation. Video:\nhttps://youtu.be/STmZduvSUMM\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 07:16:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Tiger", "Mattias", ""], ["Bergstr\u00f6m", "David", ""], ["Norrstig", "Andreas", ""], ["Heintz", "Fredrik", ""]]}, {"id": "2005.07402", "submitter": "Hideaki Ishibashi Ph.D", "authors": "Hideaki Ishibashi and Hideitsu Hino", "title": "Stopping criterion for active learning based on deterministic\n  generalization bounds", "comments": "Accepted for publication at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is a framework in which the learning machine can select the\nsamples to be used for training. This technique is promising, particularly when\nthe cost of data acquisition and labeling is high. In active learning,\ndetermining the timing at which learning should be stopped is a critical issue.\nIn this study, we propose a criterion for automatically stopping active\nlearning. The proposed stopping criterion is based on the difference in the\nexpected generalization errors and hypothesis testing. We derive a novel upper\nbound for the difference in expected generalization errors before and after\nobtaining a new training datum based on PAC-Bayesian theory. Unlike ordinary\nPAC-Bayesian bounds, though, the proposed bound is deterministic; hence, there\nis no uncontrollable trade-off between the confidence and tightness of the\ninequality. We combine the upper bound with a statistical test to derive a\nstopping criterion for active learning. We demonstrate the effectiveness of the\nproposed method via experiments with both artificial and real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 08:15:47 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Ishibashi", "Hideaki", ""], ["Hino", "Hideitsu", ""]]}, {"id": "2005.07427", "submitter": "Chen Luo", "authors": "Lei Cai, Zhengzhang Chen, Chen Luo, Jiaping Gui, Jingchao Ni, Ding Li,\n  Haifeng Chen", "title": "Structural Temporal Graph Neural Networks for Anomaly Detection in\n  Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting anomalies in dynamic graphs is a vital task, with numerous\npractical applications in areas such as security, finance, and social media.\nPrevious network embedding based methods have been mostly focusing on learning\ngood node representations, whereas largely ignoring the subgraph structural\nchanges related to the target nodes in dynamic graphs. In this paper, we\npropose StrGNN, an end-to-end structural temporal Graph Neural Network model\nfor detecting anomalous edges in dynamic graphs. In particular, we first\nextract the $h$-hop enclosing subgraph centered on the target edge and propose\nthe node labeling function to identify the role of each node in the subgraph.\nThen, we leverage graph convolution operation and Sortpooling layer to extract\nthe fixed-size feature from each snapshot/timestamp. Based on the extracted\nfeatures, we utilize Gated recurrent units (GRUs) to capture the temporal\ninformation for anomaly detection. Extensive experiments on six benchmark\ndatasets and a real enterprise security system demonstrate the effectiveness of\nStrGNN.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:17:08 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 08:38:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cai", "Lei", ""], ["Chen", "Zhengzhang", ""], ["Luo", "Chen", ""], ["Gui", "Jiaping", ""], ["Ni", "Jingchao", ""], ["Li", "Ding", ""], ["Chen", "Haifeng", ""]]}, {"id": "2005.07443", "submitter": "Alonso Marco", "authors": "Alonso Marco, Alexander von Rohr, Dominik Baumann, Jos\\'e Miguel\n  Hern\\'andez-Lobato and Sebastian Trimpe", "title": "Excursion Search for Constrained Bayesian Optimization under a Limited\n  Budget of Failures", "comments": "14 pages, 4 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning to ride a bike, a child falls down a number of times before\nachieving the first success. As falling down usually has only mild\nconsequences, it can be seen as a tolerable failure in exchange for a faster\nlearning process, as it provides rich information about an undesired behavior.\nIn the context of Bayesian optimization under unknown constraints (BOC),\ntypical strategies for safe learning explore conservatively and avoid failures\nby all means. On the other side of the spectrum, non conservative BOC\nalgorithms that allow failing may fail an unbounded number of times before\nreaching the optimum. In this work, we propose a novel decision maker grounded\nin control theory that controls the amount of risk we allow in the search as a\nfunction of a given budget of failures. Empirical validation shows that our\nalgorithm uses the failures budget more efficiently in a variety of\noptimization experiments, and generally achieves lower regret, than\nstate-of-the-art methods. In addition, we propose an original algorithm for\nunconstrained Bayesian optimization inspired by the notion of excursion sets in\nstochastic processes, upon which the failures-aware algorithm is built.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:54:09 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Marco", "Alonso", ""], ["von Rohr", "Alexander", ""], ["Baumann", "Dominik", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2005.07473", "submitter": "Fabricio Murai", "authors": "B\\'arbara Silveira, Henrique S. Silva, Fabricio Murai, Ana Paula Couto\n  da Silva", "title": "Predicting User Emotional Tone in Mental Disorder Online Communities", "comments": "8 pages, 3 figures, 3 tables", "journal-ref": "Future Generation Computer Systems, Volume 125, 2021, Pages\n  641-651, ISSN 0167-739X", "doi": "10.1016/j.future.2021.07.014", "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Online Social Networks have become an important medium for\npeople who suffer from mental disorders to share moments of hardship, and\nreceive emotional and informational support. In this work, we analyze how\ndiscussions in Reddit communities related to mental disorders can help improve\nthe health conditions of their users. Using the emotional tone of users'\nwriting as a proxy for emotional state, we uncover relationships between user\ninteractions and state changes. First, we observe that authors of negative\nposts often write rosier comments after engaging in discussions, indicating\nthat users' emotional state can improve due to social support. Second, we build\nmodels based on SOTA text embedding techniques and RNNs to predict shifts in\nemotional tone. This differs from most of related work, which focuses primarily\non detecting mental disorders from user activity. We demonstrate the\nfeasibility of accurately predicting the users' reactions to the interactions\nexperienced in these platforms, and present some examples which illustrate that\nthe models are correctly capturing the effects of comments on the author's\nemotional tone. Our models hold promising implications for interventions to\nprovide support for people struggling with mental illnesses.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 11:25:08 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 12:48:29 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Silveira", "B\u00e1rbara", ""], ["Silva", "Henrique S.", ""], ["Murai", "Fabricio", ""], ["da Silva", "Ana Paula Couto", ""]]}, {"id": "2005.07496", "submitter": "Joakim Skarding", "authors": "Joakim Skarding, Bogdan Gabrys and Katarzyna Musial", "title": "Foundations and modelling of dynamic networks using Dynamic Graph Neural\n  Networks: A survey", "comments": "28 pages, 9 figures, 8 tables", "journal-ref": "in IEEE Access, vol. 9, pp. 79143-79168, 2021", "doi": "10.1109/ACCESS.2021.3082932", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic networks are used in a wide range of fields, including social network\nanalysis, recommender systems, and epidemiology. Representing complex networks\nas structures changing over time allow network models to leverage not only\nstructural but also temporal patterns. However, as dynamic network literature\nstems from diverse fields and makes use of inconsistent terminology, it is\nchallenging to navigate. Meanwhile, graph neural networks (GNNs) have gained a\nlot of attention in recent years for their ability to perform well on a range\nof network science tasks, such as link prediction and node classification.\nDespite the popularity of graph neural networks and the proven benefits of\ndynamic network models, there has been little focus on graph neural networks\nfor dynamic networks. To address the challenges resulting from the fact that\nthis research crosses diverse fields as well as to survey dynamic graph neural\nnetworks, this work is split into two main parts. First, to address the\nambiguity of the dynamic network terminology we establish a foundation of\ndynamic networks with consistent, detailed terminology and notation. Second, we\npresent a comprehensive survey of dynamic graph neural network models using the\nproposed terminology\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 23:56:38 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 07:05:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Skarding", "Joakim", ""], ["Gabrys", "Bogdan", ""], ["Musial", "Katarzyna", ""]]}, {"id": "2005.07513", "submitter": "Sandy Huang", "authors": "Abbas Abdolmaleki, Sandy H. Huang, Leonard Hasenclever, Michael\n  Neunert, H. Francis Song, Martina Zambelli, Murilo F. Martins, Nicolas Heess,\n  Raia Hadsell, Martin Riedmiller", "title": "A Distributional View on Multi-Objective Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems require trading off multiple competing objectives.\nHowever, these objectives are often in different units and/or scales, which can\nmake it challenging for practitioners to express numerical preferences over\nobjectives in their native units. In this paper we propose a novel algorithm\nfor multi-objective reinforcement learning that enables setting desired\npreferences for objectives in a scale-invariant way. We propose to learn an\naction distribution for each objective, and we use supervised learning to fit a\nparametric policy to a combination of these distributions. We demonstrate the\neffectiveness of our approach on challenging high-dimensional real and\nsimulated robotics tasks, and show that setting different preferences in our\nframework allows us to trace out the space of nondominated solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:02:17 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Abdolmaleki", "Abbas", ""], ["Huang", "Sandy H.", ""], ["Hasenclever", "Leonard", ""], ["Neunert", "Michael", ""], ["Song", "H. Francis", ""], ["Zambelli", "Martina", ""], ["Martins", "Murilo F.", ""], ["Heess", "Nicolas", ""], ["Hadsell", "Raia", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2005.07530", "submitter": "Ine Jernelv", "authors": "Ine L. Jernelv, Dag Roar Hjelme, Yuji Matsuura, Astrid Aksnes", "title": "Convolutional neural networks for classification and regression analysis\n  of one-dimensional spectral data", "comments": "10 pages of article, 8 pages of Supplementary Information, 6 figures\n  in article, 3 figures in SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional neural networks (CNNs) are widely used for image recognition\nand text analysis, and have been suggested for application on one-dimensional\ndata as a way to reduce the need for pre-processing steps. Pre-processing is an\nintegral part of multivariate analysis, but determination of the optimal\npre-processing methods can be time-consuming due to the large number of\navailable methods. In this work, the performance of a CNN was investigated for\nclassification and regression analysis of spectral data. The CNN was compared\nwith various other chemometric methods, including support vector machines\n(SVMs) for classification and partial least squares regression (PLSR) for\nregression analysis. The comparisons were made both on raw data, and on data\nthat had gone through pre-processing and/or feature selection methods. The\nmodels were used on spectral data acquired with methods based on near-infrared,\nmid-infrared, and Raman spectroscopy. For the classification datasets the\nmodels were evaluated based on the percentage of correctly classified\nobservations, while for regression analysis the models were assessed based on\nthe coefficient of determination (R$^2$). Our results show that CNNs can\noutperform standard chemometric methods, especially for classification tasks\nwhere no pre-processing is used. However, both CNN and the standard chemometric\nmethods see improved performance when proper pre-processing and feature\nselection methods are used. These results demonstrate some of the capabilities\nand limitations of CNNs used on one-dimensional data.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:20:05 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Jernelv", "Ine L.", ""], ["Hjelme", "Dag Roar", ""], ["Matsuura", "Yuji", ""], ["Aksnes", "Astrid", ""]]}, {"id": "2005.07541", "submitter": "Tim Hertweck", "authors": "Tim Hertweck, Martin Riedmiller, Michael Bloesch, Jost Tobias\n  Springenberg, Noah Siegel, Markus Wulfmeier, Roland Hafner, Nicolas Heess", "title": "Simple Sensor Intentions for Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern reinforcement learning algorithms can learn solutions to increasingly\ndifficult control problems while at the same time reduce the amount of prior\nknowledge needed for their application. One of the remaining challenges is the\ndefinition of reward schemes that appropriately facilitate exploration without\nbiasing the solution in undesirable ways, and that can be implemented on real\nrobotic systems without expensive instrumentation. In this paper we focus on a\nsetting in which goal tasks are defined via simple sparse rewards, and\nexploration is facilitated via agent-internal auxiliary tasks. We introduce the\nidea of simple sensor intentions (SSIs) as a generic way to define auxiliary\ntasks. SSIs reduce the amount of prior knowledge that is required to define\nsuitable rewards. They can further be computed directly from raw sensor streams\nand thus do not require expensive and possibly brittle state estimation on real\nsystems. We demonstrate that a learning system based on these rewards can solve\ncomplex robotic tasks in simulation and in real world settings. In particular,\nwe show that a real robotic arm can learn to grasp and lift and solve a\nBall-in-a-Cup task from scratch, when only raw sensor streams are used for both\ncontroller input and in the auxiliary reward definition.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:46:55 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Hertweck", "Tim", ""], ["Riedmiller", "Martin", ""], ["Bloesch", "Michael", ""], ["Springenberg", "Jost Tobias", ""], ["Siegel", "Noah", ""], ["Wulfmeier", "Markus", ""], ["Hafner", "Roland", ""], ["Heess", "Nicolas", ""]]}, {"id": "2005.07572", "submitter": "Donald Martin Jr.", "authors": "Donald Martin Jr. (1), Vinodkumar Prabhakaran (1), Jill Kuhlberg (2),\n  Andrew Smart (1), William S. Isaac (3) ((1) Google (2) System Stars (3)\n  DeepMind)", "title": "Participatory Problem Formulation for Fairer Machine Learning Through\n  Community Based System Dynamics", "comments": "Eighth Annual Conference on Learning Representations (ICLR 2020),\n  Virtual Workshop: Machine Learning in Real Life, April 26, 2020, 6 pages, 1\n  figure, fix comment typo, fix author name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on algorithmic fairness has highlighted that the problem\nformulation phase of ML system development can be a key source of bias that has\nsignificant downstream impacts on ML system fairness outcomes. However, very\nlittle attention has been paid to methods for improving the fairness efficacy\nof this critical phase of ML system development. Current practice neither\naccounts for the dynamic complexity of high-stakes domains nor incorporates the\nperspectives of vulnerable stakeholders. In this paper we introduce community\nbased system dynamics (CBSD) as an approach to enable the participation of\ntypically excluded stakeholders in the problem formulation phase of the ML\nsystem development process and facilitate the deep problem understanding\nrequired to mitigate bias during this crucial stage.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 14:41:43 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 03:54:30 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 13:57:28 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Martin", "Donald", "Jr."], ["Prabhakaran", "Vinodkumar", ""], ["Kuhlberg", "Jill", ""], ["Smart", "Andrew", ""], ["Isaac", "William S.", ""]]}, {"id": "2005.07587", "submitter": "Yufei Yi", "authors": "Yufei Yi, Matey Neykov", "title": "Non-Sparse PCA in High Dimensions via Cone Projected Power Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a cone projected power iteration algorithm to\nrecover the first principal eigenvector from a noisy positive semidefinite\nmatrix. When the true principal eigenvector is assumed to belong to a convex\ncone, the proposed algorithm is fast and has a tractable error. Specifically,\nthe method achieves polynomial time complexity for certain convex cones\nequipped with fast projection such as the monotone cone. It attains a small\nerror when the noisy matrix has a small cone-restricted operator norm. We\nsupplement the above results with a minimax lower bound of the error under the\nspiked covariance model. Our numerical experiments on simulated and real data,\nshow that our method achieves shorter run time and smaller error in comparison\nto the ordinary power iteration and some sparse principal component analysis\nalgorithms if the principal eigenvector is in a convex cone.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:02:24 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 17:22:55 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Yi", "Yufei", ""], ["Neykov", "Matey", ""]]}, {"id": "2005.07605", "submitter": "Ambuj Tewari", "authors": "A. Philip Dawid and Ambuj Tewari", "title": "On Learnability under General Stochastic Processes", "comments": "The sandwiching result for the first definition of learnability in\n  the previous version is replaced by an equivalence with online learnability", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical learning theory under independent and identically distributed\n(iid) sampling and online learning theory for worst case individual sequences\nare two of the best developed branches of learning theory. Statistical learning\nunder general non-iid stochastic processes is less mature. We provide two\nnatural notions of learnability of a function class under a general stochastic\nprocess. We show that both notions are in fact equivalent to online\nlearnability. Our results are sharpest in the binary classification setting but\nwe also show that similar results continue to hold in the regression setting.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:49:23 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 21:15:13 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Dawid", "A. Philip", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2005.07606", "submitter": "Xunguang Wang", "authors": "Xunguang Wang, Ship Peng Xu, and Eric Ke Wang", "title": "Initializing Perturbations in Multiple Directions for Fast Adversarial\n  Training", "comments": "has no contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in the filed of Deep Learning have demonstrated that Deep\nNeural Networks(DNNs) are vulnerable to adversarial examples. Specifically, in\nimage classification, an adversarial example can fool the well trained deep\nneural networks by adding barely imperceptible perturbations to clean images.\nAdversarial Training, one of the most direct and effective methods, minimizes\nthe losses of perturbed-data to learn robust deep networks against adversarial\nattacks. It has been proven that using the fast gradient sign method (FGSM) can\nachieve Fast Adversarial Training. However, FGSM-based adversarial training may\nfinally obtain a failed model because of overfitting to FGSM samples. In this\npaper, we proposed the Diversified Initialized Perturbations Adversarial\nTraining (DIP-FAT) which involves seeking the initialization of the\nperturbation via enlarging the output distances of the target model in a random\ndirections. Due to the diversity of random directions, the embedded fast\nadversarial training using FGSM increases the information from the adversary\nand reduces the possibility of overfitting. In addition to preventing\noverfitting, the extensive results show that our proposed DIP-FAT technique can\nalso improve the accuracy of the clean data. The biggest advantage of DIP-FAT\nmethod: achieving the best banlance among clean-data, perturbed-data and\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:52:33 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 07:59:28 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Wang", "Xunguang", ""], ["Xu", "Ship Peng", ""], ["Wang", "Eric Ke", ""]]}, {"id": "2005.07631", "submitter": "Hongsheng Chen", "authors": "Hongsheng Chen, Teng Xiang, Kai Chen, Jing Lu", "title": "Nonlinear Residual Echo Suppression Based on Multi-stream Conv-TasNet", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic echo cannot be entirely removed by linear adaptive filters due to\nthe nonlinear relationship between the echo and far-end signal. Usually a post\nprocessing module is required to further suppress the echo. In this paper, we\npropose a residual echo suppression method based on the modification of fully\nconvolutional time-domain audio separation network (Conv-TasNet). Both the\nresidual signal of the linear acoustic echo cancellation system, and the output\nof the adaptive filter are adopted to form multiple streams for the\nConv-TasNet, resulting in more effective echo suppression while keeping a lower\nlatency of the whole system. Simulation results validate the efficacy of the\nproposed method in both single-talk and double-talk situations.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 16:41:16 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Chen", "Hongsheng", ""], ["Xiang", "Teng", ""], ["Chen", "Kai", ""], ["Lu", "Jing", ""]]}, {"id": "2005.07652", "submitter": "Omar Montasser", "authors": "Omar Montasser, Surbhi Goel, Ilias Diakonikolas, Nathan Srebro", "title": "Efficiently Learning Adversarially Robust Halfspaces with Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning adversarially robust halfspaces in the\ndistribution-independent setting. In the realizable setting, we provide\nnecessary and sufficient conditions on the adversarial perturbation sets under\nwhich halfspaces are efficiently robustly learnable. In the presence of random\nlabel noise, we give a simple computationally efficient algorithm for this\nproblem with respect to any $\\ell_p$-perturbation.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:13:54 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Montasser", "Omar", ""], ["Goel", "Surbhi", ""], ["Diakonikolas", "Ilias", ""], ["Srebro", "Nathan", ""]]}, {"id": "2005.07654", "submitter": "Asan Agibetov", "authors": "Asan Agibetov, Matthias Samwald", "title": "Benchmarking neural embeddings for link prediction in knowledge graphs\n  under semantic and structural changes", "comments": null, "journal-ref": null, "doi": "10.1016/j.websem.2020.100590", "report-no": null, "categories": "cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, link prediction algorithms based on neural embeddings have gained\ntremendous popularity in the Semantic Web community, and are extensively used\nfor knowledge graph completion. While algorithmic advances have strongly\nfocused on efficient ways of learning embeddings, fewer attention has been\ndrawn to the different ways their performance and robustness can be evaluated.\nIn this work we propose an open-source evaluation pipeline, which benchmarks\nthe accuracy of neural embeddings in situations where knowledge graphs may\nexperience semantic and structural changes. We define relation-centric\nconnectivity measures that allow us to connect the link prediction capacity to\nthe structure of the knowledge graph. Such an evaluation pipeline is especially\nimportant to simulate the accuracy of embeddings for knowledge graphs that are\nexpected to be frequently updated.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:15:45 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 08:11:29 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Agibetov", "Asan", ""], ["Samwald", "Matthias", ""]]}, {"id": "2005.07656", "submitter": "Luis Miralles PHD", "authors": "Luis Miralles-Pechu\\'an, Fernando Jim\\'enez, Hiram Ponce, Lourdes\n  Mart\\'inez-Villase\\~nor", "title": "A Deep Q-learning/genetic Algorithms Based Novel Methodology For\n  Optimizing Covid-19 Pandemic Government Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whenever countries are threatened by a pandemic, as is the case with the\nCOVID-19 virus, governments should take the right actions to safeguard public\nhealth as well as to mitigate the negative effects on the economy. In this\nregard, there are two completely different approaches governments can take: a\nrestrictive one, in which drastic measures such as self-isolation can seriously\ndamage the economy, and a more liberal one, where more relaxed restrictions may\nput at risk a high percentage of the population. The optimal approach could be\nsomewhere in between, and, in order to make the right decisions, it is\nnecessary to accurately estimate the future effects of taking one or other\nmeasures. In this paper, we use the SEIR epidemiological model (Susceptible -\nExposed - Infected - Recovered) for infectious diseases to represent the\nevolution of the virus COVID-19 over time in the population. To optimize the\nbest sequences of actions governments can take, we propose a methodology with\ntwo approaches, one based on Deep Q-Learning and another one based on Genetic\nAlgorithms. The sequences of actions (confinement, self-isolation, two-meter\ndistance or not taking restrictions) are evaluated according to a reward system\nfocused on meeting two objectives: firstly, getting few people infected so that\nhospitals are not overwhelmed with critical patients, and secondly, avoiding\ntaking drastic measures for too long which can potentially cause serious damage\nto the economy. The conducted experiments prove that our methodology is a valid\ntool to discover actions governments can take to reduce the negative effects of\na pandemic in both senses. We also prove that the approach based on Deep\nQ-Learning overcomes the one based on Genetic Algorithms for optimizing the\nsequences of actions.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:17:45 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Miralles-Pechu\u00e1n", "Luis", ""], ["Jim\u00e9nez", "Fernando", ""], ["Ponce", "Hiram", ""], ["Mart\u00ednez-Villase\u00f1or", "Lourdes", ""]]}, {"id": "2005.07675", "submitter": "Brian Kim", "authors": "Brian Kim and Yalin E. Sagduyu and Kemal Davaslioglu and Tugba Erpek\n  and Sennur Ulukus", "title": "How to Make 5G Communications \"Invisible\": Adversarial Machine Learning\n  for Wireless Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of hiding wireless communications from an\neavesdropper that employs a deep learning (DL) classifier to detect whether any\ntransmission of interest is present or not. There exists one transmitter that\ntransmits to its receiver in the presence of an eavesdropper, while a\ncooperative jammer (CJ) transmits carefully crafted adversarial perturbations\nover the air to fool the eavesdropper into classifying the received\nsuperposition of signals as noise. The CJ puts an upper bound on the strength\nof perturbation signal to limit its impact on the bit error rate (BER) at the\nreceiver. We show that this adversarial perturbation causes the eavesdropper to\nmisclassify the received signals as noise with high probability while\nincreasing the BER only slightly. On the other hand, the CJ cannot fool the\neavesdropper by simply transmitting Gaussian noise as in conventional jamming\nand instead needs to craft perturbation signals built by adversarial machine\nlearning to enable covert communications. Our results show that signals with\ndifferent modulation types and eventually 5G communications can be effectively\nhidden from an eavesdropper even if it is equipped with a DL classifier to\ndetect transmissions.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:45:11 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Kim", "Brian", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Erpek", "Tugba", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2005.07724", "submitter": "Atish Agarwala", "authors": "Atish Agarwala, Abhimanyu Das, Rina Panigrahy, Qiuyi Zhang", "title": "Learning the gravitational force law and other analytic functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural network models have been successful in learning functions of\nimportance in many branches of science, including physics, chemistry and\nbiology. Recent theoretical work has shown explicit learning bounds for wide\nnetworks and kernel methods on some simple classes of functions, but not on\nmore complex functions which arise in practice. We extend these techniques to\nprovide learning bounds for analytic functions on the sphere for any kernel\nmethod or equivalent infinitely-wide network with the corresponding activation\nfunction trained with SGD. We show that a wide, one-hidden layer ReLU network\ncan learn analytic functions with a number of samples proportional to the\nderivative of a related function. Many functions important in the sciences are\ntherefore efficiently learnable. As an example, we prove explicit bounds on\nlearning the many-body gravitational force function given by Newton's law of\ngravitation. Our theoretical bounds suggest that very wide ReLU networks (and\nthe corresponding NTK kernel) are better at learning analytic functions as\ncompared to kernel learning with Gaussian kernels. We present experimental\nevidence that the many-body gravitational force function is easier to learn\nwith ReLU networks as compared to networks with exponential activations.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 18:11:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Agarwala", "Atish", ""], ["Das", "Abhimanyu", ""], ["Panigrahy", "Rina", ""], ["Zhang", "Qiuyi", ""]]}, {"id": "2005.07755", "submitter": "Ziyi Chen", "authors": "Ziyi Chen, Yi Zhou", "title": "Momentum with Variance Reduction for Nonconvex Composition Optimization", "comments": "36 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composition optimization is widely-applied in nonconvex machine learning.\nVarious advanced stochastic algorithms that adopt momentum and variance\nreduction techniques have been developed for composition optimization. However,\nthese algorithms do not fully exploit both techniques to accelerate the\nconvergence and are lack of convergence guarantee in nonconvex optimization.\nThis paper complements the existing literature by developing various momentum\nschemes with SPIDER-based variance reduction for non-convex composition\noptimization. In particular, our momentum design requires less number of\nproximal mapping evaluations per-iteration than that required by the existing\nKatyusha momentum. Furthermore, our algorithm achieves near-optimal sample\ncomplexity results in both non-convex finite-sum and online composition\noptimization and achieves a linear convergence rate under the gradient dominant\ncondition. Numerical experiments demonstrate that our algorithm converges\nsignificantly faster than existing algorithms in nonconvex composition\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 19:29:33 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Ziyi", ""], ["Zhou", "Yi", ""]]}, {"id": "2005.07776", "submitter": "Amir Sonee", "authors": "Amir Sonee and Stefano Rini", "title": "Efficient Federated Learning over Multiple Access Channel with\n  Differential Privacy Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of federated learning (FL) through digital\ncommunication between clients and a parameter server (PS) over a multiple\naccess channel (MAC), also subject to differential privacy (DP) constraints, is\nstudied. More precisely, we consider the setting in which clients in a\ncentralized network are prompted to train a machine learning model using their\nlocal datasets. The information exchange between the clients and the PS takes\nplaces over a MAC channel and must also preserve the DP of the local datasets.\nAccordingly, the objective of the clients is to minimize the training loss\nsubject to (i) rate constraints for reliable communication over the MAC and\n(ii) DP constraint over the local datasets. For this optimization scenario, we\nproposed a novel consensus scheme in which digital distributed stochastic\ngradient descent (D-DSGD) is performed by each client. To preserve DP, a\ndigital artificial noise is also added by the users to the locally quantized\ngradients. The performance of the scheme is evaluated in terms of the\nconvergence rate and DP level for a given MAC capacity. The performance is\noptimized over the choice of the quantization levels and the artificial noise\nparameters. Numerical evaluations are presented to validate the performance of\nthe proposed scheme.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 20:38:04 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 14:39:45 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sonee", "Amir", ""], ["Rini", "Stefano", ""]]}, {"id": "2005.07783", "submitter": "Nicol\\'as Igor Tapia", "authors": "Nicol\\'as I. Tapia, Pablo A. Est\\'evez", "title": "On the Information Plane of Autoencoders", "comments": "8 pages, 9 figures. In proceedings of the 2020 International Joint\n  Conference on Neural Networks (IJCNN 2020)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207269", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training dynamics of hidden layers in deep learning are poorly understood\nin theory. Recently, the Information Plane (IP) was proposed to analyze them,\nwhich is based on the information-theoretic concept of mutual information (MI).\nThe Information Bottleneck (IB) theory predicts that layers maximize relevant\ninformation and compress irrelevant information. Due to the limitations in MI\nestimation from samples, there is an ongoing debate about the properties of the\nIP for the supervised learning case. In this work, we derive a theoretical\nconvergence for the IP of autoencoders. The theory predicts that ideal\nautoencoders with a large bottleneck layer size do not compress input\ninformation, whereas a small size causes compression only in the encoder\nlayers. For the experiments, we use a Gram-matrix based MI estimator recently\nproposed in the literature. We propose a new rule to adjust its parameters that\ncompensates scale and dimensionality effects. Using our proposed rule, we\nobtain experimental IPs closer to the theory. Our theoretical IP for\nautoencoders could be used as a benchmark to validate new methods to estimate\nMI in neural networks. In this way, experimental limitations could be\nrecognized and corrected, helping with the ongoing debate on the supervised\nlearning case.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:05:49 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 18:43:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Tapia", "Nicol\u00e1s I.", ""], ["Est\u00e9vez", "Pablo A.", ""]]}, {"id": "2005.07785", "submitter": "Usman Khan", "authors": "Muhammad I. Qureshi, Ran Xin, Soummya Kar, and Usman A. Khan", "title": "S-ADDOPT: Decentralized stochastic first-order optimization over\n  directed graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we study decentralized stochastic optimization to minimize a\nsum of smooth and strongly convex cost functions when the functions are\ndistributed over a directed network of nodes. In contrast to the existing work,\nwe use gradient tracking to improve certain aspects of the resulting algorithm.\nIn particular, we propose the~\\textbf{\\texttt{S-ADDOPT}} algorithm that assumes\na stochastic first-order oracle at each node and show that for a constant\nstep-size~$\\alpha$, each node converges linearly inside an error ball around\nthe optimal solution, the size of which is controlled by~$\\alpha$. For decaying\nstep-sizes~$\\mathcal{O}(1/k)$, we show that~\\textbf{\\texttt{S-ADDOPT}} reaches\nthe exact solution sublinearly at~$\\mathcal{O}(1/k)$ and its convergence is\nasymptotically network-independent. Thus the asymptotic behavior\nof~\\textbf{\\texttt{S-ADDOPT}} is comparable to the centralized stochastic\ngradient descent. Numerical experiments over both strongly convex and\nnon-convex problems illustrate the convergence behavior and the performance\ncomparison of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:14:22 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 04:26:55 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 19:15:28 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Qureshi", "Muhammad I.", ""], ["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "2005.07786", "submitter": "Yerlan Idelbayev", "authors": "Yerlan Idelbayev and Miguel \\'A. Carreira-Perpi\\~n\\'an", "title": "A flexible, extensible software framework for model compression based on\n  the LC algorithm", "comments": "15 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a software framework based on the ideas of the\nLearning-Compression (LC) algorithm, that allows a user to compress a neural\nnetwork or other machine learning model using different compression schemes\nwith minimal effort. Currently, the supported compressions include pruning,\nquantization, low-rank methods (including automatically learning the layer\nranks), and combinations of those, and the user can choose different\ncompression types for different parts of a neural network.\n  The LC algorithm alternates two types of steps until convergence: a learning\n(L) step, which trains a model on a dataset (using an algorithm such as SGD);\nand a compression (C) step, which compresses the model parameters (using a\ncompression scheme such as low-rank or quantization). This decoupling of the\n\"machine learning\" aspect from the \"signal compression\" aspect means that\nchanging the model or the compression type amounts to calling the corresponding\nsubroutine in the L or C step, respectively. The library fully supports this by\ndesign, which makes it flexible and extensible. This does not come at the\nexpense of performance: the runtime needed to compress a model is comparable to\nthat of training the model in the first place; and the compressed model is\ncompetitive in terms of prediction accuracy and compression ratio with other\nalgorithms (which are often specialized for specific models or compression\nschemes). The library is written in Python and PyTorch and available in Github.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:14:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Idelbayev", "Yerlan", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""]]}, {"id": "2005.07788", "submitter": "Saumitra Mishra", "authors": "Saumitra Mishra, Emmanouil Benetos, Bob L. Sturm, Simon Dixon", "title": "Reliable Local Explanations for Machine Listening", "comments": "8 pages plus references. Accepted at the IJCNN 2020 Special Session\n  on Explainable Computational/Artificial Intelligence. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to analyse the behaviour of machine learning models is through local\nexplanations that highlight input features that maximally influence model\npredictions. Sensitivity analysis, which involves analysing the effect of input\nperturbations on model predictions, is one of the methods to generate local\nexplanations. Meaningful input perturbations are essential for generating\nreliable explanations, but there exists limited work on what such perturbations\nare and how to perform them. This work investigates these questions in the\ncontext of machine listening models that analyse audio. Specifically, we use a\nstate-of-the-art deep singing voice detection (SVD) model to analyse whether\nexplanations from SoundLIME (a local explanation method) are sensitive to how\nthe method perturbs model inputs. The results demonstrate that SoundLIME\nexplanations are sensitive to the content in the occluded input regions. We\nfurther propose and demonstrate a novel method for quantitatively identifying\nsuitable content type(s) for reliably occluding inputs of machine listening\nmodels. The results for the SVD model suggest that the average magnitude of\ninput mel-spectrogram bins is the most suitable content type for temporal\nexplanations.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:17:06 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mishra", "Saumitra", ""], ["Benetos", "Emmanouil", ""], ["Sturm", "Bob L.", ""], ["Dixon", "Simon", ""]]}, {"id": "2005.07795", "submitter": "Nicol\\'as Igor Tapia", "authors": "Nicol\\'as I. Tapia, Pablo A. Est\\'evez", "title": "RED: Deep Recurrent Neural Networks for Sleep EEG Event Detection", "comments": "8 pages, 5 figures. In proceedings of the 2020 International Joint\n  Conference on Neural Networks (IJCNN 2020)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207719", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain electrical activity presents several short events during sleep that\ncan be observed as distinctive micro-structures in the electroencephalogram\n(EEG), such as sleep spindles and K-complexes. These events have been\nassociated with biological processes and neurological disorders, making them a\nresearch topic in sleep medicine. However, manual detection limits their study\nbecause it is time-consuming and affected by significant inter-expert\nvariability, motivating automatic approaches. We propose a deep learning\napproach based on convolutional and recurrent neural networks for sleep EEG\nevent detection called Recurrent Event Detector (RED). RED uses one of two\ninput representations: a) the time-domain EEG signal, or b) a complex\nspectrogram of the signal obtained with the Continuous Wavelet Transform (CWT).\nUnlike previous approaches, a fixed time window is avoided and temporal context\nis integrated to better emulate the visual criteria of experts. When evaluated\non the MASS dataset, our detectors outperform the state of the art in both\nsleep spindle and K-complex detection with a mean F1-score of at least 80.9%\nand 82.6%, respectively. Although the CWT-domain model obtained a similar\nperformance than its time-domain counterpart, the former allows in principle a\nmore interpretable input representation due to the use of a spectrogram. The\nproposed approach is event-agnostic and can be used directly to detect other\ntypes of sleep events.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:48:26 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 18:42:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Tapia", "Nicol\u00e1s I.", ""], ["Est\u00e9vez", "Pablo A.", ""]]}, {"id": "2005.07804", "submitter": "Jwala Dhamala", "authors": "Jwala Dhamala, Sandesh Ghimire, John L. Sapp, B. Milan Hor\\'acek,\n  Linwei Wang", "title": "High-dimensional Bayesian Optimization of Personalized Cardiac Model\n  Parameters via an Embedded Generative Model", "comments": "MICCAI 2018", "journal-ref": null, "doi": "10.1007/978-3-030-00934-2_56", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of patient-specific tissue properties in the form of model\nparameters is important for personalized physiological models. However, these\ntissue properties are spatially varying across the underlying anatomical model,\npresenting a significance challenge of high-dimensional (HD) optimization at\nthe presence of limited measurement data. A common solution to reduce the\ndimension of the parameter space is to explicitly partition the anatomical\nmesh, either into a fixed small number of segments or a multi-scale hierarchy.\nThis anatomy-based reduction of parameter space presents a fundamental\nbottleneck to parameter estimation, resulting in solutions that are either too\nlow in resolution to reflect tissue heterogeneity, or too high in dimension to\nbe reliably estimated within feasible computation. In this paper, we present a\nnovel concept that embeds a generative variational auto-encoder (VAE) into the\nobjective function of Bayesian optimization, providing an implicit\nlow-dimensional (LD) search space that represents the generative code of the HD\nspatially-varying tissue properties. In addition, the VAE-encoded knowledge\nabout the generative code is further used to guide the exploration of the\nsearch space. The presented method is applied to estimating tissue excitability\nin a cardiac electrophysiological model. Synthetic and real-data experiments\ndemonstrate its ability to improve the accuracy of parameter estimation with\nmore than 10x gain in efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 22:14:16 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Dhamala", "Jwala", ""], ["Ghimire", "Sandesh", ""], ["Sapp", "John L.", ""], ["Hor\u00e1cek", "B. Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "2005.07814", "submitter": "Sung-En Chiu", "authors": "Sung-En Chiu, Tara Javidi", "title": "Low Complexity Sequential Search with Size-Dependent Measurement Noise", "comments": "submitted revision to IEEE Transaction on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a target localization problem where at any given time an\nagent can choose a region to query for the presence of the target in that\nregion. The measurement noise is assumed to be increasing with the size of the\nquery region the agent chooses. Motivated by practical applications such as\ninitial beam alignment in array processing, heavy hitter detection in\nnetworking, and visual search in robotics, we consider practically important\ncomplexity constraints/metrics: \\textit{time complexity}, \\textit{computational\nand memory complexity}, and the complexity of possible query sets in terms of\ngeometry and cardinality.\n  Two novel search strategy, $dyaPM$ and $hiePM$, are proposed. Pertinent to\nthe practicality of out solutions, $dyaPM$ and $hiePM$ are of a connected query\ngeometry (i.e. query set is always a connected set) implemented with low\ncomputational and memory complexity. Additionally, $hiePM$ has a hierarchical\nstructure and, hence, a further reduction in the cardinality of possible query\nsets, making $hiePM$ practically suitable for applications such as beamforming\nin array processing where memory limitations favors a smaller codebook size.\n  Through a unified analysis with Extrinsic Jensen Shannon (EJS) Divergence,\n$dyaPM$ is shown to be asymptotically optimal in search time complexity\n(asymptotic in both resolution (rate) and error (reliability)). On the other\nhand, $hiePM$ is shown to be near-optimal in rate. In addition, both $hiePM$\nand $dyaPM$ are shown to outperform prior work in the non-asymptotic regime.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 22:40:18 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 17:55:40 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Chiu", "Sung-En", ""], ["Javidi", "Tara", ""]]}, {"id": "2005.07839", "submitter": "Le Thanh Nguyen-Meidine", "authors": "Le Thanh Nguyen-Meidine, Eric Granger, Madhu Kiran, Jose Dolz,\n  Louis-Antoine Blais-Morin", "title": "Joint Progressive Knowledge Distillation and Unsupervised Domain\n  Adaptation", "comments": "Accepted to WCCI/IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the divergence in distributions of design and operational data,\nand large computational complexity are limiting factors in the adoption of CNNs\nin real-world applications. For instance, person re-identification systems\ntypically rely on a distributed set of cameras, where each camera has different\ncapture conditions. This can translate to a considerable shift between source\n(e.g. lab setting) and target (e.g. operational camera) domains. Given the cost\nof annotating image data captured for fine-tuning in each target domain,\nunsupervised domain adaptation (UDA) has become a popular approach to adapt\nCNNs. Moreover, state-of-the-art deep learning models that provide a high level\nof accuracy often rely on architectures that are too complex for real-time\napplications. Although several compression and UDA approaches have recently\nbeen proposed to overcome these limitations, they do not allow optimizing a CNN\nto simultaneously address both. In this paper, we propose an unexplored\ndirection -- the joint optimization of CNNs to provide a compressed model that\nis adapted to perform well for a given target domain. In particular, the\nproposed approach performs unsupervised knowledge distillation (KD) from a\ncomplex teacher model to a compact student model, by leveraging both source and\ntarget data. It also improves upon existing UDA techniques by progressively\nteaching the student about domain-invariant features, instead of directly\nadapting a compact model on target domain data. Our method is compared against\nstate-of-the-art compression and UDA techniques, using two popular\nclassification datasets for UDA -- Office31 and ImageClef-DA. In both datasets,\nresults indicate that our method can achieve the highest level of accuracy\nwhile requiring a comparable or lower time complexity.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 01:07:03 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Nguyen-Meidine", "Le Thanh", ""], ["Granger", "Eric", ""], ["Kiran", "Madhu", ""], ["Dolz", "Jose", ""], ["Blais-Morin", "Louis-Antoine", ""]]}, {"id": "2005.07852", "submitter": "Reda Chhaibi", "authors": "Tariq Daouda, Reda Chhaibi, Prudencio Tossou, Alexandra-Chlo\\'e\n  Villani", "title": "Geodesics in fibered latent spaces: A geometric approach to learning\n  correspondences between conditions", "comments": "36 pages, many figures. v1: Preliminary version. v2: Minor ref fix.\n  v3: Submitted version with enhanced presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a geometric framework and a novel network architecture\nfor creating correspondences between samples of different conditions. Under\nthis formalism, the latent space is a fiber bundle stratified into a base space\nencoding conditions, and a fiber space encoding the variations within\nconditions. Furthermore, this latent space is endowed with a natural pull-back\nmetric. The correspondences between conditions are obtained by minimizing an\nenergy functional, resulting in diffeomorphism flows between fibers.\n  We illustrate this approach using MNIST and Olivetti and benchmark its\nperformances on the task of batch correction, which is the problem of\nintegrating multiple biological datasets together.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 03:14:52 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 22:27:21 GMT"}, {"version": "v3", "created": "Sun, 27 Dec 2020 11:46:48 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Daouda", "Tariq", ""], ["Chhaibi", "Reda", ""], ["Tossou", "Prudencio", ""], ["Villani", "Alexandra-Chlo\u00e9", ""]]}, {"id": "2005.07855", "submitter": "Zheng Chen", "authors": "Zheng Chen, Xinli Yu, Yuan Ling, Xiaohua Hu", "title": "Neural Stochastic Block Model & Scalable Community-Based Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a novel scalable community-based neural framework for\ngraph learning. The framework learns the graph topology through the task of\ncommunity detection and link prediction by optimizing with our proposed joint\nSBM loss function, which results from a non-trivial adaptation of the\nlikelihood function of the classic Stochastic Block Model (SBM). Compared with\nSBM, our framework is flexible, naturally allows soft labels and digestion of\ncomplex node attributes. The main goal is efficient valuation of complex graph\ndata, therefore our design carefully aims at accommodating large data, and\nensures there is a single forward pass for efficient evaluation. For large\ngraph, it remains an open problem of how to efficiently leverage its underlying\nstructure for various graph learning tasks. Previously it can be heavy work.\nWith our community-based framework, this becomes less difficult and allows the\ntask models to basically plug-in-and-play and perform joint training. We\ncurrently look into two particular applications, the graph alignment and the\nanomalous correlation detection, and discuss how to make use of our framework\nto tackle both problems. Extensive experiments are conducted to demonstrate the\neffectiveness of our approach. We also contributed tweaks of classic techniques\nwhich we find helpful for performance and scalability. For example, 1) the\nGAT+, an improved design of GAT (Graph Attention Network), the scaled-cosine\nsimilarity, and a unified implementation of the convolution/attention based and\nthe random-walk based neural graph models.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 03:28:50 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Zheng", ""], ["Yu", "Xinli", ""], ["Ling", "Yuan", ""], ["Hu", "Xiaohua", ""]]}, {"id": "2005.07866", "submitter": "Deepesh Data", "authors": "Deepesh Data and Suhas Diggavi", "title": "Byzantine-Resilient SGD in High Dimensions on Heterogeneous Data", "comments": "57 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed stochastic gradient descent (SGD) in the master-worker\narchitecture under Byzantine attacks. We consider the heterogeneous data model,\nwhere different workers may have different local datasets, and we do not make\nany probabilistic assumptions on data generation. At the core of our algorithm,\nwe use the polynomial-time outlier-filtering procedure for robust mean\nestimation proposed by Steinhardt et al. (ITCS 2018) to filter-out corrupt\ngradients. In order to be able to apply their filtering procedure in our {\\em\nheterogeneous} data setting where workers compute {\\em stochastic} gradients,\nwe derive a new matrix concentration result, which may be of independent\ninterest.\n  We provide convergence analyses for smooth strongly-convex and non-convex\nobjectives. We derive our results under the bounded variance assumption on\nlocal stochastic gradients and a {\\em deterministic} condition on datasets,\nnamely, gradient dissimilarity; and for both these quantities, we provide\nconcrete bounds in the statistical heterogeneous data model. We give a\ntrade-off between the mini-batch size for stochastic gradients and the\napproximation error. Our algorithm can tolerate up to $\\frac{1}{4}$ fraction\nByzantine workers. It can find approximate optimal parameters in the\nstrongly-convex setting exponentially fast and reach to an approximate\nstationary point in the non-convex setting with a linear speed, thus, matching\nthe convergence rates of vanilla SGD in the Byzantine-free setting.\n  We also propose and analyze a Byzantine-resilient SGD algorithm with gradient\ncompression, where workers send $k$ random coordinates of their gradients.\nUnder mild conditions, we show a $\\frac{d}{k}$-factor saving in communication\nbits as well as decoding complexity over our compression-free algorithm without\naffecting its convergence rate (order-wise) and the approximation error.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:15:27 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2005.07869", "submitter": "Yufan Zhou", "authors": "Yufan Zhou, Jiayi Xian, Changyou Chen, Jinhui Xu", "title": "Graph Neural Networks with Composite Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning on graph structured data has drawn increasing interest in recent\nyears. Frameworks like Graph Convolutional Networks (GCNs) have demonstrated\ntheir ability to capture structural information and obtain good performance in\nvarious tasks. In these frameworks, node aggregation schemes are typically used\nto capture structural information: a node's feature vector is recursively\ncomputed by aggregating features of its neighboring nodes. However, most of\naggregation schemes treat all connections in a graph equally, ignoring node\nfeature similarities. In this paper, we re-interpret node aggregation from the\nperspective of kernel weighting, and present a framework to consider feature\nsimilarity in an aggregation scheme. Specifically, we show that normalized\nadjacency matrix is equivalent to a neighbor-based kernel matrix in a Krein\nSpace. We then propose feature aggregation as the composition of the original\nneighbor-based kernel and a learnable kernel to encode feature similarities in\na feature space. We further show how the proposed method can be extended to\nGraph Attention Network (GAT). Experimental results demonstrate better\nperformance of our proposed framework in several real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:44:29 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhou", "Yufan", ""], ["Xian", "Jiayi", ""], ["Chen", "Changyou", ""], ["Xu", "Jinhui", ""]]}, {"id": "2005.07890", "submitter": "Zonghao Huang", "authors": "Zonghao Huang and Yanmin Gong", "title": "Differentially Private ADMM for Convex Distributed Learning: Improved\n  Accuracy via Multi-Step Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating Direction Method of Multipliers (ADMM) is a popular algorithm for\ndistributed learning, where a network of nodes collaboratively solve a\nregularized empirical risk minimization by iterative local computation\nassociated with distributed data and iterate exchanges. When the training data\nis sensitive, the exchanged iterates will cause serious privacy concern. In\nthis paper, we aim to propose a new differentially private distributed ADMM\nalgorithm with improved accuracy for a wide range of convex learning problems.\nIn our proposed algorithm, we adopt the approximation of the objective function\nin the local computation to introduce calibrated noise into iterate updates\nrobustly, and allow multiple primal variable updates per node in each\niteration. Our theoretical results demonstrate that our approach can obtain\nhigher utility by such multiple approximate updates, and achieve the error\nbounds asymptotic to the state-of-art ones for differentially private empirical\nrisk minimization.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 07:17:31 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Huang", "Zonghao", ""], ["Gong", "Yanmin", ""]]}, {"id": "2005.07916", "submitter": "Dongxiao Zhang", "authors": "Hao Xu, Dongxiao Zhang, and Junsheng Zeng", "title": "Deep-learning of Parametric Partial Differential Equations from Sparse\n  and Noisy Data", "comments": "30 pages, 6 figures, and 7 tables", "journal-ref": "Phys. Fluids, 33, 037132, 10.1063/5.0042868, 2021", "doi": "10.1063/5.0042868", "report-no": null, "categories": "physics.comp-ph cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven methods have recently made great progress in the discovery of\npartial differential equations (PDEs) from spatial-temporal data. However,\nseveral challenges remain to be solved, including sparse noisy data, incomplete\ncandidate library, and spatially- or temporally-varying coefficients. In this\nwork, a new framework, which combines neural network, genetic algorithm and\nadaptive methods, is put forward to address all of these challenges\nsimultaneously. In the framework, a trained neural network is utilized to\ncalculate derivatives and generate a large amount of meta-data, which solves\nthe problem of sparse noisy data. Next, genetic algorithm is utilized to\ndiscover the form of PDEs and corresponding coefficients with an incomplete\ncandidate library. Finally, a two-step adaptive method is introduced to\ndiscover parametric PDEs with spatially- or temporally-varying coefficients. In\nthis method, the structure of a parametric PDE is first discovered, and then\nthe general form of varying coefficients is identified. The proposed algorithm\nis tested on the Burgers equation, the convection-diffusion equation, the wave\nequation, and the KdV equation. The results demonstrate that this method is\nrobust to sparse and noisy data, and is able to discover parametric PDEs with\nan incomplete candidate library.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 09:09:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Xu", "Hao", ""], ["Zhang", "Dongxiao", ""], ["Zeng", "Junsheng", ""]]}, {"id": "2005.07939", "submitter": "Hanna Meyer", "authors": "Hanna Meyer and Edzer Pebesma", "title": "Predicting into unknown space? Estimating the area of applicability of\n  spatial prediction models", "comments": "16 pages, 10 figures, to be submitted to Methods in Ecology and\n  Evolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modelling using machine learning has become very popular for\nspatial mapping of the environment. Models are often applied to make\npredictions far beyond sampling locations where new geographic locations might\nconsiderably differ from the training data in their environmental properties.\nHowever, areas in the predictor space without support of training data are\nproblematic. Since the model has no knowledge about these environments,\npredictions have to be considered uncertain.\n  Estimating the area to which a prediction model can be reliably applied is\nrequired. Here, we suggest a methodology that delineates the \"area of\napplicability\" (AOA) that we define as the area, for which the cross-validation\nerror of the model applies. We first propose a \"dissimilarity index\" (DI) that\nis based on the minimum distance to the training data in the predictor space,\nwith predictors being weighted by their respective importance in the model. The\nAOA is then derived by applying a threshold based on the DI of the training\ndata where the DI is calculated with respect to the cross-validation strategy\nused for model training. We test for the ideal threshold by using simulated\ndata and compare the prediction error within the AOA with the cross-validation\nerror of the model. We illustrate the approach using a simulated case study.\n  Our simulation study suggests a threshold on DI to define the AOA at the .95\nquantile of the DI in the training data. Using this threshold, the prediction\nerror within the AOA is comparable to the cross-validation RMSE of the model,\nwhile the cross-validation error does not apply outside the AOA. This applies\nto models being trained with randomly distributed training data, as well as\nwhen training data are clustered in space and where spatial cross-validation is\napplied.\n  We suggest to report the AOA alongside predictions, complementary to\nvalidation measures.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 10:31:55 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Meyer", "Hanna", ""], ["Pebesma", "Edzer", ""]]}, {"id": "2005.07946", "submitter": "Peter Rousseeuw", "authors": "Jakob Raymaekers and Peter J. Rousseeuw", "title": "Transforming variables to central normality", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-021-05960-5", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real data sets contain numerical features (variables) whose distribution\nis far from normal (gaussian). Instead, their distribution is often skewed. In\norder to handle such data it is customary to preprocess the variables to make\nthem more normal. The Box-Cox and Yeo-Johnson transformations are well-known\ntools for this. However, the standard maximum likelihood estimator of their\ntransformation parameter is highly sensitive to outliers, and will often try to\nmove outliers inward at the expense of the normality of the central part of the\ndata. We propose a modification of these transformations as well as an\nestimator of the transformation parameter that is robust to outliers, so the\ntransformed data can be approximately normal in the center and a few outliers\nmay deviate from it. It compares favorably to existing techniques in an\nextensive simulation study and on real data.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 10:50:42 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 17:41:33 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Raymaekers", "Jakob", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "2005.07959", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki and Rik Sarkar", "title": "Characteristic Functions on Graphs: Birds of a Feather, from Statistical\n  Descriptors to Parametric Models", "comments": "Source code is available at:\n  https://github.com/benedekrozemberczki/FEATHER", "journal-ref": "CIKM 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a flexible notion of characteristic functions\ndefined on graph vertices to describe the distribution of vertex features at\nmultiple scales. We introduce FEATHER, a computationally efficient algorithm to\ncalculate a specific variant of these characteristic functions where the\nprobability weights of the characteristic function are defined as the\ntransition probabilities of random walks. We argue that features extracted by\nthis procedure are useful for node level machine learning tasks. We discuss the\npooling of these node representations, resulting in compact descriptors of\ngraphs that can serve as features for graph classification algorithms. We\nanalytically prove that FEATHER describes isomorphic graphs with the same\nrepresentation and exhibits robustness to data corruption. Using the node\nfeature characteristic functions we define parametric models where evaluation\npoints of the functions are learned parameters of supervised classifiers.\nExperiments on real world large datasets show that our proposed algorithm\ncreates high quality representations, performs transfer learning efficiently,\nexhibits robustness to hyperparameter changes, and scales linearly with the\ninput size.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 11:47:05 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 16:21:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Sarkar", "Rik", ""]]}, {"id": "2005.07960", "submitter": "George Vouros", "authors": "Alevizos Bastas, Theocharis Kravaris and George A. Vouros", "title": "Data Driven Aircraft Trajectory Prediction with Deep Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current Air Traffic Management (ATM) system worldwide has reached its\nlimits in terms of predictability, efficiency and cost effectiveness. Different\ninitiatives worldwide propose trajectory-oriented transformations that require\nhigh fidelity aircraft trajectory planning and prediction capabilities,\nsupporting the trajectory life cycle at all stages efficiently. Recently\nproposed data-driven trajectory prediction approaches provide promising\nresults. In this paper we approach the data-driven trajectory prediction\nproblem as an imitation learning task, where we aim to imitate experts\n\"shaping\" the trajectory. Towards this goal we present a comprehensive\nframework comprising the Generative Adversarial Imitation Learning state of the\nart method, in a pipeline with trajectory clustering and classification\nmethods. This approach, compared to other approaches, can provide accurate\npredictions for the whole trajectory (i.e. with a prediction horizon until\nreaching the destination) both at the pre-tactical (i.e. starting at the\ndeparture airport at a specific time instant) and at the tactical (i.e. from\nany state while flying) stages, compared to state of the art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 11:53:19 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Bastas", "Alevizos", ""], ["Kravaris", "Theocharis", ""], ["Vouros", "George A.", ""]]}, {"id": "2005.07972", "submitter": "Matteo Fontana", "authors": "Gianluca Zeni and Matteo Fontana and Simone Vantini", "title": "Conformal Prediction: a Unified Review of Theory and New Challenges", "comments": "arXiv admin note: text overlap with arXiv:0706.3188,\n  arXiv:1604.04173, arXiv:1709.06233, arXiv:1203.5422 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide a review of basic ideas and novel developments about\nConformal Prediction -- an innovative distribution-free, non-parametric\nforecasting method, based on minimal assumptions -- that is able to yield in a\nvery straightforward way predictions sets that are valid in a statistical sense\nalso in in the finite sample case. The in-depth discussion provided in the\npaper covers the theoretical underpinnings of Conformal Prediction, and then\nproceeds to list the more advanced developments and adaptations of the original\nidea.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 12:38:19 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zeni", "Gianluca", ""], ["Fontana", "Matteo", ""], ["Vantini", "Simone", ""]]}, {"id": "2005.07995", "submitter": "Cesar H Comin Prof.", "authors": "Eric K. Tokuda, Cesar H. Comin and Luciano da F. Costa", "title": "Revisiting Agglomerative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important issue in clustering concerns the avoidance of false positives\nwhile searching for clusters. This work addressed this problem considering\nagglomerative methods, namely single, average, median, complete, centroid and\nWard's approaches applied to unimodal and bimodal datasets obeying uniform,\ngaussian, exponential and power-law distributions. A model of clusters was also\nadopted, involving a higher density nucleus surrounded by a transition,\nfollowed by outliers. This paved the way to defining an objective means for\nidentifying the clusters from dendrograms. The adopted model also allowed the\nrelevance of the clusters to be quantified in terms of the height of their\nsubtrees. The obtained results include the verification that many methods\ndetect two clusters in unimodal data. The single-linkage method was found to be\nmore resilient to false positives. Also, several methods detected clusters not\ncorresponding directly to the nucleus. The possibility of identifying the type\nof distribution was also investigated.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 14:07:25 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 23:00:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tokuda", "Eric K.", ""], ["Comin", "Cesar H.", ""], ["Costa", "Luciano da F.", ""]]}, {"id": "2005.07998", "submitter": "Maung Maung April Pyone", "authors": "MaungMaung AprilPyone and Hitoshi Kiya", "title": "Encryption Inspired Adversarial Defense for Visual Classification", "comments": "To be appeared on 27th IEEE International Conference on Image\n  Processing (ICIP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional adversarial defenses reduce classification accuracy whether or\nnot a model is under attacks. Moreover, most of image processing based defenses\nare defeated due to the problem of obfuscated gradients. In this paper, we\npropose a new adversarial defense which is a defensive transform for both\ntraining and test images inspired by perceptual image encryption methods. The\nproposed method utilizes a block-wise pixel shuffling method with a secret key.\nThe experiments are carried out on both adaptive and non-adaptive maximum-norm\nbounded white-box attacks while considering obfuscated gradients. The results\nshow that the proposed defense achieves high accuracy (91.55 %) on clean images\nand (89.66 %) on adversarial examples with noise distance of 8/255 on CIFAR-10\ndataset. Thus, the proposed defense outperforms state-of-the-art adversarial\ndefenses including latent adversarial training, adversarial training and\nthermometer encoding.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 14:18:07 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["AprilPyone", "MaungMaung", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2005.08008", "submitter": "Ziheng Duan", "authors": "Haoyan Xu, Ziheng Duan, Jie Feng, Runjian Chen, Qianru Zhang, Zhongbin\n  Xu, Yueyang Wang", "title": "Graph Partitioning and Graph Neural Network based Hierarchical Graph\n  Matching for Graph Similarity Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph similarity computation aims to predict a similarity score between one\npair of graphs to facilitate downstream applications, such as finding the most\nsimilar chemical compounds similar to a query compound or Fewshot 3D Action\nRecognition. Recently, some graph similarity computation models based on neural\nnetworks have been proposed, which are either based on graph-level interaction\nor node-level comparison. However, when the number of nodes in the graph\nincreases, it will inevitably bring about reduced representation ability or\nhigh computation cost. Motivated by this observation, we propose a graph\npartitioning and graph neural network-based model, called PSimGNN, to\neffectively resolve this issue. Specifically, each of the input graphs is\npartitioned into a set of subgraphs to extract the local structural features\ndirectly. Next, a novel graph neural network with an attention mechanism is\ndesigned to map each subgraph into an embedding vector. Some of these subgraph\npairs are automatically selected for node-level comparison to supplement the\nsubgraph-level embedding with fine-grained information. Finally, coarse-grained\ninteraction information among subgraphs and fine-grained comparison information\namong nodes in different subgraphs are integrated to predict the final\nsimilarity score. Experimental results on graph datasets with different graph\nsizes demonstrate that PSimGNN outperforms state-of-the-art methods in graph\nsimilarity computation tasks using approximate Graph Edit Distance (GED) as the\ngraph similarity metric.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 15:01:58 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 11:18:54 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 00:19:12 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Xu", "Haoyan", ""], ["Duan", "Ziheng", ""], ["Feng", "Jie", ""], ["Chen", "Runjian", ""], ["Zhang", "Qianru", ""], ["Xu", "Zhongbin", ""], ["Wang", "Yueyang", ""]]}, {"id": "2005.08027", "submitter": "Aijun Zhang", "authors": "Zebin Yang, Hengtao Zhang, Agus Sudjianto, Aijun Zhang", "title": "An Effective and Efficient Initialization Scheme for Training\n  Multi-layer Feedforward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network initialization is the first and critical step for training neural\nnetworks. In this paper, we propose a novel network initialization scheme based\non the celebrated Stein's identity. By viewing multi-layer feedforward neural\nnetworks as cascades of multi-index models, the projection weights to the first\nhidden layer are initialized using eigenvectors of the cross-moment matrix\nbetween the input's second-order score function and the response. The input\ndata is then forward propagated to the next layer and such a procedure can be\nrepeated until all the hidden layers are initialized. Finally, the weights for\nthe output layer are initialized by generalized linear modeling. Such a\nproposed SteinGLM method is shown through extensive numerical results to be\nmuch faster and more accurate than other popular methods commonly used for\ntraining neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:17:37 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 05:36:21 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 12:51:00 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Yang", "Zebin", ""], ["Zhang", "Hengtao", ""], ["Sudjianto", "Agus", ""], ["Zhang", "Aijun", ""]]}, {"id": "2005.08033", "submitter": "Satyapriya Krishna", "authors": "Aarsh Patel, Rahul Gupta, Mukund Harakere, Satyapriya Krishna, Aman\n  Alok, Peng Liu", "title": "Towards classification parity across cohorts", "comments": "Published in ML-IRL ICLR 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a lot of interest in ensuring algorithmic fairness\nin machine learning where the central question is how to prevent sensitive\ninformation (e.g. knowledge about the ethnic group of an individual) from\nadding \"unfair\" bias to a learning algorithm (Feldman et al. (2015), Zemel et\nal. (2013)). This has led to several debiasing algorithms on word embeddings\n(Qian et al. (2019) , Bolukbasi et al. (2016)), coreference resolution (Zhao et\nal. (2018a)), semantic role labeling (Zhao et al. (2017)), etc. Most of these\nexisting work deals with explicit sensitive features such as gender,\noccupations or race which doesn't work with data where such features are not\ncaptured due to privacy concerns. In this research work, we aim to achieve\nclassification parity across explicit as well as implicit sensitive features.\nWe define explicit cohorts as groups of people based on explicit sensitive\nattributes provided in the data (age, gender, race) whereas implicit cohorts\nare defined as groups of people with similar language usage. We obtain implicit\ncohorts by clustering embeddings of each individual trained on the language\ngenerated by them using a language model. We achieve two primary objectives in\nthis work : [1.] We experimented and discovered classification performance\ndifferences across cohorts based on implicit and explicit features , [2] We\nimproved classification parity by introducing modification to the loss function\naimed to minimize the range of model performances across cohorts.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:31:08 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Patel", "Aarsh", ""], ["Gupta", "Rahul", ""], ["Harakere", "Mukund", ""], ["Krishna", "Satyapriya", ""], ["Alok", "Aman", ""], ["Liu", "Peng", ""]]}, {"id": "2005.08041", "submitter": "Alberto Marchisio", "authors": "Valerio Venceslai, Alberto Marchisio, Ihsen Alouani, Maurizio Martina,\n  Muhammad Shafique", "title": "NeuroAttack: Undermining Spiking Neural Networks Security through\n  Externally Triggered Bit-Flips", "comments": "Accepted for publication at the 2020 International Joint Conference\n  on Neural Networks (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207351", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their proven efficiency, machine-learning systems are deployed in a\nwide range of complex real-life problems. More specifically, Spiking Neural\nNetworks (SNNs) emerged as a promising solution to the accuracy,\nresource-utilization, and energy-efficiency challenges in machine-learning\nsystems. While these systems are going mainstream, they have inherent security\nand reliability issues. In this paper, we propose NeuroAttack, a cross-layer\nattack that threatens the SNNs integrity by exploiting low-level reliability\nissues through a high-level attack. Particularly, we trigger a fault-injection\nbased sneaky hardware backdoor through a carefully crafted adversarial input\nnoise. Our results on Deep Neural Networks (DNNs) and SNNs show a serious\nintegrity threat to state-of-the art machine-learning techniques.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:54:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Venceslai", "Valerio", ""], ["Marchisio", "Alberto", ""], ["Alouani", "Ihsen", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2005.08044", "submitter": "Fredrik Hellstr\\\"om", "authors": "Fredrik Hellstr\\\"om and Giuseppe Durisi", "title": "Generalization Bounds via Information Density and Conditional\n  Information Density", "comments": "Published in Journal on Selected Areas in Information Theory (JSAIT).\n  Important note: the proof of the data-dependent bounds provided in the paper\n  contains an error, which is rectified in the following document:\n  https://gdurisi.github.io/files/2021/jsait-correction.pdf", "journal-ref": "IEEE J. Sel. Areas Inf. Theory 1.3 (2020) 824-839", "doi": "10.1109/JSAIT.2020.3040992", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general approach, based on an exponential inequality, to derive\nbounds on the generalization error of randomized learning algorithms. Using\nthis approach, we provide bounds on the average generalization error as well as\nbounds on its tail probability, for both the PAC-Bayesian and single-draw\nscenarios. Specifically, for the case of subgaussian loss functions, we obtain\nnovel bounds that depend on the information density between the training data\nand the output hypothesis. When suitably weakened, these bounds recover many of\nthe information-theoretic available bounds in the literature. We also extend\nthe proposed exponential-inequality approach to the setting recently introduced\nby Steinke and Zakynthinou (2020), where the learning algorithm depends on a\nrandomly selected subset of the available training data. For this setup, we\npresent bounds for bounded loss functions in terms of the conditional\ninformation density between the output hypothesis and the random variable\ndetermining the subset choice, given all training data. Through our approach,\nwe recover the average generalization bound presented by Steinke and\nZakynthinou (2020) and extend it to the PAC-Bayesian and single-draw scenarios.\nFor the single-draw scenario, we also obtain novel bounds in terms of the\nconditional $\\alpha$-mutual information and the conditional maximal leakage.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 17:04:24 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 09:22:29 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 21:50:21 GMT"}, {"version": "v4", "created": "Fri, 4 Dec 2020 18:10:31 GMT"}, {"version": "v5", "created": "Fri, 19 Mar 2021 09:12:12 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Hellstr\u00f6m", "Fredrik", ""], ["Durisi", "Giuseppe", ""]]}, {"id": "2005.08047", "submitter": "Lele Cao", "authors": "Lele Cao, Sahar Asadi, Wenfei Zhu, Christian Schmidli, Michael\n  Sj\\\"oberg", "title": "Simple, Scalable, and Stable Variational Deep Clustering", "comments": "17 pages, 5 figures, source code: https://github.com/king/s3vdc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep clustering (DC) has become the state-of-the-art for unsupervised\nclustering. In principle, DC represents a variety of unsupervised methods that\njointly learn the underlying clusters and the latent representation directly\nfrom unstructured datasets. However, DC methods are generally poorly applied\ndue to high operational costs, low scalability, and unstable results. In this\npaper, we first evaluate several popular DC variants in the context of\nindustrial applicability using eight empirical criteria. We then choose to\nfocus on variational deep clustering (VDC) methods, since they mostly meet\nthose criteria except for simplicity, scalability, and stability. To address\nthese three unmet criteria, we introduce four generic algorithmic improvements:\ninitial $\\gamma$-training, periodic $\\beta$-annealing, mini-batch GMM (Gaussian\nmixture model) initialization, and inverse min-max transform. We also propose a\nnovel clustering algorithm S3VDC (simple, scalable, and stable VDC) that\nincorporates all those improvements. Our experiments show that S3VDC\noutperforms the state-of-the-art on both benchmark tasks and a large\nunstructured industrial dataset without any ground truth label. In addition, we\nanalytically evaluate the usability and interpretability of S3VDC.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 17:24:01 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 10:24:56 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Cao", "Lele", ""], ["Asadi", "Sahar", ""], ["Zhu", "Wenfei", ""], ["Schmidli", "Christian", ""], ["Sj\u00f6berg", "Michael", ""]]}, {"id": "2005.08054", "submitter": "Vidya Muthukumar", "authors": "Vidya Muthukumar, Adhyyan Narang, Vignesh Subramanian, Mikhail Belkin,\n  Daniel Hsu, Anant Sahai", "title": "Classification vs regression in overparameterized regimes: Does the loss\n  function matter?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare classification and regression tasks in the overparameterized\nlinear model with Gaussian features. On the one hand, we show that with\nsufficient overparameterization all training points are support vectors:\nsolutions obtained by least-squares minimum-norm interpolation, typically used\nfor regression, are identical to those produced by the hard-margin support\nvector machine (SVM) that minimizes the hinge loss, typically used for training\nclassifiers. On the other hand, we show that there exist regimes where these\nsolutions are near-optimal when evaluated by the 0-1 test loss function, but do\nnot generalize if evaluated by the square loss function, i.e. they achieve the\nnull risk. Our results demonstrate the very different roles and properties of\nloss functions used at the training phase (optimization) and the testing phase\n(generalization).\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 17:58:25 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Muthukumar", "Vidya", ""], ["Narang", "Adhyyan", ""], ["Subramanian", "Vignesh", ""], ["Belkin", "Mikhail", ""], ["Hsu", "Daniel", ""], ["Sahai", "Anant", ""]]}, {"id": "2005.08057", "submitter": "Yang Feng", "authors": "Yang Feng and Qingfeng Liu", "title": "Nested Model Averaging on Solution Path for High-dimensional Linear\n  Regression", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the nested model averaging method on the solution path for a\nhigh-dimensional linear regression problem. In particular, we propose to\ncombine model averaging with regularized estimators (e.g., lasso and SLOPE) on\nthe solution path for high-dimensional linear regression. In simulation\nstudies, we first conduct a systematic investigation on the impact of predictor\nordering on the behavior of nested model averaging, then show that nested model\naveraging with lasso and SLOPE compares favorably with other competing methods,\nincluding the infeasible lasso and SLOPE with the tuning parameter optimally\nselected. A real data analysis on predicting the per capita violent crime in\nthe United States shows an outstanding performance of the nested model\naveraging with lasso.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 18:09:57 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Feng", "Yang", ""], ["Liu", "Qingfeng", ""]]}, {"id": "2005.08067", "submitter": "Markus L\\\"oning", "authors": "Markus L\\\"oning, Franz Kir\\'aly", "title": "Forecasting with sktime: Designing sktime's New Forecasting API and\n  Applying It to Replicate and Extend the M4 Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new open-source framework for forecasting in Python. Our\nframework forms part of sktime, a more general machine learning toolbox for\ntime series with scikit-learn compatible interfaces for different learning\ntasks. Our new framework provides dedicated forecasting algorithms and tools to\nbuild, tune and evaluate composite models. We use sktime to both replicate and\nextend key results from the M4 forecasting study. In particular, we further\ninvestigate the potential of simple off-the-shelf machine learning approaches\nfor univariate forecasting. Our main results are that simple hybrid approaches\ncan boost the performance of statistical models, and that simple pure\napproaches can achieve competitive performance on the hourly data set,\noutperforming the statistical algorithms and coming close to the M4 winner.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 19:15:09 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 17:57:30 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["L\u00f6ning", "Markus", ""], ["Kir\u00e1ly", "Franz", ""]]}, {"id": "2005.08068", "submitter": "Ignasi Clavera", "authors": "Ignasi Clavera, Violet Fu, Pieter Abbeel", "title": "Model-Augmented Actor-Critic: Backpropagating through Paths", "comments": "Accepted paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current model-based reinforcement learning approaches use the model simply as\na learned black-box simulator to augment the data for policy optimization or\nvalue function learning. In this paper, we show how to make more effective use\nof the model by exploiting its differentiability. We construct a policy\noptimization algorithm that uses the pathwise derivative of the learned model\nand policy across future timesteps. Instabilities of learning across many\ntimesteps are prevented by using a terminal value function, learning the policy\nin an actor-critic fashion. Furthermore, we present a derivation on the\nmonotonic improvement of our objective in terms of the gradient error in the\nmodel and value function. We show that our approach (i) is consistently more\nsample efficient than existing state-of-the-art model-based algorithms, (ii)\nmatches the asymptotic performance of model-free algorithms, and (iii) scales\nto long horizons, a regime where typically past model-based approaches have\nstruggled.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 19:18:10 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Clavera", "Ignasi", ""], ["Fu", "Violet", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2005.08088", "submitter": "Ningyuan Chen", "authors": "Ningyuan Chen, Chun Wang, Longlin Wang", "title": "Learning and Optimization with Seasonal Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seasonality is a common form of non-stationary patterns in the business\nworld. We study a decision maker who tries to learn the optimal decision over\ntime when the environment is unknown and evolving with seasonality. We consider\na multi-armed bandit (MAB) framework where the mean rewards are periodic. The\nunknown periods of the arms can be different and scale with the length of the\nhorizon $T$ polynomially. We propose a two-staged policy that combines Fourier\nanalysis with a confidence-bound based learning procedure to learn the periods\nand minimize the regret. In stage one, the policy is able to correctly estimate\nthe periods of all arms with high probability. In stage two, the policy\nexplores mean rewards of arms in each phase using the periods estimated in\nstage one and exploits the optimal arm in the long run. We show that our policy\nachieves the rate of regret $\\tilde{O}(\\sqrt{T\\sum_{k=1}^K T_k})$, where $K$ is\nthe number of arms and $T_k$ is the period of arm $k$. It matches the optimal\nrate of regret of the classic MAB problem $O(\\sqrt{TK})$ if we regard each\nphase of an arm as a separate arm.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:19:25 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:15:15 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 16:30:49 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Chen", "Ningyuan", ""], ["Wang", "Chun", ""], ["Wang", "Longlin", ""]]}, {"id": "2005.08099", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler", "title": "Reducibility and Statistical-Computational Gaps from Secret Leakage", "comments": "175 pages; subsumes preliminary draft arXiv:1908.06130; accepted for\n  presentation at the Conference on Learning Theory (COLT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference problems with conjectured statistical-computational gaps are\nubiquitous throughout modern statistics, computer science and statistical\nphysics. While there has been success evidencing these gaps from the failure of\nrestricted classes of algorithms, progress towards a more traditional\nreduction-based approach to computational complexity in statistical inference\nhas been limited. Existing reductions have largely been limited to inference\nproblems with similar structure -- primarily mapping among problems\nrepresentable as a sparse submatrix signal plus a noise matrix, which are\nsimilar to the common hardness assumption of planted clique.\n  The insight in this work is that a slight generalization of the planted\nclique conjecture -- secret leakage planted clique -- gives rise to a variety\nof new average-case reduction techniques, yielding a web of reductions among\nproblems with very different structure. Using variants of the planted clique\nconjecture for specific forms of secret leakage planted clique, we deduce tight\nstatistical-computational tradeoffs for a diverse range of problems including\nrobust sparse mean estimation, mixtures of sparse linear regressions, robust\nsparse linear regression, tensor PCA, variants of dense $k$-block stochastic\nblock models, negatively correlated sparse PCA, semirandom planted dense\nsubgraph, detection in hidden partition models and a universality principle for\nlearning sparse mixtures. In particular, a $k$-partite hypergraph variant of\nthe planted clique conjecture is sufficient to establish all of our\ncomputational lower bounds. Our techniques also reveal novel connections to\ncombinatorial designs and to random matrix theory. This work gives the first\nevidence that an expanded set of hardness assumptions, such as for secret\nleakage planted clique, may be a key first step towards a more complete theory\nof reductions among statistical problems.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:56:09 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 21:59:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""]]}, {"id": "2005.08106", "submitter": "Boyana Buyuklieva", "authors": "Boyana Buyuklieva", "title": "Machine Learning for Exploring Spatial Affordance Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation uses supervised and unsupervised data mining techniques to\nanalyse office floor plans in an attempt to gain a better understanding of\ntheir geometry-to-function relationship. This question was deemed relevant\nafter a background review of the state-of-the-art in automated floor-plan\ngeneration tools showed that such tools have been prototyped since the 1960s,\nbut their search space is ill-informed because there are few formalisms to\ndescribe spatial affordance. To show and evaluate the relationship of geometry\nand use, data from visual graph analysis were used to train three supervised\nlearners and compare these to a baseline accuracy established with a ZeroR\nclassifier. This showed that for the office dataset examined, visual mean depth\nand integration are most tightly linked to usage and that the supervised\nlearning algorithm J48 can correctly predict class performance on unseen\nexamples to up to 79.5%. The thesis also includes an evaluation of the layout\ncase studies with unsupervised learners, which showed that use could not be\nimmediately reverse-engineered based solemnly on the VGA information to achieve\na strong cluster-to-class evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 21:12:06 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Buyuklieva", "Boyana", ""]]}, {"id": "2005.08110", "submitter": "Meet Vadera", "authors": "Meet P. Vadera, Brian Jalaian and Benjamin M. Marlin", "title": "Generalized Bayesian Posterior Expectation Distillation for Deep Neural\n  Networks", "comments": "Accepted at UAI '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a general framework for distilling expectations\nwith respect to the Bayesian posterior distribution of a deep neural network\nclassifier, extending prior work on the Bayesian Dark Knowledge framework. The\nproposed framework takes as input \"teacher\" and student model architectures and\na general posterior expectation of interest. The distillation method performs\nan online compression of the selected posterior expectation using iteratively\ngenerated Monte Carlo samples. We focus on the posterior predictive\ndistribution and expected entropy as distillation targets. We investigate\nseveral aspects of this framework including the impact of uncertainty and the\nchoice of student model architecture. We study methods for student model\narchitecture search from a speed-storage-accuracy perspective and evaluate\ndown-stream tasks leveraging entropy distillation including uncertainty ranking\nand out-of-distribution detection.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 21:40:47 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Vadera", "Meet P.", ""], ["Jalaian", "Brian", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2005.08114", "submitter": "Ignasi Clavera", "authors": "Yiming Ding, Ignasi Clavera, Pieter Abbeel", "title": "Mutual Information Maximization for Robust Plannable Representations", "comments": "Accepted at NeurIPS 2019 Workshop on Robot Learning: Control and\n  Interaction in the Real World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending the capabilities of robotics to real-world complex, unstructured\nenvironments requires the need of developing better perception systems while\nmaintaining low sample complexity. When dealing with high-dimensional state\nspaces, current methods are either model-free or model-based based on\nreconstruction objectives. The sample inefficiency of the former constitutes a\nmajor barrier for applying them to the real-world. The later, while they\npresent low sample complexity, they learn latent spaces that need to\nreconstruct every single detail of the scene. In real environments, the task\ntypically just represents a small fraction of the scene. Reconstruction\nobjectives suffer in such scenarios as they capture all the unnecessary\ncomponents. In this work, we present MIRO, an information theoretic\nrepresentational learning algorithm for model-based reinforcement learning. We\ndesign a latent space that maximizes the mutual information with the future\ninformation while being able to capture all the information needed for\nplanning. We show that our approach is more robust than reconstruction\nobjectives in the presence of distractors and cluttered scenes\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 21:58:47 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ding", "Yiming", ""], ["Clavera", "Ignasi", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2005.08140", "submitter": "Sebastian Ober", "authors": "Sebastian W. Ober, Laurence Aitchison", "title": "Global inducing point variational posteriors for Bayesian neural\n  networks and deep Gaussian processes", "comments": "Accepted for publication at the 38th International Conference on\n  Machine Learning (ICML 2021, PMLR 139), 33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimal approximate posterior over the top-layer weights in a\nBayesian neural network for regression, and show that it exhibits strong\ndependencies on the lower-layer weights. We adapt this result to develop a\ncorrelated approximate posterior over the weights at all layers in a Bayesian\nneural network. We extend this approach to deep Gaussian processes, unifying\ninference in the two model classes. Our approximate posterior uses learned\n\"global\" inducing points, which are defined only at the input layer and\npropagated through the network to obtain inducing inputs at subsequent layers.\nBy contrast, standard, \"local\", inducing point methods from the deep Gaussian\nprocess literature optimise a separate set of inducing inputs at every layer,\nand thus do not model correlations across layers. Our method gives\nstate-of-the-art performance for a variational Bayesian method, without data\naugmentation or tempering, on CIFAR-10 of 86.7%, which is comparable to SGMCMC\nwithout tempering but with data augmentation (88% in Wenzel et al. 2020).\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 01:10:37 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 00:10:04 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 12:14:08 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 14:39:42 GMT"}, {"version": "v5", "created": "Tue, 22 Jun 2021 13:39:01 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ober", "Sebastian W.", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2005.08144", "submitter": "Christopher Choy", "authors": "Christopher Choy, Junha Lee, Rene Ranftl, Jaesik Park, Vladlen Koltun", "title": "High-dimensional Convolutional Networks for Geometric Pattern\n  Recognition", "comments": "Accepted for CVPR 2020 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many problems in science and engineering can be formulated in terms of\ngeometric patterns in high-dimensional spaces. We present high-dimensional\nconvolutional networks (ConvNets) for pattern recognition problems that arise\nin the context of geometric registration. We first study the effectiveness of\nconvolutional networks in detecting linear subspaces in high-dimensional spaces\nwith up to 32 dimensions: much higher dimensionality than prior applications of\nConvNets. We then apply high-dimensional ConvNets to 3D registration under\nrigid motions and image correspondence estimation. Experiments indicate that\nour high-dimensional ConvNets outperform prior approaches that relied on deep\nnetworks based on global pooling operators.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 01:46:12 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Choy", "Christopher", ""], ["Lee", "Junha", ""], ["Ranftl", "Rene", ""], ["Park", "Jaesik", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2005.08158", "submitter": "Yash Chandak", "authors": "Yash Chandak, Georgios Theocharous, Shiv Shankar, Martha White,\n  Sridhar Mahadevan, Philip S. Thomas", "title": "Optimizing for the Future in Non-Stationary MDPs", "comments": "Thirty-seventh International Conference on Machine Learning (ICML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most reinforcement learning methods are based upon the key assumption that\nthe transition dynamics and reward functions are fixed, that is, the underlying\nMarkov decision process is stationary. However, in many real-world\napplications, this assumption is violated, and using existing algorithms may\nresult in a performance lag. To proactively search for a good future policy, we\npresent a policy gradient algorithm that maximizes a forecast of future\nperformance. This forecast is obtained by fitting a curve to the\ncounter-factual estimates of policy performance over time, without explicitly\nmodeling the underlying non-stationarity. The resulting algorithm amounts to a\nnon-uniform reweighting of past data, and we observe that minimizing\nperformance over some of the data from past episodes can be beneficial when\nsearching for a policy that maximizes future performance. We show that our\nalgorithm, called Prognosticator, is more robust to non-stationarity than two\nonline adaptation techniques, on three simulated problems motivated by\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 03:41:19 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:28:24 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 02:45:46 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 23:28:01 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Chandak", "Yash", ""], ["Theocharous", "Georgios", ""], ["Shankar", "Shiv", ""], ["White", "Martha", ""], ["Mahadevan", "Sridhar", ""], ["Thomas", "Philip S.", ""]]}, {"id": "2005.08189", "submitter": "Sezin Kircali Ata Dr.", "authors": "Sezin Kircali Ata, Yuan Fang, Min Wu, Jiaqi Shi, Chee Keong Kwoh and\n  Xiaoli Li", "title": "Multi-View Collaborative Network Embedding", "comments": "Accepted for publication in the ACM Transactions on Knowledge\n  Discovery from Data, TKDD", "journal-ref": "ACM Trans. Knowl. Discov. Data 15, 3, Article 39 (April 2021), 18\n  pages", "doi": "10.1145/3441450", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world networks often exist with multiple views, where each view\ndescribes one type of interaction among a common set of nodes. For example, on\na video-sharing network, while two user nodes are linked if they have common\nfavorite videos in one view, they can also be linked in another view if they\nshare common subscribers. Unlike traditional single-view networks, multiple\nviews maintain different semantics to complement each other. In this paper, we\npropose MANE, a multi-view network embedding approach to learn low-dimensional\nrepresentations. Similar to existing studies, MANE hinges on diversity and\ncollaboration - while diversity enables views to maintain their individual\nsemantics, collaboration enables views to work together. However, we also\ndiscover a novel form of second-order collaboration that has not been explored\npreviously, and further unify it into our framework to attain superior node\nrepresentations. Furthermore, as each view often has varying importance w.r.t.\ndifferent nodes, we propose MANE+, an attention-based extension of MANE to\nmodel node-wise view importance. Finally, we conduct comprehensive experiments\non three public, real-world multi-view networks, and the results demonstrate\nthat our models consistently outperform state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 08:12:53 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 14:34:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ata", "Sezin Kircali", ""], ["Fang", "Yuan", ""], ["Wu", "Min", ""], ["Shi", "Jiaqi", ""], ["Kwoh", "Chee Keong", ""], ["Li", "Xiaoli", ""]]}, {"id": "2005.08226", "submitter": "Arnab Kumar Mondal", "authors": "Arnab Kumar Mondal, Arnab Bhattacharya, Sudipto Mukherjee, Prathosh\n  AP, Sreeram Kannan, Himanshu Asnani", "title": "C-MI-GAN : Estimation of Conditional Mutual Information using MinMax\n  formulation", "comments": "Updated for UAI, 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of information theoretic quantities such as mutual information and\nits conditional variant has drawn interest in recent times owing to their\nmultifaceted applications. Newly proposed neural estimators for these\nquantities have overcome severe drawbacks of classical $k$NN-based estimators\nin high dimensions. In this work, we focus on conditional mutual information\n(CMI) estimation by utilizing its formulation as a minmax optimization problem.\nSuch a formulation leads to a joint training procedure similar to that of\ngenerative adversarial networks. We find that our proposed estimator provides\nbetter estimates than the existing approaches on a variety of simulated data\nsets comprising linear and non-linear relations between variables. As an\napplication of CMI estimation, we deploy our estimator for conditional\nindependence (CI) testing on real data and obtain better results than\nstate-of-the-art CI testers.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:22:12 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 06:02:58 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mondal", "Arnab Kumar", ""], ["Bhattacharya", "Arnab", ""], ["Mukherjee", "Sudipto", ""], ["AP", "Prathosh", ""], ["Kannan", "Sreeram", ""], ["Asnani", "Himanshu", ""]]}, {"id": "2005.08238", "submitter": "Zhibing Zhao", "authors": "Zhibing Zhao, Yingce Xia, Tao Qin, Lirong Xia, Tie-Yan Liu", "title": "Dual Learning: Theoretical Study and an Algorithmic Extension", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual learning has been successfully applied in many machine learning\napplications including machine translation, image-to-image transformation, etc.\nThe high-level idea of dual learning is very intuitive: if we map an $x$ from\none domain to another and then map it back, we should recover the original $x$.\nAlthough its effectiveness has been empirically verified, theoretical\nunderstanding of dual learning is still very limited. In this paper, we aim at\nunderstanding why and when dual learning works. Based on our theoretical\nanalysis, we further extend dual learning by introducing more related mappings\nand propose multi-step dual learning, in which we leverage feedback signals\nfrom additional domains to improve the qualities of the mappings. We prove that\nmulti-step dual learn-ing can boost the performance of standard dual learning\nunder mild conditions. Experiments on WMT 14 English$\\leftrightarrow$German and\nMultiUNEnglish$\\leftrightarrow$French translations verify our theoretical\nfindings on dual learning, and the results on the translations among English,\nFrench, and Spanish of MultiUN demonstrate the effectiveness of multi-step dual\nlearning.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 12:14:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhao", "Zhibing", ""], ["Xia", "Yingce", ""], ["Qin", "Tao", ""], ["Xia", "Lirong", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2005.08302", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, August DuMont Sch\\\"utte, Benedikt Dietz, Stefan Bauer", "title": "Clinical Predictive Models for COVID-19: Systematic Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus Disease 2019 (COVID-19) is a rapidly emerging respiratory disease\ncaused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Due\nto the rapid human-to-human transmission of SARS-CoV-2, many healthcare systems\nare at risk of exceeding their healthcare capacities, in particular in terms of\nSARS-CoV-2 tests, hospital and intensive care unit (ICU) beds and mechanical\nventilators. Predictive algorithms could potentially ease the strain on\nhealthcare systems by identifying those who are most likely to receive a\npositive SARS-CoV-2 test, be hospitalised or admitted to the ICU. Here, we\nstudy clinical predictive models that estimate, using machine learning and\nbased on routinely collected clinical data, which patients are likely to\nreceive a positive SARS-CoV-2 test, require hospitalisation or intensive care.\nTo evaluate the predictive performance of our models, we perform a\nretrospective evaluation on clinical and blood analysis data from a cohort of\n5644 patients. Our experimental results indicate that our predictive models\nidentify (i) patients that test positive for SARS-CoV-2 a priori at a\nsensitivity of 75% (95% CI: 67%, 81%) and a specificity of 49% (95% CI: 46%,\n51%), (ii) SARS-CoV-2 positive patients that require hospitalisation with 0.92\nAUC (95% CI: 0.81, 0.98), and (iii) SARS-CoV-2 positive patients that require\ncritical care with 0.98 AUC (95% CI: 0.95, 1.00). In addition, we determine\nwhich clinical features are predictive to what degree for each of the\naforementioned clinical tasks. Our results indicate that predictive models\ntrained on routinely collected clinical data could be used to predict clinical\npathways for COVID-19, and therefore help inform care and prioritise resources.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:10:39 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 20:21:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Schwab", "Patrick", ""], ["Sch\u00fctte", "August DuMont", ""], ["Dietz", "Benedikt", ""], ["Bauer", "Stefan", ""]]}, {"id": "2005.08321", "submitter": "Mahdieh Abbasi", "authors": "Mahdieh Abbasi and Arezoo Rajabi and Christian Gagne and Rakesh B.\n  Bobba", "title": "Toward Adversarial Robustness by Diversity in an Ensemble of Specialized\n  Deep Neural Networks", "comments": "Published by Springer in the Lecture Notes in Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at demonstrating the influence of diversity in the ensemble of CNNs on\nthe detection of black-box adversarial instances and hardening the generation\nof white-box adversarial attacks. To this end, we propose an ensemble of\ndiverse specialized CNNs along with a simple voting mechanism. The diversity in\nthis ensemble creates a gap between the predictive confidences of adversaries\nand those of clean samples, making adversaries detectable. We then analyze how\ndiversity in such an ensemble of specialists may mitigate the risk of the\nblack-box and white-box adversarial examples. Using MNIST and CIFAR-10, we\nempirically verify the ability of our ensemble to detect a large portion of\nwell-known black-box adversarial examples, which leads to a significant\nreduction in the risk rate of adversaries, at the expense of a small increase\nin the risk rate of clean samples. Moreover, we show that the success rate of\ngenerating white-box attacks by our ensemble is remarkably decreased compared\nto a vanilla CNN and an ensemble of vanilla CNNs, highlighting the beneficial\nrole of diversity in the ensemble for developing more robust models.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:54:49 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Abbasi", "Mahdieh", ""], ["Rajabi", "Arezoo", ""], ["Gagne", "Christian", ""], ["Bobba", "Rakesh B.", ""]]}, {"id": "2005.08323", "submitter": "Liming Zhang", "authors": "Liming Zhang, Liang Zhao, Shan Qin, Dieter Pfoser", "title": "TG-GAN: Continuous-time Temporal Graph Generation with Deep Generative\n  Models", "comments": null, "journal-ref": "thewebconf 2021", "doi": "10.1145/3442381.3449818", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent deep generative models for static graphs that are now being\nactively developed have achieved significant success in areas such as molecule\ndesign. However, many real-world problems involve temporal graphs whose\ntopology and attribute values evolve dynamically over time, including important\napplications such as protein folding, human mobility networks, and social\nnetwork growth. As yet, deep generative models for temporal graphs are not yet\nwell understood and existing techniques for static graphs are not adequate for\ntemporal graphs since they cannot 1) encode and decode continuously-varying\ngraph topology chronologically, 2) enforce validity via temporal constraints,\nor 3) ensure efficiency for information-lossless temporal resolution. To\naddress these challenges, we propose a new model, called ``Temporal Graph\nGenerative Adversarial Network'' (TG-GAN) for continuous-time temporal graph\ngeneration, by modeling the deep generative process for truncated temporal\nrandom walks and their compositions. Specifically, we first propose a novel\ntemporal graph generator that jointly model truncated edge sequences, time\nbudgets, and node attributes, with novel activation functions that enforce\ntemporal validity constraints under recurrent architecture. In addition, a new\ntemporal graph discriminator is proposed, which combines time and node encoding\noperations over a recurrent architecture to distinguish the generated sequences\nfrom the real ones sampled by a newly-developed truncated temporal random walk\nsampler. Extensive experiments on both synthetic and real-world datasets\ndemonstrate TG-GAN significantly outperforms the comparison methods in\nefficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:59:12 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 19:47:40 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zhang", "Liming", ""], ["Zhao", "Liang", ""], ["Qin", "Shan", ""], ["Pfoser", "Dieter", ""]]}, {"id": "2005.08377", "submitter": "Sumegha Garg", "authors": "Mark Braverman and Sumegha Garg", "title": "The Role of Randomness and Noise in Strategic Classification", "comments": "22 pages. Appeared in FORC, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of designing optimal classifiers in the strategic\nclassification setting, where the classification is part of a game in which\nplayers can modify their features to attain a favorable classification outcome\n(while incurring some cost). Previously, the problem has been considered from a\nlearning-theoretic perspective and from the algorithmic fairness perspective.\nOur main contributions include 1. Showing that if the objective is to maximize\nthe efficiency of the classification process (defined as the accuracy of the\noutcome minus the sunk cost of the qualified players manipulating their\nfeatures to gain a better outcome), then using randomized classifiers (that is,\nones where the probability of a given feature vector to be accepted by the\nclassifier is strictly between 0 and 1) is necessary. 2. Showing that in many\nnatural cases, the imposed optimal solution (in terms of efficiency) has the\nstructure where players never change their feature vectors (the randomized\nclassifier is structured in a way, such that the gain in the probability of\nbeing classified as a 1 does not justify the expense of changing one's\nfeatures). 3. Observing that the randomized classification is not a stable\nbest-response from the classifier's viewpoint, and that the classifier doesn't\nbenefit from randomized classifiers without creating instability in the system.\n4. Showing that in some cases, a noisier signal leads to better equilibria\noutcomes -- improving both accuracy and fairness when more than one\nsubpopulation with different feature adjustment costs are involved. This is\ninteresting from a policy perspective, since it is hard to force institutions\nto stick to a particular randomized classification strategy (especially in a\ncontext of a market with multiple classifiers), but it is possible to alter the\ninformation environment to make the feature signals inherently noisier.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 21:49:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Braverman", "Mark", ""], ["Garg", "Sumegha", ""]]}, {"id": "2005.08395", "submitter": "Babacar Mbaye Ndiaye", "authors": "Mouhamadou A.M.T. Balde, Coura Balde, Babacar M. Ndiaye", "title": "Impact studies of nationwide measures COVID-19 anti-pandemic:\n  compartmental model and machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the study of the impact of nationwide measures\nCOVID-19 anti-pandemic. We drive two processes to analyze COVID-19 data\nconsidering measures. We associate level of nationwide measure with value of\nparameters related to the contact rate of the model. Then a parametric solve,\nwith respect to those parameters of measures, shows different possibilities of\nthe evolution of the pandemic. Two machine learning tools are used to forecast\nthe evolution of the pandemic. Finally, we show comparison between\ndeterministic and two machine learning tools.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 23:23:38 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 21:57:38 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Balde", "Mouhamadou A. M. T.", ""], ["Balde", "Coura", ""], ["Ndiaye", "Babacar M.", ""]]}, {"id": "2005.08414", "submitter": "Takashi Goda", "authors": "Takashi Goda, Tomohiko Hironaka, Wataru Kitade, Adam Foster", "title": "Unbiased MLMC stochastic gradient-based optimization of Bayesian\n  experimental designs", "comments": "major revision, 26 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose an efficient stochastic optimization algorithm to\nsearch for Bayesian experimental designs such that the expected information\ngain is maximized. The gradient of the expected information gain with respect\nto experimental design parameters is given by a nested expectation, for which\nthe standard Monte Carlo method using a fixed number of inner samples yields a\nbiased estimator. In this paper, applying the idea of randomized multilevel\nMonte Carlo (MLMC) methods, we introduce an unbiased Monte Carlo estimator for\nthe gradient of the expected information gain with finite expected squared\n$\\ell_2$-norm and finite expected computational cost per sample. Our unbiased\nestimator can be combined well with stochastic gradient descent algorithms,\nwhich results in our proposal of an optimization algorithm to search for an\noptimal Bayesian experimental design. Numerical experiments confirm that our\nproposed algorithm works well not only for a simple test problem but also for a\nmore realistic pharmacokinetic problem.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 01:02:31 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 02:21:46 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 05:13:20 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Goda", "Takashi", ""], ["Hironaka", "Tomohiko", ""], ["Kitade", "Wataru", ""], ["Foster", "Adam", ""]]}, {"id": "2005.08419", "submitter": "Zhenyu Yuan", "authors": "Zhenyu Yuan, Yuxin Jiang, Jingjing Li, Handong Huang", "title": "Hybrid-DNNs: Hybrid Deep Neural Networks for Mixed Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid development of big data and high-performance computing have encouraged\nexplosive studies of deep learning in geoscience. However, most studies only\ntake single-type data as input, frittering away invaluable multisource,\nmulti-scale information. We develop a general architecture of hybrid deep\nneural networks (HDNNs) to support mixed inputs. Regarding as a combination of\nfeature learning and target learning, the new proposed networks provide great\ncapacity in high-hierarchy feature extraction and in-depth data mining.\nFurthermore, the hybrid architecture is an aggregation of multiple networks,\ndemonstrating good flexibility and wide applicability. The configuration of\nmultiple networks depends on application tasks and varies with inputs and\ntargets. Concentrating on reservoir production prediction, a specific HDNN\nmodel is configured and applied to an oil development block. Considering their\ncontributions to hydrocarbon production, core photos, logging images and\ncurves, geologic and engineering parameters can all be taken as inputs. After\npreprocessing, the mixed inputs are prepared as regular-sampled structural and\nnumerical data. For feature learning, convolutional neural networks (CNN) and\nmultilayer perceptron (MLP) network are configured to separately process\nstructural and numerical inputs. Learned features are then concatenated and fed\nto subsequent networks for target learning. Comparison with typical MLP model\nand CNN model highlights the superiority of proposed HDNN model with high\naccuracy and good generalization.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 01:40:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yuan", "Zhenyu", ""], ["Jiang", "Yuxin", ""], ["Li", "Jingjing", ""], ["Huang", "Handong", ""]]}, {"id": "2005.08431", "submitter": "Gengyan Zhao", "authors": "Gengyan Zhao, Gyujoon Hwang, Cole J. Cook, Fang Liu, Mary E. Meyerand\n  and Rasmus M. Birn", "title": "Deep Learning and Bayesian Deep Learning Based Gender Prediction in\n  Multi-Scale Brain Functional Connectivity", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain gender differences have been known for a long time and are the possible\nreason for many psychological, psychiatric and behavioral differences between\nmales and females. Predicting genders from brain functional connectivity (FC)\ncan build the relationship between brain activities and gender, and extracting\nimportant gender related FC features from the prediction model offers a way to\ninvestigate the brain gender difference. Current predictive models applied to\ngender prediction demonstrate good accuracies, but usually extract individual\nfunctional connections instead of connectivity patterns in the whole\nconnectivity matrix as features. In addition, current models often omit the\neffect of the input brain FC scale on prediction and cannot give any model\nuncertainty information. Hence, in this study we propose to predict gender from\nmultiple scales of brain FC with deep learning, which can extract full FC\npatterns as features. We further develop the understanding of the feature\nextraction mechanism in deep neural network (DNN) and propose a DNN feature\nranking method to extract the highly important features based on their\ncontributions to the prediction. Moreover, we apply Bayesian deep learning to\nthe brain FC gender prediction, which as a probabilistic model can not only\nmake accurate predictions but also generate model uncertainty for each\nprediction. Experiments were done on the high-quality Human Connectome Project\nS1200 release dataset comprising the resting state functional MRI data of 1003\nhealthy adults. First, DNN reaches 83.0%, 87.6%, 92.0%, 93.5% and 94.1%\naccuracies respectively with the FC input derived from 25, 50, 100, 200, 300\nindependent component analysis (ICA) components. DNN outperforms the\nconventional machine learning methods on the 25-ICA-component scale FC, but the\nlinear machine learning method catches up as the number of ICA components\nincreases...\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 02:43:26 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhao", "Gengyan", ""], ["Hwang", "Gyujoon", ""], ["Cook", "Cole J.", ""], ["Liu", "Fang", ""], ["Meyerand", "Mary E.", ""], ["Birn", "Rasmus M.", ""]]}, {"id": "2005.08434", "submitter": "Lai Wei", "authors": "Lai Wei, Xiaobo Tan, and Vaibhav Srivastava", "title": "Expedited Multi-Target Search with Guaranteed Performance via\n  Multi-fidelity Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scenario in which an autonomous vehicle equipped with a\ndownward facing camera operates in a 3D environment and is tasked with\nsearching for an unknown number of stationary targets on the 2D floor of the\nenvironment. The key challenge is to minimize the search time while ensuring a\nhigh detection accuracy. We model the sensing field using a multi-fidelity\nGaussian process that systematically describes the sensing information\navailable at different altitudes from the floor. Based on the sensing model, we\ndesign a novel algorithm called Expedited Multi-Target Search (EMTS) that (i)\naddresses the coverage-accuracy trade-off: sampling at locations farther from\nthe floor provides wider field of view but less accurate measurements, (ii)\ncomputes an occupancy map of the floor within a prescribed accuracy and quickly\neliminates unoccupied regions from the search space, and (iii) travels\nefficiently to collect the required samples for target detection. We rigorously\nanalyze the algorithm and establish formal guarantees on the target detection\naccuracy and the expected detection time. We illustrate the algorithm using a\nsimulated multi-target search scenario.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 02:53:52 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Wei", "Lai", ""], ["Tan", "Xiaobo", ""], ["Srivastava", "Vaibhav", ""]]}, {"id": "2005.08435", "submitter": "Sara Mohammadinejad", "authors": "Sara Mohammadinejad, Jyotirmoy V. Deshmukh, Aniruddh G. Puranic", "title": "Mining Environment Assumptions for Cyber-Physical System Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex cyber-physical systems can be modeled as heterogeneous\ncomponents interacting with each other in real-time. We assume that the\ncorrectness of each component can be specified as a requirement satisfied by\nthe output signals produced by the component, and that such an output guarantee\nis expressed in a real-time temporal logic such as Signal Temporal Logic (STL).\nIn this paper, we hypothesize that a large subset of input signals for which\nthe corresponding output signals satisfy the output requirement can also be\ncompactly described using an STL formula that we call the environment\nassumption. We propose an algorithm to mine such an environment assumption\nusing a supervised learning technique. Essentially, our algorithm treats the\nenvironment assumption as a classifier that labels input signals as good if the\ncorresponding output signal satisfies the output requirement, and as bad\notherwise. Our learning method simultaneously learns the structure of the STL\nformula as well as the values of the numeric constants appearing in the\nformula. To achieve this, we combine a procedure to systematically enumerate\ncandidate Parametric STL (PSTL) formulas, with a decision-tree based approach\nto learn parameter values. We demonstrate experimental results on real world\ndata from several domains including transportation and health care.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 03:05:21 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mohammadinejad", "Sara", ""], ["Deshmukh", "Jyotirmoy V.", ""], ["Puranic", "Aniruddh G.", ""]]}, {"id": "2005.08442", "submitter": "Snehanshu Saha", "authors": "Shailesh Sridhar, Snehanshu Saha, Azhar Shaikh, Rahul Yedida, Sriparna\n  Saha", "title": "Parsimonious Computing: A Minority Training Regime for Effective\n  Prediction in Large Microarray Expression Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rigorous mathematical investigation of learning rates used in\nback-propagation in shallow neural networks has become a necessity. This is\nbecause experimental evidence needs to be endorsed by a theoretical background.\nSuch theory may be helpful in reducing the volume of experimental effort to\naccomplish desired results. We leveraged the functional property of Mean Square\nError, which is Lipschitz continuous to compute learning rate in shallow neural\nnetworks. We claim that our approach reduces tuning efforts, especially when a\nsignificant corpus of data has to be handled. We achieve remarkable improvement\nin saving computational cost while surpassing prediction accuracy reported in\nliterature. The learning rate, proposed here, is the inverse of the Lipschitz\nconstant. The work results in a novel method for carrying out gene expression\ninference on large microarray data sets with a shallow architecture constrained\nby limited computing resources. A combination of random sub-sampling of the\ndataset, an adaptive Lipschitz constant inspired learning rate and a new\nactivation function, A-ReLU helped accomplish the results reported in the\npaper.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 03:45:05 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Sridhar", "Shailesh", ""], ["Saha", "Snehanshu", ""], ["Shaikh", "Azhar", ""], ["Yedida", "Rahul", ""], ["Saha", "Sriparna", ""]]}, {"id": "2005.08445", "submitter": "Hirokazu Kameoka", "authors": "Hirokazu Kameoka, Wen-Chin Huang, Kou Tanaka, Takuhiro Kaneko,\n  Nobukatsu Hojo, and Tomoki Toda", "title": "Many-to-Many Voice Transformer Network", "comments": "submitted to IEEE/ACM Trans. ASLP. Please also refer to our related\n  article: arXiv:1811.01609", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a voice conversion (VC) method based on a\nsequence-to-sequence (S2S) learning framework, which enables simultaneous\nconversion of the voice characteristics, pitch contour, and duration of input\nspeech. We previously proposed an S2S-based VC method using a transformer\nnetwork architecture called the voice transformer network (VTN). The original\nVTN was designed to learn only a mapping of speech feature sequences from one\nspeaker to another. The main idea we propose is an extension of the original\nVTN that can simultaneously learn mappings among multiple speakers. This\nextension called the many-to-many VTN makes it able to fully use available\ntraining data collected from multiple speakers by capturing common latent\nfeatures that can be shared across different speakers. It also allows us to\nintroduce a training loss called the identity mapping loss to ensure that the\ninput feature sequence will remain unchanged when the source and target speaker\nindices are the same. Using this particular loss for model training has been\nfound to be extremely effective in improving the performance of the model at\ntest time. We conducted speaker identity conversion experiments and found that\nour model obtained higher sound quality and speaker similarity than baseline\nmethods. We also found that our model, with a slight modification to its\narchitecture, could handle any-to-many conversion tasks reasonably well.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 04:02:08 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 13:14:07 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 14:48:19 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 22:46:52 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Kameoka", "Hirokazu", ""], ["Huang", "Wen-Chin", ""], ["Tanaka", "Kou", ""], ["Kaneko", "Takuhiro", ""], ["Hojo", "Nobukatsu", ""], ["Toda", "Tomoki", ""]]}, {"id": "2005.08467", "submitter": "Haitao Liu", "authors": "Haitao Liu, Yew-Soon Ong, Xiaomo Jiang, Xiaofang Wang", "title": "Deep Latent-Variable Kernel Learning", "comments": "13 pages, 8 figures, preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep kernel learning (DKL) leverages the connection between Gaussian process\n(GP) and neural networks (NN) to build an end-to-end, hybrid model. It combines\nthe capability of NN to learn rich representations under massive data and the\nnon-parametric property of GP to achieve automatic regularization that\nincorporates a trade-off between model fit and model complexity. However, the\ndeterministic encoder may weaken the model regularization of the following GP\npart, especially on small datasets, due to the free latent representation. We\ntherefore present a complete deep latent-variable kernel learning (DLVKL) model\nwherein the latent variables perform stochastic encoding for regularized\nrepresentation. We further enhance the DLVKL from two aspects: (i) the\nexpressive variational posterior through neural stochastic differential\nequation (NSDE) to improve the approximation quality, and (ii) the hybrid prior\ntaking knowledge from both the SDE prior and the posterior to arrive at a\nflexible trade-off. Intensive experiments imply that the DLVKL-NSDE performs\nsimilarly to the well calibrated GP on small datasets, and outperforms existing\ndeep GPs on large datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 05:55:08 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 04:46:29 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Liu", "Haitao", ""], ["Ong", "Yew-Soon", ""], ["Jiang", "Xiaomo", ""], ["Wang", "Xiaofang", ""]]}, {"id": "2005.08479", "submitter": "Wenjing Fang", "authors": "Wenjing Fang, Chaochao Chen, Jin Tan, Chaofan Yu, Yufei Lu, Li Wang,\n  Lei Wang, Jun Zhou and Alex X", "title": "A Hybrid-Domain Framework for Secure Gradient Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient tree boosting (e.g. XGB) is one of the most widely usedmachine\nlearning models in practice. How to build a secure XGB inface of data isolation\nproblem becomes a hot research topic. However, existing works tend to leak\nintermediate information and thusraise potential privacy risk. In this paper,\nwe propose a novel framework for two parties to build secure XGB with\nvertically partitioneddata. Specifically, we associate Homomorphic Encryption\n(HE) domain with Secret Sharing (SS) domain by providing the\ntwo-waytransformation primitives. The framework generally promotes\ntheefficiency for privacy preserving machine learning and offers theflexibility\nto implement other machine learning models. Then weelaborate two secure XGB\ntraining algorithms as well as a corresponding prediction algorithm under the\nhybrid security domains.Next, we compare our proposed two training algorithms\nthroughboth complexity analysis and experiments. Finally, we verify themodel\nperformance on benchmark dataset and further apply ourwork to a real-world\nscenario.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 06:31:10 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fang", "Wenjing", ""], ["Chen", "Chaochao", ""], ["Tan", "Jin", ""], ["Yu", "Chaofan", ""], ["Lu", "Yufei", ""], ["Wang", "Li", ""], ["Wang", "Lei", ""], ["Zhou", "Jun", ""], ["X", "Alex", ""]]}, {"id": "2005.08482", "submitter": "Phuoc Nguyen", "authors": "Phuoc Nguyen, Truyen Tran, Sunil Gupta, Santu Rana, Hieu-Chi Dam,\n  Svetha Venkatesh", "title": "HyperVAE: A Minimum Description Length Variational Hyper-Encoding\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework called HyperVAE for encoding distributions of\ndistributions. When a target distribution is modeled by a VAE, its neural\nnetwork parameters \\theta is drawn from a distribution p(\\theta) which is\nmodeled by a hyper-level VAE. We propose a variational inference using Gaussian\nmixture models to implicitly encode the parameters \\theta into a low\ndimensional Gaussian distribution. Given a target distribution, we predict the\nposterior distribution of the latent code, then use a matrix-network decoder to\ngenerate a posterior distribution q(\\theta). HyperVAE can encode the parameters\n\\theta in full in contrast to common hyper-networks practices, which generate\nonly the scale and bias vectors as target-network parameters. Thus HyperVAE\npreserves much more information about the model for each task in the latent\nspace. We discuss HyperVAE using the minimum description length (MDL) principle\nand show that it helps HyperVAE to generalize. We evaluate HyperVAE in density\nestimation tasks, outlier detection and discovery of novel design classes,\ndemonstrating its efficacy.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 06:46:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Nguyen", "Phuoc", ""], ["Tran", "Truyen", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Dam", "Hieu-Chi", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2005.08485", "submitter": "Kyuyong Shin", "authors": "Kyuyong Shin, Wonyoung Shin, Jung-Woo Ha, Sunyoung Kwon", "title": "Graphs, Entities, and Step Mixture", "comments": "5 pages, 4 figures, 3 tables accepted for ICML 2020 workshop on Graph\n  Representation Learning and Beyond (GRL+ 2020)", "journal-ref": "ICML 2020 GRL+ workshop", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches for graph neural networks commonly suffer from the\noversmoothing issue, regardless of how neighborhoods are aggregated. Most\nmethods also focus on transductive scenarios for fixed graphs, leading to poor\ngeneralization for unseen graphs. To address these issues, we propose a new\ngraph neural network that considers both edge-based neighborhood relationships\nand node-based entity features, i.e. Graph Entities with Step Mixture via\nrandom walk (GESM). GESM employs a mixture of various steps through random walk\nto alleviate the oversmoothing problem, attention to dynamically reflect\ninterrelations depending on node information, and structure-based\nregularization to enhance embedding representation. With intensive experiments,\nwe show that the proposed GESM achieves state-of-the-art or comparable\nperformances on eight benchmark graph datasets comprising transductive and\ninductive learning tasks. Furthermore, we empirically demonstrate the\nsignificance of considering global information.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 06:57:02 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 05:46:48 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Shin", "Kyuyong", ""], ["Shin", "Wonyoung", ""], ["Ha", "Jung-Woo", ""], ["Kwon", "Sunyoung", ""]]}, {"id": "2005.08519", "submitter": "Hanna Abi Akl", "authors": "Hanna Abi Akl, Dominique Mariko, Estelle Labidurie", "title": "Yseop at SemEval-2020 Task 5: Cascaded BERT Language Model for\n  Counterfactual Statement Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore strategies to detect and evaluate counterfactual\nsentences. We describe our system for SemEval-2020 Task 5: Modeling Causal\nReasoning in Language: Detecting Counterfactuals. We use a BERT base model for\nthe classification task and build a hybrid BERT Multi-Layer Perceptron system\nto handle the sequence identification task. Our experiments show that while\nintroducing syntactic and semantic features does little in improving the system\nin the classification task, using these types of features as cascaded linear\ninputs to fine-tune the sequence-delimiting ability of the model ensures it\noutperforms other similar-purpose complex systems like BiLSTM-CRF in the second\ntask. Our system achieves an F1 score of 85.00% in Task 1 and 83.90% in Task 2.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:19:18 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 17:35:42 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Akl", "Hanna Abi", ""], ["Mariko", "Dominique", ""], ["Labidurie", "Estelle", ""]]}, {"id": "2005.08520", "submitter": "Adrian Lancucki", "authors": "Adrian {\\L}a\\'ncucki, Jan Chorowski, Guillaume Sanchez, Ricard Marxer,\n  Nanxin Chen, Hans J.G.A. Dolfing, Sameer Khurana, Tanel Alum\\\"ae, Antoine\n  Laurent", "title": "Robust Training of Vector Quantized Bottleneck Models", "comments": "Published at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate methods for reliable and efficient training of\ndiscrete representation using Vector-Quantized Variational Auto-Encoder models\n(VQ-VAEs). Discrete latent variable models have been shown to learn nontrivial\nrepresentations of speech, applicable to unsupervised voice conversion and\nreaching state-of-the-art performance on unit discovery tasks. For unsupervised\nrepresentation learning, they became viable alternatives to continuous latent\nvariable models such as the Variational Auto-Encoder (VAE). However, training\ndeep discrete variable models is challenging, due to the inherent\nnon-differentiability of the discretization operation. In this paper we focus\non VQ-VAE, a state-of-the-art discrete bottleneck model shown to perform on par\nwith its continuous counterparts. It quantizes encoder outputs with on-line\n$k$-means clustering. We show that the codebook learning can suffer from poor\ninitialization and non-stationarity of clustered encoder outputs. We\ndemonstrate that these can be successfully overcome by increasing the learning\nrate for the codebook and periodic date-dependent codeword re-initialization.\nAs a result, we achieve more robust training across different tasks, and\nsignificantly increase the usage of latent codewords even for large codebooks.\nThis has practical benefit, for instance, in unsupervised representation\nlearning, where large codebooks may lead to disentanglement of latent\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:23:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["\u0141a\u0144cucki", "Adrian", ""], ["Chorowski", "Jan", ""], ["Sanchez", "Guillaume", ""], ["Marxer", "Ricard", ""], ["Chen", "Nanxin", ""], ["Dolfing", "Hans J. G. A.", ""], ["Khurana", "Sameer", ""], ["Alum\u00e4e", "Tanel", ""], ["Laurent", "Antoine", ""]]}, {"id": "2005.08531", "submitter": "Leonardo Cella", "authors": "Leonardo Cella, Alessandro Lazaric, Massimiliano Pontil", "title": "Meta-learning with Stochastic Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate meta-learning procedures in the setting of stochastic linear\nbandits tasks. The goal is to select a learning algorithm which works well on\naverage over a class of bandits tasks, that are sampled from a\ntask-distribution. Inspired by recent work on learning-to-learn linear\nregression, we consider a class of bandit algorithms that implement a\nregularized version of the well-known OFUL algorithm, where the regularization\nis a square euclidean distance to a bias vector. We first study the benefit of\nthe biased OFUL algorithm in terms of regret minimization. We then propose two\nstrategies to estimate the bias within the learning-to-learn setting. We show\nboth theoretically and experimentally, that when the number of tasks grows and\nthe variance of the task-distribution is small, our strategies have a\nsignificant advantage over learning the tasks in isolation.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:41:39 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cella", "Leonardo", ""], ["Lazaric", "Alessandro", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "2005.08543", "submitter": "Atalanti A. Mastakouri", "authors": "Atalanti A. Mastakouri, Bernhard Sch\\\"olkopf, Dominik Janzing", "title": "Necessary and sufficient conditions for causal feature selection in time\n  series with latent common causes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the identification of direct and indirect causes on time series and\nprovide conditions in the presence of latent variables, which we prove to be\nnecessary and sufficient under some graph constraints. Our theoretical results\nand estimation algorithms require two conditional independence tests for each\nobserved candidate time series to determine whether or not it is a cause of an\nobserved target time series. We provide experimental results in simulations, as\nwell as real data. Our results show that our method leads to very low false\npositives and relatively low false negative rates, outperforming the widely\nused Granger causality.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 09:14:34 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 16:57:47 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 08:16:30 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mastakouri", "Atalanti A.", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Janzing", "Dominik", ""]]}, {"id": "2005.08566", "submitter": "Xinchi Qiu", "authors": "Xinchi Qiu, Titouan Parcollet, Mirco Ravanelli, Nicholas Lane, Mohamed\n  Morchid", "title": "Quaternion Neural Networks for Multi-channel Distant Speech Recognition", "comments": "4 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.17061.52969", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant progress in automatic speech recognition (ASR),\ndistant ASR remains challenging due to noise and reverberation. A common\napproach to mitigate this issue consists of equipping the recording devices\nwith multiple microphones that capture the acoustic scene from different\nperspectives. These multi-channel audio recordings contain specific internal\nrelations between each signal. In this paper, we propose to capture these\ninter- and intra- structural dependencies with quaternion neural networks,\nwhich can jointly process multiple signals as whole quaternion entities. The\nquaternion algebra replaces the standard dot product with the Hamilton one,\nthus offering a simple and elegant way to model dependencies between elements.\nThe quaternion layers are then coupled with a recurrent neural network, which\ncan learn long-term dependencies in the time domain. We show that a quaternion\nlong-short term memory neural network (QLSTM), trained on the concatenated\nmulti-channel speech signals, outperforms equivalent real-valued LSTM on two\ndifferent tasks of multi-channel distant speech recognition.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 10:26:27 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 10:06:54 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Qiu", "Xinchi", ""], ["Parcollet", "Titouan", ""], ["Ravanelli", "Mirco", ""], ["Lane", "Nicholas", ""], ["Morchid", "Mohamed", ""]]}, {"id": "2005.08632", "submitter": "Sandesh Kamath K", "authors": "Sandesh Kamath, Amit Deshpande, K V Subrahmanyam", "title": "Universalization of any adversarial attack using very few test examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning models are known to be vulnerable not only to input-dependent\nadversarial attacks but also to input-agnostic or universal adversarial\nattacks. Dezfooli et al. \\cite{Dezfooli17,Dezfooli17anal} construct universal\nadversarial attack on a given model by looking at a large number of training\ndata points and the geometry of the decision boundary near them. Subsequent\nwork \\cite{Khrulkov18} constructs universal attack by looking only at test\nexamples and intermediate layers of the given model. In this paper, we propose\na simple universalization technique to take any input-dependent adversarial\nattack and construct a universal attack by only looking at very few adversarial\ntest examples. We do not require details of the given model and have negligible\ncomputational overhead for universalization. We theoretically justify our\nuniversalization technique by a spectral property common to many\ninput-dependent adversarial perturbations, e.g., gradients, Fast Gradient Sign\nMethod (FGSM) and DeepFool. Using matrix concentration inequalities and\nspectral perturbation bounds, we show that the top singular vector of\ninput-dependent adversarial directions on a small test sample gives an\neffective and simple universal adversarial attack. For VGG16 and VGG19 models\ntrained on ImageNet, our simple universalization of Gradient, FGSM, and\nDeepFool perturbations using a test sample of 64 images gives fooling rates\ncomparable to state-of-the-art universal attacks \\cite{Dezfooli17,Khrulkov18}\nfor reasonable norms of perturbation.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 12:17:38 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kamath", "Sandesh", ""], ["Deshpande", "Amit", ""], ["Subrahmanyam", "K V", ""]]}, {"id": "2005.08638", "submitter": "Moonseop Kim", "authors": "Moonseop Kim, Huayi Yin, Guang Lin", "title": "Multi-Fidelity Gaussian Process based Empirical Potential Development\n  for Si:H Nanowires", "comments": "7pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In material modeling, the calculation speed using the empirical potentials is\nfast compared to the first principle calculations, but the results are not as\naccurate as of the first principle calculations. First principle calculations\nare accurate but slow and very expensive to calculate. In this work, first, the\nH-H binding energy and H$_2$-H$_2$ interaction energy are calculated using the\nfirst principle calculations which can be applied to the Tersoff empirical\npotential. Second, the H-H parameters are estimated. After fitting H-H\nparameters, the mechanical properties are obtained. Finally, to integrate both\nthe low-fidelity empirical potential data and the data from the high-fidelity\nfirst-principle calculations, the multi-fidelity Gaussian process regression is\nemployed to predict the H-H binding energy and the H$_2$-H$_2$ interaction\nenergy. Numerical results demonstrate the accuracy of the developed empirical\npotentials.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 02:37:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kim", "Moonseop", ""], ["Yin", "Huayi", ""], ["Lin", "Guang", ""]]}, {"id": "2005.08640", "submitter": "Prashant Gupta", "authors": "Joydip Dhar, Ashaya Shukla, Mukul Kumar, Prashant Gupta", "title": "A Weighted Mutual k-Nearest Neighbour for Classification Mining", "comments": "5 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  kNN is a very effective Instance based learning method, and it is easy to\nimplement. Due to heterogeneous nature of data, noises from different possible\nsources are also widespread in nature especially in case of large-scale\ndatabases. For noise elimination and effect of pseudo neighbours, in this\npaper, we propose a new learning algorithm which performs the task of anomaly\ndetection and removal of pseudo neighbours from the dataset so as to provide\ncomparative better results. This algorithm also tries to minimize effect of\nthose neighbours which are distant. A concept of certainty measure is also\nintroduced for experimental results. The advantage of using concept of mutual\nneighbours and distance-weighted voting is that, dataset will be refined after\nremoval of anomaly and weightage concept compels to take into account more\nconsideration of those neighbours, which are closer. Consequently, finally the\nperformance of proposed algorithm is calculated.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 18:11:30 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Dhar", "Joydip", ""], ["Shukla", "Ashaya", ""], ["Kumar", "Mukul", ""], ["Gupta", "Prashant", ""]]}, {"id": "2005.08649", "submitter": "Chih-Fan Hsu", "authors": "Chih-Fan Hsu, Chia-Ching Lin, Ting-Yang Hung, Chin-Laung Lei and\n  Kuan-Ta Chen", "title": "A Detailed Look At CNN-based Approaches In Facial Landmark Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial landmark detection has been studied over decades. Numerous neural\nnetwork (NN)-based approaches have been proposed for detecting landmarks,\nespecially the convolutional neural network (CNN)-based approaches. In general,\nCNN-based approaches can be divided into regression and heatmap approaches.\nHowever, no research systematically studies the characteristics of different\napproaches. In this paper, we investigate both CNN-based approaches, generalize\ntheir advantages and disadvantages, and introduce a variation of the heatmap\napproach, a pixel-wise classification (PWC) model. To the best of our\nknowledge, using the PWC model to detect facial landmarks have not been\ncomprehensively studied. We further design a hybrid loss function and a\ndiscrimination network for strengthening the landmarks' interrelationship\nimplied in the PWC model to improve the detection accuracy without modifying\nthe original model architecture. Six common facial landmark datasets, AFW,\nHelen, LFPW, 300-W, IBUG, and COFW are adopted to train or evaluate our model.\nA comprehensive evaluation is conducted and the result shows that the proposed\nmodel outperforms other models in all tested datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:17:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Hsu", "Chih-Fan", ""], ["Lin", "Chia-Ching", ""], ["Hung", "Ting-Yang", ""], ["Lei", "Chin-Laung", ""], ["Chen", "Kuan-Ta", ""]]}, {"id": "2005.08665", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Ruyi Ding, Minghe Zhang, Pascal Van Hentenryck, Yao Xie", "title": "Spatio-Temporal Point Processes with Attention for Traffic Congestion\n  Event Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for modeling traffic congestion events over road\nnetworks. Using multi-modal data by combining count data from traffic sensors\nwith police reports that report traffic incidents, we aim to capture two types\nof triggering effect for congestion events. Current traffic congestion at one\nlocation may cause future congestion over the road network, and traffic\nincidents may cause spread traffic congestion. To model the non-homogeneous\ntemporal dependence of the event on the past, we use a novel attention-based\nmechanism based on neural networks embedding for point processes. To\nincorporate the directional spatial dependence induced by the road network, we\nadapt the \"tail-up\" model from the context of spatial statistics to the traffic\nnetwork setting. We demonstrate our approach's superior performance compared to\nthe state-of-the-art methods for both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 04:22:18 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 19:54:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zhu", "Shixiang", ""], ["Ding", "Ruyi", ""], ["Zhang", "Minghe", ""], ["Van Hentenryck", "Pascal", ""], ["Xie", "Yao", ""]]}, {"id": "2005.08672", "submitter": "Puoya Tabaghi", "authors": "Puoya Tabaghi, Ivan Dokmani\\'c", "title": "Hyperbolic Distance Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperbolic space is a natural setting for mining and visualizing data with\nhierarchical structure. In order to compute a hyperbolic embedding from\ncomparison or similarity information, one has to solve a hyperbolic distance\ngeometry problem. In this paper, we propose a unified framework to compute\nhyperbolic embeddings from an arbitrary mix of noisy metric and non-metric\ndata. Our algorithms are based on semidefinite programming and the notion of a\nhyperbolic distance matrix, in many ways parallel to its famous Euclidean\ncounterpart. A central ingredient we put forward is a semidefinite\ncharacterization of the hyperbolic Gramian -- a matrix of Lorentzian inner\nproducts. This characterization allows us to formulate a semidefinite\nrelaxation to efficiently compute hyperbolic embeddings in two stages: first,\nwe complete and denoise the observed hyperbolic distance matrix; second, we\npropose a spectral factorization method to estimate the embedded points from\nthe hyperbolic distance matrix. We show through numerical experiments how the\nflexibility to mix metric and non-metric constraints allows us to efficiently\ncompute embeddings from arbitrary data.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 12:59:49 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 17:02:32 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Tabaghi", "Puoya", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "2005.08679", "submitter": "Emiliano De Cristofaro", "authors": "Emiliano De Cristofaro", "title": "An Overview of Privacy in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, providers such as Google, Microsoft, and Amazon have\nstarted to provide customers with access to software interfaces allowing them\nto easily embed machine learning tasks into their applications. Overall,\norganizations can now use Machine Learning as a Service (MLaaS) engines to\noutsource complex tasks, e.g., training classifiers, performing predictions,\nclustering, etc. They can also let others query models trained on their data.\nNaturally, this approach can also be used (and is often advocated) in other\ncontexts, including government collaborations, citizen science projects, and\nbusiness-to-business partnerships. However, if malicious users were able to\nrecover data used to train these models, the resulting information leakage\nwould create serious issues. Likewise, if the inner parameters of the model are\nconsidered proprietary information, then access to the model should not allow\nan adversary to learn such parameters. In this document, we set to review\nprivacy challenges in this space, providing a systematic review of the relevant\nresearch literature, also exploring possible countermeasures. More\nspecifically, we provide ample background information on relevant concepts\naround machine learning and privacy. Then, we discuss possible adversarial\nmodels and settings, cover a wide range of attacks that relate to private\nand/or sensitive information leakage, and review recent results attempting to\ndefend against such attacks. Finally, we conclude with a list of open problems\nthat require more work, including the need for better evaluations, more\ntargeted defenses, and the study of the relation to policy and data protection\nefforts.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:05:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["De Cristofaro", "Emiliano", ""]]}, {"id": "2005.08689", "submitter": "Abdolrahman Peimankar Dr", "authors": "Abdolrahman Peimankar and Sadasivan Puthusserypady", "title": "DENS-ECG: A Deep Learning Approach for ECG Signal Delineation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: With the technological advancements in the field of tele-health\nmonitoring, it is now possible to gather huge amounts of electro-physiological\nsignals such as electrocardiogram (ECG). It is therefore necessary to develop\nmodels/algorithms that are capable of analysing these massive amounts of data\nin real-time. This paper proposes a deep learning model for real-time\nsegmentation of heartbeats. Methods: The proposed algorithm, named as the\nDENS-ECG algorithm, combines convolutional neural network (CNN) and long\nshort-term memory (LSTM) model to detect onset, peak, and offset of different\nheartbeat waveforms such as the P-wave, QRS complex, T-wave, and No wave (NW).\nUsing ECG as the inputs, the model learns to extract high level features\nthrough the training process, which, unlike other classical machine learning\nbased methods, eliminates the feature engineering step. Results: The proposed\nDENS-ECG model was trained and validated on a dataset with 105 ECGs of length\n15 minutes each and achieved an average sensitivity and precision of 97.95% and\n95.68%, respectively, using a 5-fold cross validation. Additionally, the model\nwas evaluated on an unseen dataset to examine its robustness in QRS detection,\nwhich resulted in a sensitivity of 99.61% and precision of 99.52%. Conclusion:\nThe empirical results show the flexibility and accuracy of the combined\nCNN-LSTM model for ECG signal delineation. Significance: This paper proposes an\nefficient and easy to use approach using deep learning for heartbeat\nsegmentation, which could potentially be used in real-time tele-health\nmonitoring systems.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:13:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Peimankar", "Abdolrahman", ""], ["Puthusserypady", "Sadasivan", ""]]}, {"id": "2005.08697", "submitter": "Xuetong Wu", "authors": "Xuetong Wu, Jonathan H. Manton, Uwe Aickelin, Jingge Zhu", "title": "Information-theoretic analysis for transfer learning", "comments": "Accepted paper in 2020 IEEE International Symposium on Information\n  Theory (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning, or domain adaptation, is concerned with machine learning\nproblems in which training and testing data come from possibly different\ndistributions (denoted as $\\mu$ and $\\mu'$, respectively). In this work, we\ngive an information-theoretic analysis on the generalization error and the\nexcess risk of transfer learning algorithms, following a line of work initiated\nby Russo and Zhou. Our results suggest, perhaps as expected, that the\nKullback-Leibler (KL) divergence $D(mu||mu')$ plays an important role in\ncharacterizing the generalization error in the settings of domain adaptation.\nSpecifically, we provide generalization error upper bounds for general transfer\nlearning algorithms and extend the results to a specific empirical risk\nminimization (ERM) algorithm where data from both distributions are available\nin the training phase. We further apply the method to iterative, noisy gradient\ndescent algorithms, and obtain upper bounds which can be easily calculated,\nonly using parameters from the learning algorithms. A few illustrative examples\nare provided to demonstrate the usefulness of the results. In particular, our\nbound is tighter in specific classification problems than the bound derived\nusing Rademacher complexity.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:23:20 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 00:57:09 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wu", "Xuetong", ""], ["Manton", "Jonathan H.", ""], ["Aickelin", "Uwe", ""], ["Zhu", "Jingge", ""]]}, {"id": "2005.08701", "submitter": "Taegeun Song", "authors": "Woo Seok Lee, Junghyo Jo, and Taegeun Song", "title": "Machine learning for the diagnosis of early stage diabetes using\n  temporal glucose profiles", "comments": "4 pages, 2 figure", "journal-ref": null, "doi": "10.1007/s40042-021-00056-8", "report-no": null, "categories": "q-bio.QM cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning shows remarkable success for recognizing patterns in data.\nHere we apply the machine learning (ML) for the diagnosis of early stage\ndiabetes, which is known as a challenging task in medicine. Blood glucose\nlevels are tightly regulated by two counter-regulatory hormones, insulin and\nglucagon, and the failure of the glucose homeostasis leads to the common\nmetabolic disease, diabetes mellitus. It is a chronic disease that has a long\nlatent period the complicates detection of the disease at an early stage. The\nvast majority of diabetics result from that diminished effectiveness of insulin\naction. The insulin resistance must modify the temporal profile of blood\nglucose. Thus we propose to use ML to detect the subtle change in the temporal\npattern of glucose concentration. Time series data of blood glucose with\nsufficient resolution is currently unavailable, so we confirm the proposal\nusing synthetic data of glucose profiles produced by a biophysical model that\nconsiders the glucose regulation and hormone action. Multi-layered perceptrons,\nconvolutional neural networks, and recurrent neural networks all identified the\ndegree of insulin resistance with high accuracy above $85\\%$.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:31:12 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Lee", "Woo Seok", ""], ["Jo", "Junghyo", ""], ["Song", "Taegeun", ""]]}, {"id": "2005.08704", "submitter": "Weipeng Cao", "authors": "Zhongwu Xie, Weipeng Cao, Xizhao Wang, Zhong Ming, Jingjing Zhang,\n  Jiyong Zhang", "title": "A Biologically Inspired Feature Enhancement Framework for Zero-Shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the Zero-Shot Learning (ZSL) algorithms currently use pre-trained\nmodels as their feature extractors, which are usually trained on the ImageNet\ndata set by using deep neural networks. The richness of the feature information\nembedded in the pre-trained models can help the ZSL model extract more useful\nfeatures from its limited training samples. However, sometimes the difference\nbetween the training data set of the current ZSL task and the ImageNet data set\nis too large, which may lead to the use of pre-trained models has no obvious\nhelp or even negative impact on the performance of the ZSL model. To solve this\nproblem, this paper proposes a biologically inspired feature enhancement\nframework for ZSL. Specifically, we design a dual-channel learning framework\nthat uses auxiliary data sets to enhance the feature extractor of the ZSL model\nand propose a novel method to guide the selection of the auxiliary data sets\nbased on the knowledge of biological taxonomy. Extensive experimental results\nshow that our proposed method can effectively improve the generalization\nability of the ZSL model and achieve state-of-the-art results on three\nbenchmark ZSL tasks. We also explained the experimental phenomena through the\nway of feature visualization.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:25:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Xie", "Zhongwu", ""], ["Cao", "Weipeng", ""], ["Wang", "Xizhao", ""], ["Ming", "Zhong", ""], ["Zhang", "Jingjing", ""], ["Zhang", "Jiyong", ""]]}, {"id": "2005.08722", "submitter": "Maurice Gerczuk", "authors": "Shahin Amiriparian, Pawel Winokurow, Vincent Karas, Sandra Ottl,\n  Maurice Gerczuk, Bj\\\"orn W. Schuller", "title": "A Novel Fusion of Attention and Sequence to Sequence Autoencoders to\n  Predict Sleepiness From Speech", "comments": "5 pages, 2 figures, submitted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the attention mechanism of the human visual system and recent\ndevelopments in the field of machine translation, we introduce our\nattention-based and recurrent sequence to sequence autoencoders for fully\nunsupervised representation learning from audio files. In particular, we test\nthe efficacy of our novel approach on the task of speech-based sleepiness\nrecognition. We evaluate the learnt representations from both autoencoders, and\nthen conduct an early fusion to ascertain possible complementarity between\nthem. In our frameworks, we first extract Mel-spectrograms from raw audio\nfiles. Second, we train recurrent autoencoders on these spectrograms which are\nconsidered as time-dependent frequency vectors. Afterwards, we extract the\nactivations of specific fully connected layers of the autoencoders which\nrepresent the learnt features of spectrograms for the corresponding audio\ninstances. Finally, we train support vector regressors on these representations\nto obtain the predictions. On the development partition of the data, we achieve\nSpearman's correlation coefficients of .324, .283, and .320 with the targets on\nthe Karolinska Sleepiness Scale by utilising attention and non-attention\nautoencoders, and the fusion of both autoencoders' representations,\nrespectively. In the same order, we achieve .311, .359, and .367 Spearman's\ncorrelation coefficients on the test data, indicating the suitability of our\nproposed fusion strategy.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 12:02:52 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 16:30:41 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Amiriparian", "Shahin", ""], ["Winokurow", "Pawel", ""], ["Karas", "Vincent", ""], ["Ottl", "Sandra", ""], ["Gerczuk", "Maurice", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2005.08741", "submitter": "Samuel Rudy", "authors": "Samuel H. Rudy and Themistoklis P. Sapsis", "title": "Sparse Methods for Automatic Relevance Determination", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2021.132843", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers methods for imposing sparsity in Bayesian regression with\napplications in nonlinear system identification. We first review automatic\nrelevance determination (ARD) and analytically demonstrate the need to\nadditional regularization or thresholding to achieve sparse models. We then\ndiscuss two classes of methods, regularization based and thresholding based,\nwhich build on ARD to learn parsimonious solutions to linear problems. In the\ncase of orthogonal covariates, we analytically demonstrate favorable\nperformance with regards to learning a small set of active terms in a linear\nsystem with a sparse solution. Several example problems are presented to\ncompare the set of proposed methods in terms of advantages and limitations to\nARD in bases with hundreds of elements. The aim of this paper is to analyze and\nunderstand the assumptions that lead to several algorithms and to provide\ntheoretical and empirical results so that the reader may gain insight and make\nmore informed choices regarding sparse Bayesian regression.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:08:49 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rudy", "Samuel H.", ""], ["Sapsis", "Themistoklis P.", ""]]}, {"id": "2005.08748", "submitter": "Peter Gr\\\"onquist", "authors": "Peter Gr\\\"onquist, Chengyuan Yao, Tal Ben-Nun, Nikoli Dryden, Peter\n  Dueben, Shigang Li, Torsten Hoefler", "title": "Deep Learning for Post-Processing Ensemble Weather Forecasts", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2020.0092", "report-no": null, "categories": "cs.LG eess.SP physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying uncertainty in weather forecasts is critical, especially for\npredicting extreme weather events. This is typically accomplished with ensemble\nprediction systems, which consist of many perturbed numerical weather\nsimulations, or trajectories, run in parallel. These systems are associated\nwith a high computational cost and often involve statistical post-processing\nsteps to inexpensively improve their raw prediction qualities. We propose a\nmixed model that uses only a subset of the original weather trajectories\ncombined with a post-processing step using deep neural networks. These enable\nthe model to account for non-linear relationships that are not captured by\ncurrent numerical models or post-processing methods. Applied to global data,\nour mixed models achieve a relative improvement in ensemble forecast skill\n(CRPS) of over 14%. Furthermore, we demonstrate that the improvement is larger\nfor extreme weather events on select case studies. We also show that our\npost-processing can use fewer trajectories to achieve comparable results to the\nfull ensemble. By using fewer trajectories, the computational costs of an\nensemble prediction system can be reduced, allowing it to run at higher\nresolution and produce more accurate forecasts.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:23:26 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 11:08:47 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Gr\u00f6nquist", "Peter", ""], ["Yao", "Chengyuan", ""], ["Ben-Nun", "Tal", ""], ["Dryden", "Nikoli", ""], ["Dueben", "Peter", ""], ["Li", "Shigang", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2005.08844", "submitter": "Donghoon Lee", "authors": "Donghoon Lee", "title": "Entropy-Augmented Entropy-Regularized Reinforcement Learning and a\n  Continuous Path from Policy Gradient to Q-Learning", "comments": "16 pages, 1 figure. refined a few expressions, proofs. added source\n  code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy augmented to reward is known to soften the greedy argmax policy to\nsoftmax policy. Entropy augmentation is reformulated and leads to a motivation\nto introduce an additional entropy term to the objective function in the form\nof KL-divergence to regularize optimization process. It results in a policy\nwhich monotonically improves while interpolating from the current policy to the\nsoftmax greedy policy. This policy is used to build a continuously\nparameterized algorithm which optimize policy and Q-function simultaneously and\nwhose extreme limits correspond to policy gradient and Q-learning,\nrespectively. Experiments show that there can be a performance gain using an\nintermediate algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:15:44 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 17:21:40 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Lee", "Donghoon", ""]]}, {"id": "2005.08854", "submitter": "Waheed Bajwa", "authors": "Matthew Nokleby, Haroon Raja, and Waheed U. Bajwa", "title": "Scaling-up Distributed Processing of Data Streams for Machine Learning", "comments": "45 pages, 9 figures; preprint of a journal paper published in\n  Proceedings of the IEEE (Special Issue on Optimization for Data-driven\n  Learning and Control)", "journal-ref": "Proc. of the IEEE, vol. 108, no. 11, pp. 1984-2012, Nov. 2020", "doi": "10.1109/JPROC.2020.3021381", "report-no": null, "categories": "cs.LG cs.DC eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging applications of machine learning in numerous areas involve\ncontinuous gathering of and learning from streams of data. Real-time\nincorporation of streaming data into the learned models is essential for\nimproved inference in these applications. Further, these applications often\ninvolve data that are either inherently gathered at geographically distributed\nentities or that are intentionally distributed across multiple machines for\nmemory, computational, and/or privacy reasons. Training of models in this\ndistributed, streaming setting requires solving stochastic optimization\nproblems in a collaborative manner over communication links between the\nphysical entities. When the streaming data rate is high compared to the\nprocessing capabilities of compute nodes and/or the rate of the communications\nlinks, this poses a challenging question: how can one best leverage the\nincoming data for distributed training under constraints on computing\ncapabilities and/or communications rate? A large body of research has emerged\nin recent decades to tackle this and related problems. This paper reviews\nrecently developed methods that focus on large-scale distributed stochastic\noptimization in the compute- and bandwidth-limited regime, with an emphasis on\nconvergence analysis that explicitly accounts for the mismatch between\ncomputation, communication and streaming rates. In particular, it focuses on\nmethods that solve: (i) distributed stochastic convex problems, and (ii)\ndistributed principal component analysis, which is a nonconvex problem with\ngeometric structure that permits global convergence. For such methods, the\npaper discusses recent advances in terms of distributed algorithmic designs\nwhen faced with high-rate streaming data. Further, it reviews guarantees\nunderlying these methods, which show there exist regimes in which systems can\nlearn from distributed, streaming data at order-optimal rates.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:28:54 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 23:48:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Nokleby", "Matthew", ""], ["Raja", "Haroon", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "2005.08859", "submitter": "Khashayar Filom", "authors": "Khashayar Filom, Konrad Paul Kording, Roozbeh Farhoodi", "title": "PDE constraints on smooth hierarchical functions computed by neural\n  networks", "comments": "52 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are versatile tools for computation, having the ability to\napproximate a broad range of functions. An important problem in the theory of\ndeep neural networks is expressivity; that is, we want to understand the\nfunctions that are computable by a given network. We study real infinitely\ndifferentiable (smooth) hierarchical functions implemented by feedforward\nneural networks via composing simpler functions in two cases:\n  1) each constituent function of the composition has fewer inputs than the\nresulting function;\n  2) constituent functions are in the more specific yet prevalent form of a\nnon-linear univariate function (e.g. tanh) applied to a linear multivariate\nfunction.\n  We establish that in each of these regimes there exist non-trivial algebraic\npartial differential equations (PDEs), which are satisfied by the computed\nfunctions. These PDEs are purely in terms of the partial derivatives and are\ndependent only on the topology of the network. For compositions of polynomial\nfunctions, the algebraic PDEs yield non-trivial equations (of degrees dependent\nonly on the architecture) in the ambient polynomial space that are satisfied on\nthe associated functional varieties. Conversely, we conjecture that such PDE\nconstraints, once accompanied by appropriate non-singularity conditions and\nperhaps certain inequalities involving partial derivatives, guarantee that the\nsmooth function under consideration can be represented by the network. The\nconjecture is verified in numerous examples including the case of tree\narchitectures which are of neuroscientific interest. Our approach is a step\ntoward formulating an algebraic description of functional spaces associated\nwith specific neural networks, and may provide new, useful tools for\nconstructing neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:34:11 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Filom", "Khashayar", ""], ["Kording", "Konrad Paul", ""], ["Farhoodi", "Roozbeh", ""]]}, {"id": "2005.08874", "submitter": "Tobias Huber", "authors": "Tobias Huber, Katharina Weitz, Elisabeth Andr\\'e, Ofra Amir", "title": "Local and Global Explanations of Agent Behavior: Integrating Strategy\n  Summaries with Saliency Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With advances in reinforcement learning (RL), agents are now being developed\nin high-stakes application domains such as healthcare and transportation.\nExplaining the behavior of these agents is challenging, as the environments in\nwhich they act have large state spaces, and their decision-making can be\naffected by delayed rewards, making it difficult to analyze their behavior. To\naddress this problem, several approaches have been developed. Some approaches\nattempt to convey the $\\textit{global}$ behavior of the agent, describing the\nactions it takes in different states. Other approaches devised $\\textit{local}$\nexplanations which provide information regarding the agent's decision-making in\na particular state. In this paper, we combine global and local explanation\nmethods, and evaluate their joint and separate contributions, providing (to the\nbest of our knowledge) the first user study of combined local and global\nexplanations for RL agents. Specifically, we augment strategy summaries that\nextract important trajectories of states from simulations of the agent with\nsaliency maps which show what information the agent attends to. Our results\nshow that the choice of what states to include in the summary (global\ninformation) strongly affects people's understanding of agents: participants\nshown summaries that included important states significantly outperformed\nparticipants who were presented with agent behavior in a randomly set of chosen\nworld-states. We find mixed results with respect to augmenting demonstrations\nwith saliency maps (local information), as the addition of saliency maps did\nnot significantly improve performance in most cases. However, we do find some\nevidence that saliency maps can help users better understand what information\nthe agent relies on in its decision making, suggesting avenues for future work\nthat can further improve explanations of RL agents.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:44:55 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 17:34:10 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 17:54:59 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Huber", "Tobias", ""], ["Weitz", "Katharina", ""], ["Andr\u00e9", "Elisabeth", ""], ["Amir", "Ofra", ""]]}, {"id": "2005.08898", "submitter": "Tian Tong", "authors": "Tian Tong, Cong Ma, Yuejie Chi", "title": "Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled\n  Gradient Descent", "comments": "Accepted to Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix estimation is a canonical problem that finds numerous\napplications in signal processing, machine learning and imaging science. A\npopular approach in practice is to factorize the matrix into two compact\nlow-rank factors, and then optimize these factors directly via simple iterative\nmethods such as gradient descent and alternating minimization. Despite\nnonconvexity, recent literatures have shown that these simple heuristics in\nfact achieve linear convergence when initialized properly for a growing number\nof problems of interest. However, upon closer examination, existing approaches\ncan still be computationally expensive especially for ill-conditioned matrices:\nthe convergence rate of gradient descent depends linearly on the condition\nnumber of the low-rank matrix, while the per-iteration cost of alternating\nminimization is often prohibitive for large matrices. The goal of this paper is\nto set forth a competitive algorithmic approach dubbed Scaled Gradient Descent\n(ScaledGD) which can be viewed as pre-conditioned or diagonally-scaled gradient\ndescent, where the pre-conditioners are adaptive and iteration-varying with a\nminimal computational overhead. With tailored variants for low-rank matrix\nsensing, robust principal component analysis and matrix completion, we\ntheoretically show that ScaledGD achieves the best of both worlds: it converges\nlinearly at a rate independent of the condition number of the low-rank matrix\nsimilar as alternating minimization, while maintaining the low per-iteration\ncost of gradient descent. Our analysis is also applicable to general loss\nfunctions that are restricted strongly convex and smooth over low-rank\nmatrices. To the best of our knowledge, ScaledGD is the first algorithm that\nprovably has such properties over a wide range of low-rank matrix estimation\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:17:16 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 03:13:06 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 18:20:43 GMT"}, {"version": "v4", "created": "Mon, 14 Jun 2021 20:11:50 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Tong", "Tian", ""], ["Ma", "Cong", ""], ["Chi", "Yuejie", ""]]}, {"id": "2005.08926", "submitter": "Patrick Kidger", "authors": "Patrick Kidger, James Morrill, James Foster, Terry Lyons", "title": "Neural Controlled Differential Equations for Irregular Time Series", "comments": "Accepted at NeurIPS 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural ordinary differential equations are an attractive option for modelling\ntemporal dynamics. However, a fundamental issue is that the solution to an\nordinary differential equation is determined by its initial condition, and\nthere is no mechanism for adjusting the trajectory based on subsequent\nobservations. Here, we demonstrate how this may be resolved through the\nwell-understood mathematics of \\emph{controlled differential equations}. The\nresulting \\emph{neural controlled differential equation} model is directly\napplicable to the general setting of partially-observed irregularly-sampled\nmultivariate time series, and (unlike previous work on this problem) it may\nutilise memory-efficient adjoint-based backpropagation even across\nobservations. We demonstrate that our model achieves state-of-the-art\nperformance against similar (ODE or RNN based) models in empirical studies on a\nrange of datasets. Finally we provide theoretical results demonstrating\nuniversal approximation, and that our model subsumes alternative ODE models.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:52:21 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 17:45:39 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kidger", "Patrick", ""], ["Morrill", "James", ""], ["Foster", "James", ""], ["Lyons", "Terry", ""]]}, {"id": "2005.08948", "submitter": "Nuri Mert Vural", "authors": "N. Mert Vural, Fatih Ilhan, Selim F. Yilmaz, Salih Erg\\\"ut and\n  Suleyman S. Kozat", "title": "Achieving Online Regression Performance of LSTMs with Simple RNNs", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.03601", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are widely used for online regression due to\ntheir ability to generalize nonlinear temporal dependencies. As an RNN model,\nLong-Short-Term-Memory Networks (LSTMs) are commonly preferred in practice, as\nthese networks are capable of learning long-term dependencies while avoiding\nthe vanishing gradient problem. However, due to their large number of\nparameters, training LSTMs requires considerably longer training time compared\nto simple RNNs (SRNNs). In this paper, we achieve the online regression\nperformance of LSTMs with SRNNs efficiently. To this end, we introduce a\nfirst-order training algorithm with a linear time complexity in the number of\nparameters. We show that when SRNNs are trained with our algorithm, they\nprovide very similar regression performance with the LSTMs in two to three\ntimes shorter training time. We provide strong theoretical analysis to support\nour experimental results by providing regret bounds on the convergence rate of\nour algorithm. Through an extensive set of experiments, we verify our\ntheoretical work and demonstrate significant performance improvements of our\nalgorithm with respect to LSTMs and the other state-of-the-art learning models.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 11:41:13 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:22:57 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vural", "N. Mert", ""], ["Ilhan", "Fatih", ""], ["Yilmaz", "Selim F.", ""], ["Erg\u00fct", "Salih", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2005.08968", "submitter": "Fengqi You", "authors": "Abdulelah S. Alshehri, Rafiqul Gani, Fengqi You", "title": "Deep Learning and Knowledge-Based Methods for Computer Aided Molecular\n  Design -- Toward a Unified Approach: State-of-the-Art and Future Directions", "comments": null, "journal-ref": "Computers and Chemical Engineering 141 (2020) 107005", "doi": "10.1016/j.compchemeng.2020.107005", "report-no": null, "categories": "q-bio.BM cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal design of compounds through manipulating properties at the\nmolecular level is often the key to considerable scientific advances and\nimproved process systems performance. This paper highlights key trends,\nchallenges, and opportunities underpinning the Computer-Aided Molecular Design\n(CAMD) problems. A brief review of knowledge-driven property estimation methods\nand solution techniques, as well as corresponding CAMD tools and applications,\nare first presented. In view of the computational challenges plaguing\nknowledge-based methods and techniques, we survey the current state-of-the-art\napplications of deep learning to molecular design as a fertile approach towards\novercoming computational limitations and navigating uncharted territories of\nthe chemical space. The main focus of the survey is given to deep generative\nmodeling of molecules under various deep learning architectures and different\nmolecular representations. Further, the importance of benchmarking and\nempirical rigor in building deep learning models is spotlighted. The review\narticle also presents a detailed discussion of the current perspectives and\nchallenges of knowledge-based and data-driven CAMD and identifies key areas for\nfuture research directions. Special emphasis is on the fertile avenue of hybrid\nmodeling paradigm, in which deep learning approaches are exploited while\nleveraging the accumulated wealth of knowledge-driven CAMD methods and tools.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:17:51 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 15:00:54 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Alshehri", "Abdulelah S.", ""], ["Gani", "Rafiqul", ""], ["You", "Fengqi", ""]]}, {"id": "2005.09020", "submitter": "Anthony Constantinou", "authors": "Anthony C. Constantinou, Yang Liu, Kiattikun Chobtham, Zhigao Guo and\n  Neville K. Kitson", "title": "Large-scale empirical validation of Bayesian Network structure learning\n  algorithms with noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous Bayesian Network (BN) structure learning algorithms have been\nproposed in the literature over the past few decades. Each publication makes an\nempirical or theoretical case for the algorithm proposed in that publication\nand results across studies are often inconsistent in their claims about which\nalgorithm is 'best'. This is partly because there is no agreed evaluation\napproach to determine their effectiveness. Moreover, each algorithm is based on\na set of assumptions, such as complete data and causal sufficiency, and tend to\nbe evaluated with data that conforms to these assumptions, however unrealistic\nthese assumptions may be in the real world. As a result, it is widely accepted\nthat synthetic performance overestimates real performance, although to what\ndegree this may happen remains unknown. This paper investigates the performance\nof 15 structure learning algorithms. We propose a methodology that applies the\nalgorithms to data that incorporates synthetic noise, in an effort to better\nunderstand the performance of structure learning algorithms when applied to\nreal data. Each algorithm is tested over multiple case studies, sample sizes,\ntypes of noise, and assessed with multiple evaluation criteria. This work\ninvolved approximately 10,000 graphs with a total structure learning runtime of\nseven months. It provides the first large-scale empirical validation of BN\nstructure learning algorithms under different assumptions of data noise. The\nresults suggest that traditional synthetic performance may overestimate\nreal-world performance by anywhere between 10% and more than 50%. They also\nshow that while score-based learning is generally superior to constraint-based\nlearning, a higher fitting score does not necessarily imply a more accurate\ncausal graph. To facilitate comparisons with future studies, we have made all\ndata, raw results, graphs and BN models freely available online.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:40:09 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:12:00 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Constantinou", "Anthony C.", ""], ["Liu", "Yang", ""], ["Chobtham", "Kiattikun", ""], ["Guo", "Zhigao", ""], ["Kitson", "Neville K.", ""]]}, {"id": "2005.09021", "submitter": "Tal Amir", "authors": "Tal Amir, Ronen Basri, Boaz Nadler", "title": "The Trimmed Lasso: Sparse Recovery Guarantees and Practical Optimization\n  by the Generalized Soft-Min Penalty", "comments": "49 pages; 7 figures; To appear in SIAM Journal on Mathematics of Data\n  Science (SIMODS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to solve the sparse approximation or best subset\nselection problem, namely find a $k$-sparse vector ${\\bf x}\\in\\mathbb{R}^d$\nthat minimizes the $\\ell_2$ residual $\\lVert A{\\bf x}-{\\bf y} \\rVert_2$. We\nconsider a regularized approach, whereby this residual is penalized by the\nnon-convex $\\textit{trimmed lasso}$, defined as the $\\ell_1$-norm of ${\\bf x}$\nexcluding its $k$ largest-magnitude entries. We prove that the trimmed lasso\nhas several appealing theoretical properties, and in particular derive sparse\nrecovery guarantees assuming successful optimization of the penalized\nobjective. Next, we show empirically that directly optimizing this objective\ncan be quite challenging. Instead, we propose a surrogate for the trimmed\nlasso, called the $\\textit{generalized soft-min}$. This penalty smoothly\ninterpolates between the classical lasso and the trimmed lasso, while taking\ninto account all possible $k$-sparse patterns. The generalized soft-min penalty\ninvolves summation over $\\binom{d}{k}$ terms, yet we derive a polynomial-time\nalgorithm to compute it. This, in turn, yields a practical method for the\noriginal sparse approximation problem. Via simulations, we demonstrate its\ncompetitive performance compared to current state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:43:06 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 21:50:13 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 21:44:57 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Amir", "Tal", ""], ["Basri", "Ronen", ""], ["Nadler", "Boaz", ""]]}, {"id": "2005.09030", "submitter": "Shahaf Finder", "authors": "Shahaf E. Finder, Eran Treister, Oren Freifeld", "title": "Effective Learning of a GMRF Mixture Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a Gaussian Mixture Model (GMM) is hard when the number of parameters\nis too large given the amount of available data. As a remedy, we propose\nrestricting the GMM to a Gaussian Markov Random Field Mixture Model (GMRF-MM),\nas well as a new method for estimating the latter's sparse precision (i.e.,\ninverse covariance) matrices. When the sparsity pattern of each matrix is\nknown, we propose an efficient optimization method for the Maximum Likelihood\nEstimate (MLE) of that matrix. When it is unknown, we utilize the popular\nGraphical LASSO (GLASSO) to estimate that pattern. However, we show that even\nfor a single Gaussian, when GLASSO is tuned to successfully estimate the\nsparsity pattern, it does so at the price of a substantial bias of the values\nof the nonzero entries of the matrix, and we show that this problem only\nworsens in a mixture setting. To overcome this, we discard the non-zero values\nestimated by GLASSO, keep only its pattern estimate and use it within the\nproposed MLE method. This yields an effective two-step procedure that removes\nthe bias. We show that our \"debiasing\" approach outperforms GLASSO in both the\nsingle-GMRF and the GMRF-MM cases. We also show that when learning priors for\nimage patches, our method outperforms GLASSO even if we merely use an educated\nguess about the sparsity pattern, and that our GMRF-MM outperforms the baseline\nGMM on real and synthetic high-dimensional datasets. Our code is available at\n\\url{https://github.com/shahaffind/GMRF-MM}.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:00:14 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 07:59:19 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Finder", "Shahaf E.", ""], ["Treister", "Eran", ""], ["Freifeld", "Oren", ""]]}, {"id": "2005.09043", "submitter": "Naz Gul Ms", "authors": "Naz Gul, Nosheen Faiz, Dan Brawn, Rafal Kulakowski, Zardad Khan and\n  Berthold Lausen", "title": "Optimal survival trees ensemble", "comments": "The paper is 24 pages long with 27 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have adopted an approach of selecting accurate and diverse\ntrees based on individual or collective performance within an ensemble for\nclassification and regression problems. This work follows in the wake of these\ninvestigations and considers the possibility of growing a forest of optimal\nsurvival trees. Initially, a large set of survival trees are grown using the\nmethod of random survival forest. The grown trees are then ranked from smallest\nto highest value of their prediction error using out-of-bag observations for\neach respective survival tree. The top ranked survival trees are then assessed\nfor their collective performance as an ensemble. This ensemble is initiated\nwith the survival tree which stands first in rank, then further trees are\ntested one by one by adding them to the ensemble in order of rank. A survival\ntree is selected for the resultant ensemble if the performance improves after\nan assessment using independent training data. This ensemble is called an\noptimal trees ensemble (OSTE). The proposed method is assessed using 17\nbenchmark datasets and the results are compared with those of random survival\nforest, conditional inference forest, bagging and a non tree based method, the\nCox proportional hazard model. In addition to improve predictive performance,\nthe proposed method reduces the number of survival trees in the ensemble as\ncompared to the other tree based methods. The method is implemented in an R\npackage called \"OSTE\".\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:28:16 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Gul", "Naz", ""], ["Faiz", "Nosheen", ""], ["Brawn", "Dan", ""], ["Kulakowski", "Rafal", ""], ["Khan", "Zardad", ""], ["Lausen", "Berthold", ""]]}, {"id": "2005.09047", "submitter": "Saeed Saremi", "authors": "Saeed Saremi", "title": "Learning and Inference in Imaginary Noise Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent developments in learning smoothed densities with empirical\nBayes, we study variational autoencoders with a decoder that is tailored for\nthe random variable $Y=X+N(0,\\sigma^2 I_d)$. A notion of smoothed variational\ninference emerges where the smoothing is implicitly enforced by the noise model\nof the decoder; \"implicit\", since during training the encoder only sees clean\nsamples. This is the concept of imaginary noise model, where the noise model\ndictates the functional form of the variational lower bound\n$\\mathcal{L}(\\sigma)$, but the noisy data are never seen during learning. The\nmodel is named $\\sigma$-VAE. We prove that all $\\sigma$-VAEs are equivalent to\neach other via a simple $\\beta$-VAE expansion: $\\mathcal{L}(\\sigma_2) \\equiv\n\\mathcal{L}(\\sigma_1,\\beta)$, where $\\beta=\\sigma_2^2/\\sigma_1^2$. We prove a\nsimilar result for the Laplace distribution in exponential families.\nEmpirically, we report an intriguing power law $\\mathcal{D}_{\\rm KL} \\sim\n\\sigma^{-\\nu}$ for the learned models and we study the inference in the\n$\\sigma$-VAE for unseen noisy data. The experiments were performed on MNIST,\nwhere we show that quite remarkably the model can make reasonable inferences on\nextremely noisy samples even though it has not seen any during training. The\nvanilla VAE completely breaks down in this regime. We finish with a hypothesis\n(the XYZ hypothesis) on the findings here.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:38:51 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 11:00:19 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 20:05:03 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Saremi", "Saeed", ""]]}, {"id": "2005.09048", "submitter": "Luis Scoccola", "authors": "Alexander Rolle, Luis Scoccola", "title": "Stable and consistent density-based clustering", "comments": "32 pages, 7 figures. v2: improves exposition, adds computational\n  examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multiscale, consistent approach to density-based clustering that\nsatisfies stability theorems -- in both the input data and in the parameters --\nwhich hold without distributional assumptions. The stability in the input data\nis with respect to the Gromov--Hausdorff--Prokhorov distance on metric\nprobability spaces and interleaving distances between (multi-parameter)\nhierarchical clusterings we introduce. We prove stability results for standard\nsimplification procedures for hierarchical clusterings, which can be combined\nwith our approach to yield a stable flat clustering algorithm. We illustrate\nthe stability of the approach with computational examples. Our framework is\nbased on the concepts of persistence and interleaving distance from Topological\nData Analysis.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:45:04 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 17:38:01 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Rolle", "Alexander", ""], ["Scoccola", "Luis", ""]]}, {"id": "2005.09052", "submitter": "Padraig Cunningham", "authors": "Padraig Cunningham, Sarah Jane Delany", "title": "Underestimation Bias and Underfitting in Machine Learning", "comments": "12 pages, 7 figures, 3 tables", "journal-ref": "In: Heintz F., Milano M., O'Sullivan B. (eds) Trustworthy AI -\n  Integrating Learning, Optimization and Reasoning. TAILOR 2020. Lecture Notes\n  in Computer Science, vol 12641. Springer, Cham", "doi": "10.1007/978-3-030-73959-1_2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, what is termed algorithmic bias in machine learning will be due to\nhistoric bias in the training data. But sometimes the bias may be introduced\n(or at least exacerbated) by the algorithm itself. The ways in which algorithms\ncan actually accentuate bias has not received a lot of attention with\nresearchers focusing directly on methods to eliminate bias - no matter the\nsource. In this paper we report on initial research to understand the factors\nthat contribute to bias in classification algorithms. We believe this is\nimportant because underestimation bias is inextricably tied to regularization,\ni.e. measures to address overfitting can accentuate bias.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 20:01:56 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 11:53:07 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 09:41:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Cunningham", "Padraig", ""], ["Delany", "Sarah Jane", ""]]}, {"id": "2005.09065", "submitter": "Shane Barratt", "authors": "Shane Barratt, Guillermo Angeris, Stephen Boyd", "title": "Optimal Representative Sample Weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of assigning weights to a set of samples or data\nrecords, with the goal of achieving a representative weighting, which happens\nwhen certain sample averages of the data are close to prescribed values. We\nframe the problem of finding representative sample weights as an optimization\nproblem, which in many cases is convex and can be efficiently solved. Our\nformulation includes as a special case the selection of a fixed number of the\nsamples, with equal weights, i.e., the problem of selecting a smaller\nrepresentative subset of the samples. While this problem is combinatorial and\nnot convex, heuristic methods based on convex optimization seem to perform very\nwell. We describe rsw, an open-source implementation of the ideas described in\nthis paper, and apply it to a skewed sample of the CDC BRFSS dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 20:29:00 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Barratt", "Shane", ""], ["Angeris", "Guillermo", ""], ["Boyd", "Stephen", ""]]}, {"id": "2005.09136", "submitter": "R\\'emi Le Priol", "authors": "R\\'emi Le Priol, Reza Babanezhad Harikandeh, Yoshua Bengio and Simon\n  Lacoste-Julien", "title": "An Analysis of the Adaptation Speed of Causal Models", "comments": "Published at AISTATS 2021. 10 pages main articles, 19 pages\n  supplement, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a collection of datasets generated by unknown interventions on an\nunknown structural causal model $G$. Recently, Bengio et al. (2020) conjectured\nthat among all candidate models, $G$ is the fastest to adapt from one dataset\nto another, along with promising experiments. Indeed, intuitively $G$ has less\nmechanisms to adapt, but this justification is incomplete. Our contribution is\na more thorough analysis of this hypothesis. We investigate the adaptation\nspeed of cause-effect SCMs. Using convergence rates from stochastic\noptimization, we justify that a relevant proxy for adaptation speed is distance\nin parameter space after intervention. Applying this proxy to categorical and\nnormal cause-effect models, we show two results. When the intervention is on\nthe cause variable, the SCM with the correct causal direction is advantaged by\na large factor. When the intervention is on the effect variable, we\ncharacterize the relative adaptation speed. Surprisingly, we find situations\nwhere the anticausal model is advantaged, falsifying the initial hypothesis.\nCode to reproduce experiments is available at\nhttps://github.com/remilepriol/causal-adaptation-speed\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 23:48:56 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 11:48:05 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Priol", "R\u00e9mi Le", ""], ["Harikandeh", "Reza Babanezhad", ""], ["Bengio", "Yoshua", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2005.09148", "submitter": "Rong Ou", "authors": "Rong Ou", "title": "Out-of-Core GPU Gradient Boosting", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPU-based algorithms have greatly accelerated many machine learning methods;\nhowever, GPU memory is typically smaller than main memory, limiting the size of\ntraining data. In this paper, we describe an out-of-core GPU gradient boosting\nalgorithm implemented in the XGBoost library. We show that much larger datasets\ncan fit on a given GPU, without degrading model accuracy or training time. To\nthe best of our knowledge, this is the first out-of-core GPU implementation of\ngradient boosting. Similar approaches can be applied to other machine learning\nalgorithms\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 00:41:00 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ou", "Rong", ""]]}, {"id": "2005.09159", "submitter": "Hangyu Lin", "authors": "Hangyu Lin, Yanwei Fu, Yu-Gang Jiang, Xiangyang Xue", "title": "Sketch-BERT: Learning Sketch Bidirectional Encoder Representation from\n  Transformers by Self-supervised Learning of Sketch Gestalt", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous researches of sketches often considered sketches in pixel format and\nleveraged CNN based models in the sketch understanding. Fundamentally, a sketch\nis stored as a sequence of data points, a vector format representation, rather\nthan the photo-realistic image of pixels. SketchRNN studied a generative neural\nrepresentation for sketches of vector format by Long Short Term Memory networks\n(LSTM). Unfortunately, the representation learned by SketchRNN is primarily for\nthe generation tasks, rather than the other tasks of recognition and retrieval\nof sketches. To this end and inspired by the recent BERT model, we present a\nmodel of learning Sketch Bidirectional Encoder Representation from Transformer\n(Sketch-BERT). We generalize BERT to sketch domain, with the novel proposed\ncomponents and pre-training algorithms, including the newly designed sketch\nembedding networks, and the self-supervised learning of sketch gestalt.\nParticularly, towards the pre-training task, we present a novel Sketch Gestalt\nModel (SGM) to help train the Sketch-BERT. Experimentally, we show that the\nlearned representation of Sketch-BERT can help and improve the performance of\nthe downstream tasks of sketch recognition, sketch retrieval, and sketch\ngestalt.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 01:35:44 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lin", "Hangyu", ""], ["Fu", "Yanwei", ""], ["Jiang", "Yu-Gang", ""], ["Xue", "Xiangyang", ""]]}, {"id": "2005.09162", "submitter": "Shahabeddin Sotudian", "authors": "Mohammad Hossein Fazel Zarandi, Shahabeddin Sotudian, Oscar Castillo", "title": "A New Validity Index for Fuzzy-Possibilistic C-Means Clustering", "comments": "The following article has been accepted by Scientia Iranica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some complicated datasets, due to the presence of noisy data points and\noutliers, cluster validity indices can give conflicting results in determining\nthe optimal number of clusters. This paper presents a new validity index for\nfuzzy-possibilistic c-means clustering called Fuzzy-Possibilistic (FP) index,\nwhich works well in the presence of clusters that vary in shape and density.\nMoreover, FPCM like most of the clustering algorithms is susceptible to some\ninitial parameters. In this regard, in addition to the number of clusters, FPCM\nrequires a priori selection of the degree of fuzziness and the degree of\ntypicality. Therefore, we presented an efficient procedure for determining\ntheir optimal values. The proposed approach has been evaluated using several\nsynthetic and real-world datasets. Final computational results demonstrate the\ncapabilities and reliability of the proposed approach compared with several\nwell-known fuzzy validity indices in the literature. Furthermore, to clarify\nthe ability of the proposed method in real applications, the proposed method is\nimplemented in microarray gene expression data clustering and medical image\nsegmentation.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 01:48:13 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zarandi", "Mohammad Hossein Fazel", ""], ["Sotudian", "Shahabeddin", ""], ["Castillo", "Oscar", ""]]}, {"id": "2005.09170", "submitter": "Jeffrey Z. Pan", "authors": "Jeffrey Z. Pan, Nicholas Zufelt", "title": "On Intrinsic Dataset Properties for Adversarial Machine Learning", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have played a key role in a wide range of machine\nlearning applications. However, DNN classifiers are vulnerable to\nhuman-imperceptible adversarial perturbations, which can cause them to\nmisclassify inputs with high confidence. Thus, creating robust DNNs which can\ndefend against malicious examples is critical in applications where security\nplays a major role. In this paper, we study the effect of intrinsic dataset\nproperties on the performance of adversarial attack and defense methods,\ntesting on five popular image classification datasets - MNIST, Fashion-MNIST,\nCIFAR10/CIFAR100, and ImageNet. We find that input size and image contrast play\nkey roles in attack and defense success. Our discoveries highlight that dataset\ndesign and data preprocessing steps are important to boost the adversarial\nrobustness of DNNs. To our best knowledge, this is the first comprehensive work\nthat studies the effect of intrinsic dataset properties on adversarial machine\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 02:24:14 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Pan", "Jeffrey Z.", ""], ["Zufelt", "Nicholas", ""]]}, {"id": "2005.09194", "submitter": "Baocheng Zhu", "authors": "Shijun Wang, Baocheng Zhu, Lintao Ma, Yuan Qi", "title": "A Riemannian Primal-dual Algorithm Based on Proximal Operator and its\n  Application in Metric Learning", "comments": "8 pages, 2 figures, published as a conference paper in 2019\n  International Joint Conference on Neural Networks (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852367", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we consider optimizing a smooth, convex, lower semicontinuous\nfunction in Riemannian space with constraints. To solve the problem, we first\nconvert it to a dual problem and then propose a general primal-dual algorithm\nto optimize the primal and dual variables iteratively. In each optimization\niteration, we employ a proximal operator to search optimal solution in the\nprimal space. We prove convergence of the proposed algorithm and show its\nnon-asymptotic convergence rate. By utilizing the proposed primal-dual\noptimization technique, we propose a novel metric learning algorithm which\nlearns an optimal feature transformation matrix in the Riemannian space of\npositive definite matrices. Preliminary experimental results on an optimal fund\nselection problem in fund of funds (FOF) management for quantitative investment\nshowed its efficacy.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:31:01 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wang", "Shijun", ""], ["Zhu", "Baocheng", ""], ["Ma", "Lintao", ""], ["Qi", "Yuan", ""]]}, {"id": "2005.09195", "submitter": "Baocheng Zhu", "authors": "Shijun Wang, Baocheng Zhu, Chen Li, Mingzhe Wu, James Zhang, Wei Chu,\n  Yuan Qi", "title": "Riemannian Proximal Policy Optimization", "comments": "12 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, We propose a general Riemannian proximal optimization\nalgorithm with guaranteed convergence to solve Markov decision process (MDP)\nproblems. To model policy functions in MDP, we employ Gaussian mixture model\n(GMM) and formulate it as a nonconvex optimization problem in the Riemannian\nspace of positive semidefinite matrices. For two given policy functions, we\nalso provide its lower bound on policy improvement by using bounds derived from\nthe Wasserstein distance of GMMs. Preliminary experiments show the efficacy of\nour proposed Riemannian proximal policy optimization algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:37:59 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wang", "Shijun", ""], ["Zhu", "Baocheng", ""], ["Li", "Chen", ""], ["Wu", "Mingzhe", ""], ["Zhang", "James", ""], ["Chu", "Wei", ""], ["Qi", "Yuan", ""]]}, {"id": "2005.09198", "submitter": "Ozgur Ozmen", "authors": "James Nutaro and Ozgur Ozmen", "title": "Quantifying the Uncertainty of Precision Estimates for Rule based Text\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule based classifiers that use the presence and absence of key sub-strings\nto make classification decisions have a natural mechanism for quantifying the\nuncertainty of their precision. For a binary classifier, the key insight is to\ntreat partitions of the sub-string set induced by the documents as Bernoulli\nrandom variables. The mean value of each random variable is an estimate of the\nclassifier's precision when presented with a document inducing that partition.\nThese means can be compared, using standard statistical tests, to a desired or\nexpected classifier precision. A set of binary classifiers can be combined into\na single, multi-label classifier by an application of the Dempster-Shafer\ntheory of evidence. The utility of this approach is demonstrated with a\nbenchmark problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:51:47 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Nutaro", "James", ""], ["Ozmen", "Ozgur", ""]]}, {"id": "2005.09209", "submitter": "Bashir Rastegarpanah", "authors": "Bashir Rastegarpanah (1), Mark Crovella (1), Krishna P. Gummadi (2)\n  ((1) Boston University, (2) MPI-SWS)", "title": "Fair Inputs and Fair Outputs: The Incompatibility of Fairness in Privacy\n  and Accuracy", "comments": null, "journal-ref": null, "doi": "10.1145/3386392.3399568", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness concerns about algorithmic decision-making systems have been mainly\nfocused on the outputs (e.g., the accuracy of a classifier across individuals\nor groups). However, one may additionally be concerned with fairness in the\ninputs. In this paper, we propose and formulate two properties regarding the\ninputs of (features used by) a classifier. In particular, we claim that fair\nprivacy (whether individuals are all asked to reveal the same information) and\nneed-to-know (whether users are only asked for the minimal information required\nfor the task at hand) are desirable properties of a decision system. We explore\nthe interaction between these properties and fairness in the outputs (fair\nprediction accuracy). We show that for an optimal classifier these three\nproperties are in general incompatible, and we explain what common properties\nof data make them incompatible. Finally we provide an algorithm to verify if\nthe trade-off between the three properties exists in a given dataset, and use\nthe algorithm to show that this trade-off is common in real data.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 04:32:16 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 23:48:21 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 22:08:23 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Rastegarpanah", "Bashir", "", "Boston University"], ["Crovella", "Mark", "", "Boston University"], ["Gummadi", "Krishna P.", "", "MPI-SWS"]]}, {"id": "2005.09218", "submitter": "Jia-Fong Yeh", "authors": "Jia-Fong Yeh and Hsin-Ying Lee and Bing-Chen Tsai and Yi-Rong Chen and\n  Ping-Chia Huang and Winston H. Hsu", "title": "Large Margin Mechanism and Pseudo Query Set on Cross-Domain Few-Shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, few-shot learning problems have received a lot of attention.\nWhile methods in most previous works were trained and tested on datasets in one\nsingle domain, cross-domain few-shot learning is a brand-new branch of few-shot\nlearning problems, where models handle datasets in different domains between\ntraining and testing phases. In this paper, to solve the problem that the model\nis pre-trained (meta-trained) on a single dataset while fine-tuned on datasets\nin four different domains, including common objects, satellite images, and\nmedical images, we propose a novel large margin fine-tuning method (LMM-PQS),\nwhich generates pseudo query images from support images and fine-tunes the\nfeature extraction modules with a large margin mechanism inspired by methods in\nface recognition. According to the experiment results, LMM-PQS surpasses the\nbaseline models by a significant margin and demonstrates that our approach is\nrobust and can easily adapt pre-trained models to new domains with few data.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:28:35 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Yeh", "Jia-Fong", ""], ["Lee", "Hsin-Ying", ""], ["Tsai", "Bing-Chen", ""], ["Chen", "Yi-Rong", ""], ["Huang", "Ping-Chia", ""], ["Hsu", "Winston H.", ""]]}, {"id": "2005.09220", "submitter": "Pierre-Alexandre Kamienny Mr", "authors": "Pierre-Alexandre Kamienny, Kai Arulkumaran, Feryal Behbahani, Wendelin\n  Boehmer, Shimon Whiteson", "title": "Privileged Information Dropout in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using privileged information during training can improve the sample\nefficiency and performance of machine learning systems. This paradigm has been\napplied to reinforcement learning (RL), primarily in the form of distillation\nor auxiliary tasks, and less commonly in the form of augmenting the inputs of\nagents. In this work, we investigate Privileged Information Dropout (\\pid) for\nachieving the latter which can be applied equally to value-based and\npolicy-based RL algorithms. Within a simple partially-observed environment, we\ndemonstrate that \\pid outperforms alternatives for leveraging privileged\ninformation, including distillation and auxiliary tasks, and can successfully\nutilise different types of privileged information. Finally, we analyse its\neffect on the learned representations.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:32:33 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kamienny", "Pierre-Alexandre", ""], ["Arulkumaran", "Kai", ""], ["Behbahani", "Feryal", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2005.09229", "submitter": "Chong Peng", "authors": "Chong Peng, Zhilu Zhang, Zhao Kang, Chenglizhao Chen, Qiang Cheng", "title": "Two-Dimensional Semi-Nonnegative Matrix Factorization for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new Semi-Nonnegative Matrix Factorization method\nfor 2-dimensional (2D) data, named TS-NMF. It overcomes the drawback of\nexisting methods that seriously damage the spatial information of the data by\nconverting 2D data to vectors in a preprocessing step. In particular,\nprojection matrices are sought under the guidance of building new data\nrepresentations, such that the spatial information is retained and projections\nare enhanced by the goal of clustering, which helps construct optimal\nprojection directions. Moreover, to exploit nonlinear structures of the data,\nmanifold is constructed in the projected subspace, which is adaptively updated\naccording to the projections and less afflicted with noise and outliers of the\ndata and thus more representative in the projected space. Hence, seeking\nprojections, building new data representations, and learning manifold are\nseamlessly integrated in a single model, which mutually enhance other and lead\nto a powerful data representation. Comprehensive experimental results verify\nthe effectiveness of TS-NMF in comparison with several state-of-the-art\nalgorithms, which suggests high potential of the proposed method for real world\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:54:14 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Peng", "Chong", ""], ["Zhang", "Zhilu", ""], ["Kang", "Zhao", ""], ["Chen", "Chenglizhao", ""], ["Cheng", "Qiang", ""]]}, {"id": "2005.09235", "submitter": "Guanyang Wang", "authors": "Guanyang Wang", "title": "On the Theoretical Properties of the Exchange Algorithm", "comments": "33 pages, 2 figures, typos fixed, include more examples, add\n  literature review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exchange algorithm is one of the most popular extensions of\nMetropolis-Hastings algorithm to sample from doubly-intractable distributions.\nHowever, theoretical exploration of exchange algorithm is very limited. For\nexample, natural questions like `Does exchange algorithm converge at a\ngeometric rate?' or `Does the exchange algorithm admit a Central Limit\nTheorem?' have not been answered. In this paper, we study the theoretical\nproperties of exchange algorithm, in terms of asymptotic variance and\nconvergence speed. We compare the exchange algorithm with the original\nMetropolis-Hastings algorithm and provide both necessary and sufficient\nconditions for geometric ergodicity of the exchange algorithm, which can be\napplied to various practical applications such as exponential random graph\nmodels and Ising models. A central limit theorem for the exchange algorithm is\nalso established. Meanwhile, a concrete example, involving the Binomial model\nwith conjugate and non-conjugate priors, is treated in detail with sharp\nconvergence rates. Our results justify the theoretical usefulness of the\nexchange algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:16:43 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 22:15:34 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 02:39:41 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Wang", "Guanyang", ""]]}, {"id": "2005.09246", "submitter": "Rajeev Bhatt Ambati", "authors": "Rajeev Bhatt Ambati, Ahmed Ada Hanifi, Ramya Vunikili, Puneet Sharma,\n  and Oladimeji Farri", "title": "Assertion Detection in Multi-Label Clinical Text using Scope\n  Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label sentences (text) in the clinical domain result from the rich\ndescription of scenarios during patient care. The state-of-theart methods for\nassertion detection mostly address this task in the setting of a single\nassertion label per sentence (text). In addition, few rules based and deep\nlearning methods perform negation/assertion scope detection on single-label\ntext. It is a significant challenge extending these methods to address\nmulti-label sentences without diminishing performance. Therefore, we developed\na convolutional neural network (CNN) architecture to localize multiple labels\nand their scopes in a single stage end-to-end fashion, and demonstrate that our\nmodel performs atleast 12% better than the state-of-the-art on multi-label\nclinical text.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:56:02 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ambati", "Rajeev Bhatt", ""], ["Hanifi", "Ahmed Ada", ""], ["Vunikili", "Ramya", ""], ["Sharma", "Puneet", ""], ["Farri", "Oladimeji", ""]]}, {"id": "2005.09261", "submitter": "Davoud Ataee Tarzanagh", "authors": "Parvin Nazari, Davoud Ataee Tarzanagh, George Michailidis", "title": "Adaptive First-and Zeroth-order Methods for Weakly Convex Stochastic\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design and analyze a new family of adaptive subgradient\nmethods for solving an important class of weakly convex (possibly nonsmooth)\nstochastic optimization problems. Adaptive methods that use exponential moving\naverages of past gradients to update search directions and learning rates have\nrecently attracted a lot of attention for solving optimization problems that\narise in machine learning. Nevertheless, their convergence analysis almost\nexclusively requires smoothness and/or convexity of the objective function. In\ncontrast, we establish non-asymptotic rates of convergence of first and\nzeroth-order adaptive methods and their proximal variants for a reasonably\nbroad class of nonsmooth \\& nonconvex optimization problems. Experimental\nresults indicate how the proposed algorithms empirically outperform stochastic\ngradient descent and its zeroth-order variant for solving such optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 07:44:52 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 15:14:43 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Nazari", "Parvin", ""], ["Tarzanagh", "Davoud Ataee", ""], ["Michailidis", "George", ""]]}, {"id": "2005.09282", "submitter": "Bolaji Yusuf", "authors": "Bolaji Yusuf and Lucas Ondel", "title": "Bayesian Subspace HMM for the Zerospeech 2020 Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe our submission to the Zerospeech 2020 challenge,\nwhere the participants are required to discover latent representations from\nunannotated speech, and to use those representations to perform speech\nsynthesis, with synthesis quality used as a proxy metric for the unit quality.\nIn our system, we use the Bayesian Subspace Hidden Markov Model (SHMM) for unit\ndiscovery. The SHMM models each unit as an HMM whose parameters are constrained\nto lie in a low dimensional subspace of the total parameter space which is\ntrained to model phonetic variability. Our system compares favorably with the\nbaseline on the human-evaluated character error rate while maintaining\nsignificantly lower unit bitrate.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:28:38 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:24:11 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yusuf", "Bolaji", ""], ["Ondel", "Lucas", ""]]}, {"id": "2005.09284", "submitter": "William Caicedo-Torres", "authors": "William Caicedo-Torres, Jairo Gutierrez", "title": "ISeeU2: Visually Interpretable ICU mortality prediction using deep\n  learning and free-text medical notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Accurate mortality prediction allows Intensive Care Units (ICUs) to\nadequately benchmark clinical practice and identify patients with unexpected\noutcomes. Traditionally, simple statistical models have been used to assess\npatient death risk, many times with sub-optimal performance. On the other hand\ndeep learning holds promise to positively impact clinical practice by\nleveraging medical data to assist diagnosis and prediction, including mortality\nprediction. However, as the question of whether powerful Deep Learning models\nattend correlations backed by sound medical knowledge when generating\npredictions remains open, additional interpretability tools are needed to\nfoster trust and encourage the use of AI by clinicians. In this work we show a\nDeep Learning model trained on MIMIC-III to predict mortality using raw nursing\nnotes, together with visual explanations for word importance. Our model reaches\na ROC of 0.8629 (+/-0.0058), outperforming the traditional SAPS-II score and\nproviding enhanced interpretability when compared with similar Deep Learning\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:30:34 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Caicedo-Torres", "William", ""], ["Gutierrez", "Jairo", ""]]}, {"id": "2005.09294", "submitter": "Martin Kotuliak", "authors": "Martin Kotuliak, Sandro E. Schoenborn, Andrei Dan", "title": "Synthesizing Unrestricted False Positive Adversarial Objects Using\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are data points misclassified by neural networks.\nOriginally, adversarial examples were limited to adding small perturbations to\na given image. Recent work introduced the generalized concept of unrestricted\nadversarial examples, without limits on the added perturbations. In this paper,\nwe introduce a new category of attacks that create unrestricted adversarial\nexamples for object detection. Our key idea is to generate adversarial objects\nthat are unrelated to the classes identified by the target object detector.\nDifferent from previous attacks, we use off-the-shelf Generative Adversarial\nNetworks (GAN), without requiring any further training or modification. Our\nmethod consists of searching over the latent normal space of the GAN for\nadversarial objects that are wrongly identified by the target object detector.\nWe evaluate this method on the commonly used Faster R-CNN ResNet-101, Inception\nv2 and SSD Mobilenet v1 object detectors using logo generative iWGAN-LC and\nSNGAN trained on CIFAR-10. The empirical results show that the generated\nadversarial objects are indistinguishable from non-adversarial objects\ngenerated by the GANs, transferable between the object detectors and robust in\nthe physical world. This is the first work to study unrestricted false positive\nadversarial examples for object detection.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:58:58 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kotuliak", "Martin", ""], ["Schoenborn", "Sandro E.", ""], ["Dan", "Andrei", ""]]}, {"id": "2005.09301", "submitter": "Mark van de Wiel", "authors": "Mark A. van de Wiel, Mirrelijn M. van Nee, Armin Rauschenberger", "title": "Fast cross-validation for multi-penalty ridge regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional prediction with multiple data types needs to account for\npotentially strong differences in predictive signal. Ridge regression is a\nsimple model for high-dimensional data that has challenged the predictive\nperformance of many more complex models and learners, and that allows inclusion\nof data type specific penalties. The largest challenge for multi-penalty ridge\nis to optimize these penalties efficiently in a cross-validation (CV) setting,\nin particular for GLM and Cox ridge regression, which require an additional\nestimation loop by iterative weighted least squares (IWLS). Our main\ncontribution is a computationally very efficient formula for the multi-penalty,\nsample-weighted hat-matrix, as used in the IWLS algorithm. As a result, nearly\nall computations are in low-dimensional space, rendering a speed-up of several\norders of magnitude. We developed a flexible framework that facilitates\nmultiple types of response, unpenalized covariates, several performance\ncriteria and repeated CV. Extensions to paired and preferential data types are\nincluded and illustrated on several cancer genomics survival prediction\nproblems. Moreover, we present similar computational shortcuts for maximum\nmarginal likelihood and Bayesian probit regression. The corresponding\nR-package, multiridge, serves as a versatile standalone tool, but also as a\nfast benchmark for other more complex models and multi-view learners.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:13:43 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 07:52:28 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["van de Wiel", "Mark A.", ""], ["van Nee", "Mirrelijn M.", ""], ["Rauschenberger", "Armin", ""]]}, {"id": "2005.09310", "submitter": "Yan Gao", "authors": "Yan Gao, Titouan Parcollet, Nicholas Lane", "title": "Distilling Knowledge from Ensembles of Acoustic Models for Joint\n  CTC-Attention End-to-End Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation has been widely used to compress existing deep\nlearning models while preserving the performance on a wide range of\napplications. In the specific context of Automatic Speech Recognition (ASR),\ndistillation from ensembles of acoustic models has recently shown promising\nresults in increasing recognition performance. In this paper, we propose an\nextension of multi-teacher distillation methods to joint CTC-attention\nend-to-end ASR systems. We also introduce three novel distillation strategies.\nThe core intuition behind them is to integrate the error rate metric to the\nteacher selection rather than solely focusing on the observed losses. In this\nway, we directly distill and optimize the student toward the relevant metric\nfor speech recognition. We evaluate these strategies under a selection of\ntraining procedures on different datasets (TIMIT, Librispeech, Common Voice)\nand various languages (English, French, Italian). In particular,\nstate-of-the-art error rates are reported on the Common Voice French, Italian\nand TIMIT datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:24:54 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 04:17:07 GMT"}, {"version": "v3", "created": "Sun, 4 Jul 2021 02:15:21 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gao", "Yan", ""], ["Parcollet", "Titouan", ""], ["Lane", "Nicholas", ""]]}, {"id": "2005.09319", "submitter": "Albert Zeyer", "authors": "Albert Zeyer, Andr\\'e Merboldt, Ralf Schl\\\"uter, Hermann Ney", "title": "A New Training Pipeline for an Improved Neural Transducer", "comments": "published at Interspeech 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1855", "report-no": null, "categories": "eess.AS cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RNN transducer is a promising end-to-end model candidate. We compare the\noriginal training criterion with the full marginalization over all alignments,\nto the commonly used maximum approximation, which simplifies, improves and\nspeeds up our training. We also generalize from the original neural network\nmodel and study more powerful models, made possible due to the maximum\napproximation. We further generalize the output label topology to cover RNN-T,\nRNA and CTC. We perform several studies among all these aspects, including a\nstudy on the effect of external alignments. We find that the transducer model\ngeneralizes much better on longer sequences than the attention model. Our final\ntransducer model outperforms our attention model on Switchboard 300h by over 6%\nrelative WER.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:35:38 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 22:13:01 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zeyer", "Albert", ""], ["Merboldt", "Andr\u00e9", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.09343", "submitter": "Hong-Bin Liu", "authors": "Hong-Bin Liu, Ickjai Lee", "title": "Bridging the Gap Between Training and Inference for Spatio-Temporal\n  Forecasting", "comments": "ECAI 2020 Accepted, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal sequence forecasting is one of the fundamental tasks in\nspatio-temporal data mining. It facilitates many real world applications such\nas precipitation nowcasting, citywide crowd flow prediction and air pollution\nforecasting. Recently, a few Seq2Seq based approaches have been proposed, but\none of the drawbacks of Seq2Seq models is that, small errors can accumulate\nquickly along the generated sequence at the inference stage due to the\ndifferent distributions of training and inference phase. That is because\nSeq2Seq models minimise single step errors only during training, however the\nentire sequence has to be generated during the inference phase which generates\na discrepancy between training and inference. In this work, we propose a novel\ncurriculum learning based strategy named Temporal Progressive Growing Sampling\nto effectively bridge the gap between training and inference for\nspatio-temporal sequence forecasting, by transforming the training process from\na fully-supervised manner which utilises all available previous ground-truth\nvalues to a less-supervised manner which replaces some of the ground-truth\ncontext with generated predictions. To do that we sample the target sequence\nfrom midway outputs from intermediate models trained with bigger timescales\nthrough a carefully designed decaying strategy. Experimental results\ndemonstrate that our proposed method better models long term dependencies and\noutperforms baseline approaches on two competitive datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 10:14:43 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Hong-Bin", ""], ["Lee", "Ickjai", ""]]}, {"id": "2005.09347", "submitter": "Yukuo Cen", "authors": "Yukuo Cen, Jianwei Zhang, Xu Zou, Chang Zhou, Hongxia Yang, Jie Tang", "title": "Controllable Multi-Interest Framework for Recommendation", "comments": "Accepted to KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks have been widely used in e-commerce recommender\nsystems, owing to the rapid development of deep learning. We formalize the\nrecommender system as a sequential recommendation problem, intending to predict\nthe next items that the user might be interacted with. Recent works usually\ngive an overall embedding from a user's behavior sequence. However, a unified\nuser embedding cannot reflect the user's multiple interests during a period. In\nthis paper, we propose a novel controllable multi-interest framework for the\nsequential recommendation, called ComiRec. Our multi-interest module captures\nmultiple interests from user behavior sequences, which can be exploited for\nretrieving candidate items from the large-scale item pool. These items are then\nfed into an aggregation module to obtain the overall recommendation. The\naggregation module leverages a controllable factor to balance the\nrecommendation accuracy and diversity. We conduct experiments for the\nsequential recommendation on two real-world datasets, Amazon and Taobao.\nExperimental results demonstrate that our framework achieves significant\nimprovements over state-of-the-art models. Our framework has also been\nsuccessfully deployed on the offline Alibaba distributed cloud platform.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 10:18:43 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 02:16:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Cen", "Yukuo", ""], ["Zhang", "Jianwei", ""], ["Zou", "Xu", ""], ["Zhou", "Chang", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "2005.09363", "submitter": "Chizhou Liu", "authors": "Chizhou Liu, Yunzhen Feng, Ranran Wang, Bin Dong", "title": "Enhancing Certified Robustness via Smoothed Weighted Ensembling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing has achieved state-of-the-art certified robustness\nagainst $l_2$-norm adversarial attacks. However, it is not wholly resolved on\nhow to find the optimal base classifier for randomized smoothing. In this work,\nwe employ a Smoothed WEighted ENsembling (SWEEN) scheme to improve the\nperformance of randomized smoothed classifiers. We show the ensembling\ngenerality that SWEEN can help achieve optimal certified robustness.\nFurthermore, theoretical analysis proves that the optimal SWEEN model can be\nobtained from training under mild assumptions. We also develop an adaptive\nprediction algorithm to reduce the prediction and certification cost of SWEEN\nmodels. Extensive experiments show that SWEEN models outperform the upper\nenvelope of their corresponding candidate models by a large margin. Moreover,\nSWEEN models constructed using a few small models can achieve comparable\nperformance to a single large model with a notable reduction in training time.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 11:13:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 06:56:51 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 14:03:58 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Liu", "Chizhou", ""], ["Feng", "Yunzhen", ""], ["Wang", "Ranran", ""], ["Dong", "Bin", ""]]}, {"id": "2005.09428", "submitter": "Ding Liu", "authors": "Ding Liu, Zekun Yao, Quan Zhang", "title": "Quantum-Classical Machine learning by Hybrid Tensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor networks (TN) have found a wide use in machine learning, and in\nparticular, TN and deep learning bear striking similarities. In this work, we\npropose the quantum-classical hybrid tensor networks (HTN) which combine tensor\nnetworks with classical neural networks in a uniform deep learning framework to\novercome the limitations of regular tensor networks in machine learning. We\nfirst analyze the limitations of regular tensor networks in the applications of\nmachine learning involving the representation power and architecture\nscalability. We conclude that in fact the regular tensor networks are not\ncompetent to be the basic building blocks of deep learning. Then, we discuss\nthe performance of HTN which overcome all the deficiency of regular tensor\nnetworks for machine learning. In this sense, we are able to train HTN in the\ndeep learning way which is the standard combination of algorithms such as Back\nPropagation and Stochastic Gradient Descent. We finally provide two applicable\ncases to show the potential applications of HTN, including quantum states\nclassification and quantum-classical autoencoder. These cases also demonstrate\nthe great potentiality to design various HTN in deep learning way.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:20:35 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Ding", ""], ["Yao", "Zekun", ""], ["Zhang", "Quan", ""]]}, {"id": "2005.09463", "submitter": "Pramit Saha", "authors": "Pramit Saha, Sidney Fels", "title": "Learning Joint Articulatory-Acoustic Representations with Normalizing\n  Flows", "comments": "5 pages, 4 figures, accepted for publication in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The articulatory geometric configurations of the vocal tract and the acoustic\nproperties of the resultant speech sound are considered to have a strong causal\nrelationship. This paper aims at finding a joint latent representation between\nthe articulatory and acoustic domain for vowel sounds via invertible neural\nnetwork models, while simultaneously preserving the respective domain-specific\nfeatures. Our model utilizes a convolutional autoencoder architecture and\nnormalizing flow-based models to allow both forward and inverse mappings in a\nsemi-supervised manner, between the mid-sagittal vocal tract geometry of a two\ndegrees-of-freedom articulatory synthesizer with 1D acoustic wave model and the\nMel-spectrogram representation of the synthesized speech sounds. Our approach\nachieves satisfactory performance in achieving both articulatory-to-acoustic as\nwell as acoustic-to-articulatory mapping, thereby demonstrating our success in\nachieving a joint encoding of both the domains.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:34:36 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 03:54:41 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Saha", "Pramit", ""], ["Fels", "Sidney", ""]]}, {"id": "2005.09485", "submitter": "Run-Qing Chen", "authors": "Wan-Lei Zhao, Run-Qing Chen, Hui Ye and Chong-Wah Ngo", "title": "k-sums: another side of k-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the decades-old clustering method k-means is revisited. The\noriginal distortion minimization model of k-means is addressed by a pure\nstochastic minimization procedure. In each step of the iteration, one sample is\ntentatively reallocated from one cluster to another. It is moved to another\ncluster as long as the reallocation allows the sample to be closer to the new\ncentroid. This optimization procedure converges faster to a better local\nminimum over k-means and many of its variants. This fundamental modification\nover the k-means loop leads to the redefinition of a family of k-means\nvariants. Moreover, a new target function that minimizes the summation of\npairwise distances within clusters is presented. We show that it could be\nsolved under the same stochastic optimization procedure. This minimization\nprocedure built upon two minimization models outperforms k-means and its\nvariants considerably with different settings and on different datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:36:12 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zhao", "Wan-Lei", ""], ["Chen", "Run-Qing", ""], ["Ye", "Hui", ""], ["Ngo", "Chong-Wah", ""]]}, {"id": "2005.09561", "submitter": "Oliver Richter", "authors": "Oliver Richter and Roger Wattenhofer", "title": "Normalized Attention Without Probability Cage", "comments": "Preprint, work in progress. Feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention architectures are widely used; they recently gained renewed\npopularity with Transformers yielding a streak of state of the art results.\nYet, the geometrical implications of softmax-attention remain largely\nunexplored. In this work we highlight the limitations of constraining attention\nweights to the probability simplex and the resulting convex hull of value\nvectors. We show that Transformers are sequence length dependent biased towards\ntoken isolation at initialization and contrast Transformers to simple max- and\nsum-pooling - two strong baselines rarely reported. We propose to replace the\nsoftmax in self-attention with normalization, yielding a hyperparameter and\ndata-bias robust, generally applicable architecture. We support our insights\nwith empirical results from more than 25,000 trained models. All results and\nimplementations are made available.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 16:26:34 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2005.09595", "submitter": "Min Jae Song", "authors": "Joan Bruna, Oded Regev, Min Jae Song, and Yi Tang", "title": "Continuous LWE", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a continuous analogue of the Learning with Errors (LWE) problem,\nwhich we name CLWE. We give a polynomial-time quantum reduction from worst-case\nlattice problems to CLWE, showing that CLWE enjoys similar hardness guarantees\nto those of LWE. Alternatively, our result can also be seen as opening new\navenues of (quantum) attacks on lattice problems. Our work resolves an open\nproblem regarding the computational complexity of learning mixtures of\nGaussians without separability assumptions (Diakonikolas 2016, Moitra 2018). As\nan additional motivation, (a slight variant of) CLWE was considered in the\ncontext of robust machine learning (Diakonikolas et al.~FOCS 2017), where\nhardness in the statistical query (SQ) model was shown; our work addresses the\nopen question regarding its computational hardness (Bubeck et al.~ICML 2019).\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:16:12 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 20:55:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bruna", "Joan", ""], ["Regev", "Oded", ""], ["Song", "Min Jae", ""], ["Tang", "Yi", ""]]}, {"id": "2005.09619", "submitter": "Andrew Ilyas", "authors": "Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras,\n  Jacob Steinhardt, Aleksander Madry", "title": "Identifying Statistical Bias in Dataset Replication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataset replication is a useful tool for assessing whether improvements in\ntest accuracy on a specific benchmark correspond to improvements in models'\nability to generalize reliably. In this work, we present unintuitive yet\nsignificant ways in which standard approaches to dataset replication introduce\nstatistical bias, skewing the resulting observations. We study ImageNet-v2, a\nreplication of the ImageNet dataset on which models exhibit a significant\n(11-14%) drop in accuracy, even after controlling for a standard\nhuman-in-the-loop measure of data quality. We show that after correcting for\nthe identified statistical bias, only an estimated $3.6\\% \\pm 1.5\\%$ of the\noriginal $11.7\\% \\pm 1.0\\%$ accuracy drop remains unaccounted for. We conclude\nwith concrete recommendations for recognizing and avoiding bias in dataset\nreplication. Code for our study is publicly available at\nhttp://github.com/MadryLab/dataset-replication-analysis .\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:48:32 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 06:38:04 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Steinhardt", "Jacob", ""], ["Madry", "Aleksander", ""]]}, {"id": "2005.09624", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, I-Hau Yeh, David Hu, Hong-Yuan Mark Liao", "title": "Batch-Augmented Multi-Agent Reinforcement Learning for Efficient Traffic\n  Signal Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to provide a viable solution based on reinforcement\nlearning for traffic signal control problems. Although the state-of-the-art\nreinforcement learning approaches have yielded great success in a variety of\ndomains, directly applying it to alleviate traffic congestion can be\nchallenging, considering the requirement of high sample efficiency and how\ntraining data is gathered. In this work, we address several challenges that we\nencountered when we attempted to mitigate serious traffic congestion occurring\nin a metropolitan area. Specifically, we are required to provide a solution\nthat is able to (1) handle the traffic signal control when certain surveillance\ncameras that retrieve information for reinforcement learning are down, (2)\nlearn from batch data without a traffic simulator, and (3) make control\ndecisions without shared information across intersections. We present a\ntwo-stage framework to deal with the above-mentioned situations. The framework\ncan be decomposed into an Evolution Strategies approach that gives a fixed-time\ntraffic signal control schedule and a multi-agent off-policy reinforcement\nlearning that is capable of learning from batch data with the aid of three\nproposed components, bounded action, batch augmentation, and surrogate reward\nclipping. Our experiments show that the proposed framework reduces traffic\ncongestion by 36% in terms of waiting time compared with the currently used\nfixed-time traffic signal plan. Furthermore, the framework requires only 600\nqueries to a simulator to achieve the result.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:53:05 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Yeh", "I-Hau", ""], ["Hu", "David", ""], ["Liao", "Hong-Yuan Mark", ""]]}, {"id": "2005.09627", "submitter": "Stanley Chan", "authors": "Abhiram Gnansambandam, Stanley H. Chan", "title": "One Size Fits All: Can We Train One Denoiser for All Noise Levels?", "comments": "Published in the 37th International Conference on Machine Learning\n  (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training an estimator such as a neural network for tasks like image\ndenoising, it is often preferred to train one estimator and apply it to all\nnoise levels. The de facto training protocol to achieve this goal is to train\nthe estimator with noisy samples whose noise levels are uniformly distributed\nacross the range of interest. However, why should we allocate the samples\nuniformly? Can we have more training samples that are less noisy, and fewer\nsamples that are more noisy? What is the optimal distribution? How do we obtain\nsuch a distribution? The goal of this paper is to address this training sample\ndistribution problem from a minimax risk optimization perspective. We derive a\ndual ascent algorithm to determine the optimal sampling distribution of which\nthe convergence is guaranteed as long as the set of admissible estimators is\nclosed and convex. For estimators with non-convex admissible sets such as deep\nneural networks, our dual formulation converges to a solution of the convex\nrelaxation. We discuss how the algorithm can be implemented in practice. We\nevaluate the algorithm on linear estimators and deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:56:04 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 02:45:03 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 20:25:19 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Gnansambandam", "Abhiram", ""], ["Chan", "Stanley H.", ""]]}, {"id": "2005.09634", "submitter": "Andrew Loeb", "authors": "George S. Baggs, Paul Guerrier, Andrew Loeb, Jason C. Jones", "title": "Automated Copper Alloy Grain Size Evaluation Using a Deep-learning CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moog Inc. has automated the evaluation of copper (Cu) alloy grain size using\na deep-learning convolutional neural network (CNN). The proof-of-concept\nautomated image acquisition and batch-wise image processing offers the\npotential for significantly reduced labor, improved accuracy of grain\nevaluation, and decreased overall turnaround times for approving Cu alloy bar\nstock for use in flight critical aircraft hardware. A classification accuracy\nof 91.1% on individual sub-images of the Cu alloy coupons was achieved. Process\ndevelopment included minimizing the variation in acquired image color,\nbrightness, and resolution to create a dataset with 12300 sub-images, and then\noptimizing the CNN hyperparameters on this dataset using statistical design of\nexperiments (DoE).\n  Over the development of the automated Cu alloy grain size evaluation, a\ndegree of \"explainability\" in the artificial intelligence (XAI) output was\nrealized, based on the decomposition of the large raw images into many smaller\ndataset sub-images, through the ability to explain the CNN ensemble image\noutput via inspection of the classification results from the individual smaller\nsub-images.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:13:38 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Baggs", "George S.", ""], ["Guerrier", "Paul", ""], ["Loeb", "Andrew", ""], ["Jones", "Jason C.", ""]]}, {"id": "2005.09683", "submitter": "Steffen Rendle", "authors": "Steffen Rendle, Walid Krichene, Li Zhang, John Anderson", "title": "Neural Collaborative Filtering vs. Matrix Factorization Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding based models have been the state of the art in collaborative\nfiltering for over a decade. Traditionally, the dot product or higher order\nequivalents have been used to combine two or more embeddings, e.g., most\nnotably in matrix factorization. In recent years, it was suggested to replace\nthe dot product with a learned similarity e.g. using a multilayer perceptron\n(MLP). This approach is often referred to as neural collaborative filtering\n(NCF). In this work, we revisit the experiments of the NCF paper that\npopularized learned similarities using MLPs. First, we show that with a proper\nhyperparameter selection, a simple dot product substantially outperforms the\nproposed learned similarities. Second, while a MLP can in theory approximate\nany function, we show that it is non-trivial to learn a dot product with an\nMLP. Finally, we discuss practical issues that arise when applying MLP based\nsimilarities and show that MLPs are too costly to use for item recommendation\nin production environments while dot products allow to apply very efficient\nretrieval algorithms. We conclude that MLPs should be used with care as\nembedding combiner and that dot products might be a better default choice.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:07:08 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 23:21:33 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Rendle", "Steffen", ""], ["Krichene", "Walid", ""], ["Zhang", "Li", ""], ["Anderson", "John", ""]]}, {"id": "2005.09711", "submitter": "Abhishek Kaul", "authors": "Abhishek Kaul, Hongjin Zhang, Konstantinos Tsampourakis and George\n  Michailidis", "title": "Inference on the Change Point for High Dimensional Dynamic Graphical\n  Models", "comments": "Software available upon request (built in R)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an estimator for the change point parameter for a dynamically\nevolving graphical model, and also obtain its asymptotic distribution under\nhigh dimensional scaling. To procure the latter result, we establish that the\nproposed estimator exhibits an $O_p(\\psi^{-2})$ rate of convergence, wherein\n$\\psi$ represents the jump size between the graphical model parameters before\nand after the change point. Further, it retains sufficient adaptivity against\nplug-in estimates of the graphical model parameters. We characterize the forms\nof the asymptotic distribution under the both a vanishing and a non-vanishing\nregime of the magnitude of the jump size. Specifically, in the former case it\ncorresponds to the argmax of a negative drift asymmetric two sided Brownian\nmotion, while in the latter case to the argmax of a negative drift asymmetric\ntwo sided random walk, whose increments depend on the distribution of the\ngraphical model. Easy to implement algorithms are provided for estimating the\nchange point and their performance assessed on synthetic data. The proposed\nmethodology is further illustrated on RNA-sequenced microbiome data and their\nchanges between young and older individuals.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 19:15:32 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 20:51:16 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 05:30:44 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kaul", "Abhishek", ""], ["Zhang", "Hongjin", ""], ["Tsampourakis", "Konstantinos", ""], ["Michailidis", "George", ""]]}, {"id": "2005.09717", "submitter": "Anders Bredahl Kock", "authors": "Anders Bredahl Kock and David Preinerstorfer and Bezirgen Veliyev", "title": "Treatment recommendation with distributional targets", "comments": "Treatment allocation, best treatment identification, statistical\n  decision theory, pure exploration, nonparametric multi-armed bandits", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of a decision maker who must provide the best possible\ntreatment recommendation based on an experiment. The desirability of the\noutcome distribution resulting from the policy recommendation is measured\nthrough a functional capturing the distributional characteristic that the\ndecision maker is interested in optimizing. This could be, e.g., its inherent\ninequality, welfare, level of poverty or its distance to a desired outcome\ndistribution. If the functional of interest is not quasi-convex or if there are\nconstraints, the optimal recommendation may be a mixture of treatments. This\nvastly expands the set of recommendations that must be considered. We\ncharacterize the difficulty of the problem by obtaining maximal expected regret\nlower bounds. Furthermore, we propose two regret-optimal policies. The first\npolicy is static and thus applicable irrespectively of the subjects arriving\nsequentially or not in the course of the experimental phase. The second policy\ncan utilize that subjects arrive sequentially by successively eliminating\ninferior treatments and thus spends the sampling effort where it is most\nneeded.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 19:27:21 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 10:57:59 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Kock", "Anders Bredahl", ""], ["Preinerstorfer", "David", ""], ["Veliyev", "Bezirgen", ""]]}, {"id": "2005.09752", "submitter": "Charu Sharma", "authors": "Charu Sharma, Jatin Chauhan, Manohar Kaul", "title": "Learning Representations using Spectral-Biased Random Walks on Graphs", "comments": "Accepted at IJCNN 2020: International Joint Conference on Neural\n  Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several state-of-the-art neural graph embedding methods are based on short\nrandom walks (stochastic processes) because of their ease of computation,\nsimplicity in capturing complex local graph properties, scalability, and\ninterpretibility. In this work, we are interested in studying how much a\nprobabilistic bias in this stochastic process affects the quality of the nodes\npicked by the process. In particular, our biased walk, with a certain\nprobability, favors movement towards nodes whose neighborhoods bear a\nstructural resemblance to the current node's neighborhood. We succinctly\ncapture this neighborhood as a probability measure based on the spectrum of the\nnode's neighborhood subgraph represented as a normalized laplacian matrix. We\npropose the use of a paragraph vector model with a novel Wasserstein\nregularization term. We empirically evaluate our approach against several\nstate-of-the-art node embedding techniques on a wide variety of real-world\ndatasets and demonstrate that our proposed method significantly improves upon\nexisting methods on both link prediction and node classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 20:42:43 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 15:12:32 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Sharma", "Charu", ""], ["Chauhan", "Jatin", ""], ["Kaul", "Manohar", ""]]}, {"id": "2005.09787", "submitter": "Justin Doak", "authors": "Justin E. Doak, Michael R. Smith, Joey B. Ingram", "title": "Self-Updating Models with Error Remediation", "comments": "17 pages, 13 figures, published in the proceedings of the Artificial\n  Intelligence and Machine Learning for Multi-Domain Operations Applications II\n  conference in the SPIE Defense + Commercial Sensing, 2020 symposium", "journal-ref": "Proc. SPIE 11413, Artificial Intelligence and Machine Learning for\n  Multi-Domain Operations Applications II, 114131W (18 May 2020)", "doi": "10.1117/12.2563843", "report-no": "SAND No: SAND2020-5113 C", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many environments currently employ machine learning models for data\nprocessing and analytics that were built using a limited number of training\ndata points. Once deployed, the models are exposed to significant amounts of\npreviously-unseen data, not all of which is representative of the original,\nlimited training data. However, updating these deployed models can be difficult\ndue to logistical, bandwidth, time, hardware, and/or data sensitivity\nconstraints. We propose a framework, Self-Updating Models with Error\nRemediation (SUMER), in which a deployed model updates itself as new data\nbecomes available. SUMER uses techniques from semi-supervised learning and\nnoise remediation to iteratively retrain a deployed model using\nintelligently-chosen predictions from the model as the labels for new training\niterations. A key component of SUMER is the notion of error remediation as\nself-labeled data can be susceptible to the propagation of errors. We\ninvestigate the use of SUMER across various data sets and iterations. We find\nthat self-updating models (SUMs) generally perform better than models that do\nnot attempt to self-update when presented with additional previously-unseen\ndata. This performance gap is accentuated in cases where there is only limited\namounts of initial training data. We also find that the performance of SUMER is\ngenerally better than the performance of SUMs, demonstrating a benefit in\napplying error remediation. Consequently, SUMER can autonomously enhance the\noperational capabilities of existing data processing systems by intelligently\nupdating models in dynamic environments.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 23:09:38 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Doak", "Justin E.", ""], ["Smith", "Michael R.", ""], ["Ingram", "Joey B.", ""]]}, {"id": "2005.09807", "submitter": "Mansura Habiba Miss", "authors": "Mansura Habiba, Barak A. Pearlmutter", "title": "Neural Ordinary Differential Equation based Recurrent Neural Network\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural differential equations are a promising new member in the neural\nnetwork family. They show the potential of differential equations for time\nseries data analysis. In this paper, the strength of the ordinary differential\nequation (ODE) is explored with a new extension. The main goal of this work is\nto answer the following questions: (i)~can ODE be used to redefine the existing\nneural network model? (ii)~can Neural ODEs solve the irregular sampling rate\nchallenge of existing neural network models for a continuous time series, i.e.,\nlength and dynamic nature, (iii)~how to reduce the training and evaluation time\nof existing Neural ODE systems? This work leverages the mathematical foundation\nof ODEs to redesign traditional RNNs such as Long Short-Term Memory (LSTM) and\nGated Recurrent Unit (GRU). The main contribution of this paper is to\nillustrate the design of two new ODE-based RNN models (GRU-ODE model and\nLSTM-ODE) which can compute the hidden state and cell state at any point of\ntime using an ODE solver. These models reduce the computation overhead of\nhidden state and cell state by a vast amount. The performance evaluation of\nthese two new models for learning continuous time series with irregular\nsampling rate is then demonstrated. Experiments show that these new ODE based\nRNN models require less training time than Latent ODEs and conventional Neural\nODEs. They can achieve higher accuracy quickly, and the design of the neural\nnetwork is simpler than, previous neural ODE systems.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:02:29 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Habiba", "Mansura", ""], ["Pearlmutter", "Barak A.", ""]]}, {"id": "2005.09810", "submitter": "Kimon Fountoulakis", "authors": "Kimon Fountoulakis, Di Wang, Shenghao Yang", "title": "$p$-Norm Flow Diffusion for Local Graph Clustering", "comments": "28 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local graph clustering and the closely related seed set expansion problem are\nprimitives on graphs that are central to a wide range of analytic and learning\ntasks such as local clustering, community detection, nodes ranking and feature\ninference. Prior work on local graph clustering mostly falls into two\ncategories with numerical and combinatorial roots respectively. In this work,\nwe draw inspiration from both fields and propose a family of convex\noptimization formulations based on the idea of diffusion with p-norm network\nflow for $p\\in (1,\\infty)$. In the context of local clustering, we characterize\nthe optimal solutions for these optimization problems and show their usefulness\nin finding low conductance cuts around input seed set. In particular, we\nachieve quadratic approximation of conductance in the case of $p=2$ similar to\nthe Cheeger-type bounds of spectral methods, constant factor approximation when\n$p\\rightarrow\\infty$ similar to max-flow based methods, and a smooth transition\nfor general $p$ values in between. Thus, our optimization formulation can be\nviewed as bridging the numerical and combinatorial approaches, and we can\nachieve the best of both worlds in terms of speed and noise robustness. We show\nthat the proposed problem can be solved in strongly local running time for\n$p\\ge 2$ and conduct empirical evaluations on both synthetic and real-world\ngraphs to illustrate our approach compares favorably with existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:08:17 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 05:53:06 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 09:09:08 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Fountoulakis", "Kimon", ""], ["Wang", "Di", ""], ["Yang", "Shenghao", ""]]}, {"id": "2005.09814", "submitter": "Manan Tomar Mr.", "authors": "Manan Tomar, Lior Shani, Yonathan Efroni, Mohammad Ghavamzadeh", "title": "Mirror Descent Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirror descent (MD), a well-known first-order method in constrained convex\noptimization, has recently been shown as an important tool to analyze\ntrust-region algorithms in reinforcement learning (RL). However, there remains\na considerable gap between such theoretically analyzed algorithms and the ones\nused in practice. Inspired by this, we propose an efficient RL algorithm,\ncalled {\\em mirror descent policy optimization} (MDPO). MDPO iteratively\nupdates the policy by {\\em approximately} solving a trust-region problem, whose\nobjective function consists of two terms: a linearization of the standard RL\nobjective and a proximity term that restricts two consecutive policies to be\nclose to each other. Each update performs this approximation by taking multiple\ngradient steps on this objective function. We derive {\\em on-policy} and {\\em\noff-policy} variants of MDPO, while emphasizing important design choices\nmotivated by the existing theory of MD in RL. We highlight the connections\nbetween on-policy MDPO and two popular trust-region RL algorithms: TRPO and\nPPO, and show that explicitly enforcing the trust-region constraint is in fact\n{\\em not} a necessity for high performance gains in TRPO. We then show how the\npopular soft actor-critic (SAC) algorithm can be derived by slight\nmodifications of off-policy MDPO. Overall, MDPO is derived from the MD\nprinciples, offers a unified approach to viewing a number of popular RL\nalgorithms, and performs better than or on-par with TRPO, PPO, and SAC in a\nnumber of continuous control tasks. Code is available at\n\\url{https://github.com/manantomar/Mirror-Descent-Policy-Optimization}.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:30:43 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 23:50:29 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 14:37:24 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 10:05:24 GMT"}, {"version": "v5", "created": "Mon, 7 Jun 2021 13:44:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tomar", "Manan", ""], ["Shani", "Lior", ""], ["Efroni", "Yonathan", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "2005.09841", "submitter": "Tom\\'a\\v{s} Koc\\'ak", "authors": "Tom\\'a\\v{s} Koc\\'ak, Aur\\'elien Garivier", "title": "Best Arm Identification in Spectral Bandits", "comments": "To be published in International Joint Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study best-arm identification with fixed confidence in bandit models with\ngraph smoothness constraint. We provide and analyze an efficient gradient\nascent algorithm to compute the sample complexity of this problem as a solution\nof a non-smooth max-min problem (providing in passing a simplified analysis for\nthe unconstrained case). Building on this algorithm, we propose an\nasymptotically optimal strategy. We furthermore illustrate by numerical\nexperiments both the strategy's efficiency and the impact of the smoothness\nconstraint on the sample complexity. Best Arm Identification (BAI) is an\nimportant challenge in many applications ranging from parameter tuning to\nclinical trials. It is now very well understood in vanilla bandit models, but\nreal-world problems typically involve some dependency between arms that\nrequires more involved models. Assuming a graph structure on the arms is an\nelegant practical way to encompass this phenomenon, but this had been done so\nfar only for regret minimization. Addressing BAI with graph constraints\ninvolves delicate optimization problems for which the present paper offers a\nsolution.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 04:12:04 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Koc\u00e1k", "Tom\u00e1\u0161", ""], ["Garivier", "Aur\u00e9lien", ""]]}, {"id": "2005.09856", "submitter": "Zixiao Shen", "authors": "Zixiao Shen, Xin Chen, Jonathan M. Garibaldi", "title": "A Novel Meta Learning Framework for Feature Selection using Data\n  Synthesis and Fuzzy Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel meta learning framework for feature selection\n(FS) based on fuzzy similarity. The proposed method aims to recommend the best\nFS method from four candidate FS methods for any given dataset. This is\nachieved by firstly constructing a large training data repository using data\nsynthesis. Six meta features that represent the characteristics of the training\ndataset are then extracted. The best FS method for each of the training\ndatasets is used as the meta label. Both the meta features and the\ncorresponding meta labels are subsequently used to train a classification model\nusing a fuzzy similarity measure based framework. Finally the trained model is\nused to recommend the most suitable FS method for a given unseen dataset. This\nproposed method was evaluated based on eight public datasets of real-world\napplications. It successfully recommended the best method for five datasets and\nthe second best method for one dataset, which outperformed any of the four\nindividual FS methods. Besides, the proposed method is computationally\nefficient for algorithm selection, leading to negligible additional time for\nthe feature selection process. Thus, the paper contributes a novel method for\neffectively recommending which feature selection method to use for any new\ngiven dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:03:41 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 03:41:56 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Shen", "Zixiao", ""], ["Chen", "Xin", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "2005.09863", "submitter": "Chang Zhou", "authors": "Zhen Yang, Ming Ding, Chang Zhou, Hongxia Yang, Jingren Zhou and Jie\n  Tang", "title": "Understanding Negative Sampling in Graph Representation Learning", "comments": "KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has been extensively studied in recent years.\nDespite its potential in generating continuous embeddings for various networks,\nboth the effectiveness and efficiency to infer high-quality representations\ntoward large corpus of nodes are still challenging. Sampling is a critical\npoint to achieve the performance goals. Prior arts usually focus on sampling\npositive node pairs, while the strategy for negative sampling is left\ninsufficiently explored. To bridge the gap, we systematically analyze the role\nof negative sampling from the perspectives of both objective and risk,\ntheoretically demonstrating that negative sampling is as important as positive\nsampling in determining the optimization objective and the resulted variance.\nTo the best of our knowledge, we are the first to derive the theory and\nquantify that the negative sampling distribution should be positively but\nsub-linearly correlated to their positive sampling distribution. With the\nguidance of the theory, we propose MCNS, approximating the positive\ndistribution with self-contrast approximation and accelerating negative\nsampling by Metropolis-Hastings. We evaluate our method on 5 datasets that\ncover extensive downstream graph learning tasks, including link prediction,\nnode classification and personalized recommendation, on a total of 19\nexperimental settings. These relatively comprehensive experimental results\ndemonstrate its robustness and superiorities.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:25:21 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 04:10:30 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Yang", "Zhen", ""], ["Ding", "Ming", ""], ["Zhou", "Chang", ""], ["Yang", "Hongxia", ""], ["Zhou", "Jingren", ""], ["Tang", "Jie", ""]]}, {"id": "2005.09871", "submitter": "Nataliya Portman Dr.", "authors": "Nataliya Portman, Paule-J Toussaint, Alan C. Evans (McConnell Brain\n  Imaging Centre, Montreal Neurological Institute, McGill University, Montreal,\n  QC, Canada)", "title": "Local semi-supervised approach to brain tissue classification in child\n  brain MRI", "comments": "This manuscript was written by Nataliya Portman in the end of her\n  postdoctoral tenure in 2014 and reviewed and edited by Paul-J Toussaint. 31\n  pages including Appendix, 14 figures. arXiv admin note: text overlap with\n  arXiv:2005.03261", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most segmentation methods in child brain MRI are supervised and are based on\nglobal intensity distributions of major brain structures. The successful\nimplementation of a supervised approach depends on availability of an\nage-appropriate probabilistic brain atlas. For the study of early normal brain\ndevelopment, the construction of such a brain atlas remains a significant\nchallenge. Moreover, using global intensity statistics leads to inaccurate\ndetection of major brain tissue classes due to substantial intensity variations\nof MR signal within the constituent parts of early developing brain. In order\nto overcome these methodological limitations we develop a local,\nsemi-supervised framework. It is based on Kernel Fisher Discriminant Analysis\n(KFDA) for pattern recognition, combined with an objective structural\nsimilarity index (SSIM) for perceptual image quality assessment. The proposed\nmethod performs optimal brain partitioning into subdomains having different\naverage intensity values followed by SSIM-guided computation of separating\nsurfaces between the constituent brain parts. The classified image subdomains\nare then stitched slice by slice via simulated annealing to form a global image\nof the classified brain. In this paper, we consider classification into major\ntissue classes (white matter and grey matter) and the cerebrospinal fluid and\nillustrate the proposed framework on examples of brain templates for ages 8 to\n11 months and ages 44 to 60 months. We show that our method improves detection\nof the tissue classes by its comparison to state-of-the-art classification\ntechniques known as Partial Volume Estimation.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:43:41 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Portman", "Nataliya", "", "McConnell Brain\n  Imaging Centre, Montreal Neurological Institute, McGill University, Montreal,\n  QC, Canada"], ["Toussaint", "Paule-J", "", "McConnell Brain\n  Imaging Centre, Montreal Neurological Institute, McGill University, Montreal,\n  QC, Canada"], ["Evans", "Alan C.", "", "McConnell Brain\n  Imaging Centre, Montreal Neurological Institute, McGill University, Montreal,\n  QC, Canada"]]}, {"id": "2005.09874", "submitter": "Weizun Zhao", "authors": "Weizun Zhao (1), Lishuai Li (1), Sameer Alam (2), Yanjun Wang (3 and\n  4) ((1) Department of Systems Engineering and Engineering Management, City\n  University of Hong Kong, (2) School of Mechanical & Aerospace Engineering,\n  Nanyang Technological University, (3) College of Civil Aviation, Nanjing\n  University of Aeronautics and Astronautics, (4) Department of Aeronautics and\n  Astronautics, Massachusetts Institute of Technology)", "title": "An Incremental Clustering Method for Anomaly Detection in Flight Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety is a top priority for civil aviation. Data mining in digital Flight\nData Recorder (FDR) or Quick Access Recorder (QAR) data, commonly referred as\nblack box data on aircraft, has gained interest from researchers, airlines, and\naviation regulation agencies for safety management. New anomaly detection\nmethods based on supervised or unsupervised learning have been developed to\nmonitor pilot operations and detect any risks from onboard digital flight data\nrecorder data. However, all existing anomaly detection methods are offline\nlearning - the models are trained once using historical data and used for all\nfuture predictions. In practice, new QAR data are generated by every flight and\ncollected by airlines whenever a datalink is available. Offline methods cannot\nrespond to new data in time. Though these offline models can be updated by\nbeing re-trained after adding new data to the original training set, it is\ntime-consuming and computational costly to train a new model every time new\ndata come in. To address this problem, we propose a novel incremental anomaly\ndetection method to identify common patterns and detect outliers in flight\noperations from FDR data. The proposed method is based on Gaussian Mixture\nModel (GMM). An initial GMM cluster model is trained on historical offline\ndata. Then, it continuously adapts to new incoming data points via an\nexpectation-maximization (EM) algorithm. To track changes in flight operation\npatterns, only model parameters need to be saved, not the raw flight data. The\nproposed method was tested on two sets of simulation data. Comparable results\nwere found from the proposed online method and a classic offline model. A\nreal-world application of the proposed method is demonstrated using FDR data\nfrom daily operations of an airline. Results are presented and future\nchallenges of using online learning scheme for flight data analytics are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:58:25 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 02:18:12 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 10:30:28 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zhao", "Weizun", "", "3 and\n  4"], ["Li", "Lishuai", "", "3 and\n  4"], ["Alam", "Sameer", "", "3 and\n  4"], ["Wang", "Yanjun", "", "3 and\n  4"]]}, {"id": "2005.09876", "submitter": "Matt Wand", "authors": "L. Maestrini and M.P. Wand", "title": "The Inverse G-Wishart Distribution and Variational Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing on a factor graph is a powerful paradigm for the coding of\napproximate inference algorithms for arbitrarily graphical large models. The\nnotion of a factor graph fragment allows for compartmentalization of algebra\nand computer code. We show that the Inverse G-Wishart family of distributions\nenables fundamental variational message passing factor graph fragments to be\nexpressed elegantly and succinctly. Such fragments arise in models for which\napproximate inference concerning covariance matrix or variance parameters is\nmade, and are ubiquitous in contemporary statistics and machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:59:48 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 06:57:56 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 06:35:47 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Maestrini", "L.", ""], ["Wand", "M. P.", ""]]}, {"id": "2005.09902", "submitter": "Harold Kiossou", "authors": "Nicolas Golenvaux, Pablo Gonzalez Alvarez, Harold Silv\\`ere Kiossou,\n  Pierre Schaus", "title": "An LSTM approach to Forecast Migration using Google Trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to model and forecast international migration as precisely as\npossible is crucial for policymaking. Recently Google Trends data in addition\nto other economic and demographic data have been shown to improve the\nforecasting quality of a gravity linear model for the one-year ahead\nforecasting. In this work, we replace the linear model with a long short-term\nmemory (LSTM) approach and compare it with two existing approaches: the linear\ngravity model and an artificial neural network (ANN) model. Our LSTM approach\ncombined with Google Trends data outperforms both these models on various\nmetrics in the task of forecasting the one-year ahead incoming international\nmigration to 35 Organization for Economic Co-operation and Development (OECD)\ncountries: for example the root mean square error (RMSE) and the mean average\nerror (MAE) have been divided by 5 and 4 on the test set. This positive result\ndemonstrates that machine learning techniques constitute a serious alternative\nover traditional approaches for studying migration mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:07:42 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 13:54:24 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Golenvaux", "Nicolas", ""], ["Alvarez", "Pablo Gonzalez", ""], ["Kiossou", "Harold Silv\u00e8re", ""], ["Schaus", "Pierre", ""]]}, {"id": "2005.09903", "submitter": "Natalia Shepeleva", "authors": "Natalia Shepeleva, Werner Zellinger, Michal Lewandowski and Bernhard\n  Moser", "title": "ReLU Code Space: A Basis for Rating Network Quality Besides Accuracy", "comments": "in ICLR 2020 Workshop on Neural Architecture Search (NAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new metric space of ReLU activation codes equipped with a\ntruncated Hamming distance which establishes an isometry between its elements\nand polyhedral bodies in the input space which have recently been shown to be\nstrongly related to safety, robustness, and confidence. This isometry allows\nthe efficient computation of adjacency relations between the polyhedral bodies.\nExperiments on MNIST and CIFAR-10 indicate that information besides accuracy\nmight be stored in the code space.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:10:28 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Shepeleva", "Natalia", ""], ["Zellinger", "Werner", ""], ["Lewandowski", "Michal", ""], ["Moser", "Bernhard", ""]]}, {"id": "2005.09904", "submitter": "Yongkweon Jeon", "authors": "Yongkweon Jeon, Baeseong Park, Se Jung Kwon, Byeongwook Kim, Jeongin\n  Yun, and Dongsoo Lee", "title": "BiQGEMM: Matrix Multiplication with Lookup Table For Binary-Coding-based\n  Quantized DNNs", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of parameters in deep neural networks (DNNs) is rapidly increasing\nto support complicated tasks and to improve model accuracy. Correspondingly,\nthe amount of computations and required memory footprint increase as well.\nQuantization is an efficient method to address such concerns by compressing\nDNNs such that computations can be simplified while required storage footprint\nis significantly reduced. Unfortunately, commercial CPUs and GPUs do not fully\nsupport quantization because only fixed data transfers (such as 32 bits) are\nallowed. As a result, even if weights are quantized into a few bits, CPUs and\nGPUs cannot access multiple quantized weights without memory bandwidth waste.\nSuccess of quantization in practice, hence, relies on an efficient computation\nengine design, especially for matrix multiplication that is a basic computation\nengine in most DNNs. In this paper, we propose a novel matrix multiplication\nmethod, called BiQGEMM, dedicated to quantized DNNs. BiQGEMM can access\nmultiple quantized weights simultaneously in one instruction. In addition,\nBiQGEMM pre-computes intermediate results that are highly redundant when\nquantization leads to limited available computation space. Since pre-computed\nvalues are stored in lookup tables and reused, BiQGEMM achieves lower amount of\noverall computations. Our extensive experimental results show that BiQGEMM\npresents higher performance than conventional schemes when DNNs are quantized.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:15:33 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 05:43:28 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Jeon", "Yongkweon", ""], ["Park", "Baeseong", ""], ["Kwon", "Se Jung", ""], ["Kim", "Byeongwook", ""], ["Yun", "Jeongin", ""], ["Lee", "Dongsoo", ""]]}, {"id": "2005.09907", "submitter": "J. Emmanuel Johnson", "authors": "J. Emmanuel Johnson, Valero Laparra, Gustau Camps-Valls", "title": "Accounting for Input Noise in Gaussian Process Parameter Retrieval", "comments": null, "journal-ref": "IEEE Geoscience and Remote Sensing Letters ( Volume: 17 , Issue: 3\n  , March 2020 )", "doi": "10.1109/LGRS.2019.2921476", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are a class of Kernel methods that have shown to be\nvery useful in geoscience and remote sensing applications for parameter\nretrieval, model inversion, and emulation. They are widely used because they\nare simple, flexible, and provide accurate estimates. GPs are based on a\nBayesian statistical framework which provides a posterior probability function\nfor each estimation. Therefore, besides the usual prediction (given in this\ncase by the mean function), GPs come equipped with the possibility to obtain a\npredictive variance (i.e., error bars, confidence intervals) for each\nprediction. Unfortunately, the GP formulation usually assumes that there is no\nnoise in the inputs, only in the observations. However, this is often not the\ncase in earth observation problems where an accurate assessment of the\nmeasuring instrument error is typically available, and where there is huge\ninterest in characterizing the error propagation through the processing\npipeline. In this letter, we demonstrate how one can account for input noise\nestimates using a GP model formulation which propagates the error terms using\nthe derivative of the predictive mean function. We analyze the resulting\npredictive variance term and show how they more accurately represent the model\nerror in a temperature prediction problem from infrared sounding data.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:23:48 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Johnson", "J. Emmanuel", ""], ["Laparra", "Valero", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "2005.09910", "submitter": "Youngdoo Son", "authors": "Sungjae Lee, Youngdoo Son", "title": "Multitask Learning with Single Gradient Step Update for Task Balancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning is a methodology to boost generalization performance and\nalso reduce computational intensity and memory usage. However, learning\nmultiple tasks simultaneously can be more difficult than learning a single task\nbecause it can cause imbalance among tasks. To address the imbalance problem,\nwe propose an algorithm to balance between tasks at the gradient level by\napplying gradient-based meta-learning to multitask learning. The proposed\nmethod trains shared layers and task-specific layers separately so that the two\nlayers with different roles in a multitask network can be fitted to their own\npurposes. In particular, the shared layer that contains informative knowledge\nshared among tasks is trained by employing single gradient step update and\ninner/outer loop training to mitigate the imbalance problem at the gradient\nlevel. We apply the proposed method to various multitask computer vision\nproblems and achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:34:20 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 12:29:42 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Lee", "Sungjae", ""], ["Son", "Youngdoo", ""]]}, {"id": "2005.09912", "submitter": "John Lafferty", "authors": "Chao Gao and John Lafferty", "title": "Model Repair: Robust Recovery of Over-Parameterized Statistical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new type of robust estimation problem is introduced where the goal is to\nrecover a statistical model that has been corrupted after it has been estimated\nfrom data. Methods are proposed for \"repairing\" the model using only the design\nand not the response values used to fit the model in a supervised learning\nsetting. Theory is developed which reveals that two important ingredients are\nnecessary for model repair---the statistical model must be over-parameterized,\nand the estimator must incorporate redundancy. In particular, estimators based\non stochastic gradient descent are seen to be well suited to model repair, but\nsparse estimators are not in general repairable. After formulating the problem\nand establishing a key technical lemma related to robust estimation, a series\nof results are presented for repair of over-parameterized linear models, random\nfeature models, and artificial neural networks. Simulation studies are\npresented that corroborate and illustrate the theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:41:56 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Gao", "Chao", ""], ["Lafferty", "John", ""]]}, {"id": "2005.09923", "submitter": "Shihua Zhang", "authors": "Kuo Gai and Shihua Zhang", "title": "Tessellated Wasserstein Auto-Encoders", "comments": "38 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-adversarial generative models such as variational auto-encoder (VAE),\nWasserstein auto-encoders with maximum mean discrepancy (WAE-MMD),\nsliced-Wasserstein auto-encoder (SWAE) are relatively easy to train and have\nless mode collapse compared to Wasserstein auto-encoder with generative\nadversarial network (WAE-GAN). However, they are not very accurate in\napproximating the target distribution in the latent space because they don't\nhave a discriminator to detect the minor difference between real and fake. To\nthis end, we develop a novel non-adversarial framework called Tessellated\nWasserstein Auto-encoders (TWAE) to tessellate the support of the target\ndistribution into a given number of regions by the centroidal Voronoi\ntessellation (CVT) technique and design batches of data according to the\ntessellation instead of random shuffling for accurate computation of\ndiscrepancy. Theoretically, we demonstrate that the error of estimate to the\ndiscrepancy decreases when the numbers of samples $n$ and regions $m$ of the\ntessellation become larger with rates of $\\mathcal{O}(\\frac{1}{\\sqrt{n}})$ and\n$\\mathcal{O}(\\frac{1}{\\sqrt{m}})$, respectively. Given fixed $n$ and $m$, a\nnecessary condition for the upper bound of measurement error to be minimized is\nthat the tessellation is the one determined by CVT. TWAE is very flexible to\ndifferent non-adversarial metrics and can substantially enhance their\ngenerative performance in terms of Fr\\'{e}chet inception distance (FID)\ncompared to VAE, WAE-MMD, SWAE. Moreover, numerical results indeed demonstrate\nthat TWAE is competitive to the adversarial model WAE-GAN, demonstrating its\npowerful generative ability.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 09:21:05 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 02:08:40 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gai", "Kuo", ""], ["Zhang", "Shihua", ""]]}, {"id": "2005.09945", "submitter": "Youssef Achenchabe", "authors": "Youssef Achenchabe, Alexis Bondu, Antoine Cornu\\'ejols and Asma\n  Dachraoui", "title": "Early Classification of Time Series. Cost-based Optimization Criterion\n  and Algorithms", "comments": "Accepted for publication in Machine learning journal (MACH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of applications require to recognize the class of an\nincoming time series as quickly as possible without unduly compromising the\naccuracy of the prediction. In this paper, we put forward a new optimization\ncriterion which takes into account both the cost of misclassification and the\ncost of delaying the decision. Based on this optimization criterion, we derived\na family of non-myopic algorithms which try to anticipate the expected future\ngain in information in balance with the cost of waiting. In one class of\nalgorithms, unsupervised-based, the expectations use the clustering of time\nseries, while in a second class, supervised-based, time series are grouped\naccording to the confidence level of the classifier used to label them.\nExtensive experiments carried out on real data sets using a large range of\ndelay cost functions show that the presented algorithms are able to\nsatisfactorily solving the earliness vs. accuracy trade-off, with the\nsupervised-based approaches faring better than the unsupervised-based ones. In\naddition, all these methods perform better in a wide variety of conditions than\na state of the art method based on a myopic strategy which is recognized as\nvery competitive.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 10:08:30 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 13:29:35 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Achenchabe", "Youssef", ""], ["Bondu", "Alexis", ""], ["Cornu\u00e9jols", "Antoine", ""], ["Dachraoui", "Asma", ""]]}, {"id": "2005.09958", "submitter": "Jos\\'e Vin\\'icius de Miranda Cardoso", "authors": "Jos\\'e Vin\\'icius de Miranda Cardoso and Daniel P. Palomar", "title": "Learning Undirected Graphs in Financial Markets", "comments": "5 pages, 13 figures, accepted at Asilomar Conference on Signals,\n  Systems, and Computers, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-fin.CP q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the problem of learning undirected graphical models under\nLaplacian structural constraints from the point of view of financial market\ndata. We show that Laplacian constraints have meaningful physical\ninterpretations related to the market index factor and to the conditional\ncorrelations between stocks. Those interpretations lead to a set of guidelines\nthat users should be aware of when estimating graphs in financial markets. In\naddition, we propose algorithms to learn undirected graphs that account for\nstylized facts and tasks intrinsic to financial data such as non-stationarity\nand stock clustering.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 10:48:21 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 05:38:27 GMT"}, {"version": "v3", "created": "Sat, 23 May 2020 08:52:07 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 11:13:28 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Cardoso", "Jos\u00e9 Vin\u00edcius de Miranda", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "2005.10008", "submitter": "Priyadarshini Kumari", "authors": "Priyadarshini K, Ritesh Goru, Siddhartha Chaudhuri and Subhasis\n  Chaudhuri", "title": "Batch Decorrelation for Active Metric Learning", "comments": "Accepted to IJCAI-PRICAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an active learning strategy for training parametric models of\ndistance metrics, given triplet-based similarity assessments: object $x_i$ is\nmore similar to object $x_j$ than to $x_k$. In contrast to prior work on\nclass-based learning, where the fundamental goal is classification and any\nimplicit or explicit metric is binary, we focus on {\\em perceptual} metrics\nthat express the {\\em degree} of (dis)similarity between objects. We find that\nstandard active learning approaches degrade when annotations are requested for\n{\\em batches} of triplets at a time: our studies suggest that correlation among\ntriplets is responsible. In this work, we propose a novel method to {\\em\ndecorrelate} batches of triplets, that jointly balances informativeness and\ndiversity while decoupling the choice of heuristic for each criterion.\nExperiments indicate our method is general, adaptable, and outperforms the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 12:47:48 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 12:52:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["K", "Priyadarshini", ""], ["Goru", "Ritesh", ""], ["Chaudhuri", "Siddhartha", ""], ["Chaudhuri", "Subhasis", ""]]}, {"id": "2005.10018", "submitter": "Maciej Skorski", "authors": "Maciej Skorski", "title": "Revisiting Concentration of Missing Mass", "comments": "Added suplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of \\emph{missing mass concentration}, developing a new\nmethod of estimating concentration of heterogenic sums, in spirit of celebrated\nRosenthal's inequality. As a result we slightly improve the state-of-art bounds\ndue to Ben-Hamou at al., and simplify the proofs.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:56:00 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 16:03:44 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 15:43:42 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "2005.10026", "submitter": "Marc Etheve", "authors": "Marc Etheve and Zacharie Al\\`es and C\\^ome Bissuel and Olivier Juan\n  and Safia Kedad-Sidhoum", "title": "Reinforcement Learning for Variable Selection in a Branch and Bound\n  Algorithm", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58942-4_12", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed integer linear programs are commonly solved by Branch and Bound\nalgorithms. A key factor of the efficiency of the most successful commercial\nsolvers is their fine-tuned heuristics. In this paper, we leverage patterns in\nreal-world instances to learn from scratch a new branching strategy optimised\nfor a given problem and compare it with a commercial solver. We propose FMSTS,\na novel Reinforcement Learning approach specifically designed for this task.\nThe strength of our method lies in the consistency between a local value\nfunction and a global metric of interest. In addition, we provide insights for\nadapting known RL techniques to the Branch and Bound setting, and present a new\nneural network architecture inspired from the literature. To our knowledge, it\nis the first time Reinforcement Learning has been used to fully optimise the\nbranching strategy. Computational experiments show that our method is\nappropriate and able to generalise well to new instances.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:15:48 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Etheve", "Marc", ""], ["Al\u00e8s", "Zacharie", ""], ["Bissuel", "C\u00f4me", ""], ["Juan", "Olivier", ""], ["Kedad-Sidhoum", "Safia", ""]]}, {"id": "2005.10036", "submitter": "Connor Coley", "authors": "Lior Hirschfeld, Kyle Swanson, Kevin Yang, Regina Barzilay, Connor W.\n  Coley", "title": "Uncertainty Quantification Using Neural Networks for Molecular Property\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification (UQ) is an important component of molecular\nproperty prediction, particularly for drug discovery applications where model\npredictions direct experimental design and where unanticipated imprecision\nwastes valuable time and resources. The need for UQ is especially acute for\nneural models, which are becoming increasingly standard yet are challenging to\ninterpret. While several approaches to UQ have been proposed in the literature,\nthere is no clear consensus on the comparative performance of these models. In\nthis paper, we study this question in the context of regression tasks. We\nsystematically evaluate several methods on five benchmark datasets using\nmultiple complementary performance metrics. Our experiments show that none of\nthe methods we tested is unequivocally superior to all others, and none\nproduces a particularly reliable ranking of errors across multiple datasets.\nWhile we believe these results show that existing UQ methods are not sufficient\nfor all common use-cases and demonstrate the benefits of further research, we\nconclude with a practical recommendation as to which existing techniques seem\nto perform well relative to others.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:31:20 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Hirschfeld", "Lior", ""], ["Swanson", "Kyle", ""], ["Yang", "Kevin", ""], ["Barzilay", "Regina", ""], ["Coley", "Connor W.", ""]]}, {"id": "2005.10039", "submitter": "Hinrikus Wolf", "authors": "Tobias Schumacher, Hinrikus Wolf, Martin Ritzert, Florian Lemmerich,\n  Jan Bachmann, Florian Frantzen, Max Klabunde, Martin Grohe, Markus Strohmaier", "title": "The Effects of Randomness on the Stability of Node Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We systematically evaluate the (in-)stability of state-of-the-art node\nembedding algorithms due to randomness, i.e., the random variation of their\noutcomes given identical algorithms and graphs. We apply five node embeddings\nalgorithms---HOPE, LINE, node2vec, SDNE, and GraphSAGE---to synthetic and\nempirical graphs and assess their stability under randomness with respect to\n(i) the geometry of embedding spaces as well as (ii) their performance in\ndownstream tasks. We find significant instabilities in the geometry of\nembedding spaces independent of the centrality of a node. In the evaluation of\ndownstream tasks, we find that the accuracy of node classification seems to be\nunaffected by random seeding while the actual classification of nodes can vary\nsignificantly. This suggests that instability effects need to be taken into\naccount when working with node embeddings. Our work is relevant for researchers\nand engineers interested in the effectiveness, reliability, and reproducibility\nof node embedding approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:36:09 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Schumacher", "Tobias", ""], ["Wolf", "Hinrikus", ""], ["Ritzert", "Martin", ""], ["Lemmerich", "Florian", ""], ["Bachmann", "Jan", ""], ["Frantzen", "Florian", ""], ["Klabunde", "Max", ""], ["Grohe", "Martin", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2005.10040", "submitter": "Antoine Blanchard", "authors": "Antoine Blanchard and Themistoklis Sapsis", "title": "Informative Path Planning for Extreme Anomaly Detection in Environment\n  Exploration and Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unmanned autonomous vehicle (UAV) is sent on a mission to explore and\nreconstruct an unknown environment from a series of measurements collected by\nBayesian optimization. The success of the mission is judged by the UAV's\nability to faithfully reconstruct any anomalous features present in the\nenvironment, with emphasis on the extremes (e.g., extreme topographic\ndepressions or abnormal chemical concentrations). We show that the criteria\ncommonly used for determining which locations the UAV should visit are\nill-suited for this task. We introduce a number of novel criteria that guide\nthe UAV towards regions of strong anomalies by leveraging previously collected\ninformation in a mathematically elegant and computationally tractable manner.\nWe demonstrate superiority of the proposed approach in several applications,\nincluding reconstruction of seafloor topography from real-world bathymetry\ndata, as well as tracking of dynamic anomalies. A particularly attractive\nproperty of our approach is its ability to overcome adversarial conditions,\nthat is, situations in which prior beliefs about the locations of the extremes\nare imprecise or erroneous.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:36:22 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 01:10:06 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 23:56:02 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Blanchard", "Antoine", ""], ["Sapsis", "Themistoklis", ""]]}, {"id": "2005.10049", "submitter": "Wilfried Michel", "authors": "Wilfried Michel and Ralf Schl\\\"uter and Hermann Ney", "title": "Early Stage LM Integration Using Local and Global Log-Linear Combination", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models with an implicit alignment mechanism (e.g.\nattention) are closing the performance gap towards traditional hybrid hidden\nMarkov models (HMM) for the task of automatic speech recognition. One important\nfactor to improve word error rate in both cases is the use of an external\nlanguage model (LM) trained on large text-only corpora. Language model\nintegration is straightforward with the clear separation of acoustic model and\nlanguage model in classical HMM-based modeling. In contrast, multiple\nintegration schemes have been proposed for attention models. In this work, we\npresent a novel method for language model integration into implicit-alignment\nbased sequence-to-sequence models. Log-linear model combination of acoustic and\nlanguage model is performed with a per-token renormalization. This allows us to\ncompute the full normalization term efficiently both in training and in\ntesting. This is compared to a global renormalization scheme which is\nequivalent to applying shallow fusion in training. The proposed methods show\ngood improvements over standard model combination (shallow fusion) on our\nstate-of-the-art Librispeech system. Furthermore, the improvements are\npersistent even if the LM is exchanged for a more powerful one after training.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:49:55 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Michel", "Wilfried", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.10050", "submitter": "Samaneh Abbasi Sureshjani", "authors": "Samaneh Abbasi-Sureshjani, Ralf Raumanns, Britt E. J. Michels, Gerard\n  Schouten, Veronika Cheplygina", "title": "Risk of Training Diagnostic Algorithms on Data with Demographic Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the critical challenges in machine learning applications is to have\nfair predictions. There are numerous recent examples in various domains that\nconvincingly show that algorithms trained with biased datasets can easily lead\nto erroneous or discriminatory conclusions. This is even more crucial in\nclinical applications where the predictive algorithms are designed mainly based\non a limited or given set of medical images and demographic variables such as\nage, sex and race are not taken into account. In this work, we conduct a survey\nof the MICCAI 2018 proceedings to investigate the common practice in medical\nimage analysis applications. Surprisingly, we found that papers focusing on\ndiagnosis rarely describe the demographics of the datasets used, and the\ndiagnosis is purely based on images. In order to highlight the importance of\nconsidering the demographics in diagnosis tasks, we used a publicly available\ndataset of skin lesions. We then demonstrate that a classifier with an overall\narea under the curve (AUC) of 0.83 has variable performance between 0.76 and\n0.91 on subgroups based on age and sex, even though the training set was\nrelatively balanced. Moreover, we show that it is possible to learn unbiased\nfeatures by explicitly using demographic variables in an adversarial training\nsetup, which leads to balanced scores per subgroups. Finally, we discuss the\nimplications of these results and provide recommendations for further research.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:51:01 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 11:33:59 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Abbasi-Sureshjani", "Samaneh", ""], ["Raumanns", "Ralf", ""], ["Michels", "Britt E. J.", ""], ["Schouten", "Gerard", ""], ["Cheplygina", "Veronika", ""]]}, {"id": "2005.10052", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan, Erik B. Dam, Nicki S. Detlefsen, Sofus Rischel,\n  Kaining Sheng, Mads Nielsen, Akshay Pai", "title": "Lung Segmentation from Chest X-rays using Variational Data Imputation", "comments": "Accepted to be presented at the first Workshop on the Art of Learning\n  with Missing Values (Artemiss) hosted by the 37th International Conference on\n  Machine Learning (ICML). Source code, training data and the trained models\n  are available here: https://github.com/raghavian/lungVAE/", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pulmonary opacification is the inflammation in the lungs caused by many\nrespiratory ailments, including the novel corona virus disease 2019 (COVID-19).\nChest X-rays (CXRs) with such opacifications render regions of lungs\nimperceptible, making it difficult to perform automated image analysis on them.\nIn this work, we focus on segmenting lungs from such abnormal CXRs as part of a\npipeline aimed at automated risk scoring of COVID-19 from CXRs. We treat the\nhigh opacity regions as missing data and present a modified CNN-based image\nsegmentation network that utilizes a deep generative model for data imputation.\nWe train this model on normal CXRs with extensive data augmentation and\ndemonstrate the usefulness of this model to extend to cases with extreme\nabnormalities.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:52:03 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 06:12:42 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Selvan", "Raghavendra", ""], ["Dam", "Erik B.", ""], ["Detlefsen", "Nicki S.", ""], ["Rischel", "Sofus", ""], ["Sheng", "Kaining", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""]]}, {"id": "2005.10085", "submitter": "Tijs Slaats", "authors": "Christoffer Olling Back, Tijs Slaats, Thomas Troels Hildebrandt,\n  Morten Marquard", "title": "DisCoveR: Accurate & Efficient Discovery of Declarative Process Models", "comments": "Author's original version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Declarative process modeling formalisms - which capture high-level process\nconstraints - have seen growing interest, especially for modeling flexible\nprocesses. This paper presents DisCoveR, an extremely efficient and accurate\ndeclarative miner for learning Dynamic Condition Response (DCR) Graphs from\nevent logs. We precisely formalize the algorithm, describe a highly efficient\nbit vector implementation and rigorously evaluate performance against two other\ndeclarative miners, representing the state-of-the-art in Declare and DCR Graphs\nmining. DisCoveR outperforms each of these w.r.t. a binary classification task,\nachieving an average accuracy of 96.2% in the Process Discovery Contest 2019.\nDue to its linear time complexity, DisCoveR also achieves run-times 1-2 orders\nof magnitude below its declarative counterparts. Finally, we show how the miner\nhas been integrated in a state-of-the-art declarative process modeling\nframework as a model recommendation tool, discuss how discovery can play an\nintegral part of the modeling task and report on how the integration has\nimproved the modeling experience of end-users.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 14:48:33 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Back", "Christoffer Olling", ""], ["Slaats", "Tijs", ""], ["Hildebrandt", "Thomas Troels", ""], ["Marquard", "Morten", ""]]}, {"id": "2005.10087", "submitter": "Guillaume Ginolhac", "authors": "Florent Bouchard, Ammar Mian, Jialun Zhou, Salem Said, Guillaume\n  Ginolhac, and Yannick Berthoumieu", "title": "Riemannian geometry for Compound Gaussian distributions: application to\n  recursive change detection", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new Riemannian geometry for the Compound Gaussian distribution is proposed.\nIn particular, the Fisher information metric is obtained, along with\ncorresponding geodesics and distance function. This new geometry is applied on\na change detection problem on Multivariate Image Times Series: a recursive\napproach based on Riemannian optimization is developed. As shown on simulated\ndata, it allows to reach optimal performance while being computationally more\nefficient.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 14:51:09 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Bouchard", "Florent", ""], ["Mian", "Ammar", ""], ["Zhou", "Jialun", ""], ["Said", "Salem", ""], ["Ginolhac", "Guillaume", ""], ["Berthoumieu", "Yannick", ""]]}, {"id": "2005.10092", "submitter": "Matteo Fasiolo", "authors": "Christian Capezza, Biagio Palumbo, Yannig Goude, Simon N. Wood and\n  Matteo Fasiolo", "title": "Additive stacking for disaggregate electricity demand forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future grid management systems will coordinate distributed production and\nstorage resources to manage, in a cost effective fashion, the increased load\nand variability brought by the electrification of transportation and by a\nhigher share of weather dependent production. Electricity demand forecasts at a\nlow level of aggregation will be key inputs for such systems. We focus on\nforecasting demand at the individual household level, which is more challenging\nthan forecasting aggregate demand, due to the lower signal-to-noise ratio and\nto the heterogeneity of consumption patterns across households. We propose a\nnew ensemble method for probabilistic forecasting, which borrows strength\nacross the households while accommodating their individual idiosyncrasies. In\nparticular, we develop a set of models or 'experts' which capture different\ndemand dynamics and we fit each of them to the data from each household. Then\nwe construct an aggregation of experts where the ensemble weights are estimated\non the whole data set, the main innovation being that we let the weights vary\nwith the covariates by adopting an additive model structure. In particular, the\nproposed aggregation method is an extension of regression stacking (Breiman,\n1996) where the mixture weights are modelled using linear combinations of\nparametric, smooth or random effects. The methods for building and fitting\nadditive stacking models are implemented by the gamFactory R package, available\nat https://github.com/mfasiolo/gamFactory.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 14:54:22 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Capezza", "Christian", ""], ["Palumbo", "Biagio", ""], ["Goude", "Yannig", ""], ["Wood", "Simon N.", ""], ["Fasiolo", "Matteo", ""]]}, {"id": "2005.10099", "submitter": "Yuhao Zhou", "authors": "Yuhao Zhou, Jiaxin Shi, Jun Zhu", "title": "Nonparametric Score Estimators", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the score, i.e., the gradient of log density function, from a set\nof samples generated by an unknown distribution is a fundamental task in\ninference and learning of probabilistic models that involve flexible yet\nintractable densities. Kernel estimators based on Stein's methods or score\nmatching have shown promise, however their theoretical properties and\nrelationships have not been fully-understood. We provide a unifying view of\nthese estimators under the framework of regularized nonparametric regression.\nIt allows us to analyse existing estimators and construct new ones with\ndesirable properties by choosing different hypothesis spaces and regularizers.\nA unified convergence analysis is provided for such estimators. Finally, we\npropose score estimators based on iterative regularization that enjoy\ncomputational benefits from curl-free kernels and fast convergence.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:01:03 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 06:41:58 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Zhou", "Yuhao", ""], ["Shi", "Jiaxin", ""], ["Zhu", "Jun", ""]]}, {"id": "2005.10111", "submitter": "Stephan Rabanser", "authors": "Stephan Rabanser, Tim Januschowski, Valentin Flunkert, David Salinas,\n  Jan Gasthaus", "title": "The Effectiveness of Discretization in Forecasting: An Empirical Study\n  on Neural Time Series Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series modeling techniques based on deep learning have seen many\nadvancements in recent years, especially in data-abundant settings and with the\ncentral aim of learning global models that can extract patterns across multiple\ntime series. While the crucial importance of appropriate data pre-processing\nand scaling has often been noted in prior work, most studies focus on improving\nmodel architectures. In this paper we empirically investigate the effect of\ndata input and output transformations on the predictive performance of several\nneural forecasting architectures. In particular, we investigate the\neffectiveness of several forms of data binning, i.e. converting real-valued\ntime series into categorical ones, when combined with feed-forward, recurrent\nneural networks, and convolution-based sequence models. In many non-forecasting\napplications where these models have been very successful, the model inputs and\noutputs are categorical (e.g. words from a fixed vocabulary in natural language\nprocessing applications or quantized pixel color intensities in computer\nvision). For forecasting applications, where the time series are typically\nreal-valued, various ad-hoc data transformations have been proposed, but have\nnot been systematically compared. To remedy this, we evaluate the forecasting\naccuracy of instances of the aforementioned model classes when combined with\ndifferent types of data scaling and binning. We find that binning almost always\nimproves performance (compared to using normalized real-valued inputs), but\nthat the particular type of binning chosen is of lesser importance.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:09:28 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Rabanser", "Stephan", ""], ["Januschowski", "Tim", ""], ["Flunkert", "Valentin", ""], ["Salinas", "David", ""], ["Gasthaus", "Jan", ""]]}, {"id": "2005.10114", "submitter": "Yuanfei Luo", "authors": "Yuanfei Luo, Hao Zhou, Weiwei Tu, Yuqiang Chen, Wenyuan Dai and Qiang\n  Yang", "title": "Network On Network for Tabular Data Classification in Real-world\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1145/3397271.3401437", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabular data is the most common data format adopted by our customers ranging\nfrom retail, finance to E-commerce, and tabular data classification plays an\nessential role to their businesses. In this paper, we present Network On\nNetwork (NON), a practical tabular data classification model based on deep\nneural network to provide accurate predictions. Various deep methods have been\nproposed and promising progress has been made. However, most of them use\noperations like neural network and factorization machines to fuse the\nembeddings of different features directly, and linearly combine the outputs of\nthose operations to get the final prediction. As a result, the intra-field\ninformation and the non-linear interactions between those operations (e.g.\nneural network and factorization machines) are ignored. Intra-field information\nis the information that features inside each field belong to the same field.\nNON is proposed to take full advantage of intra-field information and\nnon-linear interactions. It consists of three components: field-wise network at\nthe bottom to capture the intra-field information, across field network in the\nmiddle to choose suitable operations data-drivenly, and operation fusion\nnetwork on the top to fuse outputs of the chosen operations deeply. Extensive\nexperiments on six real-world datasets demonstrate NON can outperform the\nstate-of-the-art models significantly. Furthermore, both qualitative and\nquantitative study of the features in the embedding space show NON can capture\nintra-field information effectively.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:10:42 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 07:23:25 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Luo", "Yuanfei", ""], ["Zhou", "Hao", ""], ["Tu", "Weiwei", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Yang", "Qiang", ""]]}, {"id": "2005.10175", "submitter": "Shaofeng Zou", "authors": "Yue Wang and Shaofeng Zou", "title": "Finite-sample Analysis of Greedy-GQ with Linear Function Approximation\n  under Markovian Noise", "comments": "UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy-GQ is an off-policy two timescale algorithm for optimal control in\nreinforcement learning. This paper develops the first finite-sample analysis\nfor the Greedy-GQ algorithm with linear function approximation under Markovian\nnoise. Our finite-sample analysis provides theoretical justification for\nchoosing stepsizes for this two timescale algorithm for faster convergence in\npractice, and suggests a trade-off between the convergence rate and the quality\nof the obtained policy. Our paper extends the finite-sample analyses of two\ntimescale reinforcement learning algorithms from policy evaluation to optimal\ncontrol, which is of more practical interest. Specifically, in contrast to\nexisting finite-sample analyses for two timescale methods, e.g., GTD, GTD2 and\nTDC, where their objective functions are convex, the objective function of the\nGreedy-GQ algorithm is non-convex. Moreover, the Greedy-GQ algorithm is also\nnot a linear two-timescale stochastic approximation algorithm. Our techniques\nin this paper provide a general framework for finite-sample analysis of\nnon-convex value-based reinforcement learning algorithms for optimal control.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:35:19 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Wang", "Yue", ""], ["Zou", "Shaofeng", ""]]}, {"id": "2005.10190", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Feature Purification: How Adversarial Training Performs Robust Deep\n  Learning", "comments": "v2 and V3 polish writing and experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the empirical success of using Adversarial Training to defend deep\nlearning models against adversarial perturbations, so far, it still remains\nrather unclear what the principles are behind the existence of adversarial\nperturbations, and what adversarial training does to the neural network to\nremove them.\n  In this paper, we present a principle that we call Feature Purification,\nwhere we show one of the causes of the existence of adversarial examples is the\naccumulation of certain small dense mixtures in the hidden weights during the\ntraining process of a neural network; and more importantly, one of the goals of\nadversarial training is to remove such mixtures to purify hidden weights. We\npresent both experiments on the CIFAR-10 dataset to illustrate this principle,\nand a theoretical result proving that for certain natural classification tasks,\ntraining a two-layer neural network with ReLU activation using randomly\ninitialized gradient descent indeed satisfies this principle.\n  Technically, we give, to the best of our knowledge, the first result proving\nthat the following two can hold simultaneously for training a neural network\nwith ReLU activation. (1) Training over the original data is indeed non-robust\nto small adversarial perturbations of some radius. (2) Adversarial training,\neven with an empirical perturbation algorithm such as FGM, can in fact be\nprovably robust against ANY perturbations of the same radius. Finally, we also\nprove a complexity lower bound, showing that low complexity models such as\nlinear classifiers, low-degree polynomials, or even the neural tangent kernel\nfor this network, CANNOT defend against perturbations of this same radius, no\nmatter what algorithms are used to train them.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:56:08 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 08:09:49 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 19:10:04 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2005.10203", "submitter": "Wei Jin", "authors": "Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, Jiliang Tang", "title": "Graph Structure Learning for Robust Graph Neural Networks", "comments": "Accepted by KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are powerful tools in representation learning\nfor graphs. However, recent studies show that GNNs are vulnerable to\ncarefully-crafted perturbations, called adversarial attacks. Adversarial\nattacks can easily fool GNNs in making predictions for downstream tasks. The\nvulnerability to adversarial attacks has raised increasing concerns for\napplying GNNs in safety-critical applications. Therefore, developing robust\nalgorithms to defend adversarial attacks is of great significance. A natural\nidea to defend adversarial attacks is to clean the perturbed graph. It is\nevident that real-world graphs share some intrinsic properties. For example,\nmany real-world graphs are low-rank and sparse, and the features of two\nadjacent nodes tend to be similar. In fact, we find that adversarial attacks\nare likely to violate these graph properties. Therefore, in this paper, we\nexplore these properties to defend adversarial attacks on graphs. In\nparticular, we propose a general framework Pro-GNN, which can jointly learn a\nstructural graph and a robust graph neural network model from the perturbed\ngraph guided by these properties. Extensive experiments on real-world graphs\ndemonstrate that the proposed framework achieves significantly better\nperformance compared with the state-of-the-art defense methods, even when the\ngraph is heavily perturbed. We release the implementation of Pro-GNN to our\nDeepRobust repository for adversarial attacks and defenses (footnote:\nhttps://github.com/DSE-MSU/DeepRobust). The specific experimental settings to\nreproduce our results can be found in https://github.com/ChandlerBang/Pro-GNN.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:07:05 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 03:37:39 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 21:57:09 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Jin", "Wei", ""], ["Ma", "Yao", ""], ["Liu", "Xiaorui", ""], ["Tang", "Xianfeng", ""], ["Wang", "Suhang", ""], ["Tang", "Jiliang", ""]]}, {"id": "2005.10211", "submitter": "Benedict Wilkins", "authors": "Benedict Wilkins, Chris Watkins, Kostas Stathis", "title": "A Metric Learning Approach to Anomaly Detection in Video Games", "comments": "4 pages, 3 figures, Accepted in IEEE 2020 CONFERENCE ON GAMES (COG),\n  Dataset https://www.kaggle.com/benedictwilkinsai/atari-anomaly-dataset-aad ,\n  Code and pre-trained models https://github.com/BenedictWilkinsAI/S3N", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the aim of designing automated tools that assist in the video game\nquality assurance process, we frame the problem of identifying bugs in video\ngames as an anomaly detection (AD) problem. We develop State-State Siamese\nNetworks (S3N) as an efficient deep metric learning approach to AD in this\ncontext and explore how it may be used as part of an automated testing tool.\nFinally, we show by empirical evaluation on a series of Atari games, that S3N\nis able to learn a meaningful embedding, and consequently is able to identify\nvarious common types of video game bugs.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:23:21 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 13:27:00 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Wilkins", "Benedict", ""], ["Watkins", "Chris", ""], ["Stathis", "Kostas", ""]]}, {"id": "2005.10224", "submitter": "Nicholas H. Nelsen", "authors": "Nicholas H. Nelsen and Andrew M. Stuart", "title": "The Random Feature Model for Input-Output Maps between Banach Spaces", "comments": "To appear in SIAM Journal on Scientific Computing; 32 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well known to the machine learning community, the random feature model is a\nparametric approximation to kernel interpolation or regression methods. It is\ntypically used to approximate functions mapping a finite-dimensional input\nspace to the real line. In this paper, we instead propose a methodology for use\nof the random feature model as a data-driven surrogate for operators that map\nan input Banach space to an output Banach space. Although the methodology is\nquite general, we consider operators defined by partial differential equations\n(PDEs); here, the inputs and outputs are themselves functions, with the input\nparameters being functions required to specify the problem, such as initial\ndata or coefficients, and the outputs being solutions of the problem. Upon\ndiscretization, the model inherits several desirable attributes from this\ninfinite-dimensional viewpoint, including mesh-invariant approximation error\nwith respect to the true PDE solution map and the capability to be trained at\none mesh resolution and then deployed at different mesh resolutions. We view\nthe random feature model as a non-intrusive data-driven emulator, provide a\nmathematical framework for its interpretation, and demonstrate its ability to\nefficiently and accurately approximate the nonlinear parameter-to-solution maps\nof two prototypical PDEs arising in physical science and engineering\napplications: viscous Burgers' equation and a variable coefficient elliptic\nequation.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:41:40 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 22:47:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nelsen", "Nicholas H.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "2005.10242", "submitter": "Tongzhou Wang", "authors": "Tongzhou Wang, Phillip Isola", "title": "Understanding Contrastive Representation Learning through Alignment and\n  Uniformity on the Hypersphere", "comments": "International Conference on Machine Learning (ICML), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive representation learning has been outstandingly successful in\npractice. In this work, we identify two key properties related to the\ncontrastive loss: (1) alignment (closeness) of features from positive pairs,\nand (2) uniformity of the induced distribution of the (normalized) features on\nthe hypersphere. We prove that, asymptotically, the contrastive loss optimizes\nthese properties, and analyze their positive effects on downstream tasks.\nEmpirically, we introduce an optimizable metric to quantify each property.\nExtensive experiments on standard vision and language datasets confirm the\nstrong agreement between both metrics and downstream task performance.\nRemarkably, directly optimizing for these two metrics leads to representations\nwith comparable or better performance at downstream tasks than contrastive\nlearning.\n  Project Page: https://ssnl.github.io/hypersphere\n  Code: https://github.com/SsnL/align_uniform ,\nhttps://github.com/SsnL/moco_align_uniform\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:59:57 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 19:20:12 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 05:55:54 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 05:16:32 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 04:47:28 GMT"}, {"version": "v6", "created": "Mon, 24 Aug 2020 23:22:08 GMT"}, {"version": "v7", "created": "Sun, 1 Nov 2020 19:27:13 GMT"}, {"version": "v8", "created": "Sat, 7 Nov 2020 04:28:08 GMT"}, {"version": "v9", "created": "Tue, 10 Nov 2020 07:05:17 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Tongzhou", ""], ["Isola", "Phillip", ""]]}, {"id": "2005.10247", "submitter": "Alexander Robey", "authors": "Alexander Robey, Hamed Hassani, George J. Pappas", "title": "Model-Based Robust Deep Learning: Generalizing to Natural,\n  Out-of-Distribution Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has resulted in major breakthroughs in many application\ndomains, the frameworks commonly used in deep learning remain fragile to\nartificially-crafted and imperceptible changes in the data. In response to this\nfragility, adversarial training has emerged as a principled approach for\nenhancing the robustness of deep learning with respect to norm-bounded\nperturbations. However, there are other sources of fragility for deep learning\nthat are arguably more common and less thoroughly studied. Indeed, natural\nvariation such as lighting or weather conditions can significantly degrade the\naccuracy of trained neural networks, proving that such natural variation\npresents a significant challenge for deep learning.\n  In this paper, we propose a paradigm shift from perturbation-based\nadversarial robustness toward model-based robust deep learning. Our objective\nis to provide general training algorithms that can be used to train deep neural\nnetworks to be robust against natural variation in data. Critical to our\nparadigm is first obtaining a model of natural variation which can be used to\nvary data over a range of natural conditions. Such models may be either known a\npriori or else learned from data. In the latter case, we show that deep\ngenerative models can be used to learn models of natural variation that are\nconsistent with realistic conditions. We then exploit such models in three\nnovel model-based robust training algorithms in order to enhance the robustness\nof deep learning with respect to the given model. Our extensive experiments\nshow that across a variety of naturally-occurring conditions and across various\ndatasets, deep neural networks trained with our model-based algorithms\nsignificantly outperform both standard deep learning algorithms as well as\nnorm-bounded robust deep learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:46:31 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 13:20:37 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Robey", "Alexander", ""], ["Hassani", "Hamed", ""], ["Pappas", "George J.", ""]]}, {"id": "2005.10284", "submitter": "Arash Rahnama", "authors": "Arash Rahnama and Andrew Tseng", "title": "An Adversarial Approach for Explaining the Predictions of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been successfully applied to a wide range of\napplications including computer vision, natural language processing, and speech\nrecognition. A successful implementation of these models however, usually\nrelies on deep neural networks (DNNs) which are treated as opaque black-box\nsystems due to their incomprehensible complexity and intricate internal\nmechanism. In this work, we present a novel algorithm for explaining the\npredictions of a DNN using adversarial machine learning. Our approach\nidentifies the relative importance of input features in relation to the\npredictions based on the behavior of an adversarial attack on the DNN. Our\nalgorithm has the advantage of being fast, consistent, and easy to implement\nand interpret. We present our detailed analysis that demonstrates how the\nbehavior of an adversarial attack, given a DNN and a task, stays consistent for\nany input test data point proving the generality of our approach. Our analysis\nenables us to produce consistent and efficient explanations. We illustrate the\neffectiveness of our approach by conducting experiments using a variety of\nDNNs, tasks, and datasets. Finally, we compare our work with other well-known\ntechniques in the current literature.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:06:53 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 19:42:44 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 15:43:34 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 16:17:36 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Rahnama", "Arash", ""], ["Tseng", "Andrew", ""]]}, {"id": "2005.10294", "submitter": "Marko Stamenovic", "authors": "Marko Stamenovic", "title": "Towards Cover Song Detection with Siamese Convolutional Neural Networks", "comments": "Code available at\n  https://github.com/markostam/coversongs-dual-convnet", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, Stockholm, Sweden, PMLR 80, 2018", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cover song, by definition, is a new performance or recording of a\npreviously recorded, commercially released song. It may be by the original\nartist themselves or a different artist altogether and can vary from the\noriginal in unpredictable ways including key, arrangement, instrumentation,\ntimbre and more. In this work we propose a novel approach to learning audio\nrepresentations for the task of cover song detection. We train a neural\narchitecture on tens of thousands of cover-song audio clips and test it on a\nheld out set. We obtain a mean precision@1 of 65% over mini-batches, ten times\nbetter than random guessing. Our results indicate that Siamese network\nconfigurations show promise for approaching the cover song identification\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:14:41 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Stamenovic", "Marko", ""]]}, {"id": "2005.10300", "submitter": "Kyle Crandall", "authors": "Kyle Crandall and Dustin Webb", "title": "Consensus Driven Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As the complexity of our neural network models grow, so too do the data and\ncomputation requirements for successful training. One proposed solution to this\nproblem is training on a distributed network of computational devices, thus\ndistributing the computational and data storage loads. This strategy has\nalready seen some adoption by the likes of Google and other companies. In this\npaper we propose a new method of distributed, decentralized learning that\nallows a network of computation nodes to coordinate their training using\nasynchronous updates over an unreliable network while only having access to a\nlocal dataset. This is achieved by taking inspiration from Distributed\nAveraging Consensus algorithms to coordinate the various nodes. Sharing the\ninternal model instead of the training data allows the original raw data to\nremain with the computation node. The asynchronous nature and lack of\ncentralized coordination allows this paradigm to function with limited\ncommunication requirements. We demonstrate our method on the MNIST, Fashion\nMNIST, and CIFAR10 datasets. We show that our coordination method allows models\nto be learned on highly biased datasets, and in the presence of intermittent\ncommunication failure.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:24:19 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Crandall", "Kyle", ""], ["Webb", "Dustin", ""]]}, {"id": "2005.10321", "submitter": "Marko Stamenovic", "authors": "Marko Stamenovic, Jeibo Luo", "title": "Machine Identification of High Impact Research through Text and Image\n  Analysis", "comments": null, "journal-ref": "2017 IEEE Third International Conference on Multimedia Big Data\n  (BigMM)", "doi": "10.1109/BigMM.2017.63", "report-no": null, "categories": "cs.IR cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The volume of academic paper submissions and publications is growing at an\never increasing rate. While this flood of research promises progress in various\nfields, the sheer volume of output inherently increases the amount of noise. We\npresent a system to automatically separate papers with a high from those with a\nlow likelihood of gaining citations as a means to quickly find high impact,\nhigh quality research. Our system uses both a visual classifier, useful for\nsurmising a document's overall appearance, and a text classifier, for making\ncontent-informed decisions. Current work in the field focuses on small datasets\ncomposed of papers from individual conferences. Attempts to use similar\ntechniques on larger datasets generally only considers excerpts of the\ndocuments such as the abstract, potentially throwing away valuable data. We\nrectify these issues by providing a dataset composed of PDF documents and\ncitation counts spanning a decade of output within two separate academic\ndomains: computer science and medicine. This new dataset allows us to expand on\ncurrent work in the field by generalizing across time and academic domain.\nMoreover, we explore inter-domain prediction models - evaluating a classifier's\nperformance on a domain it was not trained on - to shed further insight on this\nimportant problem.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 19:12:24 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Stamenovic", "Marko", ""], ["Luo", "Jeibo", ""]]}, {"id": "2005.10335", "submitter": "Stefano Cabras", "authors": "Stefano Cabras", "title": "A Bayesian - Deep Learning model for estimating Covid-19 evolution in\n  Spain", "comments": "Related to: https://github.com/scabras/covid19-bayes-dl", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a semi-parametric approach to estimate Covid-19\n(SARS-CoV-2) evolution in Spain. Considering the sequences of 14 days\ncumulative incidence of all Spanish regions, it combines modern Deep Learning\n(DL) techniques for analyzing sequences with the usual Bayesian Poisson-Gamma\nmodel for counts. DL model provides a suitable description of observed\nsequences but no reliable uncertainty quantification around it can be obtained.\nTo overcome this we use the prediction from DL as an expert elicitation of the\nexpected number of counts along with their uncertainty and thus obtaining the\nposterior predictive distribution of counts in an orthodox Bayesian analysis\nusing the well known Poisson-Gamma model. The overall resulting model allows us\nto either predict the future evolution of the sequences on all regions, as well\nas, estimating the consequences of eventual scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 19:57:12 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 17:27:38 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Cabras", "Stefano", ""]]}, {"id": "2005.10348", "submitter": "Hiram Ponce", "authors": "Jose Roberto Ayala-Solares, Hiram Ponce", "title": "Supervised learning with artificial hydrocarbon networks: an open source\n  implementation and its applications", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial hydrocarbon networks (AHN) is a novel supervised learning method\ninspired on the structure and the inner chemical mechanisms of organic\ncompounds. As any other cutting-edge algorithm, there are two challenges to be\nfaced: time-consuming for encoding and complications to connect with other\ntechnologies. Large and open source platforms have proved to be an alternative\nsolution to the latter challenges. In that sense, this paper aims to introduce\nthe ahnr package for R that implements AHN. It provides several functions to\ncreate, train, test and visualize AHN. It also includes conventional functions\nto easily interact with the trained models. For illustration purposes, it\npresents several examples about the applications of AHN in engineering, as well\nas, the way to use it. This package is intended to be very useful for\nscientists and applied researchers interested in machine learning and data\nmodeling. Package availability is in the Comprehensive R Archive Network.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 20:40:39 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Ayala-Solares", "Jose Roberto", ""], ["Ponce", "Hiram", ""]]}, {"id": "2005.10349", "submitter": "Benjamin Dutton", "authors": "Benjamin Dutton", "title": "Adversarial Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is a statistical technique used to\nextract common information from multiple data sources or views. It has been\nused in various representation learning problems, such as dimensionality\nreduction, word embedding, and clustering. Recent work has given CCA\nprobabilistic footing in a deep learning context and uses a variational lower\nbound for the data log likelihood to estimate model parameters. Alternatively,\nadversarial techniques have arisen in recent years as a powerful alternative to\nvariational Bayesian methods in autoencoders. In this work, we explore\nstraightforward adversarial alternatives to recent work in Deep Variational CCA\n(VCCA and VCCA-Private) we call ACCA and ACCA-Private and show how these\napproaches offer a stronger and more flexible way to match the approximate\nposteriors coming from encoders to much larger classes of priors than the VCCA\nand VCCA-Private models. This allows new priors for what constitutes a good\nrepresentation, such as disentangling underlying factors of variation, to be\nmore directly pursued. We offer further analysis on the multi-level\ndisentangling properties of VCCA-Private and ACCA-Private through the use of a\nnewly designed dataset we call Tangled MNIST. We also design a validation\ncriteria for these models that is theoretically grounded, task-agnostic, and\nworks well in practice. Lastly, we fill a minor research gap by deriving an\nadditional variational lower bound for VCCA that allows the representation to\nuse view-specific information from both input views.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 20:46:35 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 21:31:21 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Dutton", "Benjamin", ""]]}, {"id": "2005.10374", "submitter": "Jussi Leinonen", "authors": "Jussi Leinonen, Daniele Nerini, Alexis Berne", "title": "Stochastic Super-Resolution for Downscaling Time-Evolving Atmospheric\n  Fields with a Generative Adversarial Network", "comments": "Accepted for publication in IEEE Transactions in Geoscience and\n  Remote Sensing", "journal-ref": "IEEE Transactions on Geoscience and Remote Sensing, 2020", "doi": "10.1109/TGRS.2020.3032790", "report-no": null, "categories": "eess.IV cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have been recently adopted for\nsuper-resolution, an application closely related to what is referred to as\n\"downscaling\" in the atmospheric sciences: improving the spatial resolution of\nlow-resolution images. The ability of conditional GANs to generate an ensemble\nof solutions for a given input lends itself naturally to stochastic\ndownscaling, but the stochastic nature of GANs is not usually considered in\nsuper-resolution applications. Here, we introduce a recurrent, stochastic\nsuper-resolution GAN that can generate ensembles of time-evolving\nhigh-resolution atmospheric fields for an input consisting of a low-resolution\nsequence of images of the same field. We test the GAN using two datasets, one\nconsisting of radar-measured precipitation from Switzerland, the other of cloud\noptical thickness derived from the Geostationary Earth Observing Satellite 16\n(GOES-16). We find that the GAN can generate realistic, temporally consistent\nsuper-resolution sequences for both datasets. The statistical properties of the\ngenerated ensemble are analyzed using rank statistics, a method adapted from\nensemble weather forecasting; these analyses indicate that the GAN produces\nclose to the correct amount of variability in its outputs. As the GAN generator\nis fully convolutional, it can be applied after training to input images larger\nthan the images used to train it. It is also able to generate time series much\nlonger than the training sequences, as demonstrated by applying the generator\nto a three-month dataset of the precipitation radar data. The source code to\nour GAN is available at https://github.com/jleinonen/downscaling-rnn-gan.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 22:06:52 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 13:45:17 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 14:41:17 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 14:28:34 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Leinonen", "Jussi", ""], ["Nerini", "Daniele", ""], ["Berne", "Alexis", ""]]}, {"id": "2005.10390", "submitter": "Yusuke Yasuda", "authors": "Yusuke Yasuda, Xin Wang, Junichi Yamagishi", "title": "Investigation of learning abilities on linguistic features in\n  sequence-to-sequence text-to-speech synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence-to-sequence text-to-speech synthesis (TTS) can produce\nhigh-quality speech directly from text or simple linguistic features such as\nphonemes. Unlike traditional pipeline TTS, the neural sequence-to-sequence TTS\ndoes not require manually annotated and complicated linguistic features such as\npart-of-speech tags and syntactic structures for system training. However, it\nmust be carefully designed and well optimized so that it can implicitly extract\nuseful linguistic features from the input features. In this paper we\ninvestigate under what conditions the neural sequence-to-sequence TTS can work\nwell in Japanese and English along with comparisons with deep neural network\n(DNN) based pipeline TTS systems. Unlike past comparative studies, the pipeline\nsystems also use autoregressive probabilistic modeling and a neural vocoder. We\ninvestigated systems from three aspects: a) model architecture, b) model\nparameter size, and c) language. For the model architecture aspect, we adopt\nmodified Tacotron systems that we previously proposed and their variants using\nan encoder from Tacotron or Tacotron2. For the model parameter size aspect, we\ninvestigate two model parameter sizes. For the language aspect, we conduct\nlistening tests in both Japanese and English to see if our findings can be\ngeneralized across languages. Our experiments suggest that a) a neural\nsequence-to-sequence TTS system should have a sufficient number of model\nparameters to produce high quality speech, b) it should also use a powerful\nencoder when it takes characters as inputs, and c) the encoder still has a room\nfor improvement and needs to have an improved architecture to learn\nsupra-segmental features more appropriately.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 23:26:14 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 04:18:56 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Yasuda", "Yusuke", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "2005.10391", "submitter": "Caio Souza", "authors": "Caio Souza and Luiz Velho", "title": "Deep Reinforcement Learning for High Level Character Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the use of traditional animations, heuristic\nbehavior and reinforcement learning in the creation of intelligent characters\nfor computational media. The traditional animation and heuristic gives artistic\ncontrol over the behavior while the reinforcement learning adds generalization.\nThe use case presented is a dog character with a high-level controller in a 3D\nenvironment which is built around the desired behaviors to be learned, such as\nfetching an item. As the development of the environment is the key for\nlearning, further analysis is conducted of how to build those learning\nenvironments, the effects of environment and agent modeling choices, training\nprocedures and generalization of the learned behavior. This analysis builds\ninsight of the aforementioned factors and may serve as guide in the development\nof environments in general.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 23:32:19 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Souza", "Caio", ""], ["Velho", "Luiz", ""]]}, {"id": "2005.10400", "submitter": "Zhichao Jiang", "authors": "Kosuke Imai, Zhichao Jiang", "title": "Principal Fairness for Human and Algorithmic Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the concept of principal stratification from the causal inference\nliterature, we introduce a new notion of fairness, called principal fairness,\nfor human and algorithmic decision-making. The key idea is that one should not\ndiscriminate among individuals who would be similarly affected by the decision.\nUnlike the existing statistical definitions of fairness, principal fairness\nexplicitly accounts for the fact that individuals can be impacted by the\ndecision. We propose an axiomatic assumption that all groups are created equal.\nThis assumption is motivated by a belief that protected attributes such as race\nand gender should have no direct causal effects on potential outcomes. Under\nthis assumption, we show that principal fairness implies all three existing\nstatistical fairness criteria once we account for relevant covariates. This\nresult also highlights the essential role of conditioning covariates in\nresolving the previously recognized tradeoffs between the existing statistical\nfairness criteria. Finally, we discuss how to empirically choose conditioning\ncovariates and then evaluate the principal fairness of a particular decision.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 00:24:54 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 03:48:41 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 00:51:42 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 02:25:12 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Imai", "Kosuke", ""], ["Jiang", "Zhichao", ""]]}, {"id": "2005.10402", "submitter": "Fanglin Chen", "authors": "Fanglin Chen, Xiao Liu, Davide Proserpio, Isamar Troncoso, Feiyu Xiong", "title": "Studying Product Competition Using Representation Learning", "comments": "8 pages, to be published in SIGIR '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying competition and market structure at the product level instead of\nbrand level can provide firms with insights on cannibalization and product line\noptimization. However, it is computationally challenging to analyze\nproduct-level competition for the millions of products available on e-commerce\nplatforms. We introduce Product2Vec, a method based on the representation\nlearning algorithm Word2Vec, to study product-level competition, when the\nnumber of products is large. The proposed model takes shopping baskets as\ninputs and, for every product, generates a low-dimensional embedding that\npreserves important product information. In order for the product embeddings to\nbe useful for firm strategic decision making, we leverage economic theories and\ncausal inference to propose two modifications to Word2Vec. First of all, we\ncreate two measures, complementarity and exchangeability, that allow us to\ndetermine whether product pairs are complements or substitutes. Second, we\ncombine these vectors with random utility-based choice models to forecast\ndemand. To accurately estimate price elasticities, i.e., how demand responds to\nchanges in price, we modify Word2Vec by removing the influence of price from\nthe product vectors. We show that, compared with state-of-the-art models, our\napproach is faster, and can produce more accurate demand forecasts and price\nelasticities.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 00:36:13 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Chen", "Fanglin", ""], ["Liu", "Xiao", ""], ["Proserpio", "Davide", ""], ["Troncoso", "Isamar", ""], ["Xiong", "Feiyu", ""]]}, {"id": "2005.10418", "submitter": "Liam Schramm", "authors": "Liam Schramm, Avishai Sintov, and Abdeslam Boularias", "title": "Learning to Transfer Dynamic Models of Underactuated Soft Robotic Hands", "comments": "ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a popular approach to bypassing data limitations in one\ndomain by leveraging data from another domain. This is especially useful in\nrobotics, as it allows practitioners to reduce data collection with physical\nrobots, which can be time-consuming and cause wear and tear. The most common\nway of doing this with neural networks is to take an existing neural network,\nand simply train it more with new data. However, we show that in some\nsituations this can lead to significantly worse performance than simply using\nthe transferred model without adaptation. We find that a major cause of these\nproblems is that models trained on small amounts of data can have chaotic or\ndivergent behavior in some regions. We derive an upper bound on the Lyapunov\nexponent of a trained transition model, and demonstrate two approaches that\nmake use of this insight. Both show significant improvement over traditional\nfine-tuning. Experiments performed on real underactuated soft robotic hands\nclearly demonstrate the capability to transfer a dynamic model from one hand to\nanother.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:46:59 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Schramm", "Liam", ""], ["Sintov", "Avishai", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "2005.10419", "submitter": "Aditya Menon", "authors": "Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, Seungyeon\n  Kim, and Sanjiv Kumar", "title": "Why distillation helps: a statistical perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge distillation is a technique for improving the performance of a\nsimple \"student\" model by replacing its one-hot training labels with a\ndistribution over labels obtained from a complex \"teacher\" model. While this\nsimple approach has proven widely effective, a basic question remains\nunresolved: why does distillation help? In this paper, we present a statistical\nperspective on distillation which addresses this question, and provides a novel\nconnection to extreme multiclass retrieval techniques. Our core observation is\nthat the teacher seeks to estimate the underlying (Bayes) class-probability\nfunction. Building on this, we establish a fundamental bias-variance tradeoff\nin the student's objective: this quantifies how approximate knowledge of these\nclass-probabilities can significantly aid learning. Finally, we show how\ndistillation complements existing negative mining techniques for extreme\nmulticlass retrieval, and propose a unified objective which combines these\nideas.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:49:51 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Menon", "Aditya Krishna", ""], ["Rawat", "Ankit Singh", ""], ["Reddi", "Sashank J.", ""], ["Kim", "Seungyeon", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2005.10435", "submitter": "HaiYing Wang", "authors": "Jun Yu, HaiYing Wang, Mingyao Ai and Huiming Zhang", "title": "Optimal Distributed Subsampling for Maximum Quasi-Likelihood Estimators\n  with Massive Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonuniform subsampling methods are effective to reduce computational burden\nand maintain estimation efficiency for massive data. Existing methods mostly\nfocus on subsampling with replacement due to its high computational efficiency.\nIf the data volume is so large that nonuniform subsampling probabilities cannot\nbe calculated all at once, then subsampling with replacement is infeasible to\nimplement. This paper solves this problem using Poisson subsampling. We first\nderive optimal Poisson subsampling probabilities in the context of\nquasi-likelihood estimation under the A- and L-optimality criteria. For a\npractically implementable algorithm with approximated optimal subsampling\nprobabilities, we establish the consistency and asymptotic normality of the\nresultant estimators. To deal with the situation that the full data are stored\nin different blocks or at multiple locations, we develop a distributed\nsubsampling framework, in which statistics are computed simultaneously on\nsmaller partitions of the full data. Asymptotic properties of the resultant\naggregated estimator are investigated. We illustrate and evaluate the proposed\nstrategies through numerical experiments on simulated and real data sets.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 02:46:56 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 13:45:32 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 15:32:22 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yu", "Jun", ""], ["Wang", "HaiYing", ""], ["Ai", "Mingyao", ""], ["Zhang", "Huiming", ""]]}, {"id": "2005.10451", "submitter": "Li Shen", "authors": "Yucong Shen, Li Shen, Hao-Zhi Huang, Xuan Wang, Wei Liu", "title": "CPOT: Channel Pruning via Optimal Transport", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep neural networks (DNNs) lead to tremendously growing\nnetwork parameters, making the deployments of DNNs on platforms with limited\nresources extremely difficult. Therefore, various pruning methods have been\ndeveloped to compress the deep network architectures and accelerate the\ninference process. Most of the existing channel pruning methods discard the\nless important filters according to well-designed filter ranking criteria.\nHowever, due to the limited interpretability of deep learning models, designing\nan appropriate ranking criterion to distinguish redundant filters is difficult.\nTo address such a challenging issue, we propose a new technique of Channel\nPruning via Optimal Transport, dubbed CPOT. Specifically, we locate the\nWasserstein barycenter for channels of each layer in the deep models, which is\nthe mean of a set of probability distributions under the optimal transport\nmetric. Then, we prune the redundant information located by Wasserstein\nbarycenters. At last, we empirically demonstrate that, for classification\ntasks, CPOT outperforms the state-of-the-art methods on pruning ResNet-20,\nResNet-32, ResNet-56, and ResNet-110. Furthermore, we show that the proposed\nCPOT technique is good at compressing the StarGAN models by pruning in the more\ndifficult case of image-to-image translation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 03:43:09 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Shen", "Yucong", ""], ["Shen", "Li", ""], ["Huang", "Hao-Zhi", ""], ["Wang", "Xuan", ""], ["Liu", "Wei", ""]]}, {"id": "2005.10473", "submitter": "Adit Krishnan", "authors": "Adit Krishnan, Mahashweta Das, Mangesh Bendre, Hao Yang, Hari Sundaram", "title": "Transfer Learning via Contextual Invariants for One-to-Many Cross-Domain\n  Recommendation", "comments": "SIGIR 2020", "journal-ref": null, "doi": "10.1145/3397271.3401078", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid proliferation of new users and items on the social web has\naggravated the gray-sheep user/long-tail item challenge in recommender systems.\nHistorically, cross-domain co-clustering methods have successfully leveraged\nshared users and items across dense and sparse domains to improve inference\nquality. However, they rely on shared rating data and cannot scale to multiple\nsparse target domains (i.e., the one-to-many transfer setting). This, combined\nwith the increasing adoption of neural recommender architectures, motivates us\nto develop scalable neural layer-transfer approaches for cross-domain learning.\nOur key intuition is to guide neural collaborative filtering with\ndomain-invariant components shared across the dense and sparse domains,\nimproving the user and item representations learned in the sparse domains. We\nleverage contextual invariances across domains to develop these shared modules,\nand demonstrate that with user-item interaction context, we can learn-to-learn\ninformative representation spaces even with sparse interaction data. We show\nthe effectiveness and scalability of our approach on two public datasets and a\nmassive transaction dataset from Visa, a global payments technology company\n(19% Item Recall, 3x faster vs. training separate models for each domain). Our\napproach is applicable to both implicit and explicit feedback settings.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 05:51:15 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Krishnan", "Adit", ""], ["Das", "Mahashweta", ""], ["Bendre", "Mangesh", ""], ["Yang", "Hao", ""], ["Sundaram", "Hari", ""]]}, {"id": "2005.10477", "submitter": "Shahin Boluki", "authors": "Siamak Zamani Dadaneh, Shahin Boluki, Mingzhang Yin, Mingyuan Zhou,\n  Xiaoning Qian", "title": "Pairwise Supervised Hashing with Bernoulli Variational Auto-Encoder and\n  Self-Control Gradient Estimator", "comments": "To appear in UAI 2020", "journal-ref": "Uncertainty in Artificial Intelligence Conference (UAI) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic hashing has become a crucial component of fast similarity search in\nmany large-scale information retrieval systems, in particular, for text data.\nVariational auto-encoders (VAEs) with binary latent variables as hashing codes\nprovide state-of-the-art performance in terms of precision for document\nretrieval. We propose a pairwise loss function with discrete latent VAE to\nreward within-class similarity and between-class dissimilarity for supervised\nhashing. Instead of solving the optimization relying on existing biased\ngradient estimators, an unbiased low-variance gradient estimator is adopted to\noptimize the hashing function by evaluating the non-differentiable loss\nfunction over two correlated sets of binary hashing codes to control the\nvariance of gradient estimates. This new semantic hashing framework achieves\nsuperior performance compared to the state-of-the-arts, as demonstrated by our\ncomprehensive experiments.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 06:11:33 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Dadaneh", "Siamak Zamani", ""], ["Boluki", "Shahin", ""], ["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "2005.10483", "submitter": "Gherardo Varando", "authors": "Gherardo Varando and Niels Richard Hansen", "title": "Graphical continuous Lyapunov models", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear Lyapunov equation of a covariance matrix parametrizes the\nequilibrium covariance matrix of a stochastic process. This parametrization can\nbe interpreted as a new graphical model class, and we show how the model class\nbehaves under marginalization and introduce a method for structure learning via\n$\\ell_1$-penalized loss minimization. Our proposed method is demonstrated to\noutperform alternative structure learning algorithms in a simulation study, and\nwe illustrate its application for protein phosphorylation network\nreconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 06:50:27 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Varando", "Gherardo", ""], ["Hansen", "Niels Richard", ""]]}, {"id": "2005.10516", "submitter": "David Charte", "authors": "David Charte, Francisco Charte, Mar\\'ia J. del Jesus, Francisco\n  Herrera", "title": "An analysis on the use of autoencoders for representation learning:\n  fundamentals, learning task case studies, explainability and challenges", "comments": null, "journal-ref": "Neurocomputing 404 (2020) 93-107", "doi": "10.1016/j.neucom.2020.04.057", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning tasks, learning a good representation of the data\ncan be the key to building a well-performant solution. This is because most\nlearning algorithms operate with the features in order to find models for the\ndata. For instance, classification performance can improve if the data is\nmapped to a space where classes are easily separated, and regression can be\nfacilitated by finding a manifold of data in the feature space. As a general\nrule, features are transformed by means of statistical methods such as\nprincipal component analysis, or manifold learning techniques such as Isomap or\nlocally linear embedding. From a plethora of representation learning methods,\none of the most versatile tools is the autoencoder. In this paper we aim to\ndemonstrate how to influence its learned representations to achieve the desired\nlearning behavior. To this end, we present a series of learning tasks: data\nembedding for visualization, image denoising, semantic hashing, detection of\nabnormal behaviors and instance generation. We model them from the\nrepresentation learning perspective, following the state of the art\nmethodologies in each field. A solution is proposed for each task employing\nautoencoders as the only learning method. The theoretical developments are put\ninto practice using a selection of datasets for the different problems and\nimplementing each solution, followed by a discussion of the results in each\ncase study and a brief explanation of other six learning applications. We also\nexplore the current challenges and approaches to explainability in the context\nof autoencoders. All of this helps conclude that, thanks to alterations in\ntheir structure as well as their objective function, autoencoders may be the\ncore of a possible solution to many problems which can be modeled as a\ntransformation of the feature space.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 08:41:57 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Charte", "David", ""], ["Charte", "Francisco", ""], ["del Jesus", "Mar\u00eda J.", ""], ["Herrera", "Francisco", ""]]}, {"id": "2005.10524", "submitter": "Gaurav Mittal", "authors": "Gaurav Mittal, Chang Liu, Nikolaos Karianakis, Victor Fragoso, Mei\n  Chen, Yun Fu", "title": "HyperSTAR: Task-Aware Hyperparameters for Deep Networks", "comments": "Published at CVPR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks excel in solving visual recognition tasks, they\nrequire significant effort to find hyperparameters that make them work\noptimally. Hyperparameter Optimization (HPO) approaches have automated the\nprocess of finding good hyperparameters but they do not adapt to a given task\n(task-agnostic), making them computationally inefficient. To reduce HPO time,\nwe present HyperSTAR (System for Task Aware Hyperparameter Recommendation), a\ntask-aware method to warm-start HPO for deep neural networks. HyperSTAR ranks\nand recommends hyperparameters by predicting their performance conditioned on a\njoint dataset-hyperparameter space. It learns a dataset (task) representation\nalong with the performance predictor directly from raw images in an end-to-end\nfashion. The recommendations, when integrated with an existing HPO method, make\nit task-aware and significantly reduce the time to achieve optimal performance.\nWe conduct extensive experiments on 10 publicly available large-scale image\nclassification datasets over two different network architectures, validating\nthat HyperSTAR evaluates 50% less configurations to achieve the best\nperformance compared to existing methods. We further demonstrate that HyperSTAR\nmakes Hyperband (HB) task-aware, achieving the optimal accuracy in just 25% of\nthe budget required by both vanilla HB and Bayesian Optimized HB~(BOHB).\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 08:56:50 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Mittal", "Gaurav", ""], ["Liu", "Chang", ""], ["Karianakis", "Nikolaos", ""], ["Fragoso", "Victor", ""], ["Chen", "Mei", ""], ["Fu", "Yun", ""]]}, {"id": "2005.10531", "submitter": "Michael Biehl", "authors": "Michiel Straat, Fthi Abadi, Zhuoyun Kan, Christina G\\\"opfert, Barbara\n  Hammer, Michael Biehl", "title": "Supervised Learning in the Presence of Concept Drift: A modelling\n  framework", "comments": "17 pages in twocolumn", "journal-ref": "Neural Computing and Applications 2021", "doi": "10.1007/s00521-021-06035-1", "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modelling framework for the investigation of supervised learning\nin non-stationary environments. Specifically, we model two example types of\nlearning systems: prototype-based Learning Vector Quantization (LVQ) for\nclassification and shallow, layered neural networks for regression tasks. We\ninvestigate so-called student teacher scenarios in which the systems are\ntrained from a stream of high-dimensional, labeled data. Properties of the\ntarget task are considered to be non-stationary due to drift processes while\nthe training is performed. Different types of concept drift are studied, which\naffect the density of example inputs only, the target rule itself, or both. By\napplying methods from statistical physics, we develop a modelling framework for\nthe mathematical analysis of the training dynamics in non-stationary\nenvironments.\n  Our results show that standard LVQ algorithms are already suitable for the\ntraining in non-stationary environments to a certain extent. However, the\napplication of weight decay as an explicit mechanism of forgetting does not\nimprove the performance under the considered drift processes. Furthermore, we\ninvestigate gradient-based training of layered neural networks with sigmoidal\nactivation functions and compare with the use of rectified linear units (ReLU).\nOur findings show that the sensitivity to concept drift and the effectiveness\nof weight decay differs significantly between the two types of activation\nfunction.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 09:13:58 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 20:45:45 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Straat", "Michiel", ""], ["Abadi", "Fthi", ""], ["Kan", "Zhuoyun", ""], ["G\u00f6pfert", "Christina", ""], ["Hammer", "Barbara", ""], ["Biehl", "Michael", ""]]}, {"id": "2005.10561", "submitter": "Yury Polyanskiy", "authors": "Soham Jana, Yury Polyanskiy and Yihong Wu", "title": "Extrapolating the profile of a finite population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a prototypical problem in empirical Bayes. Namely, consider a\npopulation consisting of $k$ individuals each belonging to one of $k$ types\n(some types can be empty). Without any structural restrictions, it is\nimpossible to learn the composition of the full population having observed only\na small (random) subsample of size $m = o(k)$. Nevertheless, we show that in\nthe sublinear regime of $m =\\omega(k/\\log k)$, it is possible to consistently\nestimate in total variation the \\emph{profile} of the population, defined as\nthe empirical distribution of the sizes of each type, which determines many\nsymmetric properties of the population. We also prove that in the linear regime\nof $m=c k$ for any constant $c$ the optimal rate is $\\Theta(1/\\log k)$. Our\nestimator is based on Wolfowitz's minimum distance method, which entails\nsolving a linear program (LP) of size $k$. We show that there is a single\ninfinite-dimensional LP whose value simultaneously characterizes the risk of\nthe minimum distance estimator and certifies its minimax optimality. The sharp\nconvergence rate is obtained by evaluating this LP using complex-analytic\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 10:39:41 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Jana", "Soham", ""], ["Polyanskiy", "Yury", ""], ["Wu", "Yihong", ""]]}, {"id": "2005.10577", "submitter": "Filippo Vannella", "authors": "Filippo Vannella, Jaeseong Jeong, Alexandre Proutiere", "title": "Off-policy Learning for Remote Electrical Tilt Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of Remote Electrical Tilt (RET) optimization using\noff-policy Contextual Multi-Armed-Bandit (CMAB) techniques. The goal in RET\noptimization is to control the orientation of the vertical tilt angle of the\nantenna to optimize Key Performance Indicators (KPIs) representing the Quality\nof Service (QoS) perceived by the users in cellular networks. Learning an\nimproved tilt update policy is hard. On the one hand, coming up with a new\npolicy in an online manner in a real network requires exploring tilt updates\nthat have never been used before, and is operationally too risky. On the other\nhand, devising this policy via simulations suffers from the\nsimulation-to-reality gap. In this paper, we circumvent these issues by\nlearning an improved policy in an offline manner using existing data collected\non real networks. We formulate the problem of devising such a policy using the\noff-policy CMAB framework. We propose CMAB learning algorithms to extract\noptimal tilt update policies from the data. We train and evaluate these\npolicies on real-world 4G Long Term Evolution (LTE) cellular network data. Our\npolicies show consistent improvements over the rule-based logging policy used\nto collect the data.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 11:30:31 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Vannella", "Filippo", ""], ["Jeong", "Jaeseong", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "2005.10614", "submitter": "Souvik Chakraborty", "authors": "Souvik Chakraborty", "title": "Transfer learning based multi-fidelity physics informed deep neural\n  network", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109942", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many systems in science and engineering, the governing differential\nequation is either not known or known in an approximate sense. Analyses and\ndesign of such systems are governed by data collected from the field and/or\nlaboratory experiments. This challenging scenario is further worsened when\ndata-collection is expensive and time-consuming. To address this issue, this\npaper presents a novel multi-fidelity physics informed deep neural network\n(MF-PIDNN). The framework proposed is particularly suitable when the physics of\nthe problem is known in an approximate sense (low-fidelity physics) and only a\nfew high-fidelity data are available. MF-PIDNN blends physics informed and\ndata-driven deep learning techniques by using the concept of transfer learning.\nThe approximate governing equation is first used to train a low-fidelity\nphysics informed deep neural network. This is followed by transfer learning\nwhere the low-fidelity model is updated by using the available high-fidelity\ndata. MF-PIDNN is able to encode useful information on the physics of the\nproblem from the {\\it approximate} governing differential equation and hence,\nprovides accurate prediction even in zones with no data. Additionally, no\nlow-fidelity data is required for training this model. Applicability and\nutility of MF-PIDNN are illustrated in solving four benchmark reliability\nanalysis problems. Case studies to illustrate interesting features of the\nproposed approach are also presented.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:57:48 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 05:17:32 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chakraborty", "Souvik", ""]]}, {"id": "2005.10615", "submitter": "Rolf Jagerman", "authors": "Rolf Jagerman and Maarten de Rijke", "title": "Accelerated Convergence for Counterfactual Learning to Rank", "comments": "SIGIR 2020 full conference paper", "journal-ref": null, "doi": "10.1145/3397271.3401069", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Learning to Rank (LTR) algorithms learn a ranking model from\nlogged user interactions, often collected using a production system. Employing\nsuch an offline learning approach has many benefits compared to an online one,\nbut it is challenging as user feedback often contains high levels of bias.\nUnbiased LTR uses Inverse Propensity Scoring (IPS) to enable unbiased learning\nfrom logged user interactions. One of the major difficulties in applying\nStochastic Gradient Descent (SGD) approaches to counterfactual learning\nproblems is the large variance introduced by the propensity weights. In this\npaper we show that the convergence rate of SGD approaches with IPS-weighted\ngradients suffers from the large variance introduced by the IPS weights:\nconvergence is slow, especially when there are large IPS weights. To overcome\nthis limitation, we propose a novel learning algorithm, called CounterSample,\nthat has provably better convergence than standard IPS-weighted gradient\ndescent methods. We prove that CounterSample converges faster and complement\nour theoretical findings with empirical results by performing extensive\nexperimentation in a number of biased LTR scenarios -- across optimizers, batch\nsizes, and different degrees of position bias.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 12:53:36 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Jagerman", "Rolf", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2005.10619", "submitter": "Sindhu Padakandla", "authors": "Sindhu Padakandla", "title": "A Survey of Reinforcement Learning Algorithms for Dynamically Varying\n  Environments", "comments": null, "journal-ref": "ACM Computing Surveys 2021", "doi": "10.1145/3459991", "report-no": "Volume 54, Issue 6", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms find applications in inventory\ncontrol, recommender systems, vehicular traffic management, cloud computing and\nrobotics. The real-world complications of many tasks arising in these domains\nmakes them difficult to solve with the basic assumptions underlying classical\nRL algorithms. RL agents in these applications often need to react and adapt to\nchanging operating conditions. A significant part of research on single-agent\nRL techniques focuses on developing algorithms when the underlying assumption\nof stationary environment model is relaxed. This paper provides a survey of RL\nmethods developed for handling dynamically varying environment models. The goal\nof methods not limited by the stationarity assumption is to help autonomous\nagents adapt to varying operating conditions. This is possible either by\nminimizing the rewards lost during learning by RL agent or by finding a\nsuitable policy for the RL agent which leads to efficient operation of the\nunderlying system. A representative collection of these algorithms is discussed\nin detail in this work along with their categorization and their relative\nmerits and demerits. Additionally we also review works which are tailored to\napplication domains. Finally, we discuss future enhancements for this field.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:42:42 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Padakandla", "Sindhu", ""]]}, {"id": "2005.10622", "submitter": "Bin Wang", "authors": "Cong Fei, Bin Wang, Yuzheng Zhuang, Zongzhang Zhang, Jianye Hao,\n  Hongbo Zhang, Xuewu Ji and Wulong Liu", "title": "Triple-GAIL: A Multi-Modal Imitation Learning Framework with Generative\n  Adversarial Nets", "comments": "7 papges, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial imitation learning (GAIL) has shown promising results\nby taking advantage of generative adversarial nets, especially in the field of\nrobot learning. However, the requirement of isolated single modal\ndemonstrations limits the scalability of the approach to real world scenarios\nsuch as autonomous vehicles' demand for a proper understanding of human\ndrivers' behavior. In this paper, we propose a novel multi-modal GAIL\nframework, named Triple-GAIL, that is able to learn skill selection and\nimitation jointly from both expert demonstrations and continuously generated\nexperiences with data augmentation purpose by introducing an auxiliary skill\nselector. We provide theoretical guarantees on the convergence to optima for\nboth of the generator and the selector respectively. Experiments on real driver\ntrajectories and real-time strategy game datasets demonstrate that Triple-GAIL\ncan better fit multi-modal behaviors close to the demonstrators and outperforms\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:24:24 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 01:05:30 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Fei", "Cong", ""], ["Wang", "Bin", ""], ["Zhuang", "Yuzheng", ""], ["Zhang", "Zongzhang", ""], ["Hao", "Jianye", ""], ["Zhang", "Hongbo", ""], ["Ji", "Xuewu", ""], ["Liu", "Wulong", ""]]}, {"id": "2005.10624", "submitter": "Manish Raghavan", "authors": "Manish Raghavan, Aleksandrs Slivkins, Jennifer Wortman Vaughan, Zhiwei\n  Steven Wu", "title": "Greedy Algorithm almost Dominates in Smoothed Contextual Bandits", "comments": "Results in this paper, without any proofs, have been announced in an\n  extended abstract (Raghavan et al., 2018a), and fleshed out in the technical\n  report (Raghavan et al., 2018b [arXiv:1806.00543]). This manuscript covers a\n  subset of results from Raghavan et al. (2018a,b), focusing on the greedy\n  algorithm, and is streamlined accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning algorithms, widely used to power search and content\noptimization on the web, must balance exploration and exploitation, potentially\nsacrificing the experience of current users in order to gain information that\nwill lead to better decisions in the future. While necessary in the worst case,\nexplicit exploration has a number of disadvantages compared to the greedy\nalgorithm that always \"exploits\" by choosing an action that currently looks\noptimal. We ask under what conditions inherent diversity in the data makes\nexplicit exploration unnecessary. We build on a recent line of work on the\nsmoothed analysis of the greedy algorithm in the linear contextual bandits\nmodel. We improve on prior results to show that a greedy approach almost\nmatches the best possible Bayesian regret rate of any other algorithm on the\nsame problem instance whenever the diversity conditions hold, and that this\nregret is at most $\\tilde O(T^{1/3})$.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:11:40 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Raghavan", "Manish", ""], ["Slivkins", "Aleksandrs", ""], ["Vaughan", "Jennifer Wortman", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2005.10629", "submitter": "Elie Azeraf", "authors": "Elie Azeraf, Emmanuel Monfrini, Emmanuel Vignon, Wojciech Pieczynski", "title": "Hidden Markov Chains, Entropic Forward-Backward, and Part-Of-Speech\n  Tagging", "comments": "5 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to take into account the characteristics - also called features -\nof observations is essential in Natural Language Processing (NLP) problems.\nHidden Markov Chain (HMC) model associated with classic Forward-Backward\nprobabilities cannot handle arbitrary features like prefixes or suffixes of any\nsize, except with an independence condition. For twenty years, this default has\nencouraged the development of other sequential models, starting with the\nMaximum Entropy Markov Model (MEMM), which elegantly integrates arbitrary\nfeatures. More generally, it led to neglect HMC for NLP. In this paper, we show\nthat the problem is not due to HMC itself, but to the way its restoration\nalgorithms are computed. We present a new way of computing HMC based\nrestorations using original Entropic Forward and Entropic Backward (EFB)\nprobabilities. Our method allows taking into account features in the HMC\nframework in the same way as in the MEMM framework. We illustrate the\nefficiency of HMC using EFB in Part-Of-Speech Tagging, showing its superiority\nover MEMM based restoration. We also specify, as a perspective, how HMCs with\nEFB might appear as an alternative to Recurrent Neural Networks to treat\nsequential data with a deep architecture.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 13:31:11 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Azeraf", "Elie", ""], ["Monfrini", "Emmanuel", ""], ["Vignon", "Emmanuel", ""], ["Pieczynski", "Wojciech", ""]]}, {"id": "2005.10630", "submitter": "Hilal Asi", "authors": "Hilal Asi, John C. Duchi", "title": "Near Instance-Optimality in Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop two notions of instance optimality in differential privacy,\ninspired by classical statistical theory: one by defining a local minimax risk\nand the other by considering unbiased mechanisms and analogizing the Cramer-Rao\nbound, and we show that the local modulus of continuity of the estimand of\ninterest completely determines these quantities. We also develop a\ncomplementary collection mechanisms, which we term the inverse sensitivity\nmechanisms, which are instance optimal (or nearly instance optimal) for a large\nclass of estimands. Moreover, these mechanisms uniformly outperform the smooth\nsensitivity framework on each instance for several function classes of\ninterest, including real-valued continuous functions. We carefully present two\ninstantiations of the mechanisms for median and robust regression estimation\nwith corresponding experiments.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:53:48 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Asi", "Hilal", ""], ["Duchi", "John C.", ""]]}, {"id": "2005.10632", "submitter": "Enrico Schiassi", "authors": "Enrico Schiassi, Carl Leake, Mario De Florio, Hunter Johnston, Roberto\n  Furfaro, Daniele Mortari", "title": "Extreme Theory of Functional Connections: A Physics-Informed Neural\n  Network Method for Solving Parametric Differential Equations", "comments": "28 pages, 12 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a novel, accurate, and robust physics-informed method\nfor solving problems involving parametric differential equations (DEs) called\nthe Extreme Theory of Functional Connections, or X-TFC. The proposed method is\na synergy of two recently developed frameworks for solving problems involving\nparametric DEs, 1) the Theory of Functional Connections, TFC, and the\nPhysics-Informed Neural Networks, PINN. Although this paper focuses on the\nsolution of exact problems involving parametric DEs (i.e. problems where the\nmodeling error is negligible) with known parameters, X-TFC can also be used for\ndata-driven solutions and data-driven discovery of parametric DEs. In the\nproposed method, the latent solution of the parametric DEs is approximated by a\nTFC constrained expression that uses a Neural Network (NN) as the\nfree-function. This approximate solution form always analytically satisfies the\nconstraints of the DE, while maintaining a NN with unconstrained parameters,\nlike the Deep-TFC method. X-TFC differs from PINN and Deep-TFC; whereas PINN\nand Deep-TFC use a deep-NN, X-TFC uses a single-layer NN, or more precisely, an\nExtreme Learning Machine, ELM. This choice is based on the properties of the\nELM algorithm. In order to numerically validate the method, it was tested over\na range of problems including the approximation of solutions to linear and\nnon-linear ordinary DEs (ODEs), systems of ODEs (SODEs), and partial DEs\n(PDEs). Furthermore, a few of these problems are of interest in physics and\nengineering such as the Classic Emden-Fowler equation, the Radiative Transfer\n(RT) equation, and the Heat-Transfer (HT) equation. The results show that X-TFC\nachieves high accuracy with low computational time and thus it is comparable\nwith the other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 22:51:04 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Schiassi", "Enrico", ""], ["Leake", "Carl", ""], ["De Florio", "Mario", ""], ["Johnston", "Hunter", ""], ["Furfaro", "Roberto", ""], ["Mortari", "Daniele", ""]]}, {"id": "2005.10636", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, Percy Liang", "title": "Graph-based, Self-Supervised Program Repair from Diagnostic Feedback", "comments": "ICML 2020. Code & data available at\n  https://github.com/michiyasunaga/DrRepair", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to repair programs from diagnostic\nfeedback (e.g., compiler error messages). Program repair is challenging for two\nreasons: First, it requires reasoning and tracking symbols across source code\nand diagnostic feedback. Second, labeled datasets available for program repair\nare relatively small. In this work, we propose novel solutions to these two\nchallenges. First, we introduce a program-feedback graph, which connects\nsymbols relevant to program repair in source code and diagnostic feedback, and\nthen apply a graph neural network on top to model the reasoning process.\nSecond, we present a self-supervised learning paradigm for program repair that\nleverages unlabeled programs available online to create a large amount of extra\nprogram repair examples, which we use to pre-train our models. We evaluate our\nproposed approach on two applications: correcting introductory programming\nassignments (DeepFix dataset) and correcting the outputs of program synthesis\n(SPoC dataset). Our final system, DrRepair, significantly outperforms prior\nwork, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best),\nand 48.4% synthesis success rate on SPoC (+3.7% over the prior best).\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 07:24:28 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 05:30:33 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Liang", "Percy", ""]]}, {"id": "2005.10638", "submitter": "Alexandre Emerick", "authors": "Smith W. A. Canchumun, Jose D. B. Castro, J\\'ulia Potratz, Alexandre\n  A. Emerick and Marco Aurelio C. Pacheco", "title": "Recent Developments Combining Ensemble Smoother and Deep Generative\n  Networks for Facies History Matching", "comments": "46 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble smoothers are among the most successful and efficient techniques\ncurrently available for history matching. However, because these methods rely\non Gaussian assumptions, their performance is severely degraded when the prior\ngeology is described in terms of complex facies distributions. Inspired by the\nimpressive results obtained by deep generative networks in areas such as image\nand video generation, we started an investigation focused on the use of\nautoencoders networks to construct a continuous parameterization for facies\nmodels. In our previous publication, we combined a convolutional variational\nautoencoder (VAE) with the ensemble smoother with multiple data assimilation\n(ES-MDA) for history matching production data in models generated with\nmultiple-point geostatistics. Despite the good results reported in our previous\npublication, a major limitation of the designed parameterization is the fact\nthat it does not allow applying distance-based localization during the ensemble\nsmoother update, which limits its application in large-scale problems.\n  The present work is a continuation of this research project focusing in two\naspects: firstly, we benchmark seven different formulations, including VAE,\ngenerative adversarial network (GAN), Wasserstein GAN, variational\nauto-encoding GAN, principal component analysis (PCA) with cycle GAN, PCA with\ntransfer style network and VAE with style loss. These formulations are tested\nin a synthetic history matching problem with channelized facies. Secondly, we\npropose two strategies to allow the use of distance-based localization with the\ndeep learning parameterizations.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 21:32:42 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Canchumun", "Smith W. A.", ""], ["Castro", "Jose D. B.", ""], ["Potratz", "J\u00falia", ""], ["Emerick", "Alexandre A.", ""], ["Pacheco", "Marco Aurelio C.", ""]]}, {"id": "2005.10642", "submitter": "Tapas Si", "authors": "Jayri Bagchi and Tapas Si", "title": "Nonlinear Regression Analysis Using Multi-Verse Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Regression analysis is an important machine learning task used for predictive\nanalytic in business, sports analysis, etc. In regression analysis,\noptimization algorithms play a significant role in search the coefficients in\nthe regression model. In this paper, nonlinear regression analysis using a\nrecently developed meta-heuristic Multi-Verse Optimizer (MVO) is proposed. The\nproposed method is applied to 10 well-known benchmark nonlinear regression\nproblems. A comparative study has been conducted with Particle Swarm Optimizer\n(PSO). The experimental results demonstrate that the proposed method\nstatistically outperforms PSO algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:03:52 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Bagchi", "Jayri", ""], ["Si", "Tapas", ""]]}, {"id": "2005.10674", "submitter": "Andrea Borghesi", "authors": "Michele Lombardi, Federico Baldo, Andrea Borghesi, Michela Milano", "title": "An Analysis of Regularized Approaches for Constrained Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization-based approaches for injecting constraints in Machine Learning\n(ML) were introduced to improve a predictive model via expert knowledge. We\ntackle the issue of finding the right balance between the loss (the accuracy of\nthe learner) and the regularization term (the degree of constraint\nsatisfaction). The key results of this paper is the formal demonstration that\nthis type of approach cannot guarantee to find all optimal solutions. In\nparticular, in the non-convex case there might be optima for the constrained\nproblem that do not correspond to any multiplier value.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:16:26 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Lombardi", "Michele", ""], ["Baldo", "Federico", ""], ["Borghesi", "Andrea", ""], ["Milano", "Michela", ""]]}, {"id": "2005.10691", "submitter": "Andrea Borghesi", "authors": "Andrea Borghesi, Federico Baldo, Michela Milano", "title": "Improving Deep Learning Models via Constraint-Based Domain Knowledge: a\n  Brief Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) models proved themselves to perform extremely well on a\nwide variety of learning tasks, as they can learn useful patterns from large\ndata sets. However, purely data-driven models might struggle when very\ndifficult functions need to be learned or when there is not enough available\ntraining data. Fortunately, in many domains prior information can be retrieved\nand used to boost the performance of DL models. This paper presents a first\nsurvey of the approaches devised to integrate domain knowledge, expressed in\nthe form of constraints, in DL learning models to improve their performance, in\nparticular targeting deep neural networks. We identify five (non-mutually\nexclusive) categories that encompass the main approaches to inject domain\nknowledge: 1) acting on the features space, 2) modifications to the hypothesis\nspace, 3) data augmentation, 4) regularization schemes, 5) constrained\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:34:09 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Borghesi", "Andrea", ""], ["Baldo", "Federico", ""], ["Milano", "Michela", ""]]}, {"id": "2005.10693", "submitter": "Mansura Habiba Miss", "authors": "Mansura Habiba, Barak A. Pearlmutter", "title": "Neural ODEs for Informative Missingness in Multivariate Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informative missingness is unavoidable in the digital processing of\ncontinuous time series, where the value for one or more observations at\ndifferent time points are missing. Such missing observations are one of the\nmajor limitations of time series processing using deep learning. Practical\napplications, e.g., sensor data, healthcare, weather, generates data that is in\ntruth continuous in time, and informative missingness is a common phenomenon in\nthese datasets. These datasets often consist of multiple variables, and often\nthere are missing values for one or many of these variables. This\ncharacteristic makes time series prediction more challenging, and the impact of\nmissing input observations on the accuracy of the final output can be\nsignificant. A recent novel deep learning model called GRU-D is one early\nattempt to address informative missingness in time series data. On the other\nhand, a new family of neural networks called Neural ODEs (Ordinary Differential\nEquations) are natural and efficient for processing time series data which is\ncontinuous in time. In this paper, a deep learning model is proposed that\nleverages the effective imputation of GRU-D, and the temporal continuity of\nNeural ODEs. A time series classification task performed on the PhysioNet\ndataset demonstrates the performance of this architecture.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 00:28:30 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Habiba", "Mansura", ""], ["Pearlmutter", "Barak A.", ""]]}, {"id": "2005.10696", "submitter": "Hao Sun", "authors": "Hao Sun, Zhenghao Peng, Bo Dai, Jian Guo, Dahua Lin, Bolei Zhou", "title": "Novel Policy Seeking with Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In problem-solving, we humans can come up with multiple novel solutions to\nthe same problem. However, reinforcement learning algorithms can only produce a\nset of monotonous policies that maximize the cumulative reward but lack\ndiversity and novelty. In this work, we address the problem of generating novel\npolicies in reinforcement learning tasks. Instead of following the\nmulti-objective framework used in existing methods, we propose to rethink the\nproblem under a novel perspective of constrained optimization. We first\nintroduce a new metric to evaluate the difference between policies and then\ndesign two practical novel policy generation methods following the new\nperspective. The two proposed methods, namely the Constrained Task Novel\nBisector (CTNB) and the Interior Policy Differentiation (IPD), are derived from\nthe feasible direction method and the interior point method commonly known in\nthe constrained optimization literature. Experimental comparisons on the MuJoCo\ncontrol suite show our methods can achieve substantial improvement over\nprevious novelty-seeking methods in terms of both the novelty of policies and\ntheir performances in the primal task.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 14:39:14 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 07:18:38 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sun", "Hao", ""], ["Peng", "Zhenghao", ""], ["Dai", "Bo", ""], ["Guo", "Jian", ""], ["Lin", "Dahua", ""], ["Zhou", "Bolei", ""]]}, {"id": "2005.10700", "submitter": "Hayden Helm", "authors": "Hayden S. Helm, Amitabh Basu, Avanti Athreya, Youngser Park, Joshua T.\n  Vogelstein, Michael Winding, Marta Zlatic, Albert Cardona, Patrick Bourke,\n  Jonathan Larson, Chris White, Carey E. Priebe", "title": "Learning to rank via combining representations", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to rank -- producing a ranked list of items specific to a query and\nwith respect to a set of supervisory items -- is a problem of general interest.\nThe setting we consider is one in which no analytic description of what\nconstitutes a good ranking is available. Instead, we have a collection of\nrepresentations and supervisory information consisting of a (target item,\ninteresting items set) pair. We demonstrate -- analytically, in simulation, and\nin real data examples -- that learning to rank via combining representations\nusing an integer linear program is effective when the supervision is as light\nas \"these few items are similar to your item of interest.\" While this\nnomination task is of general interest, for specificity we present our\nmethodology from the perspective of vertex nomination in graphs. The\nmethodology described herein is model agnostic.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:53:58 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 13:37:50 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Helm", "Hayden S.", ""], ["Basu", "Amitabh", ""], ["Athreya", "Avanti", ""], ["Park", "Youngser", ""], ["Vogelstein", "Joshua T.", ""], ["Winding", "Michael", ""], ["Zlatic", "Marta", ""], ["Cardona", "Albert", ""], ["Bourke", "Patrick", ""], ["Larson", "Jonathan", ""], ["White", "Chris", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2005.10701", "submitter": "Alexandru Cristian Mara", "authors": "Alexandru Mara, Yoosof Mashayekhi, Jefrey Lijffijt, Tijl De Bie", "title": "CSNE: Conditional Signed Network Embedding", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3411959", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signed networks are mathematical structures that encode positive and negative\nrelations between entities such as friend/foe or trust/distrust. Recently,\nseveral papers studied the construction of useful low-dimensional\nrepresentations (embeddings) of these networks for the prediction of missing\nrelations or signs. Existing embedding methods for sign prediction generally\nenforce different notions of status or balance theories in their optimization\nfunction. These theories, however, are often inaccurate or incomplete, which\nnegatively impacts method performance.\n  In this context, we introduce conditional signed network embedding (CSNE).\nOur probabilistic approach models structural information about the signs in the\nnetwork separately from fine-grained detail. Structural information is\nrepresented in the form of a prior, while the embedding itself is used for\ncapturing fine-grained information. These components are then integrated in a\nrigorous manner. CSNE's accuracy depends on the existence of sufficiently\npowerful structural priors for modelling signed networks, currently unavailable\nin the literature. Thus, as a second main contribution, which we find to be\nhighly valuable in its own right, we also introduce a novel approach to\nconstruct priors based on the Maximum Entropy (MaxEnt) principle. These priors\ncan model the \\emph{polarity} of nodes (degree to which their links are\npositive) as well as signed \\emph{triangle counts} (a measure of the degree\nstructural balance holds to in a network).\n  Experiments on a variety of real-world networks confirm that CSNE outperforms\nthe state-of-the-art on the task of sign prediction. Moreover, the MaxEnt\npriors on their own, while less accurate than full CSNE, achieve accuracies\ncompetitive with the state-of-the-art at very limited computational cost, thus\nproviding an excellent runtime-accuracy trade-off in resource-constrained\nsituations.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 19:14:52 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 10:13:43 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Mara", "Alexandru", ""], ["Mashayekhi", "Yoosof", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2005.10709", "submitter": "Yuan Wen", "authors": "Yuan Wen, Andrew Anderson, Valentin Radu, Michael F.P. O'Boyle, David\n  Gregg", "title": "TASO: Time and Space Optimization for Memory-Constrained DNN Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are used in many embedded applications,\nfrom industrial robotics and automation systems to biometric identification on\nmobile devices. State-of-the-art classification is typically achieved by large\nnetworks, which are prohibitively expensive to run on mobile and embedded\ndevices with tightly constrained memory and energy budgets. We propose an\napproach for ahead-of-time domain specific optimization of CNN models, based on\nan integer linear programming (ILP) for selecting primitive operations to\nimplement convolutional layers. We optimize the trade-off between execution\ntime and memory consumption by: 1) attempting to minimize execution time across\nthe whole network by selecting data layouts and primitive operations to\nimplement each layer; and 2) allocating an appropriate workspace that reflects\nthe upper bound of memory footprint per layer. These two optimization\nstrategies can be used to run any CNN on any platform with a C compiler. Our\nevaluation with a range of popular ImageNet neural architectures (GoogleNet,\nAlexNet, VGG, ResNet and SqueezeNet) on the ARM Cortex-A15 yields speedups of\n8x compared to a greedy algorithm based primitive selection, reduces memory\nrequirement by 2.2x while sacrificing only 15% of inference time compared to a\nsolver that considers inference time only. In addition, our optimization\napproach exposes a range of optimal points for different configurations across\nthe Pareto frontier of memory and latency trade-off, which can be used under\narbitrary system constraints.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:08:06 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Wen", "Yuan", ""], ["Anderson", "Andrew", ""], ["Radu", "Valentin", ""], ["O'Boyle", "Michael F. P.", ""], ["Gregg", "David", ""]]}, {"id": "2005.10743", "submitter": "Anru R. Zhang", "authors": "Yuetian Luo and Anru R. Zhang", "title": "Tensor Clustering with Planted Structures: Statistical Optimality and\n  Computational Limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper studies the statistical and computational limits of high-order\nclustering with planted structures. We focus on two clustering models, constant\nhigh-order clustering (CHC) and rank-one higher-order clustering (ROHC), and\nstudy the methods and theory for testing whether a cluster exists (detection)\nand identifying the support of cluster (recovery).\n  Specifically, we identify the sharp boundaries of signal-to-noise ratio for\nwhich CHC and ROHC detection/recovery are statistically possible. We also\ndevelop the tight computational thresholds: when the signal-to-noise ratio is\nbelow these thresholds, we prove that polynomial-time algorithms cannot solve\nthese problems under the computational hardness conjectures of hypergraphic\nplanted clique (HPC) detection and hypergraphic planted dense subgraph (HPDS)\nrecovery. We also propose polynomial-time tensor algorithms that achieve\nreliable detection and recovery when the signal-to-noise ratio is above these\nthresholds. Both sparsity and tensor structures yield the computational\nbarriers in high-order tensor clustering. The interplay between them results in\nsignificant differences between high-order tensor clustering and matrix\nclustering in literature in aspects of statistical and computational phase\ntransition diagrams, algorithmic approaches, hardness conjecture, and proof\ntechniques. To our best knowledge, we are the first to give a thorough\ncharacterization of the statistical and computational trade-off for such a\ndouble computational-barrier problem. Finally, we provide evidence for the\ncomputational hardness conjectures of HPC detection and HPDS recovery.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:53:44 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 01:57:19 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Luo", "Yuetian", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2005.10761", "submitter": "Leighton Barnes", "authors": "Leighton Pate Barnes, Huseyin A. Inan, Berivan Isik, and Ayfer Ozgur", "title": "rTop-k: A Statistical Estimation Approach to Distributed SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large communication cost for exchanging gradients between different nodes\nsignificantly limits the scalability of distributed training for large-scale\nlearning models. Motivated by this observation, there has been significant\nrecent interest in techniques that reduce the communication cost of distributed\nStochastic Gradient Descent (SGD), with gradient sparsification techniques such\nas top-k and random-k shown to be particularly effective. The same observation\nhas also motivated a separate line of work in distributed statistical\nestimation theory focusing on the impact of communication constraints on the\nestimation efficiency of different statistical models. The primary goal of this\npaper is to connect these two research lines and demonstrate how statistical\nestimation models and their analysis can lead to new insights in the design of\ncommunication-efficient training techniques. We propose a simple statistical\nestimation model for the stochastic gradients which captures the sparsity and\nskewness of their distribution. The statistically optimal communication scheme\narising from the analysis of this model leads to a new sparsification technique\nfor SGD, which concatenates random-k and top-k, considered separately in the\nprior literature. We show through extensive experiments on both image and\nlanguage domains with CIFAR-10, ImageNet, and Penn Treebank datasets that the\nconcatenated application of these two sparsification methods consistently and\nsignificantly outperforms either method applied alone.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 16:27:46 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 21:26:06 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Barnes", "Leighton Pate", ""], ["Inan", "Huseyin A.", ""], ["Isik", "Berivan", ""], ["Ozgur", "Ayfer", ""]]}, {"id": "2005.10783", "submitter": "Leighton Barnes", "authors": "Leighton Pate Barnes, Wei-Ning Chen, and Ayfer Ozgur", "title": "Fisher information under local differential privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop data processing inequalities that describe how Fisher information\nfrom statistical samples can scale with the privacy parameter $\\varepsilon$\nunder local differential privacy constraints. These bounds are valid under\ngeneral conditions on the distribution of the score of the statistical model,\nand they elucidate under which conditions the dependence on $\\varepsilon$ is\nlinear, quadratic, or exponential. We show how these inequalities imply order\noptimal lower bounds for private estimation for both the Gaussian location\nmodel and discrete distribution estimation for all levels of privacy\n$\\varepsilon>0$. We further apply these inequalities to sparse Bernoulli models\nand demonstrate privacy mechanisms and estimators with order-matching squared\n$\\ell^2$ error.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:05:09 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Barnes", "Leighton Pate", ""], ["Chen", "Wei-Ning", ""], ["Ozgur", "Ayfer", ""]]}, {"id": "2005.10791", "submitter": "Nihat Ay", "authors": "Nihat Ay", "title": "On the Locality of the Natural Gradient for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the natural gradient method for learning in deep Bayesian networks,\nincluding neural networks. There are two natural geometries associated with\nsuch learning systems consisting of visible and hidden units. One geometry is\nrelated to the full system, the other one to the visible sub-system. These two\ngeometries imply different natural gradients. In a first step, we demonstrate a\ngreat simplification of the natural gradient with respect to the first\ngeometry, due to locality properties of the Fisher information matrix. This\nsimplification does not directly translate to a corresponding simplification\nwith respect to the second geometry. We develop the theory for studying the\nrelation between the two versions of the natural gradient and outline a method\nfor the simplification of the natural gradient with respect to the second\ngeometry based on the first one. This method suggests to incorporate a\nrecognition model as an auxiliary model for the efficient application of the\nnatural gradient method in deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:17:03 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Ay", "Nihat", ""]]}, {"id": "2005.10804", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Ruslan Salakhutdinov, Lin F. Yang", "title": "Reinforcement Learning with General Value Function Approximation:\n  Provably Efficient Approach via Bounded Eluder Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value function approximation has demonstrated phenomenal empirical success in\nreinforcement learning (RL). Nevertheless, despite a handful of recent progress\non developing theory for RL with linear function approximation, the\nunderstanding of general function approximation schemes largely remains\nmissing. In this paper, we establish a provably efficient RL algorithm with\ngeneral value function approximation. We show that if the value functions admit\nan approximation with a function class $\\mathcal{F}$, our algorithm achieves a\nregret bound of $\\widetilde{O}(\\mathrm{poly}(dH)\\sqrt{T})$ where $d$ is a\ncomplexity measure of $\\mathcal{F}$ that depends on the eluder dimension [Russo\nand Van Roy, 2013] and log-covering numbers, $H$ is the planning horizon, and\n$T$ is the number interactions with the environment. Our theory generalizes\nrecent progress on RL with linear value function approximation and does not\nmake explicit assumptions on the model of the environment. Moreover, our\nalgorithm is model-free and provides a framework to justify the effectiveness\nof algorithms used in practice.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:36:09 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 18:59:13 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 17:49:05 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Wang", "Ruosong", ""], ["Salakhutdinov", "Ruslan", ""], ["Yang", "Lin F.", ""]]}, {"id": "2005.10807", "submitter": "Stephan Wojtowytsch", "authors": "Weinan E and Stephan Wojtowytsch", "title": "Kolmogorov Width Decay and Poor Approximators in Machine Learning:\n  Shallow Neural Networks, Random Feature Models and Neural Tangent Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a scale separation of Kolmogorov width type between subspaces of\na given Banach space under the condition that a sequence of linear maps\nconverges much faster on one of the subspaces. The general technique is then\napplied to show that reproducing kernel Hilbert spaces are poor\n$L^2$-approximators for the class of two-layer neural networks in high\ndimension, and that multi-layer networks with small path norm are poor\napproximators for certain Lipschitz functions, also in the $L^2$-topology.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:40:38 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 05:33:48 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["E", "Weinan", ""], ["Wojtowytsch", "Stephan", ""]]}, {"id": "2005.10815", "submitter": "Stephan Wojtowytsch", "authors": "Stephan Wojtowytsch and Weinan E", "title": "Can Shallow Neural Networks Beat the Curse of Dimensionality? A mean\n  field training perspective", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the gradient descent training of a two-layer neural network on\nempirical or population risk may not decrease population risk at an order\nfaster than $t^{-4/(d-2)}$ under mean field scaling. Thus gradient descent\ntraining for fitting reasonably smooth, but truly high-dimensional data may be\nsubject to the curse of dimensionality. We present numerical evidence that\ngradient descent training with general Lipschitz target functions becomes\nslower and slower as the dimension increases, but converges at approximately\nthe same rate in all dimensions when the target function lies in the natural\nfunction space for two-layer ReLU networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:50:15 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Wojtowytsch", "Stephan", ""], ["E", "Weinan", ""]]}, {"id": "2005.10817", "submitter": "Alexander Wein", "authors": "Matthias L\\\"offler, Alexander S. Wein, Afonso S. Bandeira", "title": "Computationally efficient sparse clustering", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study statistical and computational limits of clustering when the means of\nthe centres are sparse and their dimension is possibly much larger than the\nsample size. Our theoretical analysis focuses on the model $X_i = z_i \\theta +\n\\varepsilon_i, ~z_i \\in \\{-1,1\\}, ~\\varepsilon_i \\thicksim \\mathcal{N}(0,I)$,\nwhich has two clusters with centres $\\theta$ and $-\\theta$. We provide a finite\nsample analysis of a new sparse clustering algorithm based on sparse PCA and\nshow that it achieves the minimax optimal misclustering rate in the regime\n$\\|\\theta\\| \\rightarrow \\infty$.\n  Our results require the sparsity to grow slower than the square root of the\nsample size. Using a recent framework for computational lower bounds -- the\nlow-degree likelihood ratio -- we give evidence that this condition is\nnecessary for any polynomial-time clustering algorithm to succeed below the BBP\nthreshold. This complements existing evidence based on reductions and\nstatistical query lower bounds. Compared to these existing results, we cover a\nwider set of parameter regimes and give a more precise understanding of the\nruntime required and the misclustering error achievable. Our results imply that\na large class of tests based on low-degree polynomials fail to solve even the\nweak testing task.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:51:30 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:21:09 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 17:38:04 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["L\u00f6ffler", "Matthias", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""]]}, {"id": "2005.10831", "submitter": "Xiang Song Dr.", "authors": "Xiangxiang Zeng, Xiang Song, Tengfei Ma, Xiaoqin Pan, Yadi Zhou, Yuan\n  Hou, Zheng Zhang, George Karypis, and Feixiong Cheng", "title": "Repurpose Open Data to Discover Therapeutics for COVID-19 using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been more than 850,000 confirmed cases and over 48,000 deaths from\nthe human coronavirus disease 2019 (COVID-19) pandemic, caused by novel severe\nacute respiratory syndrome coronavirus (SARS-CoV-2), in the United States\nalone. However, there are currently no proven effective medications against\nCOVID-19. Drug repurposing offers a promising way for the development of\nprevention and treatment strategies for COVID-19. This study reports an\nintegrative, network-based deep learning methodology to identify repurposable\ndrugs for COVID-19 (termed CoV-KGE). Specifically, we built a comprehensive\nknowledge graph that includes 15 million edges across 39 types of relationships\nconnecting drugs, diseases, genes, pathways, and expressions, from a large\nscientific corpus of 24 million PubMed publications. Using Amazon AWS computing\nresources, we identified 41 repurposable drugs (including indomethacin,\ntoremifene and niclosamide) whose therapeutic association with COVID-19 were\nvalidated by transcriptomic and proteomic data in SARS-CoV-2 infected human\ncells and data from ongoing clinical trials. While this study, by no means\nrecommends specific drugs, it demonstrates a powerful deep learning methodology\nto prioritize existing drugs for further investigation, which holds the\npotential of accelerating therapeutic development for COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 16:02:29 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Zeng", "Xiangxiang", ""], ["Song", "Xiang", ""], ["Ma", "Tengfei", ""], ["Pan", "Xiaoqin", ""], ["Zhou", "Yadi", ""], ["Hou", "Yuan", ""], ["Zhang", "Zheng", ""], ["Karypis", "George", ""], ["Cheng", "Feixiong", ""]]}, {"id": "2005.10848", "submitter": "Surin Ahn", "authors": "Surin Ahn, Ayfer Ozgur and Mert Pilanci", "title": "Global Multiclass Classification and Dataset Construction via\n  Heterogeneous Local Experts", "comments": "27 pages, 8 figures, to be published in IEEE Journal on Selected\n  Areas in Information Theory (JSAIT) - Special Issue on Estimation and\n  Inference", "journal-ref": null, "doi": "10.1109/JSAIT.2020.3041804", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domains of dataset construction and crowdsourcing, a notable challenge\nis to aggregate labels from a heterogeneous set of labelers, each of whom is\npotentially an expert in some subset of tasks (and less reliable in others). To\nreduce costs of hiring human labelers or training automated labeling systems,\nit is of interest to minimize the number of labelers while ensuring the\nreliability of the resulting dataset. We model this as the problem of\nperforming $K$-class classification using the predictions of smaller\nclassifiers, each trained on a subset of $[K]$, and derive bounds on the number\nof classifiers needed to accurately infer the true class of an unlabeled sample\nunder both adversarial and stochastic assumptions. By exploiting a connection\nto the classical set cover problem, we produce a near-optimal scheme for\ndesigning such configurations of classifiers which recovers the well known\none-vs.-one classification approach as a special case. Experiments with the\nMNIST and CIFAR-10 datasets demonstrate the favorable accuracy (compared to a\ncentralized classifier) of our aggregation scheme applied to classifiers\ntrained on subsets of the data. These results suggest a new way to\nautomatically label data or adapt an existing set of local classifiers to\nlarger-scale multiclass problems.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 18:07:42 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 04:34:43 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 23:34:36 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ahn", "Surin", ""], ["Ozgur", "Ayfer", ""], ["Pilanci", "Mert", ""]]}, {"id": "2005.10851", "submitter": "Yinghan Long", "authors": "Yinghan Long, Indranil Chakraborty, Kaushik Roy", "title": "Conditionally Deep Hybrid Neural Networks Across Edge and Cloud", "comments": "6 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasiveness of \"Internet-of-Things\" in our daily life has led to a\nrecent surge in fog computing, encompassing a collaboration of cloud computing\nand edge intelligence. To that effect, deep learning has been a major driving\nforce towards enabling such intelligent systems. However, growing model sizes\nin deep learning pose a significant challenge towards deployment in\nresource-constrained edge devices. Moreover, in a distributed intelligence\nenvironment, efficient workload distribution is necessary between edge and\ncloud systems. To address these challenges, we propose a conditionally deep\nhybrid neural network for enabling AI-based fog computing. The proposed network\ncan be deployed in a distributed manner, consisting of quantized layers and\nearly exits at the edge and full-precision layers on the cloud. During\ninference, if an early exit has high confidence in the classification results,\nit would allow samples to exit at the edge, and the deeper layers on the cloud\nare activated conditionally, which can lead to improved energy efficiency and\ninference latency. We perform an extensive design space exploration with the\ngoal of minimizing energy consumption at the edge while achieving\nstate-of-the-art classification accuracies on image classification tasks. We\nshow that with binarized layers at the edge, the proposed conditional hybrid\nnetwork can process 65% of inferences at the edge, leading to 5.5x\ncomputational energy reduction with minimal accuracy degradation on CIFAR-10\ndataset. For the more complex dataset CIFAR-100, we observe that the proposed\nnetwork with 4-bit quantization at the edge achieves 52% early classification\nat the edge with 4.8x energy reduction. The analysis gives us insights on\ndesigning efficient hybrid networks which achieve significantly higher energy\nefficiency than full-precision networks for edge-cloud based distributed\nintelligence systems.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 18:18:43 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Long", "Yinghan", ""], ["Chakraborty", "Indranil", ""], ["Roy", "Kaushik", ""]]}, {"id": "2005.10879", "submitter": "Steven Smith", "authors": "Steven T. Smith, Edward K. Kao, Erika D. Mackin, Danelle C. Shah, Olga\n  Simek, Donald B. Rubin", "title": "Automatic Detection of Influential Actors in Disinformation Networks", "comments": "Proc. Natl. Acad. Sciences U.S.A. Vol. 118, No. 4, e2011216118", "journal-ref": null, "doi": "10.1073/pnas.2011216118", "report-no": null, "categories": "cs.SI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weaponization of digital communications and social media to conduct\ndisinformation campaigns at immense scale, speed, and reach presents new\nchallenges to identify and counter hostile influence operations (IOs). This\npaper presents an end-to-end framework to automate detection of disinformation\nnarratives, networks, and influential actors. The framework integrates natural\nlanguage processing, machine learning, graph analytics, and a novel network\ncausal inference approach to quantify the impact of individual actors in\nspreading IO narratives. We demonstrate its capability on real-world hostile IO\ncampaigns with Twitter datasets collected during the 2017 French presidential\nelections, and known IO accounts disclosed by Twitter over a broad range of IO\ncampaigns (May 2007 to February 2020), over 50,000 accounts, 17 countries, and\ndifferent account types including both trolls and bots. Our system detects IO\naccounts with 96% precision, 79% recall, and 96% area-under-the-PR-curve, maps\nout salient network communities, and discovers high-impact accounts that escape\nthe lens of traditional impact statistics based on activity counts and network\ncentrality. Results are corroborated with independent sources of known IO\naccounts from U.S. Congressional reports, investigative journalism, and IO\ndatasets provided by Twitter.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 20:15:51 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 01:10:13 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 22:15:57 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Smith", "Steven T.", ""], ["Kao", "Edward K.", ""], ["Mackin", "Erika D.", ""], ["Shah", "Danelle C.", ""], ["Simek", "Olga", ""], ["Rubin", "Donald B.", ""]]}, {"id": "2005.10881", "submitter": "Bargav Jayaraman", "authors": "Bargav Jayaraman, Lingxiao Wang, Katherine Knipmeyer, Quanquan Gu,\n  David Evans", "title": "Revisiting Membership Inference Under Realistic Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study membership inference in settings where some of the assumptions\ntypically used in previous research are relaxed. First, we consider skewed\npriors, to cover cases such as when only a small fraction of the candidate pool\ntargeted by the adversary are actually members and develop a PPV-based metric\nsuitable for this setting. This setting is more realistic than the balanced\nprior setting typically considered by researchers. Second, we consider\nadversaries that select inference thresholds according to their attack goals\nand develop a threshold selection procedure that improves inference attacks.\nSince previous inference attacks fail in imbalanced prior setting, we develop a\nnew inference attack based on the intuition that inputs corresponding to\ntraining set members will be near a local minimum in the loss function, and\nshow that an attack that combines this with thresholds on the per-instance loss\ncan achieve high PPV even in settings where other attacks appear to be\nineffective. Code for our experiments can be found here:\nhttps://github.com/bargavj/EvaluatingDPML.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 20:17:42 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 17:24:39 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 16:57:30 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 13:37:57 GMT"}, {"version": "v5", "created": "Wed, 13 Jan 2021 20:44:44 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Jayaraman", "Bargav", ""], ["Wang", "Lingxiao", ""], ["Knipmeyer", "Katherine", ""], ["Gu", "Quanquan", ""], ["Evans", "David", ""]]}, {"id": "2005.10884", "submitter": "Chong Xiang", "authors": "Chong Xiang, Arjun Nitin Bhagoji, Vikash Sehwag, Prateek Mittal", "title": "PatchGuard: A Provably Robust Defense against Adversarial Patches via\n  Small Receptive Fields and Masking", "comments": "USENIX Security Symposium 2021; extended technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localized adversarial patches aim to induce misclassification in machine\nlearning models by arbitrarily modifying pixels within a restricted region of\nan image. Such attacks can be realized in the physical world by attaching the\nadversarial patch to the object to be misclassified, and defending against such\nattacks is an unsolved/open problem. In this paper, we propose a general\ndefense framework called PatchGuard that can achieve high provable robustness\nwhile maintaining high clean accuracy against localized adversarial patches.\nThe cornerstone of PatchGuard involves the use of CNNs with small receptive\nfields to impose a bound on the number of features corrupted by an adversarial\npatch. Given a bounded number of corrupted features, the problem of designing\nan adversarial patch defense reduces to that of designing a secure feature\naggregation mechanism. Towards this end, we present our robust masking defense\nthat robustly detects and masks corrupted features to recover the correct\nprediction. Notably, we can prove the robustness of our defense against any\nadversary within our threat model. Our extensive evaluation on ImageNet,\nImageNette (a 10-class subset of ImageNet), and CIFAR-10 datasets demonstrates\nthat our defense achieves state-of-the-art performance in terms of both\nprovable robust accuracy and clean accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 03:38:34 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:51:03 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 15:39:00 GMT"}, {"version": "v4", "created": "Sun, 18 Oct 2020 18:12:03 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 14:20:39 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Xiang", "Chong", ""], ["Bhagoji", "Arjun Nitin", ""], ["Sehwag", "Vikash", ""], ["Mittal", "Prateek", ""]]}, {"id": "2005.10902", "submitter": "Artur M Schweidtmann", "authors": "Artur M. Schweidtmann, Dominik Bongartz, Daniel Grothe, Tim\n  Kerkenhoff, Xiaopeng Lin, Jaromil Najman, Alexander Mitsos", "title": "Global Optimization of Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes~(Kriging) are interpolating data-driven models that are\nfrequently applied in various disciplines. Often, Gaussian processes are\ntrained on datasets and are subsequently embedded as surrogate models in\noptimization problems. These optimization problems are nonconvex and global\noptimization is desired. However, previous literature observed computational\nburdens limiting deterministic global optimization to Gaussian processes\ntrained on few data points. We propose a reduced-space formulation for\ndeterministic global optimization with trained Gaussian processes embedded. For\noptimization, the branch-and-bound solver branches only on the degrees of\nfreedom and McCormick relaxations are propagated through explicit Gaussian\nprocess models. The approach also leads to significantly smaller and\ncomputationally cheaper subproblems for lower and upper bounding. To further\naccelerate convergence, we derive envelopes of common covariance functions for\nGPs and tight relaxations of acquisition functions used in Bayesian\noptimization including expected improvement, probability of improvement, and\nlower confidence bound. In total, we reduce computational time by orders of\nmagnitude compared to state-of-the-art methods, thus overcoming previous\ncomputational burdens. We demonstrate the performance and scaling of the\nproposed method and apply it to Bayesian optimization with global optimization\nof the acquisition function and chance-constrained programming. The Gaussian\nprocess models, acquisition functions, and training scripts are available\nopen-source within the \"MeLOn - Machine Learning Models for Optimization\"\ntoolbox~(https://git.rwth-aachen.de/avt.svt/public/MeLOn).\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 20:59:11 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Schweidtmann", "Artur M.", ""], ["Bongartz", "Dominik", ""], ["Grothe", "Daniel", ""], ["Kerkenhoff", "Tim", ""], ["Lin", "Xiaopeng", ""], ["Najman", "Jaromil", ""], ["Mitsos", "Alexander", ""]]}, {"id": "2005.10918", "submitter": "Shenda Hong", "authors": "Cao Xiao, Trong Nghia Hoang, Shenda Hong, Tengfei Ma, Jimeng Sun", "title": "CHEER: Rich Model Helps Poor Model via Knowledge Infusion", "comments": "Published in TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a growing interest in applying deep learning (DL) to healthcare,\ndriven by the availability of data with multiple feature channels in rich-data\nenvironments (e.g., intensive care units). However, in many other practical\nsituations, we can only access data with much fewer feature channels in a\npoor-data environments (e.g., at home), which often results in predictive\nmodels with poor performance. How can we boost the performance of models\nlearned from such poor-data environment by leveraging knowledge extracted from\nexisting models trained using rich data in a related environment? To address\nthis question, we develop a knowledge infusion framework named CHEER that can\nsuccinctly summarize such rich model into transferable representations, which\ncan be incorporated into the poor model to improve its performance. The infused\nmodel is analyzed theoretically and evaluated empirically on several datasets.\nOur empirical results showed that CHEER outperformed baselines by 5.60% to\n46.80% in terms of the macro-F1 score on multiple physiological datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:44:21 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Xiao", "Cao", ""], ["Hoang", "Trong Nghia", ""], ["Hong", "Shenda", ""], ["Ma", "Tengfei", ""], ["Sun", "Jimeng", ""]]}, {"id": "2005.10919", "submitter": "Rahul Mehta", "authors": "Rahul Mehta, Muge Karaman", "title": "Correlated Mixed Membership Modeling of Somatic Mutations", "comments": "To be published in IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies of cancer somatic mutation profiles seek to identify mutations\nfor targeted therapy in personalized medicine. Analysis of profiles, however,\nis not trivial, as each profile is heterogeneous and there are multiple\nconfounding factors that influence the cause-and-effect relationships between\ncancer genes such as cancer (sub)type, biological processes, total number of\nmutations, and non-linear mutation interactions. Moreover, cancer is\nbiologically redundant, i.e., distinct mutations can result in the alteration\nof similar biological processes, so it is important to identify all possible\ncombinatorial sets of mutations for effective patient treatment. To model this\nphenomena, we propose the correlated zero-inflated negative binomial process to\ninfer the inherent structure of somatic mutation profiles through latent\nrepresentations. This stochastic process takes into account different, yet\ncorrelated, co-occurring mutations using profile-specific negative binomial\ndispersion parameters that are mixed with a correlated beta-Bernoulli process\nand a probability parameter to model profile heterogeneity. These model\nparameters are inferred by iterative optimization via amortized and stochastic\nvariational inference using the Pan Cancer dataset from The Cancer Genomic\nArchive (TCGA). By examining the the latent space, we identify biologically\nrelevant correlations between somatic mutations.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:52:35 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Mehta", "Rahul", ""], ["Karaman", "Muge", ""]]}, {"id": "2005.10953", "submitter": "Xiaoxu Li", "authors": "Xiaoxu Li and Zhuo Sun and Jing-Hao Xue and Zhanyu Ma", "title": "A Concise Review of Recent Few-shot Meta-learning Methods", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot meta-learning has been recently reviving with expectations to mimic\nhumanity's fast adaption to new concepts based on prior knowledge. In this\nshort communication, we give a concise review on recent representative methods\nin few-shot meta-learning, which are categorized into four branches according\nto their technical characteristics. We conclude this review with some vital\ncurrent challenges and future prospects in few-shot meta-learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 00:39:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Li", "Xiaoxu", ""], ["Sun", "Zhuo", ""], ["Xue", "Jing-Hao", ""], ["Ma", "Zhanyu", ""]]}, {"id": "2005.10970", "submitter": "Kechen Qin", "authors": "Kechen Qin, Yu Wang, Cheng Li, Kalpa Gunaratna, Hongxia Jin, Virgil\n  Pavlu, Javed A. Aslam", "title": "A Complex KBQA System using Multiple Reasoning Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop knowledge based question answering (KBQA) is a complex task for\nnatural language understanding. Many KBQA approaches have been proposed in\nrecent years, and most of them are trained based on labeled reasoning path.\nThis hinders the system's performance as many correct reasoning paths are not\nlabeled as ground truth, and thus they cannot be learned. In this paper, we\nintroduce an end-to-end KBQA system which can leverage multiple reasoning\npaths' information and only requires labeled answer as supervision. We conduct\nexperiments on several benchmark datasets containing both single-hop simple\nquestions as well as muti-hop complex questions, including WebQuestionSP\n(WQSP), ComplexWebQuestion-1.1 (CWQ), and PathQuestion-Large (PQL), and\ndemonstrate strong performance.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 02:35:42 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Qin", "Kechen", ""], ["Wang", "Yu", ""], ["Li", "Cheng", ""], ["Gunaratna", "Kalpa", ""], ["Jin", "Hongxia", ""], ["Pavlu", "Virgil", ""], ["Aslam", "Javed A.", ""]]}, {"id": "2005.10996", "submitter": "Garrett Wilson", "authors": "Garrett Wilson, Janardhan Rao Doppa, Diane J. Cook", "title": "Multi-Source Deep Domain Adaptation with Weak Supervision for\n  Time-Series Sensor Data", "comments": "Accepted at KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) offers a valuable means to reuse data and models for\nnew problem domains. However, robust techniques have not yet been considered\nfor time series data with varying amounts of data availability. In this paper,\nwe make three main contributions to fill this gap. First, we propose a novel\nConvolutional deep Domain Adaptation model for Time Series data (CoDATS) that\nsignificantly improves accuracy and training time over state-of-the-art DA\nstrategies on real-world sensor data benchmarks. By utilizing data from\nmultiple source domains, we increase the usefulness of CoDATS to further\nimprove accuracy over prior single-source methods, particularly on complex time\nseries datasets that have high variability between domains. Second, we propose\na novel Domain Adaptation with Weak Supervision (DA-WS) method by utilizing\nweak supervision in the form of target-domain label distributions, which may be\neasier to collect than additional data labels. Third, we perform comprehensive\nexperiments on diverse real-world datasets to evaluate the effectiveness of our\ndomain adaptation and weak supervision methods. Results show that CoDATS for\nsingle-source DA significantly improves over the state-of-the-art methods, and\nwe achieve additional improvements in accuracy using data from multiple source\ndomains and weakly supervised signals. Code is available at:\nhttps://github.com/floft/codats\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 04:16:58 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Wilson", "Garrett", ""], ["Doppa", "Janardhan Rao", ""], ["Cook", "Diane J.", ""]]}, {"id": "2005.11018", "submitter": "Jingge Zhu", "authors": "Jingge Zhu", "title": "Semi-Supervised Learning: the Case When Unlabeled Data is Equally Useful", "comments": "accepted to UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning algorithms attempt to take advantage of relatively\ninexpensive unlabeled data to improve learning performance. In this work, we\nconsider statistical models where the data distributions can be characterized\nby continuous parameters. We show that under certain conditions on the\ndistribution, unlabeled data is equally useful as labeled date in terms of\nlearning rate. Specifically, let $n, m$ be the number of labeled and unlabeled\ndata, respectively. It is shown that the learning rate of semi-supervised\nlearning scales as $O(1/n)$ if $m\\sim n$, and scales as $O(1/n^{1+\\gamma})$ if\n$m\\sim n^{1+\\gamma}$ for some $\\gamma>0$, whereas the learning rate of\nsupervised learning scales as $O(1/n)$.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:05:00 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 06:53:36 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhu", "Jingge", ""]]}, {"id": "2005.11045", "submitter": "Jerry Lonlac", "authors": "Micha\\\"el Chirmeni Boujike, Jerry Lonlac, Norbert Tsopze, Engelbert\n  Mephu Nguifo", "title": "Discovering Frequent Gradual Itemsets with Imprecise Data", "comments": "24 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gradual patterns that model the complex co-variations of attributes of\nthe form \"The more/less X, The more/less Y\" play a crucial role in many real\nworld applications where the amount of numerical data to manage is important,\nthis is the biological data. Recently, these types of patterns have caught the\nattention of the data mining community, where several methods have been defined\nto automatically extract and manage these patterns from different data models.\nHowever, these methods are often faced the problem of managing the quantity of\nmined patterns, and in many practical applications, the calculation of all\nthese patterns can prove to be intractable for the user-defined frequency\nthreshold and the lack of focus leads to generating huge collections of\npatterns. Moreover another problem with the traditional approaches is that the\nconcept of gradualness is defined just as an increase or a decrease. Indeed, a\ngradualness is considered as soon as the values of the attribute on both\nobjects are different. As a result, numerous quantities of patterns extracted\nby traditional algorithms can be presented to the user although their\ngradualness is only a noise effect in the data. To address this issue, this\npaper suggests to introduce the gradualness thresholds from which to consider\nan increase or a decrease. In contrast to literature approaches, the proposed\napproach takes into account the distribution of attribute values, as well as\nthe user's preferences on the gradualness threshold and makes it possible to\nextract gradual patterns on certain databases where literature approaches fail\ndue to too large search space. Moreover, results from an experimental\nevaluation on real databases show that the proposed algorithm is scalable,\nefficient, and can eliminate numerous patterns that do not verify specific\ngradualness requirements to show a small set of patterns to the user.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 08:02:15 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Boujike", "Micha\u00ebl Chirmeni", ""], ["Lonlac", "Jerry", ""], ["Tsopze", "Norbert", ""], ["Nguifo", "Engelbert Mephu", ""]]}, {"id": "2005.11065", "submitter": "Wenjie Huang", "authors": "Wenjie Huang, Jing Jiang, Xiao Liu", "title": "Online Non-convex Learning for River Pollution Source Identification", "comments": "27 Pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, novel gradient based online learning algorithms are developed\nto investigate an important environmental application: real-time river\npollution source identification, which aims at estimating the released mass,\nthe location and the released time of a river pollution source based on\ndownstream sensor data monitoring the pollution concentration. The problem can\nbe formulated as a non-convex loss minimization problem in statistical\nlearning, and our online algorithms have vectorized and adaptive step-sizes to\nensure high estimation accuracy on dimensions having different magnitudes. In\norder to avoid gradient-based method sticking into the saddle points of\nnon-convex loss, the \"escaping from saddle points\" module and multi-start\nversion of algorithms are derived to further improve the estimation accuracy by\nsearching for the global minimimals of the loss functions. It can be shown\ntheoretically and experimentally $O(N)$ local regret of the algorithms, and the\nhigh probability cumulative regret bound $O(N)$ under particular error bound\ncondition on loss functions. A real-life river pollution source identification\nexample shows superior performance of our algorithms than the existing methods\nin terms of estimating accuracy. The managerial insights for decision maker to\nuse the algorithm in reality are also provided.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:01:05 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Huang", "Wenjie", ""], ["Jiang", "Jing", ""], ["Liu", "Xiao", ""]]}, {"id": "2005.11067", "submitter": "Diego Antognini", "authors": "Diego Antognini and Claudiu Musat and Boi Faltings", "title": "Interacting with Explanations through Critiquing", "comments": "Accepted at IJCAI 2021. 15 pages, 10 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using personalized explanations to support recommendations has been shown to\nincrease trust and perceived quality. However, to actually obtain better\nrecommendations, there needs to be a means for users to modify the\nrecommendation criteria by interacting with the explanation. We present a novel\ntechnique using aspect markers that learns to generate personalized\nexplanations of recommendations from review texts, and we show that human users\nsignificantly prefer these explanations over those produced by state-of-the-art\ntechniques. Our work's most important innovation is that it allows users to\nreact to a recommendation by critiquing the textual explanation: removing\n(symmetrically adding) certain aspects they dislike or that are no longer\nrelevant (symmetrically that are of interest). The system updates its user\nmodel and the resulting recommendations according to the critique. This is\nbased on a novel unsupervised critiquing method for single- and multi-step\ncritiquing with textual explanations. Experiments on two real-world datasets\nshow that our system is the first to achieve good performance in adapting to\nthe preferences expressed in multi-step critiquing.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:03:06 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 09:07:21 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 10:32:26 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Antognini", "Diego", ""], ["Musat", "Claudiu", ""], ["Faltings", "Boi", ""]]}, {"id": "2005.11074", "submitter": "George Kyriakides", "authors": "George Kyriakides and Konstantinos Margaritis", "title": "An Introduction to Neural Architecture Search for Convolutional Networks", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) is a research field concerned with utilizing\noptimization algorithms to design optimal neural network architectures. There\nare many approaches concerning the architectural search spaces, optimization\nalgorithms, as well as candidate architecture evaluation methods. As the field\nis growing at a continuously increasing pace, it is difficult for a beginner to\ndiscern between major, as well as emerging directions the field has followed.\nIn this work, we provide an introduction to the basic concepts of NAS for\nconvolutional networks, along with the major advances in search spaces,\nalgorithms and evaluation techniques.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:33:22 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Kyriakides", "George", ""], ["Margaritis", "Konstantinos", ""]]}, {"id": "2005.11079", "submitter": "Wenzheng Feng", "authors": "Wenzheng Feng, Jie Zhang, Yuxiao Dong, Yu Han, Huanbo Luan, Qian Xu,\n  Qiang Yang, Evgeny Kharlamov, Jie Tang", "title": "Graph Random Neural Network for Semi-Supervised Learning on Graphs", "comments": "18 pages. Accepted by NeurIPS 2020. Final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of semi-supervised learning on graphs, for which graph\nneural networks (GNNs) have been extensively explored. However, most existing\nGNNs inherently suffer from the limitations of over-smoothing, non-robustness,\nand weak-generalization when labeled nodes are scarce. In this paper, we\npropose a simple yet effective framework---GRAPH RANDOM NEURAL NETWORKS\n(GRAND)---to address these issues. In GRAND, we first design a random\npropagation strategy to perform graph data augmentation. Then we leverage\nconsistency regularization to optimize the prediction consistency of unlabeled\nnodes across different data augmentations. Extensive experiments on graph\nbenchmark datasets suggest that GRAND significantly outperforms\nstate-of-the-art GNN baselines on semi-supervised node classification. Finally,\nwe show that GRAND mitigates the issues of over-smoothing and non-robustness,\nexhibiting better generalization behavior than existing GNNs. The source code\nof GRAND is publicly available at https://github.com/Grand20/grand.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:40:13 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 07:51:17 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 05:21:52 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Feng", "Wenzheng", ""], ["Zhang", "Jie", ""], ["Dong", "Yuxiao", ""], ["Han", "Yu", ""], ["Luan", "Huanbo", ""], ["Xu", "Qian", ""], ["Yang", "Qiang", ""], ["Kharlamov", "Evgeny", ""], ["Tang", "Jie", ""]]}, {"id": "2005.11081", "submitter": "Natalia Vesselinova", "authors": "Natalia Vesselinova, Rebecca Steinert, Daniel F. Perez-Ramirez, and\n  Magnus Boman", "title": "Learning Combinatorial Optimization on Graphs: A Survey with\n  Applications to Networking", "comments": "29 pages, 1 figure, open access journal publication", "journal-ref": "IEEE Access, vol. 8, 2020, pp. 120388--120416", "doi": "10.1109/ACCESS.2020.3004964", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to solving combinatorial optimization problems on graphs\nsuffer from the need to engineer each problem algorithmically, with practical\nproblems recurring in many instances. The practical side of theoretical\ncomputer science, such as computational complexity, then needs to be addressed.\nRelevant developments in machine learning research on graphs are surveyed for\nthis purpose. We organize and compare the structures involved with learning to\nsolve combinatorial optimization problems, with a special eye on the\ntelecommunications domain and its continuous development of live and research\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:45:36 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:03:39 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Vesselinova", "Natalia", ""], ["Steinert", "Rebecca", ""], ["Perez-Ramirez", "Daniel F.", ""], ["Boman", "Magnus", ""]]}, {"id": "2005.11107", "submitter": "Kisung You", "authors": "Kisung You", "title": "Rdimtools: An R package for Dimension Reduction and Intrinsic Dimension\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering patterns of the complex high-dimensional data is a long-standing\nproblem. Dimension Reduction (DR) and Intrinsic Dimension Estimation (IDE) are\ntwo fundamental thematic programs that facilitate geometric understanding of\nthe data. We present Rdimtools - an R package that supports 133 DR and 17 IDE\nalgorithms whose extent makes multifaceted scrutiny of the data in one place\neasier. Rdimtools is distributed under the MIT license and is accessible from\nCRAN, GitHub, and its package website, all of which deliver instruction for\ninstallation, self-contained examples, and API documentation.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 11:06:43 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["You", "Kisung", ""]]}, {"id": "2005.11110", "submitter": "Jakob Lindinger", "authors": "Jakob Lindinger, David Reeb, Christoph Lippert, Barbara Rakitsch", "title": "Beyond the Mean-Field: Structured Deep Gaussian Processes Improve the\n  Predictive Uncertainties", "comments": "12 pages main text, 20 pages appendix. v2: changes due to NeurIPS\n  review process. Camera-ready version to be published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Gaussian Processes learn probabilistic data representations for\nsupervised learning by cascading multiple Gaussian Processes. While this model\nfamily promises flexible predictive distributions, exact inference is not\ntractable. Approximate inference techniques trade off the ability to closely\nresemble the posterior distribution against speed of convergence and\ncomputational efficiency. We propose a novel Gaussian variational family that\nallows for retaining covariances between latent processes while achieving fast\nconvergence by marginalising out all global latent variables. After providing a\nproof of how this marginalisation can be done for general covariances, we\nrestrict them to the ones we empirically found to be most important in order to\nalso achieve computational efficiency. We provide an efficient implementation\nof our new approach and apply it to several benchmark datasets. It yields\nexcellent results and strikes a better balance between accuracy and calibrated\nuncertainty estimates than its state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 11:10:59 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 13:53:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lindinger", "Jakob", ""], ["Reeb", "David", ""], ["Lippert", "Christoph", ""], ["Rakitsch", "Barbara", ""]]}, {"id": "2005.11115", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "Consistency of Extreme Learning Machines and Regression under\n  Non-Stationarity and Dependence for ML-Enhanced Moving Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning by extreme learning machines resp. neural networks with\nrandom weights is studied under a non-stationary spatial-temporal sampling\ndesign which especially addresses settings where an autonomous object moving in\na non-stationary spatial environment collects and analyzes data. The stochastic\nmodel especially allows for spatial heterogeneity and weak dependence. As\nefficient and computationally cheap learning methods (unconstrained) least\nsquares, ridge regression and $\\ell_s$-penalized least squares (including the\nLASSO) are studied. Consistency and asymptotic normality of the least squares\nand ridge regression estimates as well as corresponding consistency results for\nthe $\\ell_s$-penalty are shown under weak conditions. The resuts also cover\nbounds for the sample squared predicition error.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 11:29:15 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 17:05:07 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 09:56:40 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "2005.11138", "submitter": "Marko Stamenovic", "authors": "Igor Fedorov, Marko Stamenovic, Carl Jensen, Li-Chia Yang, Ari\n  Mandell, Yiming Gan, Matthew Mattina, Paul N. Whatmough", "title": "TinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids", "comments": "First four authors contributed equally. For audio samples, see\n  https://github.com/BoseCorp/efficient-neural-speech-enhancement", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern speech enhancement algorithms achieve remarkable noise suppression by\nmeans of large recurrent neural networks (RNNs). However, large RNNs limit\npractical deployment in hearing aid hardware (HW) form-factors, which are\nbattery powered and run on resource-constrained microcontroller units (MCUs)\nwith limited memory capacity and compute capability. In this work, we use model\ncompression techniques to bridge this gap. We define the constraints imposed on\nthe RNN by the HW and describe a method to satisfy them. Although model\ncompression techniques are an active area of research, we are the first to\ndemonstrate their efficacy for RNN speech enhancement, using pruning and\ninteger quantization of weights/activations. We also demonstrate state update\nskipping, which reduces the computational load. Finally, we conduct a\nperceptual evaluation of the compressed models to verify audio quality on human\nraters. Results show a reduction in model size and operations of 11.9$\\times$\nand 2.9$\\times$, respectively, over the baseline for compressed models, without\na statistical difference in listening preference and only exhibiting a loss of\n0.55dB SDR. Our model achieves a computational latency of 2.39ms, well within\nthe 10ms target and 351$\\times$ better than previous work.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 20:37:47 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Fedorov", "Igor", ""], ["Stamenovic", "Marko", ""], ["Jensen", "Carl", ""], ["Yang", "Li-Chia", ""], ["Mandell", "Ari", ""], ["Gan", "Yiming", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "2005.11144", "submitter": "Saaketh Desai", "authors": "Saaketh Desai, Alejandro Strachan", "title": "Parsimonious neural networks learn interpretable physical laws", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is playing an increasing role in the physical sciences and\nsignificant progress has been made towards embedding domain knowledge into\nmodels. Less explored is its use to discover interpretable physical laws from\ndata. We propose parsimonious neural networks (PNNs) that combine neural\nnetworks with evolutionary optimization to find models that balance accuracy\nwith parsimony. The power and versatility of the approach is demonstrated by\ndeveloping models for classical mechanics and to predict the melting\ntemperature of materials from fundamental properties. In the first example, the\nresulting PNNs are easily interpretable as Newton's second law, expressed as a\nnon-trivial time integrator that exhibits time-reversibility and conserves\nenergy, where the parsimony is critical to extract underlying symmetries from\nthe data. In the second case, the PNNs not only find the celebrated Lindemann\nmelting law, but also new relationships that outperform it in the pareto sense\nof parsimony vs. accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:15:47 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:08:51 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 21:36:40 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Desai", "Saaketh", ""], ["Strachan", "Alejandro", ""]]}, {"id": "2005.11164", "submitter": "Malte Schilling", "authors": "Malte Schilling, Kai Konen, Frank W. Ohl, Timo Korthals", "title": "Decentralized Deep Reinforcement Learning for a Distributed and Adaptive\n  Locomotion Controller of a Hexapod Robot", "comments": "Submitted as an IEEE conference paper (updated to 15 seeds in\n  comparisons)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Locomotion is a prime example for adaptive behavior in animals and biological\ncontrol principles have inspired control architectures for legged robots. While\nmachine learning has been successfully applied to many tasks in recent years,\nDeep Reinforcement Learning approaches still appear to struggle when applied to\nreal world robots in continuous control tasks and in particular do not appear\nas robust solutions that can handle uncertainties well. Therefore, there is a\nnew interest in incorporating biological principles into such learning\narchitectures. While inducing a hierarchical organization as found in motor\ncontrol has shown already some success, we here propose a decentralized\norganization as found in insect motor control for coordination of different\nlegs. A decentralized and distributed architecture is introduced on a simulated\nhexapod robot and the details of the controller are learned through Deep\nReinforcement Learning. We first show that such a concurrent local structure is\nable to learn better walking behavior. Secondly, that the simpler organization\nis learned faster compared to holistic approaches.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 11:40:37 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Schilling", "Malte", ""], ["Konen", "Kai", ""], ["Ohl", "Frank W.", ""], ["Korthals", "Timo", ""]]}, {"id": "2005.11194", "submitter": "Charlie Kirkwood", "authors": "Charlie Kirkwood", "title": "Deep covariate-learning: optimising information extraction from terrain\n  texture for geostatistical modelling applications", "comments": "14 pages, 8 figures, submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Where data is available, it is desirable in geostatistical modelling to make\nuse of additional covariates, for example terrain data, in order to improve\nprediction accuracy in the modelling task. While elevation itself may be\nimportant, additional explanatory power for any given problem can be sought\n(but not necessarily found) by filtering digital elevation models to extract\nhigher-order derivatives such as slope angles, curvatures, and roughness. In\nessence, it would be beneficial to extract as much task-relevant information as\npossible from the elevation grid. However, given the complexities of the\nnatural world, chance dictates that the use of 'off-the-shelf' filters is\nunlikely to derive covariates that provide strong explanatory power to the\ntarget variable at hand, and any attempt to manually design informative\ncovariates is likely to be a trial-and-error process -- not optimal. In this\npaper we present a solution to this problem in the form of a deep learning\napproach to automatically deriving optimal task-specific terrain texture\ncovariates from a standard SRTM 90m gridded digital elevation model (DEM). For\nour target variables we use point-sampled geochemical data from the British\nGeological Survey: concentrations of potassium, calcium and arsenic in stream\nsediments. We find that our deep learning approach produces covariates for\ngeostatistical modelling that have surprisingly strong explanatory power on\ntheir own, with R-squared values around 0.6 for all three elements (with\narsenic on the log scale). These results are achieved without the neural\nnetwork being provided with easting, northing, or absolute elevation as inputs,\nand purely reflect the capacity of our deep neural network to extract\ntask-specific information from terrain texture. We hope that these results will\ninspire further investigation into the capabilities of deep learning within\ngeostatistical applications.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 14:00:28 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 11:19:48 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kirkwood", "Charlie", ""]]}, {"id": "2005.11212", "submitter": "Max Tegmark", "authors": "Silviu-Marian Udrescu (MIT), Max Tegmark (MIT)", "title": "Symbolic Pregression: Discovering Physical Laws from Distorted Video", "comments": "Expanded and improved physics discussion, additional method details.\n  9 pages, 7 figs", "journal-ref": "Phys. Rev. E 103, 043307 (2021)", "doi": "10.1103/PhysRevE.103.043307", "report-no": null, "categories": "cs.CV cs.AI cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for unsupervised learning of equations of motion for\nobjects in raw and optionally distorted unlabeled video. We first train an\nautoencoder that maps each video frame into a low-dimensional latent space\nwhere the laws of motion are as simple as possible, by minimizing a combination\nof non-linearity, acceleration and prediction error. Differential equations\ndescribing the motion are then discovered using Pareto-optimal symbolic\nregression. We find that our pre-regression (\"pregression\") step is able to\nrediscover Cartesian coordinates of unlabeled moving objects even when the\nvideo is distorted by a generalized lens. Using intuition from multidimensional\nknot-theory, we find that the pregression step is facilitated by first adding\nextra latent space dimensions to avoid topological problems during training and\nthen removing these extra dimensions via principal component analysis.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:00:52 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 17:52:02 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Udrescu", "Silviu-Marian", "", "MIT"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "2005.11217", "submitter": "Prashnna Gyawali", "authors": "Prashnna Kumar Gyawali, Sandesh Ghimire, Pradeep Bajracharya, Zhiyuan\n  Li, Linwei Wang", "title": "Semi-supervised Medical Image Classification with Global Latent Mixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-aided diagnosis via deep learning relies on large-scale annotated\ndata sets, which can be costly when involving expert knowledge. Semi-supervised\nlearning (SSL) mitigates this challenge by leveraging unlabeled data. One\neffective SSL approach is to regularize the local smoothness of neural\nfunctions via perturbations around single data points. In this work, we argue\nthat regularizing the global smoothness of neural functions by filling the void\nin between data points can further improve SSL. We present a novel SSL approach\nthat trains the neural network on linear mixing of labeled and unlabeled data,\nat both the input and latent space in order to regularize different portions of\nthe network. We evaluated the presented model on two distinct medical image\ndata sets for semi-supervised classification of thoracic disease and skin\nlesion, demonstrating its improved performance over SSL with local\nperturbations and SSL with global mixing but at the input space only. Our code\nis available at https://github.com/Prasanna1991/LatentMixing.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 14:49:13 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Gyawali", "Prashnna Kumar", ""], ["Ghimire", "Sandesh", ""], ["Bajracharya", "Pradeep", ""], ["Li", "Zhiyuan", ""], ["Wang", "Linwei", ""]]}, {"id": "2005.11242", "submitter": "Antonio Quintero-Rincon", "authors": "Antonio Quintero-Rinc\\'on, Carlos D'Giano, Hadj Batatia", "title": "Mu-suppression detection in motor imagery electroencephalographic\n  signals using the generalized extreme value distribution", "comments": "10 pages, 6 Figures, 4 tables", "journal-ref": "IEEE 2020", "doi": "10.1109/IJCNN48605.2020.9206862", "report-no": "978-1-7281-6926-2", "categories": "eess.SP stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper deals with the detection of mu-suppression from\nelectroencephalographic (EEG) signals in brain-computer interface (BCI). For\nthis purpose, an efficient algorithm is proposed based on a statistical model\nand a linear classifier. Precisely, the generalized extreme value distribution\n(GEV) is proposed to represent the power spectrum density of the EEG signal in\nthe central motor cortex. The associated three parameters are estimated using\nthe maximum likelihood method. Based on these parameters, a simple and\nefficient linear classifier was designed to classify three types of events:\nimagery, movement, and resting. Preliminary results show that the proposed\nstatistical model can be used in order to detect precisely the mu-suppression\nand distinguish different EEG events, with very good classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 15:51:25 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 20:14:39 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Quintero-Rinc\u00f3n", "Antonio", ""], ["D'Giano", "Carlos", ""], ["Batatia", "Hadj", ""]]}, {"id": "2005.11248", "submitter": "Inkit Padhi", "authors": "Payel Das, Tom Sercu, Kahini Wadhawan, Inkit Padhi, Sebastian\n  Gehrmann, Flaviu Cipcigan, Vijil Chenthamarakshan, Hendrik Strobelt, Cicero\n  dos Santos, Pin-Yu Chen, Yi Yan Yang, Jeremy Tan, James Hedrick, Jason Crain,\n  Aleksandra Mojsilovic", "title": "Accelerating Antimicrobial Discovery with Controllable Deep Generative\n  Models and Molecular Dynamics", "comments": null, "journal-ref": "Nature Biomedical Engineering (2021)", "doi": "10.1038/s41551-021-00689-x", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De novo therapeutic design is challenged by a vast chemical repertoire and\nmultiple constraints, e.g., high broad-spectrum potency and low toxicity. We\npropose CLaSS (Controlled Latent attribute Space Sampling) - an efficient\ncomputational method for attribute-controlled generation of molecules, which\nleverages guidance from classifiers trained on an informative latent space of\nmolecules modeled using a deep generative autoencoder. We screen the generated\nmolecules for additional key attributes by using deep learning classifiers in\nconjunction with novel features derived from atomistic simulations. The\nproposed approach is demonstrated for designing non-toxic antimicrobial\npeptides (AMPs) with strong broad-spectrum potency, which are emerging drug\ncandidates for tackling antibiotic resistance. Synthesis and testing of only\ntwenty designed sequences identified two novel and minimalist AMPs with high\npotency against diverse Gram-positive and Gram-negative pathogens, including\none multidrug-resistant and one antibiotic-resistant K. pneumoniae, via\nmembrane pore formation. Both antimicrobials exhibit low in vitro and in vivo\ntoxicity and mitigate the onset of drug resistance. The proposed approach thus\npresents a viable path for faster and efficient discovery of potent and\nselective broad-spectrum antimicrobials.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 15:57:58 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 01:03:38 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Das", "Payel", ""], ["Sercu", "Tom", ""], ["Wadhawan", "Kahini", ""], ["Padhi", "Inkit", ""], ["Gehrmann", "Sebastian", ""], ["Cipcigan", "Flaviu", ""], ["Chenthamarakshan", "Vijil", ""], ["Strobelt", "Hendrik", ""], ["Santos", "Cicero dos", ""], ["Chen", "Pin-Yu", ""], ["Yang", "Yi Yan", ""], ["Tan", "Jeremy", ""], ["Hedrick", "James", ""], ["Crain", "Jason", ""], ["Mojsilovic", "Aleksandra", ""]]}, {"id": "2005.11257", "submitter": "Purushottam Kar", "authors": "Amit Chandak and Debojyoti Dey and Bhaskar Mukhoty and Purushottam Kar", "title": "Epidemiologically and Socio-economically Optimal Policies via Bayesian\n  Optimization", "comments": "Keywords: COVID-19, Optimal Policy, Lock-down, Epidemiology, Bayesian\n  Optimization Code available at https://github.com/purushottamkar/esop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass public quarantining, colloquially known as a lock-down, is a\nnon-pharmaceutical intervention to check spread of disease. This paper presents\nESOP (Epidemiologically and Socio-economically Optimal Policies), a novel\napplication of active machine learning techniques using Bayesian optimization,\nthat interacts with an epidemiological model to arrive at lock-down schedules\nthat optimally balance public health benefits and socio-economic downsides of\nreduced economic activity during lock-down periods. The utility of ESOP is\ndemonstrated using case studies with VIPER\n(Virus-Individual-Policy-EnviRonment), a stochastic agent-based simulator that\nthis paper also proposes. However, ESOP is flexible enough to interact with\narbitrary epidemiological simulators in a black-box manner, and produce\nschedules that involve multiple phases of lock-downs.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 16:11:33 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 03:44:27 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chandak", "Amit", ""], ["Dey", "Debojyoti", ""], ["Mukhoty", "Bhaskar", ""], ["Kar", "Purushottam", ""]]}, {"id": "2005.11270", "submitter": "Yunzi Ding", "authors": "Yunzi Ding, Dmitriy Kunisky, Alexander S. Wein, Afonso S. Bandeira", "title": "The Average-Case Time Complexity of Certifying the Restricted Isometry\n  Property", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressed sensing, the restricted isometry property (RIP) on $M \\times N$\nsensing matrices (where $M < N$) guarantees efficient reconstruction of sparse\nvectors. A matrix has the $(s,\\delta)$-$\\mathsf{RIP}$ property if behaves as a\n$\\delta$-approximate isometry on $s$-sparse vectors. It is well known that an\n$M\\times N$ matrix with i.i.d. $\\mathcal{N}(0,1/M)$ entries is\n$(s,\\delta)$-$\\mathsf{RIP}$ with high probability as long as $s\\lesssim\n\\delta^2 M/\\log N$. On the other hand, most prior works aiming to\ndeterministically construct $(s,\\delta)$-$\\mathsf{RIP}$ matrices have failed\nwhen $s \\gg \\sqrt{M}$. An alternative way to find an RIP matrix could be to\ndraw a random gaussian matrix and certify that it is indeed RIP. However, there\nis evidence that this certification task is computationally hard when $s \\gg\n\\sqrt{M}$, both in the worst case and the average case.\n  In this paper, we investigate the exact average-case time complexity of\ncertifying the RIP property for $M\\times N$ matrices with i.i.d.\n$\\mathcal{N}(0,1/M)$ entries, in the \"possible but hard\" regime $\\sqrt{M} \\ll\ns\\lesssim M/\\log N$. Based on analysis of the low-degree likelihood ratio, we\ngive rigorous evidence that subexponential runtime $N^{\\tilde\\Omega(s^2/M)}$ is\nrequired, demonstrating a smooth tradeoff between the maximum tolerated\nsparsity and the required computational power. This lower bound is essentially\ntight, matching the runtime of an existing algorithm due to Koiran and Zouzias.\nOur hardness result allows $\\delta$ to take any constant value in $(0,1)$,\nwhich captures the relevant regime for compressed sensing. This improves upon\nthe existing average-case hardness result of Wang, Berthet, and Plan, which is\nlimited to $\\delta = o(1)$.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 16:55:01 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 15:44:33 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 16:00:12 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Ding", "Yunzi", ""], ["Kunisky", "Dmitriy", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""]]}, {"id": "2005.11273", "submitter": "Galen Reeves", "authors": "Galen Reeves", "title": "Information-Theoretic Limits for the Matrix Tensor Product", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a high-dimensional inference problem involving the matrix\ntensor product of random matrices. This problem generalizes a number of\ncontemporary data science problems including the spiked matrix models used in\nsparse principal component analysis and covariance estimation and the\nstochastic block model used in network analysis. The main results are\nsingle-letter formulas (i.e., analytical expressions that can be approximated\nnumerically) for the mutual information and the minimum mean-squared error\n(MMSE) in the Bayes optimal setting where the distributions of all random\nquantities are known. We provide non-asymptotic bounds and show that our\nformulas describe exactly the leading order terms in the mutual information and\nMMSE in the high-dimensional regime where the number of rows $n$ and number of\ncolumns $d$ scale with $d = O(n^\\alpha)$ for some $\\alpha < 1/20$.\n  On the technical side, this paper introduces some new techniques for the\nanalysis of high-dimensional matrix-valued signals. Specific contributions\ninclude a novel extension of the adaptive interpolation method that uses\norder-preserving positive semidefinite interpolation paths, and a variance\ninequality between the overlap and the free energy that is based on\ncontinuous-time I-MMSE relations.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:03:48 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 22:24:19 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Reeves", "Galen", ""]]}, {"id": "2005.11275", "submitter": "Johannes Linder", "authors": "Johannes Linder and Georg Seelig", "title": "Fast differentiable DNA and protein sequence optimization for molecular\n  design", "comments": "All code available at http://www.github.com/johli/seqprop; Moved\n  example sequences from Suppl to new Figure 2, Added new benchmark comparison\n  to Section 4.3, Moved some technical comparisons to Suppl, Added new Methods\n  section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Designing DNA and protein sequences with improved function has the potential\nto greatly accelerate synthetic biology. Machine learning models that\naccurately predict biological fitness from sequence are becoming a powerful\ntool for molecular design. Activation maximization offers a simple design\nstrategy for differentiable models: one-hot coded sequences are first\napproximated by a continuous representation which is then iteratively optimized\nwith respect to the predictor oracle by gradient ascent. While elegant, this\nmethod suffers from vanishing gradients and may cause predictor pathologies\nleading to poor convergence. Here, we build on a previously proposed\nstraight-through approximation method to optimize through discrete sequence\nsamples. By normalizing nucleotide logits across positions and introducing an\nadaptive entropy variable, we remove bottlenecks arising from overly large or\nskewed sampling parameters. The resulting algorithm, which we call Fast\nSeqProp, achieves up to 100-fold faster convergence compared to previous\nversions of activation maximization and finds improved fitness optima for many\napplications. We demonstrate Fast SeqProp by designing DNA and protein\nsequences for six deep learning predictors, including a protein structure\npredictor.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:03:55 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 22:44:01 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Linder", "Johannes", ""], ["Seelig", "Georg", ""]]}, {"id": "2005.11282", "submitter": "Ashish Khetan", "authors": "Ashish Khetan, Zohar Karnin", "title": "PruneNet: Channel Pruning via Global Importance", "comments": "12 pages, 3 figures, Published in ICLR 2020 NAS Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel pruning is one of the predominant approaches for accelerating deep\nneural networks. Most existing pruning methods either train from scratch with a\nsparsity inducing term such as group lasso, or prune redundant channels in a\npretrained network and then fine tune the network. Both strategies suffer from\nsome limitations: the use of group lasso is computationally expensive,\ndifficult to converge and often suffers from worse behavior due to the\nregularization bias. The methods that start with a pretrained network either\nprune channels uniformly across the layers or prune channels based on the basic\nstatistics of the network parameters. These approaches either ignore the fact\nthat some CNN layers are more redundant than others or fail to adequately\nidentify the level of redundancy in different layers. In this work, we\ninvestigate a simple-yet-effective method for pruning channels based on a\ncomputationally light-weight yet effective data driven optimization step that\ndiscovers the necessary width per layer. Experiments conducted on ILSVRC-$12$\nconfirm effectiveness of our approach. With non-uniform pruning across the\nlayers on ResNet-$50$, we are able to match the FLOP reduction of\nstate-of-the-art channel pruning results while achieving a $0.98\\%$ higher\naccuracy. Further, we show that our pruned ResNet-$50$ network outperforms\nResNet-$34$ and ResNet-$18$ networks, and that our pruned ResNet-$101$\noutperforms ResNet-$50$.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:09:56 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Khetan", "Ashish", ""], ["Karnin", "Zohar", ""]]}, {"id": "2005.11295", "submitter": "Dimitris Tsipras", "authors": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Andrew Ilyas,\n  Aleksander Madry", "title": "From ImageNet to Image Classification: Contextualizing Progress on\n  Benchmarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building rich machine learning datasets in a scalable manner often\nnecessitates a crowd-sourced data collection pipeline. In this work, we use\nhuman studies to investigate the consequences of employing such a pipeline,\nfocusing on the popular ImageNet dataset. We study how specific design choices\nin the ImageNet creation process impact the fidelity of the resulting\ndataset---including the introduction of biases that state-of-the-art models\nexploit. Our analysis pinpoints how a noisy data collection pipeline can lead\nto a systematic misalignment between the resulting benchmark and the real-world\ntask it serves as a proxy for. Finally, our findings emphasize the need to\naugment our current model training and evaluation toolkit to take such\nmisalignments into account. To facilitate further research, we release our\nrefined ImageNet annotations at https://github.com/MadryLab/ImageNetMultiLabel.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:39:16 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Tsipras", "Dimitris", ""], ["Santurkar", "Shibani", ""], ["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Madry", "Aleksander", ""]]}, {"id": "2005.11300", "submitter": "Thomas Foster", "authors": "Thomas Foster, Chon Lok Lei, Martin Robinson, David Gavaghan, Ben\n  Lambert", "title": "Model Evidence with Fast Tree Based Quadrature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional integration is essential to many areas of science, ranging\nfrom particle physics to Bayesian inference. Approximating these integrals is\nhard, due in part to the difficulty of locating and sampling from regions of\nthe integration domain that make significant contributions to the overall\nintegral. Here, we present a new algorithm called Tree Quadrature (TQ) that\nseparates this sampling problem from the problem of using those samples to\nproduce an approximation of the integral. TQ places no qualifications on how\nthe samples provided to it are obtained, allowing it to use state-of-the-art\nsampling algorithms that are largely ignored by existing integration\nalgorithms. Given a set of samples, TQ constructs a surrogate model of the\nintegrand in the form of a regression tree, with a structure optimised to\nmaximise integral precision. The tree divides the integration domain into\nsmaller containers, which are individually integrated and aggregated to\nestimate the overall integral. Any method can be used to integrate each\nindividual container, so existing integration methods, like Bayesian Monte\nCarlo, can be combined with TQ to boost their performance. On a set of\nbenchmark problems, we show that TQ provides accurate approximations to\nintegrals in up to 15 dimensions; and in dimensions 4 and above, it outperforms\nsimple Monte Carlo and the popular Vegas method.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:48:06 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Foster", "Thomas", ""], ["Lei", "Chon Lok", ""], ["Robinson", "Martin", ""], ["Gavaghan", "David", ""], ["Lambert", "Ben", ""]]}, {"id": "2005.11303", "submitter": "Nima Hejazi", "authors": "Ashkan Ertefaie, Nima S. Hejazi, Mark J. van der Laan", "title": "Nonparametric inverse probability weighted estimators based on the\n  highly adaptive lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse probability weighted estimators are the oldest and potentially most\ncommonly used class of procedures for the estimation of causal effects. By\nadjusting for selection biases via a weighting mechanism, these procedures\nestimate an effect of interest by constructing a pseudo-population in which\nselection biases are eliminated. Despite their ease of use, these estimators\nrequire the correct specification of a model for the weighting mechanism, are\nknown to be inefficient, and suffer from the curse of dimensionality. We\npropose a class of nonparametric inverse probability weighted estimators in\nwhich the weighting mechanism is estimated via undersmoothing of the highly\nadaptive lasso, a nonparametric regression function proven to converge at\n$n^{-1/3}$-rate to the true weighting mechanism. We demonstrate that our\nestimators are asymptotically linear with variance converging to the\nnonparametric efficiency bound. Unlike doubly robust estimators, our procedures\nrequire neither derivation of the efficient influence function nor\nspecification of the conditional outcome model. Our theoretical developments\nhave broad implications for the construction of efficient inverse probability\nweighted estimators in large statistical models and a variety of problem\nsettings. We assess the practical performance of our estimators in simulation\nstudies and demonstrate use of our proposed methodology with data from a\nlarge-scale epidemiologic study.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:49:46 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 07:35:38 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ertefaie", "Ashkan", ""], ["Hejazi", "Nima S.", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "2005.11304", "submitter": "Dobrik Georgiev", "authors": "Dobrik Georgiev, Pietro Li\\`o", "title": "Neural Bipartite Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have found application for learning in the space\nof algorithms. However, the algorithms chosen by existing research (sorting,\nBreadth-First search, shortest path finding, etc.) usually align perfectly with\na standard GNN architecture. This report describes how neural execution is\napplied to a complex algorithm, such as finding maximum bipartite matching by\nreducing it to a flow problem and using Ford-Fulkerson to find the maximum\nflow. This is achieved via neural execution based only on features generated\nfrom a single GNN. The evaluation shows strongly generalising results with the\nnetwork achieving optimal matching almost 100% of the time.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:50:38 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 06:03:10 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 13:21:41 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Georgiev", "Dobrik", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2005.11313", "submitter": "Param Raval", "authors": "Devshree Patel, Param Raval, Ratnam Parikh, Yesha Shastri", "title": "Comparative Study of Machine Learning Models and BERT on SQuAD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aims to provide a comparative analysis of performance of certain\nmodels popular in machine learning and the BERT model on the Stanford Question\nAnswering Dataset (SQuAD). The analysis shows that the BERT model, which was\nonce state-of-the-art on SQuAD, gives higher accuracy in comparison to other\nmodels. However, BERT requires a greater execution time even when only 100\nsamples are used. This shows that with increasing accuracy more amount of time\nis invested in training the data. Whereas in case of preliminary machine\nlearning models, execution time for full data is lower but accuracy is\ncompromised.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:58:30 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Patel", "Devshree", ""], ["Raval", "Param", ""], ["Parikh", "Ratnam", ""], ["Shastri", "Yesha", ""]]}, {"id": "2005.11348", "submitter": "Dimitri Leandro De Oliveira Silva", "authors": "Dimitri Leandro de Oliveira Silva, Tito Spadini and Ricardo Suyama", "title": "Microphone Array Based Surveillance Audio Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work assessed seven classical classifiers and two beamforming algorithms\nfor detecting surveillance sound events. The tests included the use of AWGN\nwith -10 dB to 30 dB SNR. Data Augmentation was also employed to improve\nalgorithms' performance. The results showed that the combination of SVM and\nDelay-and-Sum (DaS) scored the best accuracy (up to 86.0\\%), but had high\ncomputational cost ($\\approx $ 402 ms), mainly due to DaS. The use of SGD also\nseems to be a good alternative since it has achieved good accuracy either (up\nto 85.3\\%), but with quicker processing time ($\\approx$ 165 ms).\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 18:35:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Silva", "Dimitri Leandro de Oliveira", ""], ["Spadini", "Tito", ""], ["Suyama", "Ricardo", ""]]}, {"id": "2005.11353", "submitter": "Safa Onur Sahin", "authors": "S. Onur Sahin and Suleyman S. Kozat", "title": "A Tree Architecture of LSTM Networks for Sequential Regression with\n  Missing Data", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate regression for variable length sequential data containing\nmissing samples and introduce a novel tree architecture based on the Long\nShort-Term Memory (LSTM) networks. In our architecture, we employ a variable\nnumber of LSTM networks, which use only the existing inputs in the sequence, in\na tree-like architecture without any statistical assumptions or imputations on\nthe missing data, unlike all the previous approaches. In particular, we\nincorporate the missingness information by selecting a subset of these LSTM\nnetworks based on \"presence-pattern\" of a certain number of previous inputs.\nFrom the mixture of experts perspective, we train different LSTM networks as\nour experts for various missingness patterns and then combine their outputs to\ngenerate the final prediction. We also provide the computational complexity\nanalysis of the proposed architecture, which is in the same order of the\ncomplexity of the conventional LSTM architectures for the sequence length. Our\nmethod can be readily extended to similar structures such as GRUs, RNNs as\nremarked in the paper. In the experiments, we achieve significant performance\nimprovements with respect to the state-of-the-art methods for the well-known\nfinancial and real life datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 18:57:47 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sahin", "S. Onur", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2005.11371", "submitter": "Jixuan Wang", "authors": "Jixuan Wang, Xiong Xiao, Jian Wu, Ranjani Ramamurthy, Frank Rudzicz,\n  Michael Brudno", "title": "Speaker diarization with session-level speaker embedding refinement\n  using graph neural networks", "comments": "ICASSP 2020 (45th International Conference on Acoustics, Speech, and\n  Signal Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep speaker embedding models have been commonly used as a building block for\nspeaker diarization systems; however, the speaker embedding model is usually\ntrained according to a global loss defined on the training data, which could be\nsub-optimal for distinguishing speakers locally in a specific meeting session.\nIn this work we present the first use of graph neural networks (GNNs) for the\nspeaker diarization problem, utilizing a GNN to refine speaker embeddings\nlocally using the structural information between speech segments inside each\nsession. The speaker embeddings extracted by a pre-trained model are remapped\ninto a new embedding space, in which the different speakers within a single\nsession are better separated. The model is trained for linkage prediction in a\nsupervised manner by minimizing the difference between the affinity matrix\nconstructed by the refined embeddings and the ground-truth adjacency matrix.\nSpectral clustering is then applied on top of the refined embeddings. We show\nthat the clustering performance of the refined speaker embeddings outperforms\nthe original embeddings significantly on both simulated and real meeting data,\nand our system achieves the state-of-the-art result on the NIST SRE 2000\nCALLHOME database.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 19:52:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wang", "Jixuan", ""], ["Xiao", "Xiong", ""], ["Wu", "Jian", ""], ["Ramamurthy", "Ranjani", ""], ["Rudzicz", "Frank", ""], ["Brudno", "Michael", ""]]}, {"id": "2005.11375", "submitter": "Yifan Chen", "authors": "Yifan Chen, Houman Owhadi, Andrew M. Stuart", "title": "Consistency of Empirical Bayes And Kernel Flow For Hierarchical\n  Parameter Estimation", "comments": "to appear in Mathematics of Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.NA math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process regression has proven very powerful in statistics, machine\nlearning and inverse problems. A crucial aspect of the success of this\nmethodology, in a wide range of applications to complex and real-world\nproblems, is hierarchical modeling and learning of hyperparameters. The purpose\nof this paper is to study two paradigms of learning hierarchical parameters:\none is from the probabilistic Bayesian perspective, in particular, the\nempirical Bayes approach that has been largely used in Bayesian statistics; the\nother is from the deterministic and approximation theoretic view, and in\nparticular the kernel flow algorithm that was proposed recently in the machine\nlearning literature. Analysis of their consistency in the large data limit, as\nwell as explicit identification of their implicit bias in parameter learning,\nare established in this paper for a Mat\\'ern-like model on the torus. A\nparticular technical challenge we overcome is the learning of the regularity\nparameter in the Mat\\'ern-like field, for which consistency results have been\nvery scarce in the spatial statistics literature. Moreover, we conduct\nextensive numerical experiments beyond the Mat\\'ern-like model, comparing the\ntwo algorithms further. These experiments demonstrate learning of other\nhierarchical parameters, such as amplitude and lengthscale; they also\nillustrate the setting of model misspecification in which the kernel flow\napproach could show superior performance to the more traditional empirical\nBayes approach.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 20:17:48 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 23:57:46 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Chen", "Yifan", ""], ["Owhadi", "Houman", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "2005.11394", "submitter": "Sandeep Singh Sandha", "authors": "Sandeep Singh Sandha, Mohit Aggarwal, Igor Fedorov, Mani Srivastava", "title": "MANGO: A Python Library for Parallel Hyperparameter Tuning", "comments": "5 pages, 3 figures, ICASSP Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning hyperparameters for machine learning algorithms is a tedious task, one\nthat is typically done manually. To enable automated hyperparameter tuning,\nrecent works have started to use techniques based on Bayesian optimization.\nHowever, to practically enable automated tuning for large scale machine\nlearning training pipelines, significant gaps remain in existing libraries,\nincluding lack of abstractions, fault tolerance, and flexibility to support\nscheduling on any distributed computing framework. To address these challenges,\nwe present Mango, a Python library for parallel hyperparameter tuning. Mango\nenables the use of any distributed scheduling framework, implements intelligent\nparallel search strategies, and provides rich abstractions for defining complex\nhyperparameter search spaces that are compatible with scikit-learn. Mango is\ncomparable in performance to Hyperopt, another widely used library. Mango is\navailable open-source and is currently used in production at Arm Research to\nprovide state-of-art hyperparameter tuning capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 20:58:26 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sandha", "Sandeep Singh", ""], ["Aggarwal", "Mohit", ""], ["Fedorov", "Igor", ""], ["Srivastava", "Mani", ""]]}, {"id": "2005.11411", "submitter": "Raaz Dwivedi", "authors": "Nhat Ho, Koulik Khamaru, Raaz Dwivedi, Martin J. Wainwright, Michael\n  I. Jordan, Bin Yu", "title": "Instability, Computational Efficiency and Statistical Accuracy", "comments": "First three authors contributed equally (listed in random order). 57\n  pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical estimators are defined as the fixed point of a\ndata-dependent operator, with estimators based on minimizing a cost function\nbeing an important special case. The limiting performance of such estimators\ndepends on the properties of the population-level operator in the idealized\nlimit of infinitely many samples. We develop a general framework that yields\nbounds on statistical accuracy based on the interplay between the deterministic\nconvergence rate of the algorithm at the population level, and its degree of\n(in)stability when applied to an empirical object based on $n$ samples. Using\nthis framework, we analyze both stable forms of gradient descent and some\nhigher-order and unstable algorithms, including Newton's method and its\ncubic-regularized variant, as well as the EM algorithm. We provide applications\nof our general results to several concrete classes of models, including\nGaussian mixture estimation, single-index models, and informative non-response\nmodels. We exhibit cases in which an unstable algorithm can achieve the same\nstatistical accuracy as a stable algorithm in exponentially fewer\nsteps---namely, with the number of iterations being reduced from polynomial to\nlogarithmic in sample size $n$.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 22:30:52 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ho", "Nhat", ""], ["Khamaru", "Koulik", ""], ["Dwivedi", "Raaz", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""], ["Yu", "Bin", ""]]}, {"id": "2005.11418", "submitter": "Xinwei Zhang", "authors": "Xinwei Zhang, Mingyi Hong, Sairaj Dhople, Wotao Yin and Yang Liu", "title": "FedPD: A Federated Learning Framework with Optimal Rates and Adaptivity\n  to Non-IID Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) has become a popular paradigm for learning from\ndistributed data. To effectively utilize data at different devices without\nmoving them to the cloud, algorithms such as the Federated Averaging (FedAvg)\nhave adopted a \"computation then aggregation\" (CTA) model, in which multiple\nlocal updates are performed using local data, before sending the local models\nto the cloud for aggregation.\n  However, these schemes typically require strong assumptions, such as the\nlocal data are identically independent distributed (i.i.d), or the size of the\nlocal gradients are bounded. In this paper, we first explicitly characterize\nthe behavior of the FedAvg algorithm, and show that without strong and\nunrealistic assumptions on the problem structure, the algorithm can behave\nerratically for non-convex problems (e.g., diverge to infinity). Aiming at\ndesigning FL algorithms that are provably fast and require as few assumptions\nas possible, we propose a new algorithm design strategy from the primal-dual\noptimization perspective. Our strategy yields a family of algorithms that take\nthe same CTA model as existing algorithms, but they can deal with the\nnon-convex objective, achieve the best possible optimization and communication\ncomplexity while being able to deal with both the full batch and mini-batch\nlocal computation models. Most importantly, the proposed algorithms are {\\it\ncommunication efficient}, in the sense that the communication pattern can be\nadaptive to the level of heterogeneity among the local data. To the best of our\nknowledge, this is the first algorithmic framework for FL that achieves all the\nabove properties.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 23:07:42 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 04:09:08 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 22:04:13 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Zhang", "Xinwei", ""], ["Hong", "Mingyi", ""], ["Dhople", "Sairaj", ""], ["Yin", "Wotao", ""], ["Liu", "Yang", ""]]}, {"id": "2005.11442", "submitter": "Sandeep Tata", "authors": "Abbas Kazerouni and Qi Zhao and Jing Xie and Sandeep Tata and Marc\n  Najork", "title": "Active Learning for Skewed Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a sequential active learning problem where, at each round, an agent\nselects a batch of unlabeled data points, queries their labels and updates a\nbinary classifier. While there exists a rich body of work on active learning in\nthis general form, in this paper, we focus on problems with two distinguishing\ncharacteristics: severe class imbalance (skew) and small amounts of initial\ntraining data. Both of these problems occur with surprising frequency in many\nweb applications. For instance, detecting offensive or sensitive content in\nonline communities (pornography, violence, and hate-speech) is receiving\nenormous attention from industry as well as research communities. Such problems\nhave both the characteristics we describe -- a vast majority of content is not\noffensive, so the number of positive examples for such content is orders of\nmagnitude smaller than the negative examples. Furthermore, there is usually\nonly a small amount of initial training data available when building\nmachine-learned models to solve such problems. To address both these issues, we\npropose a hybrid active learning algorithm (HAL) that balances exploiting the\nknowledge available through the currently labeled training examples with\nexploring the large amount of unlabeled data available. Through simulation\nresults, we show that HAL makes significantly better choices for what points to\nlabel when compared to strong baselines like margin-sampling. Classifiers\ntrained on the examples selected for labeling by HAL easily out-perform the\nbaselines on target metrics (like area under the precision-recall curve) given\nthe same budget for labeling examples. We believe HAL offers a simple,\nintuitive, and computationally tractable way to structure active learning for a\nwide range of machine learning applications.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 01:50:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kazerouni", "Abbas", ""], ["Zhao", "Qi", ""], ["Xie", "Jing", ""], ["Tata", "Sandeep", ""], ["Najork", "Marc", ""]]}, {"id": "2005.11478", "submitter": "Jiahong Wang", "authors": "Yuexin Zhang, Jiahong Wang", "title": "Short-term Load Forecasting Based on Hybrid Strategy Using Warm-start\n  Gradient Tree Boosting", "comments": "14 pages, 9 figures. The following article has been accepted by\n  Journal of Renewable and Sustainable Energy. After it is published, it will\n  be found at https://doi.org/10.1063/5.0015220", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep-learning-based hybrid strategy for short-term load forecasting is\npresented. The strategy proposes a novel tree-based ensemble method Warm-start\nGradient Tree Boosting (WGTB). Current strategies either ensemble submodels of\na single type, which fail to take advantage of the statistical strengths of\ndifferent inference models. Or they simply sum the outputs from completely\ndifferent inference models, which doesn't maximize the potential of ensemble.\nInspired by the bias-variance trade-off, WGTB is proposed and tailored to the\ngreat disparity among different inference models on accuracy, volatility and\nlinearity. The complete strategy integrates four different inference models of\ndifferent capacities. WGTB then ensembles their outputs by a warm-start and a\nhybrid of bagging and boosting, which lowers bias and variance concurrently. It\nis validated on two real datasets from State Grid Corporation of China of\nhourly resolution. The result demonstrates the effectiveness of the proposed\nstrategy that hybridizes the statistical strengths of both low-bias and\nlow-variance inference models.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 05:47:39 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 17:59:31 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhang", "Yuexin", ""], ["Wang", "Jiahong", ""]]}, {"id": "2005.11480", "submitter": "Ang Li", "authors": "Ang Li, Yixiao Duan, Huanrui Yang, Yiran Chen, Jianlei Yang", "title": "TIPRDC: Task-Independent Privacy-Respecting Data Crowdsourcing Framework\n  for Deep Learning with Anonymized Intermediate Representations", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403125", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning partially benefits from the availability of\nvarious large-scale datasets. These datasets are often crowdsourced from\nindividual users and contain private information like gender, age, etc. The\nemerging privacy concerns from users on data sharing hinder the generation or\nuse of crowdsourcing datasets and lead to hunger of training data for new deep\nlearning applications. One na\\\"{\\i}ve solution is to pre-process the raw data\nto extract features at the user-side, and then only the extracted features will\nbe sent to the data collector. Unfortunately, attackers can still exploit these\nextracted features to train an adversary classifier to infer private\nattributes. Some prior arts leveraged game theory to protect private\nattributes. However, these defenses are designed for known primary learning\ntasks, the extracted features work poorly for unknown learning tasks. To tackle\nthe case where the learning task may be unknown or changing, we present TIPRDC,\na task-independent privacy-respecting data crowdsourcing framework with\nanonymized intermediate representation. The goal of this framework is to learn\na feature extractor that can hide the privacy information from the intermediate\nrepresentations; while maximally retaining the original information embedded in\nthe raw data for the data collector to accomplish unknown learning tasks. We\ndesign a hybrid training method to learn the anonymized intermediate\nrepresentation: (1) an adversarial training process for hiding private\ninformation from features; (2) maximally retain original information using a\nneural-network-based mutual information estimator.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 06:21:26 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 00:42:01 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 19:13:55 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 19:58:01 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 01:23:06 GMT"}, {"version": "v6", "created": "Mon, 24 Aug 2020 13:52:38 GMT"}, {"version": "v7", "created": "Tue, 25 Aug 2020 01:36:06 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Ang", ""], ["Duan", "Yixiao", ""], ["Yang", "Huanrui", ""], ["Chen", "Yiran", ""], ["Yang", "Jianlei", ""]]}, {"id": "2005.11528", "submitter": "Sorawit Saengkyongam", "authors": "Sorawit Saengkyongam and Ricardo Silva", "title": "Learning Joint Nonlinear Effects from Single-variable Interventions in\n  the Presence of Hidden Confounders", "comments": "Accepted to The Conference on Uncertainty in Artificial Intelligence\n  (UAI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to estimate the effect of multiple simultaneous\ninterventions in the presence of hidden confounders. To overcome the problem of\nhidden confounding, we consider the setting where we have access to not only\nthe observational data but also sets of single-variable interventions in which\neach of the treatment variables is intervened on separately. We prove\nidentifiability under the assumption that the data is generated from a\nnonlinear continuous structural causal model with additive Gaussian noise. In\naddition, we propose a simple parameter estimation method by pooling all the\ndata from different regimes and jointly maximizing the combined likelihood. We\nalso conduct comprehensive experiments to verify the identifiability result as\nwell as to compare the performance of our approach against a baseline on both\nsynthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 12:52:09 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 06:20:09 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Saengkyongam", "Sorawit", ""], ["Silva", "Ricardo", ""]]}, {"id": "2005.11560", "submitter": "Haoteng Tang", "authors": "Haoteng Tang, Guixiang Ma, Yurong Chen, Lei Guo, Wei Wang, Bo Zeng,\n  Liang Zhan", "title": "Adversarial Attack on Hierarchical Graph Pooling Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence and development of graph neural\nnetworks (GNNs), which have been shown as a powerful approach for graph\nrepresentation learning in many tasks, such as node classification and graph\nclassification. The research on the robustness of these models has also started\nto attract attentions in the machine learning field. However, most of the\nexisting work in this area focus on the GNNs for node-level tasks, while little\nwork has been done to study the robustness of the GNNs for the graph\nclassification task. In this paper, we aim to explore the vulnerability of the\nHierarchical Graph Pooling (HGP) Neural Networks, which are advanced GNNs that\nperform very well in the graph classification in terms of prediction accuracy.\nWe propose an adversarial attack framework for this task. Specifically, we\ndesign a surrogate model that consists of convolutional and pooling operators\nto generate adversarial samples to fool the hierarchical GNN-based graph\nclassification models. We set the preserved nodes by the pooling operator as\nour attack targets, and then we perturb the attack targets slightly to fool the\npooling operator in hierarchical GNNs so that they will select the wrong nodes\nto preserve. We show the adversarial samples generated from multiple datasets\nby our surrogate model have enough transferability to attack current\nstate-of-art graph classification models. Furthermore, we conduct the robust\ntrain on the target models and demonstrate that the retrained graph\nclassification models are able to better defend against the attack from the\nadversarial samples. To the best of our knowledge, this is the first work on\nthe adversarial attack against hierarchical GNN-based graph classification\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 16:19:47 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tang", "Haoteng", ""], ["Ma", "Guixiang", ""], ["Chen", "Yurong", ""], ["Guo", "Lei", ""], ["Wang", "Wei", ""], ["Zeng", "Bo", ""], ["Zhan", "Liang", ""]]}, {"id": "2005.11588", "submitter": "Wenyu Chen", "authors": "Wenyu Chen, Rahul Mazumder", "title": "Multivariate Convex Regression at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present new large-scale algorithms for fitting a subgradient regularized\nmultivariate convex regression function to $n$ samples in $d$ dimensions -- a\nkey problem in shape constrained nonparametric regression with widespread\napplications in statistics, engineering and the applied sciences. The\ninfinite-dimensional learning task can be expressed via a convex quadratic\nprogram (QP) with $O(nd)$ decision variables and $O(n^2)$ constraints. While\ninstances with $n$ in the lower thousands can be addressed with current\nalgorithms within reasonable runtimes, solving larger problems (e.g., $n\\approx\n10^4$ or $10^5$) is computationally challenging. To this end, we present an\nactive set type algorithm on the dual QP. For computational scalability, we\nperform approximate optimization of the reduced sub-problems; and propose\nrandomized augmentation rules for expanding the active set. Although the dual\nis not strongly convex, we present a novel linear convergence rate of our\nalgorithm on the dual. We demonstrate that our framework can approximately\nsolve instances of the convex regression problem with $n=10^5$ and $d=10$\nwithin minutes; and offers significant computational gains compared to earlier\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 19:08:39 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 21:20:12 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chen", "Wenyu", ""], ["Mazumder", "Rahul", ""]]}, {"id": "2005.11593", "submitter": "Andrea Tirinzoni", "authors": "Andrea Tirinzoni, Alessandro Lazaric, Marcello Restelli", "title": "A Novel Confidence-Based Algorithm for Structured Bandits", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study finite-armed stochastic bandits where the rewards of each arm might\nbe correlated to those of other arms. We introduce a novel phased algorithm\nthat exploits the given structure to build confidence sets over the parameters\nof the true bandit problem and rapidly discard all sub-optimal arms. In\nparticular, unlike standard bandit algorithms with no structure, we show that\nthe number of times a suboptimal arm is selected may actually be reduced thanks\nto the information collected by pulling other arms. Furthermore, we show that,\nin some structures, the regret of an anytime extension of our algorithm is\nuniformly bounded over time. For these constant-regret structures, we also\nderive a matching lower bound. Finally, we demonstrate numerically that our\napproach better exploits certain structures than existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 19:52:44 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tirinzoni", "Andrea", ""], ["Lazaric", "Alessandro", ""], ["Restelli", "Marcello", ""]]}, {"id": "2005.11619", "submitter": "Himanshu Sharma", "authors": "Himanshu Sharma and Elise Jennings", "title": "Bayesian Neural Networks at Scale: A Performance Analysis and Pruning\n  Study", "comments": null, "journal-ref": "Journal of Super Computing (2020)", "doi": "10.1007/s11227-020-03401-z", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural Networks (BNNs) are a promising method of obtaining\nstatistical uncertainties for neural network predictions but with a higher\ncomputational overhead which can limit their practical usage. This work\nexplores the use of high performance computing with distributed training to\naddress the challenges of training BNNs at scale. We present a performance and\nscalability comparison of training the VGG-16 and Resnet-18 models on a\nCray-XC40 cluster. We demonstrate that network pruning can speed up inference\nwithout accuracy loss and provide an open source software package,\n{\\it{BPrune}} to automate this pruning. For certain models we find that pruning\nup to 80\\% of the network results in only a 7.0\\% loss in accuracy. With the\ndevelopment of new hardware accelerators for Deep Learning, BNNs are of\nconsiderable interest for benchmarking performance. This analysis of training a\nBNN at scale outlines the limitations and benefits compared to a conventional\nneural network.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 23:15:34 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 23:18:54 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Sharma", "Himanshu", ""], ["Jennings", "Elise", ""]]}, {"id": "2005.11622", "submitter": "Norman Tatro", "authors": "N. Joseph Tatro, Stefan C. Schonsheck, Rongjie Lai", "title": "Unsupervised Geometric Disentanglement for Surfaces via CFAN-VAE", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric disentanglement, the separation of latent codes for intrinsic (i.e.\nidentity) and extrinsic(i.e. pose) geometry, is a prominent task for generative\nmodels of non-Euclidean data such as 3D deformable models. It provides greater\ninterpretability of the latent space, and leads to more control in generation.\nThis work introduces a mesh feature, the conformal factor and normal feature\n(CFAN),for use in mesh convolutional autoencoders. We further propose CFAN-VAE,\na novel architecture that disentangles identity and pose using the CFAN\nfeature. Requiring no label information on the identity or pose during\ntraining, CFAN-VAE achieves geometric disentanglement in an unsupervisedway.\nOur comprehensive experiments, including reconstruction, interpolation,\ngeneration, and identity/pose transfer, demonstrate CFAN-VAE achieves\nstate-of-the-art performance on unsupervised geometric disentanglement. We also\nsuccessfully detect a level of geometric disentanglement in mesh convolutional\nautoencoders that encode xyz-coordinates directly by registering its latent\nspace to that of CFAN-VAE.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 23:28:10 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 01:50:38 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Tatro", "N. Joseph", ""], ["Schonsheck", "Stefan C.", ""], ["Lai", "Rongjie", ""]]}, {"id": "2005.11627", "submitter": "Zhiyong Cui", "authors": "Zhiyong Cui, Ruimin Ke, Ziyuan Pu, Yinhai Wang", "title": "Stacked Bidirectional and Unidirectional LSTM Recurrent Neural Network\n  for Forecasting Network-wide Traffic State with Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term traffic forecasting based on deep learning methods, especially\nrecurrent neural networks (RNN), has received much attention in recent years.\nHowever, the potential of RNN-based models in traffic forecasting has not yet\nbeen fully exploited in terms of the predictive power of spatial-temporal data\nand the capability of handling missing data. In this paper, we focus on\nRNN-based models and attempt to reformulate the way to incorporate RNN and its\nvariants into traffic prediction models. A stacked bidirectional and\nunidirectional LSTM network architecture (SBU-LSTM) is proposed to assist the\ndesign of neural network structures for traffic state forecasting. As a key\ncomponent of the architecture, the bidirectional LSTM (BDLSM) is exploited to\ncapture the forward and backward temporal dependencies in spatiotemporal data.\nTo deal with missing values in spatial-temporal data, we also propose a data\nimputation mechanism in the LSTM structure (LSTM-I) by designing an imputation\nunit to infer missing values and assist traffic prediction. The bidirectional\nversion of LSTM-I is incorporated in the SBU-LSTM architecture. Two real-world\nnetwork-wide traffic state datasets are used to conduct experiments and\npublished to facilitate further traffic prediction research. The prediction\nperformance of multiple types of multi-layer LSTM or BDLSTM models is\nevaluated. Experimental results indicate that the proposed SBU-LSTM\narchitecture, especially the two-layer BDLSTM network, can achieve superior\nperformance for the network-wide traffic prediction in both accuracy and\nrobustness. Further, comprehensive comparison results show that the proposed\ndata imputation mechanism in the RNN-based models can achieve outstanding\nprediction performance when the model's input data contains different patterns\nof missing values.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 00:17:15 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cui", "Zhiyong", ""], ["Ke", "Ruimin", ""], ["Pu", "Ziyuan", ""], ["Wang", "Yinhai", ""]]}, {"id": "2005.11638", "submitter": "Guofu Li", "authors": "Jinchao Huang, Guofu Li, Zhicong Yan, Fucai Luo, Shenghong Li", "title": "Joint learning of interpretation and distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extra trust brought by the model interpretation has made it an\nindispensable part of machine learning systems. But to explain a distilled\nmodel's prediction, one may either work with the student model itself, or turn\nto its teacher model. This leads to a more fundamental question: if a distilled\nmodel should give a similar prediction for a similar reason as its teacher\nmodel on the same input? This question becomes even more crucial when the two\nmodels have dramatically different structure, taking GBDT2NN for example. This\npaper conducts an empirical study on the new approach to explaining each\nprediction of GBDT2NN, and how imitating the explanation can further improve\nthe distillation process as an auxiliary learning task. Experiments on several\nbenchmarks show that the proposed methods achieve better performance on both\nexplanations and predictions.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 02:01:22 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Huang", "Jinchao", ""], ["Li", "Guofu", ""], ["Yan", "Zhicong", ""], ["Luo", "Fucai", ""], ["Li", "Shenghong", ""]]}, {"id": "2005.11641", "submitter": "Tudor Manole", "authors": "Tudor Manole, Abbas Khalili", "title": "Estimating the Number of Components in Finite Mixture Models via the\n  Group-Sort-Fuse Procedure", "comments": "79 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of the number of components (or order) of a finite mixture model\nis a long standing and challenging problem in statistics. We propose the\nGroup-Sort-Fuse (GSF) procedure---a new penalized likelihood approach for\nsimultaneous estimation of the order and mixing measure in multidimensional\nfinite mixture models. Unlike methods which fit and compare mixtures with\nvarying orders using criteria involving model complexity, our approach directly\npenalizes a continuous function of the model parameters. More specifically,\ngiven a conservative upper bound on the order, the GSF groups and sorts mixture\ncomponent parameters to fuse those which are redundant. For a wide range of\nfinite mixture models, we show that the GSF is consistent in estimating the\ntrue mixture order and achieves the $n^{-1/2}$ convergence rate for parameter\nestimation up to polylogarithmic factors. The GSF is implemented for several\nunivariate and multivariate mixture models in the R package GroupSortFuse. Its\nfinite sample performance is supported by a thorough simulation study, and its\napplication is illustrated on two real data examples.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 02:38:12 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Manole", "Tudor", ""], ["Khalili", "Abbas", ""]]}, {"id": "2005.11650", "submitter": "Zonghan Wu", "authors": "Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang,\n  Chengqi Zhang", "title": "Connecting the Dots: Multivariate Time Series Forecasting with Graph\n  Neural Networks", "comments": "Accepted by KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling multivariate time series has long been a subject that has attracted\nresearchers from a diverse range of fields including economics, finance, and\ntraffic. A basic assumption behind multivariate time series forecasting is that\nits variables depend on one another but, upon looking closely, it is fair to\nsay that existing methods fail to fully exploit latent spatial dependencies\nbetween pairs of variables. In recent years, meanwhile, graph neural networks\n(GNNs) have shown high capability in handling relational dependencies. GNNs\nrequire well-defined graph structures for information propagation which means\nthey cannot be applied directly for multivariate time series where the\ndependencies are not known in advance. In this paper, we propose a general\ngraph neural network framework designed specifically for multivariate time\nseries data. Our approach automatically extracts the uni-directed relations\namong variables through a graph learning module, into which external knowledge\nlike variable attributes can be easily integrated. A novel mix-hop propagation\nlayer and a dilated inception layer are further proposed to capture the spatial\nand temporal dependencies within the time series. The graph learning, graph\nconvolution, and temporal convolution modules are jointly learned in an\nend-to-end framework. Experimental results show that our proposed model\noutperforms the state-of-the-art baseline methods on 3 of 4 benchmark datasets\nand achieves on-par performance with other approaches on two traffic datasets\nwhich provide extra structural information.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 04:02:18 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wu", "Zonghan", ""], ["Pan", "Shirui", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Chang", "Xiaojun", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2005.11653", "submitter": "Fan Zhou", "authors": "Fan Zhou, Changjian Shui, Bincheng Huang, Boyu Wang and Brahim\n  Chaib-draa", "title": "Discriminative Active Learning for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Adaptation aiming to learn a transferable feature between different\nbut related domains has been well investigated and has shown excellent\nempirical performances. Previous works mainly focused on matching the marginal\nfeature distributions using the adversarial training methods while assuming the\nconditional relations between the source and target domain remained unchanged,\n$i.e.$, ignoring the conditional shift problem. However, recent works have\nshown that such a conditional shift problem exists and can hinder the\nadaptation process. To address this issue, we have to leverage labelled data\nfrom the target domain, but collecting labelled data can be quite expensive and\ntime-consuming. To this end, we introduce a discriminative active learning\napproach for domain adaptation to reduce the efforts of data annotation.\nSpecifically, we propose three-stage active adversarial training of neural\nnetworks: invariant feature space learning (first stage), uncertainty and\ndiversity criteria and their trade-off for query strategy (second stage) and\nre-training with queried target labels (third stage). Empirical comparisons\nwith existing domain adaptation methods using four benchmark datasets\ndemonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 04:20:49 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhou", "Fan", ""], ["Shui", "Changjian", ""], ["Huang", "Bincheng", ""], ["Wang", "Boyu", ""], ["Chaib-draa", "Brahim", ""]]}, {"id": "2005.11716", "submitter": "Yaxin Shi", "authors": "Yaxin Shi, Yuangang Pan, Donna Xu and Ivor W. Tsang", "title": "Multi-view Alignment and Generation in CCA via Consistent Latent\n  Encoding", "comments": "37 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view alignment, achieving one-to-one correspondence of multi-view\ninputs, is critical in many real-world multi-view applications, especially for\ncross-view data analysis problems. Recently, an increasing number of works\nstudy this alignment problem with Canonical Correlation Analysis (CCA).\nHowever, existing CCA models are prone to misalign the multiple views due to\neither the neglect of uncertainty or the inconsistent encoding of the multiple\nviews. To tackle these two issues, this paper studies multi-view alignment from\nthe Bayesian perspective. Delving into the impairments of inconsistent\nencodings, we propose to recover correspondence of the multi-view inputs by\nmatching the marginalization of the joint distribution of multi-view random\nvariables under different forms of factorization. To realize our design, we\npresent Adversarial CCA (ACCA) which achieves consistent latent encodings by\nmatching the marginalized latent encodings through the adversarial training\nparadigm. Our analysis based on conditional mutual information reveals that\nACCA is flexible for handling implicit distributions. Extensive experiments on\ncorrelation analysis and cross-view generation under noisy input settings\ndemonstrate the superiority of our model.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 10:50:15 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Shi", "Yaxin", ""], ["Pan", "Yuangang", ""], ["Xu", "Donna", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2005.11720", "submitter": "Thibaut Le Gouic", "authors": "Thibaut Le Gouic and Jean-Michel Loubes and Philippe Rigollet", "title": "Projection to Fairness in Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of regression, we consider the fundamental question of making\nan estimator fair while preserving its prediction accuracy as much as possible.\nTo that end, we define its projection to fairness as its closest fair estimator\nin a sense that reflects prediction accuracy. Our methodology leverages tools\nfrom optimal transport to construct efficiently the projection to fairness of\nany given estimator as a simple post-processing step. Moreover, our approach\nprecisely quantifies the cost of fairness, measured in terms of prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 11:20:07 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 09:16:22 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 17:46:21 GMT"}, {"version": "v4", "created": "Thu, 25 Jun 2020 17:02:18 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Gouic", "Thibaut Le", ""], ["Loubes", "Jean-Michel", ""], ["Rigollet", "Philippe", ""]]}, {"id": "2005.11730", "submitter": "Julian Skirzynski", "authors": "Julian Skirzy\\'nski, Frederic Becker and Falk Lieder", "title": "Automatic Discovery of Interpretable Planning Strategies", "comments": "Submitted to the Special Issue on Reinforcement Learning for Real\n  Life in Machine Learning Journal (2021). Code available at\n  https://github.com/RationalityEnhancement/InterpretableStrategyDiscovery", "journal-ref": null, "doi": "10.1007/s10994-021-05963-2", "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When making decisions, people often overlook critical information or are\noverly swayed by irrelevant information. A common approach to mitigate these\nbiases is to provide decision-makers, especially professionals such as medical\ndoctors, with decision aids, such as decision trees and flowcharts. Designing\neffective decision aids is a difficult problem. We propose that recently\ndeveloped reinforcement learning methods for discovering clever heuristics for\ngood decision-making can be partially leveraged to assist human experts in this\ndesign process. One of the biggest remaining obstacles to leveraging the\naforementioned methods is that the policies they learn are opaque to people. To\nsolve this problem, we introduce AI-Interpret: a general method for\ntransforming idiosyncratic policies into simple and interpretable descriptions.\nOur algorithm combines recent advances in imitation learning and program\ninduction with a new clustering method for identifying a large subset of\ndemonstrations that can be accurately described by a simple, high-performing\ndecision rule. We evaluate our new algorithm and employ it to translate\ninformation-acquisition policies discovered through metalevel reinforcement\nlearning. The results of large behavioral experiments showed that prividing the\ndecision rules generated by AI-Interpret as flowcharts significantly improved\npeople's planning strategies and decisions across three diferent classes of\nsequential decision problems. Moreover, another experiment revealed that this\napproach is significantly more effective than training people by giving them\nperformance feedback. Finally, a series of ablation studies confirmed that\nAI-Interpret is critical to the discovery of interpretable decision rules. We\nconclude that the methods and findings presented herein are an important step\ntowards leveraging automatic strategy discovery to improve human\ndecision-making.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 12:24:52 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 12:55:54 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 05:28:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Skirzy\u0144ski", "Julian", ""], ["Becker", "Frederic", ""], ["Lieder", "Falk", ""]]}, {"id": "2005.11736", "submitter": "Raghavendra Addanki", "authors": "Raghavendra Addanki, Shiva Prasad Kasiviswanathan, Andrew McGregor,\n  Cameron Musco", "title": "Efficient Intervention Design for Causal Discovery with Latents", "comments": "International Conference on Machine Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider recovering a causal graph in presence of latent variables, where\nwe seek to minimize the cost of interventions used in the recovery process. We\nconsider two intervention cost models: (1) a linear cost model where the cost\nof an intervention on a subset of variables has a linear form, and (2) an\nidentity cost model where the cost of an intervention is the same, regardless\nof what variables it is on, i.e., the goal is just to minimize the number of\ninterventions. Under the linear cost model, we give an algorithm to identify\nthe ancestral relations of the underlying causal graph, achieving within a\n$2$-factor of the optimal intervention cost. This approximation factor can be\nimproved to $1+\\epsilon$ for any $\\epsilon > 0$ under some mild restrictions.\nUnder the identity cost model, we bound the number of interventions needed to\nrecover the entire causal graph, including the latent variables, using a\nparameterization of the causal graph through a special type of colliders. In\nparticular, we introduce the notion of $p$-colliders, that are colliders\nbetween pair of nodes arising from a specific type of conditioning in the\ncausal graph, and provide an upper bound on the number of interventions as a\nfunction of the maximum number of $p$-colliders between any two nodes in the\ncausal graph.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 12:53:48 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 16:53:18 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Addanki", "Raghavendra", ""], ["Kasiviswanathan", "Shiva Prasad", ""], ["McGregor", "Andrew", ""], ["Musco", "Cameron", ""]]}, {"id": "2005.11741", "submitter": "Virginia Aglietti", "authors": "Virginia Aglietti, Xiaoyu Lu, Andrei Paleyes, Javier Gonz\\'alez", "title": "Causal Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of globally optimizing a variable of interest\nthat is part of a causal model in which a sequence of interventions can be\nperformed. This problem arises in biology, operational research, communications\nand, more generally, in all fields where the goal is to optimize an output\nmetric of a system of interconnected nodes. Our approach combines ideas from\ncausal inference, uncertainty quantification and sequential decision making. In\nparticular, it generalizes Bayesian optimization, which treats the input\nvariables of the objective function as independent, to scenarios where causal\ninformation is available. We show how knowing the causal graph significantly\nimproves the ability to reason about optimal decision making strategies\ndecreasing the optimization cost while avoiding suboptimal solutions. We\npropose a new algorithm called Causal Bayesian Optimization (CBO). CBO\nautomatically balances two trade-offs: the classical exploration-exploitation\nand the new observation-intervention, which emerges when combining real\ninterventional data with the estimated intervention effects computed via\ndo-calculus. We demonstrate the practical benefits of this method in a\nsynthetic setting and in two real-world applications.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 13:20:50 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 10:57:50 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Aglietti", "Virginia", ""], ["Lu", "Xiaoyu", ""], ["Paleyes", "Andrei", ""], ["Gonz\u00e1lez", "Javier", ""]]}, {"id": "2005.11743", "submitter": "Paulina Pankowska", "authors": "Paulina Pankowska and Daniel L. Oberski", "title": "The effect of measurement error on clustering algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering consists of a popular set of techniques used to separate data into\ninteresting groups for further analysis. Many data sources on which clustering\nis performed are well-known to contain random and systematic measurement\nerrors. Such errors may adversely affect clustering. While several techniques\nhave been developed to deal with this problem, little is known about the\neffectiveness of these solutions. Moreover, no work to-date has examined the\neffect of systematic errors on clustering solutions.\n  In this paper, we perform a Monte Carlo study to investigate the sensitivity\nof two common clustering algorithms, GMMs with merging and DBSCAN, to random\nand systematic error. We find that measurement error is particularly\nproblematic when it is systematic and when it affects all variables in the\ndataset. For the conditions considered here, we also find that the\npartition-based GMM with merged components is less sensitive to measurement\nerror than the density-based DBSCAN procedure.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 13:36:30 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Pankowska", "Paulina", ""], ["Oberski", "Daniel L.", ""]]}, {"id": "2005.11770", "submitter": "Junjie Liang", "authors": "Junjie Liang, Yanting Wu, Dongkuan Xu, Vasant Honavar", "title": "Longitudinal Deep Kernel Gaussian Process Regression", "comments": "Paper accepted by 35th AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes offer an attractive framework for predictive modeling from\nlongitudinal data, i.e., irregularly sampled, sparse observations from a set of\nindividuals over time. However, such methods have two key shortcomings: (i)\nThey rely on ad hoc heuristics or expensive trial and error to choose the\neffective kernels, and (ii) They fail to handle multilevel correlation\nstructure in the data. We introduce Longitudinal deep kernel Gaussian process\nregression (L-DKGPR), which to the best of our knowledge, is the only method to\novercome these limitations by fully automating the discovery of complex\nmultilevel correlation structure from longitudinal data. Specifically, L-DKGPR\neliminates the need for ad hoc heuristics or trial and error using a novel\nadaptation of deep kernel learning that combines the expressive power of deep\nneural networks with the flexibility of non-parametric kernel methods. L-DKGPR\neffectively learns the multilevel correlation with a novel addictive kernel\nthat simultaneously accommodates both time-varying and the time-invariant\neffects. We derive an efficient algorithm to train L-DKGPR using latent space\ninducing points and variational inference. Results of extensive experiments on\nseveral benchmark data sets demonstrate that L-DKGPR significantly outperforms\nthe state-of-the-art longitudinal data analysis (LDA) methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 15:10:48 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 19:18:23 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 14:21:33 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 20:44:53 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Liang", "Junjie", ""], ["Wu", "Yanting", ""], ["Xu", "Dongkuan", ""], ["Honavar", "Vasant", ""]]}, {"id": "2005.11797", "submitter": "Pranav Poduval", "authors": "Pranav Poduval, Hrushikesh Loya, Amit Sethi", "title": "Functional Space Variational Inference for Uncertainty Estimation in\n  Computer Aided Diagnosis", "comments": "Meaningful priors on the functional space rather than the weight\n  space, result in well calibrated uncertainty estimates", "journal-ref": "Medical Imaging with Deep Learning 2020", "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/eLL-c_Xc0B", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have revolutionized medical image analysis and disease\ndiagnosis. Despite their impressive performance, it is difficult to generate\nwell-calibrated probabilistic outputs for such networks, which makes them\nuninterpretable black boxes. Bayesian neural networks provide a principled\napproach for modelling uncertainty and increasing patient safety, but they have\na large computational overhead and provide limited improvement in calibration.\nIn this work, by taking skin lesion classification as an example task, we show\nthat by shifting Bayesian inference to the functional space we can craft\nmeaningful priors that give better calibrated uncertainty estimates at a much\nlower computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 16:42:11 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 16:47:06 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Poduval", "Pranav", ""], ["Loya", "Hrushikesh", ""], ["Sethi", "Amit", ""]]}, {"id": "2005.11818", "submitter": "Steve Hanneke", "authors": "Olivier Bousquet, Steve Hanneke, Shay Moran, and Nikita Zhivotovskiy", "title": "Proper Learning, Helly Number, and an Optimal SVM Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical PAC sample complexity bounds are stated for any Empirical Risk\nMinimizer (ERM) and contain an extra logarithmic factor $\\log(1/{\\epsilon})$\nwhich is known to be necessary for ERM in general. It has been recently shown\nby Hanneke (2016) that the optimal sample complexity of PAC learning for any VC\nclass C is achieved by a particular improper learning algorithm, which outputs\na specific majority-vote of hypotheses in C. This leaves the question of when\nthis bound can be achieved by proper learning algorithms, which are restricted\nto always output a hypothesis from C.\n  In this paper we aim to characterize the classes for which the optimal sample\ncomplexity can be achieved by a proper learning algorithm. We identify that\nthese classes can be characterized by the dual Helly number, which is a\ncombinatorial parameter that arises in discrete geometry and abstract\nconvexity. In particular, under general conditions on C, we show that the dual\nHelly number is bounded if and only if there is a proper learner that obtains\nthe optimal joint dependence on $\\epsilon$ and $\\delta$.\n  As further implications of our techniques we resolve a long-standing open\nproblem posed by Vapnik and Chervonenkis (1974) on the performance of the\nSupport Vector Machine by proving that the sample complexity of SVM in the\nrealizable case is $\\Theta((n/{\\epsilon})+(1/{\\epsilon})\\log(1/{\\delta}))$,\nwhere $n$ is the dimension. This gives the first optimal PAC bound for\nHalfspaces achieved by a proper learning algorithm, and moreover is\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 18:11:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bousquet", "Olivier", ""], ["Hanneke", "Steve", ""], ["Moran", "Shay", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2005.11878", "submitter": "Yuanhan Hu", "authors": "Mert Gurbuzbalaban, Yuanhan Hu", "title": "Fractional moment-preserving initialization schemes for training deep\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A traditional approach to initialization in deep neural networks (DNNs) is to\nsample the network weights randomly for preserving the variance of\npre-activations. On the other hand, several studies show that during the\ntraining process, the distribution of stochastic gradients can be heavy-tailed\nespecially for small batch sizes. In this case, weights and therefore\npre-activations can be modeled with a heavy-tailed distribution that has an\ninfinite variance but has a finite (non-integer) fractional moment of order $s$\nwith $s<2$. Motivated by this fact, we develop initialization schemes for fully\nconnected feed-forward networks that can provably preserve any given moment of\norder $s \\in (0, 2]$ over the layers for a class of activations including ReLU,\nLeaky ReLU, Randomized Leaky ReLU, and linear activations. These generalized\nschemes recover traditional initialization schemes in the limit $s \\to 2$ and\nserve as part of a principled theory for initialization. For all these schemes,\nwe show that the network output admits a finite almost sure limit as the number\nof layers grows, and the limit is heavy-tailed in some settings. This sheds\nfurther light into the origins of heavy tail during signal propagation in DNNs.\nWe prove that the logarithm of the norm of the network outputs, if properly\nscaled, will converge to a Gaussian distribution with an explicit mean and\nvariance we can compute depending on the activation used, the value of s chosen\nand the network width. We also prove that our initialization scheme avoids\nsmall network output values more frequently compared to traditional approaches.\nFurthermore, the proposed initialization strategy does not have an extra cost\nduring the training procedure. We show through numerical experiments that our\ninitialization can improve the training and test performance.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 01:10:01 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 02:39:19 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 17:25:23 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 20:00:48 GMT"}, {"version": "v5", "created": "Sat, 13 Feb 2021 15:23:47 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Gurbuzbalaban", "Mert", ""], ["Hu", "Yuanhan", ""]]}, {"id": "2005.11879", "submitter": "Zhou Fan", "authors": "Zhou Fan and Zhichao Wang", "title": "Spectra of the Conjugate Kernel and Neural Tangent Kernel for\n  linear-width neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the eigenvalue distributions of the Conjugate Kernel and Neural\nTangent Kernel associated to multi-layer feedforward neural networks. In an\nasymptotic regime where network width is increasing linearly in sample size,\nunder random initialization of the weights, and for input samples satisfying a\nnotion of approximate pairwise orthogonality, we show that the eigenvalue\ndistributions of the CK and NTK converge to deterministic limits. The limit for\nthe CK is described by iterating the Marcenko-Pastur map across the hidden\nlayers. The limit for the NTK is equivalent to that of a linear combination of\nthe CK matrices across layers, and may be described by recursive fixed-point\nequations that extend this Marcenko-Pastur map. We demonstrate the agreement of\nthese asymptotic predictions with the observed spectra for both synthetic and\nCIFAR-10 training data, and we perform a small simulation to investigate the\nevolutions of these spectra over training.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 01:11:49 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:46:17 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 16:47:46 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Fan", "Zhou", ""], ["Wang", "Zhichao", ""]]}, {"id": "2005.11890", "submitter": "Ronan Perry", "authors": "Ronan Perry, Gavin Mischler, Richard Guo, Theodore Lee, Alexander\n  Chang, Arman Koul, Cameron Franz, Hugo Richard, Iain Carmichael, Pierre\n  Ablin, Alexandre Gramfort, Joshua T. Vogelstein", "title": "mvlearn: Multiview Machine Learning in Python", "comments": "6 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As data are generated more and more from multiple disparate sources,\nmultiview data sets, where each sample has features in distinct views, have\nballooned in recent years. However, no comprehensive package exists that\nenables non-specialists to use these methods easily. mvlearn is a Python\nlibrary which implements the leading multiview machine learning methods. Its\nsimple API closely follows that of scikit-learn for increased ease-of-use. The\npackage can be installed from Python Package Index (PyPI) and the conda package\nmanager and is released under the MIT open-source license. The documentation,\ndetailed examples, and all releases are available at\nhttps://mvlearn.github.io/.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 02:35:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 18:20:34 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 15:13:37 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 18:16:18 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Perry", "Ronan", ""], ["Mischler", "Gavin", ""], ["Guo", "Richard", ""], ["Lee", "Theodore", ""], ["Chang", "Alexander", ""], ["Koul", "Arman", ""], ["Franz", "Cameron", ""], ["Richard", "Hugo", ""], ["Carmichael", "Iain", ""], ["Ablin", "Pierre", ""], ["Gramfort", "Alexandre", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "2005.11903", "submitter": "Chaochao Chen", "authors": "Jun Zhou, Chaochao Chen, Longfei Zheng, Huiwen Wu, Jia Wu, Xiaolin\n  Zheng, Bingzhe Wu, Ziqi Liu, Li Wang", "title": "Vertically Federated Graph Neural Network for Privacy-Preserving Node\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Graph Neural Network (GNN) has achieved remarkable progresses in\nvarious real-world tasks on graph data, consisting of node features and the\nadjacent information between different nodes. High-performance GNN models\nalways depend on both rich features and complete edge information in graph.\nHowever, such information could possibly be isolated by different data holders\nin practice, which is the so-called data isolation problem. To solve this\nproblem, in this paper, we propose VFGNN, a federated GNN learning paradigm for\nprivacy-preserving node classification task under data vertically partitioned\nsetting, which can be generalized to existing GNN models. Specifically, we\nsplit the computation graph into two parts. We leave the private data (i.e.,\nfeatures, edges, and labels) related computations on data holders, and delegate\nthe rest of computations to a semi-honest server. We also propose to apply\ndifferential privacy to prevent potential information leakage from the server.\nWe conduct experiments on three benchmarks and the results demonstrate the\neffectiveness of VFGNN.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 03:12:18 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 08:13:06 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Zhou", "Jun", ""], ["Chen", "Chaochao", ""], ["Zheng", "Longfei", ""], ["Wu", "Huiwen", ""], ["Wu", "Jia", ""], ["Zheng", "Xiaolin", ""], ["Wu", "Bingzhe", ""], ["Liu", "Ziqi", ""], ["Wang", "Li", ""]]}, {"id": "2005.11914", "submitter": "Li Wang", "authors": "Hok Shing Wong, Li Wang, Raymond Chan, and Tieyong Zeng", "title": "Deep Tensor CCA for Multi-view Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep Tensor Canonical Correlation Analysis (DTCCA), a method to\nlearn complex nonlinear transformations of multiple views (more than two) of\ndata such that the resulting representations are linearly correlated in high\norder. The high-order correlation of given multiple views is modeled by\ncovariance tensor, which is different from most CCA formulations relying solely\non the pairwise correlations. Parameters of transformations of each view are\njointly learned by maximizing the high-order canonical correlation. To solve\nthe resulting problem, we reformulate it as the best sum of rank-1\napproximation, which can be efficiently solved by existing tensor decomposition\nmethod. DTCCA is a nonlinear extension of tensor CCA (TCCA) via deep networks.\nThe transformations of DTCCA are parametric functions, which are very different\nfrom implicit mapping in the form of kernel function. Comparing with kernel\nTCCA, DTCCA not only can deal with arbitrary dimensions of the input data, but\nalso does not need to maintain the training data for computing representations\nof any given data point. Hence, DTCCA as a unified model can efficiently\novercome the scalable issue of TCCA for either high-dimensional multi-view data\nor a large amount of views, and it also naturally extends TCCA for learning\nnonlinear representation. Extensive experiments on three multi-view data sets\ndemonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 04:04:28 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wong", "Hok Shing", ""], ["Wang", "Li", ""], ["Chan", "Raymond", ""], ["Zeng", "Tieyong", ""]]}, {"id": "2005.11930", "submitter": "Benjamin Lucas", "authors": "Benjamin Lucas, Charlotte Pelletier, Daniel Schmidt, Geoffrey I. Webb,\n  and Fran\\c{c}ois Petitjean", "title": "A Bayesian-inspired, deep learning-based, semi-supervised domain\n  adaptation technique for land cover mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land cover maps are a vital input variable to many types of environmental\nresearch and management. While they can be produced automatically by machine\nlearning techniques, these techniques require substantial training data to\nachieve high levels of accuracy, which are not always available. One technique\nresearchers use when labelled training data are scarce is domain adaptation\n(DA) -- where data from an alternate region, known as the source domain, are\nused to train a classifier and this model is adapted to map the study region,\nor target domain. The scenario we address in this paper is known as\nsemi-supervised DA, where some labelled samples are available in the target\ndomain. In this paper we present Sourcerer, a Bayesian-inspired, deep\nlearning-based, semi-supervised DA technique for producing land cover maps from\nSITS data. The technique takes a convolutional neural network trained on a\nsource domain and then trains further on the available target domain with a\nnovel regularizer applied to the model weights. The regularizer adjusts the\ndegree to which the model is modified to fit the target data, limiting the\ndegree of change when the target data are few in number and increasing it as\ntarget data quantity increases. Our experiments on Sentinel-2 time series\nimages compare Sourcerer with two state-of-the-art semi-supervised domain\nadaptation techniques and four baseline models. We show that on two different\nsource-target domain pairings Sourcerer outperforms all other methods for any\nquantity of labelled target data available. In fact, the results on the more\ndifficult target domain show that the starting accuracy of Sourcerer (when no\nlabelled target data are available), 74.2%, is greater than the next-best\nstate-of-the-art method trained on 20,000 labelled target instances.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 05:36:50 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 05:57:44 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Lucas", "Benjamin", ""], ["Pelletier", "Charlotte", ""], ["Schmidt", "Daniel", ""], ["Webb", "Geoffrey I.", ""], ["Petitjean", "Fran\u00e7ois", ""]]}, {"id": "2005.11949", "submitter": "Yunfei Yang", "authors": "Yunfei Yang, Zhen Li, Yang Wang", "title": "Approximation in shift-invariant spaces with deep ReLU neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expressive power of deep ReLU neural networks for approximating\nfunctions in dilated shift-invariant spaces, which are widely used in signal\nprocessing, image processing, communications and so on. Approximation error\nbounds are estimated with respect to the width and depth of neural networks.\nThe network construction is based on the bit extraction and data-fitting\ncapacity of deep neural networks. As applications of our main results, the\napproximation rates of classical function spaces such as Sobolev spaces and\nBesov spaces are obtained. We also give lower bounds of the $L^p (1\\le p \\le\n\\infty)$ approximation error for Sobolev spaces, which show that our\nconstruction of neural network is asymptotically optimal up to a logarithmic\nfactor.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 07:23:47 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 08:47:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yang", "Yunfei", ""], ["Li", "Zhen", ""], ["Wang", "Yang", ""]]}, {"id": "2005.12005", "submitter": "O\\u{g}uzhan Karaahmeto\\u{g}lu", "authors": "Oguzhan Karaahmetoglu (1 and 2), Fatih Ilhan (1 and 2), Ismail Balaban\n  (2), Suleyman Serdar Kozat (1 and 2) ((1) Bilkent University, (2) DataBoss\n  A.S.)", "title": "Unsupervised Online Anomaly Detection On Irregularly Sampled Or Missing\n  Valued Time-Series Data Using LSTM Networks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study anomaly detection and introduce an algorithm that processes variable\nlength, irregularly sampled sequences or sequences with missing values. Our\nalgorithm is fully unsupervised, however, can be readily extended to supervised\nor semisupervised cases when the anomaly labels are present as remarked\nthroughout the paper. Our approach uses the Long Short Term Memory (LSTM)\nnetworks in order to extract temporal features and find the most relevant\nfeature vectors for anomaly detection. We incorporate the sampling time\ninformation to our model by modulating the standard LSTM model with time\nmodulation gates. After obtaining the most relevant features from the LSTM, we\nlabel the sequences using a Support Vector Data Descriptor (SVDD) model. We\nintroduce a loss function and then jointly optimize the feature extraction and\nsequence processing mechanisms in an end-to-end manner. Through this joint\noptimization, the LSTM extracts the most relevant features for anomaly\ndetection later to be used in the SVDD, hence completely removes the need for\nfeature selection by expert knowledge. Furthermore, we provide a training\nalgorithm for the online setup, where we optimize our model parameters with\nindividual sequences as the new data arrives. Finally, on real-life datasets,\nwe show that our model significantly outperforms the standard approaches thanks\nto its combination of LSTM with SVDD and joint optimization.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 09:41:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Karaahmetoglu", "Oguzhan", "", "1 and 2"], ["Ilhan", "Fatih", "", "1 and 2"], ["Balaban", "Ismail", "", "1 and 2"], ["Kozat", "Suleyman Serdar", "", "1 and 2"]]}, {"id": "2005.12055", "submitter": "Seyed Mostafa Kia", "authors": "Seyed Mostafa Kia, Hester Huijsdens, Richard Dinga, Thomas Wolfers,\n  Maarten Mennes, Ole A. Andreassen, Lars T. Westlye, Christian F. Beckmann,\n  Andre F. Marquand", "title": "Hierarchical Bayesian Regression for Multi-Site Normative Modeling of\n  Neuroimaging Data", "comments": "To be published in MICCAI 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical neuroimaging has recently witnessed explosive growth in data\navailability which brings studying heterogeneity in clinical cohorts to the\nspotlight. Normative modeling is an emerging statistical tool for achieving\nthis objective. However, its application remains technically challenging due to\ndifficulties in properly dealing with nuisance variation, for example due to\nvariability in image acquisition devices. Here, in a fully probabilistic\nframework, we propose an application of hierarchical Bayesian regression (HBR)\nfor multi-site normative modeling. Our experimental results confirm the\nsuperiority of HBR in deriving more accurate normative ranges on large\nmulti-site neuroimaging data compared to widely used methods. This provides the\npossibility i) to learn the normative range of structural and functional brain\nmeasures on large multi-site data; ii) to recalibrate and reuse the learned\nmodel on local small data; therefore, HBR closes the technical loop for\napplying normative modeling as a medical tool for the diagnosis and prognosis\nof mental disorders.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 11:55:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kia", "Seyed Mostafa", ""], ["Huijsdens", "Hester", ""], ["Dinga", "Richard", ""], ["Wolfers", "Thomas", ""], ["Mennes", "Maarten", ""], ["Andreassen", "Ole A.", ""], ["Westlye", "Lars T.", ""], ["Beckmann", "Christian F.", ""], ["Marquand", "Andre F.", ""]]}, {"id": "2005.12061", "submitter": "Kaiwen Zhou", "authors": "Kaiwen Zhou, Anthony Man-Cho So, James Cheng", "title": "Boosting First-Order Methods by Shifting Objective: New Schemes with\n  Faster Worst-Case Rates", "comments": "NeurIPS 2020, 29 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new methodology to design first-order methods for unconstrained\nstrongly convex problems. Specifically, instead of tackling the original\nobjective directly, we construct a shifted objective function that has the same\nminimizer as the original objective and encodes both the smoothness and strong\nconvexity of the original objective in an interpolation condition. We then\npropose an algorithmic template for tackling the shifted objective, which can\nexploit such a condition. Following this template, we derive several new\naccelerated schemes for problems that are equipped with various first-order\noracles and show that the interpolation condition allows us to vastly simplify\nand tighten the analysis of the derived methods. In particular, all the derived\nmethods have faster worst-case convergence rates than their existing\ncounterparts. Experiments on machine learning tasks are conducted to evaluate\nthe new methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:08:58 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 16:12:19 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zhou", "Kaiwen", ""], ["So", "Anthony Man-Cho", ""], ["Cheng", "James", ""]]}, {"id": "2005.12069", "submitter": "Andreas Sedlmeier", "authors": "Andreas Sedlmeier and Robert M\\\"uller and Steffen Illium and Claudia\n  Linnhoff-Popien", "title": "Policy Entropy for Out-of-Distribution Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One critical prerequisite for the deployment of reinforcement learning\nsystems in the real world is the ability to reliably detect situations on which\nthe agent was not trained. Such situations could lead to potential safety risks\nwhen wrong predictions lead to the execution of harmful actions. In this work,\nwe propose PEOC, a new policy entropy based out-of-distribution classifier that\nreliably detects unencountered states in deep reinforcement learning. It is\nbased on using the entropy of an agent's policy as the classification score of\na one-class classifier. We evaluate our approach using a procedural environment\ngenerator. Results show that PEOC is highly competitive against\nstate-of-the-art one-class classification algorithms on the evaluated\nenvironments. Furthermore, we present a structured process for benchmarking\nout-of-distribution classification in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:18:20 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sedlmeier", "Andreas", ""], ["M\u00fcller", "Robert", ""], ["Illium", "Steffen", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "2005.12108", "submitter": "Mohammed Sharafath Abdul Hameed", "authors": "Mohammed Sharafath Abdul Hameed (1), Gavneet Singh Chadha (1), Andreas\n  Schwung (1), and Steven X. Ding (2) ((1) South Westphalia University of\n  Applied Sciences, Germany (2) University of Duisburg-Essen, Germany)", "title": "Gradient Monitored Reinforcement Learning", "comments": "14 pages, 15 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a novel neural network training approach for faster\nconvergence and better generalization abilities in deep reinforcement learning.\nParticularly, we focus on the enhancement of training and evaluation\nperformance in reinforcement learning algorithms by systematically reducing\ngradient's variance and thereby providing a more targeted learning process. The\nproposed method which we term as Gradient Monitoring(GM), is an approach to\nsteer the learning in the weight parameters of a neural network based on the\ndynamic development and feedback from the training process itself. We propose\ndifferent variants of the GM methodology which have been proven to increase the\nunderlying performance of the model. The one of the proposed variant, Momentum\nwith Gradient Monitoring (M-WGM), allows for a continuous adjustment of the\nquantum of back-propagated gradients in the network based on certain learning\nparameters. We further enhance the method with Adaptive Momentum with Gradient\nMonitoring (AM-WGM) method which allows for automatic adjustment between\nfocused learning of certain weights versus a more dispersed learning depending\non the feedback from the rewards collected. As a by-product, it also allows for\nautomatic derivation of the required deep network sizes during training as the\nalgorithm automatically freezes trained weights. The approach is applied to two\ndiscrete (Multi-Robot Co-ordination problem and Atari games) and one continuous\ncontrol task (MuJoCo) using Advantage Actor-Critic (A2C) and Proximal Policy\nOptimization (PPO) respectively. The results obtained particularly underline\nthe applicability and performance improvements of the methods in terms of\ngeneralization capability.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 13:45:47 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Hameed", "Mohammed Sharafath Abdul", ""], ["Chadha", "Gavneet Singh", ""], ["Schwung", "Andreas", ""], ["Ding", "Steven X.", ""]]}, {"id": "2005.12123", "submitter": "Makoto Yamada", "authors": "Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and\n  Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and\n  Makoto Yamada", "title": "Feature Robust Optimal Transport for High-dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport is a machine learning problem with applications including\ndistribution comparison, feature selection, and generative adversarial\nnetworks. In this paper, we propose feature-robust optimal transport (FROT) for\nhigh-dimensional data, which solves high-dimensional OT problems using feature\nselection to avoid the curse of dimensionality. Specifically, we find a\ntransport plan with discriminative features. To this end, we formulate the FROT\nproblem as a min--max optimization problem. We then propose a convex\nformulation of the FROT problem and solve it using a Frank--Wolfe-based\noptimization algorithm, whereby the subproblem can be efficiently solved using\nthe Sinkhorn algorithm. Since FROT finds the transport plan from selected\nfeatures, it is robust to noise features. To show the effectiveness of FROT, we\npropose using the FROT algorithm for the layer selection problem in deep neural\nnetworks for semantic correspondence. By conducting synthetic and benchmark\nexperiments, we demonstrate that the proposed method can find a strong\ncorrespondence by determining important layers. We show that the FROT algorithm\nachieves state-of-the-art performance in real-world semantic correspondence\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:07:16 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 14:19:37 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 15:09:10 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 05:38:13 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Petrovich", "Mathis", ""], ["Liang", "Chao", ""], ["Sato", "Ryoma", ""], ["Liu", "Yanbin", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Zhu", "Linchao", ""], ["Yang", "Yi", ""], ["Salakhutdinov", "Ruslan", ""], ["Yamada", "Makoto", ""]]}, {"id": "2005.12129", "submitter": "Matthew Davidow", "authors": "Matthew Davidow, David S. Matteson", "title": "Factor Analysis of Mixed Data for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims to identify observations that deviate from the typical\npattern of data. Anomalous observations may correspond to financial fraud,\nhealth risks, or incorrectly measured data in practice. We show detecting\nanomalies in high-dimensional mixed data is enhanced through first embedding\nthe data then assessing an anomaly scoring scheme. We focus on unsupervised\ndetection and the continuous and categorical (mixed) variable case. We propose\na kurtosis-weighted Factor Analysis of Mixed Data for anomaly detection,\nFAMDAD, to obtain a continuous embedding for anomaly scoring. We illustrate\nthat anomalies are highly separable in the first and last few ordered\ndimensions of this space, and test various anomaly scoring experiments within\nthis subspace. Results are illustrated for both simulated and real datasets,\nand the proposed approach (FAMDAD) is highly accurate for high-dimensional\nmixed data throughout these diverse scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:13:10 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Davidow", "Matthew", ""], ["Matteson", "David S.", ""]]}, {"id": "2005.12141", "submitter": "Manuel Dalcastagn\\'e", "authors": "Manuel Dalcastagn\\'e, Andrea Mariello, Roberto Battiti", "title": "Reactive Sample Size for Heuristic Search in Simulation-based\n  Optimization", "comments": "14 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In simulation-based optimization, the optimal setting of the input parameters\nof the objective function can be determined by heuristic optimization\ntechniques. However, when simulators model the stochasticity of real-world\nproblems, their output is a random variable and multiple evaluations of the\nobjective function are necessary to properly compare the expected performance\nof different parameter settings. This paper presents a novel reactive sample\nsize algorithm based on parametric tests and indifference-zone selection, which\ncan be used for improving the efficiency and robustness of heuristic\noptimization methods. The algorithm reactively decides, in an online manner,\nthe sample size to be used for each comparison during the optimization\naccording to observed statistical evidence. Tests employ benchmark functions\nextended with artificial levels of noise and a simulation-based optimization\ntool for hotel revenue management. Experimental results show that the reactive\nmethod can improve the efficiency and robustness of simulation-based\noptimization techniques.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:38:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Dalcastagn\u00e9", "Manuel", ""], ["Mariello", "Andrea", ""], ["Battiti", "Roberto", ""]]}, {"id": "2005.12154", "submitter": "Battista Biggio", "authors": "Fei Zhang, Patrick P.K. Chan, Battista Biggio, Daniel S. Yeung, Fabio\n  Roli", "title": "Adversarial Feature Selection against Evasion Attacks", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, vol. 46, no. 3, March 2016", "doi": "10.1109/TCYB.2015.2415032", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern recognition and machine learning techniques have been increasingly\nadopted in adversarial settings such as spam, intrusion and malware detection,\nalthough their security against well-crafted attacks that aim to evade\ndetection by manipulating data at test time has not yet been thoroughly\nassessed. While previous work has been mainly focused on devising\nadversary-aware classification algorithms to counter evasion attempts, only few\nauthors have considered the impact of using reduced feature sets on classifier\nsecurity against the same attacks. An interesting, preliminary result is that\nclassifier security to evasion may be even worsened by the application of\nfeature selection. In this paper, we provide a more detailed investigation of\nthis aspect, shedding some light on the security properties of feature\nselection against evasion attacks. Inspired by previous work on adversary-aware\nclassifiers, we propose a novel adversary-aware feature selection model that\ncan improve classifier security against evasion attacks, by incorporating\nspecific assumptions on the adversary's data manipulation strategy. We focus on\nan efficient, wrapper-based implementation of our approach, and experimentally\nvalidate its soundness on different application examples, including spam and\nmalware detection.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:05:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhang", "Fei", ""], ["Chan", "Patrick P. K.", ""], ["Biggio", "Battista", ""], ["Yeung", "Daniel S.", ""], ["Roli", "Fabio", ""]]}, {"id": "2005.12178", "submitter": "Alan Mazankiewicz", "authors": "Alan Mazankiewicz, Klemens B\\\"ohm, Mario Berg\\'es", "title": "Incremental Real-Time Personalization in Human Activity Recognition\n  Using Domain Adaptive Batch Normalization", "comments": "Updated version of the preprint from 05/2020 after going through\n  revision. The content (experiments, results, proposed method) has not\n  changed. The explanations changed. Certain sentences have been\n  added/removed/rephrased to be clearer. Removed Figure 3. Added Discussion\n  section. Renamed \"Description of Approach\" Section. Added a reference to\n  related work", "journal-ref": "Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 4,\n  Article 144 (December 2020), 20 pages", "doi": "10.1145/3432230", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human Activity Recognition (HAR) from devices like smartphone accelerometers\nis a fundamental problem in ubiquitous computing. Machine learning based\nrecognition models often perform poorly when applied to new users that were not\npart of the training data. Previous work has addressed this challenge by\npersonalizing general recognition models to the unique motion pattern of a new\nuser in a static batch setting. They require target user data to be available\nupfront. The more challenging online setting has received less attention. No\nsamples from the target user are available in advance, but they arrive\nsequentially. Additionally, the motion pattern of users may change over time.\nThus, adapting to new and forgetting old information must be traded off.\nFinally, the target user should not have to do any work to use the recognition\nsystem by, say, labeling any activities. Our work addresses all of these\nchallenges by proposing an unsupervised online domain adaptation algorithm.\nBoth classification and personalization happen continuously and incrementally\nin real time. Our solution works by aligning the feature distributions of all\nsubjects, be they sources or the target, in hidden neural network layers. To\nthis end, we normalize the input of a layer with user-specific mean and\nvariance statistics. During training, these statistics are computed over\nuser-specific batches. In the online phase, they are estimated incrementally\nfor any new target user.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:49:10 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 14:13:48 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Mazankiewicz", "Alan", ""], ["B\u00f6hm", "Klemens", ""], ["Berg\u00e9s", "Mario", ""]]}, {"id": "2005.12183", "submitter": "Filippo Masi", "authors": "Filippo Masi, Ioannis Stefanou, Paolo Vannucci, Victor Maffi-Berthier", "title": "Thermodynamics-based Artificial Neural Networks for constitutive\n  modeling", "comments": null, "journal-ref": "Journal of the Mechanics and Physics of Solids, 147, 104277 (2021)", "doi": "10.1016/j.jmps.2020.104277", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning methods and, in particular, Artificial Neural Networks\n(ANNs) have demonstrated promising capabilities in material constitutive\nmodeling. One of the main drawbacks of such approaches is the lack of a\nrigorous frame based on the laws of physics. This may render physically\ninconsistent the predictions of a trained network, which can be even dangerous\nfor real applications.\n  Here we propose a new class of data-driven, physics-based, neural networks\nfor constitutive modeling of strain rate independent processes at the material\npoint level, which we define as Thermodynamics-based Artificial Neural Networks\n(TANNs). The two basic principles of thermodynamics are encoded in the\nnetwork's architecture by taking advantage of automatic differentiation to\ncompute the numerical derivatives of a network with respect to its inputs. In\nthis way, derivatives of the free-energy, the dissipation rate and their\nrelation with the stress and internal state variables are hardwired in the\nnetwork. Consequently, our network does not have to identify the underlying\npattern of thermodynamic laws during training, reducing the need of large\ndata-sets. Moreover the training is more efficient and robust, and the\npredictions more accurate. Finally and more important, the predictions remain\nthermodynamically consistent, even for unseen data. Based on these features,\nTANNs are a starting point for data-driven, physics-based constitutive modeling\nwith neural networks.\n  We demonstrate the wide applicability of TANNs for modeling elasto-plastic\nmaterials, with strain hardening and strain softening. Detailed comparisons\nshow that the predictions of TANNs outperform those of standard ANNs. TANNs '\narchitecture is general, enabling applications to materials with different or\nmore complex behavior, without any modification.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:56:34 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Masi", "Filippo", ""], ["Stefanou", "Ioannis", ""], ["Vannucci", "Paolo", ""], ["Maffi-Berthier", "Victor", ""]]}, {"id": "2005.12186", "submitter": "Philipp Behrendt", "authors": "Philipp Behrendt", "title": "Learnability of Timescale Graphical Event Models", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report tries to fill a gap in current literature on Timescale\nGraphical Event Models. I propose and evaluate different heuristics to\ndetermine hyper-parameters during the structure learning algorithm and refine\nan existing distance measure. A comprehensive benchmark on synthetic data will\nbe conducted allowing conclusions about the applicability of the different\nheuristics.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:57:22 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Behrendt", "Philipp", ""]]}, {"id": "2005.12195", "submitter": "Christopher Kello", "authors": "Mohammad K. Ebrahimpour, Timothy Shea, Andreea Danielescu, David C.\n  Noelle, Christopher T. Kello", "title": "End-to-End Auditory Object Recognition via Inception Nucleus", "comments": "Published In proceedings of ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning approaches to auditory object recognition are traditionally\nbased on engineered features such as those derived from the spectrum or\ncepstrum. More recently, end-to-end classification systems in image and\nauditory recognition systems have been developed to learn features jointly with\nclassification and result in improved classification accuracy. In this paper,\nwe propose a novel end-to-end deep neural network to map the raw waveform\ninputs to sound class labels. Our network includes an \"inception nucleus\" that\noptimizes the size of convolutional filters on the fly that results in reducing\nengineering efforts dramatically. Classification results compared favorably\nagainst current state-of-the-art approaches, besting them by 10.4 percentage\npoints on the Urbansound8k dataset. Analyses of learned representations\nrevealed that filters in the earlier hidden layers learned wavelet-like\ntransforms to extract features that were informative for classification.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:08:41 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ebrahimpour", "Mohammad K.", ""], ["Shea", "Timothy", ""], ["Danielescu", "Andreea", ""], ["Noelle", "David C.", ""], ["Kello", "Christopher T.", ""]]}, {"id": "2005.12198", "submitter": "Minjie Wang", "authors": "Minjie Wang, Tianyi Yao, Genevera I. Allen", "title": "Supervised Convex Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering has long been a popular unsupervised learning approach to identify\ngroups of similar objects and discover patterns from unlabeled data in many\napplications. Yet, coming up with meaningful interpretations of the estimated\nclusters has often been challenging precisely due to its unsupervised nature.\nMeanwhile, in many real-world scenarios, there are some noisy supervising\nauxiliary variables, for instance, subjective diagnostic opinions, that are\nrelated to the observed heterogeneity of the unlabeled data. By leveraging\ninformation from both supervising auxiliary variables and unlabeled data, we\nseek to uncover more scientifically interpretable group structures that may be\nhidden by completely unsupervised analyses. In this work, we propose and\ndevelop a new statistical pattern discovery method named Supervised Convex\nClustering (SCC) that borrows strength from both information sources and guides\ntowards finding more interpretable patterns via a joint convex fusion penalty.\nWe develop several extensions of SCC to integrate different types of\nsupervising auxiliary variables, to adjust for additional covariates, and to\nfind biclusters. We demonstrate the practical advantages of SCC through\nsimulations and a case study on Alzheimer's Disease genomics. Specifically, we\ndiscover new candidate genes as well as new subtypes of Alzheimer's Disease\nthat can potentially lead to better understanding of the underlying genetic\nmechanisms responsible for the observed heterogeneity of cognitive decline in\nolder adults.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:12:38 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wang", "Minjie", ""], ["Yao", "Tianyi", ""], ["Allen", "Genevera I.", ""]]}, {"id": "2005.12206", "submitter": "Qingpeng Cai", "authors": "Jianxiong Wei, Anxiang Zeng, Yueqiu Wu, Peng Guo, Qingsong Hua,\n  Qingpeng Cai", "title": "Generator and Critic: A Deep Reinforcement Learning Approach for Slate\n  Re-ranking in E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The slate re-ranking problem considers the mutual influences between items to\nimprove user satisfaction in e-commerce, compared with the point-wise ranking.\nPrevious works either directly rank items by an end to end model, or rank items\nby a score function that trades-off the point-wise score and the diversity\nbetween items. However, there are two main existing challenges that are not\nwell studied: (1) the evaluation of the slate is hard due to the complex mutual\ninfluences between items of one slate; (2) even given the optimal evaluation,\nsearching the optimal slate is challenging as the action space is exponentially\nlarge. In this paper, we present a novel Generator and Critic slate re-ranking\napproach, where the Critic evaluates the slate and the Generator ranks the\nitems by the reinforcement learning approach. We propose a Full Slate Critic\n(FSC) model that considers the real impressed items and avoids the impressed\nbias of existing models. For the Generator, to tackle the problem of large\naction space, we propose a new exploration reinforcement learning algorithm,\ncalled PPO-Exploration. Experimental results show that the FSC model\nsignificantly outperforms the state of the art slate evaluation methods, and\nthe PPO-Exploration algorithm outperforms the existing reinforcement learning\nmethods substantially. The Generator and Critic approach improves both the\nslate efficiency(4% gmv and 5% number of orders) and diversity in live\nexperiments on one of the largest e-commerce websites in the world.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:24:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wei", "Jianxiong", ""], ["Zeng", "Anxiang", ""], ["Wu", "Yueqiu", ""], ["Guo", "Peng", ""], ["Hua", "Qingsong", ""], ["Cai", "Qingpeng", ""]]}, {"id": "2005.12254", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh and Liang Zheng", "title": "Dynamic Value Estimation for Single-Task Multi-Scene Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep reinforcement learning agents on environments with multiple\nlevels / scenes / conditions from the same task, has become essential for many\napplications aiming to achieve generalization and domain transfer from\nsimulation to the real world. While such a strategy is helpful with\ngeneralization, the use of multiple scenes significantly increases the variance\nof samples collected for policy gradient computations. Current methods continue\nto view this collection of scenes as a single Markov Decision Process (MDP)\nwith a common value function; however, we argue that it is better to treat the\ncollection as a single environment with multiple underlying MDPs. To this end,\nwe propose a dynamic value estimation (DVE) technique for these multiple-MDP\nenvironments, motivated by the clustering effect observed in the value function\ndistribution across different scenes. The resulting agent is able to learn a\nmore accurate and scene-specific value function estimate (and hence the\nadvantage function), leading to a lower sample variance. Our proposed approach\nis simple to accommodate with several existing implementations (like PPO, A3C)\nand results in consistent improvements for a range of ProcGen environments and\nthe AI2-THOR framework based visual navigation task.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:56:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2005.12263", "submitter": "Chun-Na Li", "authors": "Xiang-Fei Yang, Yuan-Hai Shao, Chun-Na Li, Li-Ming Liu, Nai-Yang Deng", "title": "Principal Component Analysis Based on T$\\ell_1$-norm Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical principal component analysis (PCA) may suffer from the sensitivity\nto outliers and noise. Therefore PCA based on $\\ell_1$-norm and $\\ell_p$-norm\n($0 < p < 1$) have been studied. Among them, the ones based on $\\ell_p$-norm\nseem to be most interesting from the robustness point of view. However, their\nnumerical performance is not satisfactory. Note that, although T$\\ell_1$-norm\nis similar to $\\ell_p$-norm ($0 < p < 1$) in some sense, it has the stronger\nsuppression effect to outliers and better continuity. So PCA based on\nT$\\ell_1$-norm is proposed in this paper. Our numerical experiments have shown\nthat its performance is superior than PCA-$\\ell_p$ and $\\ell_p$SPCA as well as\nPCA, PCA-$\\ell_1$ obviously.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 04:28:45 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Yang", "Xiang-Fei", ""], ["Shao", "Yuan-Hai", ""], ["Li", "Chun-Na", ""], ["Liu", "Li-Ming", ""], ["Deng", "Nai-Yang", ""]]}, {"id": "2005.12326", "submitter": "Cong Wang", "authors": "Cong Wang, Yuanyuan Yang and Pengzhan Zhou", "title": "Towards Efficient Scheduling of Federated Mobile Devices under\n  Computational and Statistical Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Originated from distributed learning, federated learning enables\nprivacy-preserved collaboration on a new abstracted level by sharing the model\nparameters only. While the current research mainly focuses on optimizing\nlearning algorithms and minimizing communication overhead left by distributed\nlearning, there is still a considerable gap when it comes to the real\nimplementation on mobile devices. In this paper, we start with an empirical\nexperiment to demonstrate computation heterogeneity is a more pronounced\nbottleneck than communication on the current generation of battery-powered\nmobile devices, and the existing methods are haunted by mobile stragglers.\nFurther, non-identically distributed data across the mobile users makes the\nselection of participants critical to the accuracy and convergence. To tackle\nthe computational and statistical heterogeneity, we utilize data as a tuning\nknob and propose two efficient polynomial-time algorithms to schedule different\nworkloads on various mobile devices, when data is identically or\nnon-identically distributed. For identically distributed data, we combine\npartitioning and linear bottleneck assignment to achieve near-optimal training\ntime without accuracy loss. For non-identically distributed data, we convert it\ninto an average cost minimization problem and propose a greedy algorithm to\nfind a reasonable balance between computation time and accuracy. We also\nestablish an offline profiler to quantify the runtime behavior of different\ndevices, which serves as the input to the scheduling algorithms. We conduct\nextensive experiments on a mobile testbed with two datasets and up to 20\ndevices. Compared with the common benchmarks, the proposed algorithms achieve\n2-100x speedup epoch-wise, 2-7% accuracy gain and boost the convergence rate by\nmore than 100% on CIFAR10.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:21:51 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 18:12:30 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Cong", ""], ["Yang", "Yuanyuan", ""], ["Zhou", "Pengzhan", ""]]}, {"id": "2005.12339", "submitter": "Dan Roth", "authors": "Dan Roth", "title": "Incidental Supervision: Moving beyond Supervised Learning", "comments": "6 pages, 1 figure. Appeared in AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning and Inference methods have become ubiquitous in our attempt\nto induce more abstract representations of natural language text, visual\nscenes, and other messy, naturally occurring data, and support decisions that\ndepend on it. However, learning models for these tasks is difficult partly\nbecause generating the necessary supervision signals for it is costly and does\nnot scale. This paper describes several learning paradigms that are designed to\nalleviate the supervision bottleneck. It will illustrate their benefit in the\ncontext of multiple problems, all pertaining to inducing various levels of\nsemantic representations from text.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:44:53 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Roth", "Dan", ""]]}, {"id": "2005.12359", "submitter": "Michael Moor", "authors": "Michael Moor, Max Horn, Christian Bock, Karsten Borgwardt, Bastian\n  Rieck", "title": "Path Imputation Strategies for Signature Models of Irregular Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The signature transform is a 'universal nonlinearity' on the space of\ncontinuous vector-valued paths, and has received attention for use in machine\nlearning on time series. However, real-world temporal data is typically\nobserved at discrete points in time, and must first be transformed into a\ncontinuous path before signature techniques can be applied. We make this step\nexplicit by characterising it as an imputation problem, and empirically assess\nthe impact of various imputation strategies when applying signature-based\nneural nets to irregular time series data. For one of these strategies,\nGaussian process (GP) adapters, we propose an extension~(GP-PoM) that makes\nuncertainty information directly available to the subsequent classifier while\nat the same time preventing costly Monte-Carlo (MC) sampling. In our\nexperiments, we find that the choice of imputation drastically affects shallow\nsignature models, whereas deeper architectures are more robust. Next, we\nobserve that uncertainty-aware predictions (based on GP-PoM or indicator\nimputations) are beneficial for predictive performance, even compared to the\nuncertainty-aware training of conventional GP adapters. In conclusion, we have\ndemonstrated that the path construction is indeed crucial for signature models\nand that our proposed strategy leads to competitive performance in general,\nwhile improving robustness of signature models in particular.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 19:31:21 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 13:05:35 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Moor", "Michael", ""], ["Horn", "Max", ""], ["Bock", "Christian", ""], ["Borgwardt", "Karsten", ""], ["Rieck", "Bastian", ""]]}, {"id": "2005.12379", "submitter": "Sumon Biswas", "authors": "Sumon Biswas and Hridesh Rajan", "title": "Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias?\n  An Empirical Study on Model Fairness", "comments": "To be appeared in ESEC/FSE 2020", "journal-ref": "ESEC/FSE'2020: The 28th ACM Joint European Software Engineering\n  Conference and Symposium on the Foundations of Software Engineering,\n  Sacramento, California, United States, November 8-13, 2020", "doi": "10.1145/3368089.3409704", "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are increasingly being used in important\ndecision-making software such as approving bank loans, recommending criminal\nsentencing, hiring employees, and so on. It is important to ensure the fairness\nof these models so that no discrimination is made based on protected attribute\n(e.g., race, sex, age) while decision making. Algorithms have been developed to\nmeasure unfairness and mitigate them to a certain extent. In this paper, we\nhave focused on the empirical evaluation of fairness and mitigations on\nreal-world machine learning models. We have created a benchmark of 40 top-rated\nmodels from Kaggle used for 5 different tasks, and then using a comprehensive\nset of fairness metrics, evaluated their fairness. Then, we have applied 7\nmitigation techniques on these models and analyzed the fairness, mitigation\nresults, and impacts on performance. We have found that some model optimization\ntechniques result in inducing unfairness in the models. On the other hand,\nalthough there are some fairness control mechanisms in machine learning\nlibraries, they are not documented. The mitigation algorithm also exhibit\ncommon patterns such as mitigation in the post-processing is often costly (in\nterms of performance) and mitigation in the pre-processing stage is preferred\nin most cases. We have also presented different trade-off choices of fairness\nmitigation decisions. Our study suggests future research directions to reduce\nthe gap between theoretical fairness aware algorithms and the software\nengineering methods to leverage them in practice.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 23:35:53 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 17:27:44 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Biswas", "Sumon", ""], ["Rajan", "Hridesh", ""]]}, {"id": "2005.12386", "submitter": "Yiqi Wang", "authors": "Yiqi Wang, Yao Ma, Charu Aggarwal, Jiliang Tang", "title": "Non-IID Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is an important task on graph-structured data with many\nreal-world applications. The goal of graph classification task is to train a\nclassifier using a set of training graphs. Recently, Graph Neural Networks\n(GNNs) have greatly advanced the task of graph classification. When building a\nGNN model for graph classification, the graphs in the training set are usually\nassumed to be identically distributed. However, in many real-world\napplications, graphs in the same dataset could have dramatically different\nstructures, which indicates that these graphs are likely non-identically\ndistributed. Therefore, in this paper, we aim to develop graph neural networks\nfor graphs that are not non-identically distributed. Specifically, we propose a\ngeneral non-IID graph neural network framework, i.e., Non-IID-GNN. Given a\ngraph, Non-IID-GNN can adapt any existing graph neural network model to\ngenerate a sample-specific model for this graph. Comprehensive experiments on\nvarious graph classification benchmarks demonstrate the effectiveness of the\nproposed framework. We will release the code of the proposed framework upon the\nacceptance of the paper.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 05:22:24 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Wang", "Yiqi", ""], ["Ma", "Yao", ""], ["Aggarwal", "Charu", ""], ["Tang", "Jiliang", ""]]}, {"id": "2005.12394", "submitter": "Ye Hu", "authors": "Ye Hu, Mingzhe Chen, Walid Saad, H. Vincent Poor, and Shuguang Cui", "title": "Meta-Reinforcement Learning for Trajectory Design in Wireless UAV\n  Networks", "comments": "6 pages, Fig.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the design of an optimal trajectory for an energy-constrained\ndrone operating in dynamic network environments is studied. In the considered\nmodel, a drone base station (DBS) is dispatched to provide uplink connectivity\nto ground users whose demand is dynamic and unpredictable. In this case, the\nDBS's trajectory must be adaptively adjusted to satisfy the dynamic user access\nrequests. To this end, a meta-learning algorithm is proposed in order to adapt\nthe DBS's trajectory when it encounters novel environments, by tuning a\nreinforcement learning (RL) solution. The meta-learning algorithm provides a\nsolution that adapts the DBS in novel environments quickly based on limited\nformer experiences. The meta-tuned RL is shown to yield a faster convergence to\nthe optimal coverage in unseen environments with a considerably low computation\ncomplexity, compared to the baseline policy gradient algorithm. Simulation\nresults show that, the proposed meta-learning solution yields a 25% improvement\nin the convergence speed, and about 10% improvement in the DBS' communication\nperformance, compared to a baseline policy gradient algorithm. Meanwhile, the\nprobability that the DBS serves over 50% of user requests increases about 27%,\ncompared to the baseline policy gradient algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 20:43:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Hu", "Ye", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Poor", "H. Vincent", ""], ["Cui", "Shuguang", ""]]}, {"id": "2005.12395", "submitter": "Davide Viviano Mr.", "authors": "Davide Viviano, Jelena Bradic", "title": "Fair Policy Targeting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major concerns of targeting interventions on individuals in social\nwelfare programs is discrimination: individualized treatments may induce\ndisparities on sensitive attributes such as age, gender, or race. This paper\naddresses the question of the design of fair and efficient treatment allocation\nrules. We adopt the non-maleficence perspective of \"first do no harm\": we\npropose to select the fairest allocation within the Pareto frontier. We provide\nenvy-freeness justifications to novel counterfactual notions of fairness. We\ndiscuss easy-to-implement estimators of the policy function, by casting the\noptimization into a mixed-integer linear program formulation. We derive regret\nbounds on the unfairness of the estimated policy function, and small sample\nguarantees on the Pareto frontier. Finally, we illustrate our method using an\napplication from education economics.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 20:45:25 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 17:53:09 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Viviano", "Davide", ""], ["Bradic", "Jelena", ""]]}, {"id": "2005.12415", "submitter": "Jason Sun", "authors": "Daqian Sun, Martin T. Wells", "title": "Robust Matrix Completion with Mixed Data Types", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the matrix completion problem of recovering a structured low rank\nmatrix with partially observed entries with mixed data types. Vast majority of\nthe solutions have proposed computationally feasible estimators with strong\nstatistical guarantees for the case where the underlying distribution of data\nin the matrix is continuous. A few recent approaches have extended using\nsimilar ideas these estimators to the case where the underlying distributions\nbelongs to the exponential family. Most of these approaches assume that there\nis only one underlying distribution and the low rank constraint is regularized\nby the matrix Schatten Norm. We propose a computationally feasible statistical\napproach with strong recovery guarantees along with an algorithmic framework\nsuited for parallelization to recover a low rank matrix with partially observed\nentries for mixed data types in one step. We also provide extensive simulation\nevidence that corroborate our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:35:10 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Sun", "Daqian", ""], ["Wells", "Martin T.", ""]]}, {"id": "2005.12418", "submitter": "Cristi\\'an Bravo", "authors": "Cristi\\'an Bravo and Mar\\'ia \\'Oskarsd\\'ottir", "title": "Evolution of Credit Risk Using a Personalized Pagerank Algorithm for\n  Multilayer Networks", "comments": "Conference camera-ready paper - accepted at KDD MLF 2020. 15 pages,\n  10 figures", "journal-ref": "Proceedings of the Third KDD Workshop on Machine Learning in\n  Finance, joint with 26th ACM SIGKDD Conference on Knowledge Discovery in\n  Databases (KDD MLF 2020). ACM, New York, NY, USA, 8 pages", "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel algorithm to study the evolution of credit\nrisk across complex multilayer networks. Pagerank-like algorithms allow for the\npropagation of an influence variable across single networks, and allow\nquantifying the risk single entities (nodes) are subject to given the\nconnection they have to other nodes in the network. Multilayer networks, on the\nother hand, are networks where subset of nodes can be associated to a unique\nset (layer), and where edges connect elements either intra or inter networks.\nOur personalized PageRank algorithm for multilayer networks allows for\nquantifying how credit risk evolves across time and propagates through these\nnetworks. By using bipartite networks in each layer, we can quantify the risk\nof various components, not only the loans. We test our method in an\nagricultural lending dataset, and our results show how default risk is a\nchallenging phenomenon that propagates and evolves through the network across\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:46:57 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 20:18:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Bravo", "Cristi\u00e1n", ""], ["\u00d3skarsd\u00f3ttir", "Mar\u00eda", ""]]}, {"id": "2005.12419", "submitter": "Takanori Fujiwara", "authors": "Takanori Fujiwara, Jian Zhao, Francine Chen, Yaoliang Yu, Kwan-Liu Ma", "title": "Interpretable Contrastive Learning for Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning (CL) is an emerging analysis approach that aims to\ndiscover unique patterns in one dataset relative to another. By applying this\napproach to network analysis, we can reveal unique characteristics in one\nnetwork by contrasting with another. For example, with networks of protein\ninteractions obtained from normal and cancer tissues, we can discover unique\ntypes of interactions in cancer tissues. However, existing CL methods cannot be\ndirectly applied to networks. To address this issue, we introduce a novel\napproach called contrastive network representation learning (cNRL). This\napproach embeds network nodes into a low-dimensional space that reveals the\nuniqueness of one network compared to another. Within this approach, we also\ndesign a method, named i-cNRL, that offers interpretability in the learned\nresults, allowing for understanding which specific patterns are found in one\nnetwork but not the other. We demonstrate the capability of i-cNRL with\nmultiple network models and real-world datasets. Furthermore, we provide\nquantitative and qualitative comparisons across i-cNRL and other potential cNRL\nalgorithm designs.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:46:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Fujiwara", "Takanori", ""], ["Zhao", "Jian", ""], ["Chen", "Francine", ""], ["Yu", "Yaoliang", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2005.12442", "submitter": "Shashank Sonkar", "authors": "Shashank Sonkar, Andrew E. Waters, Andrew S. Lan, Phillip J. Grimaldi,\n  Richard G. Baraniuk", "title": "qDKT: Question-centric Deep Knowledge Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing (KT) models, e.g., the deep knowledge tracing (DKT) model,\ntrack an individual learner's acquisition of skills over time by examining the\nlearner's performance on questions related to those skills. A practical\nlimitation in most existing KT models is that all questions nested under a\nparticular skill are treated as equivalent observations of a learner's ability,\nwhich is an inaccurate assumption in real-world educational scenarios. To\novercome this limitation we introduce qDKT, a variant of DKT that models every\nlearner's success probability on individual questions over time. First, qDKT\nincorporates graph Laplacian regularization to smooth predictions under each\nskill, which is particularly useful when the number of questions in the dataset\nis big. Second, qDKT uses an initialization scheme inspired by the fastText\nalgorithm, which has found success in a variety of language modeling tasks. Our\nexperiments on several real-world datasets show that qDKT achieves state-of-art\nperformance on predicting learner outcomes. Because of this, qDKT can serve as\na simple, yet tough-to-beat, baseline for new question-centric KT models.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 23:43:55 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Sonkar", "Shashank", ""], ["Waters", "Andrew E.", ""], ["Lan", "Andrew S.", ""], ["Grimaldi", "Phillip J.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "2005.12483", "submitter": "Ernest Chan", "authors": "Xin Man and Ernest Chan", "title": "The best way to select features?", "comments": "8 pages, submitted to ACM International Conference on AI in Finance\n  (ICAIF-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection in machine learning is subject to the intrinsic randomness\nof the feature selection algorithms (for example, random permutations during\nMDA). Stability of selected features with respect to such randomness is\nessential to the human interpretability of a machine learning algorithm. We\nproposes a rank based stability metric called instability index to compare the\nstabilities of three feature selection algorithms MDA, LIME, and SHAP as\napplied to random forests. Typically, features are selected by averaging many\nrandom iterations of a selection algorithm. Though we find that the variability\nof the selected features does decrease as the number of iterations increases,\nit does not go to zero, and the features selected by the three algorithms do\nnot necessarily converge to the same set. We find LIME and SHAP to be more\nstable than MDA, and LIME is at least as stable as SHAP for the top ranked\nfeatures. Hence overall LIME is best suited for human interpretability.\nHowever, the selected set of features from all three algorithms significantly\nimproves various predictive metrics out of sample, and their predictive\nperformances do not differ significantly. Experiments were conducted on\nsynthetic datasets, two public benchmark datasets, and on proprietary data from\nan active investment strategy.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 02:20:40 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Man", "Xin", ""], ["Chan", "Ernest", ""]]}, {"id": "2005.12488", "submitter": "Takashi Mori", "authors": "Takashi Mori, Masahito Ueda", "title": "Is deeper better? It depends on locality of relevant features", "comments": "13+4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been recognized that a heavily overparameterized artificial neural\nnetwork exhibits surprisingly good generalization performance in various\nmachine-learning tasks. Recent theoretical studies have made attempts to unveil\nthe mystery of the overparameterization. In most of those previous works, the\noverparameterization is achieved by increasing the width of the network, while\nthe effect of increasing the depth has remained less well understood. In this\nwork, we investigate the effect of increasing the depth within an\noverparameterized regime. To gain an insight into the advantage of depth, we\nintroduce local and global labels as abstract but simple classification rules.\nIt turns out that the locality of the relevant feature for a given\nclassification rule plays a key role; our experimental results suggest that\ndeeper is better for local labels, whereas shallower is better for global\nlabels. We also compare the results of finite networks with those of the neural\ntangent kernel (NTK), which is equivalent to an infinitely wide network with a\nproper initialization and an infinitesimal learning rate. It is shown that the\nNTK does not correctly capture the depth dependence of the generalization\nperformance, which indicates the importance of the feature learning rather than\nthe lazy learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 02:44:18 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 12:22:50 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Mori", "Takashi", ""], ["Ueda", "Masahito", ""]]}, {"id": "2005.12496", "submitter": "Eric Zelikman", "authors": "Eric Zelikman, Christopher Healy, Sharon Zhou, Anand Avati", "title": "CRUDE: Calibrating Regression Uncertainty Distributions Empirically", "comments": "ICML 2020 Workshop on Uncertainty & Robustness in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibrated uncertainty estimates in machine learning are crucial to many\nfields such as autonomous vehicles, medicine, and weather and climate\nforecasting. While there is extensive literature on uncertainty calibration for\nclassification, the classification findings do not always translate to\nregression. As a result, modern models for predicting uncertainty in regression\nsettings typically produce uncalibrated and overconfident estimates. To address\nthese gaps, we present a calibration method for regression settings that does\nnot assume a particular uncertainty distribution over the error: Calibrating\nRegression Uncertainty Distributions Empirically (CRUDE). CRUDE makes the\nweaker assumption that error distributions have a constant arbitrary shape\nacross the output space, shifted by predicted mean and scaled by predicted\nstandard deviation. We detail a theoretical connection between CRUDE and\nconformal inference. Across an extensive set of regression tasks, CRUDE\ndemonstrates consistently sharper, better calibrated, and more accurate\nuncertainty estimates than state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 03:08:43 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 02:35:57 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 23:22:57 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 01:25:07 GMT"}, {"version": "v5", "created": "Wed, 14 Oct 2020 21:23:56 GMT"}, {"version": "v6", "created": "Mon, 15 Mar 2021 02:30:18 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zelikman", "Eric", ""], ["Healy", "Christopher", ""], ["Zhou", "Sharon", ""], ["Avati", "Anand", ""]]}, {"id": "2005.12564", "submitter": "T. Konstantin Rusch", "authors": "Siddhartha Mishra, T. Konstantin Rusch", "title": "Enhancing accuracy of deep learning algorithms by training with\n  low-discrepancy sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep supervised learning algorithm based on low-discrepancy\nsequences as the training set. By a combination of theoretical arguments and\nextensive numerical experiments we demonstrate that the proposed algorithm\nsignificantly outperforms standard deep learning algorithms that are based on\nrandomly chosen training data, for problems in moderately high dimensions. The\nproposed algorithm provides an efficient method for building inexpensive\nsurrogates for many underlying maps in the context of scientific computing.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 08:14:00 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Mishra", "Siddhartha", ""], ["Rusch", "T. Konstantin", ""]]}, {"id": "2005.12601", "submitter": "Thomas Berrett", "authors": "Thomas B. Berrett and Cristina Butucea", "title": "Locally private non-asymptotic testing of discrete distributions is\n  faster using interactive mechanisms", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find separation rates for testing multinomial or more general discrete\ndistributions under the constraint of local differential privacy. We construct\nefficient randomized algorithms and test procedures, in both the case where\nonly non-interactive privacy mechanisms are allowed and also in the case where\nall sequentially interactive privacy mechanisms are allowed. The separation\nrates are faster in the latter case. We prove general information theoretical\nbounds that allow us to establish the optimality of our algorithms among all\npairs of privacy mechanisms and test procedures, in most usual cases.\nConsidered examples include testing uniform, polynomially and exponentially\ndecreasing distributions.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 09:43:08 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Berrett", "Thomas B.", ""], ["Butucea", "Cristina", ""]]}, {"id": "2005.12627", "submitter": "Morteza Haghir Chehreghani", "authors": "Fazeleh Sadat Hoseini, Morteza Haghir Chehreghani", "title": "Memory-Efficient Sampling for Minimax Distance Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimax distance measure extracts the underlying patterns and manifolds in an\nunsupervised manner. The existing methods require a quadratic memory with\nrespect to the number of objects. In this paper, we investigate efficient\nsampling schemes in order to reduce the memory requirement and provide a linear\nspace complexity. In particular, we propose a novel sampling technique that\nadapts well with Minimax distances. We evaluate the methods on real-world\ndatasets from different domains and analyze the results.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:00:34 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Hoseini", "Fazeleh Sadat", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2005.12636", "submitter": "Zoltan Szabo", "authors": "Pierre-Cyril Aubin-Frankowski, Zoltan Szabo", "title": "Hard Shape-Constrained Kernel Machines", "comments": "camera-ready paper", "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS-2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape constraints (such as non-negativity, monotonicity, convexity) play a\ncentral role in a large number of applications, as they usually improve\nperformance for small sample size and help interpretability. However enforcing\nthese shape requirements in a hard fashion is an extremely challenging problem.\nClassically, this task is tackled (i) in a soft way (without out-of-sample\nguarantees), (ii) by specialized transformation of the variables on a\ncase-by-case basis, or (iii) by using highly restricted function classes, such\nas polynomials or polynomial splines. In this paper, we prove that hard affine\nshape constraints on function derivatives can be encoded in kernel machines\nwhich represent one of the most flexible and powerful tools in machine learning\nand statistics. Particularly, we present a tightened second-order cone\nconstrained reformulation, that can be readily implemented in convex solvers.\nWe prove performance guarantees on the solution, and demonstrate the efficiency\nof the approach in joint quantile regression with applications to economics and\nto the analysis of aircraft trajectories, among others.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:35:49 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 09:59:26 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Aubin-Frankowski", "Pierre-Cyril", ""], ["Szabo", "Zoltan", ""]]}, {"id": "2005.12639", "submitter": "Evgenii Egorov", "authors": "Anna Kuzina, Evgenii Egorov, Evgeny Burnaev", "title": "Bayesian Generative Models for Knowledge Transfer in MRI Semantic\n  Segmentation Problems", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.05480", "journal-ref": null, "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/3i6X1618wi", "categories": "eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic segmentation methods based on deep learning have recently\ndemonstrated state-of-the-art performance, outperforming the ordinary methods.\nNevertheless, these methods are inapplicable for small datasets, which are very\ncommon in medical problems. To this end, we propose a knowledge transfer method\nbetween diseases via the Generative Bayesian Prior network. Our approach is\ncompared to a pre-train approach and random initialization and obtains the best\nresults in terms of Dice Similarity Coefficient metric for the small subsets of\nthe Brain Tumor Segmentation 2018 database (BRATS2018).\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:42:17 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 19:54:19 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Kuzina", "Anna", ""], ["Egorov", "Evgenii", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2005.12657", "submitter": "Xin Yao", "authors": "Xin Yao, Lifeng Sun", "title": "Continual Local Training for Better Initialization of Federated Models", "comments": "This paper has been accepted to 2020 IEEE International Conference on\n  Image Processing (ICIP 2020)", "journal-ref": null, "doi": "10.1109/ICIP40778.2020.9190968", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) refers to the learning paradigm that trains machine\nlearning models directly in the decentralized systems consisting of smart edge\ndevices without transmitting the raw data, which avoids the heavy communication\ncosts and privacy concerns. Given the typical heterogeneous data distributions\nin such situations, the popular FL algorithm \\emph{Federated Averaging}\n(FedAvg) suffers from weight divergence and thus cannot achieve a competitive\nperformance for the global model (denoted as the \\emph{initial performance} in\nFL) compared to centralized methods. In this paper, we propose the local\ncontinual training strategy to address this problem. Importance weights are\nevaluated on a small proxy dataset on the central server and then used to\nconstrain the local training. With this additional term, we alleviate the\nweight divergence and continually integrate the knowledge on different local\nclients into the global model, which ensures a better generalization ability.\nExperiments on various FL settings demonstrate that our method significantly\nimproves the initial performance of federated models with few extra\ncommunication costs.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 12:27:31 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Yao", "Xin", ""], ["Sun", "Lifeng", ""]]}, {"id": "2005.12729", "submitter": "Andrew Ilyas", "authors": "Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras,\n  Firdaus Janoos, Larry Rudolph, Aleksander Madry", "title": "Implementation Matters in Deep Policy Gradients: A Case Study on PPO and\n  TRPO", "comments": "ICLR 2020 version. arXiv admin note: text overlap with\n  arXiv:1811.02553", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the roots of algorithmic progress in deep policy gradient algorithms\nthrough a case study on two popular algorithms: Proximal Policy Optimization\n(PPO) and Trust Region Policy Optimization (TRPO). Specifically, we investigate\nthe consequences of \"code-level optimizations:\" algorithm augmentations found\nonly in implementations or described as auxiliary details to the core\nalgorithm. Seemingly of secondary importance, such optimizations turn out to\nhave a major impact on agent behavior. Our results show that they (a) are\nresponsible for most of PPO's gain in cumulative reward over TRPO, and (b)\nfundamentally change how RL methods function. These insights show the\ndifficulty and importance of attributing performance gains in deep\nreinforcement learning. Code for reproducing our results is available at\nhttps://github.com/MadryLab/implementation-matters .\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:24:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Janoos", "Firdaus", ""], ["Rudolph", "Larry", ""], ["Madry", "Aleksander", ""]]}, {"id": "2005.12743", "submitter": "Arushi Gupta", "authors": "Arushi Gupta", "title": "Inherent Noise in Gradient Based Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has examined the ability of larger capacity neural networks to\ngeneralize better than smaller ones, even without explicit regularizers, by\nanalyzing gradient based algorithms such as GD and SGD. The presence of noise\nand its effect on robustness to parameter perturbations has been linked to\ngeneralization. We examine a property of GD and SGD, namely that instead of\niterating through all scalar weights in the network and updating them one by\none, GD (and SGD) updates all the parameters at the same time. As a result,\neach parameter $w^i$ calculates its partial derivative at the stale parameter\n$\\mathbf{w_t}$, but then suffers loss $\\hat{L}(\\mathbf{w_{t+1}})$. We show that\nthis causes noise to be introduced into the optimization. We find that this\nnoise penalizes models that are sensitive to perturbations in the weights. We\nfind that penalties are most pronounced for batches that are currently being\nused to update, and are higher for larger models.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:12:22 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Gupta", "Arushi", ""]]}, {"id": "2005.12766", "submitter": "Hongchao Fang", "authors": "Hongchao Fang, Sicheng Wang, Meng Zhou, Jiayuan Ding, Pengtao Xie", "title": "CERT: Contrastive Self-supervised Learning for Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models such as BERT, GPT have shown great effectiveness\nin language understanding. The auxiliary predictive tasks in existing\npretraining approaches are mostly defined on tokens, thus may not be able to\ncapture sentence-level semantics very well. To address this issue, we propose\nCERT: Contrastive self-supervised Encoder Representations from Transformers,\nwhich pretrains language representation models using contrastive\nself-supervised learning at the sentence level. CERT creates augmentations of\noriginal sentences using back-translation. Then it finetunes a pretrained\nlanguage encoder (e.g., BERT) by predicting whether two augmented sentences\noriginate from the same sentence. CERT is simple to use and can be flexibly\nplugged into any pretraining-finetuning NLP pipeline. We evaluate CERT on 11\nnatural language understanding tasks in the GLUE benchmark where CERT\noutperforms BERT on 7 tasks, achieves the same performance as BERT on 2 tasks,\nand performs worse than BERT on 2 tasks. On the averaged score of the 11 tasks,\nCERT outperforms BERT. The data and code are available at\nhttps://github.com/UCSD-AI4H/CERT\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:20:38 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 12:47:18 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Fang", "Hongchao", ""], ["Wang", "Sicheng", ""], ["Zhou", "Meng", ""], ["Ding", "Jiayuan", ""], ["Xie", "Pengtao", ""]]}, {"id": "2005.12781", "submitter": "Bingqing Yu", "authors": "Jacopo Tagliabue, Bingqing Yu, Marie Beaulieu", "title": "How to Grow a (Product) Tree: Personalized Category Suggestions for\n  eCommerce Type-Ahead", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an attempt to balance precision and recall in the search page, leading\ndigital shops have been effectively nudging users into select category facets\nas early as in the type-ahead suggestions. In this work, we present\nSessionPath, a novel neural network model that improves facet suggestions on\ntwo counts: first, the model is able to leverage session embeddings to provide\nscalable personalization; second, SessionPath predicts facets by explicitly\nproducing a probability distribution at each node in the taxonomy path. We\nbenchmark SessionPath on two partnering shops against count-based and neural\nmodels, and show how business requirements and model behavior can be combined\nin a principled way.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:03:16 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Tagliabue", "Jacopo", ""], ["Yu", "Bingqing", ""], ["Beaulieu", "Marie", ""]]}, {"id": "2005.12782", "submitter": "Herv\\'e Chabanne", "authors": "Herv\\'e Chabanne and Vincent Despiegel and Linda Guiga", "title": "A Protection against the Extraction of Neural Network Models", "comments": "Add Noisy Identity Parasitic layers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given oracle access to a Neural Network (NN), it is possible to extract its\nunderlying model. We here introduce a protection by adding parasitic layers\nwhich keep the underlying NN's predictions mostly unchanged while complexifying\nthe task of reverse-engineering. Our countermeasure relies on approximating a\nnoisy identity mapping with a Convolutional NN. We explain why the introduction\nof new parasitic layers complexifies the attacks. We report experiments\nregarding the performance and the accuracy of the protected NN.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:04:29 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:25:07 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 09:41:41 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Chabanne", "Herv\u00e9", ""], ["Despiegel", "Vincent", ""], ["Guiga", "Linda", ""]]}, {"id": "2005.12787", "submitter": "Nan Wu", "authors": "Yuan Gao, Jian-Guo Liu, Nan Wu", "title": "Data-driven Efficient Solvers for Langevin Dynamics on Manifold in High\n  Dimensions", "comments": "48 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Langevin dynamics of a physical system with manifold structure\n$\\mathcal{M}\\subset\\mathbb{R}^p$ based on collected sample points\n$\\{\\mathsf{x}_i\\}_{i=1}^n \\subset \\mathcal{M}$ that probe the unknown manifold\n$\\mathcal{M}$. Through the diffusion map, we first learn the reaction\ncoordinates $\\{\\mathsf{y}_i\\}_{i=1}^n\\subset \\mathcal{N}$ corresponding to\n$\\{\\mathsf{x}_i\\}_{i=1}^n$, where $\\mathcal{N}$ is a manifold diffeomorphic to\n$\\mathcal{M}$ and isometrically embedded in $\\mathbb{R}^\\ell$ with $\\ell \\ll\np$. The induced Langevin dynamics on $\\mathcal{N}$ in terms of the reaction\ncoordinates captures the slow time scale dynamics such as conformational\nchanges in biochemical reactions. To construct an efficient and stable\napproximation for the Langevin dynamics on $\\mathcal{N}$, we leverage the\ncorresponding Fokker-Planck equation on the manifold $\\mathcal{N}$ in terms of\nthe reaction coordinates $\\mathsf{y}$. We propose an implementable,\nunconditionally stable, data-driven finite volume scheme for this Fokker-Planck\nequation, which automatically incorporates the manifold structure of\n$\\mathcal{N}$. Furthermore, we provide a weighted $L^2$ convergence analysis of\nthe finite volume scheme to the Fokker-Planck equation on $\\mathcal{N}$. The\nproposed finite volume scheme leads to a Markov chain on\n$\\{\\mathsf{y}_i\\}_{i=1}^n$ with an approximated transition probability and jump\nrate between the nearest neighbor points. After an unconditionally stable\nexplicit time discretization, the data-driven finite volume scheme gives an\napproximated Markov process for the Langevin dynamics on $\\mathcal{N}$ and the\napproximated Markov process enjoys detailed balance, ergodicity, and other good\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 16:55:38 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 04:28:43 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Gao", "Yuan", ""], ["Liu", "Jian-Guo", ""], ["Wu", "Nan", ""]]}, {"id": "2005.12792", "submitter": "Carlos Outeiral Rubiera", "authors": "Carlos Outeiral, Martin Strahm, Jiye Shi, Garrett M. Morris, Simon C.\n  Benjamin, Charlotte M. Deane", "title": "The prospects of quantum computing in computational molecular biology", "comments": "23 pages, 3 figures", "journal-ref": "WIREs Computational Molecular Science, 2020", "doi": "10.1002/wcms.1481", "report-no": null, "categories": "quant-ph q-bio.BM q-bio.GN q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum computers can in principle solve certain problems exponentially more\nquickly than their classical counterparts. We have not yet reached the advent\nof useful quantum computation, but when we do, it will affect nearly all\nscientific disciplines. In this review, we examine how current quantum\nalgorithms could revolutionize computational biology and bioinformatics. There\nare potential benefits across the entire field, from the ability to process\nvast amounts of information and run machine learning algorithms far more\nefficiently, to algorithms for quantum simulation that are poised to improve\ncomputational calculations in drug discovery, to quantum algorithms for\noptimization that may advance fields from protein structure prediction to\nnetwork analysis. However, these exciting prospects are susceptible to \"hype\",\nand it is also important to recognize the caveats and challenges in this new\ntechnology. Our aim is to introduce the promise and limitations of emerging\nquantum computing technologies in the areas of computational molecular biology\nand bioinformatics.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:18:05 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Outeiral", "Carlos", ""], ["Strahm", "Martin", ""], ["Shi", "Jiye", ""], ["Morris", "Garrett M.", ""], ["Benjamin", "Simon C.", ""], ["Deane", "Charlotte M.", ""]]}, {"id": "2005.12801", "submitter": "Kiant\\'e Brantley", "authors": "Kiant\\'e Brantley, Amr Sharaf, Hal Daum\\'e III", "title": "Active Imitation Learning with Noisy Guidance", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms provide state-of-the-art results on many\nstructured prediction tasks by learning near-optimal search policies. Such\nalgorithms assume training-time access to an expert that can provide the\noptimal action at any queried state; unfortunately, the number of such queries\nis often prohibitive, frequently rendering these approaches impractical. To\ncombat this query complexity, we consider an active learning setting in which\nthe learning algorithm has additional access to a much cheaper noisy heuristic\nthat provides noisy guidance. Our algorithm, LEAQI, learns a difference\nclassifier that predicts when the expert is likely to disagree with the\nheuristic, and queries the expert only when necessary. We apply LEAQI to three\nsequence labeling tasks, demonstrating significantly fewer queries to the\nexpert and comparable (or better) accuracies over a passive approach.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:35:46 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Brantley", "Kiant\u00e9", ""], ["Sharaf", "Amr", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "2005.12815", "submitter": "Diego Aghi", "authors": "Diego Aghi, Vittorio Mazzia, Marcello Chiaberge", "title": "Local Motion Planner for Autonomous Navigation in Vineyards with a RGB-D\n  Camera-Based Algorithm and Deep Learning Synergy", "comments": null, "journal-ref": null, "doi": "10.3390/machines8020027", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of agriculture 3.0 and 4.0, researchers are increasingly\nfocusing on the development of innovative smart farming and precision\nagriculture technologies by introducing automation and robotics into the\nagricultural processes. Autonomous agricultural field machines have been\ngaining significant attention from farmers and industries to reduce costs,\nhuman workload, and required resources. Nevertheless, achieving sufficient\nautonomous navigation capabilities requires the simultaneous cooperation of\ndifferent processes; localization, mapping, and path planning are just some of\nthe steps that aim at providing to the machine the right set of skills to\noperate in semi-structured and unstructured environments. In this context, this\nstudy presents a low-cost local motion planner for autonomous navigation in\nvineyards based only on an RGB-D camera, low range hardware, and a dual layer\ncontrol algorithm. The first algorithm exploits the disparity map and its depth\nrepresentation to generate a proportional control for the robotic platform.\nConcurrently, a second back-up algorithm, based on representations learning and\nresilient to illumination variations, can take control of the machine in case\nof a momentaneous failure of the first block. Moreover, due to the double\nnature of the system, after initial training of the deep learning model with an\ninitial dataset, the strict synergy between the two algorithms opens the\npossibility of exploiting new automatically labeled data, coming from the\nfield, to extend the existing model knowledge. The machine learning algorithm\nhas been trained and tested, using transfer learning, with acquired images\nduring different field surveys in the North region of Italy and then optimized\nfor on-device inference with model pruning and quantization. Finally, the\noverall system has been validated with a customized robot platform in the\nrelevant environment.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:47:42 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Aghi", "Diego", ""], ["Mazzia", "Vittorio", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2005.12830", "submitter": "Jia Xue", "authors": "Jia Xue (University of Toronto), Junxiang Chen (University of\n  Pittsburgh), Ran Hu (University of Toronto), Chen Chen (University of\n  Toronto), ChengDa Zheng (University of Toronto), Xiaoqian Liu (Chinese\n  Academy of Sciences), Tingshao Zhu (China Academy of Science)", "title": "Twitter discussions and emotions about COVID-19 pandemic: a machine\n  learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the study is to examine coronavirus disease (COVID-19)\nrelated discussions, concerns, and sentiments that emerged from tweets posted\nby Twitter users. We analyze 4 million Twitter messages related to the COVID-19\npandemic using a list of 25 hashtags such as \"coronavirus,\" \"COVID-19,\"\n\"quarantine\" from March 1 to April 21 in 2020. We use a machine learning\napproach, Latent Dirichlet Allocation (LDA), to identify popular unigram,\nbigrams, salient topics and themes, and sentiments in the collected Tweets.\nPopular unigrams include \"virus,\" \"lockdown,\" and \"quarantine.\" Popular bigrams\ninclude \"COVID-19,\" \"stay home,\" \"corona virus,\" \"social distancing,\" and \"new\ncases.\" We identify 13 discussion topics and categorize them into five\ndifferent themes, such as \"public health measures to slow the spread of\nCOVID-19,\" \"social stigma associated with COVID-19,\" \"coronavirus news cases\nand deaths,\" \"COVID-19 in the United States,\" and \"coronavirus cases in the\nrest of the world\". Across all identified topics, the dominant sentiments for\nthe spread of coronavirus are anticipation that measures that can be taken,\nfollowed by a mixed feeling of trust, anger, and fear for different topics. The\npublic reveals a significant feeling of fear when they discuss the coronavirus\nnew cases and deaths than other topics. The study shows that Twitter data and\nmachine learning approaches can be leveraged for infodemiology study by\nstudying the evolving public discussions and sentiments during the COVID-19.\nReal-time monitoring and assessment of the Twitter discussion and concerns can\nbe promising for public health emergency responses and planning. Already\nemerged pandemic fear, stigma, and mental health concerns may continue to\ninfluence public trust when there occurs a second wave of COVID-19 or a new\nsurge of the imminent pandemic.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:10:02 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 02:43:13 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Xue", "Jia", "", "University of Toronto"], ["Chen", "Junxiang", "", "University of\n  Pittsburgh"], ["Hu", "Ran", "", "University of Toronto"], ["Chen", "Chen", "", "University of\n  Toronto"], ["Zheng", "ChengDa", "", "University of Toronto"], ["Liu", "Xiaoqian", "", "Chinese\n  Academy of Sciences"], ["Zhu", "Tingshao", "", "China Academy of Science"]]}, {"id": "2005.12844", "submitter": "Sushrut Karmalkar", "authors": "Ilias Diakonikolas, Surbhi Goel, Sushrut Karmalkar, Adam R. Klivans,\n  Mahdi Soltanolkotabi", "title": "Approximation Schemes for ReLU Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental problem of ReLU regression, where the goal is to\noutput the best fitting ReLU with respect to square loss given access to draws\nfrom some unknown distribution. We give the first efficient, constant-factor\napproximation algorithm for this problem assuming the underlying distribution\nsatisfies some weak concentration and anti-concentration conditions (and\nincludes, for example, all log-concave distributions). This solves the main\nopen problem of Goel et al., who proved hardness results for any exact\nalgorithm for ReLU regression (up to an additive $\\epsilon$). Using more\nsophisticated techniques, we can improve our results and obtain a\npolynomial-time approximation scheme for any subgaussian distribution. Given\nthe aforementioned hardness results, these guarantees can not be substantially\nimproved.\n  Our main insight is a new characterization of surrogate losses for nonconvex\nactivations. While prior work had established the existence of convex\nsurrogates for monotone activations, we show that properties of the underlying\ndistribution actually induce strong convexity for the loss, allowing us to\nrelate the global minimum to the activation's Chow parameters.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:26:17 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 18:08:38 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Goel", "Surbhi", ""], ["Karmalkar", "Sushrut", ""], ["Klivans", "Adam R.", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2005.12864", "submitter": "Giuseppe Canonaco", "authors": "Giuseppe Canonaco, Andrea Soprani, Manuel Roveri, Marcello Restelli", "title": "Time-Variant Variational Transfer for Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most of the transfer learning approaches to reinforcement learning (RL)\nthe distribution over the tasks is assumed to be stationary. Therefore, the\ntarget and source tasks are i.i.d. samples of the same distribution. In the\ncontext of this work, we consider the problem of transferring value functions\nthrough a variational method when the distribution that generates the tasks is\ntime-variant, proposing a solution that leverages this temporal structure\ninherent in the task generating process. Furthermore, by means of a\nfinite-sample analysis, the previously mentioned solution is theoretically\ncompared to its time-invariant version. Finally, we will provide an\nexperimental evaluation of the proposed technique with three distinct temporal\ndynamics in three different RL environments.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:52:26 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 13:13:12 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Canonaco", "Giuseppe", ""], ["Soprani", "Andrea", ""], ["Roveri", "Manuel", ""], ["Restelli", "Marcello", ""]]}, {"id": "2005.12900", "submitter": "Yuxin Chen", "authors": "Gen Li, Yuting Wei, Yuejie Chi, Yuantao Gu, Yuxin Chen", "title": "Breaking the Sample Size Barrier in Model-Based Reinforcement Learning\n  with a Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the sample efficiency of reinforcement learning in a\n$\\gamma$-discounted infinite-horizon Markov decision process (MDP) with state\nspace $\\mathcal{S}$ and action space $\\mathcal{A}$, assuming access to a\ngenerative model. Despite a number of prior work tackling this problem, a\ncomplete picture of the trade-offs between sample complexity and statistical\naccuracy is yet to be determined. In particular, prior results suffer from a\nsample size barrier, in the sense that their claimed statistical guarantees\nhold only when the sample size exceeds at least\n$\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)^2}$ (up to some log factor). The\ncurrent paper overcomes this barrier by certifying the minimax optimality of\nmodel-based reinforcement learning as soon as the sample size exceeds the order\nof $\\frac{|\\mathcal{S}||\\mathcal{A}|}{1-\\gamma}$ (modulo some log factor). More\nspecifically, a perturbed model-based planning algorithm provably finds an\n$\\varepsilon$-optimal policy with an order of $\\frac{|\\mathcal{S}||\\mathcal{A}|\n}{(1-\\gamma)^3\\varepsilon^2}\\log\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)\\varepsilon}$\nsamples for any $\\varepsilon \\in (0, \\frac{1}{1-\\gamma}]$. Along the way, we\nderive improved (instance-dependent) guarantees for model-based policy\nevaluation. To the best of our knowledge, this work provides the first\nminimax-optimal guarantee in a generative model that accommodates the entire\nrange of sample sizes (beyond which finding a meaningful policy is information\ntheoretically impossible).\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:53:18 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 17:50:39 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 02:02:42 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Li", "Gen", ""], ["Wei", "Yuting", ""], ["Chi", "Yuejie", ""], ["Gu", "Yuantao", ""], ["Chen", "Yuxin", ""]]}, {"id": "2005.12901", "submitter": "Cong Wang", "authors": "Cong Wang, Yanru Xiao, Xing Gao, Li Li, Jun Wang", "title": "A Framework for Behavioral Biometric Authentication using Deep Metric\n  Learning on Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile authentication using behavioral biometrics has been an active area of\nresearch. Existing research relies on building machine learning classifiers to\nrecognize an individual's unique patterns. However, these classifiers are not\npowerful enough to learn the discriminative features. When implemented on the\nmobile devices, they face new challenges from the behavioral dynamics, data\nprivacy and side-channel leaks. To address these challenges, we present a new\nframework to incorporate training on battery-powered mobile devices, so private\ndata never leaves the device and training can be flexibly scheduled to adapt\nthe behavioral patterns at runtime. We re-formulate the classification problem\ninto deep metric learning to improve the discriminative power and design an\neffective countermeasure to thwart side-channel leaks by embedding a noise\nsignature in the sensing signals without sacrificing too much usability. The\nexperiments demonstrate authentication accuracy over 95% on three public\ndatasets, a sheer 15% gain from multi-class classification with less data and\nrobustness against brute-force and side-channel attacks with 99% and 90%\nsuccess, respectively. We show the feasibility of training with mobile CPUs,\nwhere training 100 epochs takes less than 10 mins and can be boosted 3-5 times\nwith feature transfer. Finally, we profile memory, energy and computational\noverhead. Our results indicate that training consumes lower energy than\nwatching videos and slightly higher energy than playing games.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:56:20 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 16:39:08 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Cong", ""], ["Xiao", "Yanru", ""], ["Gao", "Xing", ""], ["Li", "Li", ""], ["Wang", "Jun", ""]]}, {"id": "2005.12914", "submitter": "Ziyu Xu", "authors": "Ziyu Xu, Chen Dan, Justin Khim, Pradeep Ravikumar", "title": "Class-Weighted Classification: Trade-offs and Robust Approaches", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address imbalanced classification, the problem in which a label may have\nlow marginal probability relative to other labels, by weighting losses\naccording to the correct class. First, we examine the convergence rates of the\nexpected excess weighted risk of plug-in classifiers where the weighting for\nthe plug-in classifier and the risk may be different. This leads to irreducible\nerrors that do not converge to the weighted Bayes risk, which motivates our\nconsideration of robust risks. We define a robust risk that minimizes risk over\na set of weightings and show excess risk bounds for this problem. Finally, we\nshow that particular choices of the weighting set leads to a special instance\nof conditional value at risk (CVaR) from stochastic programming, which we call\nlabel conditional value at risk (LCVaR). Additionally, we generalize this\nweighting to derive a new robust risk problem that we call label heterogeneous\nconditional value at risk (LHCVaR). Finally, we empirically demonstrate the\nefficacy of LCVaR and LHCVaR on improving class conditional risks.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:45:13 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Xu", "Ziyu", ""], ["Dan", "Chen", ""], ["Khim", "Justin", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "2005.12964", "submitter": "Jianxin Ma", "authors": "Chang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, Hongxia Yang", "title": "Contrastive Learning for Debiased Candidate Generation in Large-Scale\n  Recommender Systems", "comments": "Accepted by the 27th ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining (KDD 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep candidate generation (DCG) that narrows down the collection of relevant\nitems from billions to hundreds via representation learning has become\nprevalent in industrial recommender systems. Standard approaches approximate\nmaximum likelihood estimation (MLE) through sampling for better scalability and\naddress the problem of DCG in a way similar to language modeling. However, live\nrecommender systems face severe exposure bias and have a vocabulary several\norders of magnitude larger than that of natural language, implying that MLE\nwill preserve and even exacerbate the exposure bias in the long run in order to\nfaithfully fit the observed samples. In this paper, we theoretically prove that\na popular choice of contrastive loss is equivalent to reducing the exposure\nbias via inverse propensity weighting, which provides a new perspective for\nunderstanding the effectiveness of contrastive learning. Based on the\ntheoretical discovery, we design CLRec, a contrastive learning method to\nimprove DCG in terms of fairness, effectiveness and efficiency in recommender\nsystems with extremely large candidate size. We further improve upon CLRec and\npropose Multi-CLRec, for accurate multi-intention aware bias reduction. Our\nmethods have been successfully deployed in Taobao, where at least four-month\nonline A/B tests and offline analyses demonstrate its substantial improvements,\nincluding a dramatic reduction in the Matthew effect.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:15:23 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 17:46:41 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 09:21:25 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 17:15:04 GMT"}, {"version": "v5", "created": "Wed, 10 Jun 2020 14:32:52 GMT"}, {"version": "v6", "created": "Thu, 11 Jun 2020 12:29:48 GMT"}, {"version": "v7", "created": "Thu, 18 Feb 2021 07:41:38 GMT"}, {"version": "v8", "created": "Wed, 19 May 2021 08:14:17 GMT"}, {"version": "v9", "created": "Fri, 4 Jun 2021 16:34:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhou", "Chang", ""], ["Ma", "Jianxin", ""], ["Zhang", "Jianwei", ""], ["Zhou", "Jingren", ""], ["Yang", "Hongxia", ""]]}, {"id": "2005.12968", "submitter": "Benjamin Lansdell", "authors": "Benjamin Lansdell", "title": "Towards intervention-centric causal reasoning in learning agents", "comments": "11 page, 4 figures. Presented at ICLR 2020 workshop 'Causal learning\n  for decision making'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interventions are central to causal learning and reasoning. Yet ultimately an\nintervention is an abstraction: an agent embedded in a physical environment\n(perhaps modeled as a Markov decision process) does not typically come equipped\nwith the notion of an intervention -- its action space is typically\nego-centric, without actions of the form `intervene on X'. Such a\ncorrespondence between ego-centric actions and interventions would be\nchallenging to hard-code. It would instead be better if an agent learnt which\nsequence of actions allow it to make targeted manipulations of the environment,\nand learnt corresponding representations that permitted learning from\nobservation. Here we show how a meta-learning approach can be used to perform\ncausal learning in this challenging setting, where the action-space is not a\nset of interventions and the observation space is a high-dimensional space with\na latent causal structure. A meta-reinforcement learning algorithm is used to\nlearn relationships that transfer on observational causal learning tasks. This\nwork shows how advances in deep reinforcement learning and meta-learning can\nprovide intervention-centric causal learning in high-dimensional environments\nwith a latent causal structure.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 18:53:04 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Lansdell", "Benjamin", ""]]}, {"id": "2005.12971", "submitter": "Chuan-Ju Wang", "authors": "Chuan-Ju Wang, Yu-Neng Chuang, Chih-Ming Chen, and Ming-Feng Tsai", "title": "Skewness Ranking Optimization for Personalized Recommendation", "comments": "Accepted by UAI'20. The first two authors contributed equally to this\n  work; author order was determined by seniority", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel optimization criterion that leverages\nfeatures of the skew normal distribution to better model the problem of\npersonalized recommendation. Specifically, the developed criterion borrows the\nconcept and the flexibility of the skew normal distribution, based on which\nthree hyperparameters are attached to the optimization criterion. Furthermore,\nfrom a theoretical point of view, we not only establish the relation between\nthe maximization of the proposed criterion and the shape parameter in the skew\nnormal distribution, but also provide the analogies and asymptotic analysis of\nthe proposed criterion to maximization of the area under the ROC curve.\nExperimental results conducted on a range of large-scale real-world datasets\nshow that our model significantly outperforms the state of the art and yields\nconsistently best performance on all tested datasets.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 00:59:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wang", "Chuan-Ju", ""], ["Chuang", "Yu-Neng", ""], ["Chen", "Chih-Ming", ""], ["Tsai", "Ming-Feng", ""]]}, {"id": "2005.12974", "submitter": "Nasim Sonboli", "authors": "Nasim Sonboli, Farzad Eskandanian, Robin Burke, Weiwen Liu, Bamshad\n  Mobasher", "title": "Opportunistic Multi-aspect Fairness through Personalized Re-ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As recommender systems have become more widespread and moved into areas with\ngreater social impact, such as employment and housing, researchers have begun\nto seek ways to ensure fairness in the results that such systems produce. This\nwork has primarily focused on developing recommendation approaches in which\nfairness metrics are jointly optimized along with recommendation accuracy.\nHowever, the previous work had largely ignored how individual preferences may\nlimit the ability of an algorithm to produce fair recommendations. Furthermore,\nwith few exceptions, researchers have only considered scenarios in which\nfairness is measured relative to a single sensitive feature or attribute (such\nas race or gender). In this paper, we present a re-ranking approach to\nfairness-aware recommendation that learns individual preferences across\nmultiple fairness dimensions and uses them to enhance provider fairness in\nrecommendation results. Specifically, we show that our opportunistic and\nmetric-agnostic approach achieves a better trade-off between accuracy and\nfairness than prior re-ranking approaches and does so across multiple fairness\ndimensions.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 04:25:20 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Sonboli", "Nasim", ""], ["Eskandanian", "Farzad", ""], ["Burke", "Robin", ""], ["Liu", "Weiwen", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "2005.12979", "submitter": "Shijun Li", "authors": "Shijun Li, Wenqiang Lei, Qingyun Wu, Xiangnan He, Peng Jiang, Tat-Seng\n  Chua", "title": "Seamlessly Unifying Attributes and Items: Conversational Recommendation\n  for Cold-Start Users", "comments": "TOIS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static recommendation methods like collaborative filtering suffer from the\ninherent limitation of performing real-time personalization for cold-start\nusers. Online recommendation, e.g., multi-armed bandit approach, addresses this\nlimitation by interactively exploring user preference online and pursuing the\nexploration-exploitation (EE) trade-off. However, existing bandit-based methods\nmodel recommendation actions homogeneously. Specifically, they only consider\nthe items as the arms, being incapable of handling the item attributes, which\nnaturally provide interpretable information of user's current demands and can\neffectively filter out undesired items. In this work, we consider the\nconversational recommendation for cold-start users, where a system can both ask\nthe attributes from and recommend items to a user interactively. This important\nscenario was studied in a recent work. However, it employs a hand-crafted\nfunction to decide when to ask attributes or make recommendations. Such\nseparate modeling of attributes and items makes the effectiveness of the system\nhighly rely on the choice of the hand-crafted function, thus introducing\nfragility to the system. To address this limitation, we seamlessly unify\nattributes and items in the same arm space and achieve their EE trade-offs\nautomatically using the framework of Thompson Sampling. Our Conversational\nThompson Sampling (ConTS) model holistically solves all questions in\nconversational recommendation by choosing the arm with the maximal reward to\nplay. Extensive experiments on three benchmark datasets show that ConTS\noutperforms the state-of-the-art methods Conversational UCB (ConUCB) and\nEstimation-Action-Reflection model in both metrics of success rate and average\nnumber of conversation turns.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 08:56:37 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 07:51:45 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 10:27:32 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 04:13:52 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Li", "Shijun", ""], ["Lei", "Wenqiang", ""], ["Wu", "Qingyun", ""], ["He", "Xiangnan", ""], ["Jiang", "Peng", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2005.12987", "submitter": "Alessio Benavoli", "authors": "Alessio Benavoli and Dario Azzimonti and Dario Piga", "title": "Skew Gaussian Processes for Classification", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are distributions over functions, which provide a\nBayesian nonparametric approach to regression and classification. In spite of\ntheir success, GPs have limited use in some applications, for example, in some\ncases a symmetric distribution with respect to its mean is an unreasonable\nmodel. This implies, for instance, that the mean and the median coincide, while\nthe mean and median in an asymmetric (skewed) distribution can be different\nnumbers. In this paper, we propose Skew-Gaussian processes (SkewGPs) as a\nnon-parametric prior over functions. A SkewGP extends the multivariate Unified\nSkew-Normal distribution over finite dimensional vectors to a stochastic\nprocesses. The SkewGP class of distributions includes GPs and, therefore,\nSkewGPs inherit all good properties of GPs and increase their flexibility by\nallowing asymmetry in the probabilistic model. By exploiting the fact that\nSkewGP and probit likelihood are conjugate model, we derive closed form\nexpressions for the marginal likelihood and predictive distribution of this new\nnonparametric classifier. We verify empirically that the proposed SkewGP\nclassifier provides a better performance than a GP classifier based on either\nLaplace's method or Expectation Propagation.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 19:13:03 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Benavoli", "Alessio", ""], ["Azzimonti", "Dario", ""], ["Piga", "Dario", ""]]}, {"id": "2005.12991", "submitter": "Dawid Rymarczyk", "authors": "Dawid Rymarczyk and Adriana Borowa and Jacek Tabor and Bartosz\n  Zieli\\'nski", "title": "Kernel Self-Attention in Deep Multiple Instance Learning", "comments": "https://openaccess.thecvf.com/content/WACV2021/papers/Rymarczyk_Kernel_Self-Attention_for_Weakly-Supervised_Image_Classification_Using_Deep_Multiple_Instance_WACV_2021_paper.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all supervised learning problems are described by a pair of a fixed-size\ninput tensor and a label. In some cases, especially in medical image analysis,\na label corresponds to a bag of instances (e.g. image patches), and to classify\nsuch bag, aggregation of information from all of the instances is needed. There\nhave been several attempts to create a model working with a bag of instances,\nhowever, they are assuming that there are no dependencies within the bag and\nthe label is connected to at least one instance. In this work, we introduce\nSelf-Attention Attention-based MIL Pooling (SA-AbMILP) aggregation operation to\naccount for the dependencies between instances. We conduct several experiments\non MNIST, histological, microbiological, and retinal databases to show that\nSA-AbMILP performs better than other models. Additionally, we investigate\nkernel variations of Self-Attention and their influence on the results.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:59:13 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 12:36:50 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Rymarczyk", "Dawid", ""], ["Borowa", "Adriana", ""], ["Tabor", "Jacek", ""], ["Zieli\u0144ski", "Bartosz", ""]]}, {"id": "2005.13012", "submitter": "Eduardo C\\'esar Garrido-Merch\\'an", "authors": "Santiago Gonz\\'alez-Carvajal and Eduardo C. Garrido-Merch\\'an", "title": "Comparing BERT against traditional machine learning text classification", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BERT model has arisen as a popular state-of-the-art machine learning\nmodel in the recent years that is able to cope with multiple NLP tasks such as\nsupervised text classification without human supervision. Its flexibility to\ncope with any type of corpus delivering great results has make this approach\nvery popular not only in academia but also in the industry. Although, there are\nlots of different approaches that have been used throughout the years with\nsuccess. In this work, we first present BERT and include a little review on\nclassical NLP approaches. Then, we empirically test with a suite of experiments\ndealing different scenarios the behaviour of BERT against the traditional\nTF-IDF vocabulary fed to machine learning algorithms. Our purpose of this work\nis to add empirical evidence to support or refuse the use of BERT as a default\non NLP tasks. Experiments show the superiority of BERT and its independence of\nfeatures of the NLP problem such as the language of the text adding empirical\nevidence to use BERT as a default technique to be used in NLP problems.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 20:14:39 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 15:48:52 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Gonz\u00e1lez-Carvajal", "Santiago", ""], ["Garrido-Merch\u00e1n", "Eduardo C.", ""]]}, {"id": "2005.13028", "submitter": "David K.E. Green", "authors": "David K. E. Green and Filip Rindler", "title": "Probabilistic solution of chaotic dynamical system inverse problems\n  using Bayesian Artificial Neural Networks", "comments": "36 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the application of Bayesian Artificial Neural\nNetworks to Ordinary Differential Equation (ODE) inverse problems. We consider\nthe case of estimating an unknown chaotic dynamical system transition model\nfrom state observation data. Inverse problems for chaotic systems are\nnumerically challenging as small perturbations in model parameters can cause\nvery large changes in estimated forward trajectories. Bayesian Artificial\nNeural Networks can be used to simultaneously fit a model and estimate model\nparameter uncertainty. Knowledge of model parameter uncertainty can then be\nincorporated into the probabilistic estimates of the inferred system's forward\ntime evolution. The method is demonstrated numerically by analysing the chaotic\nSprott B system. Observations of the system are used to estimate a posterior\npredictive distribution over the weights of a parametric polynomial kernel\nArtificial Neural Network. It is shown that the proposed method is able to\nperform accurate time predictions. Further, the proposed method is able to\ncorrectly account for model uncertainties and provide useful prediction\nuncertainty bounds.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 20:35:02 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Green", "David K. E.", ""], ["Rindler", "Filip", ""]]}, {"id": "2005.13037", "submitter": "Naveen Sai Madiraju", "authors": "Naveen Madiraju, Homa Karimabadi", "title": "Instance Explainable Temporal Network For Multivariate Timeseries", "comments": "7 pages, 7 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep networks have been widely adopted, one of their shortcomings\nhas been their blackbox nature. One particularly difficult problem in machine\nlearning is multivariate time series (MVTS) classification. MVTS data arise in\nmany applications and are becoming ever more pervasive due to explosive growth\nof sensors and IoT devices. Here, we propose a novel network (IETNet) that\nidentifies the important channels in the classification decision for each\ninstance of inference. This feature also enables identification and removal of\nnon-predictive variables which would otherwise lead to overfit and/or\ninaccurate model. IETNet is an end-to-end network that combines temporal\nfeature extraction, variable selection, and joint variable interaction into a\nsingle learning framework. IETNet utilizes an 1D convolutions for temporal\nfeatures, a novel channel gate layer for variable-class assignment using an\nattention layer to perform cross channel reasoning and perform classification\nobjective. To gain insight into the learned temporal features and channels, we\nextract region of interest attention map along both time and channels. The\nviability of this network is demonstrated through a multivariate time series\ndata from N body simulations and spacecraft sensor data.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 20:55:24 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 22:56:10 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Madiraju", "Naveen", ""], ["Karimabadi", "Homa", ""]]}, {"id": "2005.13040", "submitter": "Rylan Perumal", "authors": "Rylan Perumal and Terence L van Zyl", "title": "Comparison of Recurrent Neural Network Architectures for Wildfire Spread\n  Modelling", "comments": null, "journal-ref": "2020 International SAUPEC/RobMech/PRASA Conference, Cape Town,\n  South Africa, 2020, pp. 1-6", "doi": "10.1109/SAUPEC/RobMech/PRASA48453.2020.9078028", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wildfire modelling is an attempt to reproduce fire behaviour. Through active\nfire analysis, it is possible to reproduce a dynamical process, such as\nwildfires, with limited duration time series data. Recurrent neural networks\n(RNNs) can model dynamic temporal behaviour due to their ability to remember\ntheir internal input. In this paper, we compare the Gated Recurrent Unit (GRU)\nand the Long Short-Term Memory (LSTM) network. We try to determine whether a\nwildfire continues to burn and given that it does, we aim to predict which one\nof the 8 cardinal directions the wildfire will spread in. Overall the GRU\nperforms better for longer time series than the LSTM. We have shown that\nalthough we are reasonable at predicting the direction in which the wildfire\nwill spread, we are not able to asses if the wildfire continues to burn due to\nthe lack of auxiliary data.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 20:58:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Perumal", "Rylan", ""], ["van Zyl", "Terence L", ""]]}, {"id": "2005.13078", "submitter": "Sakshi Arya", "authors": "Sakshi Arya and Yuhong Yang", "title": "To update or not to update? Delayed Nonparametric Bandits with\n  Randomized Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delayed rewards problem in contextual bandits has been of interest in various\npractical settings. We study randomized allocation strategies and provide an\nunderstanding on how the exploration-exploitation tradeoff is affected by\ndelays in observing the rewards. In randomized strategies, the extent of\nexploration-exploitation is controlled by a user-determined exploration\nprobability sequence. In the presence of delayed rewards, one may choose\nbetween using the original exploration sequence that updates at every time\npoint or update the sequence only when a new reward is observed, leading to two\ncompeting strategies. In this work, we show that while both strategies may lead\nto strong consistency in allocation, the property holds for a wider scope of\nsituations for the latter. However, for finite sample performance, we\nillustrate that both strategies have their own advantages and disadvantages,\ndepending on the severity of the delay and underlying reward generating\nmechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 23:06:20 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Arya", "Sakshi", ""], ["Yang", "Yuhong", ""]]}, {"id": "2005.13092", "submitter": "Aditya Rawal", "authors": "Aditya Rawal, Joel Lehman, Felipe Petroski Such, Jeff Clune, Kenneth\n  O. Stanley", "title": "Synthetic Petri Dish: A Novel Surrogate Model for Rapid Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) explores a large space of architectural\nmotifs -- a compute-intensive process that often involves ground-truth\nevaluation of each motif by instantiating it within a large network, and\ntraining and evaluating the network with thousands of domain-specific data\nsamples. Inspired by how biological motifs such as cells are sometimes\nextracted from their natural environment and studied in an artificial Petri\ndish setting, this paper proposes the Synthetic Petri Dish model for evaluating\narchitectural motifs. In the Synthetic Petri Dish, architectural motifs are\ninstantiated in very small networks and evaluated using very few learned\nsynthetic data samples (to effectively approximate performance in the full\nproblem). The relative performance of motifs in the Synthetic Petri Dish can\nsubstitute for their ground-truth performance, thus accelerating the most\nexpensive step of NAS. Unlike other neural network-based prediction models that\nparse the structure of the motif to estimate its performance, the Synthetic\nPetri Dish predicts motif performance by training the actual motif in an\nartificial setting, thus deriving predictions from its true intrinsic\nproperties. Experiments in this paper demonstrate that the Synthetic Petri Dish\ncan therefore predict the performance of new motifs with significantly higher\naccuracy, especially when insufficient ground truth data is available. Our hope\nis that this work can inspire a new research direction in studying the\nperformance of extracted components of models in an alternative controlled\nsetting.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:12:06 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Rawal", "Aditya", ""], ["Lehman", "Joel", ""], ["Such", "Felipe Petroski", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "2005.13097", "submitter": "Rasa Hosseinzadeh", "authors": "Murat A. Erdogdu, Rasa Hosseinzadeh", "title": "On the Convergence of Langevin Monte Carlo: The Interplay between Tail\n  Growth and Smoothness", "comments": "51 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sampling from a target distribution ${\\nu_* = e^{-f}}$ using the\nunadjusted Langevin Monte Carlo (LMC) algorithm. For any potential function $f$\nwhose tails behave like ${\\|x\\|^\\alpha}$ for ${\\alpha \\in [1,2]}$, and has\n$\\beta$-H\\\"older continuous gradient, we prove that ${\\widetilde{\\mathcal{O}}\n\\Big(d^{\\frac{1}{\\beta}+\\frac{1+\\beta}{\\beta}(\\frac{2}{\\alpha} -\n\\boldsymbol{1}_{\\{\\alpha \\neq 1\\}})} \\epsilon^{-\\frac{1}{\\beta}}\\Big)}$ steps\nare sufficient to reach the $\\epsilon $-neighborhood of a $d$-dimensional\ntarget distribution $\\nu_*$ in KL-divergence. This convergence rate, in terms\nof $\\epsilon$ dependency, is not directly influenced by the tail growth rate\n$\\alpha$ of the potential function as long as its growth is at least linear,\nand it only relies on the order of smoothness $\\beta$. One notable consequence\nof this result is that for potentials with Lipschitz gradient, i.e. $\\beta=1$,\nour rate recovers the best known rate\n${\\widetilde{\\mathcal{O}}(d\\epsilon^{-1})}$ which was established for strongly\nconvex potentials in terms of $\\epsilon$ dependency, but we show that the same\nrate is achievable for a wider class of potentials that are degenerately convex\nat infinity. The growth rate $\\alpha$ starts to have an effect on the\nestablished rate in high dimensions where $d$ is large; furthermore, it\nrecovers the best-known dimension dependency when the tail growth of the\npotential is quadratic, i.e. ${\\alpha = 2}$, in the current setup. Our\nframework allows for finite perturbations, and any order of smoothness\n${\\beta\\in(0,1]}$; consequently, our results are applicable to a wide class of\nnon-convex potentials that are weakly smooth and exhibit at least linear tail\ngrowth.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:26:20 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Erdogdu", "Murat A.", ""], ["Hosseinzadeh", "Rasa", ""]]}, {"id": "2005.13099", "submitter": "Sahib Singh", "authors": "Sahib Singh, Harshvardhan Sikka, Sasikanth Kotti, Andrew Trask", "title": "Benchmarking Differentially Private Residual Networks for Medical\n  Imagery", "comments": "5 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we measure the effectiveness of $\\epsilon$-Differential Privacy\n(DP) when applied to medical imaging. We compare two robust differential\nprivacy mechanisms: Local-DP and DP-SGD and benchmark their performance when\nanalyzing medical imagery records. We analyze the trade-off between the model's\naccuracy and the level of privacy it guarantees, and also take a closer look to\nevaluate how useful these theoretical privacy guarantees actually prove to be\nin the real world medical setting.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:29:56 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 09:47:09 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 03:15:27 GMT"}, {"version": "v4", "created": "Sun, 19 Jul 2020 03:27:18 GMT"}, {"version": "v5", "created": "Sat, 5 Sep 2020 02:25:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Singh", "Sahib", ""], ["Sikka", "Harshvardhan", ""], ["Kotti", "Sasikanth", ""], ["Trask", "Andrew", ""]]}, {"id": "2005.13100", "submitter": "Marieme Ngom", "authors": "Marieme Ngom and Oana Marin", "title": "Fourier Neural Networks as Function Approximators and Differential\n  Equation Solvers", "comments": "22 pages, 10 figures Added figures to explain the initialization\n  strategy, fixed typos, updated abstract and modified title to make it more\n  self explanatory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Fourier neural network (FNN) that can be mapped directly to the\nFourier decomposition. The choice of activation and loss function yields\nresults that replicate a Fourier series expansion closely while preserving a\nstraightforward architecture with a single hidden layer. The simplicity of this\nnetwork architecture facilitates the integration with any other\nhigher-complexity networks, at a data pre- or postprocessing stage. We validate\nthis FNN on naturally periodic smooth functions and on piecewise continuous\nperiodic functions. We showcase the use of this FNN for modeling or solving\npartial differential equations with periodic boundary conditions. The main\nadvantages of the current approach are the validity of the solution outside the\ntraining region, interpretability of the trained model, and simplicity of use.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:30:58 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 19:56:18 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Ngom", "Marieme", ""], ["Marin", "Oana", ""]]}, {"id": "2005.13102", "submitter": "Bangalore Ravi Kiran", "authors": "Leonardo Gigli, B Ravi Kiran, Thomas Paul, Andres Serna, Nagarjuna\n  Vemuri, Beatriz Marcotegui, Santiago Velasco-Forero", "title": "Road Segmentation on low resolution Lidar point clouds for autonomous\n  vehicles", "comments": "ISPRS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point cloud datasets for perception tasks in the context of autonomous\ndriving often rely on high resolution 64-layer Light Detection and Ranging\n(LIDAR) scanners. They are expensive to deploy on real-world autonomous driving\nsensor architectures which usually employ 16/32 layer LIDARs. We evaluate the\neffect of subsampling image based representations of dense point clouds on the\naccuracy of the road segmentation task. In our experiments the low resolution\n16/32 layer LIDAR point clouds are simulated by subsampling the original 64\nlayer data, for subsequent transformation in to a feature map in the\nBird-Eye-View (BEV) and SphericalView (SV) representations of the point cloud.\nWe introduce the usage of the local normal vector with the LIDAR's spherical\ncoordinates as an input channel to existing LoDNN architectures. We demonstrate\nthat this local normal feature in conjunction with classical features not only\nimproves performance for binary road segmentation on full resolution point\nclouds, but it also reduces the negative impact on the accuracy when\nsubsampling dense point clouds as compared to the usage of classical features\nalone. We assess our method with several experiments on two datasets: KITTI\nRoad-segmentation benchmark and the recently released Semantic KITTI dataset.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:38:39 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Gigli", "Leonardo", ""], ["Kiran", "B Ravi", ""], ["Paul", "Thomas", ""], ["Serna", "Andres", ""], ["Vemuri", "Nagarjuna", ""], ["Marcotegui", "Beatriz", ""], ["Velasco-Forero", "Santiago", ""]]}, {"id": "2005.13107", "submitter": "Zichao Wang", "authors": "Zichao Wang, Yi Gu, Andrew Lan, Richard Baraniuk", "title": "VarFA: A Variational Factor Analysis Framework For Efficient Bayesian\n  Learning Analytics", "comments": "edm 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose VarFA, a variational inference factor analysis framework that\nextends existing factor analysis models for educational data mining to\nefficiently output uncertainty estimation in the model's estimated factors.\nSuch uncertainty information is useful, for example, for an adaptive testing\nscenario, where additional tests can be administered if the model is not quite\ncertain about a students' skill level estimation. Traditional Bayesian\ninference methods that produce such uncertainty information are computationally\nexpensive and do not scale to large data sets. VarFA utilizes variational\ninference which makes it possible to efficiently perform Bayesian inference\neven on very large data sets. We use the sparse factor analysis model as a case\nstudy and demonstrate the efficacy of VarFA on both synthetic and real data\nsets. VarFA is also very general and can be applied to a wide array of factor\nanalysis models.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:03:07 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 20:46:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Zichao", ""], ["Gu", "Yi", ""], ["Lan", "Andrew", ""], ["Baraniuk", "Richard", ""]]}, {"id": "2005.13111", "submitter": "Lili Yu", "authors": "Kyle Swanson, Lili Yu, Tao Lei", "title": "Rationalizing Text Matching: Learning Sparse Alignments via Optimal\n  Transport", "comments": "To appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Selecting input features of top relevance has become a popular method for\nbuilding self-explaining models. In this work, we extend this selective\nrationalization approach to text matching, where the goal is to jointly select\nand align text pieces, such as tokens or sentences, as a justification for the\ndownstream prediction. Our approach employs optimal transport (OT) to find a\nminimal cost alignment between the inputs. However, directly applying OT often\nproduces dense and therefore uninterpretable alignments. To overcome this\nlimitation, we introduce novel constrained variants of the OT problem that\nresult in highly sparse alignments with controllable sparsity. Our model is\nend-to-end differentiable using the Sinkhorn algorithm for OT and can be\ntrained without any alignment annotations. We evaluate our model on the\nStackExchange, MultiNews, e-SNLI, and MultiRC datasets. Our model achieves very\nsparse rationale selections with high fidelity while preserving prediction\naccuracy compared to strong attention baseline models.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:20:49 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Swanson", "Kyle", ""], ["Yu", "Lili", ""], ["Lei", "Tao", ""]]}, {"id": "2005.13120", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew, Hanseok Ko", "title": "Data Separability for Neural Network Classifiers and the Development of\n  a Separability Index", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, the performance of a classifier depends on both the\nclassifier model and the dataset. For a specific neural network classifier, the\ntraining process varies with the training set used; some training data make\ntraining accuracy fast converged to high values, while some data may lead to\nslowly converged to lower accuracy. To quantify this phenomenon, we created the\nDistance-based Separability Index (DSI), which is independent of the classifier\nmodel, to measure the separability of datasets. In this paper, we consider the\nsituation where different classes of data are mixed together in the same\ndistribution is most difficult for classifiers to separate, and we show that\nthe DSI can indicate whether data belonging to different classes have similar\ndistributions. When comparing our proposed approach with several existing\nseparability/complexity measures using synthetic and real datasets, the results\nshow the DSI is an effective separability measure. We also discussed possible\napplications of the DSI in the fields of data science, machine learning, and\ndeep learning.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:49:19 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 03:23:17 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""], ["Ko", "Hanseok", ""]]}, {"id": "2005.13149", "submitter": "Mike Wu", "authors": "Mike Wu, Chengxu Zhuang, Milan Mosse, Daniel Yamins, Noah Goodman", "title": "On Mutual Information in Contrastive Learning for Visual Representations", "comments": "8 pages content; 15 pages supplement with proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several unsupervised, \"contrastive\" learning algorithms in\nvision have been shown to learn representations that perform remarkably well on\ntransfer tasks. We show that this family of algorithms maximizes a lower bound\non the mutual information between two or more \"views\" of an image where typical\nviews come from a composition of image augmentations. Our bound generalizes the\nInfoNCE objective to support negative sampling from a restricted region of\n\"difficult\" contrasts. We find that the choice of negative samples and views\nare critical to the success of these algorithms. Reformulating previous\nlearning objectives in terms of mutual information also simplifies and\nstabilizes them. In practice, our new objectives yield representations that\noutperform those learned with previous approaches for transfer to\nclassification, bounding box detection, instance segmentation, and keypoint\ndetection. % experiments show that choosing more difficult negative samples\nresults in a stronger representation, outperforming those learned with IR, LA,\nand CMC in classification, bounding box detection, instance segmentation, and\nkeypoint detection. The mutual information framework provides a unifying\ncomparison of approaches to contrastive learning and uncovers the choices that\nimpact representation learning.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 04:21:53 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 16:39:20 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Wu", "Mike", ""], ["Zhuang", "Chengxu", ""], ["Mosse", "Milan", ""], ["Yamins", "Daniel", ""], ["Goodman", "Noah", ""]]}, {"id": "2005.13166", "submitter": "Koorosh Aslansefat", "authors": "Koorosh Aslansefat, Ioannis Sorokos, Declan Whiting, Ramin Tavakoli\n  Kolagari, Yiannis Papadopoulos", "title": "SafeML: Safety Monitoring of Machine Learning Classifiers through\n  Statistical Difference Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ensuring safety and explainability of machine learning (ML) is a topic of\nincreasing relevance as data-driven applications venture into safety-critical\napplication domains, traditionally committed to high safety standards that are\nnot satisfied with an exclusive testing approach of otherwise inaccessible\nblack-box systems. Especially the interaction between safety and security is a\ncentral challenge, as security violations can lead to compromised safety. The\ncontribution of this paper to addressing both safety and security within a\nsingle concept of protection applicable during the operation of ML systems is\nactive monitoring of the behaviour and the operational context of the\ndata-driven system based on distance measures of the Empirical Cumulative\nDistribution Function (ECDF). We investigate abstract datasets (XOR, Spiral,\nCircle) and current security-specific datasets for intrusion detection\n(CICIDS2017) of simulated network traffic, using distributional shift detection\nmeasures including the Kolmogorov-Smirnov, Kuiper, Anderson-Darling,\nWasserstein and mixed Wasserstein-Anderson-Darling measures. Our preliminary\nfindings indicate that the approach can provide a basis for detecting whether\nthe application context of an ML component is valid in the safety-security. Our\npreliminary code and results are available at\nhttps://github.com/ISorokos/SafeML.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 05:27:38 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Aslansefat", "Koorosh", ""], ["Sorokos", "Ioannis", ""], ["Whiting", "Declan", ""], ["Kolagari", "Ramin Tavakoli", ""], ["Papadopoulos", "Yiannis", ""]]}, {"id": "2005.13171", "submitter": "Yu Wang", "authors": "Yu Wang, JunPeng Bao, JianQiang Du, YongFeng Li", "title": "Precisely Predicting Acute Kidney Injury with Convolutional Neural\n  Network Based on Electronic Health Record Data", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incidence of Acute Kidney Injury (AKI) commonly happens in the Intensive\nCare Unit (ICU) patients, especially in the adults, which is an independent\nrisk factor affecting short-term and long-term mortality. Though researchers in\nrecent years highlight the early prediction of AKI, the performance of existing\nmodels are not precise enough. The objective of this research is to precisely\npredict AKI by means of Convolutional Neural Network on Electronic Health\nRecord (EHR) data. The data sets used in this research are two public\nElectronic Health Record (EHR) databases: MIMIC-III and eICU database. In this\nstudy, we take several Convolutional Neural Network models to train and test\nour AKI predictor, which can precisely predict whether a certain patient will\nsuffer from AKI after admission in ICU according to the last measurements of\nthe 16 blood gas and demographic features. The research is based on Kidney\nDisease Improving Global Outcomes (KDIGO) criteria for AKI definition. Our work\ngreatly improves the AKI prediction precision, and the best AUROC is up to\n0.988 on MIMIC-III data set and 0.936 on eICU data set, both of which\noutperform the state-of-art predictors. And the dimension of the input vector\nused in this predictor is much fewer than that used in other existing\nresearches. Compared with the existing AKI predictors, the predictor in this\nwork greatly improves the precision of early prediction of AKI by using the\nConvolutional Neural Network architecture and a more concise input vector.\nEarly and precise prediction of AKI will bring much benefit to the decision of\ntreatment, so it is believed that our work is a very helpful clinical\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 05:39:42 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wang", "Yu", ""], ["Bao", "JunPeng", ""], ["Du", "JianQiang", ""], ["Li", "YongFeng", ""]]}, {"id": "2005.13183", "submitter": "Yaming Yang", "authors": "Yaming Yang, Ziyu Guan, Jianxin Li, Wei Zhao, Jiangtao Cui, Quan Wang", "title": "Interpretable and Efficient Heterogeneous Graph Convolutional Network", "comments": "This paper has been submitted to IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Network (GCN) has achieved extraordinary success in\nlearning effective task-specific representations of nodes in graphs. However,\nregarding Heterogeneous Information Network (HIN), existing HIN-oriented GCN\nmethods still suffer from two deficiencies: (1) they cannot flexibly explore\nall possible meta-paths and extract the most useful ones for a target object,\nwhich hinders both effectiveness and interpretability; (2) they often need to\ngenerate intermediate meta-path based dense graphs, which leads to high\ncomputational complexity. To address the above issues, we propose an\ninterpretable and efficient Heterogeneous Graph Convolutional Network (ie-HGCN)\nto learn the representations of objects in HINs. It is designed as a\nhierarchical aggregation architecture, i.e., object-level aggregation first,\nfollowed by type-level aggregation. The novel architecture can automatically\nextract useful meta-paths for each object from all possible meta-paths (within\na length limit), which brings good model interpretability. It can also reduce\nthe computational cost by avoiding intermediate HIN transformation and\nneighborhood attention. We provide theoretical analysis about the proposed\nie-HGCN in terms of evaluating the usefulness of all possible meta-paths, its\nconnection to the spectral graph convolution on HINs, and its quasi-linear time\ncomplexity. Extensive experiments on three real network datasets demonstrate\nthe superiority of ie-HGCN over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 06:06:00 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 03:15:13 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Yang", "Yaming", ""], ["Guan", "Ziyu", ""], ["Li", "Jianxin", ""], ["Zhao", "Wei", ""], ["Cui", "Jiangtao", ""], ["Wang", "Quan", ""]]}, {"id": "2005.13191", "submitter": "Paulito Palmes", "authors": "Paulito Palmes, Joern Ploennigs, Niall Brady", "title": "TSML (Time Series Machine Learnng)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Over the past years, the industrial sector has seen many innovations brought\nabout by automation. Inherent in this automation is the installation of sensor\nnetworks for status monitoring and data collection. One of the major challenges\nin these data-rich environments is how to extract and exploit information from\nthese large volume of data to detect anomalies, discover patterns to reduce\ndowntimes and manufacturing errors, reduce energy usage, predict\nfaults/failures, effective maintenance schedules, etc. To address these issues,\nwe developed TSML. Its technology is based on using the pipeline of lightweight\nfilters as building blocks to process huge amount of industrial time series\ndata in parallel.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 06:37:49 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Palmes", "Paulito", ""], ["Ploennigs", "Joern", ""], ["Brady", "Niall", ""]]}, {"id": "2005.13231", "submitter": "Boumediene Hamzi", "authors": "Stefan Klus, Feliks N\\\"uske, Boumediene Hamzi", "title": "Kernel-based approximation of the Koopman generator and Schr\\\"odinger\n  operator", "comments": null, "journal-ref": null, "doi": "10.3390/e22070722", "report-no": null, "categories": "math.DS cs.NA math-ph math.MP math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many dimensionality and model reduction techniques rely on estimating\ndominant eigenfunctions of associated dynamical operators from data. Important\nexamples include the Koopman operator and its generator, but also the\nSchr\\\"odinger operator. We propose a kernel-based method for the approximation\nof differential operators in reproducing kernel Hilbert spaces and show how\neigenfunctions can be estimated by solving auxiliary matrix eigenvalue\nproblems. The resulting algorithms are applied to molecular dynamics and\nquantum chemistry examples. Furthermore, we exploit that, under certain\nconditions, the Schr\\\"odinger operator can be transformed into a Kolmogorov\nbackward operator corresponding to a drift-diffusion process and vice versa.\nThis allows us to apply methods developed for the analysis of high-dimensional\nstochastic differential equations to quantum mechanical systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:23:29 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 10:09:25 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 18:23:49 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Klus", "Stefan", ""], ["N\u00fcske", "Feliks", ""], ["Hamzi", "Boumediene", ""]]}, {"id": "2005.13232", "submitter": "Alireza Doostan", "authors": "Alexandre Cortiella, Kwang-Chun Park, and Alireza Doostan", "title": "Sparse Identification of Nonlinear Dynamical Systems via Reweighted\n  $\\ell_1$-regularized Least Squares", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113620", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an iterative sparse-regularized regression method to\nrecover governing equations of nonlinear dynamical systems from noisy state\nmeasurements. The method is inspired by the Sparse Identification of Nonlinear\nDynamics (SINDy) approach of {\\it [Brunton et al., PNAS, 113 (15) (2016)\n3932-3937]}, which relies on two main assumptions: the state variables are\nknown {\\it a priori} and the governing equations lend themselves to sparse,\nlinear expansions in a (nonlinear) basis of the state variables. The aim of\nthis work is to improve the accuracy and robustness of SINDy in the presence of\nstate measurement noise. To this end, a reweighted $\\ell_1$-regularized least\nsquares solver is developed, wherein the regularization parameter is selected\nfrom the corner point of a Pareto curve. The idea behind using weighted\n$\\ell_1$-norm for regularization -- instead of the standard $\\ell_1$-norm -- is\nto better promote sparsity in the recovery of the governing equations and, in\nturn, mitigate the effect of noise in the state variables. We also present a\nmethod to recover single physical constraints from state measurements. Through\nseveral examples of well-known nonlinear dynamical systems, we demonstrate\nempirically the accuracy and robustness of the reweighted $\\ell_1$-regularized\nleast squares strategy with respect to state measurement noise, thus\nillustrating its viability for a wide range of potential applications.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:30:15 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Cortiella", "Alexandre", ""], ["Park", "Kwang-Chun", ""], ["Doostan", "Alireza", ""]]}, {"id": "2005.13239", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano Ermon, James Zou, Sergey\n  Levine, Chelsea Finn, Tengyu Ma", "title": "MOPO: Model-based Offline Policy Optimization", "comments": "NeurIPS 2020. First two authors contributed equally. Last two authors\n  advised equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning (RL) refers to the problem of learning\npolicies entirely from a large batch of previously collected data. This problem\nsetting offers the promise of utilizing such datasets to acquire policies\nwithout any costly or dangerous active exploration. However, it is also\nchallenging, due to the distributional shift between the offline training data\nand those states visited by the learned policy. Despite significant recent\nprogress, the most successful prior methods are model-free and constrain the\npolicy to the support of data, precluding generalization to unseen states. In\nthis paper, we first observe that an existing model-based RL algorithm already\nproduces significant gains in the offline setting compared to model-free\napproaches. However, standard model-based RL methods, designed for the online\nsetting, do not provide an explicit mechanism to avoid the offline setting's\ndistributional shift issue. Instead, we propose to modify the existing\nmodel-based RL methods by applying them with rewards artificially penalized by\nthe uncertainty of the dynamics. We theoretically show that the algorithm\nmaximizes a lower bound of the policy's return under the true MDP. We also\ncharacterize the trade-off between the gain and risk of leaving the support of\nthe batch data. Our algorithm, Model-based Offline Policy Optimization (MOPO),\noutperforms standard model-based RL algorithms and prior state-of-the-art\nmodel-free offline RL algorithms on existing offline RL benchmarks and two\nchallenging continuous control tasks that require generalizing from data\ncollected for a different task. The code is available at\nhttps://github.com/tianheyu927/mopo.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:46:41 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 06:01:54 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 23:25:56 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 07:08:58 GMT"}, {"version": "v5", "created": "Tue, 29 Sep 2020 23:49:26 GMT"}, {"version": "v6", "created": "Sun, 22 Nov 2020 07:04:17 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yu", "Tianhe", ""], ["Thomas", "Garrett", ""], ["Yu", "Lantao", ""], ["Ermon", "Stefano", ""], ["Zou", "James", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""], ["Ma", "Tengyu", ""]]}, {"id": "2005.13245", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "On the Monotonicity of a Nondifferentially Mismeasured Binary Confounder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we are interested in the average causal effect of a binary\ntreatment on an outcome when this relationship is confounded by a binary\nconfounder. Suppose that the confounder is unobserved but a nondifferential\nproxy of it is observed. We show that, under certain monotonicity assumption\nthat is empirically verifiable, adjusting for the proxy produces a measure of\nthe effect that is between the unadjusted and the true measures.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 09:07:07 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 07:35:40 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 12:07:23 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 08:48:17 GMT"}, {"version": "v5", "created": "Fri, 3 Jul 2020 09:39:26 GMT"}, {"version": "v6", "created": "Sun, 2 Aug 2020 20:24:29 GMT"}, {"version": "v7", "created": "Tue, 4 Aug 2020 14:07:42 GMT"}, {"version": "v8", "created": "Fri, 14 Aug 2020 18:38:40 GMT"}, {"version": "v9", "created": "Sun, 23 Aug 2020 07:45:49 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "2005.13249", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and\n  Patients", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The healthcare industry generates troves of unlabelled physiological data.\nThis data can be exploited via contrastive learning, a self-supervised\npre-training method that encourages representations of instances to be similar\nto one another. We propose a family of contrastive learning methods, CLOCS,\nthat encourages representations across space, time, \\textit{and} patients to be\nsimilar to one another. We show that CLOCS consistently outperforms the\nstate-of-the-art methods, BYOL and SimCLR, when performing a linear evaluation\nof, and fine-tuning on, downstream tasks. We also show that CLOCS achieves\nstrong generalization performance with only 25\\% of labelled training data.\nFurthermore, our training procedure naturally generates patient-specific\nrepresentations that can be used to quantify patient-similarity.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 09:25:41 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 17:46:42 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 13:12:14 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2005.13273", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Taiji Suzuki", "title": "Selective Inference for Latent Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection in latent block models has been a challenging but important\ntask in the field of statistics. Specifically, a major challenge is encountered\nwhen constructing a test on a block structure obtained by applying a specific\nclustering algorithm to a finite size matrix. In this case, it becomes crucial\nto consider the selective bias in the block structure, that is, the block\nstructure is selected from all the possible cluster memberships based on some\ncriterion by the clustering algorithm. To cope with this problem, this study\nprovides a selective inference method for latent block models. Specifically, we\nconstruct a statistical test on a set of row and column cluster memberships of\na latent block model, which is given by a squared residue minimization\nalgorithm. The proposed test, by its nature, includes and thus can also be used\nas the test on the set of row and column cluster numbers. We also propose an\napproximated version of the test based on simulated annealing to avoid\ncombinatorial explosion in searching the optimal block structure. The results\nshow that the proposed exact and approximated tests work effectively, compared\nto the naive test that did not take the selective bias into account.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 10:44:19 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 06:05:44 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 05:51:07 GMT"}, {"version": "v4", "created": "Sat, 8 May 2021 05:19:36 GMT"}, {"version": "v5", "created": "Sun, 6 Jun 2021 04:38:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2005.13284", "submitter": "Pablo Jim\\'enez", "authors": "Alain Durmus, Pablo Jim\\'enez, \\'Eric Moulines, Salem Said, Hoi-To Wai", "title": "Convergence Analysis of Riemannian Stochastic Approximation Schemes", "comments": "41 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the convergence for a large class of Riemannian\nstochastic approximation (SA) schemes, which aim at tackling stochastic\noptimization problems. In particular, the recursions we study use either the\nexponential map of the considered manifold (geodesic schemes) or more general\nretraction functions (retraction schemes) used as a proxy for the exponential\nmap. Such approximations are of great interest since they are low complexity\nalternatives to geodesic schemes. Under the assumption that the mean field of\nthe SA is correlated with the gradient of a smooth Lyapunov function (possibly\nnon-convex), we show that the above Riemannian SA schemes find an\n${\\mathcal{O}}(b_\\infty + \\log n / \\sqrt{n})$-stationary point (in expectation)\nwithin ${\\mathcal{O}}(n)$ iterations, where $b_\\infty \\geq 0$ is the asymptotic\nbias. Compared to previous works, the conditions we derive are considerably\nmilder. First, all our analysis are global as we do not assume iterates to be\na-priori bounded. Second, we study biased SA schemes. To be more specific, we\nconsider the case where the mean-field function can only be estimated up to a\nsmall bias, and/or the case in which the samples are drawn from a controlled\nMarkov chain. Third, the conditions on retractions required to ensure\nconvergence of the related SA schemes are weak and hold for well-known\nexamples. We illustrate our results on three machine learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:24:58 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 10:05:10 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 14:25:42 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Durmus", "Alain", ""], ["Jim\u00e9nez", "Pablo", ""], ["Moulines", "\u00c9ric", ""], ["Said", "Salem", ""], ["Wai", "Hoi-To", ""]]}, {"id": "2005.13285", "submitter": "Jannis Born", "authors": "Jannis Born, Matteo Manica, Joris Cadow, Greta Markert, Nil Adell\n  Mill, Modestas Filipavicius, Mar\\'ia Rodr\\'iguez Mart\\'inez", "title": "PaccMann$^{RL}$ on SARS-CoV-2: Designing antiviral candidates with\n  conditional generative models", "comments": "5 pages, 6 figures", "journal-ref": "ICML Workshop on Computational Biology 2020", "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the fast development of COVID-19 into a global pandemic, scientists\naround the globe are desperately searching for effective antiviral therapeutic\nagents. Bridging systems biology and drug discovery, we propose a deep learning\nframework for conditional de novo design of antiviral candidate drugs tailored\nagainst given protein targets. First, we train a multimodal ligand--protein\nbinding affinity model on predicting affinities of antiviral compounds to\ntarget proteins and couple this model with pharmacological toxicity predictors.\nExploiting this multi-objective as a reward function of a conditional molecular\ngenerator (consisting of two VAEs), we showcase a framework that navigates the\nchemical space toward regions with more antiviral molecules. Specifically, we\nexplore a challenging setting of generating ligands against unseen protein\ntargets by performing a leave-one-out-cross-validation on 41 SARS-CoV-2-related\ntarget proteins. Using deep RL, it is demonstrated that in 35 out of 41 cases,\nthe generation is biased towards sampling more binding ligands, with an average\nincrease of 83% comparing to an unbiased VAE. We present a case-study on a\npotential Envelope-protein inhibitor and perform a synthetic accessibility\nassessment of the best generated molecules is performed that resembles a viable\nroadmap towards a rapid in-vitro evaluation of potential SARS-CoV-2 inhibitors.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:30:15 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 16:52:25 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 14:44:02 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Born", "Jannis", ""], ["Manica", "Matteo", ""], ["Cadow", "Joris", ""], ["Markert", "Greta", ""], ["Mill", "Nil Adell", ""], ["Filipavicius", "Modestas", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""]]}, {"id": "2005.13288", "submitter": "Jonas Wurst", "authors": "Jonas Wurst, Alberto Flores Fern\\'andez, Michael Botsch and Wolfgang\n  Utschick", "title": "An Entropy Based Outlier Score and its Application to Novelty Detection\n  for Road Infrastructure Images", "comments": "Copyright 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "2020 IEEE Intelligent Vehicles Symposium (IV)", "doi": "10.1109/IV47402.2020.9304733", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel unsupervised outlier score, which can be embedded into graph based\ndimensionality reduction techniques, is presented in this work. The score uses\nthe directed nearest neighbor graphs of those techniques. Hence, the same\nmeasure of similarity that is used to project the data into lower dimensions,\nis also utilized to determine the outlier score. The outlier score is realized\nthrough a weighted normalized entropy of the similarities. This score is\napplied to road infrastructure images. The aim is to identify newly observed\ninfrastructures given a pre-collected base dataset. Detecting unknown scenarios\nis a key for accelerated validation of autonomous vehicles. The results show\nthe high potential of the proposed technique. To validate the generalization\ncapabilities of the outlier score, it is additionally applied to various real\nworld datasets. The overall average performance in identifying outliers using\nthe proposed methods is higher compared to state-of-the-art methods. In order\nto generate the infrastructure images, an openDRIVE parsing and plotting tool\nfor Matlab is developed as part of this work. This tool and the implementation\nof the entropy based outlier score in combination with Uniform Manifold\nApproximation and Projection are made publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:34:42 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 08:40:47 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Wurst", "Jonas", ""], ["Fern\u00e1ndez", "Alberto Flores", ""], ["Botsch", "Michael", ""], ["Utschick", "Wolfgang", ""]]}, {"id": "2005.13291", "submitter": "Andrew Port", "authors": "Andrew Port, Chelhwon Kim, Mitesh Patel", "title": "Earballs: Neural Transmodal Translation", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As is expressed in the adage \"a picture is worth a thousand words\", when\nusing spoken language to communicate visual information, brevity can be a\nchallenge. This work describes a novel technique for leveraging machine learned\nfeature embeddings to translate visual (and other types of) information into a\nperceptual audio domain, allowing users to perceive this information using only\ntheir aural faculty. The system uses a pretrained image embedding network to\nextract visual features and embed them in a compact subset of Euclidean space\n-- this converts the images into feature vectors whose $L^2$ distances can be\nused as a meaningful measure of similarity. A generative adversarial network\n(GAN) is then used to find a distance preserving map from this metric space of\nfeature vectors into the metric space defined by a target audio dataset\nequipped with either the Euclidean metric or a mel-frequency cepstrum-based\npsychoacoustic distance metric. We demonstrate this technique by translating\nimages of faces into human speech-like audio. For both target audio metrics,\nthe GAN successfully found a metric preserving mapping, and in human subject\ntests, users were able to accurately classify audio translations of faces.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:41:48 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 20:48:18 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Port", "Andrew", ""], ["Kim", "Chelhwon", ""], ["Patel", "Mitesh", ""]]}, {"id": "2005.13293", "submitter": "Pascal Kerschke", "authors": "Moritz Seiler and Heike Trautmann and Pascal Kerschke", "title": "Enhancing Resilience of Deep Learning Networks by Means of Transferable\n  Adversaries", "comments": "This version has been accepted for publication at the International\n  Joint Conference on Neural Networks (IJCNN) 2020, which is part of the IEEE\n  World Congress on Computational Intelligence (IEEE WCCI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks in general and deep learning networks in\nparticular established themselves as popular and powerful machine learning\nalgorithms. While the often tremendous sizes of these networks are beneficial\nwhen solving complex tasks, the tremendous number of parameters also causes\nsuch networks to be vulnerable to malicious behavior such as adversarial\nperturbations. These perturbations can change a model's classification\ndecision. Moreover, while single-step adversaries can easily be transferred\nfrom network to network, the transfer of more powerful multi-step adversaries\nhas - usually -- been rather difficult. In this work, we introduce a method for\ngenerating strong ad-versaries that can easily (and frequently) be transferred\nbetween different models. This method is then used to generate a large set of\nadversaries, based on which the effects of selected defense methods are\nexperimentally assessed. At last, we introduce a novel, simple, yet effective\napproach to enhance the resilience of neural networks against adversaries and\nbenchmark it against established defense methods. In contrast to the already\nexisting methods, our proposed defense approach is much more efficient as it\nonly requires a single additional forward-pass to achieve comparable\nperformance results.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:52:42 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Seiler", "Moritz", ""], ["Trautmann", "Heike", ""], ["Kerschke", "Pascal", ""]]}, {"id": "2005.13300", "submitter": "Wonryong Ryou", "authors": "Wonryong Ryou, Jiayu Chen, Mislav Balunovic, Gagandeep Singh, Andrei\n  Dan, Martin Vechev", "title": "Scalable Polyhedral Verification of Recurrent Neural Networks", "comments": "Published in CAV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a scalable and precise verifier for recurrent neural networks,\ncalled Prover based on two novel ideas: (i) a method to compute a set of\npolyhedral abstractions for the non-convex and nonlinear recurrent update\nfunctions by combining sampling, optimization, and Fermat's theorem, and (ii) a\ngradient descent based algorithm for abstraction refinement guided by the\ncertification problem that combines multiple abstractions for each neuron.\nUsing Prover, we present the first study of certifying a non-trivial use case\nof recurrent neural networks, namely speech classification. To achieve this, we\nadditionally develop custom abstractions for the non-linear speech\npreprocessing pipeline. Our evaluation shows that Prover successfully verifies\nseveral challenging recurrent models in computer vision, speech, and motion\nsensor data classification beyond the reach of prior work.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:57:01 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 09:56:18 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 21:49:38 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ryou", "Wonryong", ""], ["Chen", "Jiayu", ""], ["Balunovic", "Mislav", ""], ["Singh", "Gagandeep", ""], ["Dan", "Andrei", ""], ["Vechev", "Martin", ""]]}, {"id": "2005.13303", "submitter": "Junqi Zhang", "authors": "Junqi Zhang, Bing Bai, Ye Lin, Jian Liang, Kun Bai, Fei Wang", "title": "General-Purpose User Embeddings based on Mobile App Usage", "comments": "To be published in the KDD2020 proceedings as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report our recent practice at Tencent for user modeling\nbased on mobile app usage. User behaviors on mobile app usage, including\nretention, installation, and uninstallation, can be a good indicator for both\nlong-term and short-term interests of users. For example, if a user installs\nSnapseed recently, she might have a growing interest in photographing. Such\ninformation is valuable for numerous downstream applications, including\nadvertising, recommendations, etc. Traditionally, user modeling from mobile app\nusage heavily relies on handcrafted feature engineering, which requires onerous\nhuman work for different downstream applications, and could be sub-optimal\nwithout domain experts. However, automatic user modeling based on mobile app\nusage faces unique challenges, including (1) retention, installation, and\nuninstallation are heterogeneous but need to be modeled collectively, (2) user\nbehaviors are distributed unevenly over time, and (3) many long-tailed apps\nsuffer from serious sparsity. In this paper, we present a tailored\nAutoEncoder-coupled Transformer Network (AETN), by which we overcome these\nchallenges and achieve the goals of reducing manual efforts and boosting\nperformance. We have deployed the model at Tencent, and both online/offline\nexperiments from multiple domains of downstream applications have demonstrated\nthe effectiveness of the output user embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 12:01:50 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zhang", "Junqi", ""], ["Bai", "Bing", ""], ["Lin", "Ye", ""], ["Liang", "Jian", ""], ["Bai", "Kun", ""], ["Wang", "Fei", ""]]}, {"id": "2005.13326", "submitter": "Keyu An", "authors": "Keyu An, Hongyu Xiang, Zhijian Ou", "title": "CAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end\n  Approaches towards Data Efficiency and Low Latency", "comments": "Accepted into INTERSPEECH 2020. arXiv admin note: text overlap with\n  arXiv:1911.08747", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new open source toolkit for speech recognition,\nnamed CAT (CTC-CRF based ASR Toolkit). CAT inherits the data-efficiency of the\nhybrid approach and the simplicity of the E2E approach, providing a\nfull-fledged implementation of CTC-CRFs and complete training and testing\nscripts for a number of English and Chinese benchmarks. Experiments show CAT\nobtains state-of-the-art results, which are comparable to the fine-tuned hybrid\nmodels in Kaldi but with a much simpler training pipeline. Compared to existing\nnon-modularized E2E models, CAT performs better on limited-scale datasets,\ndemonstrating its data efficiency. Furthermore, we propose a new method called\ncontextualized soft forgetting, which enables CAT to do streaming ASR without\naccuracy degradation. We hope CAT, especially the CTC-CRF based framework and\nsoftware, will be of broad interest to the community, and can be further\nexplored and improved.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 12:41:21 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 02:00:08 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["An", "Keyu", ""], ["Xiang", "Hongyu", ""], ["Ou", "Zhijian", ""]]}, {"id": "2005.13369", "submitter": "Francesco Zola", "authors": "Francesco Zola, Jan Lukas Bruse, Xabier Etxeberria Barrio, Mikel\n  Galar, Raul Orduna Urrutia", "title": "Generative Adversarial Networks for Bitcoin Data Augmentation", "comments": "8 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bitcoin entity classification, results are strongly conditioned by the\nground-truth dataset, especially when applying supervised machine learning\napproaches. However, these ground-truth datasets are frequently affected by\nsignificant class imbalance as generally they contain much more information\nregarding legal services (Exchange, Gambling), than regarding services that may\nbe related to illicit activities (Mixer, Service). Class imbalance increases\nthe complexity of applying machine learning techniques and reduces the quality\nof classification results, especially for underrepresented, but critical\nclasses.\n  In this paper, we propose to address this problem by using Generative\nAdversarial Networks (GANs) for Bitcoin data augmentation as GANs recently have\nshown promising results in the domain of image classification. However, there\nis no \"one-fits-all\" GAN solution that works for every scenario. In fact,\nsetting GAN training parameters is non-trivial and heavily affects the quality\nof the generated synthetic data. We therefore evaluate how GAN parameters such\nas the optimization function, the size of the dataset and the chosen batch size\naffect GAN implementation for one underrepresented entity class (Mining Pool)\nand demonstrate how a \"good\" GAN configuration can be obtained that achieves\nhigh similarity between synthetically generated and real Bitcoin address data.\nTo the best of our knowledge, this is the first study presenting GANs as a\nvalid tool for generating synthetic address data for data augmentation in\nBitcoin entity classification.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 13:58:11 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zola", "Francesco", ""], ["Bruse", "Jan Lukas", ""], ["Barrio", "Xabier Etxeberria", ""], ["Galar", "Mikel", ""], ["Urrutia", "Raul Orduna", ""]]}, {"id": "2005.13417", "submitter": "Tim Janke", "authors": "Tim Janke and Florian Steinke", "title": "Probabilistic multivariate electricity price forecasting using implicit\n  generative ensemble post-processing", "comments": "To be presented at the 16th International Conference on Probabilistic\n  Methods Applied to Power Systems 2020 (PMAPS 2020)", "journal-ref": null, "doi": "10.1109/PMAPS47429.2020.9183687", "report-no": null, "categories": "stat.AP econ.EM q-fin.RM q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliable estimation of forecast uncertainties is crucial for\nrisk-sensitive optimal decision making. In this paper, we propose implicit\ngenerative ensemble post-processing, a novel framework for multivariate\nprobabilistic electricity price forecasting. We use a likelihood-free implicit\ngenerative model based on an ensemble of point forecasting models to generate\nmultivariate electricity price scenarios with a coherent dependency structure\nas a representation of the joint predictive distribution. Our ensemble\npost-processing method outperforms well-established model combination\nbenchmarks. This is demonstrated on a data set from the German day-ahead\nmarket. As our method works on top of an ensemble of domain-specific expert\nmodels, it can readily be deployed to other forecasting tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 15:22:10 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Janke", "Tim", ""], ["Steinke", "Florian", ""]]}, {"id": "2005.13420", "submitter": "Derek Onken", "authors": "Derek Onken and Lars Ruthotto", "title": "Discretize-Optimize vs. Optimize-Discretize for Time-Series Regression\n  and Continuous Normalizing Flows", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We compare the discretize-optimize (Disc-Opt) and optimize-discretize\n(Opt-Disc) approaches for time-series regression and continuous normalizing\nflows (CNFs) using neural ODEs. Neural ODEs are ordinary differential equations\n(ODEs) with neural network components. Training a neural ODE is an optimal\ncontrol problem where the weights are the controls and the hidden features are\nthe states. Every training iteration involves solving an ODE forward and\nanother backward in time, which can require large amounts of computation, time,\nand memory. Comparing the Opt-Disc and Disc-Opt approaches in image\nclassification tasks, Gholami et al. (2019) suggest that Disc-Opt is preferable\ndue to the guaranteed accuracy of gradients. In this paper, we extend the\ncomparison to neural ODEs for time-series regression and CNFs. Unlike in\nclassification, meaningful models in these tasks must also satisfy additional\nrequirements beyond accurate final-time output, e.g., the invertibility of the\nCNF. Through our numerical experiments, we demonstrate that with careful\nnumerical treatment, Disc-Opt methods can achieve similar performance as\nOpt-Disc at inference with drastically reduced training costs. Disc-Opt reduced\ncosts in six out of seven separate problems with training time reduction\nranging from 39% to 97%, and in one case, Disc-Opt reduced training from nine\ndays to less than one day.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 15:28:11 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 00:28:12 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Onken", "Derek", ""], ["Ruthotto", "Lars", ""]]}, {"id": "2005.13438", "submitter": "Hyeoncheol Cho", "authors": "Hyeoncheol Cho, Eok Kyun Lee, Insung S. Choi", "title": "InteractionNet: Modeling and Explaining of Noncovalent Protein-Ligand\n  Interactions with Noncovalent Graph Neural Network and Layer-Wise Relevance\n  Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expanding the scope of graph-based, deep-learning models to noncovalent\nprotein-ligand interactions has earned increasing attention in structure-based\ndrug design. Modeling the protein-ligand interactions with graph neural\nnetworks (GNNs) has experienced difficulties in the conversion of\nprotein-ligand complex structures into the graph representation and left\nquestions regarding whether the trained models properly learn the appropriate\nnoncovalent interactions. Here, we proposed a GNN architecture, denoted as\nInteractionNet, which learns two separated molecular graphs, being covalent and\nnoncovalent, through distinct convolution layers. We also analyzed the\nInteractionNet model with an explainability technique, i.e., layer-wise\nrelevance propagation, for examination of the chemical relevance of the model's\npredictions. Separation of the covalent and noncovalent convolutional steps\nmade it possible to evaluate the contribution of each step independently and\nanalyze the graph-building strategy for noncovalent interactions. We applied\nInteractionNet to the prediction of protein-ligand binding affinity and showed\nthat our model successfully predicted the noncovalent interactions in both\nperformance and relevance in chemical interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:46:44 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Cho", "Hyeoncheol", ""], ["Lee", "Eok Kyun", ""], ["Choi", "Insung S.", ""]]}, {"id": "2005.13458", "submitter": "Allen Wang", "authors": "Allen Wang, Xin Huang, Ashkan Jasour, and Brian Williams", "title": "Fast Risk Assessment for Autonomous Vehicles Using Learned Models of\n  Agent Futures", "comments": "To appear in Robotics: Science and Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents fast non-sampling based methods to assess the risk of\ntrajectories for autonomous vehicles when probabilistic predictions of other\nagents' futures are generated by deep neural networks (DNNs). The presented\nmethods address a wide range of representations for uncertain predictions\nincluding both Gaussian and non-Gaussian mixture models for predictions of both\nagent positions and controls. We show that the problem of risk assessment when\nGaussian mixture models (GMMs) of agent positions are learned can be solved\nrapidly to arbitrary levels of accuracy with existing numerical methods. To\naddress the problem of risk assessment for non-Gaussian mixture models of agent\nposition, we propose finding upper bounds on risk using Chebyshev's Inequality\nand sums-of-squares (SOS) programming; they are both of interest as the former\nis much faster while the latter can be arbitrarily tight. These approaches only\nrequire statistical moments of agent positions to determine upper bounds on\nrisk. To perform risk assessment when models are learned for agent controls as\nopposed to positions, we develop TreeRing, an algorithm analogous to tree\nsearch over the ring of polynomials that can be used to exactly propagate\nmoments of control distributions into position distributions through nonlinear\ndynamics. The presented methods are demonstrated on realistic predictions from\nDNNs trained on the Argoverse and CARLA datasets and are shown to be effective\nfor rapidly assessing the probability of low probability events.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 16:16:36 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 23:56:09 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wang", "Allen", ""], ["Huang", "Xin", ""], ["Jasour", "Ashkan", ""], ["Williams", "Brian", ""]]}, {"id": "2005.13461", "submitter": "Moonseop Kim", "authors": "Moonseop Kim, Guang Lin", "title": "Peri-Net-Pro: The neural processes with quantified uncertainty for crack\n  patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses the peridynamic theory, which is well-suited to crack\nstudies, to predict the crack patterns in a moving disk and classify them\naccording to the modes and finally perform regression analysis. In that way,\nthe crack patterns are obtained according to each mode by Molecular Dynamic\n(MD) simulation using the peridynamics. Image classification and regression\nstudies are conducted through Convolutional Neural Networks (CNNs) and the\nneural processes. First, we increased the amount and quality of the data using\nperidynamics, which can theoretically compensate for the problems of the finite\nelement method (FEM) in generating crack pattern images. Second, we did the\ncase study for the PMB, LPS, and VES models that were obtained using the\nperidynamic theory. Case studies were performed to classify the images using\nCNNs and determine the PMB, LBS, and VES models' suitability. Finally, we\nperformed the regression analysis for the images of the crack patterns with\nneural processes to predict the crack patterns. In the regression problem, by\nrepresenting the results of the variance according to the epochs, it can be\nconfirmed that the result of the variance is decreased by increasing the epoch\nnumbers through the neural processes. The most critical point of this study is\nthat the neural processes make an accurate prediction even if there are missing\nor insufficient training data.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 06:33:37 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Kim", "Moonseop", ""], ["Lin", "Guang", ""]]}, {"id": "2005.13483", "submitter": "Pradeep Reddy Raamana", "authors": "Pradeep Reddy Raamana", "title": "Kernel methods library for pattern analysis and machine learning in\n  python", "comments": "6 pages, 3 code examples, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kernel methods have proven to be powerful techniques for pattern analysis and\nmachine learning (ML) in a variety of domains. However, many of their original\nor advanced implementations remain in Matlab. With the incredible rise and\nadoption of Python in the ML and data science world, there is a clear need for\na well-defined library that enables not only the use of popular kernels, but\nalso allows easy definition of customized kernels to fine-tune them for diverse\napplications. The kernelmethods library fills that important void in the python\nML ecosystem in a domain-agnostic fashion, allowing the sample data type to be\nanything from numerical, categorical, graphs or a combination of them. In\naddition, this library provides a number of well-defined classes to make\nvarious kernel-based operations efficient (for large scale datasets), modular\n(for ease of domain adaptation), and inter-operable (across different\necosystems). The library is available at\nhttps://github.com/raamana/kernelmethods.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 16:44:42 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Raamana", "Pradeep Reddy", ""]]}, {"id": "2005.13510", "submitter": "Jeremy Georges-Filteau", "authors": "Jeremy Georges-Filteau, Elisa Cirillo", "title": "Synthetic Observational Health Data with GANs: from slow adoption to a\n  boom in medical research and ultimately digital twins?", "comments": "31 pages (10 in previous version), not including references and\n  glossary, 51 in total. Inclusion of a large number of recent publications and\n  expansion of the discussion accordingly", "journal-ref": null, "doi": "10.22541/au.158921777.79483839/v2", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  After being collected for patient care, Observational Health Data (OHD) can\nfurther benefit patient well-being by sustaining the development of health\ninformatics and medical research. Vast potential is unexploited because of the\nfiercely private nature of patient-related data and regulations to protect it.\n  Generative Adversarial Networks (GANs) have recently emerged as a\ngroundbreaking way to learn generative models that produce realistic synthetic\ndata. They have revolutionized practices in multiple domains such as\nself-driving cars, fraud detection, digital twin simulations in industrial\nsectors, and medical imaging.\n  The digital twin concept could readily apply to modelling and quantifying\ndisease progression. In addition, GANs posses many capabilities relevant to\ncommon problems in healthcare: lack of data, class imbalance, rare diseases,\nand preserving privacy. Unlocking open access to privacy-preserving OHD could\nbe transformative for scientific research. In the midst of COVID-19, the\nhealthcare system is facing unprecedented challenges, many of which of are data\nrelated for the reasons stated above.\n  Considering these facts, publications concerning GAN applied to OHD seemed to\nbe severely lacking. To uncover the reasons for this slow adoption, we broadly\nreviewed the published literature on the subject. Our findings show that the\nproperties of OHD were initially challenging for the existing GAN algorithms\n(unlike medical imaging, for which state-of-the-art model were directly\ntransferable) and the evaluation synthetic data lacked clear metrics.\n  We find more publications on the subject than expected, starting slowly in\n2017, and since then at an increasing rate. The difficulties of OHD remain, and\nwe discuss issues relating to evaluation, consistency, benchmarking, data\nmodelling, and reproducibility.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 17:40:35 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 18:08:47 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 05:27:34 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Georges-Filteau", "Jeremy", ""], ["Cirillo", "Elisa", ""]]}, {"id": "2005.13522", "submitter": "Weiran Yao", "authors": "Weiran Yao, Sean Qian", "title": "Learning to Recommend Signal Plans under Incidents with Real-Time\n  Traffic Prediction", "comments": "To be published in Transportation Research Record (2020)", "journal-ref": null, "doi": "10.1177/0361198120917668", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main question to address in this paper is to recommend optimal signal\ntiming plans in real time under incidents by incorporating domain knowledge\ndeveloped with the traffic signal timing plans tuned for possible incidents,\nand learning from historical data of both traffic and implemented signals\ntiming. The effectiveness of traffic incident management is often limited by\nthe late response time and excessive workload of traffic operators. This paper\nproposes a novel decision-making framework that learns from both data and\ndomain knowledge to real-time recommend contingency signal plans that\naccommodate non-recurrent traffic, with the outputs from real-time traffic\nprediction at least 30 minutes in advance. Specifically, considering the rare\noccurrences of engagement of contingency signal plans for incidents, we propose\nto decompose the end-to-end recommendation task into two hierarchical models:\nreal-time traffic prediction and plan association. We learn the connections\nbetween the two models through metric learning, which reinforces partial-order\npreferences observed from historical signal engagement records. We demonstrate\nthe effectiveness of our approach by testing this framework on the traffic\nnetwork in Cranberry Township in 2019. Results show that our recommendation\nsystem has a precision score of 96.75% and recall of 87.5% on the testing plan,\nand make recommendation of an average of 22.5 minutes lead time ahead of Waze\nalerts. The results suggest that our framework is capable of giving traffic\noperators a significant time window to access the conditions and respond\nappropriately.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:30:29 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Yao", "Weiran", ""], ["Qian", "Sean", ""]]}, {"id": "2005.13523", "submitter": "Abdul Moeed", "authors": "Abdul Moeed", "title": "Emotion-robust EEG Classification for Motor Imagery", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developments in Brain Computer Interfaces (BCIs) are empowering those with\nsevere physical afflictions through their use in assistive systems. Common\nmethods of achieving this is via Motor Imagery (MI), which maps brain signals\nto code for certain commands. Electroencephalogram (EEG) is preferred for\nrecording brain signal data on account of it being non-invasive. Despite their\npotential utility, MI-BCI systems are yet confined to research labs. A major\ncause for this is lack of robustness of such systems. As hypothesized by two\nteams during Cybathlon 2016, a particular source of the system's vulnerability\nis the sharp change in the subject's state of emotional arousal. This work aims\ntowards making MI-BCI systems resilient to such emotional perturbations. To do\nso, subjects are exposed to high and low arousal-inducing virtual reality (VR)\nenvironments before recording EEG data. The advent of COVID-19 compelled us to\nmodify our methodology. Instead of training machine learning algorithms to\nclassify emotional arousal, we opt for classifying subjects that serve as proxy\nfor each state. Additionally, MI models are trained for each subject instead of\neach arousal state. As training subjects to use MI-BCI can be an arduous and\ntime-consuming process, reducing this variability and increasing robustness can\nconsiderably accelerate the acceptance and adoption of assistive technologies\npowered by BCI.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 17:31:07 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Moeed", "Abdul", ""]]}, {"id": "2005.13525", "submitter": "Mitch Hill", "authors": "Mitch Hill, Jonathan Mitchell, Song-Chun Zhu", "title": "Stochastic Security: Adversarial Defense Using Long-Run Dynamics of\n  Energy-Based Models", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep networks to adversarial attacks is a central\nproblem for deep learning from the perspective of both cognition and security.\nThe current most successful defense method is to train a classifier using\nadversarial images created during learning. Another defense approach involves\ntransformation or purification of the original input to remove adversarial\nsignals before the image is classified. We focus on defending naturally-trained\nclassifiers using Markov Chain Monte Carlo (MCMC) sampling with an Energy-Based\nModel (EBM) for adversarial purification. In contrast to adversarial training,\nour approach is intended to secure pre-existing and highly vulnerable\nclassifiers.\n  The memoryless behavior of long-run MCMC sampling will eventually remove\nadversarial signals, while metastable behavior preserves consistent appearance\nof MCMC samples after many steps to allow accurate long-run prediction.\nBalancing these factors can lead to effective purification and robust\nclassification. We evaluate adversarial defense with an EBM using the strongest\nknown attacks against purification. Our contributions are 1) an improved method\nfor training EBM's with realistic long-run MCMC samples, 2) an\nExpectation-Over-Transformation (EOT) defense that resolves theoretical\nambiguities for stochastic defenses and from which the EOT attack naturally\nfollows, and 3) state-of-the-art adversarial defense for naturally-trained\nclassifiers and competitive defense compared to adversarially-trained\nclassifiers on Cifar-10, SVHN, and Cifar-100. Code and pre-trained models are\navailable at https://github.com/point0bar1/ebm-defense.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 17:53:36 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 19:39:26 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Hill", "Mitch", ""], ["Mitchell", "Jonathan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2005.13530", "submitter": "Stephan Wojtowytsch", "authors": "Stephan Wojtowytsch", "title": "On the Convergence of Gradient Descent Training for Two-layer\n  ReLU-networks in the Mean Field Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a necessary and sufficient condition for the convergence to\nminimum Bayes risk when training two-layer ReLU-networks by gradient descent in\nthe mean field regime with omni-directional initial parameter distribution.\nThis article extends recent results of Chizat and Bach to ReLU-activated\nnetworks and to the situation in which there are no parameters which exactly\nachieve MBR. The condition does not depend on the initalization of parameters\nand concerns only the weak convergence of the realization of the neural\nnetwork, not its parameter distribution.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 17:54:17 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wojtowytsch", "Stephan", ""]]}, {"id": "2005.13590", "submitter": "Haoxian Chen", "authors": "Han Lin, Haoxian Chen, Tianyi Zhang, Clement Laroche, and Krzysztof\n  Choromanski", "title": "Demystifying Orthogonal Monte Carlo and Beyond", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal Monte Carlo (OMC) is a very effective sampling algorithm imposing\nstructural geometric conditions (orthogonality) on samples for variance\nreduction. Due to its simplicity and superior performance as compared to its\nQuasi Monte Carlo counterparts, OMC is used in a wide spectrum of challenging\nmachine learning applications ranging from scalable kernel methods to\npredictive recurrent neural networks, generative models and reinforcement\nlearning. However theoretical understanding of the method remains very limited.\nIn this paper we shed new light on the theoretical principles behind OMC,\napplying theory of negatively dependent random variables to obtain several new\nconcentration results. We also propose a novel extensions of the method\nleveraging number theory techniques and particle algorithms, called\nNear-Orthogonal Monte Carlo (NOMC). We show that NOMC is the first algorithm\nconsistently outperforming OMC in applications ranging from kernel methods to\napproximating distances in probabilistic metric spaces.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 18:44:38 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Lin", "Han", ""], ["Chen", "Haoxian", ""], ["Zhang", "Tianyi", ""], ["Laroche", "Clement", ""], ["Choromanski", "Krzysztof", ""]]}, {"id": "2005.13596", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep (DEEP) Mukhopadhyay and Kaijun Wang", "title": "Breiman's \"Two Cultures\" Revisited and Reconciled", "comments": "This paper celebrates the 70th anniversary of Statistical Machine\n  Learning--- how far we've come, and how far we have to go. Keywords:\n  Integrated statistical learning theory, Exploratory machine learning,\n  Uncertainty prediction machine, ML-powered modern applied statistics,\n  Information theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG econ.EM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a landmark paper published in 2001, Leo Breiman described the tense\nstandoff between two cultures of data modeling: parametric statistical and\nalgorithmic machine learning. The cultural division between these two\nstatistical learning frameworks has been growing at a steady pace in recent\nyears. What is the way forward? It has become blatantly obvious that this\nwidening gap between \"the two cultures\" cannot be averted unless we find a way\nto blend them into a coherent whole. This article presents a solution by\nestablishing a link between the two cultures. Through examples, we describe the\nchallenges and potential gains of this new integrated statistical thinking.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:02:56 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Subhadeep", "", "", "DEEP"], ["Mukhopadhyay", "", ""], ["Wang", "Kaijun", ""]]}, {"id": "2005.13607", "submitter": "Hehuan Ma", "authors": "Hehuan Ma, Yatao Bian, Yu Rong, Wenbing Huang, Tingyang Xu, Weiyang\n  Xie, Geyan Ye, Junzhou Huang", "title": "Multi-View Graph Neural Networks for Molecular Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crux of molecular property prediction is to generate meaningful\nrepresentations of the molecules. One promising route is to exploit the\nmolecular graph structure through Graph Neural Networks (GNNs). It is well\nknown that both atoms and bonds significantly affect the chemical properties of\na molecule, so an expressive model shall be able to exploit both node (atom)\nand edge (bond) information simultaneously. Guided by this observation, we\npresent Multi-View Graph Neural Network (MV-GNN), a multi-view message passing\narchitecture to enable more accurate predictions of molecular properties. In\nMV-GNN, we introduce a shared self-attentive readout component and disagreement\nloss to stabilize the training process. This readout component also renders the\nwhole architecture interpretable. We further boost the expressive power of\nMV-GNN by proposing a cross-dependent message passing scheme that enhances\ninformation communication of the two views, which results in the MV-GNN^cross\nvariant. Lastly, we theoretically justify the expressiveness of the two\nproposed models in terms of distinguishing non-isomorphism graphs. Extensive\nexperiments demonstrate that MV-GNN models achieve remarkably superior\nperformance over the state-of-the-art models on a variety of challenging\nbenchmarks. Meanwhile, visualization results of the node importance are\nconsistent with prior knowledge, which confirms the interpretability power of\nMV-GNN models.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 04:46:07 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 08:57:04 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 06:09:52 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ma", "Hehuan", ""], ["Bian", "Yatao", ""], ["Rong", "Yu", ""], ["Huang", "Wenbing", ""], ["Xu", "Tingyang", ""], ["Xie", "Weiyang", ""], ["Ye", "Geyan", ""], ["Huang", "Junzhou", ""]]}, {"id": "2005.13616", "submitter": "Barry-John Theobald", "authors": "Ahmed Hussen Abdelaziz and Barry-John Theobald and Paul Dixon and\n  Reinhard Knothe and Nicholas Apostoloff and Sachin Kajareker", "title": "Modality Dropout for Improved Performance-driven Talking Faces", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our novel deep learning approach for driving animated faces using\nboth acoustic and visual information. In particular, speech-related facial\nmovements are generated using audiovisual information, and non-speech facial\nmovements are generated using only visual information. To ensure that our model\nexploits both modalities during training, batches are generated that contain\naudio-only, video-only, and audiovisual input features. The probability of\ndropping a modality allows control over the degree to which the model exploits\naudio and visual information during training. Our trained model runs in\nreal-time on resource limited hardware (e.g.\\ a smart phone), it is user\nagnostic, and it is not dependent on a potentially error-prone transcription of\nthe speech. We use subjective testing to demonstrate: 1) the improvement of\naudiovisual-driven animation over the equivalent video-only approach, and 2)\nthe improvement in the animation of speech-related facial movements after\nintroducing modality dropout. Before introducing dropout, viewers prefer\naudiovisual-driven animation in 51% of the test sequences compared with only\n18% for video-driven. After introducing dropout viewer preference for\naudiovisual-driven animation increases to 74%, but decreases to 8% for\nvideo-only.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:55:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Abdelaziz", "Ahmed Hussen", ""], ["Theobald", "Barry-John", ""], ["Dixon", "Paul", ""], ["Knothe", "Reinhard", ""], ["Apostoloff", "Nicholas", ""], ["Kajareker", "Sachin", ""]]}, {"id": "2005.13625", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel, Ananth Hari, Luis Santos, Benjamin\n  Black", "title": "Revisiting Parameter Sharing In Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Nonstationarity\" is a fundamental problem in cooperative multi-agent\nreinforcement learning (MARL). It results from every agent's policy changing\nduring learning, while being part of the environment from the perspective of\nother agents. This causes information to inherently oscillate between agents\nduring learning, greatly slowing convergence. We use the MAILP model of\ninformation transfer during multi-agent learning to show that increasing\ncentralization during learning arbitrarily mitigates the slowing of convergence\ndue to nonstationarity. The most centralized case of learning is parameter\nsharing, an uncommonly used MARL method, specific to environments with\nhomogeneous agents. It bootstraps single-agent reinforcement learning (RL)\nmethods and learns an identical policy for each agent. We experimentally\nreplicate our theoretical result of increased learning centralization leading\nto better performance. We further apply parameter sharing to 8 more modern\nsingle-agent deep RL methods for the first time, achieving up to 44 times more\naverage reward in 16% as many episodes compared to previous parameter sharing\nexperiments. We finally give a formal proof of a set of methods that allow\nparameter sharing to serve in environments with heterogeneous agents.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:14:28 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 08:33:31 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 23:17:06 GMT"}, {"version": "v4", "created": "Fri, 24 Jul 2020 05:39:03 GMT"}, {"version": "v5", "created": "Wed, 11 Nov 2020 01:19:15 GMT"}, {"version": "v6", "created": "Thu, 25 Feb 2021 22:24:34 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""], ["Hari", "Ananth", ""], ["Santos", "Luis", ""], ["Black", "Benjamin", ""]]}, {"id": "2005.13630", "submitter": "Johannes Schneider", "authors": "Johannes Schneider and Michalis Vlachos", "title": "Explaining Neural Networks by Decoding Layer Activations", "comments": null, "journal-ref": "Intelligent Data Analysis (IDA), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a `CLAssifier-DECoder' architecture (\\emph{ClaDec}) which\nfacilitates the comprehension of the output of an arbitrary layer in a neural\nnetwork (NN). It uses a decoder to transform the non-interpretable\nrepresentation of the given layer to a representation that is more similar to\nthe domain a human is familiar with. In an image recognition problem, one can\nrecognize what information is represented by a layer by contrasting\nreconstructed images of \\emph{ClaDec} with those of a conventional\nauto-encoder(AE) serving as reference. We also extend \\emph{ClaDec} to allow\nthe trade-off between human interpretability and fidelity. We evaluate our\napproach for image classification using Convolutional NNs. We show that\nreconstructed visualizations using encodings from a classifier capture more\nrelevant information for classification than conventional AEs. Relevant code is\navailable at \\url{https://github.com/JohnTailor/ClaDec}\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:22:10 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 16:35:52 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 17:11:43 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Schneider", "Johannes", ""], ["Vlachos", "Michalis", ""]]}, {"id": "2005.13638", "submitter": "Sebastian Raschka", "authors": "Zhongjie Yu and Sebastian Raschka", "title": "Looking back to lower-level information in few-shot learning", "comments": "13 pages, 2 figures; fixed typographic errors and added journal ref", "journal-ref": "Information 2020, 11, 345", "doi": "10.3390/info11070345", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of learning new concepts from small numbers of examples.\nIn contrast, supervised deep learning models usually lack the ability to\nextract reliable predictive rules from limited data scenarios when attempting\nto classify new examples. This challenging scenario is commonly known as\nfew-shot learning. Few-shot learning has garnered increased attention in recent\nyears due to its significance for many real-world problems. Recently, new\nmethods relying on meta-learning paradigms combined with graph-based\nstructures, which model the relationship between examples, have shown promising\nresults on a variety of few-shot classification tasks. However, existing work\non few-shot learning is only focused on the feature embeddings produced by the\nlast layer of the neural network. In this work, we propose the utilization of\nlower-level, supporting information, namely the feature embeddings of the\nhidden neural network layers, to improve classifier accuracy. Based on a\ngraph-based meta-learning framework, we develop a method called Looking-Back,\nwhere such lower-level information is used to construct additional graphs for\nlabel propagation in limited data settings. Our experiments on two popular\nfew-shot learning datasets, miniImageNet and tieredImageNet, show that our\nmethod can utilize the lower-level information in the network to improve\nstate-of-the-art classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:32:13 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 02:32:21 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Yu", "Zhongjie", ""], ["Raschka", "Sebastian", ""]]}, {"id": "2005.13702", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei and Xin Liu", "title": "On the Difficulty of Membership Inference Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies propose membership inference (MI) attacks on deep models,\nwhere the goal is to infer if a sample has been used in the training process.\nDespite their apparent success, these studies only report accuracy, precision,\nand recall of the positive class (member class). Hence, the performance of\nthese attacks have not been clearly reported on negative class (non-member\nclass). In this paper, we show that the way the MI attack performance has been\nreported is often misleading because they suffer from high false positive rate\nor false alarm rate (FAR) that has not been reported. FAR shows how often the\nattack model mislabel non-training samples (non-member) as training (member)\nones. The high FAR makes MI attacks fundamentally impractical, which is\nparticularly more significant for tasks such as membership inference where the\nmajority of samples in reality belong to the negative (non-training) class.\nMoreover, we show that the current MI attack models can only identify the\nmembership of misclassified samples with mediocre accuracy at best, which only\nconstitute a very small portion of training samples.\n  We analyze several new features that have not been comprehensively explored\nfor membership inference before, including distance to the decision boundary\nand gradient norms, and conclude that deep models' responses are mostly similar\namong train and non-train samples. We conduct several experiments on image\nclassification tasks, including MNIST, CIFAR-10, CIFAR-100, and ImageNet, using\nvarious model architecture, including LeNet, AlexNet, ResNet, etc. We show that\nthe current state-of-the-art MI attacks cannot achieve high accuracy and low\nFAR at the same time, even when the attacker is given several advantages.\n  The source code is available at https://github.com/shrezaei/MI-Attack.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 23:09:17 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 00:18:48 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 20:17:22 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Liu", "Xin", ""]]}, {"id": "2005.13746", "submitter": "Yinan Wang", "authors": "Yinan Wang, Weihong \"Grace\" Guo, Xiaowei Yue", "title": "Tensor decomposition to Compress Convolutional Layers in Deep Learning", "comments": "35 pages, IISE Transactions", "journal-ref": null, "doi": "10.1080/24725854.2021.1894514", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction for tensor data serves as an important step in many tasks\nsuch as anomaly detection, process monitoring, image classification, and\nquality control. Although many methods have been proposed for tensor feature\nextraction, there are still two challenges that need to be addressed: 1) how to\nreduce the computation cost for high dimensional and large volume tensor data;\n2) how to interpret the output features and evaluate their significance. {The\nmost recent methods in deep learning, such as Convolutional Neural Network\n(CNN), have shown outstanding performance in analyzing tensor data, but their\nwide adoption is still hindered by model complexity and lack of\ninterpretability. To fill this research gap, we propose to use CP-decomposition\nto approximately compress the convolutional layer (CPAC-Conv layer) in deep\nlearning. The contributions of our work could be summarized into three aspects:\n(1) we adapt CP-decomposition to compress convolutional kernels and derive the\nexpressions of both forward and backward propagations for our proposed\nCPAC-Conv layer; (2) compared with the original convolutional layer, the\nproposed CPAC-Conv layer can reduce the number of parameters without decaying\nprediction performance. It can combine with other layers to build novel deep\nNeural Networks; (3) the value of decomposed kernels indicates the significance\nof the corresponding feature map, which provides us with insights to guide\nfeature selection.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 02:35:48 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 01:53:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Yinan", ""], ["Guo", "Weihong \"Grace\"", ""], ["Yue", "Xiaowei", ""]]}, {"id": "2005.13748", "submitter": "Han Bao", "authors": "Han Bao, Clayton Scott, Masashi Sugiyama", "title": "Calibrated Surrogate Losses for Adversarially Robust Classification", "comments": "Corrigendum to the published version in COLT2020\n  (http://proceedings.mlr.press/v125/bao20a.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarially robust classification seeks a classifier that is insensitive to\nadversarial perturbations of test patterns. This problem is often formulated\nvia a minimax objective, where the target loss is the worst-case value of the\n0-1 loss subject to a bound on the size of perturbation. Recent work has\nproposed convex surrogates for the adversarial 0-1 loss, in an effort to make\noptimization more tractable. A primary question is that of consistency, that\nis, whether minimization of the surrogate risk implies minimization of the\nadversarial 0-1 risk. In this work, we analyze this question through the lens\nof calibration, which is a pointwise notion of consistency. We show that no\nconvex surrogate loss is calibrated with respect to the adversarial 0-1 loss\nwhen restricted to the class of linear models. We further introduce a class of\nnonconvex losses and offer necessary and sufficient conditions for losses in\nthis class to be calibrated. We also show that if the underlying distribution\nsatisfies Massart's noise condition, convex losses can also be calibrated in\nthe adversarial setting.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 02:40:42 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 09:56:30 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Bao", "Han", ""], ["Scott", "Clayton", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2005.13755", "submitter": "Paula Gordaliza", "authors": "Eustasio del Barrio, Paula Gordaliza, Jean-Michel Loubes", "title": "Review of Mathematical frameworks for Fairness in Machine Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.07864,\n  arXiv:1911.04322, arXiv:1906.05082 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A review of the main fairness definitions and fair learning methodologies\nproposed in the literature over the last years is presented from a mathematical\npoint of view. Following our independence-based approach, we consider how to\nbuild fair algorithms and the consequences on the degradation of their\nperformance compared to the possibly unfair case. This corresponds to the price\nfor fairness given by the criteria $\\textit{statistical parity}$ or\n$\\textit{equality of odds}$. Novel results giving the expressions of the\noptimal fair classifier and the optimal fair predictor (under a linear\nregression gaussian model) in the sense of $\\textit{equality of odds}$ are\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:40:13 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["del Barrio", "Eustasio", ""], ["Gordaliza", "Paula", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "2005.13769", "submitter": "Vivek Narayanaswamy", "authors": "Vivek Narayanaswamy, Jayaraman J. Thiagarajan, Rushil Anirudh and\n  Andreas Spanias", "title": "Unsupervised Audio Source Separation using Generative Priors", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art under-determined audio source separation systems rely on\nsupervised end-end training of carefully tailored neural network architectures\noperating either in the time or the spectral domain. However, these methods are\nseverely challenged in terms of requiring access to expensive source level\nlabeled data and being specific to a given set of sources and the mixing\nprocess, which demands complete re-training when those assumptions change. This\nstrongly emphasizes the need for unsupervised methods that can leverage the\nrecent advances in data-driven modeling, and compensate for the lack of labeled\ndata through meaningful priors. To this end, we propose a novel approach for\naudio source separation based on generative priors trained on individual\nsources. Through the use of projected gradient descent optimization, our\napproach simultaneously searches in the source-specific latent spaces to\neffectively recover the constituent sources. Though the generative priors can\nbe defined in the time domain directly, e.g. WaveGAN, we find that using\nspectral domain loss functions for our optimization leads to good-quality\nsource estimates. Our empirical studies on standard spoken digit and instrument\ndatasets clearly demonstrate the effectiveness of our approach over classical\nas well as state-of-the-art unsupervised baselines.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 03:57:16 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Narayanaswamy", "Vivek", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Anirudh", "Rushil", ""], ["Spanias", "Andreas", ""]]}, {"id": "2005.13778", "submitter": "Parth Chadha", "authors": "Parth Chadha", "title": "Domain Knowledge Integration By Gradient Matching For Sample-Efficient\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) agents can learn an effective\npolicy directly from repeated interactions with a black-box environment.\nHowever in practice, the algorithms often require large amounts of training\nexperience to learn and generalize well. In addition, classic model-free\nlearning ignores the domain information contained in the state transition\ntuples. Model-based RL, on the other hand, attempts to learn a model of the\nenvironment from experience and is substantially more sample efficient, but\nsuffers from significantly large asymptotic bias owing to the imperfect\ndynamics model. In this paper, we propose a gradient matching algorithm to\nimprove sample efficiency by utilizing target slope information from the\ndynamics predictor to aid the model-free learner. We demonstrate this by\npresenting a technique for matching the gradient information from the\nmodel-based learner with the model-free component in an abstract\nlow-dimensional space and validate the proposed technique through experimental\nresults that demonstrate the efficacy of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 05:02:47 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Chadha", "Parth", ""]]}, {"id": "2005.13796", "submitter": "Zejiang Hou", "authors": "Zejiang Hou and Sun-Yuan Kung", "title": "A Feature-map Discriminant Perspective for Pruning Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning has become the de facto tool to accelerate deep neural\nnetworks for mobile and edge applications. Recently, feature-map discriminant\nbased channel pruning has shown promising results, as it aligns well with the\nCNN objective of differentiating multiple classes and offers better\ninterpretability of the pruning decision. However, existing discriminant-based\nmethods are challenged by computation inefficiency, as there is a lack of\ntheoretical guidance on quantifying the feature-map discriminant power. In this\npaper, we present a new mathematical formulation to accurately and efficiently\nquantify the feature-map discriminativeness, which gives rise to a novel\ncriterion,Discriminant Information(DI). We analyze the theoretical property of\nDI, specifically the non-decreasing property, that makes DI a valid selection\ncriterion. DI-based pruning removes channels with minimum influence to DI\nvalue, as they contain little information regarding to the discriminant power.\nThe versatility of DI criterion also enables an intra-layer mixed precision\nquantization to further compress the network. Moreover, we propose a DI-based\ngreedy pruning algorithm and structure distillation technique to automatically\ndecide the pruned structure that satisfies certain resource budget, which is a\ncommon requirement in reality. Extensive experiments demonstratethe\neffectiveness of our method: our pruned ResNet50 on ImageNet achieves 44% FLOPs\nreduction without any Top-1 accuracy loss compared to unpruned model\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 06:25:22 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Hou", "Zejiang", ""], ["Kung", "Sun-Yuan", ""]]}, {"id": "2005.13815", "submitter": "Nam Ho-Nguyen", "authors": "Nam Ho-Nguyen, Stephen J. Wright", "title": "Adversarial Classification via Distributional Robustness with\n  Wasserstein Ambiguity", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a model for adversarial classification based on distributionally\nrobust chance constraints. We show that under Wasserstein ambiguity, the model\naims to minimize the conditional value-at-risk of the distance to\nmisclassification, and we explore links to adversarial classification models\nproposed earlier and to maximum-margin classifiers. We also provide a\nreformulation of the distributionally robust model for linear classification,\nand show it is equivalent to minimizing a regularized ramp loss objective.\nNumerical experiments show that, despite the nonconvexity of this formulation,\nstandard descent methods appear to converge to the global minimizer for this\nproblem. Inspired by this observation, we show that, for a certain separable\ndistribution, the only stationary point of the regularized ramp loss\nminimization problem is the global minimizer.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:28:47 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:14:13 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Ho-Nguyen", "Nam", ""], ["Wright", "Stephen J.", ""]]}, {"id": "2005.13818", "submitter": "He Huang", "authors": "He Huang, Martin Pouls, Anne Meyer, and Markus Pauly", "title": "Travel Time Prediction using Tree-Based Ensembles", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-59747-4_27", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the task of predicting travel times between two\narbitrary points in an urban scenario. We view this problem from two temporal\nperspectives: long-term forecasting with a horizon of several days and\nshort-term forecasting with a horizon of one hour. Both of these perspectives\nare relevant for planning tasks in the context of urban mobility and\ntransportation services. We utilize tree-based ensemble methods that we train\nand evaluate on a dataset of taxi trip records from New York City. Through\nextensive data analysis, we identify relevant temporal and spatial features. We\nalso engineer additional features based on weather and routing data. The latter\nis obtained via a routing solver operating on the road network. The\ncomputational results show that the addition of this routing data can be\nbeneficial to the model performance. Moreover, employing different models for\nshort and long-term prediction is useful as short-term models are better suited\nto mirror current traffic conditions. In fact, we show that accurate short-term\npredictions may be obtained with only little training data.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:43:54 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Huang", "He", ""], ["Pouls", "Martin", ""], ["Meyer", "Anne", ""], ["Pauly", "Markus", ""]]}, {"id": "2005.13826", "submitter": "Weiran Huang", "authors": "Aoxue Li and Weiran Huang and Xu Lan and Jiashi Feng and Zhenguo Li\n  and Liwei Wang", "title": "Boosting Few-Shot Learning With Adaptive Margin Loss", "comments": "Accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning (FSL) has attracted increasing attention in recent years\nbut remains challenging, due to the intrinsic difficulty in learning to\ngeneralize from a few examples. This paper proposes an adaptive margin\nprinciple to improve the generalization ability of metric-based meta-learning\napproaches for few-shot learning problems. Specifically, we first develop a\nclass-relevant additive margin loss, where semantic similarity between each\npair of classes is considered to separate samples in the feature embedding\nspace from similar classes. Further, we incorporate the semantic context among\nall classes in a sampled training task and develop a task-relevant additive\nmargin loss to better distinguish samples from different classes. Our adaptive\nmargin method can be easily extended to a more realistic generalized FSL\nsetting. Extensive experiments demonstrate that the proposed method can boost\nthe performance of current metric-based meta-learning approaches, under both\nthe standard FSL and generalized FSL settings.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:58:41 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Li", "Aoxue", ""], ["Huang", "Weiran", ""], ["Lan", "Xu", ""], ["Feng", "Jiashi", ""], ["Li", "Zhenguo", ""], ["Wang", "Liwei", ""]]}, {"id": "2005.13885", "submitter": "Gian Maria Marconi", "authors": "Gian Maria Marconi, Lorenzo Rosasco and Carlo Ciliberto", "title": "Hyperbolic Manifold Regression", "comments": "13 pages, 3 figures To be published in 23rd International Conference\n  on Artificial Intelligence and Statistics Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric representation learning has recently shown great promise in several\nmachine learning settings, ranging from relational learning to language\nprocessing and generative models. In this work, we consider the problem of\nperforming manifold-valued regression onto an hyperbolic space as an\nintermediate component for a number of relevant machine learning applications.\nIn particular, by formulating the problem of predicting nodes of a tree as a\nmanifold regression task in the hyperbolic space, we propose a novel\nperspective on two challenging tasks: 1) hierarchical classification via label\nembeddings and 2) taxonomy extension of hyperbolic representations. To address\nthe regression problem we consider previous methods as well as proposing two\nnovel approaches that are computationally more advantageous: a parametric deep\nlearning model that is informed by the geodesics of the target space and a\nnon-parametric kernel-method for which we also prove excess risk bounds. Our\nexperiments show that the strategy of leveraging the hyperbolic geometry is\npromising. In particular, in the taxonomy expansion setting, we find that the\nhyperbolic-based estimators significantly outperform methods performing\nregression in the ambient Euclidean space.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 10:16:30 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Marconi", "Gian Maria", ""], ["Rosasco", "Lorenzo", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "2005.13912", "submitter": "Rem-Sophia Mouradi", "authors": "Rem-Sophia Mouradi, C\\'edric Goeury, Olivier Thual, Fabrice Zaoui and\n  Pablo Tassi", "title": "Physically interpretable machine learning algorithm on multidimensional\n  non-linear fields", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.110074", "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an ever-increasing interest for Machine Learning (ML) and a favorable data\ndevelopment context, we here propose an original methodology for data-based\nprediction of two-dimensional physical fields. Polynomial Chaos Expansion\n(PCE), widely used in the Uncertainty Quantification community (UQ), has long\nbeen employed as a robust representation for probabilistic input-to-output\nmapping. It has been recently tested in a pure ML context, and shown to be as\npowerful as classical ML techniques for point-wise prediction. Some advantages\nare inherent to the method, such as its explicitness and adaptability to small\ntraining sets, in addition to the associated probabilistic framework.\nSimultaneously, Dimensionality Reduction (DR) techniques are increasingly used\nfor pattern recognition and data compression and have gained interest due to\nimproved data quality. In this study, the interest of Proper Orthogonal\nDecomposition (POD) for the construction of a statistical predictive model is\ndemonstrated. Both POD and PCE have amply proved their worth in their\nrespective frameworks. The goal of the present paper was to combine them for a\nfield-measurement-based forecasting. The described steps are also useful to\nanalyze the data. Some challenging issues encountered when using\nmultidimensional field measurements are addressed, for example when dealing\nwith few data. The POD-PCE coupling methodology is presented, with particular\nfocus on input data characteristics and training-set choice. A simple\nmethodology for evaluating the importance of each physical parameter is\nproposed for the PCE model and extended to the POD-PCE coupling.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 11:26:06 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 19:54:49 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Mouradi", "Rem-Sophia", ""], ["Goeury", "C\u00e9dric", ""], ["Thual", "Olivier", ""], ["Zaoui", "Fabrice", ""], ["Tassi", "Pablo", ""]]}, {"id": "2005.13930", "submitter": "Benedikt Boenninghoff", "authors": "Benedikt Boenninghoff, Steffen Zeiler, Robert M. Nickel, Dorothea\n  Kolossa", "title": "Variational Autoencoder with Embedded Student-$t$ Mixture Model for\n  Authorship Attribution", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional computational authorship attribution describes a classification\ntask in a closed-set scenario. Given a finite set of candidate authors and\ncorresponding labeled texts, the objective is to determine which of the authors\nhas written another set of anonymous or disputed texts. In this work, we\npropose a probabilistic autoencoding framework to deal with this supervised\nclassification task. More precisely, we are extending a variational autoencoder\n(VAE) with embedded Gaussian mixture model to a Student-$t$ mixture model.\nAutoencoders have had tremendous success in learning latent representations.\nHowever, existing VAEs are currently still bound by limitations imposed by the\nassumed Gaussianity of the underlying probability distributions in the latent\nspace. In this work, we are extending the Gaussian model for the VAE to a\nStudent-$t$ model, which allows for an independent control of the \"heaviness\"\nof the respective tails of the implied probability densities. Experiments over\nan Amazon review dataset indicate superior performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 11:52:32 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Boenninghoff", "Benedikt", ""], ["Zeiler", "Steffen", ""], ["Nickel", "Robert M.", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "2005.13948", "submitter": "Patrick Kidger", "authors": "Patrick Kidger, James Morrill, Terry Lyons", "title": "Generalised Interpretable Shapelets for Irregular Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shapelet transform is a form of feature extraction for time series, in\nwhich a time series is described by its similarity to each of a collection of\n`shapelets'. However it has previously suffered from a number of limitations,\nsuch as being limited to regularly-spaced fully-observed time series, and\nhaving to choose between efficient training and interpretability. Here, we\nextend the method to continuous time, and in doing so handle the general case\nof irregularly-sampled partially-observed multivariate time series.\nFurthermore, we show that a simple regularisation penalty may be used to train\nefficiently without sacrificing interpretability. The continuous-time\nformulation additionally allows for learning the length of each shapelet\n(previously a discrete object) in a differentiable manner. Finally, we\ndemonstrate that the measure of similarity between time series may be\ngeneralised to a learnt pseudometric. We validate our method by demonstrating\nits performance and interpretability on several datasets; for example we\ndiscover (purely from data) that the digits 5 and 6 may be distinguished by the\nchirality of their bottom loop, and that a kind of spectral gap exists in\nspoken audio classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 12:32:19 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 11:08:16 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Kidger", "Patrick", ""], ["Morrill", "James", ""], ["Lyons", "Terry", ""]]}, {"id": "2005.13953", "submitter": "Andriy Serdega", "authors": "Andriy Serdega, Dae-Shik Kim", "title": "VMI-VAE: Variational Mutual Information Maximization Framework for VAE\n  With Discrete and Continuous Priors", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.14254.95042", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoder is a scalable method for learning latent variable\nmodels of complex data. It employs a clear objective that can be easily\noptimized. However, it does not explicitly measure the quality of learned\nrepresentations. We propose a Variational Mutual Information Maximization\nFramework for VAE to address this issue. It provides an objective that\nmaximizes the mutual information between latent codes and observations. The\nobjective acts as a regularizer that forces VAE to not ignore the latent code\nand allows one to select particular components of it to be most informative\nwith respect to the observations. On top of that, the proposed framework\nprovides a way to evaluate mutual information between latent codes and\nobservations for a fixed VAE model.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 12:44:23 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Serdega", "Andriy", ""], ["Kim", "Dae-Shik", ""]]}, {"id": "2005.13971", "submitter": "Christian Oliva", "authors": "Christian Oliva and Luis F. Lago-Fern\\'andez", "title": "Separation of Memory and Processing in Dual Recurrent Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.FL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a neural network architecture that stacks a recurrent layer and a\nfeedforward layer that is also connected to the input, and compare it to\nstandard Elman and LSTM architectures in terms of accuracy and\ninterpretability. When noise is introduced into the activation function of the\nrecurrent units, these neurons are forced into a binary activation regime that\nmakes the networks behave much as finite automata. The resulting models are\nsimpler, easier to interpret and get higher accuracy on different sample\nproblems, including the recognition of regular languages, the computation of\nadditions in different bases and the generation of arithmetic expressions.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:38:42 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Oliva", "Christian", ""], ["Lago-Fern\u00e1ndez", "Luis F.", ""]]}, {"id": "2005.13977", "submitter": "Tiago Peixoto", "authors": "Tiago P. Peixoto", "title": "Revealing consensus and dissensus between network partitions", "comments": "28 pages, 16 figures", "journal-ref": "Phys. Rev. X 11, 021003 (2021)", "doi": "10.1103/PhysRevX.11.021003", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Community detection methods attempt to divide a network into groups of nodes\nthat share similar properties, thus revealing its large-scale structure. A\nmajor challenge when employing such methods is that they are often degenerate,\ntypically yielding a complex landscape of competing answers. As an attempt to\nextract understanding from a population of alternative solutions, many methods\nexist to establish a consensus among them in the form of a single partition\n\"point estimate\" that summarizes the whole distribution. Here we show that it\nis in general not possible to obtain a consistent answer from such point\nestimates when the underlying distribution is too heterogeneous. As an\nalternative, we provide a comprehensive set of methods designed to characterize\nand summarize complex populations of partitions in a manner that captures not\nonly the existing consensus, but also the dissensus between elements of the\npopulation. Our approach is able to model mixed populations of partitions where\nmultiple consensuses can coexist, representing different competing hypotheses\nfor the network structure. We also show how our methods can be used to compare\npairs of partitions, how they can be generalized to hierarchical divisions, and\nbe used to perform statistical model selection between competing hypotheses.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 13:29:42 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 13:36:41 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 16:12:35 GMT"}, {"version": "v4", "created": "Fri, 8 Jan 2021 13:13:23 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 22:26:28 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Peixoto", "Tiago P.", ""]]}, {"id": "2005.13992", "submitter": "Anahita Sanandaji", "authors": "Anahita Sanandaji, Saeed Ghanbartehrani, Zahra Mokhtari, Kimia Tajik", "title": "A Novel Ramp Metering Approach Based on Machine Learning and Historical\n  Data", "comments": "5 pages, 11 figures, 2 tables", "journal-ref": null, "doi": "10.3390/make2040021", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random nature of traffic conditions on freeways can cause excessive\ncongestions and irregularities in the traffic flow. Ramp metering is a proven\neffective method to maintain freeway efficiency under various traffic\nconditions. Creating a reliable and practical ramp metering algorithm that\nconsiders both critical traffic measures and historical data is still a\nchallenging problem. In this study we use machine learning approaches to\ndevelop a novel real-time prediction model for ramp metering. We evaluate the\npotentials of our approach in providing promising results by comparing it with\na baseline traffic-responsive ramp metering algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 21:05:01 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sanandaji", "Anahita", ""], ["Ghanbartehrani", "Saeed", ""], ["Mokhtari", "Zahra", ""], ["Tajik", "Kimia", ""]]}, {"id": "2005.13995", "submitter": "Zhaoyu Xu", "authors": "Xinyue Cui, Zhaoyu Xu, Yue Zhou", "title": "Using Machine Learning to Forecast Future Earnings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this essay, we have comprehensively evaluated the feasibility and\nsuitability of adopting the Machine Learning Models on the forecast of\ncorporation fundamentals (i.e. the earnings), where the prediction results of\nour method have been thoroughly compared with both analysts' consensus\nestimation and traditional statistical models. As a result, our model has\nalready been proved to be capable of serving as a favorable auxiliary tool for\nanalysts to conduct better predictions on company fundamentals. Compared with\nprevious traditional statistical models being widely adopted in the industry\nlike Logistic Regression, our method has already achieved satisfactory\nadvancement on both the prediction accuracy and speed. Meanwhile, we are also\nconfident enough that there are still vast potentialities for this model to\nevolve, where we do hope that in the near future, the machine learning model\ncould generate even better performances compared with professional analysts.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:39:38 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Cui", "Xinyue", ""], ["Xu", "Zhaoyu", ""], ["Zhou", "Yue", ""]]}, {"id": "2005.14001", "submitter": "Zhijian Ou", "authors": "Zhijian Ou, Yunfu Song", "title": "Joint Stochastic Approximation and Its Application to Learning Discrete\n  Latent Variable Models", "comments": "Accepted by UAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although with progress in introducing auxiliary amortized inference models,\nlearning discrete latent variable models is still challenging. In this paper,\nwe show that the annoying difficulty of obtaining reliable stochastic gradients\nfor the inference model and the drawback of indirectly optimizing the target\nlog-likelihood can be gracefully addressed in a new method based on stochastic\napproximation (SA) theory of the Robbins-Monro type. Specifically, we propose\nto directly maximize the target log-likelihood and simultaneously minimize the\ninclusive divergence between the posterior and the inference model. The\nresulting learning algorithm is called joint SA (JSA). To the best of our\nknowledge, JSA represents the first method that couples an SA version of the EM\n(expectation-maximization) algorithm (SAEM) with an adaptive MCMC procedure.\nExperiments on several benchmark generative modeling and structured prediction\ntasks show that JSA consistently outperforms recent competitive algorithms,\nwith faster convergence, better final likelihoods, and lower variance of\ngradient estimates.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 13:50:08 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Ou", "Zhijian", ""], ["Song", "Yunfu", ""]]}, {"id": "2005.14007", "submitter": "Ambedkar Dukkipati", "authors": "Sourabh Balgi and Ambedkar Dukkipati", "title": "Contradistinguisher: A Vapnik's Imperative to Unsupervised Domain\n  Adaptation", "comments": "18 pages. arXiv admin note: text overlap with arXiv:1909.03442", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complex combination of simultaneous supervised-unsupervised learning is\nbelieved to be the key to humans performing tasks seamlessly across multiple\ndomains or tasks. This phenomenon of cross-domain learning has been very well\nstudied in domain adaptation literature. Recent domain adaptation works rely on\nan indirect way of first aligning the source and target domain distributions\nand then train a classifier on the labeled source domain to classify the target\ndomain. However, this approach has the main drawback that obtaining a\nnear-perfect alignment of the domains in itself might be difficult/impossible\n(e.g., language domains). To address this, we follow Vapnik's imperative of\nstatistical learning that states any desired problem should be solved in the\nmost direct way rather than solving a more general intermediate task and\npropose a direct approach to domain adaptation that does not require domain\nalignment. We propose a model referred Contradistinguisher that learns\ncontrastive features and whose objective is to jointly learn to\ncontradistinguish the unlabeled target domain in an unsupervised way and\nclassify in a supervised way on the source domain. We achieve the\nstate-of-the-art on Office-31 and VisDA-2017 datasets in both single-source and\nmulti-source settings. We also notice that the contradistinguish loss improves\nthe model performance by increasing the shape bias.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 19:54:38 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 06:36:05 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 11:55:34 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Balgi", "Sourabh", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "2005.14015", "submitter": "Purushottam Kar", "authors": "Darshak Chhatbar and Umair Z. Ahmed and Purushottam Kar", "title": "MACER: A Modular Framework for Accelerated Compilation Error Repair", "comments": "19 pages, 9 figures. A short version of this paper will appear at the\n  21st International Conference on Artificial Intelligence in Education (AIED).\n  Code for the MACER tool-chain is available at\n  https://github.com/purushottamkar/macer/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated compilation error repair, the problem of suggesting fixes to buggy\nprograms that fail to compile, has generated significant interest in recent\nyears. Apart from being a tool of general convenience, automated code repair\nhas significant pedagogical applications for novice programmers who find\ncompiler error messages cryptic and unhelpful. Existing approaches largely\nsolve this problem using a blackbox-application of a heavy-duty generative\nlearning technique, such as sequence-to-sequence prediction (TRACER) or\nreinforcement learning (RLAssist). Although convenient, such black-box\napplication of learning techniques makes existing approaches bulky in terms of\ntraining time, as well as inefficient at targeting specific error types.\n  We present MACER, a novel technique for accelerated error repair based on a\nmodular segregation of the repair process into repair identification and repair\napplication. MACER uses powerful yet inexpensive discriminative learning\ntechniques such as multi-label classifiers and rankers to first identify the\ntype of repair required and then apply the suggested repair.\n  Experiments indicate that the fine-grained approach adopted by MACER offers\nnot only superior error correction, but also much faster training and\nprediction. On a benchmark dataset of 4K buggy programs collected from actual\nstudent submissions, MACER outperforms existing methods by 20% at suggesting\nfixes for popular errors that exactly match the fix desired by the student.\nMACER is also competitive or better than existing methods at all error types --\nwhether popular or rare. MACER offers a training time speedup of 2x over TRACER\nand 800x over RLAssist, and a test time speedup of 2-4x over both.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:00:03 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Chhatbar", "Darshak", ""], ["Ahmed", "Umair Z.", ""], ["Kar", "Purushottam", ""]]}, {"id": "2005.14036", "submitter": "Kalliopi Basioti", "authors": "Kalliopi Basioti, George V. Moustakides", "title": "Image Restoration from Parametric Transformations using Generative\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When images are statistically described by a generative model we can use this\ninformation to develop optimum techniques for various image restoration\nproblems as inpainting, super-resolution, image coloring, generative model\ninversion, etc. With the help of the generative model it is possible to\nformulate, in a natural way, these restoration problems as Statistical\nestimation problems. Our approach, by combining maximum a-posteriori\nprobability with maximum likelihood estimation, is capable of restoring images\nthat are distorted by transformations even when the latter contain unknown\nparameters. The resulting optimization is completely defined with no parameters\nrequiring tuning. This must be compared with the current state of the art which\nrequires exact knowledge of the transformations and contains regularizer terms\nwith weights that must be properly defined. Finally, we must mention that we\nextend our method to accommodate mixtures of multiple images where each image\nis described by its own generative model and we are able of successfully\nseparating each participating image from a single mixture.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:14:40 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 12:09:41 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Basioti", "Kalliopi", ""], ["Moustakides", "George V.", ""]]}, {"id": "2005.14057", "submitter": "Andrii Babii", "authors": "Andrii Babii and Eric Ghysels and Jonas Striaukas", "title": "Machine Learning Time Series Regressions with an Application to\n  Nowcasting", "comments": "Portions of this work previously appeared as arXiv:1912.06307v1 which\n  has been split into two articles", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces structured machine learning regressions for\nhigh-dimensional time series data potentially sampled at different frequencies.\nThe sparse-group LASSO estimator can take advantage of such time series data\nstructures and outperforms the unstructured LASSO. We establish oracle\ninequalities for the sparse-group LASSO estimator within a framework that\nallows for the mixing processes and recognizes that the financial and the\nmacroeconomic data may have heavier than exponential tails. An empirical\napplication to nowcasting US GDP growth indicates that the estimator performs\nfavorably compared to other alternatives and that text data can be a useful\naddition to more traditional numerical data.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:42:58 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 00:50:12 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 19:53:54 GMT"}, {"version": "v4", "created": "Sat, 12 Dec 2020 18:30:09 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Babii", "Andrii", ""], ["Ghysels", "Eric", ""], ["Striaukas", "Jonas", ""]]}, {"id": "2005.14062", "submitter": "Anthony Gitter", "authors": "David Merrell, Anthony Gitter", "title": "Inferring Signaling Pathways with Probabilistic Programming", "comments": "15 pages, 10 figures; added Appendices C and D", "journal-ref": "Bioinformatics 36:Supplement_2 (2020) i822-i830", "doi": "10.1093/bioinformatics/btaa861", "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cells regulate themselves via dizzyingly complex biochemical processes called\nsignaling pathways. These are usually depicted as a network, where nodes\nrepresent proteins and edges indicate their influence on each other. In order\nto understand diseases and therapies at the cellular level, it is crucial to\nhave an accurate understanding of the signaling pathways at work. Since\nsignaling pathways can be modified by disease, the ability to infer signaling\npathways from condition- or patient-specific data is highly valuable. A variety\nof techniques exist for inferring signaling pathways. We build on past works\nthat formulate signaling pathway inference as a Dynamic Bayesian Network\nstructure estimation problem on phosphoproteomic time course data. We take a\nBayesian approach, using Markov Chain Monte Carlo to estimate a posterior\ndistribution over possible Dynamic Bayesian Network structures. Our primary\ncontributions are (i) a novel proposal distribution that efficiently samples\nsparse graphs and (ii) the relaxation of common restrictive modeling\nassumptions. We implement our method, named Sparse Signaling Pathway Sampling,\nin Julia using the Gen probabilistic programming language. Probabilistic\nprogramming is a powerful methodology for building statistical models. The\nresulting code is modular, extensible, and legible. The Gen language, in\nparticular, allows us to customize our inference procedure for biological\ngraphs and ensure efficient sampling. We evaluate our algorithm on simulated\ndata and the HPN-DREAM pathway reconstruction challenge, comparing our\nperformance against a variety of baseline methods. Our results demonstrate the\nvast potential for probabilistic programming, and Gen specifically, for\nbiological network inference. Find the full codebase at\nhttps://github.com/gitter-lab/ssps\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:55:11 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 22:15:36 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Merrell", "David", ""], ["Gitter", "Anthony", ""]]}, {"id": "2005.14070", "submitter": "Muhammad Shah", "authors": "Muhammad A. Shah, Raphael Olivier and Bhiksha Raj", "title": "Exploiting Non-Linear Redundancy for Neural Model Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying deep learning models, comprising of non-linear combination of\nmillions, even billions, of parameters is challenging given the memory, power\nand compute constraints of the real world. This situation has led to research\ninto model compression techniques most of which rely on suboptimal heuristics\nand do not consider the parameter redundancies due to linear dependence between\nneuron activations in overparametrized networks. In this paper, we propose a\nnovel model compression approach based on exploitation of linear dependence,\nthat compresses networks by elimination of entire neurons and redistribution of\ntheir activations over other neurons in a manner that is provably lossless\nwhile training. We combine this approach with an annealing algorithm that may\nbe applied during training, or even on a trained model, and demonstrate, using\npopular datasets, that our method results in a reduction of up to 99\\% in\noverall network size with small loss in performance. Furthermore, we provide\ntheoretical results showing that in overparametrized, locally linear (ReLU)\nneural networks where redundant features exist, and with correct hyperparameter\nselection, our method is indeed able to capture and suppress those\ndependencies.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:13:21 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Shah", "Muhammad A.", ""], ["Olivier", "Raphael", ""], ["Raj", "Bhiksha", ""]]}, {"id": "2005.14073", "submitter": "Banghua Zhu", "authors": "Banghua Zhu, Jiantao Jiao and Jacob Steinhardt", "title": "Robust estimation via generalized quasi-gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore why many recently proposed robust estimation problems are\nefficiently solvable, even though the underlying optimization problems are\nnon-convex. We study the loss landscape of these robust estimation problems,\nand identify the existence of \"generalized quasi-gradients\". Whenever these\nquasi-gradients exist, a large family of low-regret algorithms are guaranteed\nto approximate the global minimum; this includes the commonly-used filtering\nalgorithm.\n  For robust mean estimation of distributions under bounded covariance, we show\nthat any first-order stationary point of the associated optimization problem is\nan {approximate global minimum} if and only if the corruption level $\\epsilon <\n1/3$. Consequently, any optimization algorithm that aproaches a stationary\npoint yields an efficient robust estimator with breakdown point $1/3$. With\ncareful initialization and step size, we improve this to $1/2$, which is\noptimal.\n  For other tasks, including linear regression and joint mean and covariance\nestimation, the loss landscape is more rugged: there are stationary points\narbitrarily far from the global minimum. Nevertheless, we show that generalized\nquasi-gradients exist and construct efficient algorithms. These algorithms are\nsimpler than previous ones in the literature, and for linear regression we\nimprove the estimation error from $O(\\sqrt{\\epsilon})$ to the optimal rate of\n$O(\\epsilon)$ for small $\\epsilon$ assuming certified hypercontractivity. For\nmean estimation with near-identity covariance, we show that a simple gradient\ndescent algorithm achieves breakdown point $1/3$ and iteration complexity\n$\\tilde{O}(d/\\epsilon^2)$.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:14:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2005.14105", "submitter": "Christoph Hertrich", "authors": "Christoph Hertrich and Martin Skutella", "title": "Provably Good Solutions to the Knapsack Problem via Neural Networks of\n  Bounded Size", "comments": "A short version of this paper appears in the proceedings of AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DM cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of a satisfying and rigorous mathematical understanding of\nthe performance of neural networks is a major challenge in artificial\nintelligence. Against this background, we study the expressive power of neural\nnetworks through the example of the classical NP-hard Knapsack Problem. Our\nmain contribution is a class of recurrent neural networks (RNNs) with rectified\nlinear units that are iteratively applied to each item of a Knapsack instance\nand thereby compute optimal or provably good solution values. We show that an\nRNN of depth four and width depending quadratically on the profit of an optimum\nKnapsack solution is sufficient to find optimum Knapsack solutions. We also\nprove the following tradeoff between the size of an RNN and the quality of the\ncomputed Knapsack solution: for Knapsack instances consisting of $n$ items, an\nRNN of depth five and width $w$ computes a solution of value at least\n$1-\\mathcal{O}(n^2/\\sqrt{w})$ times the optimum solution value. Our results\nbuild upon a classical dynamic programming formulation of the Knapsack Problem\nas well as a careful rounding of profit values that are also at the core of the\nwell-known fully polynomial-time approximation scheme for the Knapsack Problem.\nA carefully conducted computational study qualitatively supports our\ntheoretical size bounds. Finally, we point out that our results can be\ngeneralized to many other combinatorial optimization problems that admit\ndynamic programming solution methods, such as various Shortest Path Problems,\nthe Longest Common Subsequence Problem, and the Traveling Salesperson Problem.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:55:37 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 10:26:12 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Hertrich", "Christoph", ""], ["Skutella", "Martin", ""]]}, {"id": "2005.14117", "submitter": "Alessio Fagioli", "authors": "Danilo Avola, Luigi Cinque, Alessio Fagioli, Sebastiano Filetti,\n  Giorgio Grani, Emanuele Rodol\\`a", "title": "Knowledge-Driven Learning via Experts Consult for Thyroid Nodule\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided diagnosis (CAD) is becoming a prominent approach to assist\nclinicians spanning across multiple fields. These automated systems take\nadvantage of various computer vision (CV) procedures, as well as artificial\nintelligence (AI) techniques, so that a diagnosis of a given image (e.g.,\ncomputed tomography and ultrasound) can be formulated. Advances in both areas\n(CV and AI) are enabling ever increasing performances of CAD systems, which can\nultimately avoid performing invasive procedures such as fine-needle aspiration.\nIn this study, we focus on thyroid ultrasonography to present a novel\nknowledge-driven classification framework. The proposed system leverages cues\nprovided by an ensemble of experts, in order to guide the learning phase of a\ndensely connected convolutional network (DenseNet). The ensemble is composed by\nvarious networks pretrained on ImageNet, including AlexNet, ResNet, VGG, and\nothers, so that previously computed feature parameters could be used to create\nultrasonography domain experts via transfer learning, decreasing, moreover, the\nnumber of samples required for training. To validate the proposed method,\nextensive experiments were performed, providing detailed performances for both\nthe experts ensemble and the knowledge-driven DenseNet. The obtained results,\nshow how the the proposed system can become a great asset when formulating a\ndiagnosis, by leveraging previous knowledge derived from a consult.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:12:04 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Avola", "Danilo", ""], ["Cinque", "Luigi", ""], ["Fagioli", "Alessio", ""], ["Filetti", "Sebastiano", ""], ["Grani", "Giorgio", ""], ["Rodol\u00e0", "Emanuele", ""]]}, {"id": "2005.14137", "submitter": "Huichen Li", "authors": "Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, Bo Li", "title": "QEBA: Query-Efficient Boundary-Based Blackbox Attack", "comments": "Accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML), especially deep neural networks (DNNs) have been\nwidely used in various applications, including several safety-critical ones\n(e.g. autonomous driving). As a result, recent research about adversarial\nexamples has raised great concerns. Such adversarial attacks can be achieved by\nadding a small magnitude of perturbation to the input to mislead model\nprediction. While several whitebox attacks have demonstrated their\neffectiveness, which assume that the attackers have full access to the machine\nlearning models; blackbox attacks are more realistic in practice. In this\npaper, we propose a Query-Efficient Boundary-based blackbox Attack (QEBA) based\nonly on model's final prediction labels. We theoretically show why previous\nboundary-based attack with gradient estimation on the whole gradient space is\nnot efficient in terms of query numbers, and provide optimality analysis for\nour dimension reduction-based gradient estimation. On the other hand, we\nconducted extensive experiments on ImageNet and CelebA datasets to evaluate\nQEBA. We show that compared with the state-of-the-art blackbox attacks, QEBA is\nable to use a smaller number of queries to achieve a lower magnitude of\nperturbation with 100% attack success rate. We also show case studies of\nattacks on real-world APIs including MEGVII Face++ and Microsoft Azure.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:41:12 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Li", "Huichen", ""], ["Xu", "Xiaojun", ""], ["Zhang", "Xiaolu", ""], ["Yang", "Shuang", ""], ["Li", "Bo", ""]]}, {"id": "2005.14139", "submitter": "Philipp Marquetand", "authors": "Julia Westermayr, Philipp Marquetand", "title": "Machine learning and excited-state molecular dynamics", "comments": null, "journal-ref": "Mach. Learn.: Sci. Technol., 1, 043001 (2020)", "doi": "10.1088/2632-2153/ab9c3e", "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is employed at an increasing rate in the research field of\nquantum chemistry. While the majority of approaches target the investigation of\nchemical systems in their electronic ground state, the inclusion of light into\nthe processes leads to electronically excited states and gives rise to several\nnew challenges. Here, we survey recent advances for excited-state dynamics\nbased on machine learning. In doing so, we highlight successes, pitfalls,\nchallenges and future avenues for machine learning approaches for light-induced\nmolecular processes.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:43:18 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Westermayr", "Julia", ""], ["Marquetand", "Philipp", ""]]}, {"id": "2005.14181", "submitter": "Hugo Carvalho", "authors": "Hugo Tremonte de Carvalho, Fl\\'avio Rainho \\'Avila, Luiz Wagner\n  Pereira Biscainho", "title": "Bayesian Restoration of Audio Degraded by Low-Frequency Pulses Modeled\n  via Gaussian Process", "comments": "14 pages, 7 figures, 4 tables. Submitted to IEEE Journal of Selected\n  Topics in Signal Processing - Special Issue \"Reconstruction of audio from\n  incomplete or highly degraded observations\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common defect found when reproducing old vinyl and gramophone recordings\nwith mechanical devices are the long pulses with significant low-frequency\ncontent caused by the interaction of the arm-needle system with deep scratches\nor even breakages on the media surface. Previous approaches to their\nsuppression on digital counterparts of the recordings depend on a prior\nestimation of the pulse location, usually performed via heuristic methods. This\npaper proposes a novel Bayesian approach capable of jointly estimating the\npulse location; interpolating the almost annihilated signal underlying the\nstrong discontinuity that initiates the pulse; and also estimating the long\npulse tail by a simple Gaussian Process, allowing its suppression from the\ncorrupted signal. The posterior distribution for the model parameters as well\nfor the pulse is explored via Markov-Chain Monte Carlo (MCMC) algorithms.\nControlled experiments indicate that the proposed method, while requiring\nsignificantly less user intervention, achieves perceptual results similar to\nthose of previous approaches and performs well when dealing with naturally\ndegraded signals.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 17:52:26 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 14:11:51 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["de Carvalho", "Hugo Tremonte", ""], ["\u00c1vila", "Fl\u00e1vio Rainho", ""], ["Biscainho", "Luiz Wagner Pereira", ""]]}, {"id": "2005.14256", "submitter": "Zhou Shou", "authors": "Sha Yuan, Zhou Shao, Yu Zhang, Xingxing Wei, Tong Xiao, Yifan Wang,\n  Jie Tang", "title": "Attention: to Better Stand on the Shoulders of Giants", "comments": "arXiv admin note: text overlap with arXiv:1811.02117,\n  arXiv:1811.02129", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Science of science (SciSci) is an emerging discipline wherein science is used\nto study the structure and evolution of science itself using large data sets.\nThe increasing availability of digital data on scholarly outcomes offers\nunprecedented opportunities to explore SciSci. In the progress of science, the\npreviously discovered knowledge principally inspires new scientific ideas, and\ncitation is a reasonably good reflection of this cumulative nature of\nscientific research. The researches that choose potentially influential\nreferences will have a lead over the emerging publications. Although the peer\nreview process is the mainly reliable way of predicting a paper's future\nimpact, the ability to foresee the lasting impact based on citation records is\nincreasingly essential in the scientific impact analysis in the era of big\ndata. This paper develops an attention mechanism for the long-term scientific\nimpact prediction and validates the method based on a real large-scale citation\ndata set. The results break conventional thinking. Instead of accurately\nsimulating the original power-law distribution, emphasizing the limited\nattention can better stand on the shoulders of giants.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:25:51 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Yuan", "Sha", ""], ["Shao", "Zhou", ""], ["Zhang", "Yu", ""], ["Wei", "Xingxing", ""], ["Xiao", "Tong", ""], ["Wang", "Yifan", ""], ["Tang", "Jie", ""]]}, {"id": "2005.14346", "submitter": "Simge Kucukyavuz", "authors": "Simge Kucukyavuz, Ali Shojaie, Hasan Manzour, Linchuan Wei", "title": "Consistent Second-Order Conic Integer Programming for Learning Bayesian\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Networks (BNs) represent conditional probability relations among a\nset of random variables (nodes) in the form of a directed acyclic graph (DAG),\nand have found diverse applications in knowledge discovery. We study the\nproblem of learning the sparse DAG structure of a BN from continuous\nobservational data. The central problem can be modeled as a mixed-integer\nprogram with an objective function composed of a convex quadratic loss function\nand a regularization penalty subject to linear constraints. The optimal\nsolution to this mathematical program is known to have desirable statistical\nproperties under certain conditions. However, the state-of-the-art optimization\nsolvers are not able to obtain provably optimal solutions to the existing\nmathematical formulations for medium-size problems within reasonable\ncomputational times. To address this difficulty, we tackle the problem from\nboth computational and statistical perspectives. On the one hand, we propose a\nconcrete early stopping criterion to terminate the branch-and-bound process in\norder to obtain a near-optimal solution to the mixed-integer program, and\nestablish the consistency of this approximate solution. On the other hand, we\nimprove the existing formulations by replacing the linear \"big-$M$\" constraints\nthat represent the relationship between the continuous and binary indicator\nvariables with second-order conic constraints. Our numerical results\ndemonstrate the effectiveness of the proposed approaches.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 00:13:15 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 17:04:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kucukyavuz", "Simge", ""], ["Shojaie", "Ali", ""], ["Manzour", "Hasan", ""], ["Wei", "Linchuan", ""]]}, {"id": "2005.14359", "submitter": "Mao Ye", "authors": "Yan Min, Mao Ye, Liang Tian, Yulin Jian, Ce Zhu, Shangming Yang", "title": "Unsupervised Feature Selection via Multi-step Markov Transition\n  Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is a widely used dimension reduction technique to select\nfeature subsets because of its interpretability. Many methods have been\nproposed and achieved good results, in which the relationships between adjacent\ndata points are mainly concerned. But the possible associations between data\npairs that are may not adjacent are always neglected. Different from previous\nmethods, we propose a novel and very simple approach for unsupervised feature\nselection, named MMFS (Multi-step Markov transition probability for Feature\nSelection). The idea is using multi-step Markov transition probability to\ndescribe the relation between any data pair. Two ways from the positive and\nnegative viewpoints are employed respectively to keep the data structure after\nfeature selection. From the positive viewpoint, the maximum transition\nprobability that can be reached in a certain number of steps is used to\ndescribe the relation between two points. Then, the features which can keep the\ncompact data structure are selected. From the viewpoint of negative, the\nminimum transition probability that can be reached in a certain number of steps\nis used to describe the relation between two points. On the contrary, the\nfeatures that least maintain the loose data structure are selected. And the two\nways can also be combined. Thus three algorithms are proposed. Our main\ncontributions are a novel feature section approach which uses multi-step\ntransition probability to characterize the data structure, and three algorithms\nproposed from the positive and negative aspects for keeping data structure. The\nperformance of our approach is compared with the state-of-the-art methods on\neight real-world data sets, and the experimental results show that the proposed\nMMFS is effective in unsupervised feature selection.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 01:15:16 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Min", "Yan", ""], ["Ye", "Mao", ""], ["Tian", "Liang", ""], ["Jian", "Yulin", ""], ["Zhu", "Ce", ""], ["Yang", "Shangming", ""]]}, {"id": "2005.14381", "submitter": "Kiattikun Chobtham", "authors": "Kiattikun Chobtham, Anthony C. Constantinou", "title": "Bayesian network structure learning with causal effects in the presence\n  of latent variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variables may lead to spurious relationships that can be\nmisinterpreted as causal relationships. In Bayesian Networks (BNs), this\nchallenge is known as learning under causal insufficiency. Structure learning\nalgorithms that assume causal insufficiency tend to reconstruct the ancestral\ngraph of a BN, where bi-directed edges represent confounding and directed edges\nrepresent direct or ancestral relationships. This paper describes a hybrid\nstructure learning algorithm, called CCHM, which combines the constraint-based\npart of cFCI with hill-climbing score-based learning. The score-based process\nincorporates Pearl s do-calculus to measure causal effects and orientate edges\nthat would otherwise remain undirected, under the assumption the BN is a linear\nStructure Equation Model where data follow a multivariate Gaussian\ndistribution. Experiments based on both randomised and well-known networks show\nthat CCHM improves the state-of-the-art in terms of reconstructing the true\nancestral graph.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 04:42:28 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 06:17:56 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Chobtham", "Kiattikun", ""], ["Constantinou", "Anthony C.", ""]]}, {"id": "2005.14419", "submitter": "Paul Weng", "authors": "Olivier Buffet, Olivier Pietquin, Paul Weng", "title": "Reinforcement Learning", "comments": "Chapter in \"A Guided Tour of Artificial Intelligence Research\",\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a general framework for adaptive control,\nwhich has proven to be efficient in many domains, e.g., board games, video\ngames or autonomous vehicles. In such problems, an agent faces a sequential\ndecision-making problem where, at every time step, it observes its state,\nperforms an action, receives a reward and moves to a new state. An RL agent\nlearns by trial and error a good policy (or controller) based on observations\nand numeric reward feedback on the previously performed action. In this\nchapter, we present the basic framework of RL and recall the two main families\nof approaches that have been developed to learn a good policy. The first one,\nwhich is value-based, consists in estimating the value of an optimal policy,\nvalue from which a policy can be recovered, while the other, called policy\nsearch, directly works in a policy space. Actor-critic methods can be seen as a\npolicy search technique where the policy value that is learned guides the\npolicy improvement. Besides, we give an overview of some extensions of the\nstandard RL framework, notably when risk-averse behavior needs to be taken into\naccount or when rewards are not available or not known.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 06:53:29 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 05:19:26 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Buffet", "Olivier", ""], ["Pietquin", "Olivier", ""], ["Weng", "Paul", ""]]}, {"id": "2005.14424", "submitter": "Mao Ye", "authors": "Mao Ye, Chengyue Gong, Qiang Liu", "title": "SAFER: A Structure-free Approach for Certified Robustness to Adversarial\n  Word Substitutions", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art NLP models can often be fooled by human-unaware\ntransformations such as synonymous word substitution. For security reasons, it\nis of critical importance to develop models with certified robustness that can\nprovably guarantee that the prediction is can not be altered by any possible\nsynonymous word substitution. In this work, we propose a certified robust\nmethod based on a new randomized smoothing technique, which constructs a\nstochastic ensemble by applying random word substitutions on the input\nsentences, and leverage the statistical properties of the ensemble to provably\ncertify the robustness. Our method is simple and structure-free in that it only\nrequires the black-box queries of the model outputs, and hence can be applied\nto any pre-trained models (such as BERT) and any types of models (world-level\nor subword-level). Our method significantly outperforms recent state-of-the-art\nmethods for certified robustness on both IMDB and Amazon text classification\ntasks. To the best of our knowledge, we are the first work to achieve certified\nrobustness on large systems such as BERT with practically meaningful certified\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 07:15:19 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ye", "Mao", ""], ["Gong", "Chengyue", ""], ["Liu", "Qiang", ""]]}, {"id": "2005.14425", "submitter": "Srinivas Kota Reddy", "authors": "Sahasrajit Sarmasarkar, Kota Srinivas Reddy, and Nikhil Karamchandani", "title": "Query complexity of heavy hitter estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying the subset\n$\\mathcal{S}^{\\gamma}_{\\mathcal{P}}$ of elements in the support of an\nunderlying distribution $\\mathcal{P}$ whose probability value is larger than a\ngiven threshold $\\gamma$, by actively querying an oracle to gain information\nabout a sequence $X_1, X_2, \\ldots$ of $i.i.d.$ samples drawn from\n$\\mathcal{P}$. We consider two query models: $(a)$ each query is an index $i$\nand the oracle return the value $X_i$ and $(b)$ each query is a pair $(i,j)$\nand the oracle gives a binary answer confirming if $X_i = X_j$ or not. For each\nof these query models, we design sequential estimation algorithms which at each\nround, either decide what query to send to the oracle depending on the entire\nhistory of responses or decide to stop and output an estimate of\n$\\mathcal{S}^{\\gamma}_{\\mathcal{P}}$, which is required to be correct with some\npre-specified large probability. We provide upper bounds on the query\ncomplexity of the algorithms for any distribution $\\mathcal{P}$ and also derive\nlower bounds on the optimal query complexity under the two query models. We\nalso consider noisy versions of the two query models and propose robust\nestimators which can effectively counter the noise in the oracle responses.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 07:15:46 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 12:18:38 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Sarmasarkar", "Sahasrajit", ""], ["Reddy", "Kota Srinivas", ""], ["Karamchandani", "Nikhil", ""]]}, {"id": "2005.14426", "submitter": "Quanquan Gu", "authors": "Spencer Frei and Yuan Cao and Quanquan Gu", "title": "Agnostic Learning of a Single Neuron with Gradient Descent", "comments": "31 pages, 3 tables. This version improves the risk bound from\n  O(OPT^1/2) to O(OPT) for strictly increasing activation functions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the best-fitting single neuron as\nmeasured by the expected square loss $\\mathbb{E}_{(x,y)\\sim\n\\mathcal{D}}[(\\sigma(w^\\top x)-y)^2]$ over some unknown joint distribution\n$\\mathcal{D}$ by using gradient descent to minimize the empirical risk induced\nby a set of i.i.d. samples $S\\sim \\mathcal{D}^n$. The activation function\n$\\sigma$ is an arbitrary Lipschitz and non-decreasing function, making the\noptimization problem nonconvex and nonsmooth in general, and covers typical\nneural network activation functions and inverse link functions in the\ngeneralized linear model setting. In the agnostic PAC learning setting, where\nno assumption on the relationship between the labels $y$ and the input $x$ is\nmade, if the optimal population risk is $\\mathsf{OPT}$, we show that gradient\ndescent achieves population risk $O(\\mathsf{OPT})+\\epsilon$ in polynomial time\nand sample complexity when $\\sigma$ is strictly increasing. For the ReLU\nactivation, our population risk guarantee is $O(\\mathsf{OPT}^{1/2})+\\epsilon$.\nWhen labels take the form $y = \\sigma(v^\\top x) + \\xi$ for zero-mean\nsub-Gaussian noise $\\xi$, we show that the population risk guarantees for\ngradient descent improve to $\\mathsf{OPT} + \\epsilon$. Our sample complexity\nand runtime guarantees are (almost) dimension independent, and when $\\sigma$ is\nstrictly increasing, require no distributional assumptions beyond boundedness.\nFor ReLU, we show the same results under a nondegeneracy assumption for the\nmarginal distribution of the input.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 07:20:35 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:43:43 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 17:19:08 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Frei", "Spencer", ""], ["Cao", "Yuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "2005.14436", "submitter": "Duccio Fanelli", "authors": "Lorenzo Giambagli, Lorenzo Buffoni, Timoteo Carletti, Walter\n  Nocentini, Duccio Fanelli", "title": "Machine learning in spectral domain", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-021-21481-0", "report-no": null, "categories": "cs.LG cond-mat.stat-mech eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are usually trained in the space of the nodes, by\nadjusting the weights of existing links via suitable optimization protocols. We\nhere propose a radically new approach which anchors the learning process to\nreciprocal space. Specifically, the training acts on the spectral domain and\nseeks to modify the eigenvalues and eigenvectors of transfer operators in\ndirect space. The proposed method is ductile and can be tailored to return\neither linear or non-linear classifiers. Adjusting the eigenvalues, when\nfreezing the eigenvectors entries, yields performances which are superior to\nthose attained with standard methods {\\it restricted} to a operate with an\nidentical number of free parameters. Tuning the eigenvalues correspond in fact\nto performing a global training of the neural network, a procedure which\npromotes (resp. inhibits) collective modes on which an effective information\nprocessing relies. This is at variance with the usual approach to learning\nwhich implements instead a local modulation of the weights associated to\npairwise links. Interestingly, spectral learning limited to the eigenvalues\nreturns a distribution of the predicted weights which is close to that obtained\nwhen training the neural network in direct space, with no restrictions on the\nparameters to be tuned. Based on the above, it is surmised that spectral\nlearning bound to the eigenvalues could be also employed for pre-training of\ndeep neural networks, in conjunction with conventional machine-learning\nschemes. Changing the eigenvectors to a different non-orthogonal basis alters\nthe topology of the network in direct space and thus allows to export the\nspectral learning strategy to other frameworks, as e.g. reservoir computing.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 07:55:37 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 16:13:09 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Giambagli", "Lorenzo", ""], ["Buffoni", "Lorenzo", ""], ["Carletti", "Timoteo", ""], ["Nocentini", "Walter", ""], ["Fanelli", "Duccio", ""]]}, {"id": "2005.14456", "submitter": "Yixing Xu", "authors": "Yunhe Wang, Yixing Xu, Dacheng Tao", "title": "DC-NAS: Divide-and-Conquer Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most applications demand high-performance deep neural architectures costing\nlimited resources. Neural architecture searching is a way of automatically\nexploring optimal deep neural networks in a given huge search space. However,\nall sub-networks are usually evaluated using the same criterion; that is, early\nstopping on a small proportion of the training dataset, which is an inaccurate\nand highly complex approach. In contrast to conventional methods, here we\npresent a divide-and-conquer (DC) approach to effectively and efficiently\nsearch deep neural architectures. Given an arbitrary search space, we first\nextract feature representations of all sub-networks according to changes in\nparameters or output features of each layer, and then calculate the similarity\nbetween two different sampled networks based on the representations. Then, a\nk-means clustering is conducted to aggregate similar architectures into the\nsame cluster, separately executing sub-network evaluation in each cluster. The\nbest architecture in each cluster is later merged to obtain the optimal neural\narchitecture. Experimental results conducted on several benchmarks illustrate\nthat DC-NAS can overcome the inaccurate evaluation problem, achieving a\n$75.1\\%$ top-1 accuracy on the ImageNet dataset, which is higher than that of\nstate-of-the-art methods using the same search space.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 09:02:16 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Wang", "Yunhe", ""], ["Xu", "Yixing", ""], ["Tao", "Dacheng", ""]]}, {"id": "2005.14458", "submitter": "Domagoj \\'Cevid MMath", "authors": "Domagoj \\'Cevid, Loris Michel, Jeffrey N\\\"af, Nicolai Meinshausen,\n  Peter B\\\"uhlmann", "title": "Distributional Random Forests: Heterogeneity Adjustment and Multivariate\n  Distributional Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Forests (Breiman, 2001) is a successful and widely used regression and\nclassification algorithm. Part of its appeal and reason for its versatility is\nits (implicit) construction of a kernel-type weighting function on training\ndata, which can also be used for targets other than the original mean\nestimation. We propose a novel forest construction for multivariate responses\nbased on their joint conditional distribution, independent of the estimation\ntarget and the data model. It uses a new splitting criterion based on the MMD\ndistributional metric, which is suitable for detecting heterogeneity in\nmultivariate distributions. The induced weights define an estimate of the full\nconditional distribution, which in turn can be used for arbitrary and\npotentially complicated targets of interest. The method is very versatile and\nconvenient to use, as we illustrate on a wide range of examples. The code is\navailable as Python and R packages drf.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 09:05:00 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:21:04 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["\u0106evid", "Domagoj", ""], ["Michel", "Loris", ""], ["N\u00e4f", "Jeffrey", ""], ["Meinshausen", "Nicolai", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "2005.14501", "submitter": "Kevin Fauvel", "authors": "Kevin Fauvel, V\\'eronique Masson, \\'Elisa Fromont", "title": "A Performance-Explainability Framework to Benchmark Machine Learning\n  Methods: Application to Multivariate Time Series Classifiers", "comments": "In Proceedings of the IJCAI-PRICAI 2020 Workshop on Explainable\n  Artificial Intelligence. An example of this framework in use is available in\n  arXiv:2005.03645", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims to propose a new performance-explainability analytical\nframework to assess and benchmark machine learning methods. The framework\ndetails a set of characteristics that systematize the\nperformance-explainability assessment of existing machine learning methods. In\norder to illustrate the use of the framework, we apply it to benchmark the\ncurrent state-of-the-art multivariate time series classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 11:08:31 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 10:49:05 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 06:45:12 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 10:44:26 GMT"}, {"version": "v5", "created": "Fri, 18 Dec 2020 17:29:31 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Fauvel", "Kevin", ""], ["Masson", "V\u00e9ronique", ""], ["Fromont", "\u00c9lisa", ""]]}, {"id": "2005.14506", "submitter": "Philip Blagoveschensky", "authors": "Philip Blagoveschensky, Anh Huy Phan", "title": "Deep convolutional tensor network", "comments": "14 pages, 18 figures, to be published in the proceedings of NeurIPS\n  2020 Quantum tensor networks in machine learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks have achieved state of the art results in many areas,\nsupposedly due to parameter sharing, locality, and depth. Tensor networks (TNs)\nare linear algebraic representations of quantum many-body states based on their\nentanglement structure. TNs have found use in machine learning. We devise a\nnovel TN based model called Deep convolutional tensor network (DCTN) for image\nclassification, which has parameter sharing, locality, and depth. It is based\non the Entangled plaquette states (EPS) TN. We show how EPS can be implemented\nas a backpropagatable layer. We test DCTN on MNIST, FashionMNIST, and CIFAR10\ndatasets. A shallow DCTN performs well on MNIST and FashionMNIST and has a\nsmall parameter count. Unfortunately, depth increases overfitting and thus\ndecreases test accuracy. Also, DCTN of any depth performs badly on CIFAR10 due\nto overfitting. It is to be determined why. We discuss how the hyperparameters\nof DCTN affect its training and overfitting.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 11:36:52 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 21:25:00 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Blagoveschensky", "Philip", ""], ["Phan", "Anh Huy", ""]]}, {"id": "2005.14565", "submitter": "Cristiano Premebida", "authors": "G. Melotti, C. Premebida, J.J. Bird, D.R. Faria, N. Gon\\c{c}alves", "title": "Probabilistic Object Classification using CNN ML-MAP layers", "comments": "Accepted at the Workshop on Perception for Autonomous Driving (PAD),\n  European Conference on Computer Vision (ECCV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are currently the state-of-the-art for sensory perception in\nautonomous driving and robotics. However, deep models often generate\noverconfident predictions precluding proper probabilistic interpretation which\nwe argue is due to the nature of the SoftMax layer. To reduce the\noverconfidence without compromising the classification performance, we\nintroduce a CNN probabilistic approach based on distributions calculated in the\nnetwork's Logit layer. The approach enables Bayesian inference by means of ML\nand MAP layers. Experiments with calibrated and the proposed prediction layers\nare carried out on object classification using data from the KITTI database.\nResults are reported for camera ($RGB$) and LiDAR (range-view) modalities,\nwhere the new approach shows promising performance compared to SoftMax.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 13:34:15 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 11:37:53 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Melotti", "G.", ""], ["Premebida", "C.", ""], ["Bird", "J. J.", ""], ["Faria", "D. R.", ""], ["Gon\u00e7alves", "N.", ""]]}, {"id": "2005.14601", "submitter": "Jingfan Chen", "authors": "Jingfan Chen, Guanghui Zhu, Chunfeng Yuan, Yihua Huang", "title": "Semi-supervised Embedding Learning for High-dimensional Bayesian\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a broadly applied methodology to optimize the\nexpensive black-box function. Despite its success, it still faces the challenge\nfrom the high-dimensional search space. To alleviate this problem, we propose a\nnovel Bayesian optimization framework (termed SILBO), which finds a\nlow-dimensional space to perform Bayesian optimization iteratively through\nsemi-supervised dimension reduction. SILBO incorporates both labeled points and\nunlabeled points acquired from the acquisition function to guide the embedding\nspace learning. To accelerate the learning procedure, we present a randomized\nmethod for generating the projection matrix. Furthermore, to map from the\nlow-dimensional space to the high-dimensional original space, we propose two\nmapping strategies: $\\text{SILBO}_{FZ}$ and $\\text{SILBO}_{FX}$ according to\nthe evaluation overhead of the objective function. Experimental results on both\nsynthetic function and hyperparameter optimization tasks demonstrate that SILBO\noutperforms the existing state-of-the-art high-dimensional Bayesian\noptimization methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 14:37:12 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 11:48:16 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 05:36:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Jingfan", ""], ["Zhu", "Guanghui", ""], ["Yuan", "Chunfeng", ""], ["Huang", "Yihua", ""]]}, {"id": "2005.14605", "submitter": "Alexander Borisenko", "authors": "Oleksandr Borysenko and Maksym Byshkin", "title": "CoolMomentum: A Method for Stochastic Optimization by Langevin Dynamics\n  with Simulated Annealing", "comments": "9 pages, 2 figures", "journal-ref": "Borysenko, O., Byshkin, M. CoolMomentum: a method for stochastic\n  optimization by Langevin dynamics with simulated annealing. Sci Rep 11, 10705\n  (2021)", "doi": "10.1038/s41598-021-90144-3", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning applications require global optimization of non-convex\nobjective functions, which have multiple local minima. The same problem is\noften found in physical simulations and may be resolved by the methods of\nLangevin dynamics with Simulated Annealing, which is a well-established\napproach for minimization of many-particle potentials. This analogy provides\nuseful insights for non-convex stochastic optimization in machine learning.\nHere we find that integration of the discretized Langevin equation gives a\ncoordinate updating rule equivalent to the famous Momentum optimization\nalgorithm. As a main result, we show that a gradual decrease of the momentum\ncoefficient from the initial value close to unity until zero is equivalent to\napplication of Simulated Annealing or slow cooling, in physical terms. Making\nuse of this novel approach, we propose CoolMomentum -- a new stochastic\noptimization method. Applying Coolmomentum to optimization of Resnet-20 on\nCifar-10 dataset and Efficientnet-B0 on Imagenet, we demonstrate that it is\nable to achieve high accuracies.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 14:44:24 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 15:26:37 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Borysenko", "Oleksandr", ""], ["Byshkin", "Maksym", ""]]}, {"id": "2005.14611", "submitter": "Lea Sch\\\"onherr", "authors": "Sina D\\\"aubener, Lea Sch\\\"onherr, Asja Fischer, Dorothea Kolossa", "title": "Detecting Adversarial Examples for Speech Recognition via Uncertainty\n  Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems and also, specifically, automatic speech recognition\n(ASR) systems are vulnerable against adversarial attacks, where an attacker\nmaliciously changes the input. In the case of ASR systems, the most interesting\ncases are targeted attacks, in which an attacker aims to force the system into\nrecognizing given target transcriptions in an arbitrary audio sample. The\nincreasing number of sophisticated, quasi imperceptible attacks raises the\nquestion of countermeasures. In this paper, we focus on hybrid ASR systems and\ncompare four acoustic models regarding their ability to indicate uncertainty\nunder attack: a feed-forward neural network and three neural networks\nspecifically designed for uncertainty quantification, namely a Bayesian neural\nnetwork, Monte Carlo dropout, and a deep ensemble. We employ uncertainty\nmeasures of the acoustic model to construct a simple one-class classification\nmodel for assessing whether inputs are benign or adversarial. Based on this\napproach, we are able to detect adversarial examples with an area under the\nreceiving operator curve score of more than 0.99. The neural networks for\nuncertainty quantification simultaneously diminish the vulnerability to the\nattack, which is reflected in a lower recognition accuracy of the malicious\ntarget text in comparison to a standard hybrid ASR system.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 19:31:02 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 16:37:01 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["D\u00e4ubener", "Sina", ""], ["Sch\u00f6nherr", "Lea", ""], ["Fischer", "Asja", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "2005.14612", "submitter": "Zhengyang Wang", "authors": "Meng Liu, Zhengyang Wang, Shuiwang Ji", "title": "Non-Local Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern graph neural networks (GNNs) learn node embeddings through multilayer\nlocal aggregation and achieve great success in applications on assortative\ngraphs. However, tasks on disassortative graphs usually require non-local\naggregation. In this work, we propose a simple yet effective non-local\naggregation framework with an efficient attention-guided sorting for GNNs.\nBased on it, we develop various non-local GNNs. We perform thorough experiments\nto analyze disassortative graph datasets and evaluate our non-local GNNs.\nExperimental results demonstrate that our non-local GNNs significantly\noutperform previous state-of-the-art methods on six benchmark datasets of\ndisassortative graphs, in terms of both model performance and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 14:50:27 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Liu", "Meng", ""], ["Wang", "Zhengyang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2005.14617", "submitter": "Manuel Roehrl", "authors": "Manuel A. Roehrl, Thomas A. Runkler, Veronika Brandtstetter, Michel\n  Tokic, Stefan Obermayer", "title": "Modeling System Dynamics with Physics-Informed Neural Networks Based on\n  Lagrangian Mechanics", "comments": "Accepted for publication at the 21st IFAC World Congress 2020", "journal-ref": null, "doi": "10.1016/j.ifacol.2020.12.2182", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying accurate dynamic models is required for the simulation and\ncontrol of various technical systems. In many important real-world\napplications, however, the two main modeling approaches often fail to meet\nrequirements: first principles methods suffer from high bias, whereas\ndata-driven modeling tends to have high variance. Additionally, purely\ndata-based models often require large amounts of data and are often difficult\nto interpret. In this paper, we present physics-informed neural ordinary\ndifferential equations (PINODE), a hybrid model that combines the two modeling\ntechniques to overcome the aforementioned problems. This new approach directly\nincorporates the equations of motion originating from the Lagrange Mechanics\ninto a deep neural network structure. Thus, we can integrate prior physics\nknowledge where it is available and use function approximation--e. g., neural\nnetworks--where it is not. The method is tested with a forward model of a\nreal-world physical system with large uncertainties. The resulting model is\naccurate and data-efficient while ensuring physical plausibility. With this, we\ndemonstrate a method that beneficially merges physical insight with real data.\nOur findings are of interest for model-based control and system identification\nof mechanical systems.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 15:10:43 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Roehrl", "Manuel A.", ""], ["Runkler", "Thomas A.", ""], ["Brandtstetter", "Veronika", ""], ["Tokic", "Michel", ""], ["Obermayer", "Stefan", ""]]}, {"id": "2005.14621", "submitter": "Ibrahim Alabdulmohsin", "authors": "Ibrahim Alabdulmohsin", "title": "Fair Classification via Unconstrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving the Bayes optimal binary classification rule subject to group\nfairness constraints is known to be reducible, in some cases, to learning a\ngroup-wise thresholding rule over the Bayes regressor. In this paper, we extend\nthis result by proving that, in a broader setting, the Bayes optimal fair\nlearning rule remains a group-wise thresholding rule over the Bayes regressor\nbut with a (possible) randomization at the thresholds. This provides a stronger\njustification to the post-processing approach in fair classification, in which\n(1) a predictor is learned first, after which (2) its output is adjusted to\nremove bias. We show how the post-processing rule in this two-stage approach\ncan be learned quite efficiently by solving an unconstrained optimization\nproblem. The proposed algorithm can be applied to any black-box machine\nlearning model, such as deep neural networks, random forests and support vector\nmachines. In addition, it can accommodate many fairness criteria that have been\npreviously proposed in the literature, such as equalized odds and statistical\nparity. We prove that the algorithm is Bayes consistent and motivate it,\nfurthermore, via an impossibility result that quantifies the tradeoff between\naccuracy and fairness across multiple demographic groups. Finally, we conclude\nby validating the algorithm on the Adult benchmark dataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 11:29:05 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Alabdulmohsin", "Ibrahim", ""]]}, {"id": "2005.14635", "submitter": "David Aparicio", "authors": "Joana Lorenz, Maria In\\^es Silva, David Apar\\'icio, Jo\\~ao Tiago\n  Ascens\\~ao, Pedro Bizarro", "title": "Machine learning methods to detect money laundering in the Bitcoin\n  blockchain in the presence of label scarcity", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year, criminals launder billions of dollars acquired from serious\nfelonies (e.g., terrorism, drug smuggling, or human trafficking) harming\ncountless people and economies. Cryptocurrencies, in particular, have developed\nas a haven for money laundering activity. Machine Learning can be used to\ndetect these illicit patterns. However, labels are so scarce that traditional\nsupervised algorithms are inapplicable. Here, we address money laundering\ndetection assuming minimal access to labels. First, we show that existing\nstate-of-the-art solutions using unsupervised anomaly detection methods are\ninadequate to detect the illicit patterns in a real Bitcoin transaction\ndataset. Then, we show that our proposed active learning solution is capable of\nmatching the performance of a fully supervised baseline by using just 5\\% of\nthe labels. This solution mimics a typical real-life situation in which a\nlimited number of labels can be acquired through manual annotation by experts.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 15:52:48 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Lorenz", "Joana", ""], ["Silva", "Maria In\u00eas", ""], ["Apar\u00edcio", "David", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2005.14658", "submitter": "Cristi\\'an Bravo", "authors": "Luisa Roa, Alejandro Correa-Bahnsen, Gabriel Suarez, Fernando\n  Cort\\'es-Tejada, Mar\\'ia A. Luque and Cristi\\'an Bravo", "title": "Super-App Behavioral Patterns in Credit Risk Models: Financial,\n  Statistical and Regulatory Implications", "comments": "Accepted - v2. 25 pages", "journal-ref": "Expert Systems with Applications: 114486 (2020)", "doi": "10.1016/j.eswa.2020.114486", "report-no": null, "categories": "q-fin.GN cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we present the impact of alternative data that originates from\nan app-based marketplace, in contrast to traditional bureau data, upon credit\nscoring models. These alternative data sources have shown themselves to be\nimmensely powerful in predicting borrower behavior in segments traditionally\nunderserved by banks and financial institutions. Our results, validated across\ntwo countries, show that these new sources of data are particularly useful for\npredicting financial behavior in low-wealth and young individuals, who are also\nthe most likely to engage with alternative lenders. Furthermore, using the\nTreeSHAP method for Stochastic Gradient Boosting interpretation, our results\nalso revealed interesting non-linear trends in the variables originating from\nthe app, which would not normally be available to traditional banks. Our\nresults represent an opportunity for technology companies to disrupt\ntraditional banking by correctly identifying alternative data sources and\nhandling this new information properly. At the same time alternative data must\nbe carefully validated to overcome regulatory hurdles across diverse\njurisdictions.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:32:03 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:51:22 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Roa", "Luisa", ""], ["Correa-Bahnsen", "Alejandro", ""], ["Suarez", "Gabriel", ""], ["Cort\u00e9s-Tejada", "Fernando", ""], ["Luque", "Mar\u00eda A.", ""], ["Bravo", "Cristi\u00e1n", ""]]}, {"id": "2005.14670", "submitter": "Florian Ziel", "authors": "Florian Ziel", "title": "The energy distance for ensemble and scenario reduction", "comments": "Accepted for publication in Philosophical Transactions A", "journal-ref": null, "doi": "10.1098/rsta.2019.0431", "report-no": null, "categories": "stat.ML cs.LG math.OC q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario reduction techniques are widely applied for solving sophisticated\ndynamic and stochastic programs, especially in energy and power systems, but\nalso used in probabilistic forecasting, clustering and estimating generative\nadversarial networks (GANs). We propose a new method for ensemble and scenario\nreduction based on the energy distance which is a special case of the maximum\nmean discrepancy (MMD). We discuss the choice of energy distance in detail,\nespecially in comparison to the popular Wasserstein distance which is\ndominating the scenario reduction literature. The energy distance is a metric\nbetween probability measures that allows for powerful tests for equality of\narbitrary multivariate distributions or independence. Thanks to the latter, it\nis a suitable candidate for ensemble and scenario reduction problems. The\ntheoretical properties and considered examples indicate clearly that the\nreduced scenario sets tend to exhibit better statistical properties for the\nenergy distance than a corresponding reduction with respect to the Wasserstein\ndistance. We show applications to a Bernoulli random walk and two real data\nbased examples for electricity demand profiles and day-ahead electricity\nprices.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:52:23 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 18:46:10 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ziel", "Florian", ""]]}, {"id": "2005.14679", "submitter": "Roberto Calandra", "authors": "Mike Lambeta and Po-Wei Chou and Stephen Tian and Brian Yang and\n  Benjamin Maloon and Victoria Rose Most and Dave Stroud and Raymond Santos and\n  Ahmad Byagowi and Gregg Kammerer and Dinesh Jayaraman and Roberto Calandra", "title": "DIGIT: A Novel Design for a Low-Cost Compact High-Resolution Tactile\n  Sensor with Application to In-Hand Manipulation", "comments": "8 pages, published in the IEEE Robotics and Automation Letters (RA-L)", "journal-ref": null, "doi": "10.1109/LRA.2020.2977257", "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite decades of research, general purpose in-hand manipulation remains one\nof the unsolved challenges of robotics. One of the contributing factors that\nlimit current robotic manipulation systems is the difficulty of precisely\nsensing contact forces -- sensing and reasoning about contact forces are\ncrucial to accurately control interactions with the environment. As a step\ntowards enabling better robotic manipulation, we introduce DIGIT, an\ninexpensive, compact, and high-resolution tactile sensor geared towards in-hand\nmanipulation. DIGIT improves upon past vision-based tactile sensors by\nminiaturizing the form factor to be mountable on multi-fingered hands, and by\nproviding several design improvements that result in an easier, more repeatable\nmanufacturing process, and enhanced reliability. We demonstrate the\ncapabilities of the DIGIT sensor by training deep neural network model-based\ncontrollers to manipulate glass marbles in-hand with a multi-finger robotic\nhand. To provide the robotic community access to reliable and low-cost tactile\nsensors, we open-source the DIGIT design at https://digit.ml/.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:07:54 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Lambeta", "Mike", ""], ["Chou", "Po-Wei", ""], ["Tian", "Stephen", ""], ["Yang", "Brian", ""], ["Maloon", "Benjamin", ""], ["Most", "Victoria Rose", ""], ["Stroud", "Dave", ""], ["Santos", "Raymond", ""], ["Byagowi", "Ahmad", ""], ["Kammerer", "Gregg", ""], ["Jayaraman", "Dinesh", ""], ["Calandra", "Roberto", ""]]}, {"id": "2005.14707", "submitter": "Charles Jin", "authors": "Charles Jin, Martin Rinard", "title": "Learning From Context-Agnostic Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for synthesizing training data given only a single\nexample of each class. Rather than learn over a large but fixed dataset of\nexamples, we generate our entire training set using only the synthetic examples\nprovided. The goal is to learn a classifier that generalizes to a non-synthetic\ndomain without pretraining or fine-tuning on any real world data. We evaluate\nour approach by training neural networks for two standard benchmarks for\nreal-world image classification: on the GTSRB traffic sign recognition\nbenchmark, we achieve 96% test accuracy using only one clean example of each\nsign on a blank background; on the MNIST handwritten digit benchmark, we\nachieve 90% test accuracy using a single example of each digit taken from a\ncomputer font. Our performance is competitive with state-of-the-art results\nfrom the few-shot learning and domain transfer literature, while using\nsignificantly less data.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:53:25 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 22:50:20 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jin", "Charles", ""], ["Rinard", "Martin", ""]]}, {"id": "2005.14708", "submitter": "Prasanna Sanjay Raut", "authors": "Prasanna Sanjay Raut, Omid Sadeghi and Maryam Fazel", "title": "Online DR-Submodular Maximization with Stochastic Cumulative Constraints", "comments": "To appear in proceedings of AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider online continuous DR-submodular maximization with\nlinear stochastic long-term constraints. Compared to the prior work on online\nsubmodular maximization, our setting introduces the extra complication of\nstochastic linear constraint functions that are i.i.d. generated at each round.\nTo be precise, at step $t\\in\\{1,\\dots,T\\}$, a DR-submodular utility function\n$f_t(\\cdot)$ and a constraint vector $p_t$, i.i.d. generated from an unknown\ndistribution with mean $p$, are revealed after committing to an action $x_t$\nand we aim to maximize the overall utility while the expected cumulative\nresource consumption $\\sum_{t=1}^T \\langle p,x_t\\rangle$ is below a fixed\nbudget $B_T$. Stochastic long-term constraints arise naturally in applications\nwhere there is a limited budget or resource available and resource consumption\nat each step is governed by stochastically time-varying environments. We\npropose the Online Lagrangian Frank-Wolfe (OLFW) algorithm to solve this class\nof online problems. We analyze the performance of the OLFW algorithm and we\nobtain sub-linear regret bounds as well as sub-linear cumulative constraint\nviolation bounds, both in expectation and with high probability.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:55:42 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 02:02:50 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 14:45:10 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Raut", "Prasanna Sanjay", ""], ["Sadeghi", "Omid", ""], ["Fazel", "Maryam", ""]]}, {"id": "2005.14713", "submitter": "Ashudeep Singh", "authors": "Marco Morik, Ashudeep Singh, Jessica Hong, Thorsten Joachims", "title": "Controlling Fairness and Bias in Dynamic Learning-to-Rank", "comments": "First two authors contributed equally. In Proceedings of the 43rd\n  International ACM SIGIR Conference on Research and Development in Information\n  Retrieval 2020", "journal-ref": null, "doi": "10.1145/3397271.3401100", "report-no": null, "categories": "cs.IR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rankings are the primary interface through which many online platforms match\nusers to items (e.g. news, products, music, video). In these two-sided markets,\nnot only the users draw utility from the rankings, but the rankings also\ndetermine the utility (e.g. exposure, revenue) for the item providers (e.g.\npublishers, sellers, artists, studios). It has already been noted that\nmyopically optimizing utility to the users, as done by virtually all\nlearning-to-rank algorithms, can be unfair to the item providers. We,\ntherefore, present a learning-to-rank approach for explicitly enforcing\nmerit-based fairness guarantees to groups of items (e.g. articles by the same\npublisher, tracks by the same artist). In particular, we propose a learning\nalgorithm that ensures notions of amortized group fairness, while\nsimultaneously learning the ranking function from implicit feedback data. The\nalgorithm takes the form of a controller that integrates unbiased estimators\nfor both fairness and utility, dynamically adapting both as more data becomes\navailable. In addition to its rigorous theoretical foundation and convergence\nguarantees, we find empirically that the algorithm is highly practical and\nrobust.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:57:56 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Morik", "Marco", ""], ["Singh", "Ashudeep", ""], ["Hong", "Jessica", ""], ["Joachims", "Thorsten", ""]]}, {"id": "2005.14717", "submitter": "Lydia Zakynthinou", "authors": "Anamay Chaturvedi, Huy Nguyen, Lydia Zakynthinou", "title": "Differentially Private Decomposable Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of differentially private constrained maximization of\ndecomposable submodular functions. A submodular function is decomposable if it\ntakes the form of a sum of submodular functions. The special case of maximizing\na monotone, decomposable submodular function under cardinality constraints is\nknown as the Combinatorial Public Projects (CPP) problem [Papadimitriou et al.,\n2008]. Previous work by Gupta et al. [2010] gave a differentially private\nalgorithm for the CPP problem. We extend this work by designing differentially\nprivate algorithms for both monotone and non-monotone decomposable submodular\nmaximization under general matroid constraints, with competitive utility\nguarantees. We complement our theoretical bounds with experiments demonstrating\nempirical performance, which improves over the differentially private\nalgorithms for the general case of submodular maximization and is close to the\nperformance of non-private algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:59:46 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Chaturvedi", "Anamay", ""], ["Nguyen", "Huy", ""], ["Zakynthinou", "Lydia", ""]]}]