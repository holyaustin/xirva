[{"id": "2106.00006", "submitter": "Georgios Giasemidis Dr", "authors": "Stephen Haben, Siddharth Arora, Georgios Giasemidis, Marcus Voss,\n  Danica Vukadinovic Greetham", "title": "Review of Low-Voltage Load Forecasting: Methods, Applications, and\n  Recommendations", "comments": "33 pages, 5 figures, review paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased digitalisation and monitoring of the energy system opens up\nnumerous opportunities % and solutions which can help to decarbonise the energy\nsystem. Applications on low voltage (LV), localised networks, such as community\nenergy markets and smart storage will facilitate decarbonisation, but they will\nrequire advanced control and management. Reliable forecasting will be a\nnecessary component of many of these systems to anticipate key features and\nuncertainties. Despite this urgent need, there has not yet been an extensive\ninvestigation into the current state-of-the-art of low voltage level forecasts,\nother than at the smart meter level. This paper aims to provide a comprehensive\noverview of the landscape, current approaches, core applications, challenges\nand recommendations. Another aim of this paper is to facilitate the continued\nimprovement and advancement in this area. To this end, the paper also surveys\nsome of the most relevant and promising trends. It establishes an open,\ncommunity-driven list of the known LV level open datasets to encourage further\nresearch and development.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 14:18:43 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Haben", "Stephen", ""], ["Arora", "Siddharth", ""], ["Giasemidis", "Georgios", ""], ["Voss", "Marcus", ""], ["Greetham", "Danica Vukadinovic", ""]]}, {"id": "2106.00058", "submitter": "Bahareh Tolooshams", "authors": "Bahareh Tolooshams and Demba Ba", "title": "PUDLE: Implicit Acceleration of Dictionary Learning by Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dictionary learning problem, representing data as a combination of few\natoms, has long stood as a popular method for learning representations in\nstatistics and signal processing. The most popular dictionary learning\nalgorithm alternates between sparse coding and dictionary update steps, and a\nrich literature has studied its theoretical convergence. The growing popularity\nof neurally plausible unfolded sparse coding networks has led to the empirical\nfinding that backpropagation through such networks performs dictionary\nlearning. This paper offers the first theoretical proof for these empirical\nresults through PUDLE, a Provable Unfolded Dictionary LEarning method. We\nhighlight the impact of loss, unfolding, and backpropagation on convergence. We\ndiscover an implicit acceleration: as a function of unfolding, the\nbackpropagated gradient converges faster and is more accurate than the gradient\nfrom alternating minimization. We complement our findings through synthetic and\nimage denoising experiments. The findings support the use of accelerated deep\nlearning optimizers and unfolded networks for dictionary learning.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 18:49:58 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Tolooshams", "Bahareh", ""], ["Ba", "Demba", ""]]}, {"id": "2106.00072", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Alexander Bukharin, Liyan Xie, Shihao Yang, Pinar\n  Keskinocak, Yao Xie", "title": "Early Detection of COVID-19 Hotspots Using Spatio-Temporal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Centers for Disease Control and Prevention (CDC) has worked\nwith other federal agencies to identify counties with increasing coronavirus\ndisease 2019 (COVID-19) incidence (hotspots) and offers support to local health\ndepartments to limit the spread of the disease. Understanding the\nspatio-temporal dynamics of hotspot events is of great importance to support\npolicy decisions and prevent large-scale outbreaks. This paper presents a\nspatio-temporal Bayesian framework for early detection of COVID-19 hotspots (at\nthe county level) in the United States. We assume both the observed number of\ncases and hotspots depend on a class of latent random variables, which encode\nthe underlying spatio-temporal dynamics of the transmission of COVID-19. Such\nlatent variables follow a zero-mean Gaussian process, whose covariance is\nspecified by a non-stationary kernel function. The most salient feature of our\nkernel function is that deep neural networks are introduced to enhance the\nmodel's representative power while still enjoying the interpretability of the\nkernel. We derive a sparse model and fit the model using a variational learning\nstrategy to circumvent the computational intractability for large data sets.\nOur model demonstrates better interpretability and superior hotspot-detection\nperformance compared to other baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 19:28:17 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zhu", "Shixiang", ""], ["Bukharin", "Alexander", ""], ["Xie", "Liyan", ""], ["Yang", "Shihao", ""], ["Keskinocak", "Pinar", ""], ["Xie", "Yao", ""]]}, {"id": "2106.00075", "submitter": "Antonio Moretti", "authors": "Antonio Khalil Moretti, Liyi Zhang, Christian A. Naesseth, Hadiah\n  Venner, David Blei, Itsik Pe'er", "title": "Variational Combinatorial Sequential Monte Carlo Methods for Bayesian\n  Phylogenetic Inference", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian phylogenetic inference is often conducted via local or sequential\nsearch over topologies and branch lengths using algorithms such as random-walk\nMarkov chain Monte Carlo (MCMC) or Combinatorial Sequential Monte Carlo (CSMC).\nHowever, when MCMC is used for evolutionary parameter learning, convergence\nrequires long runs with inefficient exploration of the state space. We\nintroduce Variational Combinatorial Sequential Monte Carlo (VCSMC), a powerful\nframework that establishes variational sequential search to learn distributions\nover intricate combinatorial structures. We then develop nested CSMC, an\nefficient proposal distribution for CSMC and prove that nested CSMC is an exact\napproximation to the (intractable) locally optimal proposal. We use nested CSMC\nto define a second objective, VNCSMC which yields tighter lower bounds than\nVCSMC. We show that VCSMC and VNCSMC are computationally efficient and explore\nhigher probability spaces than existing methods on a range of tasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 19:44:24 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 19:23:23 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Moretti", "Antonio Khalil", ""], ["Zhang", "Liyi", ""], ["Naesseth", "Christian A.", ""], ["Venner", "Hadiah", ""], ["Blei", "David", ""], ["Pe'er", "Itsik", ""]]}, {"id": "2106.00092", "submitter": "Kushal Chakrabarti", "authors": "Kushal Chakrabarti, Nikhil Chopra", "title": "Generalized AdaGrad (G-AdaGrad) and Adam: A State-Space Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerated gradient-based methods are being extensively used for solving\nnon-convex machine learning problems, especially when the data points are\nabundant or the available data is distributed across several agents. Two of the\nprominent accelerated gradient algorithms are AdaGrad and Adam. AdaGrad is the\nsimplest accelerated gradient method, which is particularly effective for\nsparse data. Adam has been shown to perform favorably in deep learning problems\ncompared to other methods. In this paper, we propose a new fast optimizer,\nGeneralized AdaGrad (G-AdaGrad), for accelerating the solution of potentially\nnon-convex machine learning problems. Specifically, we adopt a state-space\nperspective for analyzing the convergence of gradient acceleration algorithms,\nnamely G-AdaGrad and Adam, in machine learning. Our proposed state-space models\nare governed by ordinary differential equations. We present simple convergence\nproofs of these two algorithms in the deterministic settings with minimal\nassumptions. Our analysis also provides intuition behind improving upon\nAdaGrad's convergence rate. We provide empirical results on MNIST dataset to\nreinforce our claims on the convergence and performance of G-AdaGrad and Adam.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 20:30:25 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Chakrabarti", "Kushal", ""], ["Chopra", "Nikhil", ""]]}, {"id": "2106.00115", "submitter": "Waleed Mustafa", "authors": "Waleed Mustafa, Yunwen Lei, Antoine Ledent, Marius Kloft", "title": "Fine-grained Generalization Analysis of Structured Output Prediction", "comments": "To appearn in IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning we often encounter structured output prediction problems\n(SOPPs), i.e. problems where the output space admits a rich internal structure.\nApplication domains where SOPPs naturally occur include natural language\nprocessing, speech recognition, and computer vision. Typical SOPPs have an\nextremely large label set, which grows exponentially as a function of the size\nof the output. Existing generalization analysis implies generalization bounds\nwith at least a square-root dependency on the cardinality $d$ of the label set,\nwhich can be vacuous in practice. In this paper, we significantly improve the\nstate of the art by developing novel high-probability bounds with a logarithmic\ndependency on $d$. Moreover, we leverage the lens of algorithmic stability to\ndevelop generalization bounds in expectation without any dependency on $d$. Our\nresults therefore build a solid theoretical foundation for learning in\nlarge-scale SOPPs. Furthermore, we extend our results to learning with weakly\ndependent data.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 21:44:14 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Mustafa", "Waleed", ""], ["Lei", "Yunwen", ""], ["Ledent", "Antoine", ""], ["Kloft", "Marius", ""]]}, {"id": "2106.00120", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep\n  Probabilistic Models", "comments": "arXiv admin note: text overlap with arXiv:1811.06622", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic deep learning is deep learning that accounts for uncertainty,\nboth model uncertainty and data uncertainty. It is based on the use of\nprobabilistic models and deep neural networks. We distinguish two approaches to\nprobabilistic deep learning: probabilistic neural networks and deep\nprobabilistic models. The former employs deep neural networks that utilize\nprobabilistic layers which can represent and process uncertainty; the latter\nuses probabilistic models that incorporate deep neural network components which\ncapture complex non-linear stochastic relationships between the random\nvariables. We discuss some major examples of each approach including Bayesian\nneural networks and mixture density networks (for probabilistic neural\nnetworks), and variational autoencoders, deep Gaussian processes and deep mixed\neffects models (for deep probabilistic models). TensorFlow Probability is a\nlibrary for probabilistic modeling and inference which can be used for both\napproaches of probabilistic deep learning. We include its code examples for\nillustration.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 22:13:21 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 00:45:23 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 17:43:40 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "2106.00154", "submitter": "Joao Marques-Silva", "authors": "Joao Marques-Silva, Thomas Gerspacher, Martin Cooper, Alexey Ignatiev,\n  Nina Narodytska", "title": "Explanations for Monotonic Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many classification tasks there is a requirement of monotonicity.\nConcretely, if all else remains constant, increasing (resp. decreasing) the\nvalue of one or more features must not decrease (resp. increase) the value of\nthe prediction. Despite comprehensive efforts on learning monotonic\nclassifiers, dedicated approaches for explaining monotonic classifiers are\nscarce and classifier-specific. This paper describes novel algorithms for the\ncomputation of one formal explanation of a (black-box) monotonic classifier.\nThese novel algorithms are polynomial in the run time complexity of the\nclassifier and the number of features. Furthermore, the paper presents a\npractically efficient model-agnostic algorithm for enumerating formal\nexplanations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 00:14:12 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Marques-Silva", "Joao", ""], ["Gerspacher", "Thomas", ""], ["Cooper", "Martin", ""], ["Ignatiev", "Alexey", ""], ["Narodytska", "Nina", ""]]}, {"id": "2106.00173", "submitter": "Brandon Victor", "authors": "Brandon Victor, Aiden Nibali, Zhen He, David L. Carey", "title": "Enhancing Trajectory Prediction using Sparse Outputs: Application to\n  Team Sports", "comments": "10 pages (not including references), 7 figures. Published in Neural\n  Computing and Applications on 20 March 2021", "journal-ref": null, "doi": "10.1007/s00521-021-05888-w", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sophisticated trajectory prediction models that effectively mimic team\ndynamics have many potential uses for sports coaches, broadcasters and\nspectators. However, through experiments on soccer data we found that it can be\nsurprisingly challenging to train a deep learning model for player trajectory\nprediction which outperforms linear extrapolation on average distance between\npredicted and true future trajectories. We propose and test a novel method for\nimproving training by predicting a sparse trajectory and interpolating using\nconstant acceleration, which improves performance for several models. This\ninterpolation can also be used on models that aren't trained with sparse\noutputs, and we find that this consistently improves performance for all tested\nmodels. Additionally, we find that the accuracy of predicted trajectories for a\nsubset of players can be improved by conditioning on the full trajectories of\nthe other players, and that this is further improved when combined with sparse\npredictions. We also propose a novel architecture using graph networks and\nmulti-head attention (GraN-MA) which achieves better performance than other\ntested state-of-the-art models on our dataset and is trivially adapted for both\nsparse trajectories and full-trajectory conditioned trajectory prediction.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 01:43:19 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Victor", "Brandon", ""], ["Nibali", "Aiden", ""], ["He", "Zhen", ""], ["Carey", "David L.", ""]]}, {"id": "2106.00175", "submitter": "Kumail Abbas", "authors": "Kumail Abbas and Sajjad Haider", "title": "Duckworth-Lewis-Stern Method Comparison with Machine Learning Approach", "comments": "The paper has been published in the conference of Frontiers of\n  Information Technology 2019", "journal-ref": "2019 International Conference on Frontiers of Information\n  Technology (FIT), 2019, pp. 197-1975", "doi": "10.1109/FIT47737.2019.00045", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an analysis of the Duckworth-Lewis-Stern (DLS) method for\nOne Day International (ODI) cricket matches. The accuracy of the DLS method is\ncompared against various supervised learning algorithms for result prediction.\nThe result of a cricket match is predicted during the second inning. The paper\nalso optimized DLS resource table which is used in the Duckworth-Lewis (D/L)\nformula to increase its predictive power. Finally, an Unpredictability Index is\ndeveloped that ranks different cricket playing nations according to how\nunpredictable they are while playing an ODI match.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 01:48:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Abbas", "Kumail", ""], ["Haider", "Sajjad", ""]]}, {"id": "2106.00225", "submitter": "Zhen Lin", "authors": "Zhen Lin, Shubhendu Trivedi, Jimeng Sun", "title": "Locally Valid and Discriminative Confidence Intervals for Deep Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Crucial for building trust in deep learning models for critical real-world\napplications is efficient and theoretically sound uncertainty quantification, a\ntask that continues to be challenging. Useful uncertainty information is\nexpected to have two key properties: It should be valid (guaranteeing coverage)\nand discriminative (more uncertain when the expected risk is high). Moreover,\nwhen combined with deep learning (DL) methods, it should be scalable and affect\nthe DL model performance minimally. Most existing Bayesian methods lack\nfrequentist coverage guarantees and usually affect model performance. The few\navailable frequentist methods are rarely discriminative and/or violate coverage\nguarantees due to unrealistic assumptions. Moreover, many methods are expensive\nor require substantial modifications to the base neural network. Building upon\nrecent advances in conformal prediction and leveraging the classical idea of\nkernel regression, we propose Locally Valid and Discriminative confidence\nintervals (LVD), a simple, efficient and lightweight method to construct\ndiscriminative confidence intervals (CIs) for almost any DL model. With no\nassumptions on the data distribution, such CIs also offer finite-sample local\ncoverage guarantees (contrasted to the simpler marginal coverage). Using a\ndiverse set of datasets, we empirically verify that besides being the only\nlocally valid method, LVD also exceeds or matches the performance (including\ncoverage rate and prediction accuracy) of existing uncertainty quantification\nmethods, while offering additional benefits in scalability and flexibility.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 04:39:56 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Lin", "Zhen", ""], ["Trivedi", "Shubhendu", ""], ["Sun", "Jimeng", ""]]}, {"id": "2106.00293", "submitter": "Antonios Varvitsiotis", "authors": "Yong Sheng Soh, Antonios Varvitsiotis", "title": "A Non-commutative Extension of Lee-Seung's Algorithm for Positive\n  Semidefinite Factorizations", "comments": "Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a matrix $X\\in \\mathbb{R}_+^{m\\times n}$ with nonnegative entries, a\nPositive Semidefinite (PSD) factorization of $X$ is a collection of $r \\times\nr$-dimensional PSD matrices $\\{A_i\\}$ and $\\{B_j\\}$ satisfying $X_{ij}=\n\\mathrm{tr}(A_i B_j)$ for all $\\ i\\in [m],\\ j\\in [n]$. PSD factorizations are\nfundamentally linked to understanding the expressiveness of semidefinite\nprograms as well as the power and limitations of quantum resources in\ninformation theory. The PSD factorization task generalizes the Non-negative\nMatrix Factorization (NMF) problem where we seek a collection of\n$r$-dimensional nonnegative vectors $\\{a_i\\}$ and $\\{b_j\\}$ satisfying $X_{ij}=\na_i^\\top b_j$, for all $i\\in [m],\\ j\\in [n]$ -- one can recover the latter\nproblem by choosing matrices in the PSD factorization to be diagonal. The most\nwidely used algorithm for computing NMFs of a matrix is the Multiplicative\nUpdate algorithm developed by Lee and Seung, in which nonnegativity of the\nupdates is preserved by scaling with positive diagonal matrices. In this paper,\nwe describe a non-commutative extension of Lee-Seung's algorithm, which we call\nthe Matrix Multiplicative Update (MMU) algorithm, for computing PSD\nfactorizations. The MMU algorithm ensures that updates remain PSD by congruence\nscaling with the matrix geometric mean of appropriate PSD matrices, and it\nretains the simplicity of implementation that Lee-Seung's algorithm enjoys.\nBuilding on the Majorization-Minimization framework, we show that under our\nupdate scheme the squared loss objective is non-increasing and fixed points\ncorrespond to critical points. The analysis relies on Lieb's Concavity Theorem.\nBeyond PSD factorizations, we use the MMU algorithm as a primitive to calculate\nblock-diagonal PSD factorizations and tensor PSD factorizations. We demonstrate\nthe utility of our method with experiments on real and synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:55:09 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Soh", "Yong Sheng", ""], ["Varvitsiotis", "Antonios", ""]]}, {"id": "2106.00311", "submitter": "Marine Le Morvan", "authors": "Marine Le Morvan (PARIETAL, IJCLab), Julie Josse (CRISAM), Erwan\n  Scornet (CMAP), Ga\\\"el Varoquaux (PARIETAL)", "title": "What's a good imputation to predict with missing values?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to learn a good predictor on data with missing values? Most efforts focus\non first imputing as well as possible and second learning on the completed data\nto predict the outcome. Yet, this widespread practice has no theoretical\ngrounding. Here we show that for almost all imputation functions, an\nimpute-then-regress procedure with a powerful learner is Bayes optimal. This\nresult holds for all missing-values mechanisms, in contrast with the classic\nstatistical results that require missing-at-random settings to use imputation\nin probabilistic modeling. Moreover, it implies that perfect conditional\nimputation may not be needed for good prediction asymptotically. In fact, we\nshow that on perfectly imputed data the best regression function will generally\nbe discontinuous, which makes it hard to learn. Crafting instead the imputation\nso as to leave the regression function unchanged simply shifts the problem to\nlearning discontinuous imputations. Rather, we suggest that it is easier to\nlearn imputation and regression jointly. We propose such a procedure, adapting\nNeuMiss, a neural network capturing the conditional links across observed and\nunobserved variables whatever the missing-value pattern. Experiments confirm\nthat joint imputation and regression through NeuMiss is better than various two\nstep procedures in our experiments with finite number of samples.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:40:30 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Morvan", "Marine Le", "", "PARIETAL, IJCLab"], ["Josse", "Julie", "", "CRISAM"], ["Scornet", "Erwan", "", "CMAP"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL"]]}, {"id": "2106.00322", "submitter": "Bahar Taskesen", "authors": "Bahar Taskesen, Man-Chung Yue, Jose Blanchet, Daniel Kuhn, Viet Anh\n  Nguyen", "title": "Sequential Domain Adaptation by Synthesizing Distributionally Robust\n  Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least squares estimators, when trained on a few target domain samples, may\npredict poorly. Supervised domain adaptation aims to improve the predictive\naccuracy by exploiting additional labeled training samples from a source\ndistribution that is close to the target distribution. Given available data, we\ninvestigate novel strategies to synthesize a family of least squares estimator\nexperts that are robust with regard to moment conditions. When these moment\nconditions are specified using Kullback-Leibler or Wasserstein-type\ndivergences, we can find the robust estimators efficiently using convex\noptimization. We use the Bernstein online aggregation algorithm on the proposed\nfamily of robust experts to generate predictions for the sequential stream of\ntarget test samples. Numerical experiments on real data show that the robust\nstrategies may outperform non-robust interpolations of the empirical least\nsquares estimators.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:51:55 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Taskesen", "Bahar", ""], ["Yue", "Man-Chung", ""], ["Blanchet", "Jose", ""], ["Kuhn", "Daniel", ""], ["Nguyen", "Viet Anh", ""]]}, {"id": "2106.00418", "submitter": "Aur\\'elien Bibaut", "authors": "Aur\\'elien Bibaut and Antoine Chambaz and Maria Dimakopoulou and\n  Nathan Kallus and Mark van der Laan", "title": "Post-Contextual-Bandit Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are increasingly replacing non-adaptive A/B\ntests in e-commerce, healthcare, and policymaking because they can both improve\noutcomes for study participants and increase the chance of identifying good or\neven best policies. To support credible inference on novel interventions at the\nend of the study, nonetheless, we still want to construct valid confidence\nintervals on average treatment effects, subgroup effects, or value of new\npolicies. The adaptive nature of the data collected by contextual bandit\nalgorithms, however, makes this difficult: standard estimators are no longer\nasymptotically normally distributed and classic confidence intervals fail to\nprovide correct coverage. While this has been addressed in non-contextual\nsettings by using stabilized estimators, the contextual setting poses unique\nchallenges that we tackle for the first time in this paper. We propose the\nContextual Adaptive Doubly Robust (CADR) estimator, the first estimator for\npolicy value that is asymptotically normal under contextual adaptive data\ncollection. The main technical challenge in constructing CADR is designing\nadaptive and consistent conditional standard deviation estimators for\nstabilization. Extensive numerical experiments using 57 OpenML datasets\ndemonstrate that confidence intervals based on CADR uniquely provide correct\ncoverage.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 12:01:51 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Bibaut", "Aur\u00e9lien", ""], ["Chambaz", "Antoine", ""], ["Dimakopoulou", "Maria", ""], ["Kallus", "Nathan", ""], ["van der Laan", "Mark", ""]]}, {"id": "2106.00467", "submitter": "Daniele Regoli", "authors": "Alessandro Castelnovo, Riccardo Crupi, Greta Greco, Daniele Regoli", "title": "The zoo of Fairness metrics in Machine Learning", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the problem of addressing fairness in Machine Learning (ML)\nand automatic decision-making has attracted a lot of attention in the\nscientific communities dealing with Artificial Intelligence. A plethora of\ndifferent definitions of fairness in ML have been proposed, that consider\ndifferent notions of what is a \"fair decision\" in situations impacting\nindividuals in the population. The precise differences, implications and\n\"orthogonality\" between these notions have not yet been fully analyzed in the\nliterature. In this work, we try to make some order out of this zoo of\ndefinitions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 13:19:30 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 21:34:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Castelnovo", "Alessandro", ""], ["Crupi", "Riccardo", ""], ["Greco", "Greta", ""], ["Regoli", "Daniele", ""]]}, {"id": "2106.00474", "submitter": "Antti Honkela", "authors": "Antti Honkela", "title": "Gaussian Processes with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian processes (GPs) are non-parametric Bayesian models that are widely\nused for diverse prediction tasks. Previous work in adding strong privacy\nprotection to GPs via differential privacy (DP) has been limited to protecting\nonly the privacy of the prediction targets (model outputs) but not inputs. We\nbreak this limitation by introducing GPs with DP protection for both model\ninputs and outputs. We achieve this by using sparse GP methodology and\npublishing a private variational approximation on known inducing points. The\napproximation covariance is adjusted to approximately account for the added\nuncertainty from DP noise. The approximation can be used to compute arbitrary\npredictions using standard sparse GP techniques. We propose a method for\nhyperparameter learning using a private selection protocol applied to\nvalidation set log-likelihood. Our experiments demonstrate that given\nsufficient amount of data, the method can produce accurate models under strong\nprivacy protection.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 13:23:16 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Honkela", "Antti", ""]]}, {"id": "2106.00477", "submitter": "Antti Koskela", "authors": "Antti Koskela, Mikko A. Heikkil\\\"a, Antti Honkela", "title": "Tight Accounting in the Shuffle Model of Differential Privacy", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Shuffle model of differential privacy is a novel distributed privacy model\nbased on a combination of local privacy mechanisms and a trusted shuffler. It\nhas been shown that the additional randomisation provided by the shuffler\nimproves privacy bounds compared to the purely local mechanisms. Accounting\ntight bounds, especially for multi-message protocols, is complicated by the\ncomplexity brought by the shuffler. The recently proposed Fourier Accountant\nfor evaluating $(\\varepsilon,\\delta)$-differential privacy guarantees has been\nshown to give tighter bounds than commonly used methods for non-adaptive\ncompositions of various complex mechanisms. In this paper we show how to\ncompute tight privacy bounds using the Fourier Accountant for multi-message\nversions of several ubiquitous mechanisms in the shuffle model and demonstrate\nlooseness of the existing bounds in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 13:30:32 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Koskela", "Antti", ""], ["Heikkil\u00e4", "Mikko A.", ""], ["Honkela", "Antti", ""]]}, {"id": "2106.00492", "submitter": "Nicholas Gray", "authors": "Nicholas Gray and Scott Ferson", "title": "Logistic Regression Through the Veil of Imprecise Data", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression is an important statistical tool for assessing the\nprobability of an outcome based upon some predictive variables. Standard\nmethods can only deal with precisely known data, however many datasets have\nuncertainties which traditional methods either reduce to a single point or\ncompletely disregarded. In this paper we show that it is possible to include\nthese uncertainties by considering an imprecise logistic regression model using\nthe set of possible models that can be obtained from values from within the\nintervals. This has the advantage of clearly expressing the epistemic\nuncertainty removed by traditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 13:51:46 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Gray", "Nicholas", ""], ["Ferson", "Scott", ""]]}, {"id": "2106.00528", "submitter": "Beate Sick", "authors": "Sefan H\\\"ortling, Daniel Dold, Oliver D\\\"urr, Beate Sick", "title": "Transformation Models for Flexible Posteriors in Variational Bayes", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main challenge in Bayesian models is to determine the posterior for the\nmodel parameters. Already, in models with only one or few parameters, the\nanalytical posterior can only be determined in special settings. In Bayesian\nneural networks, variational inference is widely used to approximate\ndifficult-to-compute posteriors by variational distributions. Usually,\nGaussians are used as variational distributions (Gaussian-VI) which limits the\nquality of the approximation due to their limited flexibility. Transformation\nmodels on the other hand are flexible enough to fit any distribution. Here we\npresent transformation model-based variational inference (TM-VI) and\ndemonstrate that it allows to accurately approximate complex posteriors in\nmodels with one parameter and also works in a mean-field fashion for\nmulti-parameter models like neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 14:43:47 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["H\u00f6rtling", "Sefan", ""], ["Dold", "Daniel", ""], ["D\u00fcrr", "Oliver", ""], ["Sick", "Beate", ""]]}, {"id": "2106.00543", "submitter": "Amrit Singh Bedi", "authors": "Junyu Zhang, Amrit Singh Bedi, Mengdi Wang, and Alec Koppel", "title": "MARL with General Utilities via Decentralized Shadow Reward Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We posit a new mechanism for cooperation in multi-agent reinforcement\nlearning (MARL) based upon any nonlinear function of the team's long-term\nstate-action occupancy measure, i.e., a \\emph{general utility}. This subsumes\nthe cumulative return but also allows one to incorporate risk-sensitivity,\nexploration, and priors. % We derive the {\\bf D}ecentralized {\\bf S}hadow\nReward {\\bf A}ctor-{\\bf C}ritic (DSAC) in which agents alternate between policy\nevaluation (critic), weighted averaging with neighbors (information mixing),\nand local gradient updates for their policy parameters (actor). DSAC augments\nthe classic critic step by requiring agents to (i) estimate their local\noccupancy measure in order to (ii) estimate the derivative of the local utility\nwith respect to their occupancy measure, i.e., the \"shadow reward\". DSAC\nconverges to $\\epsilon$-stationarity in $\\mathcal{O}(1/\\epsilon^{2.5})$\n(Theorem \\ref{theorem:final}) or faster $\\mathcal{O}(1/\\epsilon^{2})$\n(Corollary \\ref{corollary:communication}) steps with high probability,\ndepending on the amount of communications. We further establish the\nnon-existence of spurious stationary points for this problem, that is, DSAC\nfinds the globally optimal policy (Corollary \\ref{corollary:global}).\nExperiments demonstrate the merits of goals beyond the cumulative return in\ncooperative MARL.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:05:48 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 17:20:27 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Zhang", "Junyu", ""], ["Bedi", "Amrit Singh", ""], ["Wang", "Mengdi", ""], ["Koppel", "Alec", ""]]}, {"id": "2106.00545", "submitter": "Victor Veitch", "authors": "Victor Veitch, Alexander D'Amour, Steve Yadlowsky, Jacob Eisenstein", "title": "Counterfactual Invariance to Spurious Correlations: Why and How to Pass\n  Stress Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informally, a `spurious correlation' is the dependence of a model on some\naspect of the input data that an analyst thinks shouldn't matter. In machine\nlearning, these have a know-it-when-you-see-it character; e.g., changing the\ngender of a sentence's subject changes a sentiment predictor's output. To check\nfor spurious correlations, we can `stress test' models by perturbing irrelevant\nparts of input data and seeing if model predictions change. In this paper, we\nstudy stress testing using the tools of causal inference. We introduce\n\\emph{counterfactual invariance} as a formalization of the requirement that\nchanging irrelevant parts of the input shouldn't change model predictions. We\nconnect counterfactual invariance to out-of-domain model performance, and\nprovide practical schemes for learning (approximately) counterfactual invariant\npredictors (without access to counterfactual examples). It turns out that both\nthe means and implications of counterfactual invariance depend fundamentally on\nthe true underlying causal structure of the data. Distinct causal structures\nrequire distinct regularization schemes to induce counterfactual invariance.\nSimilarly, counterfactual invariance implies different domain shift guarantees\ndepending on the underlying causal structure. This theory is supported by\nempirical results on text classification.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:39:38 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 03:11:24 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Veitch", "Victor", ""], ["D'Amour", "Alexander", ""], ["Yadlowsky", "Steve", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "2106.00553", "submitter": "Zaccharie Ramzi", "authors": "Zaccharie Ramzi, Florian Mannel, Shaojie Bai, Jean-Luc Starck,\n  Philippe Ciuciu, Thomas Moreau", "title": "SHINE: SHaring the INverse Estimate from the forward pass for bi-level\n  optimization and implicit models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, implicit deep learning has emerged as a method to increase\nthe depth of deep neural networks. While their training is memory-efficient,\nthey are still significantly slower to train than their explicit counterparts.\nIn Deep Equilibrium Models (DEQs), the training is performed as a bi-level\nproblem, and its computational complexity is partially driven by the iterative\ninversion of a huge Jacobian matrix. In this paper, we propose a novel strategy\nto tackle this computational bottleneck from which many bi-level problems\nsuffer. The main idea is to use the quasi-Newton matrices from the forward pass\nto efficiently approximate the inverse Jacobian matrix in the direction needed\nfor the gradient computation. We provide a theorem that motivates using our\nmethod with the original forward algorithms. In addition, by modifying these\nforward algorithms, we further provide theoretical guarantees that our method\nasymptotically estimates the true implicit gradient. We empirically study this\napproach in many settings, ranging from hyperparameter optimization to large\nMultiscale DEQs applied to CIFAR and ImageNet. We show that it reduces the\ncomputational cost of the backward pass by up to two orders of magnitude. All\nthis is achieved while retaining the excellent performance of the original\nmodels in hyperparameter optimization and on CIFAR, and giving encouraging and\ncompetitive results on ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 15:07:34 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 13:32:51 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Ramzi", "Zaccharie", ""], ["Mannel", "Florian", ""], ["Bai", "Shaojie", ""], ["Starck", "Jean-Luc", ""], ["Ciuciu", "Philippe", ""], ["Moreau", "Thomas", ""]]}, {"id": "2106.00555", "submitter": "Bernard Mourrain", "authors": "Rima Khouja (AROMATH), Pierre-Alexandre Mattei (MAASAI), Bernard\n  Mourrain (AROMATH)", "title": "Tensor decomposition for learning Gaussian mixtures from moments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data processing and machine learning, an important challenge is to recover\nand exploit models that can represent accurately the data. We consider the\nproblem of recovering Gaussian mixture models from datasets. We investigate\nsymmetric tensor decomposition methods for tackling this problem, where the\ntensor is built from empirical moments of the data distribution. We consider\nidentifiable tensors, which have a unique decomposition, showing that moment\ntensors built from spherical Gaussian mixtures have this property. We prove\nthat symmetric tensors with interpolation degree strictly less than half their\norder are identifiable and we present an algorithm, based on simple linear\nalgebra operations, to compute their decomposition. Illustrative\nexperimentations show the impact of the tensor decomposition method for\nrecovering Gaussian mixtures, in comparison with other state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 15:11:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Khouja", "Rima", "", "AROMATH"], ["Mattei", "Pierre-Alexandre", "", "MAASAI"], ["Mourrain", "Bernard", "", "AROMATH"]]}, {"id": "2106.00651", "submitter": "Jacob Zavatone-Veth", "authors": "Jacob A. Zavatone-Veth and Abdulkadir Canatar and Cengiz Pehlevan", "title": "Asymptotics of representation learning in finite Bayesian neural\n  networks", "comments": "12+28 pages, 2+1 figures; v2: fix typo in (8) and add references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent works have suggested that finite Bayesian neural networks may\noutperform their infinite cousins because finite networks can flexibly adapt\ntheir internal representations. However, our theoretical understanding of how\nthe learned hidden layer representations of finite networks differ from the\nfixed representations of infinite networks remains incomplete. Perturbative\nfinite-width corrections to the network prior and posterior have been studied,\nbut the asymptotics of learned features have not been fully characterized.\nHere, we argue that the leading finite-width corrections to the average feature\nkernels for any Bayesian network with linear readout and quadratic cost have a\nlargely universal form. We illustrate this explicitly for two classes of fully\nconnected networks: deep linear networks and networks with a single nonlinear\nhidden layer. Our results begin to elucidate which features of data wide\nBayesian neural networks learn to represent.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:30:30 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 15:13:39 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Zavatone-Veth", "Jacob A.", ""], ["Canatar", "Abdulkadir", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2106.00661", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Brendan O'Donoghue, Guillaume Desjardins and Satinder\n  Singh", "title": "Reward is enough for convex MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximising a cumulative reward function that is Markov and stationary, i.e.,\ndefined over state-action pairs and independent of time, is sufficient to\ncapture many kinds of goals in a Markov Decision Process (MDP) based on the\nReinforcement Learning (RL) problem formulation. However, not all goals can be\ncaptured in this manner. Specifically, it is easy to see that Convex MDPs in\nwhich goals are expressed as convex functions of stationary distributions\ncannot, in general, be formulated in this manner. In this paper, we reformulate\nthe convex MDP problem as a min-max game between the policy and cost (negative\nreward) players using Fenchel duality and propose a meta-algorithm for solving\nit. We show that the average of the policies produced by an RL agent that\nmaximizes the non-stationary reward produced by the cost player converges to an\noptimal solution to the convex MDP. Finally, we show that the meta-algorithm\nunifies several disparate branches of reinforcement learning algorithms in the\nliterature, such as apprenticeship learning, variational intrinsic control,\nconstrained MDPs, and pure exploration into a single framework.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:46:25 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zahavy", "Tom", ""], ["O'Donoghue", "Brendan", ""], ["Desjardins", "Guillaume", ""], ["Singh", "Satinder", ""]]}, {"id": "2106.00665", "submitter": "Joshua Myszewski", "authors": "Joshua J Myszewski, Emily Klossowski, Patrick Meyer, Kristin Bevil,\n  Lisa Klesius, Kristopher M Schroeder", "title": "Validating GAN-BioBERT: A Methodology For Assessing Reporting Trends In\n  Clinical Trials", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the past decade, there has been much discussion about the issue of biased\nreporting in clinical research. Despite this attention, there have been limited\ntools developed for the systematic assessment of qualitative statements made in\nclinical research, with most studies assessing qualitative statements relying\non the use of manual expert raters, which limits their size. Also, previous\nattempts to develop larger scale tools, such as those using natural language\nprocessing, were limited by both their accuracy and the number of categories\nused for the classification of their findings. With these limitations in mind,\nthis study's goal was to develop a classification algorithm that was both\nsuitably accurate and finely grained to be applied on a large scale for\nassessing the qualitative sentiment expressed in clinical trial abstracts.\nAdditionally, this study seeks to compare the performance of the proposed\nalgorithm, GAN-BioBERT, to previous studies as well as to expert manual rating\nof clinical trial abstracts. This study develops a three-class sentiment\nclassification algorithm for clinical trial abstracts using a semi-supervised\nnatural language process model based on the Bidirectional Encoder\nRepresentation from Transformers (BERT) model, from a series of clinical trial\nabstracts annotated by a group of experts in academic medicine. Results: The\nuse of this algorithm was found to have a classification accuracy of 91.3%,\nwith a macro F1-Score of 0.92, which is a significant improvement in accuracy\nwhen compared to previous methods and expert ratings, while also making the\nsentiment classification finer grained than previous studies. The proposed\nalgorithm, GAN-BioBERT, is a suitable classification model for the large-scale\nassessment of qualitative statements in clinical trial literature, providing an\naccurate, reproducible tool for the large-scale study of clinical publication\ntrends.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:51:54 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Myszewski", "Joshua J", ""], ["Klossowski", "Emily", ""], ["Meyer", "Patrick", ""], ["Bevil", "Kristin", ""], ["Klesius", "Lisa", ""], ["Schroeder", "Kristopher M", ""]]}, {"id": "2106.00669", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Brendan O'Donoghue, Andre Barreto, Volodymyr Mnih,\n  Sebastian Flennerhag and Satinder Singh", "title": "Discovering Diverse Nearly Optimal Policies withSuccessor Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding different solutions to the same problem is a key aspect of\nintelligence associated with creativity and adaptation to novel situations. In\nreinforcement learning, a set of diverse policies can be useful for\nexploration, transfer, hierarchy, and robustness. We propose Diverse Successive\nPolicies, a method for discovering policies that are diverse in the space of\nSuccessor Features, while assuring that they are near optimal. We formalize the\nproblem as a Constrained Markov Decision Process (CMDP) where the goal is to\nfind policies that maximize diversity, characterized by an intrinsic diversity\nreward, while remaining near-optimal with respect to the extrinsic reward of\nthe MDP. We also analyze how recently proposed robustness and discrimination\nrewards perform and find that they are sensitive to the initialization of the\nprocedure and may converge to sub-optimal solutions. To alleviate this, we\npropose new explicit diversity rewards that aim to minimize the correlation\nbetween the Successor Features of the policies in the set. We compare the\ndifferent diversity mechanisms in the DeepMind Control Suite and find that the\ntype of explicit diversity we are proposing is important to discover distinct\nbehavior, like for example different locomotion patterns.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:56:13 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zahavy", "Tom", ""], ["O'Donoghue", "Brendan", ""], ["Barreto", "Andre", ""], ["Mnih", "Volodymyr", ""], ["Flennerhag", "Sebastian", ""], ["Singh", "Satinder", ""]]}, {"id": "2106.00694", "submitter": "James Halverson", "authors": "Anindita Maiti, Keegan Stoner, James Halverson", "title": "Symmetry-via-Duality: Invariant Neural Network Densities from\n  Parameter-Space Correlators", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parameter-space and function-space provide two different duality frames in\nwhich to study neural networks. We demonstrate that symmetries of network\ndensities may be determined via dual computations of network correlation\nfunctions, even when the density is unknown and the network is not equivariant.\nSymmetry-via-duality relies on invariance properties of the correlation\nfunctions, which stem from the choice of network parameter distributions. Input\nand output symmetries of neural network densities are determined, which recover\nknown Gaussian process results in the infinite width limit. The mechanism may\nalso be utilized to determine symmetries during training, when parameters are\ncorrelated, as well as symmetries of the Neural Tangent Kernel. We demonstrate\nthat the amount of symmetry in the initialization density affects the accuracy\nof networks trained on Fashion-MNIST, and that symmetry breaking helps only\nwhen it is in the direction of ground truth.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 18:00:06 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Maiti", "Anindita", ""], ["Stoner", "Keegan", ""], ["Halverson", "James", ""]]}, {"id": "2106.00719", "submitter": "Rui Meng", "authors": "Rui Meng, Herbie Lee, Kristofer Bouchard", "title": "Collaborative Nonstationary Multivariate Gaussian Process Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, multi-output Gaussian process regression models either do not\nmodel nonstationarity or are associated with severe computational burdens and\nstorage demands. Nonstationary multi-variate Gaussian process models (NMGP) use\na nonstationary covariance function with an input-dependent linear model of\ncoregionalisation to jointly model input-dependent correlation, scale, and\nsmoothness of outputs. Variational sparse approximation relies on inducing\npoints to enable scalable computations. Here, we take the best of both worlds:\nconsidering an inducing variable framework on the underlying latent functions\nin NMGP, we propose a novel model called the collaborative nonstationary\nGaussian process model(CNMGP). For CNMGP, we derive computationally tractable\nvariational bounds amenable to doubly stochastic variational inference.\nTogether, this allows us to model data in which outputs do not share a common\ninput set, with a computational complexity that is independent of the size of\nthe inputs and outputs. We illustrate the performance of our method on\nsynthetic data and three real datasets and show that our model generally\npro-vides better predictive performance than the state-of-the-art, and also\nprovides estimates of time-varying correlations that differ across outputs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 18:25:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Meng", "Rui", ""], ["Lee", "Herbie", ""], ["Bouchard", "Kristofer", ""]]}, {"id": "2106.00734", "submitter": "Michael Mahoney", "authors": "Charles H. Martin and Michael W. Mahoney", "title": "Post-mortem on a deep learning contest: a Simpson's paradox and the\n  complementary roles of scale metrics versus shape metrics", "comments": "23 pages; 9 figures; 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand better the causes of good generalization performance in\nstate-of-the-art neural network (NN) models, we analyze of a corpus of models\nthat was made publicly-available for a contest to predict the generalization\naccuracy of NNs. These models include a wide range of qualities and were\ntrained with a range of architectures and regularization hyperparameters. We\nidentify what amounts to a Simpson's paradox: where \"scale\" metrics (from\ntraditional statistical learning theory) perform well overall but perform\npoorly on subpartitions of the data of a given depth, when regularization\nhyperparameters are varied; and where \"shape\" metrics (from Heavy-Tailed Self\nRegularization theory) perform well on subpartitions of the data, when\nhyperparameters are varied for models of a given depth, but perform poorly\noverall when models with varying depths are aggregated. Our results highlight\nthe subtly of comparing models when both architectures and hyperparameters are\nvaried, as well as the complementary role of implicit scale versus implicit\nshape parameters in understanding NN model quality. Our results also suggest\ncaution when one tries to extract causal insight with a single metric applied\nto aggregate data, and they highlight the need to go beyond one-size-fits-all\nmetrics based on upper bounds from generalization theory to describe the\nperformance of state-of-the-art NN models. Based on these findings, we present\ntwo novel shape metrics, one data-independent, and the other data-dependent,\nwhich can predict trends in the test accuracy of a series of NNs, of a fixed\narchitecture/depth, when varying solver hyperparameters.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 19:19:49 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Martin", "Charles H.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2106.00750", "submitter": "Sana Tonekaboni", "authors": "Sana Tonekaboni, Danny Eytan, Anna Goldenberg", "title": "Unsupervised Representation Learning for Time Series with Temporal\n  Neighborhood Coding", "comments": "Camera-ready at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are often complex and rich in information but sparsely labeled\nand therefore challenging to model. In this paper, we propose a self-supervised\nframework for learning generalizable representations for non-stationary time\nseries. Our approach, called Temporal Neighborhood Coding (TNC), takes\nadvantage of the local smoothness of a signal's generative process to define\nneighborhoods in time with stationary properties. Using a debiased contrastive\nobjective, our framework learns time series representations by ensuring that in\nthe encoding space, the distribution of signals from within a neighborhood is\ndistinguishable from the distribution of non-neighboring signals. Our\nmotivation stems from the medical field, where the ability to model the dynamic\nnature of time series data is especially valuable for identifying, tracking,\nand predicting the underlying patients' latent states in settings where\nlabeling data is practically impossible. We compare our method to recently\ndeveloped unsupervised representation learning approaches and demonstrate\nsuperior performance on clustering and classification tasks for multiple\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 19:53:24 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Tonekaboni", "Sana", ""], ["Eytan", "Danny", ""], ["Goldenberg", "Anna", ""]]}, {"id": "2106.00774", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis, Yair Schiff, Youssef Mroueh", "title": "Optimizing Functionals on the Space of Probabilities with Input Convex\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient flows are a powerful tool for optimizing functionals in general\nmetric spaces, including the space of probabilities endowed with the\nWasserstein metric. A typical approach to solving this optimization problem\nrelies on its connection to the dynamic formulation of optimal transport and\nthe celebrated Jordan-Kinderlehrer-Otto (JKO) scheme. However, this formulation\ninvolves optimization over convex functions, which is challenging, especially\nin high dimensions. In this work, we propose an approach that relies on the\nrecently introduced input-convex neural networks (ICNN) to parameterize the\nspace of convex functions in order to approximate the JKO scheme, as well as in\ndesigning functionals over measures that enjoy convergence guarantees. We\nderive a computationally efficient implementation of this JKO-ICNN framework\nand use various experiments to demonstrate its feasibility and validity in\napproximating solutions of low-dimensional partial differential equations with\nknown solutions. We also explore the use of our JKO-ICNN approach in high\ndimensions with an experiment in controlled generation for molecular discovery.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 20:13:18 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 19:40:29 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Schiff", "Yair", ""], ["Mroueh", "Youssef", ""]]}, {"id": "2106.00792", "submitter": "Ramon Winterhalder", "authors": "Ramon Winterhalder, Marco Bellagente, Benjamin Nachman", "title": "Latent Space Refinement for Deep Generative Models", "comments": "14 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ex hep-ph physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep generative models are becoming widely used across science and industry\nfor a variety of purposes. A common challenge is achieving a precise implicit\nor explicit representation of the data probability density. Recent proposals\nhave suggested using classifier weights to refine the learned density of deep\ngenerative models. We extend this idea to all types of generative models and\nshow how latent space refinement via iterated generative modeling can\ncircumvent topological obstructions and improve precision. This methodology\nalso applies to cases were the target model is non-differentiable and has many\ninternal latent dimensions which must be marginalized over before refinement.\nWe demonstrate our Latent Space Refinement (LaSeR) protocol on a variety of\nexamples, focusing on the combinations of Normalizing Flows and Generative\nAdversarial Networks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 21:01:39 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Winterhalder", "Ramon", ""], ["Bellagente", "Marco", ""], ["Nachman", "Benjamin", ""]]}, {"id": "2106.00797", "submitter": "Maxime Vono", "authors": "Maxime Vono, Vincent Plassier, Alain Durmus, Aymeric Dieuleveut, Eric\n  Moulines", "title": "QLSD: Quantised Langevin stochastic dynamics for Bayesian federated\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning aims at conducting inference when data are decentralised\nand locally stored on several clients, under two main constraints: data\nownership and communication overhead. In this paper, we address these issues\nunder the Bayesian paradigm. To this end, we propose a novel Markov chain Monte\nCarlo algorithm coined \\texttt{QLSD} built upon quantised versions of\nstochastic gradient Langevin dynamics. To improve performance in a big data\nregime, we introduce variance-reduced alternatives of our methodology referred\nto as \\texttt{QLSD}$^\\star$ and \\texttt{QLSD}$^{++}$. We provide both\nnon-asymptotic and asymptotic convergence guarantees for the proposed\nalgorithms and illustrate their benefits on several federated learning\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 21:08:54 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Vono", "Maxime", ""], ["Plassier", "Vincent", ""], ["Durmus", "Alain", ""], ["Dieuleveut", "Aymeric", ""], ["Moulines", "Eric", ""]]}, {"id": "2106.00808", "submitter": "Sorawit Saengkyongam", "authors": "Sorawit Saengkyongam, Nikolaj Thams, Jonas Peters and Niklas Pfister", "title": "Invariant Policy Learning: A Causal Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, contextual bandit and reinforcement learning algorithms\nhave been successfully used in various interactive learning systems such as\nonline advertising, recommender systems, and dynamic pricing. However, they\nhave yet to be widely adopted in high-stakes application domains, such as\nhealthcare. One reason may be that existing approaches assume that the\nunderlying mechanisms are static in the sense that they do not change over time\nor over different environments. In many real world systems, however, the\nmechanisms are subject to shifts across environments which may invalidate the\nstatic environment assumption. In this paper, we tackle the problem of\nenvironmental shifts under the framework of offline contextual bandits. We view\nthe environmental shift problem through the lens of causality and propose\nmulti-environment contextual bandits that allow for changes in the underlying\nmechanisms. We adopt the concept of invariance from the causality literature\nand introduce the notion of policy invariance. We argue that policy invariance\nis only relevant if unobserved confounders are present and show that, in that\ncase, an optimal invariant policy is guaranteed, under certain assumptions, to\ngeneralize across environments. Our results do not only provide a solution to\nthe environmental shift problem but also establish concrete connections among\ncausality, invariance and contextual bandits.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 21:20:48 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 09:46:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Saengkyongam", "Sorawit", ""], ["Thams", "Nikolaj", ""], ["Peters", "Jonas", ""], ["Pfister", "Niklas", ""]]}, {"id": "2106.00810", "submitter": "Alessio Russo", "authors": "Alessio Russo", "title": "Some Ethical Issues in the Review Process of Machine Learning\n  Conferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent successes in the Machine Learning community have led to a steep\nincrease in the number of papers submitted to conferences. This increase made\nmore prominent some of the issues that affect the current review process used\nby these conferences. The review process has several issues that may undermine\nthe nature of scientific research, which is of being fully objective,\napolitical, unbiased and free of misconduct (such as plagiarism, cheating,\nimproper influence, and other improprieties). In this work, we study the\nproblem of reviewers' recruitment, infringements of the double-blind process,\nfraudulent behaviors, biases in numerical ratings, and the appendix phenomenon\n(i.e., the fact that it is becoming more common to publish results in the\nappendix section of a paper). For each of these problems, we provide a short\ndescription and possible solutions. The goal of this work is to raise awareness\nin the Machine Learning community regarding these issues.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 21:22:41 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Russo", "Alessio", ""]]}, {"id": "2106.00827", "submitter": "Eric Bunch", "authors": "Eric Bunch, Jeffery Kline, Daniel Dickinson, Suhaas Bhat, Glenn Fung", "title": "Weighting vectors for machine learning: numerical harmonic analysis\n  applied to boundary detection", "comments": "16 pages. arXiv admin note: text overlap with arXiv:2006.14063", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric space magnitude, an active field of research in algebraic topology, is\na scalar quantity that summarizes the effective number of distinct points that\nlive in a general metric space. The {\\em weighting vector} is a closely-related\nconcept that captures, in a nontrivial way, much of the underlying geometry of\nthe original metric space. Recent work has demonstrated that when the metric\nspace is Euclidean, the weighting vector serves as an effective tool for\nboundary detection. We recast this result and show the weighting vector may be\nviewed as a solution to a kernelized SVM. As one consequence, we apply this new\ninsight to the task of outlier detection, and we demonstrate performance that\nis competitive or exceeds performance of state-of-the-art techniques on\nbenchmark data sets. Under mild assumptions, we show the weighting vector,\nwhich has computational cost of matrix inversion, can be efficiently\napproximated in linear time. We show how nearest neighbor methods can\napproximate solutions to the minimization problems defined by SVMs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 22:14:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Bunch", "Eric", ""], ["Kline", "Jeffery", ""], ["Dickinson", "Daniel", ""], ["Bhat", "Suhaas", ""], ["Fung", "Glenn", ""]]}, {"id": "2106.00839", "submitter": "Agni Orfanoudaki", "authors": "Dimitris Bertsimas, Agni Orfanoudaki", "title": "Pricing Algorithmic Insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.RM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning algorithms start to get integrated into the\ndecision-making process of companies and organizations, insurance products will\nbe developed to protect their owners from risk. We introduce the concept of\nalgorithmic insurance and present a quantitative framework to enable the\npricing of the derived insurance contracts. We propose an optimization\nformulation to estimate the risk exposure and price for a binary classification\nmodel. Our approach outlines how properties of the model, such as accuracy,\ninterpretability and generalizability, can influence the insurance contract\nevaluation. To showcase a practical implementation of the proposed framework,\nwe present a case study of medical malpractice in the context of breast cancer\ndetection. Our analysis focuses on measuring the effect of the model parameters\non the expected financial loss and identifying the aspects of algorithmic\nperformance that predominantly affect the price of the contract.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 22:32:02 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Orfanoudaki", "Agni", ""]]}, {"id": "2106.00858", "submitter": "Jiri Navratil", "authors": "Jiri Navratil, Benjamin Elder, Matthew Arnold, Soumya Ghosh, Prasanna\n  Sattigeri", "title": "Uncertainty Characteristics Curves: A Systematic Assessment of\n  Prediction Intervals", "comments": "10 pages main paper, 9 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate quantification of model uncertainty has long been recognized as a\nfundamental requirement for trusted AI. In regression tasks, uncertainty is\ntypically quantified using prediction intervals calibrated to a specific\noperating point, making evaluation and comparison across different studies\ndifficult. Our work leverages: (1) the concept of operating characteristics\ncurves and (2) the notion of a gain over a simple reference, to derive a novel\noperating point agnostic assessment methodology for prediction intervals. The\npaper describes the corresponding algorithm, provides a theoretical analysis,\nand demonstrates its utility in multiple scenarios. We argue that the proposed\nmethod addresses the current need for comprehensive assessment of prediction\nintervals and thus represents a valuable addition to the uncertainty\nquantification toolbox.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 23:46:44 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Navratil", "Jiri", ""], ["Elder", "Benjamin", ""], ["Arnold", "Matthew", ""], ["Ghosh", "Soumya", ""], ["Sattigeri", "Prasanna", ""]]}, {"id": "2106.00885", "submitter": "Fengzhuo Zhang", "authors": "Fengzhuo Zhang, Vincent Y. F. Tan", "title": "Robustifying Algorithms of Learning Latent Trees with Vector Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning the structures of Gaussian latent tree models with\nvector observations when a subset of them are arbitrarily corrupted. First, we\npresent the sample complexities of Recursive Grouping (RG) and Chow-Liu\nRecursive Grouping (CLRG) without the assumption that the effective depth is\nbounded in the number of observed nodes, significantly generalizing the results\nin Choi et al. (2011). We show that Chow-Liu initialization in CLRG greatly\nreduces the sample complexity of RG from being exponential in the diameter of\nthe tree to only logarithmic in the diameter for the hidden Markov model (HMM).\nSecond, we robustify RG, CLRG, Neighbor Joining (NJ) and Spectral NJ (SNJ) by\nusing the truncated inner product. These robustified algorithms can tolerate a\nnumber of corruptions up to the square root of the number of clean samples.\nFinally, we derive the first known instance-dependent impossibility result for\nstructure learning of latent trees. The optimalities of the robust version of\nCLRG and NJ are verified by comparing their sample complexities and the\nimpossibility result.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 01:37:52 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 07:23:19 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhang", "Fengzhuo", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2106.00886", "submitter": "Keisuke Kawano", "authors": "Keisuke Kawano, Satoshi Koide, Keisuke Otaki", "title": "Partial Wasserstein Covering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a general task called partial Wasserstein covering with the goal\nof emulating a large dataset (e.g., application dataset) using a small dataset\n(e.g., development dataset) in terms of the empirical distribution by selecting\na small subset from a candidate dataset and adding it to the small dataset. We\nmodel this task as a discrete optimization problem with partial Wasserstein\ndivergence as an objective function. Although this problem is NP-hard, we prove\nthat it has the submodular property, allowing us to use a greedy algorithm with\na 0.63 approximation. However, the greedy algorithm is still inefficient\nbecause it requires linear programming for each objective function evaluation.\nTo overcome this difficulty, we propose quasi-greedy algorithms for\nacceleration, which consist of a series of techniques such as sensitivity\nanalysis based on strong duality and the so-called $C$-transform in the optimal\ntransport field. Experimentally, we demonstrate that we can efficiently make\ntwo datasets similar in terms of partial Wasserstein divergence, including\ndriving scene datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 01:48:41 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kawano", "Keisuke", ""], ["Koide", "Satoshi", ""], ["Otaki", "Keisuke", ""]]}, {"id": "2106.00901", "submitter": "Hiroshi Kajino", "authors": "Hiroshi Kajino", "title": "A Differentiable Point Process with Its Application to Spiking Neural\n  Networks", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is concerned about a learning algorithm for a probabilistic model\nof spiking neural networks (SNNs). Jimenez Rezende & Gerstner (2014) proposed a\nstochastic variational inference algorithm to train SNNs with hidden neurons.\nThe algorithm updates the variational distribution using the score function\ngradient estimator, whose high variance often impedes the whole learning\nalgorithm. This paper presents an alternative gradient estimator for SNNs based\non the path-wise gradient estimator. The main technical difficulty is a lack of\na general method to differentiate a realization of an arbitrary point process,\nwhich is necessary to derive the path-wise gradient estimator. We develop a\ndifferentiable point process, which is the technical highlight of this paper,\nand apply it to derive the path-wise gradient estimator for SNNs. We\ninvestigate the effectiveness of our gradient estimator through numerical\nsimulation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:40:17 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 07:15:32 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Kajino", "Hiroshi", ""]]}, {"id": "2106.00925", "submitter": "Yunqi Wang", "authors": "Yunqi Wang, Furui Liu, Zhitang Chen, Qing Lian, Shoubo Hu, Jianye Hao,\n  Yik-Chung Wu", "title": "Contrastive ACE: Domain Generalization Through Alignment of Causal\n  Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization aims to learn knowledge invariant across different\ndistributions while semantically meaningful for downstream tasks from multiple\nsource domains, to improve the model's generalization ability on unseen target\ndomains. The fundamental objective is to understand the underlying \"invariance\"\nbehind these observational distributions and such invariance has been shown to\nhave a close connection to causality. While many existing approaches make use\nof the property that causal features are invariant across domains, we consider\nthe causal invariance of the average causal effect of the features to the\nlabels. This invariance regularizes our training approach in which\ninterventions are performed on features to enforce stability of the causal\nprediction by the classifier across domains. Our work thus sheds some light on\nthe domain generalization problem by introducing invariance of the mechanisms\ninto the learning process. Experiments on several benchmark datasets\ndemonstrate the performance of the proposed method against SOTAs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 04:01:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Yunqi", ""], ["Liu", "Furui", ""], ["Chen", "Zhitang", ""], ["Lian", "Qing", ""], ["Hu", "Shoubo", ""], ["Hao", "Jianye", ""], ["Wu", "Yik-Chung", ""]]}, {"id": "2106.00958", "submitter": "Diogo Almeida", "authors": "Diogo Almeida, Clemens Winter, Jie Tang, Wojciech Zaremba", "title": "A Generalizable Approach to Learning Optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core issue with learning to optimize neural networks has been the lack of\ngeneralization to real world problems. To address this, we describe a system\ndesigned from a generalization-first perspective, learning to update optimizer\nhyperparameters instead of model parameters directly using novel features,\nactions, and a reward function. This system outperforms Adam at all neural\nnetwork tasks including on modalities not seen during training. We achieve 2x\nspeedups on ImageNet, and a 2.5x speedup on a language modeling task using over\n5 orders of magnitude more compute than the training tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 06:03:18 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 19:36:13 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Almeida", "Diogo", ""], ["Winter", "Clemens", ""], ["Tang", "Jie", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "2106.01070", "submitter": "Viet Anh Nguyen", "authors": "Nian Si and Karthyek Murthy and Jose Blanchet and Viet Anh Nguyen", "title": "Testing Group Fairness via Optimal Transport Projections", "comments": null, "journal-ref": "International Conference on Machine Learning 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a statistical testing framework to detect if a given machine\nlearning classifier fails to satisfy a wide range of group fairness notions.\nThe proposed test is a flexible, interpretable, and statistically rigorous tool\nfor auditing whether exhibited biases are intrinsic to the algorithm or due to\nthe randomness in the data. The statistical challenges, which may arise from\nmultiple impact criteria that define group fairness and which are discontinuous\non model parameters, are conveniently tackled by projecting the empirical\nmeasure onto the set of group-fair probability models using optimal transport.\nThis statistic is efficiently computed using linear programming and its\nasymptotic distribution is explicitly obtained. The proposed framework can also\nbe used to test for testing composite fairness hypotheses and fairness with\nmultiple sensitive attributes. The optimal transport testing formulation\nimproves interpretability by characterizing the minimal covariate perturbations\nthat eliminate the bias observed in the audit.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 10:51:39 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Si", "Nian", ""], ["Murthy", "Karthyek", ""], ["Blanchet", "Jose", ""], ["Nguyen", "Viet Anh", ""]]}, {"id": "2106.01098", "submitter": "Bastian Rieck", "authors": "Leslie O'Bray, Max Horn, Bastian Rieck, Karsten Borgwardt", "title": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and\n  Practical Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph generative models are a highly active branch of machine learning. Given\nthe steady development of new models of ever-increasing complexity, it is\nnecessary to provide a principled way to evaluate and compare them. In this\npaper, we enumerate the desirable criteria for comparison metrics, discuss the\ndevelopment of such metrics, and provide a comparison of their respective\nexpressive power. We perform a systematic evaluation of the main metrics in use\ntoday, highlighting some of the challenges and pitfalls researchers\ninadvertently can run into. We then describe a collection of suitable metrics,\ngive recommendations as to their practical suitability, and analyse their\nbehaviour on synthetically generated perturbed graphs as well as on recently\nproposed graph generative models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:04:29 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["O'Bray", "Leslie", ""], ["Horn", "Max", ""], ["Rieck", "Bastian", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "2106.01101", "submitter": "Gilad Yehudai", "authors": "Gal Vardi, Gilad Yehudai, Ohad Shamir", "title": "Learning a Single Neuron with Bias Using Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We theoretically study the fundamental problem of learning a single neuron\nwith a bias term ($\\mathbf{x} \\mapsto \\sigma(<\\mathbf{w},\\mathbf{x}> + b)$) in\nthe realizable setting with the ReLU activation, using gradient descent.\nPerhaps surprisingly, we show that this is a significantly different and more\nchallenging problem than the bias-less case (which was the focus of previous\nworks on single neurons), both in terms of the optimization geometry as well as\nthe ability of gradient methods to succeed in some scenarios. We provide a\ndetailed study of this problem, characterizing the critical points of the\nobjective, demonstrating failure cases, and providing positive convergence\nguarantees under different sets of assumptions. To prove our results, we\ndevelop some tools which may be of independent interest, and improve previous\nresults on learning single neurons.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:09:55 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Vardi", "Gal", ""], ["Yehudai", "Gilad", ""], ["Shamir", "Ohad", ""]]}, {"id": "2106.01109", "submitter": "Pritam Anand Dr.", "authors": "Pritam Anand, Reshma Rastogi and Suresh Chandra", "title": "Improvement over Pinball Loss Support Vector Machine", "comments": "The numerical results presented in this paper can be regenerated by\n  the code available at https://github.com/ltpritamanand/UnifiedPinSVM/ . We\n  hope that our this work will let the researchers to use the correct\n  formulation of Pin-SVM model in future and improve the predictions across\n  different domain of technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, there have been several papers that discuss the extension of the\nPinball loss Support Vector Machine (Pin-SVM) model, originally proposed by\nHuang et al.,[1][2]. Pin-SVM classifier deals with the pinball loss function,\nwhich has been defined in terms of the parameter $\\tau$. The parameter $\\tau$\ncan take values in $[ -1,1]$. The existing Pin-SVM model requires to solve the\nsame optimization problem for all values of $\\tau$ in $[ -1,1]$. In this paper,\nwe improve the existing Pin-SVM model for the binary classification task. At\nfirst, we note that there is major difficulty in Pin-SVM model (Huang et al.\n[1]) for $ -1 \\leq \\tau < 0$. Specifically, we show that the Pin-SVM model\nrequires the solution of different optimization problem for $ -1 \\leq \\tau <\n0$. We further propose a unified model termed as Unified Pin-SVM which results\nin a QPP valid for all $-1\\leq \\tau \\leq 1$ and hence more convenient to use.\nThe proposed Unified Pin-SVM model can obtain a significant improvement in\naccuracy over the existing Pin-SVM model which has also been empirically\njustified by extensive numerical experiments with real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:19:28 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Anand", "Pritam", ""], ["Rastogi", "Reshma", ""], ["Chandra", "Suresh", ""]]}, {"id": "2106.01121", "submitter": "Motonobu Kanagawa", "authors": "Veit Wild, Motonobu Kanagawa, Dino Sejdinovic", "title": "Connections and Equivalences between the Nystr\\\"om Method and Sparse\n  Variational Gaussian Processes", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the connections between sparse approximation methods for\nmaking kernel methods and Gaussian processes (GPs) scalable to massive data,\nfocusing on the Nystr\\\"om method and the Sparse Variational Gaussian Processes\n(SVGP). While sparse approximation methods for GPs and kernel methods share\nsome algebraic similarities, the literature lacks a deep understanding of how\nand why they are related. This is a possible obstacle for the communications\nbetween the GP and kernel communities, making it difficult to transfer results\nfrom one side to the other. Our motivation is to remove this possible obstacle,\nby clarifying the connections between the sparse approximations for GPs and\nkernel methods. In this work, we study the two popular approaches, the\nNystr\\\"om and SVGP approximations, in the context of a regression problem, and\nestablish various connections and equivalences between them. In particular, we\nprovide an RKHS interpretation of the SVGP approximation, and show that the\nEvidence Lower Bound of the SVGP contains the objective function of the\nNystr\\\"om approximation, revealing the origin of the algebraic equivalence\nbetween the two approaches. We also study recently established convergence\nresults for the SVGP and how they are related to the approximation quality of\nthe Nystr\\\"om method.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:45:49 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wild", "Veit", ""], ["Kanagawa", "Motonobu", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2106.01128", "submitter": "Meyer Scetbon", "authors": "Meyer Scetbon, Gabriel Peyr\\'e, Marco Cuturi", "title": "Linear-Time Gromov Wasserstein Distances using Low Rank Couplings and\n  Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to compare and align related datasets living in heterogeneous\nspaces plays an increasingly important role in machine learning. The\nGromov-Wasserstein (GW) formalism can help tackle this problem. Its main goal\nis to seek an assignment (more generally a coupling matrix) that can register\npoints across otherwise incomparable datasets. As a non-convex and quadratic\ngeneralization of optimal transport (OT), GW is NP-hard. Yet, heuristics are\nknown to work reasonably well in practice, the state of the art approach being\nto solve a sequence of nested regularized OT problems. While popular, that\nheuristic remains too costly to scale, with cubic complexity in the number of\nsamples $n$. We show in this paper how a recent variant of the Sinkhorn\nalgorithm can substantially speed up the resolution of GW. That variant\nrestricts the set of admissible couplings to those admitting a low rank\nfactorization as the product of two sub-couplings. By updating alternatively\neach sub-coupling, our algorithm computes a stationary point of the problem in\nquadratic time with respect to the number of samples. When cost matrices have\nthemselves low rank, our algorithm has time complexity $\\mathcal{O}(n)$. We\ndemonstrate the efficiency of our method on simulated and real data.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:50:56 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Scetbon", "Meyer", ""], ["Peyr\u00e9", "Gabriel", ""], ["Cuturi", "Marco", ""]]}, {"id": "2106.01143", "submitter": "Leonardo Zepeda-N\\'u\\~nez", "authors": "Matthew Li, Laurent Demanet, Leonardo Zepeda-N\\'u\\~nez", "title": "Accurate and Robust Deep Learning Framework for Solving Wave-Based\n  Inverse Problems in the Super-Resolution Regime", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end deep learning framework that comprehensively solves\nthe inverse wave scattering problem across all length scales. Our framework\nconsists of the newly introduced wide-band butterfly network coupled with a\nsimple training procedure that dynamically injects noise during training. While\nour trained network provides competitive results in classical imaging regimes,\nmost notably it also succeeds in the super-resolution regime where other\ncomparable methods fail. This encompasses both (i) reconstruction of scatterers\nwith sub-wavelength geometric features, and (ii) accurate imaging when two or\nmore scatterers are separated by less than the classical diffraction limit. We\ndemonstrate these properties are retained even in the presence of strong noise\nand extend to scatterers not previously seen in the training set. In addition,\nour network is straightforward to train requiring no restarts and has an online\nruntime that is an order of magnitude faster than optimization-based\nalgorithms. We perform experiments with a variety of wave scattering mediums\nand we demonstrate that our proposed framework outperforms both classical\ninversion and competing network architectures that specialize in oscillatory\nwave scattering data.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 13:30:28 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Li", "Matthew", ""], ["Demanet", "Laurent", ""], ["Zepeda-N\u00fa\u00f1ez", "Leonardo", ""]]}, {"id": "2106.01202", "submitter": "Pierre Marion", "authors": "Adeline Fermanian, Pierre Marion, Jean-Philippe Vert, G\\'erard Biau", "title": "Framing RNN as a kernel method: A neural ODE approach", "comments": "32 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the interpretation of a recurrent neural network (RNN) as a\ncontinuous-time neural differential equation, we show, under appropriate\nconditions, that the solution of a RNN can be viewed as a linear function of a\nspecific feature set of the input sequence, known as the signature. This\nconnection allows us to frame a RNN as a kernel method in a suitable\nreproducing kernel Hilbert space. As a consequence, we obtain theoretical\nguarantees on generalization and stability for a large class of recurrent\nnetworks. Our results are illustrated on simulated datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:46:40 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Fermanian", "Adeline", ""], ["Marion", "Pierre", ""], ["Vert", "Jean-Philippe", ""], ["Biau", "G\u00e9rard", ""]]}, {"id": "2106.01257", "submitter": "Alexey Naumov", "authors": "Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov, Kevin\n  Scaman, Hoi-To Wai", "title": "Tight High Probability Bounds for Linear Stochastic Approximation with\n  Fixed Stepsize", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper provides a non-asymptotic analysis of linear stochastic\napproximation (LSA) algorithms with fixed stepsize. This family of methods\narises in many machine learning tasks and is used to obtain approximate\nsolutions of a linear system $\\bar{A}\\theta = \\bar{b}$ for which $\\bar{A}$ and\n$\\bar{b}$ can only be accessed through random estimates $\\{({\\bf A}_n, {\\bf\nb}_n): n \\in \\mathbb{N}^*\\}$. Our analysis is based on new results regarding\nmoments and high probability bounds for products of matrices which are shown to\nbe tight. We derive high probability bounds on the performance of LSA under\nweaker conditions on the sequence $\\{({\\bf A}_n, {\\bf b}_n): n \\in\n\\mathbb{N}^*\\}$ than previous works. However, in contrast, we establish\npolynomial concentration bounds with order depending on the stepsize. We show\nthat our conclusions cannot be improved without additional assumptions on the\nsequence of random matrices $\\{{\\bf A}_n: n \\in \\mathbb{N}^*\\}$, and in\nparticular that no Gaussian or exponential high probability bounds can hold.\nFinally, we pay a particular attention to establishing bounds with sharp order\nwith respect to the number of iterations and the stepsize and whose leading\nterms contain the covariance matrices appearing in the central limit theorems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:10:37 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Durmus", "Alain", ""], ["Moulines", "Eric", ""], ["Naumov", "Alexey", ""], ["Samsonov", "Sergey", ""], ["Scaman", "Kevin", ""], ["Wai", "Hoi-To", ""]]}, {"id": "2106.01260", "submitter": "Patrick Rubin-Delanchy Dr", "authors": "Nick Whiteley, Annie Gray and Patrick Rubin-Delanchy", "title": "Matrix factorisation and the interpretation of geodesic distance", "comments": "28 pages; 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a graph or similarity matrix, we consider the problem of recovering a\nnotion of true distance between the nodes, and so their true positions. Through\nnew insights into the manifold geometry underlying a generic latent position\nmodel, we show that this can be accomplished in two steps: matrix\nfactorisation, followed by nonlinear dimension reduction. This combination is\neffective because the point cloud obtained in the first step lives close to a\nmanifold in which latent distance is encoded as geodesic distance. Hence, a\nnonlinear dimension reduction tool, approximating geodesic distance, can\nrecover the latent positions, up to a simple transformation. We give a detailed\naccount of the case where spectral embedding is used, followed by Isomap, and\nprovide encouraging experimental evidence for other combinations of techniques.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:11:33 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Whiteley", "Nick", ""], ["Gray", "Annie", ""], ["Rubin-Delanchy", "Patrick", ""]]}, {"id": "2106.01271", "submitter": "Jonathan Dumas", "authors": "Jonathan Dumas, Colin Cointe, Xavier Fettweis, Bertrand Corn\\'elusse", "title": "Deep learning-based multi-output quantile forecasting of PV generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper develops probabilistic PV forecasters by taking advantage of\nrecent breakthroughs in deep learning. It tailored forecasting tool, named\nencoder-decoder, is implemented to compute intraday multi-output PV quantiles\nforecasts to efficiently capture the time correlation. The models are trained\nusing quantile regression, a non-parametric approach that assumes no prior\nknowledge of the probabilistic forecasting distribution. The case study is\ncomposed of PV production monitored on-site at the University of Li\\`ege\n(ULi\\`ege), Belgium. The weather forecasts from the regional climate model\nprovided by the Laboratory of Climatology are used as inputs of the deep\nlearning models. The forecast quality is quantitatively assessed by the\ncontinuous ranked probability and interval scores. The results indicate this\narchitecture improves the forecast quality and is computationally efficient to\nbe incorporated in an intraday decision-making tool for robust optimization.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:28:10 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 16:19:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dumas", "Jonathan", ""], ["Cointe", "Colin", ""], ["Fettweis", "Xavier", ""], ["Corn\u00e9lusse", "Bertrand", ""]]}, {"id": "2106.01277", "submitter": "Pierre Gutierrez", "authors": "Pierre Gutierrez, Antoine Cordier, Tha\\\"is Caldeira, Th\\'eophile\n  Sautory", "title": "Data augmentation and pre-trained networks for extremely low data\n  regimes unsupervised visual inspection", "comments": "16 pages, 8 figures, 9 tables, SPIE proceedings of Optical Metrology\n  conference (https://spie.org/conferences-and-exhibitions/optical-metrology)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of deep features coming from pre-trained neural networks for\nunsupervised anomaly detection purposes has recently gathered momentum in the\ncomputer vision field. In particular, industrial inspection applications can\ntake advantage of such features, as demonstrated by the multiple successes of\nrelated methods on the MVTec Anomaly Detection (MVTec AD) dataset. These\nmethods make use of neural networks pre-trained on auxiliary classification\ntasks such as ImageNet. However, to our knowledge, no comparative study of\nrobustness to the low data regimes between these approaches has been conducted\nyet. For quality inspection applications, the handling of limited sample sizes\nmay be crucial as large quantities of images are not available for small\nseries. In this work, we aim to compare three approaches based on deep\npre-trained features when varying the quantity of available data in MVTec AD:\nKNN, Mahalanobis, and PaDiM. We show that although these methods are mostly\nrobust to small sample sizes, they still can benefit greatly from using data\naugmentation in the original image space, which allows to deal with very small\nproduction runs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:37:20 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Gutierrez", "Pierre", ""], ["Cordier", "Antoine", ""], ["Caldeira", "Tha\u00efs", ""], ["Sautory", "Th\u00e9ophile", ""]]}, {"id": "2106.01282", "submitter": "Patrick Rubin-Delanchy Dr", "authors": "Ian Gallagher, Andrew Jones and Patrick Rubin-Delanchy", "title": "Spectral embedding for dynamic networks with stability guarantees", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of embedding a dynamic network, to obtain\ntime-evolving vector representations of each node, which can then be used to\ndescribe the changes in behaviour of a single node, one or more communities, or\nthe entire graph. Given this open-ended remit, we wish to guarantee stability\nin the spatio-temporal positioning of the nodes: assigning the same position,\nup to noise, to nodes behaving similarly at a given time (cross-sectional\nstability) and a constant position, up to noise, to a single node behaving\nsimilarly across different times (longitudinal stability). These properties are\ndefined formally within a generic dynamic latent position model. By showing how\nthis model can be recast as a multilayer random dot product graph, we\ndemonstrate that unfolded adjacency spectral embedding satisfies both stability\nconditions, allowing, for example, spatio-temporal clustering under the dynamic\nstochastic block model. We also show how alternative methods, such as omnibus,\nindependent or time-averaged spectral embedding, lack one or the other form of\nstability.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:43:43 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Gallagher", "Ian", ""], ["Jones", "Andrew", ""], ["Rubin-Delanchy", "Patrick", ""]]}, {"id": "2106.01325", "submitter": "David Lindner", "authors": "David Lindner and Hoda Heidari and Andreas Krause", "title": "Addressing the Long-term Impact of ML Decisions via Policy Regret", "comments": "Accepted to IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) increasingly informs the allocation of opportunities to\nindividuals and communities in areas such as lending, education, employment,\nand beyond. Such decisions often impact their subjects' future characteristics\nand capabilities in an a priori unknown fashion. The decision-maker, therefore,\nfaces exploration-exploitation dilemmas akin to those in multi-armed bandits.\nFollowing prior work, we model communities as arms. To capture the long-term\neffects of ML-based allocation decisions, we study a setting in which the\nreward from each arm evolves every time the decision-maker pulls that arm. We\nfocus on reward functions that are initially increasing in the number of pulls\nbut may become (and remain) decreasing after a certain point. We argue that an\nacceptable sequential allocation of opportunities must take an arm's potential\nfor growth into account. We capture these considerations through the notion of\npolicy regret, a much stronger notion than the often-studied external regret,\nand present an algorithm with provably sub-linear policy regret for\nsufficiently long time horizons. We empirically compare our algorithm with\nseveral baselines and find that it consistently outperforms them, in particular\nfor long time horizons.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:38:10 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Lindner", "David", ""], ["Heidari", "Hoda", ""], ["Krause", "Andreas", ""]]}, {"id": "2106.01336", "submitter": "Huanyu Zhang", "authors": "Gautam Kamath, Xingtu Liu, Huanyu Zhang", "title": "Improved Rates for Differentially Private Stochastic Convex Optimization\n  with Heavy-Tailed Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic convex optimization with heavy-tailed data under the\nconstraint of differential privacy. Most prior work on this problem is\nrestricted to the case where the loss function is Lipschitz. Instead, as\nintroduced by Wang, Xiao, Devadas, and Xu, we study general convex loss\nfunctions with the assumption that the distribution of gradients has bounded\n$k$-th moments. We provide improved upper bounds on the excess population risk\nunder approximate differential privacy of\n$\\tilde{O}\\left(\\sqrt{\\frac{d}{n}}+\\left(\\frac{d}{\\epsilon\nn}\\right)^{\\frac{k-1}{k}}\\right)$ and\n$\\tilde{O}\\left(\\frac{d}{n}+\\left(\\frac{d}{\\epsilon\nn}\\right)^{\\frac{2k-2}{k}}\\right)$ for convex and strongly convex loss\nfunctions, respectively. We also prove nearly-matching lower bounds under the\nconstraint of pure differential privacy, giving strong evidence that our bounds\nare tight.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:45:47 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 04:40:12 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Kamath", "Gautam", ""], ["Liu", "Xingtu", ""], ["Zhang", "Huanyu", ""]]}, {"id": "2106.01342", "submitter": "Gowthami Somepalli", "authors": "Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C. Bayan Bruss,\n  Tom Goldstein", "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and\n  Contrastive Pre-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tabular data underpins numerous high-impact applications of machine learning\nfrom fraud detection to genomics and healthcare. Classical approaches to\nsolving tabular problems, such as gradient boosting and random forests, are\nwidely used by practitioners. However, recent deep learning methods have\nachieved a degree of performance competitive with popular techniques. We devise\na hybrid deep learning approach to solving tabular data problems. Our method,\nSAINT, performs attention over both rows and columns, and it includes an\nenhanced embedding method. We also study a new contrastive self-supervised\npre-training method for use when labels are scarce. SAINT consistently improves\nperformance over previous deep learning methods, and it even outperforms\ngradient boosting methods, including XGBoost, CatBoost, and LightGBM, on\naverage over a variety of benchmark tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 17:51:05 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Somepalli", "Gowthami", ""], ["Goldblum", "Micah", ""], ["Schwarzschild", "Avi", ""], ["Bruss", "C. Bayan", ""], ["Goldstein", "Tom", ""]]}, {"id": "2106.01357", "submitter": "Valentin De Bortoli", "authors": "Valentin De Bortoli, James Thornton, Jeremy Heng, Arnaud Doucet", "title": "Diffusion Schr\\\"odinger Bridge with Applications to Score-Based\n  Generative Modeling", "comments": "57 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Progressively applying Gaussian noise transforms complex data distributions\nto approximately Gaussian. Reversing this dynamic defines a generative model.\nWhen the forward noising process is given by a Stochastic Differential Equation\n(SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the\nassociated reverse-time SDE may be estimated using score-matching. A limitation\nof this approach is that the forward-time SDE must be run for a sufficiently\nlong time for the final distribution to be approximately Gaussian. In contrast,\nsolving the Schr\\\"odinger Bridge problem (SB), i.e. an entropy-regularized\noptimal transport problem on path spaces, yields diffusions which generate\nsamples from the data distribution in finite time. We present Diffusion SB\n(DSB), an original approximation of the Iterative Proportional Fitting (IPF)\nprocedure to solve the SB problem, and provide theoretical analysis along with\ngenerative modeling experiments. The first DSB iteration recovers the\nmethodology proposed by Song et al. (2021), with the flexibility of using\nshorter time intervals, as subsequent DSB iterations reduce the discrepancy\nbetween the final-time marginal of the forward (resp. backward) SDE with\nrespect to the prior (resp. data) distribution. Beyond generative modeling, DSB\noffers a widely applicable computational optimal transport tool as the\ncontinuous state-space analogue of the popular Sinkhorn algorithm (Cuturi,\n2013).\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:34:27 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 13:27:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["De Bortoli", "Valentin", ""], ["Thornton", "James", ""], ["Heng", "Jeremy", ""], ["Doucet", "Arnaud", ""]]}, {"id": "2106.01413", "submitter": "Anthony Caterini", "authors": "Anthony L. Caterini, Gabriel Loaiza-Ganem, Geoff Pleiss, John P.\n  Cunningham", "title": "Rectangular Flows for Manifold Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are invertible neural networks with tractable\nchange-of-volume terms, which allows optimization of their parameters to be\nefficiently performed via maximum likelihood. However, data of interest is\ntypically assumed to live in some (often unknown) low-dimensional manifold\nembedded in high-dimensional ambient space. The result is a modelling mismatch\nsince -- by construction -- the invertibility requirement implies\nhigh-dimensional support of the learned distribution. Injective flows, mapping\nfrom low- to high-dimensional space, aim to fix this discrepancy by learning\ndistributions on manifolds, but the resulting volume-change term becomes more\nchallenging to evaluate. Current approaches either avoid computing this term\nentirely using various heuristics, or assume the manifold is known beforehand\nand therefore are not widely applicable. Instead, we propose two methods to\ntractably calculate the gradient of this term with respect to the parameters of\nthe model, relying on careful use of automatic differentiation and techniques\nfrom numerical linear algebra. Both approaches perform end-to-end nonlinear\nmanifold learning and density estimation for data projected onto this manifold.\nWe study the trade-offs between our proposed methods, empirically verify that\nwe outperform approaches ignoring the volume-change term by more accurately\nlearning manifolds and the corresponding distributions on them, and show\npromising results on out-of-distribution detection.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 18:30:39 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Caterini", "Anthony L.", ""], ["Loaiza-Ganem", "Gabriel", ""], ["Pleiss", "Geoff", ""], ["Cunningham", "John P.", ""]]}, {"id": "2106.01420", "submitter": "Amin Karbasi", "authors": "Amin Karbasi, Vahab Mirrokni, Mohammad Shadravan", "title": "Parallelizing Thompson Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can we make use of information parallelism in online decision making\nproblems while efficiently balancing the exploration-exploitation trade-off? In\nthis paper, we introduce a batch Thompson Sampling framework for two canonical\nonline decision making problems, namely, stochastic multi-arm bandit and linear\ncontextual bandit with finitely many arms. Over a time horizon $T$, our\n\\textit{batch} Thompson Sampling policy achieves the same (asymptotic) regret\nbound of a fully sequential one while carrying out only $O(\\log T)$ batch\nqueries. To achieve this exponential reduction, i.e., reducing the number of\ninteractions from $T$ to $O(\\log T)$, our batch policy dynamically determines\nthe duration of each batch in order to balance the exploration-exploitation\ntrade-off. We also demonstrate experimentally that dynamic batch allocation\ndramatically outperforms natural baselines such as static batch allocations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 18:51:57 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Karbasi", "Amin", ""], ["Mirrokni", "Vahab", ""], ["Shadravan", "Mohammad", ""]]}, {"id": "2106.01429", "submitter": "Gabriel Peyr\\'e", "authors": "Clarice Poon and Gabriel Peyr\\'e", "title": "Smooth Bilevel Programming for Sparse Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Iteratively reweighted least square (IRLS) is a popular approach to solve\nsparsity-enforcing regression problems in machine learning. State of the art\napproaches are more efficient but typically rely on specific coordinate pruning\nschemes. In this work, we show how a surprisingly simple reparametrization of\nIRLS, coupled with a bilevel resolution (instead of an alternating scheme) is\nable to achieve top performances on a wide range of sparsity (such as Lasso,\ngroup Lasso and trace norm regularizations), regularization strength (including\nhard constraints), and design matrices (ranging from correlated designs to\ndifferential operators). Similarly to IRLS, our method only involves linear\nsystems resolutions, but in sharp contrast, corresponds to the minimization of\na smooth function. Despite being non-convex, we show that there is no spurious\nminima and that saddle points are \"ridable\", so that there always exists a\ndescent direction. We thus advocate for the use of a BFGS quasi-Newton solver,\nwhich makes our approach simple, robust and efficient. We perform a numerical\nbenchmark of the convergence speed of our algorithm against state of the art\nsolvers for Lasso, group Lasso, trace norm and linearly constrained problems.\nThese results highlight the versatility of our approach, removing the need to\nuse different solvers depending on the specificity of the ML problem under\nstudy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 19:18:22 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Poon", "Clarice", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "2106.01474", "submitter": "Chengchun Shi", "authors": "Chengchun Shi, Yunzhe Zhou and Lexin Li", "title": "Testing Directed Acyclic Graph via Structural, Supervised and Generative\n  Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a new hypothesis testing method for directed\nacyclic graph (DAG). While there is a rich class of DAG estimation methods,\nthere is a relative paucity of DAG inference solutions. Moreover, the existing\nmethods often impose some specific model structures such as linear models or\nadditive models, and assume independent data observations. Our proposed test\ninstead allows the associations among the random variables to be nonlinear and\nthe data to be time-dependent. We build the test based on some highly flexible\nneural networks learners. We establish the asymptotic guarantees of the test,\nwhile allowing either the number of subjects or the number of time points for\neach subject to diverge to infinity. We demonstrate the efficacy of the test\nthrough simulations and a brain connectivity network analysis.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 21:18:59 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Shi", "Chengchun", ""], ["Zhou", "Yunzhe", ""], ["Li", "Lexin", ""]]}, {"id": "2106.01485", "submitter": "Chengliang Tang", "authors": "Chengliang Tang, Gan Yuan, Tian Zheng", "title": "Weakly Supervised Learning Creates a Fusion of Modeling Cultures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past two decades have witnessed the great success of the algorithmic\nmodeling framework advocated by Breiman et al. (2001). Nevertheless, the\nexcellent prediction performance of these black-box models rely heavily on the\navailability of strong supervision, i.e. a large set of accurate and exact\nground-truth labels. In practice, strong supervision can be unavailable or\nexpensive, which calls for modeling techniques under weak supervision. In this\ncomment, we summarize the key concepts in weakly supervised learning and\ndiscuss some recent developments in the field. Using algorithmic modeling alone\nunder a weak supervision might lead to unstable and misleading results. A\npromising direction would be integrating the data modeling culture into such a\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 21:52:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Tang", "Chengliang", ""], ["Yuan", "Gan", ""], ["Zheng", "Tian", ""]]}, {"id": "2106.01506", "submitter": "Matthew A. Wright", "authors": "Matthew A. Wright, Joseph E. Gonzalez", "title": "Transformers are Deep Infinite-Dimensional Non-Mercer Binary Kernel\n  Machines", "comments": "Work in progress, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their ubiquity in core AI fields like natural language processing,\nthe mechanics of deep attention-based neural networks like the Transformer\nmodel are not fully understood. In this article, we present a new perspective\ntowards understanding how Transformers work. In particular, we show that the\n\"dot-product attention\" that is the core of the Transformer's operation can be\ncharacterized as a kernel learning method on a pair of Banach spaces. In\nparticular, the Transformer's kernel is characterized as having an infinite\nfeature dimension. Along the way we consider an extension of the standard\nkernel learning problem to a binary setting, where data come from two input\ndomains and a response is defined for every cross-domain pair. We prove a new\nrepresenter theorem for these binary kernel machines with non-Mercer\n(indefinite, asymmetric) kernels (implying that the functions learned are\nelements of reproducing kernel Banach spaces rather than Hilbert spaces), and\nalso prove a new universal approximation theorem showing that the Transformer\ncalculation can learn any binary non-Mercer reproducing kernel Banach space\npair. We experiment with new kernels in Transformers, and obtain results that\nsuggest the infinite dimensionality of the standard Transformer kernel is\npartially responsible for its performance. This paper's results provide a new\ntheoretical understanding of a very important but poorly understood model in\nmodern machine~learning.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 23:24:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Wright", "Matthew A.", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2106.01528", "submitter": "Derek Hansen", "authors": "Derek Hansen, Brian Manzo, Jeffrey Regier", "title": "Normalizing Flows for Knockoff-free Controlled Feature Selection", "comments": "17 pages, 4 figures. Under review at Neurips 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of controlled feature selection is to discover the features a\nresponse depends on while limiting the proportion of false discoveries to a\npredefined level. Recently, multiple methods have been proposed that use deep\nlearning to generate knockoffs for controlled feature selection through the\nModel-X knockoff framework. We demonstrate, however, that these methods often\nfail to control the false discovery rate (FDR). There are two reasons for this\nshortcoming. First, these methods often learn inaccurate models of features.\nSecond, the \"swap\" property, which is required for knockoffs to be valid, is\noften not well enforced. We propose a new procedure called FlowSelect that\nremedies both of these problems. To more accurately model the features,\nFlowSelect uses normalizing flows, the state-of-the-art method for density\nestimation. To circumvent the need to enforce the swap property, FlowSelect\nuses a novel MCMC-based procedure to directly compute p-values for each\nfeature. Asymptotically, FlowSelect controls the FDR exactly. Empirically,\nFlowSelect controls the FDR well on both synthetic and semi-synthetic\nbenchmarks, whereas competing knockoff-based approaches fail to do so.\nFlowSelect also demonstrates greater power on these benchmarks. Additionally,\nusing data from a genome-wide association study of soybeans, FlowSelect\ncorrectly infers the genetic variants associated with specific soybean traits.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 01:19:01 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Hansen", "Derek", ""], ["Manzo", "Brian", ""], ["Regier", "Jeffrey", ""]]}, {"id": "2106.01529", "submitter": "Alden Green", "authors": "Alden Green, Sivaraman Balakrishnan, Ryan J. Tibshirani", "title": "Minimax Optimal Regression over Sobolev Spaces via Laplacian\n  Regularization on Neighborhood Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we study the statistical properties of Laplacian smoothing, a\ngraph-based approach to nonparametric regression. Under standard regularity\nconditions, we establish upper bounds on the error of the Laplacian smoothing\nestimator $\\widehat{f}$, and a goodness-of-fit test also based on\n$\\widehat{f}$. These upper bounds match the minimax optimal estimation and\ntesting rates of convergence over the first-order Sobolev class\n$H^1(\\mathcal{X})$, for $\\mathcal{X}\\subseteq \\mathbb{R}^d$ and $1 \\leq d < 4$;\nin the estimation problem, for $d = 4$, they are optimal modulo a $\\log n$\nfactor. Additionally, we prove that Laplacian smoothing is manifold-adaptive:\nif $\\mathcal{X} \\subseteq \\mathbb{R}^d$ is an $m$-dimensional manifold with $m\n< d$, then the error rate of Laplacian smoothing (in either estimation or\ntesting) depends only on $m$, in the same way it would if $\\mathcal{X}$ were a\nfull-dimensional set in $\\mathbb{R}^d$.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 01:20:41 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Green", "Alden", ""], ["Balakrishnan", "Sivaraman", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "2106.01584", "submitter": "Hoon Hwangbo", "authors": "Di Bo, Hoon Hwangbo, Vinit Sharma, Corey Arndt, Stephanie C. TerMaath", "title": "A Subspace-based Approach for Dimensionality Reduction and Important\n  Variable Selection", "comments": "16 pages, 4 figures, will be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An analysis of high dimensional data can offer a detailed description of a\nsystem but is often challenged by the curse of dimensionality. General\ndimensionality reduction techniques can alleviate such difficulty by extracting\na few important features, but they are limited due to the lack of\ninterpretability and connectivity to actual decision making associated with\neach physical variable. Important variable selection techniques, as an\nalternative, can maintain the interpretability, but they often involve a greedy\nsearch that is susceptible to failure in capturing important interactions. This\nresearch proposes a new method that produces subspaces, reduced-dimensional\nphysical spaces, based on a randomized search and forms an ensemble of models\nfor critical subspaces. When applied to high-dimensional data collected from a\ncomposite metal development process, the proposed method shows its superiority\nin prediction and important variable selection.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 04:10:34 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bo", "Di", ""], ["Hwangbo", "Hoon", ""], ["Sharma", "Vinit", ""], ["Arndt", "Corey", ""], ["TerMaath", "Stephanie C.", ""]]}, {"id": "2106.01604", "submitter": "Hyun-Jin Park", "authors": "Hyun-Jin Park, Pai Zhu, Ignacio Lopez Moreno, Niranjan Subrahmanya", "title": "Noisy student-teacher training for robust keyword spotting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose self-training with noisy student-teacher approach for streaming\nkeyword spotting, that can utilize large-scale unlabeled data and aggressive\ndata augmentation. The proposed method applies aggressive data augmentation\n(spectral augmentation) on the input of both student and teacher and utilize\nunlabeled data at scale, which significantly boosts the accuracy of student\nagainst challenging conditions. Such aggressive augmentation usually degrades\nmodel performance when used with supervised training with hard-labeled data.\nExperiments show that aggressive spec augmentation on baseline supervised\ntraining method degrades accuracy, while the proposed self-training with noisy\nstudent-teacher training improves accuracy of some difficult-conditioned test\nsets by as much as 60%.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 05:36:18 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Park", "Hyun-Jin", ""], ["Zhu", "Pai", ""], ["Moreno", "Ignacio Lopez", ""], ["Subrahmanya", "Niranjan", ""]]}, {"id": "2106.01606", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Ke Xu, Xiao Yang, Tianyu Pang, Zhijie Deng, Hang Su, Jun\n  Zhu", "title": "Exploring Memorization in Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that deep learning models have a propensity for fitting the\nentire training set even with random labels, which requires memorization of\nevery training sample. In this paper, we investigate the memorization effect in\nadversarial training (AT) for promoting a deeper understanding of capacity,\nconvergence, generalization, and especially robust overfitting of adversarially\ntrained classifiers. We first demonstrate that deep networks have sufficient\ncapacity to memorize adversarial examples of training data with completely\nrandom labels, but not all AT algorithms can converge under the extreme\ncircumstance. Our study of AT with random labels motivates further analyses on\nthe convergence and generalization of AT. We find that some AT methods suffer\nfrom a gradient instability issue, and the recently suggested complexity\nmeasures cannot explain robust generalization by considering models trained on\nrandom labels. Furthermore, we identify a significant drawback of memorization\nin AT that it could result in robust overfitting. We then propose a new\nmitigation algorithm motivated by detailed memorization analyses. Extensive\nexperiments on various datasets validate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 05:39:57 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Dong", "Yinpeng", ""], ["Xu", "Ke", ""], ["Yang", "Xiao", ""], ["Pang", "Tianyu", ""], ["Deng", "Zhijie", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2106.01660", "submitter": "Botao Hao", "authors": "Tor Lattimore, Botao Hao", "title": "Bandit Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a bandit version of phase retrieval where the learner chooses\nactions $(A_t)_{t=1}^n$ in the $d$-dimensional unit ball and the expected\nreward is $\\langle A_t, \\theta_\\star\\rangle^2$ where $\\theta_\\star \\in \\mathbb\nR^d$ is an unknown parameter vector. We prove that the minimax cumulative\nregret in this problem is $\\smash{\\tilde \\Theta(d \\sqrt{n})}$, which improves\non the best known bounds by a factor of $\\smash{\\sqrt{d}}$. We also show that\nthe minimax simple regret is $\\smash{\\tilde \\Theta(d / \\sqrt{n})}$ and that\nthis is only achievable by an adaptive algorithm. Our analysis shows that an\napparently convincing heuristic for guessing lower bounds can be misleading and\nthat uniform bounds on the information ratio for information-directed sampling\nare not sufficient for optimal regret.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:04:33 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 15:52:52 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Lattimore", "Tor", ""], ["Hao", "Botao", ""]]}, {"id": "2106.01682", "submitter": "Olivier Sprangers", "authors": "Olivier Sprangers, Sebastian Schelter, Maarten de Rijke", "title": "Probabilistic Gradient Boosting Machines for Large-Scale Probabilistic\n  Regression", "comments": null, "journal-ref": null, "doi": "10.1145/3447548.3467278", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient Boosting Machines (GBM) are hugely popular for solving tabular data\nproblems. However, practitioners are not only interested in point predictions,\nbut also in probabilistic predictions in order to quantify the uncertainty of\nthe predictions. Creating such probabilistic predictions is difficult with\nexisting GBM-based solutions: they either require training multiple models or\nthey become too computationally expensive to be useful for large-scale\nsettings. We propose Probabilistic Gradient Boosting Machines (PGBM), a method\nto create probabilistic predictions with a single ensemble of decision trees in\na computationally efficient manner. PGBM approximates the leaf weights in a\ndecision tree as a random variable, and approximates the mean and variance of\neach sample in a dataset via stochastic tree ensemble update equations. These\nlearned moments allow us to subsequently sample from a specified distribution\nafter training. We empirically demonstrate the advantages of PGBM compared to\nexisting state-of-the-art methods: (i) PGBM enables probabilistic estimates\nwithout compromising on point performance in a single model, (ii) PGBM learns\nprobabilistic estimates via a single model only (and without requiring\nmulti-parameter boosting), and thereby offers a speedup of up to several orders\nof magnitude over existing state-of-the-art methods on large datasets, and\n(iii) PGBM achieves accurate probabilistic estimates in tasks with complex\ndifferentiable loss functions, such as hierarchical time series problems, where\nwe observed up to 10% improvement in point forecasting performance and up to\n300% improvement in probabilistic forecasting performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:32:13 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 15:26:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sprangers", "Olivier", ""], ["Schelter", "Sebastian", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2106.01712", "submitter": "Jonas Wallin", "authors": "David Bolin and Jonas Wallin", "title": "Efficient methods for Gaussian Markov random fields under sparse linear\n  constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for inference and simulation of linearly constrained Gaussian Markov\nRandom Fields (GMRF) are computationally prohibitive when the number of\nconstraints is large. In some cases, such as for intrinsic GMRFs, they may even\nbe unfeasible. We propose a new class of methods to overcome these challenges\nin the common case of sparse constraints, where one has a large number of\nconstraints and each only involves a few elements. Our methods rely on a basis\ntransformation into blocks of constrained versus non-constrained subspaces, and\nwe show that the methods greatly outperform existing alternatives in terms of\ncomputational cost. By combining the proposed methods with the stochastic\npartial differential equation approach for Gaussian random fields, we also show\nhow to formulate Gaussian process regression with linear constraints in a GMRF\nsetting to reduce computational cost. This is illustrated in two applications\nwith simulated data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:31:12 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bolin", "David", ""], ["Wallin", "Jonas", ""]]}, {"id": "2106.01713", "submitter": "Bruno Sudret", "authors": "M. Moustapha, S. Marelli and B. Sudret", "title": "A generalized framework for active learning reliability: survey and\n  benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": "RSUQ-2021-002", "categories": "stat.CO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning methods have recently surged in the literature due to their\nability to solve complex structural reliability problems within an affordable\ncomputational cost. These methods are designed by adaptively building an\ninexpensive surrogate of the original limit-state function. Examples of such\nsurrogates include Gaussian process models which have been adopted in many\ncontributions, the most popular ones being the efficient global reliability\nanalysis (EGRA) and the active Kriging Monte Carlo simulation (AK-MCS), two\nmilestone contributions in the field. In this paper, we first conduct a survey\nof the recent literature, showing that most of the proposed methods actually\nspan from modifying one or more aspects of the two aforementioned methods. We\nthen propose a generalized modular framework to build on-the-fly efficient\nactive learning strategies by combining the following four ingredients or\nmodules: surrogate model, reliability estimation algorithm, learning function\nand stopping criterion. Using this framework, we devise 39 strategies for the\nsolution of 20 reliability benchmark problems. The results of this extensive\nbenchmark are analyzed under various criteria leading to a synthesized set of\nrecommendations for practitioners. These may be refined with a priori knowledge\nabout the feature of the problem to solve, i.e., dimensionality and magnitude\nof the failure probability. This benchmark has eventually highlighted the\nimportance of using surrogates in conjunction with sophisticated reliability\nestimation algorithms as a way to enhance the efficiency of the latter.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:33:59 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Moustapha", "M.", ""], ["Marelli", "S.", ""], ["Sudret", "B.", ""]]}, {"id": "2106.01723", "submitter": "Aur\\'elien Bibaut", "authors": "Aur\\'elien Bibaut and Antoine Chambaz and Maria Dimakopoulou and\n  Nathan Kallus and Mark van der Laan", "title": "Risk Minimization from Adaptively Collected Data: Guarantees for\n  Supervised and Policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical risk minimization (ERM) is the workhorse of machine learning,\nwhether for classification and regression or for off-policy policy learning,\nbut its model-agnostic guarantees can fail when we use adaptively collected\ndata, such as the result of running a contextual bandit algorithm. We study a\ngeneric importance sampling weighted ERM algorithm for using adaptively\ncollected data to minimize the average of a loss function over a hypothesis\nclass and provide first-of-their-kind generalization guarantees and fast\nconvergence rates. Our results are based on a new maximal inequality that\ncarefully leverages the importance sampling structure to obtain rates with the\nright dependence on the exploration rate in the data. For regression, we\nprovide fast rates that leverage the strong convexity of squared-error loss.\nFor policy learning, we provide rate-optimal regret guarantees that close an\nopen gap in the existing literature whenever exploration decays to zero, as is\nthe case for bandit-collected data. An empirical investigation validates our\ntheory.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:50:13 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bibaut", "Aur\u00e9lien", ""], ["Chambaz", "Antoine", ""], ["Dimakopoulou", "Maria", ""], ["Kallus", "Nathan", ""], ["van der Laan", "Mark", ""]]}, {"id": "2106.01770", "submitter": "Susanne Trick", "authors": "Susanne Trick, Constantin A. Rothkopf", "title": "A Normative Model of Classifier Fusion", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining the outputs of multiple classifiers or experts into a single\nprobabilistic classification is a fundamental task in machine learning with\nbroad applications from classifier fusion to expert opinion pooling. Here we\npresent a hierarchical Bayesian model of probabilistic classifier fusion based\non a new correlated Dirichlet distribution. This distribution explicitly models\npositive correlations between marginally Dirichlet-distributed random vectors\nthereby allowing normative modeling of correlations between base classifiers or\nexperts. The proposed model naturally accommodates the classic Independent\nOpinion Pool and other independent fusion algorithms as special cases. It is\nevaluated by uncertainty reduction and correctness of fusion on synthetic and\nreal-world data sets. We show that a change in performance of the fused\nclassifier due to uncertainty reduction can be Bayes optimal even for highly\ncorrelated base classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 11:52:13 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Trick", "Susanne", ""], ["Rothkopf", "Constantin A.", ""]]}, {"id": "2106.01808", "submitter": "Thierry Mora", "authors": "Giulio Isacchini, Natanael Spisak, Armita Nourmohammad, Thierry Mora,\n  Aleksandra M. Walczak", "title": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood\n  Inference from Sampled Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-based inference enables learning the parameters of a model even\nwhen its likelihood cannot be computed in practice. One class of methods uses\ndata simulated with different parameters to infer an amortized estimator for\nthe likelihood-to-evidence ratio, or equivalently the posterior function. We\nshow that this approach can be formulated in terms of mutual information\nmaximization between model parameters and simulated data. We use this\nequivalence to reinterpret existing approaches for amortized inference, and\npropose two new methods that rely on lower bounds of the mutual information. We\napply our framework to the inference of parameters of stochastic processes and\nchaotic dynamical systems from sampled trajectories, using artificial neural\nnetworks for posterior prediction. Our approach provides a unified framework\nthat leverages the power of mutual information estimators for inference.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 12:59:16 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Isacchini", "Giulio", ""], ["Spisak", "Natanael", ""], ["Nourmohammad", "Armita", ""], ["Mora", "Thierry", ""], ["Walczak", "Aleksandra M.", ""]]}, {"id": "2106.01826", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge", "title": "Towards a Mathematical Theory of Abstraction", "comments": "03/06/21 initial upload. 25/06/21 minor fixes and corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the utility of well-chosen abstractions for understanding and\npredicting the behaviour of complex systems is well appreciated, precisely what\nan abstraction $\\textit{is}$ has so far has largely eluded mathematical\nformalization. In this paper, we aim to set out a mathematical theory of\nabstraction. We provide a precise characterisation of what an abstraction is\nand, perhaps more importantly, suggest how abstractions can be learnt directly\nfrom data both for static datasets and for dynamical systems. We define an\nabstraction to be a small set of `summaries' of a system which can be used to\nanswer a set of queries about the system or its behaviour. The difference\nbetween the ground truth behaviour of the system on the queries and the\nbehaviour of the system predicted only by the abstraction provides a measure of\nthe `leakiness' of the abstraction which can be used as a loss function to\ndirectly learn abstractions from data. Our approach can be considered a\ngeneralization of classical statistics where we are not interested in\nreconstructing `the data' in full, but are instead only concerned with\nanswering a set of arbitrary queries about the data. While highly theoretical,\nour results have deep implications for statistical inference and machine\nlearning and could be used to develop explicit methods for learning precise\nkinds of abstractions directly from data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 13:23:49 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 19:37:18 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Millidge", "Beren", ""]]}, {"id": "2106.01858", "submitter": "Anders L{\\o}land", "authors": "Dag Tj{\\o}stheim and Martin Jullum and Anders L{\\o}land", "title": "Statistical embedding: Beyond principal components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an intense recent activity in embedding of very high\ndimensional and nonlinear data structures, much of it in the data science and\nmachine learning literature. We survey this activity in four parts. In the\nfirst part we cover nonlinear methods such as principal curves,\nmultidimensional scaling, local linear methods, ISOMAP, graph based methods and\nkernel based methods. The second part is concerned with topological embedding\nmethods, in particular mapping topological properties into persistence\ndiagrams. Another type of data sets with a tremendous growth is very\nhigh-dimensional network data. The task considered in part three is how to\nembed such data in a vector space of moderate dimension to make the data\namenable to traditional techniques such as cluster and classification\ntechniques. The final part of the survey deals with embedding in\n$\\mathbb{R}^2$, which is visualization. Three methods are presented: $t$-SNE,\nUMAP and LargeVis based on methods in parts one, two and three, respectively.\nThe methods are illustrated and compared on two simulated data sets; one\nconsisting of a triple of noisy Ranunculoid curves, and one consisting of\nnetworks of increasing complexity and with two types of nodes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:01:21 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Tj\u00f8stheim", "Dag", ""], ["Jullum", "Martin", ""], ["L\u00f8land", "Anders", ""]]}, {"id": "2106.01906", "submitter": "Jingyu He", "authors": "Jingyu He, Nicholas Polson, Jianeng Xu", "title": "Bayesian Inference for Gamma Models", "comments": "Duplicate submission of arXiv:1905.12141 Please check\n  arXiv:1905.12141 for future update", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use the theory of normal variance-mean mixtures to derive a data\naugmentation scheme for models that include gamma functions. Our methodology\napplies to many situations in statistics and machine learning, including\nMultinomial-Dirichlet distributions, Negative binomial regression,\nPoisson-Gamma hierarchical models, Extreme value models, to name but a few. All\nof those models include a gamma function which does not admit a natural\nconjugate prior distribution providing a significant challenge to inference and\nprediction. To provide a data augmentation strategy, we construct and develop\nthe theory of the class of Exponential Reciprocal Gamma distributions. This\nallows scalable EM and MCMC algorithms to be developed. We illustrate our\nmethodology on a number of examples, including gamma shape inference, negative\nbinomial regression and Dirichlet allocation. Finally, we conclude with\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:58:39 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 14:48:53 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["He", "Jingyu", ""], ["Polson", "Nicholas", ""], ["Xu", "Jianeng", ""]]}, {"id": "2106.01921", "submitter": "James Long", "authors": "James P. Long and Min Jin Ha", "title": "Sample Selection Bias in Evaluation of Prediction Performance of Causal\n  Models", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal models are notoriously difficult to validate because they make\nuntestable assumptions regarding confounding. New scientific experiments offer\nthe possibility of evaluating causal models using prediction performance.\nPrediction performance measures are typically robust to violations in causal\nassumptions. However prediction performance does depend on the selection of\ntraining and test sets. In particular biased training sets can lead to\noptimistic assessments of model performance. In this work, we revisit the\nprediction performance of several recently proposed causal models tested on a\ngenetic perturbation data set of Kemmeren [Kemmeren et al., 2014]. We find that\nsample selection bias is likely a key driver of model performance. We propose\nusing a less-biased evaluation set for assessing prediction performance on\nKemmeren and compare models on this new set. In this setting, the causal model\ntested have similar performance to standard association based estimators such\nas Lasso. Finally we compare the performance of causal estimators in simulation\nstudies which reproduce the Kemmeren structure of genetic knockout experiments\nbut without any sample selection bias. These results provide an improved\nunderstanding of the performance of several causal models and offer guidance on\nhow future studies should use Kemmeren.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 15:15:30 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Long", "James P.", ""], ["Ha", "Min Jin", ""]]}, {"id": "2106.01939", "submitter": "Jean Kaddour", "authors": "Jean Kaddour, Qi Liu, Yuchen Zhu, Matt J. Kusner, Ricardo Silva", "title": "Graph Intervention Networks for Causal Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the estimation of conditional average treatment effects (CATEs)\nwhen treatments are graph-structured (e.g., molecular graphs of drugs). Given a\nweak condition on the effect, we propose a plug-in estimator that decomposes\nCATE estimation into separate, simpler optimization problems. Our estimator (a)\nisolates the causal estimands (reducing regularization bias), and (b) allows\none to plug in arbitrary models for learning. In experiments with small-world\nand molecular graphs, we show that our approach outperforms prior approaches\nand is robust to varying selection biases. Our implementation is online.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 15:41:00 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 11:03:46 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Kaddour", "Jean", ""], ["Liu", "Qi", ""], ["Zhu", "Yuchen", ""], ["Kusner", "Matt J.", ""], ["Silva", "Ricardo", ""]]}, {"id": "2106.01982", "submitter": "Thomas Pinder", "authors": "Thomas Pinder, Kathryn Turnbull, Christopher Nemeth, David Leslie", "title": "Gaussian Processes on Hypergraphs", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a Matern Gaussian process (GP) on the vertices of a hypergraph.\nThis enables estimation of regression models of observed or latent values\nassociated with the vertices, in which the correlation and uncertainty\nestimates are informed by the hypergraph structure. We further present a\nframework for embedding the vertices of a hypergraph into a latent space using\nthe hypergraph GP. Finally, we provide a scheme for identifying a small number\nof representative inducing vertices that enables scalable inference through\nsparse GPs. We demonstrate the utility of our framework on three challenging\nreal-world problems that concern multi-class classification for the political\nparty affiliation of legislators on the basis of voting behaviour,\nprobabilistic matrix factorisation of movie reviews, and embedding a hypergraph\nof animals into a low-dimensional latent space.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 16:58:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Pinder", "Thomas", ""], ["Turnbull", "Kathryn", ""], ["Nemeth", "Christopher", ""], ["Leslie", "David", ""]]}, {"id": "2106.01986", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang, Tao Huang, Yuchao Cai, Hanfang Yang, Zhouchen Lin", "title": "Gradient Boosted Binary Histogram Ensemble for Large-scale Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose a gradient boosting algorithm for large-scale\nregression problems called \\textit{Gradient Boosted Binary Histogram Ensemble}\n(GBBHE) based on binary histogram partition and ensemble learning. From the\ntheoretical perspective, by assuming the H\\\"{o}lder continuity of the target\nfunction, we establish the statistical convergence rate of GBBHE in the space\n$C^{0,\\alpha}$ and $C^{1,0}$, where a lower bound of the convergence rate for\nthe base learner demonstrates the advantage of boosting. Moreover, in the space\n$C^{1,0}$, we prove that the number of iterations to achieve the fast\nconvergence rate can be reduced by using ensemble regressor as the base\nlearner, which improves the computational efficiency. In the experiments,\ncompared with other state-of-the-art algorithms such as gradient boosted\nregression tree (GBRT), Breiman's forest, and kernel-based methods, our GBBHE\nalgorithm shows promising performance with less running time on large-scale\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:05:40 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Hang", "Hanyuan", ""], ["Huang", "Tao", ""], ["Cai", "Yuchao", ""], ["Yang", "Hanfang", ""], ["Lin", "Zhouchen", ""]]}, {"id": "2106.02018", "submitter": "Yu-Hang Tang", "authors": "Elizaveta Rebrova and Yu-Hang Tang", "title": "Nonlinear Matrix Approximation with Radial Basis Function Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and investigate matrix approximation by decomposition into a sum\nof radial basis function (RBF) components. An RBF component is a generalization\nof the outer product between a pair of vectors, where an RBF function replaces\nthe scalar multiplication between individual vector elements. Even though the\nRBF functions are positive definite, the summation across components is not\nrestricted to convex combinations and allows us to compute the decomposition\nfor any real matrix that is not necessarily symmetric or positive definite. We\nformulate the problem of seeking such a decomposition as an optimization\nproblem with a nonlinear and non-convex loss function. Several modern versions\nof the gradient descent method, including their scalable stochastic\ncounterparts, are used to solve this problem. We provide extensive empirical\nevidence of the effectiveness of the RBF decomposition and that of the\ngradient-based fitting algorithm. While being conceptually motivated by\nsingular value decomposition (SVD), our proposed nonlinear counterpart\noutperforms SVD by drastically reducing the memory required to approximate a\ndata matrix with the same L2 error for a wide range of matrix types. For\nexample, it leads to 2 to 6 times memory save for Gaussian noise, graph\nadjacency matrices, and kernel matrices. Moreover, this proximity-based\ndecomposition can offer additional interpretability in applications that\ninvolve, e.g., capturing the inner low-dimensional structure of the data,\nretaining graph connectivity structure, and preserving the acutance of images.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:37:41 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 22:26:02 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Rebrova", "Elizaveta", ""], ["Tang", "Yu-Hang", ""]]}, {"id": "2106.02029", "submitter": "Ruohan Zhan", "authors": "Ruohan Zhan, Vitor Hadad, David A. Hirshberg, and Susan Athey", "title": "Off-Policy Evaluation via Adaptive Weighting with Data from Contextual\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has become increasingly common for data to be collected adaptively, for\nexample using contextual bandits. Historical data of this type can be used to\nevaluate other treatment assignment policies to guide future innovation or\nexperiments. However, policy evaluation is challenging if the target policy\ndiffers from the one used to collect data, and popular estimators, including\ndoubly robust (DR) estimators, can be plagued by bias, excessive variance, or\nboth. In particular, when the pattern of treatment assignment in the collected\ndata looks little like the pattern generated by the policy to be evaluated, the\nimportance weights used in DR estimators explode, leading to excessive\nvariance.\n  In this paper, we improve the DR estimator by adaptively weighting\nobservations to control its variance. We show that a t-statistic based on our\nimproved estimator is asymptotically normal under certain conditions, allowing\nus to form confidence intervals and test hypotheses. Using synthetic data and\npublic benchmarks, we provide empirical evidence for our estimator's improved\naccuracy and inferential properties relative to existing alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:54:44 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 17:56:15 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zhan", "Ruohan", ""], ["Hadad", "Vitor", ""], ["Hirshberg", "David A.", ""], ["Athey", "Susan", ""]]}, {"id": "2106.02040", "submitter": "Huazhe Xu", "authors": "Huazhe Xu, Yuping Luo, Shaoxiong Wang, Trevor Darrell, Roberto\n  Calandra", "title": "Towards Learning to Play Piano with Dexterous Hands and Touch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The virtuoso plays the piano with passion, poetry and extraordinary technical\nability. As Liszt said (a virtuoso)must call up scent and blossom, and breathe\nthe breath of life. The strongest robots that can play a piano are based on a\ncombination of specialized robot hands/piano and hardcoded planning algorithms.\nIn contrast to that, in this paper, we demonstrate how an agent can learn\ndirectly from machine-readable music score to play the piano with dexterous\nhands on a simulated piano using reinforcement learning (RL) from scratch. We\ndemonstrate the RL agents can not only find the correct key position but also\ndeal with various rhythmic, volume and fingering, requirements. We achieve this\nby using a touch-augmented reward and a novel curriculum of tasks. We conclude\nby carefully studying the important aspects to enable such learning algorithms\nand that can potentially shed light on future research in this direction.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 17:59:31 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 23:09:52 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Xu", "Huazhe", ""], ["Luo", "Yuping", ""], ["Wang", "Shaoxiong", ""], ["Darrell", "Trevor", ""], ["Calandra", "Roberto", ""]]}, {"id": "2106.02051", "submitter": "Florian List", "authors": "Florian List", "title": "The Earth Mover's Pinball Loss: Quantiles for Histogram-Valued\n  Regression", "comments": "ICML 2021. The code is available at https://github.com/FloList/EMPL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although ubiquitous in the sciences, histogram data have not received much\nattention by the Deep Learning community. Whilst regression and classification\ntasks for scalar and vector data are routinely solved by neural networks, a\nprincipled approach for estimating histogram labels as a function of an input\nvector or image is lacking in the literature. We present a dedicated method for\nDeep Learning-based histogram regression, which incorporates cross-bin\ninformation and yields distributions over possible histograms, expressed by\n$\\tau$-quantiles of the cumulative histogram in each bin. The crux of our\napproach is a new loss function obtained by applying the pinball loss to the\ncumulative histogram, which for 1D histograms reduces to the Earth Mover's\ndistance (EMD) in the special case of the median ($\\tau = 0.5$), and\ngeneralizes it to arbitrary quantiles. We validate our method with an\nillustrative toy example, a football-related task, and an astrophysical\ncomputer vision problem. We show that with our loss function, the accuracy of\nthe predicted median histograms is very similar to the standard EMD case (and\nhigher than for per-bin loss functions such as cross-entropy), while the\npredictions become much more informative at almost no additional computational\ncost.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:00:04 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["List", "Florian", ""]]}, {"id": "2106.02073", "submitter": "Xiaoyan Han", "authors": "X.Y. Han, Vardan Papyan, David L. Donoho", "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central\n  Path", "comments": "Appendix contains [Section A] empirical experiments, [Sections B-D]\n  discussions and proofs of theoretical results, and [Section E] survey of\n  related works examining Neural Collapse", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent work [Papyan, Han, and Donoho, 2020] discovered a phenomenon called\nNeural Collapse (NC) that occurs pervasively in today's deep net training\nparadigm of driving cross-entropy loss towards zero. In this phenomenon, the\nlast-layer features collapse to their class-means, both the classifiers and\nclass-means collapse to the same Simplex Equiangular Tight Frame (ETF), and the\nbehavior of the last-layer classifier converges to that of the\nnearest-class-mean decision rule. Since then, follow-ups-such as Mixon et al.\n[2020] and Poggio and Liao [2020a,b]-formally analyzed this inductive bias by\nreplacing the hard-to-study cross-entropy by the more tractable mean squared\nerror (MSE) loss. But, these works stopped short of demonstrating the empirical\nreality of MSE-NC on benchmark datasets and canonical networks-as had been done\nin Papyan, Han, and Donoho [2020] for the cross-entropy loss. In this work, we\nestablish the empirical reality of MSE-NC by reporting experimental\nobservations for three prototypical networks and five canonical datasets with\ncode for reproducing NC. Following this, we develop three main contributions\ninspired by MSE-NC. Firstly, we show a new theoretical decomposition of the MSE\nloss into (A) a term assuming the last-layer classifier is exactly the\nleast-squares or Webb and Lowe [1990] classifier and (B) a term capturing the\ndeviation from this least-squares classifier. Secondly, we exhibit experiments\non canonical datasets and networks demonstrating that, during training,\nterm-(B) is negligible. This motivates a new theoretical construct: the central\npath, where the linear classifier stays MSE-optimal-for the given feature\nactivations-throughout the dynamics. Finally, through our study of continually\nrenormalized gradient flow along the central path, we produce closed-form\ndynamics that predict full Neural Collapse in an unconstrained features model.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:31:41 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Han", "X. Y.", ""], ["Papyan", "Vardan", ""], ["Donoho", "David L.", ""]]}, {"id": "2106.02078", "submitter": "Kaustubh Sridhar", "authors": "Kaustubh Sridhar, Oleg Sokolsky, Insup Lee, James Weimer", "title": "Robust Learning via Persistency of Excitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% points on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% points in various state-of-the-art adversarially trained models on\nthe AutoAttack benchmark, where every small margin of improvement is\nsignificant.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:49:05 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 16:12:55 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 03:32:47 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Sridhar", "Kaustubh", ""], ["Sokolsky", "Oleg", ""], ["Lee", "Insup", ""], ["Weimer", "James", ""]]}, {"id": "2106.02081", "submitter": "Francisco Vargas", "authors": "Francisco Vargas, Pierre Thodoroff, Neil D. Lawrence, Austen Lamacraft", "title": "Solving Schr\\\"odinger Bridges via Maximum Likelihood", "comments": "9 pages + appendix (total 28 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Schr\\\"odinger bridge problem (SBP) finds the most likely stochastic\nevolution between two probability distributions given a prior stochastic\nevolution. As well as applications in the natural sciences, problems of this\nkind have important applications in machine learning such as dataset alignment\nand hypothesis testing. Whilst the theory behind this problem is relatively\nmature, scalable numerical recipes to estimate the Schr\\\"odinger bridge remain\nan active area of research. We prove an equivalence between the SBP and maximum\nlikelihood estimation enabling direct application of successful machine\nlearning techniques. We propose a numerical procedure to estimate SBPs using\nGaussian process and demonstrate the practical usage of our approach in\nnumerical simulations and experiments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:58:12 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 07:48:10 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 19:38:58 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Vargas", "Francisco", ""], ["Thodoroff", "Pierre", ""], ["Lawrence", "Neil D.", ""], ["Lamacraft", "Austen", ""]]}, {"id": "2106.02096", "submitter": "Kisung You", "authors": "Byeongsu Yu, Kisung You", "title": "Shape-Preserving Dimensionality Reduction : An Algorithm and Measures of\n  Topological Equivalence", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce a linear dimensionality reduction technique preserving\ntopological features via persistent homology. The method is designed to find\nlinear projection $L$ which preserves the persistent diagram of a point cloud\n$\\mathbb{X}$ via simulated annealing. The projection $L$ induces a set of\ncanonical simplicial maps from the Rips (or \\v{C}ech) filtration of\n$\\mathbb{X}$ to that of $L\\mathbb{X}$. In addition to the distance between\npersistent diagrams, the projection induces a map between filtrations, called\nfiltration homomorphism. Using the filtration homomorphism, one can measure the\ndifference between shapes of two filtrations directly comparing simplicial\ncomplexes with respect to quasi-isomorphism $\\mu_{\\operatorname{quasi-iso}}$ or\nstrong homotopy equivalence $\\mu_{\\operatorname{equiv}}$. These\n$\\mu_{\\operatorname{quasi-iso}}$ and $\\mu_{\\operatorname{equiv}}$ measures how\nmuch portion of corresponding simplicial complexes is quasi-isomorphic or\nhomotopy equivalence respectively. We validate the effectiveness of our\nframework with simple examples.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 19:28:52 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 16:59:07 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 21:03:10 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yu", "Byeongsu", ""], ["You", "Kisung", ""]]}, {"id": "2106.02119", "submitter": "Christian K\\\"ummerle", "authors": "Christian K\\\"ummerle, Claudio Mayrink Verdun", "title": "A Scalable Second Order Method for Ill-Conditioned Matrix Completion\n  from Few Samples", "comments": "45 pages, 8 figures, to be published in ICML 2021. arXiv admin note:\n  text overlap with arXiv:2009.02905", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an iterative algorithm for low-rank matrix completion that can be\ninterpreted as an iteratively reweighted least squares (IRLS) algorithm, a\nsaddle-escaping smoothing Newton method or a variable metric proximal gradient\nmethod applied to a non-convex rank surrogate. It combines the favorable\ndata-efficiency of previous IRLS approaches with an improved scalability by\nseveral orders of magnitude. We establish the first local convergence guarantee\nfrom a minimal number of samples for that class of algorithms, showing that the\nmethod attains a local quadratic convergence rate. Furthermore, we show that\nthe linear systems to be solved are well-conditioned even for very\nill-conditioned ground truth matrices. We provide extensive experiments,\nindicating that unlike many state-of-the-art approaches, our method is able to\ncomplete very ill-conditioned matrices with a condition number of up to\n$10^{10}$ from few samples, while being competitive in its scalability.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 20:31:00 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["K\u00fcmmerle", "Christian", ""], ["Verdun", "Claudio Mayrink", ""]]}, {"id": "2106.02126", "submitter": "Anand Kalvit", "authors": "Anand Kalvit and Assaf Zeevi", "title": "A Closer Look at the Worst-case Behavior of Multi-armed Bandit\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key drivers of complexity in the classical (stochastic)\nmulti-armed bandit (MAB) problem is the difference between mean rewards in the\ntop two arms, also known as the instance gap. The celebrated Upper Confidence\nBound (UCB) policy is among the simplest optimism-based MAB algorithms that\nnaturally adapts to this gap: for a horizon of play n, it achieves optimal\nO(log n) regret in instances with \"large\" gaps, and a near-optimal O(\\sqrt{n\nlog n}) minimax regret when the gap can be arbitrarily \"small.\" This paper\nprovides new results on the arm-sampling behavior of UCB, leading to several\nimportant insights. Among these, it is shown that arm-sampling rates under UCB\nare asymptotically deterministic, regardless of the problem complexity. This\ndiscovery facilitates new sharp asymptotics and a novel alternative proof for\nthe O(\\sqrt{n log n}) minimax regret of UCB. Furthermore, the paper also\nprovides the first complete process-level characterization of the MAB problem\nunder UCB in the conventional diffusion scaling. Among other things, the\n\"small\" gap worst-case lens adopted in this paper also reveals profound\ndistinctions between the behavior of UCB and Thompson Sampling, such as an\n\"incomplete learning\" phenomenon characteristic of the latter.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 20:52:26 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kalvit", "Anand", ""], ["Zeevi", "Assaf", ""]]}, {"id": "2106.02129", "submitter": "Brice Huang", "authors": "Guy Bresler, Brice Huang", "title": "The Algorithmic Phase Transition of Random $k$-SAT for Low Degree\n  Polynomials", "comments": "44 pages, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math-ph math.MP math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\Phi$ be a uniformly random $k$-SAT formula with $n$ variables and $m$\nclauses. We study the algorithmic task of finding a satisfying assignment of\n$\\Phi$. It is known that a satisfying assignment exists with high probability\nat clause density $m/n < 2^k \\log 2 - \\frac{1}{2} (\\log 2 + 1) + o_k(1)$, while\nthe best polynomial-time algorithm known, the Fix algorithm of Coja-Oghlan,\nfinds a satisfying assignment at the much lower clause density $(1 - o_k(1))\n2^k \\log k / k$. This prompts the question: is it possible to efficiently find\na satisfying assignment at higher clause densities?\n  To understand the algorithmic threshold of random $k$-SAT, we study low\ndegree polynomial algorithms, which are a powerful class of algorithms\nincluding Fix, Survey Propagation guided decimation (with bounded or mildly\ngrowing number of message passing rounds), and paradigms such as message\npassing and local graph algorithms. We show that low degree polynomial\nalgorithms can find a satisfying assignment at clause density $(1 - o_k(1)) 2^k\n\\log k / k$, matching Fix, and not at clause density $(1 + o_k(1)) \\kappa^* 2^k\n\\log k / k$, where $\\kappa^* \\approx 4.911$. This shows the first sharp (up to\nconstant factor) computational phase transition of random $k$-SAT for a class\nof algorithms. Our proof establishes and leverages a new many-way overlap gap\nproperty tailored to random $k$-SAT.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 21:01:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 02:36:55 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bresler", "Guy", ""], ["Huang", "Brice", ""]]}, {"id": "2106.02154", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Laplacian-Based Dimensionality Reduction Including Spectral Clustering,\n  Laplacian Eigenmap, Locality Preserving Projection, Graph Embedding, and\n  Diffusion Map: Tutorial and Survey", "comments": "To appear as a part of an upcoming textbook on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a tutorial and survey paper for nonlinear dimensionality and feature\nextraction methods which are based on the Laplacian of graph of data. We first\nintroduce adjacency matrix, definition of Laplacian matrix, and the\ninterpretation of Laplacian. Then, we cover the cuts of graph and spectral\nclustering which applies clustering in a subspace of data. Different\noptimization variants of Laplacian eigenmap and its out-of-sample extension are\nexplained. Thereafter, we introduce the locality preserving projection and its\nkernel variant as linear special cases of Laplacian eigenmap. Versions of graph\nembedding are then explained which are generalized versions of Laplacian\neigenmap and locality preserving projection. Finally, diffusion map is\nintroduced which is a method based on Laplacian of data and random walks on the\ndata graph.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 22:10:40 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2106.02175", "submitter": "Haoyue Wang", "authors": "Rahul Mazumder, Haoyue Wang", "title": "Linear regression with partially mismatched data: local search with\n  theoretical guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression is a fundamental modeling tool in statistics and related\nfields. In this paper, we study an important variant of linear regression in\nwhich the predictor-response pairs are partially mismatched. We use an\noptimization formulation to simultaneously learn the underlying regression\ncoefficients and the permutation corresponding to the mismatches. The\ncombinatorial structure of the problem leads to computational challenges. We\npropose and study a simple greedy local search algorithm for this optimization\nproblem that enjoys strong theoretical guarantees and appealing computational\nperformance. We prove that under a suitable scaling of the number of mismatched\npairs compared to the number of samples and features, and certain assumptions\non problem data; our local search algorithm converges to a nearly-optimal\nsolution at a linear rate. In particular, in the noiseless case, our algorithm\nconverges to the global optimal solution with a linear convergence rate. We\nalso propose an approximate local search step that allows us to scale our\napproach to much larger instances. We conduct numerical experiments to gather\nfurther insights into our theoretical results and show promising performance\ngains compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 23:32:12 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mazumder", "Rahul", ""], ["Wang", "Haoyue", ""]]}, {"id": "2106.02197", "submitter": "Wu Xinxing", "authors": "Xinxing Wu, Qiang Cheng", "title": "Top-$k$ Regularization for Supervised Feature Selection", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection identifies subsets of informative features and reduces\ndimensions in the original feature space, helping provide insights into data\ngeneration or a variety of domain problems. Existing methods mainly depend on\nfeature scoring functions or sparse regularizations; nonetheless, they have\nlimited ability to reconcile the representativeness and inter-correlations of\nfeatures. In this paper, we introduce a novel, simple yet effective\nregularization approach, named top-$k$ regularization, to supervised feature\nselection in regression and classification tasks. Structurally, the top-$k$\nregularization induces a sub-architecture on the architecture of a learning\nmodel to boost its ability to select the most informative features and model\ncomplex nonlinear relationships simultaneously. Theoretically, we derive and\nmathematically prove a uniform approximation error bound for using this\napproach to approximate high-dimensional sparse functions. Extensive\nexperiments on a wide variety of benchmarking datasets show that the top-$k$\nregularization is effective and stable for supervised feature selection.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 01:12:47 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Wu", "Xinxing", ""], ["Cheng", "Qiang", ""]]}, {"id": "2106.02206", "submitter": "Linfeng Liu", "authors": "Linfeng Liu, Michael C. Hughes, Soha Hassoun, Li-Ping Liu", "title": "Stochastic Iterative Graph Matching", "comments": "To appear in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works leveraging Graph Neural Networks to approach graph matching\ntasks have shown promising results. Recent progress in learning discrete\ndistributions poses new opportunities for learning graph matching models. In\nthis work, we propose a new model, Stochastic Iterative Graph MAtching (SIGMA),\nto address the graph matching problem. Our model defines a distribution of\nmatchings for a graph pair so the model can explore a wide range of possible\nmatchings. We further introduce a novel multi-step matching procedure, which\nlearns how to refine a graph pair's matching results incrementally. The model\nalso includes dummy nodes so that the model does not have to find matchings for\nnodes without correspondence. We fit this model to data via scalable stochastic\noptimization. We conduct extensive experiments across synthetic graph datasets\nas well as biochemistry and computer vision applications. Across all tasks, our\nresults show that SIGMA can produce significantly improved graph matching\nresults compared to state-of-the-art models. Ablation studies verify that each\nof our components (stochastic training, iterative matching, and dummy nodes)\noffers noticeable improvement.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 02:05:35 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Liu", "Linfeng", ""], ["Hughes", "Michael C.", ""], ["Hassoun", "Soha", ""], ["Liu", "Li-Ping", ""]]}, {"id": "2106.02212", "submitter": "Soumyabrata Pal", "authors": "Wasim Huleihel, Arya Mazumdar, Soumyabrata Pal", "title": "Fuzzy Clustering with Similarity Queries", "comments": "47 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fuzzy or soft $k$-means objective is a popular generalization of the\nwell-known $k$-means problem, extending the clustering capability of the\n$k$-means to datasets that are uncertain, vague, and otherwise hard to cluster.\nIn this paper, we propose a semi-supervised active clustering framework, where\nthe learner is allowed to interact with an oracle (domain expert), asking for\nthe similarity between a certain set of chosen items. We study the query and\ncomputational complexities of clustering in this framework. We prove that\nhaving a few of such similarity queries enables one to get a polynomial-time\napproximation algorithm to an otherwise conjecturally NP-hard problem. In\nparticular, we provide probabilistic algorithms for fuzzy clustering in this\nsetting that asks $O(\\mathsf{poly}(k)\\log n)$ similarity queries and run with\npolynomial-time-complexity, where $n$ is the number of items. The fuzzy\n$k$-means objective is nonconvex, with $k$-means as a special case, and is\nequivalent to some other generic nonconvex problem such as non-negative matrix\nfactorization. The ubiquitous Lloyd-type algorithms (or,\nexpectation-maximization algorithm) can get stuck at a local minima. Our\nresults show that by making few similarity queries, the problem becomes easier\nto solve. Finally, we test our algorithms over real-world datasets, showing\ntheir effectiveness in real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 02:32:26 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Huleihel", "Wasim", ""], ["Mazumdar", "Arya", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "2106.02260", "submitter": "Johannes Lederer", "authors": "Leni Ven and Johannes Lederer", "title": "Regularization and Reparameterization Avoid Vanishing Gradients in\n  Sigmoid-Type Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning requires several design choices, such as the nodes' activation\nfunctions and the widths, types, and arrangements of the layers. One\nconsideration when making these choices is the vanishing-gradient problem,\nwhich is the phenomenon of algorithms getting stuck at suboptimal points due to\nsmall gradients. In this paper, we revisit the vanishing-gradient problem in\nthe context of sigmoid-type activation. We use mathematical arguments to\nhighlight two different sources of the phenomenon, namely large individual\nparameters and effects across layers, and to illustrate two simple remedies,\nnamely regularization and rescaling. We then demonstrate the effectiveness of\nthe two remedies in practice. In view of the vanishing-gradient problem being a\nmain reason why tanh and other sigmoid-type activation has become much less\npopular than relu-type activation, our results bring sigmoid-type activation\nback to the table.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 04:53:22 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ven", "Leni", ""], ["Lederer", "Johannes", ""]]}, {"id": "2106.02261", "submitter": "Abdulkadir Canatar", "authors": "Abdulkadir Canatar, Blake Bordelon, Cengiz Pehlevan", "title": "Out-of-Distribution Generalization in Kernel Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real word applications, data generating process for training a machine\nlearning model often differs from what the model encounters in the test stage.\nUnderstanding how and whether machine learning models generalize under such\ndistributional shifts have been a theoretical challenge. Here, we study\ngeneralization in kernel regression when the training and test distributions\nare different using methods from statistical physics. Using the replica method,\nwe derive an analytical formula for the out-of-distribution generalization\nerror applicable to any kernel and real datasets. We identify an overlap matrix\nthat quantifies the mismatch between distributions for a given kernel as a key\ndeterminant of generalization performance under distribution shift. Using our\nanalytical expressions we elucidate various generalization phenomena including\npossible improvement in generalization when there is a mismatch. We develop\nprocedures for optimizing training and test distributions for a given data\nbudget to find best and worst case generalizations under the shift. We present\napplications of our theory to real and synthetic datasets and for many kernels.\nWe compare results of our theory applied to Neural Tangent Kernel with\nsimulations of wide networks and show agreement. We analyze linear regression\nin further depth.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 04:54:25 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Canatar", "Abdulkadir", ""], ["Bordelon", "Blake", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2106.02305", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Zheng Xu, Zachary Garrett, Zachary Charles, Luyang Liu,\n  Gauri Joshi", "title": "Local Adaptivity in Federated Learning: Convergence and Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The federated learning (FL) framework trains a machine learning model using\ndecentralized data stored at edge client devices by periodically aggregating\nlocally trained models. Popular optimization algorithms of FL use vanilla\n(stochastic) gradient descent for both local updates at clients and global\nupdates at the aggregating server. Recently, adaptive optimization methods such\nas AdaGrad have been studied for server updates. However, the effect of using\nadaptive optimization methods for local updates at clients is not yet\nunderstood. We show in both theory and practice that while local adaptive\nmethods can accelerate convergence, they can cause a non-vanishing solution\nbias, where the final converged solution may be different from the stationary\npoint of the global objective function. We propose correction techniques to\novercome this inconsistency and complement the local adaptive methods for FL.\nExtensive experiments on realistic federated training tasks show that the\nproposed algorithms can achieve faster convergence and higher test accuracy\nthan the baselines without local adaptivity.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 07:36:59 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Wang", "Jianyu", ""], ["Xu", "Zheng", ""], ["Garrett", "Zachary", ""], ["Charles", "Zachary", ""], ["Liu", "Luyang", ""], ["Joshi", "Gauri", ""]]}, {"id": "2106.02346", "submitter": "Bryn Elesedy", "authors": "Bryn Elesedy", "title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is a commonly held belief that enforcing invariance improves\ngeneralisation. Although this approach enjoys widespread popularity, it is only\nvery recently that a rigorous theoretical demonstration of this benefit has\nbeen established. In this work we build on the function space perspective of\nElesedy and Zaidi arXiv:2102.10333 to derive a strictly non-zero generalisation\nbenefit of incorporating invariance in kernel ridge regression when the target\nis invariant to the action of a compact group. We study invariance enforced by\nfeature averaging and find that generalisation is governed by a notion of\neffective dimension that arises from the interplay between the kernel and the\ngroup. In building towards this result, we find that the action of the group\ninduces an orthogonal decomposition of both the reproducing kernel Hilbert\nspace and its kernel, which may be of interest in its own right.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 08:55:28 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Elesedy", "Bryn", ""]]}, {"id": "2106.02347", "submitter": "Oliver T. Unke", "authors": "Oliver T. Unke, Mihail Bogojeski, Michael Gastegger, Mario Geiger,\n  Tess Smidt, Klaus-Robert M\\\"uller", "title": "SE(3)-equivariant prediction of molecular wavefunctions and electronic\n  densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has enabled the prediction of quantum chemical properties\nwith high accuracy and efficiency, allowing to bypass computationally costly ab\ninitio calculations. Instead of training on a fixed set of properties, more\nrecent approaches attempt to learn the electronic wavefunction (or density) as\na central quantity of atomistic systems, from which all other observables can\nbe derived. This is complicated by the fact that wavefunctions transform\nnon-trivially under molecular rotations, which makes them a challenging\nprediction target. To solve this issue, we introduce general SE(3)-equivariant\noperations and building blocks for constructing deep learning architectures for\ngeometric point cloud data and apply them to reconstruct wavefunctions of\natomistic systems with unprecedented accuracy. Our model reduces prediction\nerrors by up to two orders of magnitude compared to the previous\nstate-of-the-art and makes it possible to derive properties such as energies\nand forces directly from the wavefunction in an end-to-end manner. We\ndemonstrate the potential of our approach in a transfer learning application,\nwhere a model trained on low accuracy reference wavefunctions implicitly learns\nto correct for electronic many-body interactions from observables computed at a\nhigher level of theory. Such machine-learned wavefunction surrogates pave the\nway towards novel semi-empirical methods, offering resolution at an electronic\nlevel while drastically decreasing computational cost. While we focus on\nphysics applications in this contribution, the proposed equivariant framework\nfor deep learning on point clouds is promising also beyond, say, in computer\nvision or graphics.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 08:57:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Unke", "Oliver T.", ""], ["Bogojeski", "Mihail", ""], ["Gastegger", "Michael", ""], ["Geiger", "Mario", ""], ["Smidt", "Tess", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2106.02356", "submitter": "Marco Mondelli", "authors": "Marco Mondelli and Ramji Venkataramanan", "title": "PCA Initialization for Approximate Message Passing in Rotationally\n  Invariant Models", "comments": "70 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating a rank-$1$ signal in the presence of\nrotationally invariant noise-a class of perturbations more general than\nGaussian noise. Principal Component Analysis (PCA) provides a natural\nestimator, and sharp results on its performance have been obtained in the\nhigh-dimensional regime. Recently, an Approximate Message Passing (AMP)\nalgorithm has been proposed as an alternative estimator with the potential to\nimprove the accuracy of PCA. However, the existing analysis of AMP requires an\ninitialization that is both correlated with the signal and independent of the\nnoise, which is often unrealistic in practice. In this work, we combine the two\nmethods, and propose to initialize AMP with PCA. Our main result is a rigorous\nasymptotic characterization of the performance of this estimator. Both the AMP\nalgorithm and its analysis differ from those previously derived in the Gaussian\nsetting: at every iteration, our AMP algorithm requires a specific term to\naccount for PCA initialization, while in the Gaussian case, PCA initialization\naffects only the first iteration of AMP. The proof is based on a two-phase\nartificial AMP that first approximates the PCA estimator and then mimics the\ntrue AMP. Our numerical simulations show an excellent agreement between AMP\nresults and theoretical predictions, and suggest an interesting open direction\non achieving Bayes-optimal performance.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:13:51 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Mondelli", "Marco", ""], ["Venkataramanan", "Ramji", ""]]}, {"id": "2106.02357", "submitter": "Surya Sai Teja Desu Surya", "authors": "Surya Sai Teja Desu, P.K. Srijith, M.V. Panduranga Rao, Naveen\n  Sivadasan", "title": "Adiabatic Quantum Feature Selection for Sparse Linear Regression", "comments": "8 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Linear regression is a popular machine learning approach to learn and predict\nreal valued outputs or dependent variables from independent variables or\nfeatures. In many real world problems, its beneficial to perform sparse linear\nregression to identify important features helpful in predicting the dependent\nvariable. It not only helps in getting interpretable results but also avoids\noverfitting when the number of features is large, and the amount of data is\nsmall. The most natural way to achieve this is by using `best subset selection'\nwhich penalizes non-zero model parameters by adding $\\ell_0$ norm over\nparameters to the least squares loss. However, this makes the objective\nfunction non-convex and intractable even for a small number of features. This\npaper aims to address the intractability of sparse linear regression with\n$\\ell_0$ norm using adiabatic quantum computing, a quantum computing paradigm\nthat is particularly useful for solving optimization problems faster. We\nformulate the $\\ell_0$ optimization problem as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem and solve it using the D-Wave adiabatic quantum\ncomputer. We study and compare the quality of QUBO solution on synthetic and\nreal world datasets. The results demonstrate the effectiveness of the proposed\nadiabatic quantum computing approach in finding the optimal solution. The QUBO\nsolution matches the optimal solution for a wide range of sparsity penalty\nvalues across the datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:14:01 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Desu", "Surya Sai Teja", ""], ["Srijith", "P. K.", ""], ["Rao", "M. V. Panduranga", ""], ["Sivadasan", "Naveen", ""]]}, {"id": "2106.02390", "submitter": "Alejandro Daniel Noel", "authors": "Alejandro Daniel Noel (1), Charel van Hoof (1), Beren Millidge (2)\n  ((1) Delft University of Technology, (2) University of Oxford)", "title": "Online reinforcement learning with sparse rewards through an active\n  inference capsule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligent agents must pursue their goals in complex environments with\npartial information and often limited computational capacity. Reinforcement\nlearning methods have achieved great success by creating agents that optimize\nengineered reward functions, but which often struggle to learn in sparse-reward\nenvironments, generally require many environmental interactions to perform\nwell, and are typically computationally very expensive. Active inference is a\nmodel-based approach that directs agents to explore uncertain states while\nadhering to a prior model of their goal behaviour. This paper introduces an\nactive inference agent which minimizes the novel free energy of the expected\nfuture. Our model is capable of solving sparse-reward problems with a very high\nsample efficiency due to its objective function, which encourages directed\nexploration of uncertain states. Moreover, our model is computationally very\nlight and can operate in a fully online manner while achieving comparable\nperformance to offline RL methods. We showcase the capabilities of our model by\nsolving the mountain car problem, where we demonstrate its superior exploration\nproperties and its robustness to observation noise, which in fact improves\nperformance. We also introduce a novel method for approximating the prior model\nfrom the reward function, which simplifies the expression of complex objectives\nand improves performance over previous active inference approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 10:03:36 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Noel", "Alejandro Daniel", "", "Delft University of Technology"], ["van Hoof", "Charel", "", "Delft University of Technology"], ["Millidge", "Beren", "", "University of Oxford"]]}, {"id": "2106.02398", "submitter": "L\\^e-Nguy\\^en Hoang", "authors": "Sadegh Farhadkhani, Rachid Guerraoui and L\\^e-Nguy\\^en Hoang", "title": "Strategyproof Learning: Building Trustworthy User-Generated Datasets", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's large-scale machine learning algorithms harness massive amounts of\nuser-generated data to train large models. However, especially in the context\nof content recommendation with enormous social, economical and political\nincentives to promote specific views, products or ideologies, strategic users\nmight be tempted to fabricate or mislabel data in order to bias algorithms in\ntheir favor. Unfortunately, today's learning schemes strongly incentivize such\nstrategic data misreporting. This is a major concern, as it endangers the\ntrustworthiness of the entire training datasets, and questions the safety of\nany algorithm trained on such datasets. In this paper, we show that, perhaps\nsurprisingly, incentivizing data misreporting is not a fatality. We propose the\nfirst personalized collaborative learning framework, Licchavi, with provable\nstrategyproofness guarantees through a careful design of the underlying loss\nfunction. Interestingly, we also prove that Licchavi is Byzantine resilient: it\ntolerates a minority of users that provide arbitrary data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 10:24:49 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Farhadkhani", "Sadegh", ""], ["Guerraoui", "Rachid", ""], ["Hoang", "L\u00ea-Nguy\u00ean", ""]]}, {"id": "2106.02469", "submitter": "Lewis Smith", "authors": "Lewis Smith, Joost van Amersfoort, Haiwen Huang, Stephen Roberts,\n  Yarin Gal", "title": "Can convolutional ResNets approximately preserve input distances? A\n  frequency analysis perspective", "comments": "Main paper 10 pages including references, appendix 10 pages. 7\n  figures and 6 tables including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ResNets constrained to be bi-Lipschitz, that is, approximately distance\npreserving, have been a crucial component of recently proposed techniques for\ndeterministic uncertainty quantification in neural models. We show that\ntheoretical justifications for recent regularisation schemes trying to enforce\nsuch a constraint suffer from a crucial flaw -- the theoretical link between\nthe regularisation scheme used and bi-Lipschitzness is only valid under\nconditions which do not hold in practice, rendering existing theory of limited\nuse, despite the strong empirical performance of these models. We provide a\ntheoretical explanation for the effectiveness of these regularisation schemes\nusing a frequency analysis perspective, showing that under mild conditions\nthese schemes will enforce a lower Lipschitz bound on the low-frequency\nprojection of images. We then provide empirical evidence supporting our\ntheoretical claims, and perform further experiments which demonstrate that our\nbroader conclusions appear to hold when some of the mathematical assumptions of\nour proof are relaxed, corresponding to the setup used in prior work. In\naddition, we present a simple constructive algorithm to search for counter\nexamples to the distance preservation condition, and discuss possible\nimplications of our theory for future model design.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 13:12:42 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 14:12:14 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Smith", "Lewis", ""], ["van Amersfoort", "Joost", ""], ["Huang", "Haiwen", ""], ["Roberts", "Stephen", ""], ["Gal", "Yarin", ""]]}, {"id": "2106.02488", "submitter": "Amir Hossein Akhavan Rahnama", "authors": "Amir Hossein Akhavan Rahnama, Judith Butepage, Pierre Geurts, Henrik\n  Bostrom", "title": "Evaluation of Local Model-Agnostic Explanations Using Ground Truth", "comments": "Submitted on May 28 2021, 13 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explanation techniques are commonly evaluated using human-grounded methods,\nlimiting the possibilities for large-scale evaluations and rapid progress in\nthe development of new techniques. We propose a functionally-grounded\nevaluation procedure for local model-agnostic explanation techniques. In our\napproach, we generate ground truth for explanations when the black-box model is\nLogistic Regression and Gaussian Naive Bayes and compare how similar each\nexplanation is to the extracted ground truth. In our empirical study,\nexplanations of Local Interpretable Model-agnostic Explanations (LIME), SHapley\nAdditive exPlanations (SHAP), and Local Permutation Importance (LPI) are\ncompared in terms of how similar they are to the extracted ground truth. In the\ncase of Logistic Regression, we find that the performance of the explanation\ntechniques is highly dependent on the normalization of the data. In contrast,\nLocal Permutation Importance outperforms the other techniques on Naive Bayes,\nirrespective of normalization. We hope that this work lays the foundation for\nfurther research into functionally-grounded evaluation methods for explanation\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 13:47:31 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Rahnama", "Amir Hossein Akhavan", ""], ["Butepage", "Judith", ""], ["Geurts", "Pierre", ""], ["Bostrom", "Henrik", ""]]}, {"id": "2106.02524", "submitter": "James Mullenbach", "authors": "James Mullenbach, Yada Pruksachatkun, Sean Adler, Jennifer Seale,\n  Jordan Swartz, T. Greg McKelvey, Hui Dai, Yi Yang, David Sontag", "title": "CLIP: A Dataset for Extracting Action Items for Physicians from Hospital\n  Discharge Notes", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuity of care is crucial to ensuring positive health outcomes for\npatients discharged from an inpatient hospital setting, and improved\ninformation sharing can help. To share information, caregivers write discharge\nnotes containing action items to share with patients and their future\ncaregivers, but these action items are easily lost due to the lengthiness of\nthe documents. In this work, we describe our creation of a dataset of clinical\naction items annotated over MIMIC-III, the largest publicly available dataset\nof real clinical notes. This dataset, which we call CLIP, is annotated by\nphysicians and covers 718 documents representing 100K sentences. We describe\nthe task of extracting the action items from these documents as multi-aspect\nextractive summarization, with each aspect representing a type of action to be\ntaken. We evaluate several machine learning models on this task, and show that\nthe best models exploit in-domain language model pre-training on 59K\nunannotated documents, and incorporate context from neighboring sentences. We\nalso propose an approach to pre-training data selection that allows us to\nexplore the trade-off between size and domain-specificity of pre-training\ndatasets for this task.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 14:49:02 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Mullenbach", "James", ""], ["Pruksachatkun", "Yada", ""], ["Adler", "Sean", ""], ["Seale", "Jennifer", ""], ["Swartz", "Jordan", ""], ["McKelvey", "T. Greg", ""], ["Dai", "Hui", ""], ["Yang", "Yi", ""], ["Sontag", "David", ""]]}, {"id": "2106.02531", "submitter": "Georgios Batzolis", "authors": "Georgios Batzolis, Marcello Carioni, Christian Etmann, Soroosh\n  Afyouni, Zoe Kourtzi, Carola Bibiane Sch\\\"onlieb", "title": "CAFLOW: Conditional Autoregressive Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CAFLOW, a new diverse image-to-image translation model that\nsimultaneously leverages the power of auto-regressive modeling and the modeling\nefficiency of conditional normalizing flows. We transform the conditioning\nimage into a sequence of latent encodings using a multi-scale normalizing flow\nand repeat the process for the conditioned image. We model the conditional\ndistribution of the latent encodings by modeling the auto-regressive\ndistributions with an efficient multi-scale normalizing flow, where each\nconditioning factor affects image synthesis at its respective resolution scale.\nOur proposed framework performs well on a range of image-to-image translation\ntasks. It outperforms former designs of conditional flows because of its\nexpressive auto-regressive structure.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 14:57:41 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Batzolis", "Georgios", ""], ["Carioni", "Marcello", ""], ["Etmann", "Christian", ""], ["Afyouni", "Soroosh", ""], ["Kourtzi", "Zoe", ""], ["Sch\u00f6nlieb", "Carola Bibiane", ""]]}, {"id": "2106.02542", "submitter": "Mokhtar Z. Alaya", "authors": "Mokhtar Z. Alaya, Gilles Gasso, Maxime Berar, Alain Rakotomamonjy", "title": "Distributional Sliced Embedding Discrepancy for Incomparable\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gromov-Wasserstein (GW) distance is a key tool for manifold learning and\ncross-domain learning, allowing the comparison of distributions that do not\nlive in the same metric space. Because of its high computational complexity,\nseveral approximate GW distances have been proposed based on entropy\nregularization or on slicing, and one-dimensional GW computation. In this\npaper, we propose a novel approach for comparing two incomparable\ndistributions, that hinges on the idea of distributional slicing, embeddings,\nand on computing the closed-form Wasserstein distance between the sliced\ndistributions. We provide a theoretical analysis of this new divergence, called\ndistributional sliced embedding (DSE) discrepancy, and we show that it\npreserves several interesting properties of GW distance including\nrotation-invariance. We show that the embeddings involved in DSE can be\nefficiently learned. Finally, we provide a large set of experiments\nillustrating the behavior of DSE as a divergence in the context of generative\nmodeling and in query framework.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 15:11:30 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Alaya", "Mokhtar Z.", ""], ["Gasso", "Gilles", ""], ["Berar", "Maxime", ""], ["Rakotomamonjy", "Alain", ""]]}, {"id": "2106.02552", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Afshin Rostamizadeh", "title": "Active Covering", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze the problem of active covering, where the learner is given an\nunlabeled dataset and can sequentially label query examples. The objective is\nto label query all of the positive examples in the fewest number of total label\nqueries. We show under standard non-parametric assumptions that a classical\nsupport estimator can be repurposed as an offline algorithm attaining an excess\nquery cost of $\\widetilde{\\Theta}(n^{D/(D+1)})$ compared to the optimal\nlearner, where $n$ is the number of datapoints and $D$ is the dimension. We\nthen provide a simple active learning method that attains an improved excess\nquery cost of $\\widetilde{O}(n^{(D-1)/D})$. Furthermore, the proposed\nalgorithms only require access to the positive labeled examples, which in\ncertain settings provides additional computational and privacy benefits.\nFinally, we show that the active learning method consistently outperforms\noffline methods as well as a variety of baselines on a wide range of benchmark\nimage-based datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 15:32:39 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Jiang", "Heinrich", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "2106.02553", "submitter": "Jackie Baek", "authors": "Jackie Baek, Vivek F. Farias", "title": "Fair Exploration via Axiomatic Bargaining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the consideration of fairly sharing the cost of exploration\nbetween multiple groups in learning problems, we develop the Nash bargaining\nsolution in the context of multi-armed bandits. Specifically, the 'grouped'\nbandit associated with any multi-armed bandit problem associates, with each\ntime step, a single group from some finite set of groups. The utility gained by\na given group under some learning policy is naturally viewed as the reduction\nin that group's regret relative to the regret that group would have incurred\n'on its own'. We derive policies that yield the Nash bargaining solution\nrelative to the set of incremental utilities possible under any policy. We show\nthat on the one hand, the 'price of fairness' under such policies is limited,\nwhile on the other hand, regret optimal policies are arbitrarily unfair under\ngeneric conditions. Our theoretical development is complemented by a case study\non contextual bandits for warfarin dosing where we are concerned with the cost\nof exploration across multiple races and age groups.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 15:34:11 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Baek", "Jackie", ""], ["Farias", "Vivek F.", ""]]}, {"id": "2106.02584", "submitter": "Jannik Kossen", "authors": "Jannik Kossen, Neil Band, Clare Lyle, Aidan N. Gomez, Tom Rainforth,\n  Yarin Gal", "title": "Self-Attention Between Datapoints: Going Beyond Individual Input-Output\n  Pairs in Deep Learning", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We challenge a common assumption underlying most supervised deep learning:\nthat a model makes a prediction depending only on its parameters and the\nfeatures of a single input. To this end, we introduce a general-purpose deep\nlearning architecture that takes as input the entire dataset instead of\nprocessing one datapoint at a time. Our approach uses self-attention to reason\nabout relationships between datapoints explicitly, which can be seen as\nrealizing non-parametric models using parametric attention mechanisms. However,\nunlike conventional non-parametric models, we let the model learn end-to-end\nfrom the data how to make use of other datapoints for prediction. Empirically,\nour models solve cross-datapoint lookup and complex reasoning tasks unsolvable\nby traditional deep learning models. We show highly competitive results on\ntabular data, early results on CIFAR-10, and give insight into how the model\nmakes use of the interactions between points.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:30:49 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kossen", "Jannik", ""], ["Band", "Neil", ""], ["Lyle", "Clare", ""], ["Gomez", "Aidan N.", ""], ["Rainforth", "Tom", ""], ["Gal", "Yarin", ""]]}, {"id": "2106.02588", "submitter": "Stephan Wojtowytsch", "authors": "Stephan Wojtowytsch", "title": "Stochastic gradient descent with noise of machine learning type. Part\n  II: Continuous time analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representation of functions by artificial neural networks depends on a\nlarge number of parameters in a non-linear fashion. Suitable parameters of\nthese are found by minimizing a 'loss functional', typically by stochastic\ngradient descent (SGD) or an advanced SGD-based algorithm.\n  In a continuous time model for SGD with noise that follows the 'machine\nlearning scaling', we show that in a certain noise regime, the optimization\nalgorithm prefers 'flat' minima of the objective function in a sense which is\ndifferent from the flat minimum selection of continuous time SGD with\nhomogeneous noise.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:34:32 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Wojtowytsch", "Stephan", ""]]}, {"id": "2106.02590", "submitter": "J\\'er\\^ome-Alexis Chevalier", "authors": "J\\'er\\^ome-Alexis Chevalier, Tuan-Binh Nguyen, Bertrand Thirion,\n  Joseph Salmon", "title": "Spatially relaxed inference on high-dimensional linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the inference problem for high-dimensional linear models, when\ncovariates have an underlying spatial organization reflected in their\ncorrelation. A typical example of such a setting is high-resolution imaging, in\nwhich neighboring pixels are usually very similar. Accurate point and\nconfidence intervals estimation is not possible in this context with many more\ncovariates than samples, furthermore with high correlation between covariates.\nThis calls for a reformulation of the statistical inference problem, that takes\ninto account the underlying spatial structure: if covariates are locally\ncorrelated, it is acceptable to detect them up to a given spatial uncertainty.\nWe thus propose to rely on the $\\delta$-FWER, that is the probability of making\na false discovery at a distance greater than $\\delta$ from any true positive.\nWith this target measure in mind, we study the properties of ensembled\nclustered inference algorithms which combine three techniques: spatially\nconstrained clustering, statistical inference, and ensembling to aggregate\nseveral clustered inference solutions. We show that ensembled clustered\ninference algorithms control the $\\delta$-FWER under standard assumptions for\n$\\delta$ equal to the largest cluster diameter. We complement the theoretical\nanalysis with empirical results, demonstrating accurate $\\delta$-FWER control\nand decent power achieved by such inference algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:37:19 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Chevalier", "J\u00e9r\u00f4me-Alexis", ""], ["Nguyen", "Tuan-Binh", ""], ["Thirion", "Bertrand", ""], ["Salmon", "Joseph", ""]]}, {"id": "2106.02597", "submitter": "Janis Klaise", "authors": "Robert-Florian Samoilescu, Arnaud Van Looveren, Janis Klaise", "title": "Model-agnostic and Scalable Counterfactual Explanations via\n  Reinforcement Learning", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual instances are a powerful tool to obtain valuable insights into\nautomated decision processes, describing the necessary minimal changes in the\ninput space to alter the prediction towards a desired target. Most previous\napproaches require a separate, computationally expensive optimization procedure\nper instance, making them impractical for both large amounts of data and\nhigh-dimensional data. Moreover, these methods are often restricted to certain\nsubclasses of machine learning models (e.g. differentiable or tree-based\nmodels). In this work, we propose a deep reinforcement learning approach that\ntransforms the optimization procedure into an end-to-end learnable process,\nallowing us to generate batches of counterfactual instances in a single forward\npass. Our experiments on real-world data show that our method i) is\nmodel-agnostic (does not assume differentiability), relying only on feedback\nfrom model predictions; ii) allows for generating target-conditional\ncounterfactual instances; iii) allows for flexible feature range constraints\nfor numerical and categorical attributes, including the immutability of\nprotected features (e.g. gender, race); iv) is easily extended to other data\nmodalities such as images.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:54:36 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Samoilescu", "Robert-Florian", ""], ["Van Looveren", "Arnaud", ""], ["Klaise", "Janis", ""]]}, {"id": "2106.02613", "submitter": "Alexandre Pich\\'e", "authors": "Alexandre Pich\\'e, Joseph Marino, Gian Maria Marconi, Christopher Pal,\n  Mohammad Emtiyaz Khan", "title": "Beyond Target Networks: Improving Deep $Q$-learning with Functional\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Target networks are at the core of recent success in Reinforcement Learning.\nThey stabilize the training by using old parameters to estimate the $Q$-values,\nbut this also limits the propagation of newly-encountered rewards which could\nultimately slow down the training. In this work, we propose an alternative\ntraining method based on functional regularization which does not have this\ndeficiency. Unlike target networks, our method uses up-to-date parameters to\nestimate the target $Q$-values, thereby speeding up training while maintaining\nstability. Surprisingly, in some cases, we can show that target networks are a\nspecial, restricted type of functional regularizers. Using this approach, we\nshow empirical improvements in sample efficiency and performance across a range\nof Atari and simulated robotics environments.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:21:07 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 20:23:18 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Pich\u00e9", "Alexandre", ""], ["Marino", "Joseph", ""], ["Marconi", "Gian Maria", ""], ["Pal", "Christopher", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2106.02614", "submitter": "Jinjie Zhang", "authors": "Jinjie Zhang, Alexander Cloninger, Rayan Saab", "title": "Sigma-Delta and Distributed Noise-Shaping Quantization Methods for\n  Random Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping\nmethods for quantizing the Random Fourier features (RFFs) associated with\nshift-invariant kernels. We prove that our quantized RFFs -- even in the case\nof $1$-bit quantization -- allow a high accuracy approximation of the\nunderlying kernels, and the approximation error decays at least polynomially\nfast as the dimension of the RFFs increases. We also show that the quantized\nRFFs can be further compressed, yielding an excellent trade-off between memory\nuse and accuracy. Namely, the approximation error now decays exponentially as a\nfunction of the bits used. Moreover, we empirically show by testing the\nperformance of our methods on several machine learning tasks that our method\ncompares favorably to other state of the art quantization methods in this\ncontext.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:24:47 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhang", "Jinjie", ""], ["Cloninger", "Alexander", ""], ["Saab", "Rayan", ""]]}, {"id": "2106.02619", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Forward Super-Resolution: How Can GANs Learn Hierarchical Generative\n  Models for Real-World Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are among the most successful models\nfor learning high-complexity, real-world distributions. However, in theory, due\nto the highly non-convex, non-concave landscape of the minmax training\nobjective, GAN remains one of the least understood deep learning models. In\nthis work, we formally study how GANs can efficiently learn certain\nhierarchically generated distributions that are close to the distribution of\nimages in practice. We prove that when a distribution has a structure that we\nrefer to as Forward Super-Resolution, then simply training generative\nadversarial networks using gradient descent ascent (GDA) can indeed learn this\ndistribution efficiently, both in terms of sample and time complexities. We\nalso provide concrete empirical evidence that not only our assumption \"forward\nsuper-resolution\" is very natural in practice, but also the underlying learning\nmechanisms that we study in this paper (to allow us efficiently train GAN via\nGDA in theory) simulates the actual learning process of GANs in practice on\nreal-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:33:29 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2106.02624", "submitter": "Felix Dangel", "authors": "Felix Dangel, Lukas Tatzel, Philipp Hennig", "title": "ViViT: Curvature access through the generalized Gauss-Newton's low-rank\n  structure", "comments": "Main text: 11 pages, 3 figures; Supplements: 14 pages, 10 figures, 2\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Curvature in form of the Hessian or its generalized Gauss-Newton (GGN)\napproximation is valuable for algorithms that rely on a local model for the\nloss to train, compress, or explain deep networks. Existing methods based on\nimplicit multiplication via automatic differentiation or Kronecker-factored\nblock diagonal approximations do not consider noise in the mini-batch. We\npresent ViViT, a curvature model that leverages the GGN's low-rank structure\nwithout further approximations. It allows for efficient computation of\neigenvalues, eigenvectors, as well as per-sample first- and second-order\ndirectional derivatives. The representation is computed in parallel with\ngradients in one backward pass and offers a fine-grained cost-accuracy\ntrade-off, which allows it to scale. As examples for ViViT's usefulness, we\ninvestigate the directional gradients and curvatures during training, and how\nnoise information can be used to improve the stability of second-order methods.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:37:47 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Dangel", "Felix", ""], ["Tatzel", "Lukas", ""], ["Hennig", "Philipp", ""]]}, {"id": "2106.02630", "submitter": "Elvis Dohmatob", "authors": "Elvis Dohmatob", "title": "Fundamental tradeoffs between memorization and robustness in random\n  features and neural tangent regimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the (non)robustness of two-layer neural networks in various\nhigh-dimensional linearized regimes. We establish fundamental trade-offs\nbetween memorization and robustness, as measured by the Sobolev-seminorm of the\nmodel w.r.t the data distribution, i.e the square root of the average squared\n$L_2$-norm of the gradients of the model w.r.t the its input. More precisely,\nif $n$ is the number of training examples, $d$ is the input dimension, and $k$\nis the number of hidden neurons in a two-layer neural network, we prove for a\nlarge class of activation functions that, if the model memorizes even a\nfraction of the training, then its Sobolev-seminorm is lower-bounded by (i)\n$\\sqrt{n}$ in case of infinite-width random features (RF) or neural tangent\nkernel (NTK) with $d \\gtrsim n$; (ii) $\\sqrt{n}$ in case of finite-width RF\nwith proportionate scaling of $d$ and $k$; and (iii) $\\sqrt{n/k}$ in case of\nfinite-width NTK with proportionate scaling of $d$ and $k$. Moreover, all of\nthese lower-bounds are tight: they are attained by the min-norm / least-squares\ninterpolator (when $n$, $d$, and $k$ are in the appropriate interpolating\nregime). All our results hold as soon as data is log-concave isotropic, and\nthere is label-noise, i.e the target variable is not a deterministic function\nof the data / features. We empirically validate our theoretical results with\nexperiments. Accidentally, these experiments also reveal for the first time,\n(iv) a multiple-descent phenomenon in the robustness of the min-norm\ninterpolator.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:52:50 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Dohmatob", "Elvis", ""]]}, {"id": "2106.02654", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Harikrishna Narasimhan, Dara Bahri, Andrew Cotter,\n  Afshin Rostamizadeh", "title": "Churn Reduction via Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real-world systems, models are frequently updated as more data becomes\navailable, and in addition to achieving high accuracy, the goal is to also\nmaintain a low difference in predictions compared to the base model (i.e.\npredictive ``churn''). If model retraining results in vastly different\nbehavior, then it could cause negative effects in downstream systems,\nespecially if this churn can be avoided with limited impact on model accuracy.\nIn this paper, we show an equivalence between training with distillation using\nthe base model as the teacher and training with an explicit constraint on the\npredictive churn. We then show that distillation performs strongly for low\nchurn training against a number of recent baselines on a wide range of datasets\nand model architectures, including fully-connected networks, convolutional\nnetworks, and transformers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 18:03:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jiang", "Heinrich", ""], ["Narasimhan", "Harikrishna", ""], ["Bahri", "Dara", ""], ["Cotter", "Andrew", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "2106.02680", "submitter": "Allen Liu", "authors": "Allen Liu, Ankur Moitra", "title": "How to Decompose a Tensor with Group Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the orbit recovery problem, which is a natural\nabstraction for the problem of recovering a planted signal from noisy\nmeasurements under unknown group actions. Many important inverse problems in\nstatistics, engineering and the sciences fit into this framework. Prior work\nhas studied cases when the group is discrete and/or abelian. However\nfundamentally new techniques are needed in order to handle more complex group\nactions.\n  Our main result is a quasi-polynomial time algorithm to solve orbit recovery\nover $SO(3)$ - i.e. the cryo-electron tomography problem which asks to recover\nthe three-dimensional structure of a molecule from noisy measurements of\nrandomly rotated copies of it. We analyze a variant of the frequency marching\nheuristic in the framework of smoothed analysis. Our approach exploits the\nlayered structure of the invariant polynomials, and simultaneously yields a new\nclass of tensor decomposition algorithms that work in settings when the tensor\nis not low-rank but rather where the factors are algebraically related to each\nother by a group action.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:27:24 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Allen", ""], ["Moitra", "Ankur", ""]]}, {"id": "2106.02713", "submitter": "Blake Bordelon", "authors": "Blake Bordelon and Cengiz Pehlevan", "title": "Learning Curves for SGD on Structured Features", "comments": "Fixed Typo in A.7", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The generalization performance of a machine learning algorithm such as a\nneural network depends in a non-trivial way on the structure of the data\ndistribution. Models of generalization in machine learning theory often ignore\nthe low-dimensional structure of natural signals, either by considering\ndata-agnostic bounds or by studying the performance of the algorithm when\ntrained on uncorrelated features. To analyze the influence of data structure on\ntest loss dynamics, we study an exactly solveable model of stochastic gradient\ndescent (SGD) which predicts test loss when training on features with arbitrary\ncovariance structure. We solve the theory exactly for both Gaussian features\nand arbitrary features and we show that the simpler Gaussian model accurately\npredicts test loss of nonlinear random-feature models and deep neural networks\ntrained with SGD on real datasets such as MNIST and CIFAR-10. We show that\nmodeling the geometry of the data in the induced feature space is indeed\ncrucial to accurately predict the test error throughout learning.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 20:48:20 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 14:44:31 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Bordelon", "Blake", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2106.02735", "submitter": "Sui Tang", "authors": "Jinchao Feng, Yunxiang Ren, Sui Tang", "title": "Data-driven discovery of interacting particle systems using Gaussian\n  processes", "comments": "10 pages; Appendix 19 pages;", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interacting particle or agent systems that display a rich variety of\ncollection motions are ubiquitous in science and engineering. A fundamental and\nchallenging goal is to understand the link between individual interaction rules\nand collective behaviors. In this paper, we study the data-driven discovery of\ndistance-based interaction laws in second-order interacting particle systems.\nWe propose a learning approach that models the latent interaction kernel\nfunctions as Gaussian processes, which can simultaneously fulfill two inference\ngoals: one is the nonparametric inference of interaction kernel function with\nthe pointwise uncertainty quantification, and the other one is the inference of\nunknown parameters in the non-collective forces of the system. We formulate\nlearning interaction kernel functions as a statistical inverse problem and\nprovide a detailed analysis of recoverability conditions, establishing that a\ncoercivity condition is sufficient for recoverability. We provide a\nfinite-sample analysis, showing that our posterior mean estimator converges at\nan optimal rate equal to the one in the classical 1-dimensional Kernel Ridge\nregression. Numerical results on systems that exhibit different collective\nbehaviors demonstrate efficient learning of our approach from scarce noisy\ntrajectory data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 22:00:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Feng", "Jinchao", ""], ["Ren", "Yunxiang", ""], ["Tang", "Sui", ""]]}, {"id": "2106.02770", "submitter": "Dongxia Wu", "authors": "Dongxia Wu, Matteo Chinazzi, Alessandro Vespignani, Yi-An Ma, Rose Yu", "title": "Accelerating Stochastic Simulation with Interactive Neural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic simulations such as large-scale, spatiotemporal, age-structured\nepidemic models are computationally expensive at fine-grained resolution. We\npropose Interactive Neural Process (INP), an interactive framework to\ncontinuously learn a deep learning surrogate model and accelerate simulation.\nOur framework is based on the novel integration of Bayesian active learning,\nstochastic simulation and deep sequence modeling. In particular, we develop a\nnovel spatiotemporal neural process model to mimic the underlying process\ndynamics. Our model automatically infers the latent process which describes the\nintrinsic uncertainty of the simulator. This also gives rise to a new\nacquisition function that can quantify the uncertainty of deep learning\npredictions. We design Bayesian active learning algorithms to iteratively query\nthe simulator, gather more data, and continuously improve the model. We perform\ntheoretical analysis and demonstrate that our approach reduces sample\ncomplexity compared with random sampling in high dimension. Empirically, we\ndemonstrate our framework can faithfully imitate the behavior of a complex\ninfectious disease simulator with a small number of examples, enabling rapid\nsimulation and scenario exploration.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 01:31:51 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 03:45:26 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wu", "Dongxia", ""], ["Chinazzi", "Matteo", ""], ["Vespignani", "Alessandro", ""], ["Ma", "Yi-An", ""], ["Yu", "Rose", ""]]}, {"id": "2106.02774", "submitter": "Allen Liu", "authors": "Jerry Li, Allen Liu, Ankur Moitra", "title": "Sparsification for Sums of Exponentials and its Algorithmic Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many works in signal processing and learning theory operate under the\nassumption that the underlying model is simple, e.g. that a signal is\napproximately $k$-Fourier-sparse or that a distribution can be approximated by\na mixture model that has at most $k$ components. However the problem of fitting\nthe parameters of such a model becomes more challenging when the\nfrequencies/components are too close together.\n  In this work we introduce new methods for sparsifying sums of exponentials\nand give various algorithmic applications. First we study Fourier-sparse\ninterpolation without a frequency gap, where Chen et al. gave an algorithm for\nfinding an $\\epsilon$-approximate solution which uses $k' = \\mbox{poly}(k, \\log\n1/\\epsilon)$ frequencies. Second, we study learning Gaussian mixture models in\none dimension without a separation condition. Kernel density estimators give an\n$\\epsilon$-approximation that uses $k' = O(k/\\epsilon^2)$ components. These\nmethods both output models that are much more complex than what we started out\nwith. We show how to post-process to reduce the number of\nfrequencies/components down to $k' = \\widetilde{O}(k)$, which is optimal up to\nlogarithmic factors. Moreover we give applications to model selection. In\nparticular, we give the first algorithms for approximately (and robustly)\ndetermining the number of components in a Gaussian mixture model that work\nwithout a separation condition.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 01:58:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Li", "Jerry", ""], ["Liu", "Allen", ""], ["Moitra", "Ankur", ""]]}, {"id": "2106.02780", "submitter": "Tianyi Peng", "authors": "Vivek F. Farias, Andrew A. Li, Tianyi Peng", "title": "Learning Treatment Effects in Panels with General Intervention Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of causal inference with panel data is a central econometric\nquestion. The following is a fundamental version of this problem: Let $M^*$ be\na low rank matrix and $E$ be a zero-mean noise matrix. For a `treatment' matrix\n$Z$ with entries in $\\{0,1\\}$ we observe the matrix $O$ with entries $O_{ij} :=\nM^*_{ij} + E_{ij} + \\mathcal{T}_{ij} Z_{ij}$ where $\\mathcal{T}_{ij} $ are\nunknown, heterogenous treatment effects. The problem requires we estimate the\naverage treatment effect $\\tau^* := \\sum_{ij} \\mathcal{T}_{ij} Z_{ij} /\n\\sum_{ij} Z_{ij}$. The synthetic control paradigm provides an approach to\nestimating $\\tau^*$ when $Z$ places support on a single row. This paper extends\nthat framework to allow rate-optimal recovery of $\\tau^*$ for general $Z$, thus\nbroadly expanding its applicability. Our guarantees are the first of their type\nin this general setting. Computational experiments on synthetic and real-world\ndata show a substantial advantage over competing estimators.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 02:42:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Farias", "Vivek F.", ""], ["Li", "Andrew A.", ""], ["Peng", "Tianyi", ""]]}, {"id": "2106.02803", "submitter": "Tianxi Li", "authors": "Tianxi Li, Can M. Le", "title": "Network Estimation by Mixing: Adaptivity and More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks analysis has been commonly used to study the interactions between\nunits of complex systems. One problem of particular interest is learning the\nnetwork's underlying connection pattern given a single and noisy instantiation.\nWhile many methods have been proposed to address this problem in recent years,\nthey usually assume that the true model belongs to a known class, which is not\nverifiable in most real-world applications. Consequently, network modeling\nbased on these methods either suffers from model misspecification or relies on\nadditional model selection procedures that are not well understood in theory\nand can potentially be unstable in practice. To address this difficulty, we\npropose a mixing strategy that leverages available arbitrary models to improve\ntheir individual performances. The proposed method is computationally efficient\nand almost tuning-free; thus, it can be used as an off-the-shelf method for\nnetwork modeling. We show that the proposed method performs equally well as the\noracle estimate when the true model is included as individual candidates. More\nimportantly, the method remains robust and outperforms all current estimates\neven when the models are misspecified. Extensive simulation examples are used\nto verify the advantage of the proposed mixing method. Evaluation of link\nprediction performance on 385 real-world networks from six domains also\ndemonstrates the universal competitiveness of the mixing method across multiple\ndomains.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 05:17:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Li", "Tianxi", ""], ["Le", "Can M.", ""]]}, {"id": "2106.02847", "submitter": "Aymen Al Marjani", "authors": "Aymen Al Marjani, Aur\\'elien Garivier, Alexandre Proutiere", "title": "Navigating to the Best Policy in Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the classical active pure exploration problem in Markov\nDecision Processes, where the agent sequentially selects actions and, from the\nresulting system trajectory, aims at identifying the best policy as fast as\npossible. We propose an information-theoretic lower bound on the average number\nof steps required before a correct answer can be given with probability at\nleast $1-\\delta$. This lower bound involves a non-convex optimization problem,\nfor which we propose a convex relaxation. We further provide an algorithm whose\nsample complexity matches the relaxed lower bound up to a factor $2$. This\nalgorithm addresses general communicating MDPs; we propose a variant with\nreduced exploration rate (and hence faster convergence) under an additional\nergodicity assumption. This work extends previous results relative to the\n\\emph{generative setting}~\\cite{marjani2020adaptive}, where the agent could at\neach step observe the random outcome of any (state, action) pair. In contrast,\nwe show here how to deal with the \\emph{navigation constraints}. Our analysis\nrelies on an ergodic theorem for non-homogeneous Markov chains which we\nconsider of wide interest in the analysis of Markov Decision Processes.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 09:16:28 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Marjani", "Aymen Al", ""], ["Garivier", "Aur\u00e9lien", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "2106.02875", "submitter": "Zhaozhi Qian", "authors": "Zhaozhi Qian, William R. Zame, Lucas M. Fleuren, Paul Elbers, Mihaela\n  van der Schaar", "title": "Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease\n  Progression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling a system's temporal behaviour in reaction to external stimuli is a\nfundamental problem in many areas. Pure Machine Learning (ML) approaches often\nfail in the small sample regime and cannot provide actionable insights beyond\npredictions. A promising modification has been to incorporate expert domain\nknowledge into ML models. The application we consider is predicting the\nprogression of disease under medications, where a plethora of domain knowledge\nis available from pharmacology. Pharmacological models describe the dynamics of\ncarefully-chosen medically meaningful variables in terms of systems of Ordinary\nDifferential Equations (ODEs). However, these models only describe a limited\ncollection of variables, and these variables are often not observable in\nclinical environments. To close this gap, we propose the latent hybridisation\nmodel (LHM) that integrates a system of expert-designed ODEs with\nmachine-learned Neural ODEs to fully describe the dynamics of the system and to\nlink the expert and latent variables to observable quantities. We evaluated LHM\non synthetic data as well as real-world intensive care data of COVID-19\npatients. LHM consistently outperforms previous works, especially when few\ntraining samples are available such as at the beginning of the pandemic.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 11:42:45 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 08:09:33 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 10:07:10 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Qian", "Zhaozhi", ""], ["Zame", "William R.", ""], ["Fleuren", "Lucas M.", ""], ["Elbers", "Paul", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2106.02878", "submitter": "Zhen-Hai Chang", "authors": "Wei Liu and Zhenhai Chang and Caiyan Jia and Yimei Zheng", "title": "A Generative Node-attribute Network Model for Detecting Generalized\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploring meaningful structural regularities embedded in networks is a key to\nunderstanding and analyzing the structure and function of a network. The\nnode-attribute information can help improve such understanding and analysis.\nHowever, most of the existing methods focus on detecting traditional\ncommunities, i.e., groupings of nodes with dense internal connections and\nsparse external ones. In this paper, based on the connectivity behavior of\nnodes and homogeneity of attributes, we propose a principle model (named GNAN),\nwhich can generate both topology information and attribute information. The new\nmodel can detect not only community structure, but also a range of other types\nof structure in networks, such as bipartite structure, core-periphery\nstructure, and their mixture structure, which are collectively referred to as\ngeneralized structure. The proposed model that combines topological information\nand node-attribute information can detect communities more accurately than the\nmodel that only uses topology information. The dependency between attributes\nand communities can be automatically learned by our model and thus we can\nignore the attributes that do not contain useful information. The model\nparameters are inferred by using the expectation-maximization algorithm. And a\ncase study is provided to show the ability of our model in the semantic\ninterpretability of communities. Experiments on both synthetic and real-world\nnetworks show that the new model is competitive with other state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 12:07:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Wei", ""], ["Chang", "Zhenhai", ""], ["Jia", "Caiyan", ""], ["Zheng", "Yimei", ""]]}, {"id": "2106.02890", "submitter": "Dinghuai Zhang", "authors": "Dinghuai Zhang, Kartik Ahuja, Yilun Xu, Yisen Wang, Aaron Courville", "title": "Can Subnetwork Structure be the Key to Out-of-Distribution\n  Generalization?", "comments": "Accepted to ICML2021 as long talk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can models with particular structure avoid being biased towards spurious\ncorrelation in out-of-distribution (OOD) generalization? Peters et al. (2016)\nprovides a positive answer for linear cases. In this paper, we use a functional\nmodular probing method to analyze deep model structures under OOD setting. We\ndemonstrate that even in biased models (which focus on spurious correlation)\nthere still exist unbiased functional subnetworks. Furthermore, we articulate\nand demonstrate the functional lottery ticket hypothesis: full network contains\na subnetwork that can achieve better OOD performance. We then propose Modular\nRisk Minimization to solve the subnetwork selection problem. Our algorithm\nlearns the subnetwork structure from a given dataset, and can be combined with\nany other OOD regularization methods. Experiments on various OOD generalization\ntasks corroborate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 13:19:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Dinghuai", ""], ["Ahuja", "Kartik", ""], ["Xu", "Yilun", ""], ["Wang", "Yisen", ""], ["Courville", "Aaron", ""]]}, {"id": "2106.02978", "submitter": "Qin Ding Miss", "authors": "Qin Ding, Cho-Jui Hsieh, James Sharpnack", "title": "Robust Stochastic Linear Contextual Bandits Under Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic linear contextual bandit algorithms have substantial applications\nin practice, such as recommender systems, online advertising, clinical trials,\netc. Recent works show that optimal bandit algorithms are vulnerable to\nadversarial attacks and can fail completely in the presence of attacks.\nExisting robust bandit algorithms only work for the non-contextual setting\nunder the attack of rewards and cannot improve the robustness in the general\nand popular contextual bandit environment. In addition, none of the existing\nmethods can defend against attacked context. In this work, we provide the first\nrobust bandit algorithm for stochastic linear contextual bandit setting under a\nfully adaptive and omniscient attack. Our algorithm not only works under the\nattack of rewards, but also under attacked context. Moreover, it does not need\nany information about the attack budget or the particular form of the attack.\nWe provide theoretical guarantees for our proposed algorithm and show by\nextensive experiments that our proposed algorithm significantly improves the\nrobustness against various kinds of popular attacks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 22:20:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ding", "Qin", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "2106.02979", "submitter": "Qin Ding Miss", "authors": "Qin Ding, Yi-Wei Liu, Cho-Jui Hsieh, James Sharpnack", "title": "Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in\n  Contextual Bandit Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic contextual bandit problem, which models the trade-off between\nexploration and exploitation, has many real applications, including recommender\nsystems, online advertising and clinical trials. As many other machine learning\nalgorithms, contextual bandit algorithms often have one or more\nhyper-parameters. As an example, in most optimal stochastic contextual bandit\nalgorithms, there is an unknown exploration parameter which controls the\ntrade-off between exploration and exploitation. A proper choice of the\nhyper-parameters is essential for contextual bandit algorithms to perform well.\nHowever, it is infeasible to use offline tuning methods to select\nhyper-parameters in contextual bandit environment since there is no\npre-collected dataset and the decisions have to be made in real time. To tackle\nthis problem, we first propose a two-layer bandit structure for auto tuning the\nexploration parameter and further generalize it to the Syndicated Bandits\nframework which can learn multiple hyper-parameters dynamically in contextual\nbandit environment. We show our Syndicated Bandits framework can achieve the\noptimal regret upper bounds and is general enough to handle the tuning tasks in\nmany popular contextual bandit algorithms, such as LinUCB, LinTS, UCB-GLM, etc.\nExperiments on both synthetic and real datasets validate the effectiveness of\nour proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 22:30:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ding", "Qin", ""], ["Liu", "Yi-Wei", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "2106.02988", "submitter": "Yangyi Lu", "authors": "Yangyi Lu, Amirhossein Meisami, Ambuj Tewari", "title": "Causal Bandits with Unknown Graph Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In causal bandit problems, the action set consists of interventions on\nvariables of a causal graph. Several researchers have recently studied such\nbandit problems and pointed out their practical applications. However, all\nexisting works rely on a restrictive and impractical assumption that the\nlearner is given full knowledge of the causal graph structure upfront. In this\npaper, we develop novel causal bandit algorithms without knowing the causal\ngraph. Our algorithms work well for causal trees, causal forests and a general\nclass of causal graphs. The regret guarantees of our algorithms greatly improve\nupon those of standard multi-armed bandit (MAB) algorithms under mild\nconditions. Lastly, we prove our mild conditions are necessary: without them\none cannot do better than standard MAB bandit algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 23:41:38 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lu", "Yangyi", ""], ["Meisami", "Amirhossein", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2106.02993", "submitter": "Arka Daw", "authors": "Arka Daw, M. Maruf, Anuj Karpatne", "title": "PID-GAN: A GAN Framework based on a Physics-informed Discriminator for\n  Uncertainty Quantification with Physics", "comments": "11 pages, 11 figures, 2 tables, Published at KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467449", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As applications of deep learning (DL) continue to seep into critical\nscientific use-cases, the importance of performing uncertainty quantification\n(UQ) with DL has become more pressing than ever before. In scientific\napplications, it is also important to inform the learning of DL models with\nknowledge of physics of the problem to produce physically consistent and\ngeneralized solutions. This is referred to as the emerging field of\nphysics-informed deep learning (PIDL). We consider the problem of developing\nPIDL formulations that can also perform UQ. To this end, we propose a novel\nphysics-informed GAN architecture, termed PID-GAN, where the knowledge of\nphysics is used to inform the learning of both the generator and discriminator\nmodels, making ample use of unlabeled data instances. We show that our proposed\nPID-GAN framework does not suffer from imbalance of generator gradients from\nmultiple loss terms as compared to state-of-the-art. We also empirically\ndemonstrate the efficacy of our proposed framework on a variety of case studies\ninvolving benchmark physics-based PDEs as well as imperfect physics. All the\ncode and datasets used in this study have been made available on this link :\nhttps://github.com/arkadaw9/PID-GAN.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 00:12:57 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Daw", "Arka", ""], ["Maruf", "M.", ""], ["Karpatne", "Anuj", ""]]}, {"id": "2106.03007", "submitter": "Shohei Ohsawa", "authors": "Shohei Ohsawa", "title": "Unbiased Self-Play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE econ.EM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a general optimization framework for emergent belief-state\nrepresentation without any supervision. We employed the common configuration of\nmultiagent reinforcement learning and communication to improve exploration\ncoverage over an environment by leveraging the knowledge of each agent. In this\npaper, we obtained that recurrent neural nets (RNNs) with shared weights are\nhighly biased in partially observable environments because of their\nnoncooperativity. To address this, we designated an unbiased version of\nself-play via mechanism design, also known as reverse game theory, to clarify\nunbiased knowledge at the Bayesian Nash equilibrium. The key idea is to add\nimaginary rewards using the peer prediction mechanism, i.e., a mechanism for\nmutually criticizing information in a decentralized environment. Numerical\nanalyses, including StarCraft exploration tasks with up to 20 agents and\noff-the-shelf RNNs, demonstrate the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 02:16:45 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ohsawa", "Shohei", ""]]}, {"id": "2106.03022", "submitter": "Fang Han", "authors": "Zhen Miao, Weihao Kong, Ramya Korlakai Vinayak, Wei Sun, and Fang Han", "title": "Fisher-Pitman permutation tests based on nonparametric Poisson mixtures\n  with application to single cell genomics", "comments": "52 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the theoretical and empirical performance of\nFisher-Pitman-type permutation tests for assessing the equality of unknown\nPoisson mixture distributions. Building on nonparametric maximum likelihood\nestimators (NPMLEs) of the mixing distribution, these tests are theoretically\nshown to be able to adapt to complicated unspecified structures of count data\nand also consistent against their corresponding ANOVA-type alternatives; the\nlatter is a result in parallel to classic claims made by Robinson (Robinson,\n1973). The studied methods are then applied to a single-cell RNA-seq data\nobtained from different cell types from brain samples of autism subjects and\nhealthy controls; empirically, they unveil genes that are differentially\nexpressed between autism and control subjects yet are missed using common\ntests. For justifying their use, rate optimality of NPMLEs is also established\nin settings similar to nonparametric Gaussian (Wu and Yang, 2020a) and binomial\nmixtures (Tian et al., 2017; Vinayak et al., 2019).\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 03:31:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Miao", "Zhen", ""], ["Kong", "Weihao", ""], ["Vinayak", "Ramya Korlakai", ""], ["Sun", "Wei", ""], ["Han", "Fang", ""]]}, {"id": "2106.03023", "submitter": "Ioannis Papageorgiou", "authors": "Ioannis Papageorgiou, Ioannis Kontoyiannis", "title": "Hierarchical Bayesian Mixture Models for Time Series Using Context Trees\n  as State Space Partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general Bayesian framework is introduced for mixture modelling and\ninference with real-valued time series. At the top level, the state space is\npartitioned via the choice of a discrete context tree, so that the resulting\npartition depends on the values of some of the most recent samples. At the\nbottom level, a different model is associated with each region of the\npartition. This defines a very rich and flexible class of mixture models, for\nwhich we provide algorithms that allow for efficient, exact Bayesian inference.\nIn particular, we show that the maximum a posteriori probability (MAP) model\n(including the relevant MAP context tree partition) can be precisely\nidentified, along with its exact posterior probability. The utility of this\ngeneral framework is illustrated in detail when a different autoregressive (AR)\nmodel is used in each state-space region, resulting in a mixture-of-AR model\nclass. The performance of the associated algorithmic tools is demonstrated in\nthe problems of model selection and forecasting on both simulated and\nreal-world data, where they are found to provide results as good or better than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 03:46:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Papageorgiou", "Ioannis", ""], ["Kontoyiannis", "Ioannis", ""]]}, {"id": "2106.03032", "submitter": "Jongsu Kim", "authors": "Jongsu Kim and Changhoon Lee", "title": "Deep Particulate Matter Forecasting Model Using Correntropy-Induced Loss", "comments": "Submitted to Journal of Mechanical Science and Technology (In review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Forecasting the particulate matter (PM) concentration in South Korea has\nbecome urgently necessary owing to its strong negative impact on human life. In\nmost statistical or machine learning methods, independent and identically\ndistributed data, for example, a Gaussian distribution, are assumed; however,\ntime series such as air pollution and weather data do not meet this assumption.\nIn this study, the maximum correntropy criterion for regression (MCCR) loss is\nused in an analysis of the statistical characteristics of air pollution and\nweather data. Rigorous seasonality adjustment of the air pollution and weather\ndata was performed because of their complex seasonality patterns and the\nheavy-tailed distribution of data even after deseasonalization. The MCCR loss\nwas applied to multiple models including conventional statistical models and\nstate-of-the-art machine learning models. The results show that the MCCR loss\nis more appropriate than the conventional mean squared error loss for\nforecasting extreme values.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 05:17:24 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kim", "Jongsu", ""], ["Lee", "Changhoon", ""]]}, {"id": "2106.03091", "submitter": "Soufiane Hayou", "authors": "Soufiane Hayou, Fadhel Ayed", "title": "Regularization in ResNet with Stochastic Depth", "comments": "24 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization plays a major role in modern deep learning. From classic\ntechniques such as L1,L2 penalties to other noise-based methods such as\nDropout, regularization often yields better generalization properties by\navoiding overfitting. Recently, Stochastic Depth (SD) has emerged as an\nalternative regularization technique for residual neural networks (ResNets) and\nhas proven to boost the performance of ResNet on many tasks [Huang et al.,\n2016]. Despite the recent success of SD, little is known about this technique\nfrom a theoretical perspective. This paper provides a hybrid analysis combining\nperturbation analysis and signal propagation to shed light on different\nregularization effects of SD. Our analysis allows us to derive principled\nguidelines for choosing the survival rates used for training with SD.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 10:56:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hayou", "Soufiane", ""], ["Ayed", "Fadhel", ""]]}, {"id": "2106.03131", "submitter": "Vinod Vaikuntanathan", "authors": "Aparna Gupte and Vinod Vaikuntanathan", "title": "The Fine-Grained Hardness of Sparse Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sparse linear regression is the well-studied inference problem where one is\ngiven a design matrix $\\mathbf{A} \\in \\mathbb{R}^{M\\times N}$ and a response\nvector $\\mathbf{b} \\in \\mathbb{R}^M$, and the goal is to find a solution\n$\\mathbf{x} \\in \\mathbb{R}^{N}$ which is $k$-sparse (that is, it has at most\n$k$ non-zero coordinates) and minimizes the prediction error $||\\mathbf{A}\n\\mathbf{x} - \\mathbf{b}||_2$. On the one hand, the problem is known to be\n$\\mathcal{NP}$-hard which tells us that no polynomial-time algorithm exists\nunless $\\mathcal{P} = \\mathcal{NP}$. On the other hand, the best known\nalgorithms for the problem do a brute-force search among $N^k$ possibilities.\nIn this work, we show that there are no better-than-brute-force algorithms,\nassuming any one of a variety of popular conjectures including the weighted\n$k$-clique conjecture from the area of fine-grained complexity, or the hardness\nof the closest vector problem from the geometry of numbers. We also show the\nimpossibility of better-than-brute-force algorithms when the prediction error\nis measured in other $\\ell_p$ norms, assuming the strong exponential-time\nhypothesis.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 14:19:43 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Gupte", "Aparna", ""], ["Vaikuntanathan", "Vinod", ""]]}, {"id": "2106.03156", "submitter": "Youngki Shin", "authors": "Sokbae Lee, Yuan Liao, Myung Hwan Seo, Youngki Shin", "title": "Fast and Robust Online Inference with Stochastic Gradient Descent via\n  Random Scaling", "comments": "16 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We develop a new method of online inference for a vector of parameters\nestimated by the Polyak-Ruppert averaging procedure of stochastic gradient\ndescent (SGD) algorithms. We leverage insights from time series regression in\neconometrics and construct asymptotically pivotal statistics via random\nscaling. Our approach is fully operational with online data and is rigorously\nunderpinned by a functional central limit theorem. Our proposed inference\nmethod has a couple of key advantages over the existing methods. First, the\ntest statistic is computed in an online fashion with only SGD iterates and the\ncritical values can be obtained without any resampling methods, thereby\nallowing for efficient implementation suitable for massive online data. Second,\nthere is no need to estimate the asymptotic variance and our inference method\nis shown to be robust to changes in the tuning parameters for SGD algorithms in\nsimulation experiments with synthetic data.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 15:38:37 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 13:52:59 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Lee", "Sokbae", ""], ["Liao", "Yuan", ""], ["Seo", "Myung Hwan", ""], ["Shin", "Youngki", ""]]}, {"id": "2106.03194", "submitter": "Saber Jafarpour", "authors": "Saber Jafarpour, Alexander Davydov, Anton V. Proskurnikov, Francesco\n  Bullo", "title": "Robust Implicit Networks via Non-Euclidean Contractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit neural networks, a.k.a., deep equilibrium networks, are a class of\nimplicit-depth learning models where function evaluation is performed by\nsolving a fixed point equation. They generalize classic feedforward models and\nare equivalent to infinite-depth weight-tied feedforward networks. While\nimplicit models show improved accuracy and significant reduction in memory\nconsumption, they can suffer from ill-posedness and convergence instability.\n  This paper provides a new framework to design well-posed and robust implicit\nneural networks based upon contraction theory for the non-Euclidean norm\n$\\ell_\\infty$. Our framework includes (i) a novel condition for well-posedness\nbased on one-sided Lipschitz constants, (ii) an average iteration for computing\nfixed-points, and (iii) explicit estimates on input-output Lipschitz constants.\nAdditionally, we design a training problem with the well-posedness condition\nand the average iteration as constraints and, to achieve robust models, with\nthe input-output Lipschitz constant as a regularizer. Our $\\ell_\\infty$\nwell-posedness condition leads to a larger polytopic training search space than\nexisting conditions and our average iteration enjoys accelerated convergence.\nFinally, we perform several numerical experiments for function estimation and\ndigit classification through the MNIST data set. Our numerical results\ndemonstrate improved accuracy and robustness of the implicit models with\nsmaller input-output Lipschitz bounds.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 18:05:02 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 16:37:34 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Jafarpour", "Saber", ""], ["Davydov", "Alexander", ""], ["Proskurnikov", "Anton V.", ""], ["Bullo", "Francesco", ""]]}, {"id": "2106.03195", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss, Dominique Heyn, Jinfan Chen, Andreas Krause", "title": "Meta-Learning Reliable Priors in the Function Space", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Meta-Learning promises to enable more data-efficient inference by harnessing\nprevious experience from related learning tasks. While existing meta-learning\nmethods help us to improve the accuracy of our predictions in face of data\nscarcity, they fail to supply reliable uncertainty estimates, often being\ngrossly overconfident in their predictions. Addressing these shortcomings, we\nintroduce a novel meta-learning framework, called F-PACOH, that treats\nmeta-learned priors as stochastic processes and performs meta-level\nregularization directly in the function space. This allows us to directly steer\nthe probabilistic predictions of the meta-learner towards high epistemic\nuncertainty in regions of insufficient meta-training data and, thus, obtain\nwell-calibrated uncertainty estimates. Finally, we showcase how our approach\ncan be integrated with sequential decision making, where reliable uncertainty\nquantification is imperative. In our benchmark study on meta-learning for\nBayesian Optimization (BO), F-PACOH significantly outperforms all other\nmeta-learners and standard baselines. Even in a challenging lifelong BO\nsetting, where optimization tasks arrive one at a time and the meta-learner\nneeds to build up informative prior knowledge incrementally, our proposed\nmethod demonstrates strong positive transfer.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 18:07:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Heyn", "Dominique", ""], ["Chen", "Jinfan", ""], ["Krause", "Andreas", ""]]}, {"id": "2106.03207", "submitter": "Jonathan Chang", "authors": "Jonathan D. Chang, Masatoshi Uehara, Dhruv Sreenivas, Rahul Kidambi,\n  Wen Sun", "title": "Mitigating Covariate Shift in Imitation Learning via Offline Data\n  Without Great Coverage", "comments": "42 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies offline Imitation Learning (IL) where an agent learns to\nimitate an expert demonstrator without additional online environment\ninteractions. Instead, the learner is presented with a static offline dataset\nof state-action-next state transition triples from a potentially less\nproficient behavior policy. We introduce Model-based IL from Offline data\n(MILO): an algorithmic framework that utilizes the static dataset to solve the\noffline IL problem efficiently both in theory and in practice. In theory, even\nif the behavior policy is highly sub-optimal compared to the expert, we show\nthat as long as the data from the behavior policy provides sufficient coverage\non the expert state-action traces (and with no necessity for a global coverage\nover the entire state-action space), MILO can provably combat the covariate\nshift issue in IL. Complementing our theory results, we also demonstrate that a\npractical implementation of our approach mitigates covariate shift on benchmark\nMuJoCo continuous control tasks. We demonstrate that with behavior policies\nwhose performances are less than half of that of the expert, MILO still\nsuccessfully imitates with an extremely low number of expert state-action pairs\nwhile traditional offline IL method such as behavior cloning (BC) fails\ncompletely. Source code is provided at https://github.com/jdchang1/milo.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 18:31:08 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 14:13:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chang", "Jonathan D.", ""], ["Uehara", "Masatoshi", ""], ["Sreenivas", "Dhruv", ""], ["Kidambi", "Rahul", ""], ["Sun", "Wen", ""]]}, {"id": "2106.03211", "submitter": "Nhuong Nguyen", "authors": "Nhuong V. Nguyen and Sybille Legitime", "title": "Distributed Learning and its Application for Time-Series Prediction", "comments": "8 pages, 10 figures, and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extreme events are occurrences whose magnitude and potential cause extensive\ndamage on people, infrastructure, and the environment. Motivated by the extreme\nnature of the current global health landscape, which is plagued by the\ncoronavirus pandemic, we seek to better understand and model extreme events.\nModeling extreme events is common in practice and plays an important role in\ntime-series prediction applications. Our goal is to (i) compare and investigate\nthe effect of some common extreme events modeling methods to explore which\nmethod can be practical in reality and (ii) accelerate the deep learning\ntraining process, which commonly uses deep recurrent neural network (RNN), by\nimplementing the asynchronous local Stochastic Gradient Descent (SGD) framework\namong multiple compute nodes. In order to verify our distributed extreme events\nmodeling, we evaluate our proposed framework on a stock data set S\\&P500, with\na standard recurrent neural network. Our intuition is to explore the (best)\nextreme events modeling method which could work well under the distributed deep\nlearning setting. Moreover, by using asynchronous distributed learning, we aim\nto significantly reduce the communication cost among the compute nodes and\ncentral server, which is the main bottleneck of almost all distributed learning\nframeworks.\n  We implement our proposed work and evaluate its performance on representative\ndata sets, such as S&P500 stock in $5$-year period. The experimental results\nvalidate the correctness of the design principle and show a significant\ntraining duration reduction upto $8$x, compared to the baseline single compute\nnode. Our results also show that our proposed work can achieve the same level\nof test accuracy, compared to the baseline setting.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 18:57:30 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 22:04:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Nguyen", "Nhuong V.", ""], ["Legitime", "Sybille", ""]]}, {"id": "2106.03212", "submitter": "Zhu Li", "authors": "Zhu Li, Zhi-Hua Zhou, Arthur Gretton", "title": "Towards an Understanding of Benign Overfitting in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning models often employ a huge number of parameters and\nare typically optimized to have zero training loss; yet surprisingly, they\npossess near-optimal prediction performance, contradicting classical learning\ntheory. We examine how these benign overfitting phenomena occur in a two-layer\nneural network setting where sample covariates are corrupted with noise. We\naddress the high dimensional regime, where the data dimension $d$ grows with\nthe number $n$ of data points. Our analysis combines an upper bound on the bias\nwith matching upper and lower bounds on the variance of the interpolator (an\nestimator that interpolates the data). These results indicate that the excess\nlearning risk of the interpolator decays under mild conditions. We further show\nthat it is possible for the two-layer ReLU network interpolator to achieve a\nnear minimax-optimal learning rate, which to our knowledge is the first\ngeneralization result for such networks. Finally, our theory predicts that the\nexcess learning risk starts to increase once the number of parameters $s$ grows\nbeyond $O(n^2)$, matching recent empirical findings.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:08:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Li", "Zhu", ""], ["Zhou", "Zhi-Hua", ""], ["Gretton", "Arthur", ""]]}, {"id": "2106.03216", "submitter": "Gerrit van den Burg", "authors": "Gerrit J. J. van den Burg, Christopher K. I. Williams", "title": "On Memorization in Probabilistic Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep generative models have led to impressive results in a\nvariety of application domains. Motivated by the possibility that deep learning\nmodels might memorize part of the input data, there have been increased efforts\nto understand how memorization can occur. In this work, we extend a recently\nproposed measure of memorization for supervised learning (Feldman, 2019) to the\nunsupervised density estimation problem and simplify the accompanying\nestimator. Next, we present an exploratory study that demonstrates how\nmemorization can arise in probabilistic deep generative models, such as\nvariational autoencoders. This reveals that the form of memorization to which\nthese models are susceptible differs fundamentally from mode collapse and\noverfitting. Finally, we discuss several strategies that can be used to limit\nmemorization in practice.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:33:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Burg", "Gerrit J. J. van den", ""], ["Williams", "Christopher K. I.", ""]]}, {"id": "2106.03221", "submitter": "Brijen Thananjeyan", "authors": "Brijen Thananjeyan, Kirthevasan Kandasamy, Ion Stoica, Michael I.\n  Jordan, Ken Goldberg, Joseph E. Gonzalez", "title": "PAC Best Arm Identification Under a Deadline", "comments": "In submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study $(\\epsilon, \\delta)$-PAC best arm identification, where a\ndecision-maker must identify an $\\epsilon$-optimal arm with probability at\nleast $1 - \\delta$, while minimizing the number of arm pulls (samples). Most of\nthe work on this topic is in the sequential setting, where there is no\nconstraint on the time taken to identify such an arm; this allows the\ndecision-maker to pull one arm at a time. In this work, the decision-maker is\ngiven a deadline of $T$ rounds, where, on each round, it can adaptively choose\nwhich arms to pull and how many times to pull them; this distinguishes the\nnumber of decisions made (i.e., time or number of rounds) from the number of\nsamples acquired (cost). Such situations occur in clinical trials, where one\nmay need to identify a promising treatment under a deadline while minimizing\nthe number of test subjects, or in simulation-based studies run on the cloud,\nwhere we can elastically scale up or down the number of virtual machines to\nconduct as many experiments as we wish, but need to pay for the resource-time\nused. As the decision-maker can only make $T$ decisions, she may need to pull\nsome arms excessively relative to a sequential algorithm in order to perform\nwell on all possible problems. We formalize this added difficulty with two\nhardness results that indicate that unlike sequential settings, the ability to\nadapt to the problem difficulty is constrained by the finite deadline. We\npropose Elastic Batch Racing (EBR), a novel algorithm for this setting and\nbound its sample complexity, showing that EBR is optimal with respect to both\nhardness results. We present simulations evaluating EBR in this setting, where\nit outperforms baselines by several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:48:32 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 01:35:09 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Thananjeyan", "Brijen", ""], ["Kandasamy", "Kirthevasan", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""], ["Goldberg", "Ken", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2106.03227", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Yao Xie", "title": "Neural Tangent Kernel Maximum Mean Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a novel neural network Maximum Mean Discrepancy (MMD) statistic by\nidentifying a connection between neural tangent kernel (NTK) and MMD statistic.\nThis connection enables us to develop a computationally efficient and\nmemory-efficient approach to compute the MMD statistic and perform neural\nnetwork based two-sample tests towards addressing the long-standing challenge\nof memory and computational complexity of the MMD statistic, which is essential\nfor online implementation to assimilate new samples. Theoretically, such a\nconnection allows us to understand the properties of the new test statistic,\nsuch as Type-I error and testing power for performing the two-sample test, by\nleveraging analysis tools for kernel MMD. Numerical experiments on synthetic\nand real-world datasets validate the theory and demonstrate the effectiveness\nof the proposed NTK-MMD statistic.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 20:00:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Xie", "Yao", ""]]}, {"id": "2106.03234", "submitter": "Pranava Madhyastha", "authors": "Chunyang Xiao, Pranava Madhyastha", "title": "A call for better unit testing for invariant risk minimisation", "comments": "Manuscript v1.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a controlled study on the linearized IRM framework\n(IRMv1) introduced in Arjovsky et al. (2020). We show that IRMv1 (and its\nvariants) framework can be potentially unstable under small changes to the\noptimal regressor. This can, notably, lead to worse generalisation to new\nenvironments, even compared with ERM which converges simply to the global\nminimum for all training environments mixed up all together. We also highlight\nthe isseus of scaling in the the IRMv1 setup. These observations highlight the\nimportance of rigorous evaluation and importance of unit-testing for measuring\nprogress towards IRM.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 20:07:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Xiao", "Chunyang", ""], ["Madhyastha", "Pranava", ""]]}, {"id": "2106.03273", "submitter": "Evgenii Nikishin", "authors": "Evgenii Nikishin, Romina Abachi, Rishabh Agarwal, Pierre-Luc Bacon", "title": "Control-Oriented Model-Based Reinforcement Learning with Implicit\n  Differentiation", "comments": "Code at https://github.com/evgenii-nikishin/omd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shortcomings of maximum likelihood estimation in the context of\nmodel-based reinforcement learning have been highlighted by an increasing\nnumber of papers. When the model class is misspecified or has a limited\nrepresentational capacity, model parameters with high likelihood might not\nnecessarily result in high performance of the agent on a downstream control\ntask. To alleviate this problem, we propose an end-to-end approach for model\nlearning which directly optimizes the expected returns using implicit\ndifferentiation. We treat a value function that satisfies the Bellman\noptimality operator induced by the model as an implicit function of model\nparameters and show how to differentiate the function. We provide theoretical\nand empirical evidence highlighting the benefits of our approach in the model\nmisspecification regime compared to likelihood-based methods.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 23:15:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nikishin", "Evgenii", ""], ["Abachi", "Romina", ""], ["Agarwal", "Rishabh", ""], ["Bacon", "Pierre-Luc", ""]]}, {"id": "2106.03300", "submitter": "Shu Hu", "authors": "Shu Hu, Yiming Ying, Xin Wang, Siwei Lyu", "title": "Sum of Ranked Range Loss for Supervised Learning", "comments": "40 pages. arXiv admin note: substantial text overlap with\n  arXiv:2010.01741", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In forming learning objectives, one oftentimes needs to aggregate a set of\nindividual values to a single output. Such cases occur in the aggregate loss,\nwhich combines individual losses of a learning model over each training sample,\nand in the individual loss for multi-label learning, which combines prediction\nscores over all class labels. In this work, we introduce the sum of ranked\nrange (SoRR) as a general approach to form learning objectives. A ranked range\nis a consecutive sequence of sorted values of a set of real numbers. The\nminimization of SoRR is solved with the difference of convex algorithm (DCA).\nWe explore two applications in machine learning of the minimization of the SoRR\nframework, namely the AoRR aggregate loss for binary/multi-class classification\nat the sample level and the TKML individual loss for multi-label/multi-class\nclassification at the label level. A combination loss of AoRR and TKML is\nproposed as a new learning objective for improving the robustness of\nmulti-label learning in the face of outliers in sample and labels alike. Our\nempirical results highlight the effectiveness of the proposed optimization\nframeworks and demonstrate the applicability of proposed losses using synthetic\nand real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 02:11:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hu", "Shu", ""], ["Ying", "Yiming", ""], ["Wang", "Xin", ""], ["Lyu", "Siwei", ""]]}, {"id": "2106.03314", "submitter": "Ching-Yao Chuang", "authors": "Ching-Yao Chuang, Youssef Mroueh, Kristjan Greenewald, Antonio\n  Torralba, Stefanie Jegelka", "title": "Measuring Generalization with Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the generalization of deep neural networks is one of the most\nimportant tasks in deep learning. Although much progress has been made,\ntheoretical error bounds still often behave disparately from empirical\nobservations. In this work, we develop margin-based generalization bounds,\nwhere the margins are normalized with optimal transport costs between\nindependent random subsets sampled from the training distribution. In\nparticular, the optimal transport cost can be interpreted as a generalization\nof variance which captures the structural properties of the learned feature\nspace. Our bounds robustly predict the generalization error, given training\ndata and network parameters, on large scale datasets. Theoretically, we\ndemonstrate that the concentration and separation of features play crucial\nroles in generalization, supporting empirical results in the literature. The\ncode is available at \\url{https://github.com/chingyaoc/kV-Margin}.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 03:04:59 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chuang", "Ching-Yao", ""], ["Mroueh", "Youssef", ""], ["Greenewald", "Kristjan", ""], ["Torralba", "Antonio", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "2106.03344", "submitter": "Fei Xue", "authors": "Fei Xue, Rong Ma, Hongzhe Li", "title": "Semi-Supervised Statistical Inference for High-Dimensional Linear\n  Regression with Blockwise Missing Data", "comments": "39 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockwise missing data occurs frequently when we integrate multisource or\nmultimodality data where different sources or modalities contain complementary\ninformation. In this paper, we consider a high-dimensional linear regression\nmodel with blockwise missing covariates and a partially observed response\nvariable. Under this semi-supervised framework, we propose a computationally\nefficient estimator for the regression coefficient vector based on carefully\nconstructed unbiased estimating equations and a multiple blockwise imputation\nprocedure, and obtain its rates of convergence. Furthermore, building upon an\ninnovative semi-supervised projected estimating equation technique that\nintrinsically achieves bias-correction of the initial estimator, we propose\nnearly unbiased estimators for the individual regression coefficients that are\nasymptotically normally distributed under mild conditions. By carefully\nanalyzing these debiased estimators, asymptotically valid confidence intervals\nand statistical tests about each regression coefficient are constructed.\nNumerical studies and application analysis of the Alzheimer's Disease\nNeuroimaging Initiative data show that the proposed method performs better and\nbenefits more from unsupervised samples than existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 05:12:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Xue", "Fei", ""], ["Ma", "Rong", ""], ["Li", "Hongzhe", ""]]}, {"id": "2106.03352", "submitter": "Qinghua Liu", "authors": "Chi Jin, Qinghua Liu, Tiancheng Yu", "title": "The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern reinforcement learning (RL) commonly engages practical problems with\nlarge state spaces, where function approximation must be deployed to\napproximate either the value function or the policy. While recent progresses in\nRL theory address a rich set of RL problems with general function\napproximation, such successes are mostly restricted to the single-agent\nsetting. It remains elusive how to extend these results to multi-agent RL,\nespecially due to the new challenges arising from its game-theoretical nature.\nThis paper considers two-player zero-sum Markov Games (MGs). We propose a new\nalgorithm that can provably find the Nash equilibrium policy using a polynomial\nnumber of samples, for any MG with low multi-agent Bellman-Eluder dimension --\na new complexity measure adapted from its single-agent version (Jin et al.,\n2021). A key component of our new algorithm is the exploiter, which facilitates\nthe learning of the main player by deliberately exploiting her weakness. Our\ntheoretical framework is generic, which applies to a wide range of models\nincluding but not limited to tabular MGs, MGs with linear or kernel function\napproximation, and MGs with rich observations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 05:39:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jin", "Chi", ""], ["Liu", "Qinghua", ""], ["Yu", "Tiancheng", ""]]}, {"id": "2106.03354", "submitter": "Partha Mitra", "authors": "Partha P Mitra and Cl\\'ement Sire", "title": "Parameter-free Statistically Consistent Interpolation:\n  Dimension-independent Convergence Rates for Hilbert kernel regression", "comments": "30 Pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech math.FA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previously, statistical textbook wisdom has held that interpolating noisy\ndata will generalize poorly, but recent work has shown that data interpolation\nschemes can generalize well. This could explain why overparameterized deep nets\ndo not necessarily overfit. Optimal data interpolation schemes have been\nexhibited that achieve theoretical lower bounds for excess risk in any\ndimension for large data (Statistically Consistent Interpolation). These are\nnon-parametric Nadaraya-Watson estimators with singular kernels. The recently\nproposed weighted interpolating nearest neighbors method (wiNN) is in this\nclass, as is the previously studied Hilbert kernel interpolation scheme, in\nwhich the estimator has the form $\\hat{f}(x)=\\sum_i y_i w_i(x)$, where $w_i(x)=\n\\|x-x_i\\|^{-d}/\\sum_j \\|x-x_j\\|^{-d}$. This estimator is unique in being\ncompletely parameter-free. While statistical consistency was previously proven,\nconvergence rates were not established. Here, we comprehensively study the\nfinite sample properties of Hilbert kernel regression. We prove that the excess\nrisk is asymptotically equivalent pointwise to $\\sigma^2(x)/\\ln(n)$ where\n$\\sigma^2(x)$ is the noise variance. We show that the excess risk of the plugin\nclassifier is less than $2|f(x)-1/2|^{1-\\alpha}\\,(1+\\varepsilon)^\\alpha\n\\sigma^\\alpha(x)(\\ln(n))^{-\\frac{\\alpha}{2}}$, for any $0<\\alpha<1$, where $f$\nis the regression function $x\\mapsto\\mathbb{E}[y|x]$. We derive asymptotic\nequivalents of the moments of the weight functions $w_i(x)$ for large $n$, for\ninstance for $\\beta>1$, $\\mathbb{E}[w_i^{\\beta}(x)]\\sim_{n\\rightarrow\n\\infty}((\\beta-1)n\\ln(n))^{-1}$. We derive an asymptotic equivalent for the\nLagrange function and exhibit the nontrivial extrapolation properties of this\nestimator. We present heuristic arguments for a universal $w^{-2}$ power-law\nbehavior of the probability density of the weights in the large $n$ limit.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 05:50:02 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mitra", "Partha P", ""], ["Sire", "Cl\u00e9ment", ""]]}, {"id": "2106.03357", "submitter": "Ryan Theisen", "authors": "Ryan Theisen, Huan Wang, Lav R. Varshney, Caiming Xiong, Richard\n  Socher", "title": "Evaluating State-of-the-Art Classification Models Against Bayes\n  Optimality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evaluating the inherent difficulty of a given data-driven classification\nproblem is important for establishing absolute benchmarks and evaluating\nprogress in the field. To this end, a natural quantity to consider is the\n\\emph{Bayes error}, which measures the optimal classification error\ntheoretically achievable for a given data distribution. While generally an\nintractable quantity, we show that we can compute the exact Bayes error of\ngenerative models learned using normalizing flows. Our technique relies on a\nfundamental result, which states that the Bayes error is invariant under\ninvertible transformation. Therefore, we can compute the exact Bayes error of\nthe learned flow models by computing it for Gaussian base distributions, which\ncan be done efficiently using Holmes-Diaconis-Ross integration. Moreover, we\nshow that by varying the temperature of the learned flow models, we can\ngenerate synthetic datasets that closely resemble standard benchmark datasets,\nbut with almost any desired Bayes error. We use our approach to conduct a\nthorough investigation of state-of-the-art classification models, and find that\nin some -- but not all -- cases, these models are capable of obtaining accuracy\nvery near optimal. Finally, we use our method to evaluate the intrinsic\n\"hardness\" of standard benchmark datasets, and classes within those datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 06:21:20 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Theisen", "Ryan", ""], ["Wang", "Huan", ""], ["Varshney", "Lav R.", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "2106.03365", "submitter": "Yuxuan Han", "authors": "Yuxuan Han, Zhipeng Liang, Yang Wang, Jiheng Zhang", "title": "Generalized Linear Bandits with Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are useful in personalized online\ndecision-making. However, many applications such as personalized medicine and\nonline advertising require the utilization of individual-specific information\nfor effective learning, while user's data should remain private from the server\ndue to privacy concerns. This motivates the introduction of local differential\nprivacy (LDP), a stringent notion in privacy, to contextual bandits. In this\npaper, we design LDP algorithms for stochastic generalized linear bandits to\nachieve the same regret bound as in non-privacy settings. Our main idea is to\ndevelop a stochastic gradient-based estimator and update mechanism to ensure\nLDP. We then exploit the flexibility of stochastic gradient descent (SGD),\nwhose theoretical guarantee for bandit problems is rarely explored, in dealing\nwith generalized linear bandits. We also develop an estimator and update\nmechanism based on Ordinary Least Square (OLS) for linear bandits. Finally, we\nconduct experiments with both simulation and real-world datasets to demonstrate\nthe consistently superb performance of our algorithms under LDP constraints\nwith reasonably small parameters $(\\varepsilon, \\delta)$ to ensure strong\nprivacy protection.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 06:42:00 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Han", "Yuxuan", ""], ["Liang", "Zhipeng", ""], ["Wang", "Yang", ""], ["Zhang", "Jiheng", ""]]}, {"id": "2106.03395", "submitter": "Laurens Sluijterman", "authors": "Laurens Sluijterman, Eric Cator, Tom Heskes", "title": "How to Evaluate Uncertainty Estimates in Machine Learning for\n  Regression?", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks become more popular, the need for accompanying uncertainty\nestimates increases. The current testing methodology focusses on how good the\npredictive uncertainty estimates explain the differences between predictions\nand observations in a previously unseen test set. Intuitively this is a logical\napproach. The current setup of benchmark data sets also allows easy comparison\nbetween the different methods. We demonstrate, however, through both\ntheoretical arguments and simulations that this way of evaluating the quality\nof uncertainty estimates has serious flaws. Firstly, it cannot disentangle the\naleatoric from the epistemic uncertainty. Secondly, the current methodology\nconsiders the uncertainty averaged over all test samples, implicitly averaging\nout overconfident and underconfident predictions. When checking if the correct\nfraction of test points falls inside prediction intervals, a good score on\naverage gives no guarantee that the intervals are sensible for individual\npoints. We demonstrate through practical examples that these effects can result\nin favoring a method, based on the predictive uncertainty, that has undesirable\nbehaviour of the confidence intervals. Finally, we propose a simulation-based\ntesting approach that addresses these problems while still allowing easy\ncomparison between different methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 07:47:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sluijterman", "Laurens", ""], ["Cator", "Eric", ""], ["Heskes", "Tom", ""]]}, {"id": "2106.03477", "submitter": "Siu Lun Chau", "authors": "Siu Lun Chau, Jean-Fran\\c{c}ois Ton, Javier Gonz\\'alez, Yee Whye Teh,\n  Dino Sejdinovic", "title": "BayesIMP: Uncertainty Quantification for Causal Data Fusion", "comments": "10 pages main text, 10 pages supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While causal models are becoming one of the mainstays of machine learning,\nthe problem of uncertainty quantification in causal inference remains\nchallenging. In this paper, we study the causal data fusion problem, where\ndatasets pertaining to multiple causal graphs are combined to estimate the\naverage treatment effect of a target variable. As data arises from multiple\nsources and can vary in quality and quantity, principled uncertainty\nquantification becomes essential. To that end, we introduce Bayesian\nInterventional Mean Processes, a framework which combines ideas from\nprobabilistic integration and kernel mean embeddings to represent\ninterventional distributions in the reproducing kernel Hilbert space, while\ntaking into account the uncertainty within each causal graph. To demonstrate\nthe utility of our uncertainty estimation, we apply our method to the Causal\nBayesian Optimisation task and show improvements over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 10:14:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chau", "Siu Lun", ""], ["Ton", "Jean-Fran\u00e7ois", ""], ["Gonz\u00e1lez", "Javier", ""], ["Teh", "Yee Whye", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2106.03480", "submitter": "Alex Markham", "authors": "Alex Markham and Moritz Grosse-Wentrup", "title": "A Distance Covariance-based Kernel for Nonlinear Causal Clustering in\n  Heterogeneous Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of causal structure learning in the setting of\nheterogeneous populations, i.e., populations in which a single causal structure\ndoes not adequately represent all population members, as is common in\nbiological and social sciences. To this end, we introduce a distance\ncovariance-based kernel designed specifically to measure the similarity between\nthe underlying nonlinear causal structures of different samples. This kernel\nenables us to perform clustering to identify the homogeneous subpopulations.\nIndeed, we prove the corresponding feature map is a statistically consistent\nestimator of nonlinear independence structure, rendering the kernel itself a\nstatistical test for the hypothesis that sets of samples come from different\ngenerating causal structures. We can then use existing methods to learn a\ncausal structure for each of these subpopulations. We demonstrate using our\nkernel for causal clustering with an application in genetics, allowing us to\nreason about the latent transcription factor networks regulating measured gene\nexpression levels.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 10:16:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Markham", "Alex", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "2106.03485", "submitter": "Diego Doimo", "authors": "Diego Doimo, Aldo Glielmo, Sebastian Goldt, Alessandro Laio", "title": "Representation mitosis in wide neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) defy the classical bias-variance trade-off:\nadding parameters to a DNN that exactly interpolates its training data will\ntypically improve its generalisation performance. Explaining the mechanism\nbehind the benefit of such over-parameterisation is an outstanding challenge\nfor deep learning theory. Here, we study the last layer representation of\nvarious deep architectures such as Wide-ResNets for image classification and\nfind evidence for an underlying mechanism that we call *representation\nmitosis*: if the last hidden representation is wide enough, its neurons tend to\nsplit into groups which carry identical information, and differ from each other\nonly by a statistically independent noise. Like in a mitosis process, the\nnumber of such groups, or ``clones'', increases linearly with the width of the\nlayer, but only if the width is above a critical value. We show that a key\ningredient to activate mitosis is continuing the training process until the\ntraining error is zero. Finally, we show that in one of the learning tasks we\nconsidered, a wide model with several automatically developed clones performs\nsignificantly better than a deep ensemble based on architectures in which the\nlast layer has the same size as the clones.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 10:18:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Doimo", "Diego", ""], ["Glielmo", "Aldo", ""], ["Goldt", "Sebastian", ""], ["Laio", "Alessandro", ""]]}, {"id": "2106.03500", "submitter": "Dimitris Kalatzis", "authors": "Dimitris Kalatzis, Johan Ziruo Ye, Jesper Wohlert, S{\\o}ren Hauberg", "title": "Multi-chart flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present Multi-chart flows, a flow-based model for concurrently learning\ntopologically non-trivial manifolds and statistical densities on them. Current\nmethods focus on manifolds that are topologically Euclidean, enforce strong\nstructural priors on the learned models or use operations that do not scale to\nhigh dimensions. In contrast, our model learns the local manifold topology\npiecewise by \"gluing\" it back together through a collection of learned\ncoordinate charts. We demonstrate the efficiency of our approach on synthetic\ndata of known manifolds, as well as higher dimensional manifolds of unknown\ntopology, where we show better sample efficiency and competitive or superior\nperformance against current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 10:37:06 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kalatzis", "Dimitris", ""], ["Ye", "Johan Ziruo", ""], ["Wohlert", "Jesper", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "2106.03517", "submitter": "Siddhant M. Jayakumar", "authors": "Siddhant M. Jayakumar, Razvan Pascanu, Jack W. Rae, Simon Osindero,\n  Erich Elsen", "title": "Top-KAST: Top-K Always Sparse Training", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 33, 20744-20754", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse neural networks are becoming increasingly important as the field seeks\nto improve the performance of existing models by scaling them up, while\nsimultaneously trying to reduce power consumption and computational footprint.\nUnfortunately, most existing methods for inducing performant sparse models\nstill entail the instantiation of dense parameters, or dense gradients in the\nbackward-pass, during training. For very large models this requirement can be\nprohibitive. In this work we propose Top-KAST, a method that preserves constant\nsparsity throughout training (in both the forward and backward-passes). We\ndemonstrate the efficacy of our approach by showing that it performs comparably\nto or better than previous works when training models on the established\nImageNet benchmark, whilst fully maintaining sparsity. In addition to our\nImageNet results, we also demonstrate our approach in the domain of language\nmodeling where the current best performing architectures tend to have tens of\nbillions of parameters and scaling up does not yet seem to have saturated\nperformance. Sparse versions of these architectures can be run with\nsignificantly fewer resources, making them more widely accessible and\napplicable. Furthermore, in addition to being effective, our approach is\nstraightforward and can easily be implemented in a wide range of existing\nmachine learning frameworks with only a few additional lines of code. We\ntherefore hope that our contribution will help enable the broader community to\nexplore the potential held by massive models, without incurring massive\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 11:13:05 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jayakumar", "Siddhant M.", ""], ["Pascanu", "Razvan", ""], ["Rae", "Jack W.", ""], ["Osindero", "Simon", ""], ["Elsen", "Erich", ""]]}, {"id": "2106.03542", "submitter": "Andrew Y. K. Foong", "authors": "Andrew Y. K. Foong, Wessel P. Bruinsma, David R. Burt, Richard E.\n  Turner", "title": "How Tight Can PAC-Bayes be in the Small Data Regime?", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the question: Given a small number of\ndatapoints, for example N = 30, how tight can PAC-Bayes and test set bounds be\nmade? For such small datasets, test set bounds adversely affect generalisation\nperformance by discarding data. In this setting, PAC-Bayes bounds are\nespecially attractive, due to their ability to use all the data to\nsimultaneously learn a posterior and bound its generalisation risk. We focus on\nthe case of i.i.d. data with a bounded loss and consider the generic PAC-Bayes\ntheorem of Germain et al. (2009) and Begin et al. (2016). While their theorem\nis known to recover many existing PAC-Bayes bounds, it is unclear what the\ntightest bound derivable from their framework is. Surprisingly, we show that\nfor a fixed learning algorithm and dataset, the tightest bound of this form\ncoincides with the tightest bound of the more restrictive family of bounds\nconsidered in Catoni (2007). In contrast, in the more natural case of\ndistributions over datasets, we give examples (both analytic and numerical)\nshowing that the family of bounds in Catoni (2007) can be suboptimal. Within\nthe proof framework of Germain et al. (2009) and Begin et al. (2016), we\nestablish a lower bound on the best bound achievable in expectation, which\nrecovers the Chernoff test set bound in the case when the posterior is equal to\nthe prior. Finally, to illustrate how tight these bounds can potentially be, we\nstudy a synthetic one-dimensional classification task in which it is feasible\nto meta-learn both the prior and the form of the bound to obtain the tightest\nPAC-Bayes and test set bounds possible. We find that in this simple, controlled\nscenario, PAC-Bayes bounds are surprisingly competitive with comparable,\ncommonly used Chernoff test set bounds. However, the sharpest test set bounds\nstill lead to better guarantees on the generalisation error than the PAC-Bayes\nbounds we consider.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 12:11:32 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Foong", "Andrew Y. K.", ""], ["Bruinsma", "Wessel P.", ""], ["Burt", "David R.", ""], ["Turner", "Richard E.", ""]]}, {"id": "2106.03585", "submitter": "Mathieu Even", "authors": "Mathieu Even, Hadrien Hendrikx, Laurent Massoulie", "title": "Decentralized Optimization with Heterogeneous Delays: a Continuous-Time\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In decentralized optimization, nodes of a communication network privately\npossess a local objective function, and communicate using gossip-based methods\nin order to minimize the average of these per-node objectives. While\nsynchronous algorithms can be heavily slowed down by a few nodes and edges in\nthe graph (the straggler problem), their asynchronous counterparts lack from a\nsharp analysis taking into account heterogeneous delays in the communication\nnetwork. In this paper, we propose a novel continuous-time framework to analyze\nasynchronous algorithms, which does not require to define a global ordering of\nthe events, and allows to finely characterize the time complexity in the\npresence of (heterogeneous) delays. Using this framework, we describe a fully\nasynchronous decentralized algorithm to minimize the sum of smooth and strongly\nconvex functions. Our algorithm (DCDM, Delayed Coordinate Dual Method), based\non delayed randomized gossip communications and local computational updates,\nachieves an asynchronous speed-up: the rate of convergence is tightly\ncharacterized in terms of the eigengap of the graph weighted by local delays\nonly, instead of the global worst-case delays as in previous analyses.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:09:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Even", "Mathieu", ""], ["Hendrikx", "Hadrien", ""], ["Massoulie", "Laurent", ""]]}, {"id": "2106.03591", "submitter": "Kexuan Li", "authors": "Kexuan Li, Fangfang Wang, Ruiqi Liu, Fan Yang, Zuofeng Shang", "title": "Calibrating multi-dimensional complex ODE from noisy data via deep\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary differential equations (ODEs) are widely used to model complex\ndynamics that arises in biology, chemistry, engineering, finance, physics, etc.\nCalibration of a complicated ODE system using noisy data is generally very\ndifficult. In this work, we propose a two-stage nonparametric approach to\naddress this problem. We first extract the de-noised data and their higher\norder derivatives using boundary kernel method, and then feed them into a\nsparsely connected deep neural network with ReLU activation function. Our\nmethod is able to recover the ODE system without being subject to the curse of\ndimensionality and complicated ODE structure. When the ODE possesses a general\nmodular structure, with each modular component involving only a few input\nvariables, and the network architecture is properly chosen, our method is\nproven to be consistent. Theoretical properties are corroborated by an\nextensive simulation study that demonstrates the validity and effectiveness of\nthe proposed method. Finally, we use our method to simultaneously characterize\nthe growth rate of Covid-19 infection cases from 50 states of the USA.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:17:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Li", "Kexuan", ""], ["Wang", "Fangfang", ""], ["Liu", "Ruiqi", ""], ["Yang", "Fan", ""], ["Shang", "Zuofeng", ""]]}, {"id": "2106.03632", "submitter": "Guojun Zhang", "authors": "Guojun Zhang, Han Zhao, Yaoliang Yu, Pascal Poupart", "title": "Quantifying and Improving Transferability in Domain Generalization", "comments": "36 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-distribution generalization is one of the key challenges when\ntransferring a model from the lab to the real world. Existing efforts mostly\nfocus on building invariant features among source and target domains. Based on\ninvariant features, a high-performing classifier on source domains could\nhopefully behave equally well on a target domain. In other words, the invariant\nfeatures are \\emph{transferable}. However, in practice, there are no perfectly\ntransferable features, and some algorithms seem to learn ''more transferable''\nfeatures than others. How can we understand and quantify such\n\\emph{transferability}? In this paper, we formally define transferability that\none can quantify and compute in domain generalization. We point out the\ndifference and connection with common discrepancy measures between domains,\nsuch as total variation and Wasserstein distance. We then prove that our\ntransferability can be estimated with enough samples and give a new upper bound\nfor the target error based on our transferability. Empirically, we evaluate the\ntransferability of the feature embeddings learned by existing algorithms for\ndomain generalization. Surprisingly, we find that many algorithms are not quite\nlearning transferable features, although few could still survive. In light of\nthis, we propose a new algorithm for learning transferable features and test it\nover various benchmark datasets, including RotatedMNIST, PACS, Office-Home and\nWILDS-FMoW. Experimental results show that the proposed algorithm achieves\nconsistent improvement over many state-of-the-art algorithms, corroborating our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 14:04:32 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Guojun", ""], ["Zhao", "Han", ""], ["Yu", "Yaoliang", ""], ["Poupart", "Pascal", ""]]}, {"id": "2106.03640", "submitter": "Dominic Masters", "authors": "Dominic Masters, Antoine Labatie, Zach Eaton-Rosen and Carlo Luschi", "title": "Making EfficientNet More Efficient: Exploring Batch-Independent\n  Normalization, Group Convolutions and Reduced Resolution Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Much recent research has been dedicated to improving the efficiency of\ntraining and inference for image classification. This effort has commonly\nfocused on explicitly improving theoretical efficiency, often measured as\nImageNet validation accuracy per FLOP. These theoretical savings have, however,\nproven challenging to achieve in practice, particularly on high-performance\ntraining accelerators.\n  In this work, we focus on improving the practical efficiency of the\nstate-of-the-art EfficientNet models on a new class of accelerator, the\nGraphcore IPU. We do this by extending this family of models in the following\nways: (i) generalising depthwise convolutions to group convolutions; (ii)\nadding proxy-normalized activations to match batch normalization performance\nwith batch-independent statistics; (iii) reducing compute by lowering the\ntraining resolution and inexpensively fine-tuning at higher resolution. We find\nthat these three methods improve the practical efficiency for both training and\ninference. Our code will be made available online.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 14:10:52 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 14:10:55 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 08:50:21 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Masters", "Dominic", ""], ["Labatie", "Antoine", ""], ["Eaton-Rosen", "Zach", ""], ["Luschi", "Carlo", ""]]}, {"id": "2106.03676", "submitter": "Sonja Petrovic", "authors": "Jelena Mojsilovi\\'c, Dylan Peifer, Sonja Petrovi\\'c", "title": "Learning a performance metric of Buchberger's algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC cs.LG cs.SC math.AG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  What can be (machine) learned about the complexity of Buchberger's algorithm?\n  Given a system of polynomials, Buchberger's algorithm computes a Gr\\\"obner\nbasis of the ideal these polynomials generate using an iterative procedure\nbased on multivariate long division. The runtime of each step of the algorithm\nis typically dominated by a series of polynomial additions, and the total\nnumber of these additions is a hardware independent performance metric that is\noften used to evaluate and optimize various implementation choices. In this\nwork we attempt to predict, using just the starting input, the number of\npolynomial additions that take place during one run of Buchberger's algorithm.\nGood predictions are useful for quickly estimating difficulty and understanding\nwhat features make Gr\\\"obner basis computation hard. Our features and methods\ncould also be used for value models in the reinforcement learning approach to\noptimize Buchberger's algorithm introduced in [Peifer, Stillman, and\nHalpern-Leistner, 2020].\n  We show that a multiple linear regression model built from a set of\neasy-to-compute ideal generator statistics can predict the number of polynomial\nadditions somewhat well, better than an uninformed model, and better than\nregression models built on some intuitive commutative algebra invariants that\nare more difficult to compute. We also train a simple recursive neural network\nthat outperforms these linear models. Our work serves as a proof of concept,\ndemonstrating that predicting the number of polynomial additions in\nBuchberger's algorithm is a feasible problem from the point of view of machine\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 14:57:57 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mojsilovi\u0107", "Jelena", ""], ["Peifer", "Dylan", ""], ["Petrovi\u0107", "Sonja", ""]]}, {"id": "2106.03686", "submitter": "Udaya Sampath Karunathilaka Perera Miriya Thanthrige", "authors": "Udaya S.K.P. Miriya Thanthrige, Peter Jung, and Aydin Sezgin", "title": "Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the detection of material defects, which are inside a layered\nmaterial structure using compressive sensing based multiple-input and\nmultiple-output (MIMO) wireless radar. Here, the strong clutter due to the\nreflection of the layered structure's surface often makes the detection of the\ndefects challenging. Thus, sophisticated signal separation methods are required\nfor improved defect detection. In many scenarios, the number of defects that we\nare interested in is limited and the signaling response of the layered\nstructure can be modeled as a low-rank structure. Therefore, we propose joint\nrank and sparsity minimization for defect detection. In particular, we propose\na non-convex approach based on the iteratively reweighted nuclear and\n$\\ell_1-$norm (a double-reweighted approach) to obtain a higher accuracy\ncompared to the conventional nuclear norm and $\\ell_1-$norm minimization. To\nthis end, an iterative algorithm is designed to estimate the low-rank and\nsparse contributions. Further, we propose deep learning to learn the parameters\nof the algorithm (i.e., algorithm unfolding) to improve the accuracy and the\nspeed of convergence of the algorithm. Our numerical results show that the\nproposed approach outperforms the conventional approaches in terms of mean\nsquare errors of the recovered low-rank and sparse components and the speed of\nconvergence.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 15:00:33 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 19:42:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Thanthrige", "Udaya S. K. P. Miriya", ""], ["Jung", "Peter", ""], ["Sezgin", "Aydin", ""]]}, {"id": "2106.03696", "submitter": "Courtney Paquette", "authors": "Courtney Paquette, Elliot Paquette", "title": "Dynamics of Stochastic Momentum Methods on Large-scale, Quadratic Models", "comments": "39 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a class of stochastic gradient algorithms with momentum on a\nhigh-dimensional random least squares problem. Our framework, inspired by\nrandom matrix theory, provides an exact (deterministic) characterization for\nthe sequence of loss values produced by these algorithms which is expressed\nonly in terms of the eigenvalues of the Hessian. This leads to simple\nexpressions for nearly-optimal hyperparameters, a description of the limiting\nneighborhood, and average-case complexity.\n  As a consequence, we show that (small-batch) stochastic heavy-ball momentum\nwith a fixed momentum parameter provides no actual performance improvement over\nSGD when step sizes are adjusted correctly. For contrast, in the non-strongly\nconvex setting, it is possible to get a large improvement over SGD using\nmomentum. By introducing hyperparameters that depend on the number of samples,\nwe propose a new algorithm sDANA (stochastic dimension adjusted Nesterov\nacceleration) which obtains an asymptotically optimal average-case complexity\nwhile remaining linearly convergent in the strongly convex setting without\nadjusting parameters.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 15:08:24 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Paquette", "Courtney", ""], ["Paquette", "Elliot", ""]]}, {"id": "2106.03702", "submitter": "Edgardo Solano Carrillo", "authors": "Edgardo Solano-Carrillo", "title": "Can a single neuron learn quantiles?", "comments": "20 pages (10 of contents + 10 of supplementary material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A novel non-parametric quantile estimation method for continuous random\nvariables is introduced, based on a minimal neural network architecture\nconsisting of a single unit. Its advantage over estimations from ranking the\norder statistics is shown, specifically for small sample size. In a regression\ncontext, the method can be used to quantify predictive uncertainty under the\nsplit conformal prediction setting, where prediction intervals are estimated\nfrom the residuals of a pre-trained model on a held-out validation set to\nquantify the uncertainty in future predictions. Benchmarking experiments\ndemonstrate that the method is competitive in quality and coverage with\nstate-of-the-art solutions, with the added benefit of being more\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 15:12:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Solano-Carrillo", "Edgardo", ""]]}, {"id": "2106.03743", "submitter": "Antoine Labatie", "authors": "Antoine Labatie, Dominic Masters, Zach Eaton-Rosen, Carlo Luschi", "title": "Proxy-Normalizing Activations to Match Batch Normalization while\n  Removing Batch Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We investigate the reasons for the performance degradation incurred with\nbatch-independent normalization. We find that the prototypical techniques of\nlayer normalization and instance normalization both induce the appearance of\nfailure modes in the neural network's pre-activations: (i) layer normalization\ninduces a collapse towards channel-wise constant functions; (ii) instance\nnormalization induces a lack of variability in instance statistics, symptomatic\nof an alteration of the expressivity. To alleviate failure mode (i) without\naggravating failure mode (ii), we introduce the technique \"Proxy Normalization\"\nthat normalizes post-activations using a proxy distribution. When combined with\nlayer normalization or group normalization, this batch-independent\nnormalization emulates batch normalization's behavior and consistently matches\nor exceeds its performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:08:48 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 13:50:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Labatie", "Antoine", ""], ["Masters", "Dominic", ""], ["Eaton-Rosen", "Zach", ""], ["Luschi", "Carlo", ""]]}, {"id": "2106.03747", "submitter": "Jonas M. K\\\"ubler", "authors": "Jonas M. K\\\"ubler, Simon Buchholz, Bernhard Sch\\\"olkopf", "title": "The Inductive Bias of Quantum Kernels", "comments": "Code available upon request", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been hypothesized that quantum computers may lend themselves well to\napplications in machine learning. In the present work, we analyze function\nclasses defined via quantum kernels. Quantum computers offer the possibility to\nefficiently compute inner products of exponentially large density operators\nthat are classically hard to compute. However, having an exponentially large\nfeature space renders the problem of generalization hard. Furthermore, being\nable to evaluate inner products in high dimensional spaces efficiently by\nitself does not guarantee a quantum advantage, as already classically tractable\nkernels can correspond to high- or infinite-dimensional reproducing kernel\nHilbert spaces (RKHS).\n  We analyze the spectral properties of quantum kernels and find that we can\nexpect an advantage if their RKHS is low dimensional and contains functions\nthat are hard to compute classically. If the target function is known to lie in\nthis class, this implies a quantum advantage, as the quantum computer can\nencode this inductive bias, whereas there is no classically efficient way to\nconstrain the function class in the same way. However, we show that finding\nsuitable quantum kernels is not easy because the kernel evaluation might\nrequire exponentially many measurements.\n  In conclusion, our message is a somewhat sobering one: we conjecture that\nquantum machine learning models can offer speed-ups only if we manage to encode\nknowledge about the problem at hand into quantum circuits, while encoding the\nsame bias into a classical model would be hard. These situations may plausibly\noccur when learning on data generated by a quantum process, however, they\nappear to be harder to come by for classical datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:14:32 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["K\u00fcbler", "Jonas M.", ""], ["Buchholz", "Simon", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2106.03748", "submitter": "William Guss", "authors": "William Hebgen Guss, Stephanie Milani, Nicholay Topin, Brandon\n  Houghton, Sharada Mohanty, Andrew Melnik, Augustin Harter, Benoit Buschmaas,\n  Bjarne Jaster, Christoph Berganski, Dennis Heitkamp, Marko Henning, Helge\n  Ritter, Chengjie Wu, Xiaotian Hao, Yiming Lu, Hangyu Mao, Yihuan Mao, Chao\n  Wang, Michal Opanowicz, Anssi Kanervisto, Yanick Schraner, Christian\n  Scheller, Xiren Zhou, Lu Liu, Daichi Nishio, Toi Tsuneda, Karolis\n  Ramanauskas, Gabija Juceviciute", "title": "Towards robust and domain agnostic reinforcement learning competitions", "comments": "20 pages, several figures, published PMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning competitions have formed the basis for standard\nresearch benchmarks, galvanized advances in the state-of-the-art, and shaped\nthe direction of the field. Despite this, a majority of challenges suffer from\nthe same fundamental problems: participant solutions to the posed challenge are\nusually domain-specific, biased to maximally exploit compute resources, and not\nguaranteed to be reproducible. In this paper, we present a new framework of\ncompetition design that promotes the development of algorithms that overcome\nthese barriers. We propose four central mechanisms for achieving this end:\nsubmission retraining, domain randomization, desemantization through domain\nobfuscation, and the limitation of competition compute and environment-sample\nbudget. To demonstrate the efficacy of this design, we proposed, organized, and\nran the MineRL 2020 Competition on Sample-Efficient Reinforcement Learning. In\nthis work, we describe the organizational outcomes of the competition and show\nthat the resulting participant submissions are reproducible, non-specific to\nthe competition environment, and sample/resource efficient, despite the\ndifficult competition task.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:15:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Guss", "William Hebgen", ""], ["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Houghton", "Brandon", ""], ["Mohanty", "Sharada", ""], ["Melnik", "Andrew", ""], ["Harter", "Augustin", ""], ["Buschmaas", "Benoit", ""], ["Jaster", "Bjarne", ""], ["Berganski", "Christoph", ""], ["Heitkamp", "Dennis", ""], ["Henning", "Marko", ""], ["Ritter", "Helge", ""], ["Wu", "Chengjie", ""], ["Hao", "Xiaotian", ""], ["Lu", "Yiming", ""], ["Mao", "Hangyu", ""], ["Mao", "Yihuan", ""], ["Wang", "Chao", ""], ["Opanowicz", "Michal", ""], ["Kanervisto", "Anssi", ""], ["Schraner", "Yanick", ""], ["Scheller", "Christian", ""], ["Zhou", "Xiren", ""], ["Liu", "Lu", ""], ["Nishio", "Daichi", ""], ["Tsuneda", "Toi", ""], ["Ramanauskas", "Karolis", ""], ["Juceviciute", "Gabija", ""]]}, {"id": "2106.03755", "submitter": "Hankui Peng", "authors": "Hankui Peng, Angelica I. Aviles-Rivero, Carola-Bibiane Schonlieb", "title": "HERS Superpixels: Deep Affinity Learning for Hierarchical Entropy Rate\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Superpixels serve as a powerful preprocessing tool in many computer vision\ntasks. By using superpixel representation, the number of image primitives can\nbe largely reduced by orders of magnitudes. The majority of superpixel methods\nuse handcrafted features, which usually do not translate well into strong\nadherence to object boundaries. A few recent superpixel methods have introduced\ndeep learning into the superpixel segmentation process. However, none of these\nmethods is able to produce superpixels in near real-time, which is crucial to\nthe applicability of a superpixel method in practice. In this work, we propose\na two-stage graph-based framework for superpixel segmentation. In the first\nstage, we introduce an efficient Deep Affinity Learning (DAL) network that\nlearns pairwise pixel affinities by aggregating multi-scale information. In the\nsecond stage, we propose a highly efficient superpixel method called\nHierarchical Entropy Rate Segmentation (HERS). Using the learned affinities\nfrom the first stage, HERS builds a hierarchical tree structure that can\nproduce any number of highly adaptive superpixels instantaneously. We\ndemonstrate, through visual and numerical experiments, the effectiveness and\nefficiency of our method compared to various state-of-the-art superpixel\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:20:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Peng", "Hankui", ""], ["Aviles-Rivero", "Angelica I.", ""], ["Schonlieb", "Carola-Bibiane", ""]]}, {"id": "2106.03760", "submitter": "Hussein Hazimeh", "authors": "Hussein Hazimeh, Zhe Zhao, Aakanksha Chowdhery, Maheswaran\n  Sathiamoorthy, Yihua Chen, Rahul Mazumder, Lichan Hong, Ed H. Chi", "title": "DSelect-k: Differentiable Selection in the Mixture of Experts with\n  Applications to Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mixture-of-experts (MoE) architecture is showing promising results in\nmulti-task learning (MTL) and in scaling high-capacity neural networks.\nState-of-the-art MoE models use a trainable sparse gate to select a subset of\nthe experts for each input example. While conceptually appealing, existing\nsparse gates, such as Top-k, are not smooth. The lack of smoothness can lead to\nconvergence and statistical performance issues when training with\ngradient-based methods. In this paper, we develop DSelect-k: the first,\ncontinuously differentiable and sparse gate for MoE, based on a novel binary\nencoding formulation. Our gate can be trained using first-order methods, such\nas stochastic gradient descent, and offers explicit control over the number of\nexperts to select. We demonstrate the effectiveness of DSelect-k in the context\nof MTL, on both synthetic and real datasets with up to 128 tasks. Our\nexperiments indicate that MoE models based on DSelect-k can achieve\nstatistically significant improvements in predictive and expert selection\nperformance. Notably, on a real-world large-scale recommender system, DSelect-k\nachieves over 22% average improvement in predictive performance compared to the\nTop-k gate. We provide an open-source TensorFlow implementation of our gate.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:25:27 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 15:25:04 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Hazimeh", "Hussein", ""], ["Zhao", "Zhe", ""], ["Chowdhery", "Aakanksha", ""], ["Sathiamoorthy", "Maheswaran", ""], ["Chen", "Yihua", ""], ["Mazumder", "Rahul", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""]]}, {"id": "2106.03761", "submitter": "Tiago Salvador", "authors": "Tiago Salvador, Stephanie Cairns, Vikram Voleti, Noah Marshall, Adam\n  Oberman", "title": "Bias Mitigation of Face Recognition Models Through Calibration", "comments": "22 pages, 20 tables, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition models suffer from bias: for example, the probability of a\nfalse positive (incorrect face match) strongly depends on sensitive attributes\nlike ethnicity. As a result, these models may disproportionately and negatively\nimpact minority groups when used in law enforcement. In this work, we introduce\nthe Bias Mitigation Calibration (BMC) method, which (i) increases model\naccuracy (improving the state-of-the-art), (ii) produces fairly-calibrated\nprobabilities, (iii) significantly reduces the gap in the false positive rates,\nand (iv) does not require knowledge of the sensitive attribute.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:26:26 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Salvador", "Tiago", ""], ["Cairns", "Stephanie", ""], ["Voleti", "Vikram", ""], ["Marshall", "Noah", ""], ["Oberman", "Adam", ""]]}, {"id": "2106.03762", "submitter": "Tiago Salvador", "authors": "Tiago Salvador, Vikram Voleti, Alexander Iannantuono, Adam Oberman", "title": "Improved Predictive Uncertainty using Corruption-based Calibration", "comments": "21 pages, 6 Tables, 17 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple post hoc calibration method to estimate the\nconfidence/uncertainty that a model prediction is correct on data with\ncovariate shift, as represented by the large-scale corrupted data benchmark\n[Ovadia et al, 2019]. We achieve this by synthesizing surrogate calibration\nsets by corrupting the calibration set with varying intensities of a known\ncorruption. Our method demonstrates significant improvements on the benchmark\non a wide range of covariate shifts.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:27:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Salvador", "Tiago", ""], ["Voleti", "Vikram", ""], ["Iannantuono", "Alexander", ""], ["Oberman", "Adam", ""]]}, {"id": "2106.03765", "submitter": "Alicia Curth", "authors": "Alicia Curth and Mihaela van der Schaar", "title": "On Inductive Biases for Heterogeneous Treatment Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how to exploit structural similarities of an individual's\npotential outcomes (POs) under different treatments to obtain better estimates\nof conditional average treatment effects in finite samples. Especially when it\nis unknown whether a treatment has an effect at all, it is natural to\nhypothesize that the POs are similar - yet, some existing strategies for\ntreatment effect estimation employ regularization schemes that implicitly\nencourage heterogeneity even when it does not exist and fail to fully make use\nof shared structure. In this paper, we investigate and compare three end-to-end\nlearning strategies to overcome this problem - based on regularization,\nreparametrization and a flexible multi-task architecture - each encoding\ninductive bias favoring shared behavior across POs. To build understanding of\ntheir relative strengths, we implement all strategies using neural networks and\nconduct a wide range of semi-synthetic experiments. We observe that all three\napproaches can lead to substantial improvements upon numerous baselines and\ngain insight into performance differences across various experimental settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:30:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Curth", "Alicia", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2106.03790", "submitter": "Ningyuan Chen", "authors": "Ningyuan Chen", "title": "Multi-armed Bandit Requiring Monotone Arm Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many online learning or multi-armed bandit problems, the taken actions or\npulled arms are ordinal and required to be monotone over time. Examples include\ndynamic pricing, in which the firms use markup pricing policies to please early\nadopters and deter strategic waiting, and clinical trials, in which the dose\nallocation usually follows the dose escalation principle to prevent dose\nlimiting toxicities. We consider the continuum-armed bandit problem when the\narm sequence is required to be monotone. We show that when the unknown\nobjective function is Lipschitz continuous, the regret is $O(T)$. When in\naddition the objective function is unimodal or quasiconcave, the regret is\n$\\tilde O(T^{3/4})$ under the proposed algorithm, which is also shown to be the\noptimal rate. This deviates from the optimal rate $\\tilde O(T^{2/3})$ in the\ncontinuous-armed bandit literature and demonstrates the cost to the learning\nefficiency brought by the monotonicity requirement.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:53:05 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 19:52:14 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Chen", "Ningyuan", ""]]}, {"id": "2106.03791", "submitter": "Gabriele Sicuro", "authors": "Bruno Loureiro, Gabriele Sicuro, C\\'edric Gerbelot, Alessandro Pacco,\n  Florent Krzakala, Lenka Zdeborov\\'a", "title": "Learning Gaussian Mixtures with Generalised Linear Models: Precise\n  Asymptotics in High-dimensions", "comments": "12 pages + 34 pages of Appendix, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalised linear models for multi-class classification problems are one of\nthe fundamental building blocks of modern machine learning tasks. In this\nmanuscript, we characterise the learning of a mixture of $K$ Gaussians with\ngeneric means and covariances via empirical risk minimisation (ERM) with any\nconvex loss and regularisation. In particular, we prove exact asymptotics\ncharacterising the ERM estimator in high-dimensions, extending several previous\nresults about Gaussian mixture classification in the literature. We exemplify\nour result in two tasks of interest in statistical learning: a) classification\nfor a mixture with sparse means, where we study the efficiency of $\\ell_1$\npenalty with respect to $\\ell_2$; b) max-margin multi-class classification,\nwhere we characterise the phase transition on the existence of the multi-class\nlogistic maximum likelihood estimator for $K>2$. Finally, we discuss how our\ntheory can be applied beyond the scope of synthetic data, showing that in\ndifferent cases Gaussian mixtures capture closely the learning curve of\nclassification tasks in real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:53:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Loureiro", "Bruno", ""], ["Sicuro", "Gabriele", ""], ["Gerbelot", "C\u00e9dric", ""], ["Pacco", "Alessandro", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2106.03795", "submitter": "Melih Barsbey", "authors": "Melih Barsbey, Milad Sefidgaran, Murat A. Erdogdu, Ga\\\"el Richard,\n  Umut \\c{S}im\\c{s}ekli", "title": "Heavy Tails in SGD and Compressibility of Overparametrized Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network compression techniques have become increasingly popular as\nthey can drastically reduce the storage and computation requirements for very\nlarge networks. Recent empirical studies have illustrated that even simple\npruning strategies can be surprisingly effective, and several theoretical\nstudies have shown that compressible networks (in specific senses) should\nachieve a low generalization error. Yet, a theoretical characterization of the\nunderlying cause that makes the networks amenable to such simple compression\nschemes is still missing. In this study, we address this fundamental question\nand reveal that the dynamics of the training algorithm has a key role in\nobtaining such compressible networks. Focusing our attention on stochastic\ngradient descent (SGD), our main contribution is to link compressibility to two\nrecently established properties of SGD: (i) as the network size goes to\ninfinity, the system can converge to a mean-field limit, where the network\nweights behave independently, (ii) for a large step-size/batch-size ratio, the\nSGD iterates can converge to a heavy-tailed stationary distribution. In the\ncase where these two phenomena occur simultaneously, we prove that the networks\nare guaranteed to be '$\\ell_p$-compressible', and the compression errors of\ndifferent pruning techniques (magnitude, singular value, or node pruning)\nbecome arbitrarily small as the network size increases. We further prove\ngeneralization bounds adapted to our theoretical framework, which indeed\nconfirm that the generalization error will be lower for more compressible\nnetworks. Our theory and numerical study on various neural networks show that\nlarge step-size/batch-size ratios introduce heavy-tails, which, in combination\nwith overparametrization, result in compressibility.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:02:59 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Barsbey", "Melih", ""], ["Sefidgaran", "Milad", ""], ["Erdogdu", "Murat A.", ""], ["Richard", "Ga\u00ebl", ""], ["\u015eim\u015fekli", "Umut", ""]]}, {"id": "2106.03805", "submitter": "Andrew Ilyas", "authors": "Guillaume Leclerc, Hadi Salman, Andrew Ilyas, Sai Vemprala, Logan\n  Engstrom, Vibhav Vineet, Kai Xiao, Pengchuan Zhang, Shibani Santurkar, Greg\n  Yang, Ashish Kapoor, Aleksander Madry", "title": "3DB: A Framework for Debugging Computer Vision Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce 3DB: an extendable, unified framework for testing and debugging\nvision models using photorealistic simulation. We demonstrate, through a wide\nrange of use cases, that 3DB allows users to discover vulnerabilities in\ncomputer vision systems and gain insights into how models make decisions. 3DB\ncaptures and generalizes many robustness analyses from prior work, and enables\none to study their interplay. Finally, we find that the insights generated by\nthe system transfer to the physical world.\n  We are releasing 3DB as a library (https://github.com/3db/3db) alongside a\nset of example analyses, guides, and documentation: https://3db.github.io/3db/ .\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:16:12 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Leclerc", "Guillaume", ""], ["Salman", "Hadi", ""], ["Ilyas", "Andrew", ""], ["Vemprala", "Sai", ""], ["Engstrom", "Logan", ""], ["Vineet", "Vibhav", ""], ["Xiao", "Kai", ""], ["Zhang", "Pengchuan", ""], ["Santurkar", "Shibani", ""], ["Yang", "Greg", ""], ["Kapoor", "Ashish", ""], ["Madry", "Aleksander", ""]]}, {"id": "2106.03820", "submitter": "Salim I. Amoukou", "authors": "Salim I. Amoukou, Nicolas J-B. Brunel, Tangi Sala\\\"un", "title": "Accurate and robust Shapley Values for explaining predictions and\n  focusing on local important variables", "comments": "9 pages, 4 figures, 2 tables. arXiv admin note: substantial text\n  overlap with arXiv:2103.13342", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although Shapley Values (SV) are widely used in explainable AI, they can be\npoorly understood and estimated, which implies that their analysis may lead to\nspurious inferences and explanations. As a starting point, we remind an\ninvariance principle for SV and derive the correct approach for computing the\nSV of categorical variables that are particularly sensitive to the encoding\nused. In the case of tree-based models, we introduce two estimators of Shapley\nValues that exploit efficiently the tree structure and are more accurate than\nstate-of-the-art methods. For interpreting additive explanations, we recommend\nto filter the non-influential variables and to compute the Shapley Values only\nfor groups of influential variables. For this purpose, we use the concept of\n\"Same Decision Probability\" (SDP) that evaluates the robustness of a prediction\nwhen some variables are missing. This prior selection procedure produces sparse\nadditive explanations easier to visualize and analyse. Simulations and\ncomparisons are performed with state-of-the-art algorithm, and show the\npractical gain of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:35:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Amoukou", "Salim I.", ""], ["Brunel", "Nicolas J-B.", ""], ["Sala\u00fcn", "Tangi", ""]]}, {"id": "2106.03823", "submitter": "Michael O'Malley", "authors": "Michael O'Malley, Adam M. Sykulski, Rick Lumpkin, Alejandro Schuler", "title": "Multivariate Probabilistic Regression with Natural Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many single-target regression problems require estimates of uncertainty along\nwith the point predictions. Probabilistic regression algorithms are well-suited\nfor these tasks. However, the options are much more limited when the prediction\ntarget is multivariate and a joint measure of uncertainty is required. For\nexample, in predicting a 2D velocity vector a joint uncertainty would quantify\nthe probability of any vector in the plane, which would be more expressive than\ntwo separate uncertainties on the x- and y- components. To enable joint\nprobabilistic regression, we propose a Natural Gradient Boosting (NGBoost)\napproach based on nonparametrically modeling the conditional parameters of the\nmultivariate predictive distribution. Our method is robust, works\nout-of-the-box without extensive tuning, is modular with respect to the assumed\ntarget distribution, and performs competitively in comparison to existing\napproaches. We demonstrate these claims in simulation and with a case study\npredicting two-dimensional oceanographic velocity data. An implementation of\nour method is available at https://github.com/stanfordmlgroup/ngboost.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:44:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["O'Malley", "Michael", ""], ["Sykulski", "Adam M.", ""], ["Lumpkin", "Rick", ""], ["Schuler", "Alejandro", ""]]}, {"id": "2106.03831", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Wenhu Chen, Michael Saxon, William Yang Wang", "title": "Counterfactual Maximum Likelihood Estimation for Training Deep Networks", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning models have driven state-of-the-art performance on a\nwide array of tasks, they are prone to learning spurious correlations that\nshould not be learned as predictive clues. To mitigate this problem, we propose\na causality-based training framework to reduce the spurious correlations caused\nby observable confounders. We give theoretical analysis on the underlying\ngeneral Structural Causal Model (SCM) and propose to perform Maximum Likelihood\nEstimation (MLE) on the interventional distribution instead of the\nobservational distribution, namely Counterfactual Maximum Likelihood Estimation\n(CMLE). As the interventional distribution, in general, is hidden from the\nobservational data, we then derive two different upper bounds of the expected\nnegative log-likelihood and propose two general algorithms, Implicit CMLE and\nExplicit CMLE, for causal predictions of deep learning models using\nobservational data. We conduct experiments on two real-world tasks: Natural\nLanguage Inference (NLI) and Image Captioning. The results show that CMLE\nmethods outperform the regular MLE method in terms of out-of-domain\ngeneralization performance and reducing spurious correlations, while\nmaintaining comparable performance on the regular evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:47:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wang", "Xinyi", ""], ["Chen", "Wenhu", ""], ["Saxon", "Michael", ""], ["Wang", "William Yang", ""]]}, {"id": "2106.03880", "submitter": "Jens Eisert", "authors": "Matthias C. Caro, Elies Gil-Fuster, Johannes Jakob Meyer, Jens Eisert,\n  Ryan Sweke", "title": "Encoding-dependent generalization bounds for parametrized quantum\n  circuits", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of recent work has begun to explore the potential of\nparametrized quantum circuits (PQCs) as machine learning models, within the\nframework of hybrid quantum-classical optimization. In particular, theoretical\nguarantees on the out-of-sample performance of such models, in terms of\ngeneralization bounds, have emerged. However, none of these generalization\nbounds depend explicitly on how the classical input data is encoded into the\nPQC. We derive generalization bounds for PQC-based models that depend\nexplicitly on the strategy used for data-encoding. These imply bounds on the\nperformance of trained PQC-based models on unseen data. Moreover, our results\nfacilitate the selection of optimal data-encoding strategies via structural\nrisk minimization, a mathematically rigorous framework for model selection. We\nobtain our generalization bounds by bounding the complexity of PQC-based models\nas measured by the Rademacher complexity and the metric entropy, two complexity\nmeasures from statistical learning theory. To achieve this, we rely on a\nrepresentation of PQC-based models via trigonometric functions. Our\ngeneralization bounds emphasize the importance of well-considered data-encoding\nstrategies for PQC-based models.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 18:01:38 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Caro", "Matthias C.", ""], ["Gil-Fuster", "Elies", ""], ["Meyer", "Johannes Jakob", ""], ["Eisert", "Jens", ""], ["Sweke", "Ryan", ""]]}, {"id": "2106.03885", "submitter": "Stefano Massaroli", "authors": "Stefano Massaroli, Michael Poli, Sho Sonoda, Taji Suzuki, Jinkyoo\n  Park, Atsushi Yamashita and Hajime Asama", "title": "Differentiable Multiple Shooting Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We detail a novel class of implicit neural models. Leveraging time-parallel\nmethods for differential equations, Multiple Shooting Layers (MSLs) seek\nsolutions of initial value problems via parallelizable root-finding algorithms.\nMSLs broadly serve as drop-in replacements for neural ordinary differential\nequations (Neural ODEs) with improved efficiency in number of function\nevaluations (NFEs) and wall-clock inference time. We develop the algorithmic\nframework of MSLs, analyzing the different choices of solution methods from a\ntheoretical and computational perspective. MSLs are showcased in long horizon\noptimal control of ODEs and PDEs and as latent models for sequence generation.\nFinally, we investigate the speedups obtained through application of MSL\ninference in neural controlled differential equations (Neural CDEs) for time\nseries classification of medical data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 18:05:44 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Massaroli", "Stefano", ""], ["Poli", "Michael", ""], ["Sonoda", "Sho", ""], ["Suzuki", "Taji", ""], ["Park", "Jinkyoo", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""]]}, {"id": "2106.03907", "submitter": "Liyuan Xu", "authors": "Liyuan Xu, Heishiro Kanagawa, Arthur Gretton", "title": "Deep Proxy Causal Learning and its Application to Confounded Bandit\n  Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proxy causal learning (PCL) is a method for estimating the causal effect of\ntreatments on outcomes in the presence of unobserved confounding, using proxies\n(structured side information) for the confounder. This is achieved via\ntwo-stage regression: in the first stage, we model relations among the\ntreatment and proxies; in the second stage, we use this model to learn the\neffect of treatment on the outcome, given the context provided by the proxies.\nPCL guarantees recovery of the true causal effect, subject to identifiability\nconditions. We propose a novel method for PCL, the deep feature proxy variable\nmethod (DFPV), to address the case where the proxies, treatments, and outcomes\nare high-dimensional and have nonlinear complex relationships, as represented\nby deep neural network features. We show that DFPV outperforms recent\nstate-of-the-art PCL methods on challenging synthetic benchmarks, including\nsettings involving high dimensional image data. Furthermore, we show that PCL\ncan be applied to off-policy evaluation for the confounded bandit problem, in\nwhich DFPV also exhibits competitive performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 18:36:13 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Xu", "Liyuan", ""], ["Kanagawa", "Heishiro", ""], ["Gretton", "Arthur", ""]]}, {"id": "2106.03922", "submitter": "Stefano Teso", "authors": "Stefano Teso, Andrea Bontempelli, Fausto Giunchiglia, Andrea Passerini", "title": "Interactive Label Cleaning with Example-based Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle sequential learning under label noise in applications where a human\nsupervisor can be queried to relabel suspicious examples. Existing approaches\nare flawed, in that they only relabel incoming examples that look\n``suspicious'' to the model. As a consequence, those mislabeled examples that\nelude (or don't undergo) this cleaning step end up tainting the training data\nand the model with no further chance of being cleaned. We propose Cincer, a\nnovel approach that cleans both new and past data by identifying pairs of\nmutually incompatible examples. Whenever it detects a suspicious example,\nCincer identifies a counter-example in the training set that -- according to\nthe model -- is maximally incompatible with the suspicious example, and asks\nthe annotator to relabel either or both examples, resolving this possible\ninconsistency. The counter-examples are chosen to be maximally incompatible, so\nto serve as explanations of the model' suspicion, and highly influential, so to\nconvey as much information as possible if relabeled. Cincer achieves this by\nleveraging an efficient and robust approximation of influence functions based\non the Fisher information matrix (FIM). Our extensive empirical evaluation\nshows that clarifying the reasons behind the model's suspicions by cleaning the\ncounter-examples helps acquiring substantially better data and models,\nespecially when paired with our FIM approximation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 19:11:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Teso", "Stefano", ""], ["Bontempelli", "Andrea", ""], ["Giunchiglia", "Fausto", ""], ["Passerini", "Andrea", ""]]}, {"id": "2106.03931", "submitter": "Argenis Arriojas", "authors": "Argenis Arriojas, Stas Tiomkin and Rahul V. Kulkarni", "title": "Closed-Form Analytical Results for Maximum Entropy Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce a mapping between Maximum Entropy Reinforcement Learning (MaxEnt\nRL) and Markovian processes conditioned on rare events. In the long time limit,\nthis mapping allows us to derive analytical expressions for the optimal policy,\ndynamics and initial state distributions for the general case of stochastic\ndynamics in MaxEnt RL. We find that soft-$\\mathcal{Q}$ functions in MaxEnt RL\ncan be obtained from the Perron-Frobenius eigenvalue and the corresponding left\neigenvector of a regular, non-negative matrix derived from the underlying\nMarkov Decision Process (MDP). The results derived lead to novel algorithms for\nmodel-based and model-free MaxEnt RL, which we validate by numerical\nsimulations. The mapping established in this work opens further avenues for the\napplication of novel analytical and computational approaches to problems in\nMaxEnt RL. We make our code available at:\nhttps://github.com/argearriojas/maxent-rl-mdp-scripts\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 19:42:06 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Arriojas", "Argenis", ""], ["Tiomkin", "Stas", ""], ["Kulkarni", "Rahul V.", ""]]}, {"id": "2106.03955", "submitter": "Emmanuel Bengio", "authors": "Emmanuel Bengio, Joelle Pineau, Doina Precup", "title": "Correcting Momentum in Temporal Difference Learning", "comments": "NeurIPS Deep RL Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common optimization tool used in deep reinforcement learning is momentum,\nwhich consists in accumulating and discounting past gradients, reapplying them\nat each iteration. We argue that, unlike in supervised learning, momentum in\nTemporal Difference (TD) learning accumulates gradients that become doubly\nstale: not only does the gradient of the loss change due to parameter updates,\nthe loss itself changes due to bootstrapping. We first show that this\nphenomenon exists, and then propose a first-order correction term to momentum.\nWe show that this correction term improves sample efficiency in policy\nevaluation by correcting target value drift. An important insight of this work\nis that deep RL methods are not always best served by directly importing\ntechniques from the supervised setting.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 20:41:15 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bengio", "Emmanuel", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""]]}, {"id": "2106.03970", "submitter": "Hadi Daneshmand", "authors": "Hadi Daneshmand, Amir Joudaki, Francis Bach", "title": "Batch Normalization Orthogonalizes Representations in Deep Random\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper underlines a subtle property of batch-normalization (BN):\nSuccessive batch normalizations with random linear transformations make hidden\nrepresentations increasingly orthogonal across layers of a deep neural network.\nWe establish a non-asymptotic characterization of the interplay between depth,\nwidth, and the orthogonality of deep representations. More precisely, under a\nmild assumption, we prove that the deviation of the representations from\northogonality rapidly decays with depth up to a term inversely proportional to\nthe network width. This result has two main implications: 1) Theoretically, as\nthe depth grows, the distribution of the representation -- after the linear\nlayers -- contracts to a Wasserstein-2 ball around an isotropic Gaussian\ndistribution. Furthermore, the radius of this Wasserstein ball shrinks with the\nwidth of the network. 2) In practice, the orthogonality of the representations\ndirectly influences the performance of stochastic gradient descent (SGD). When\nrepresentations are initially aligned, we observe SGD wastes many iterations to\northogonalize representations before the classification. Nevertheless, we\nexperimentally show that starting optimization from orthogonal representations\nis sufficient to accelerate SGD, with no need for BN.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 21:14:59 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Daneshmand", "Hadi", ""], ["Joudaki", "Amir", ""], ["Bach", "Francis", ""]]}, {"id": "2106.04013", "submitter": "Mufan (Bill) Li", "authors": "Mufan Bill Li, Mihai Nica, Daniel M. Roy", "title": "The Future is Log-Gaussian: ResNets and Their Infinite-Depth-and-Width\n  Limit at Initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical results show that neural networks can be approximated by Gaussian\nprocesses in the infinite-width limit. However, for fully connected networks,\nit has been previously shown that for any fixed network width, $n$, the\nGaussian approximation gets worse as the network depth, $d$, increases. Given\nthat modern networks are deep, this raises the question of how well modern\narchitectures, like ResNets, are captured by the infinite-width limit. To\nprovide a better approximation, we study ReLU ResNets in the\ninfinite-depth-and-width limit, where both depth and width tend to infinity as\ntheir ratio, $d/n$, remains constant. In contrast to the Gaussian\ninfinite-width limit, we show theoretically that the network exhibits\nlog-Gaussian behaviour at initialization in the infinite-depth-and-width limit,\nwith parameters depending on the ratio $d/n$. Using Monte Carlo simulations, we\ndemonstrate that even basic properties of standard ResNet architectures are\npoorly captured by the Gaussian limit, but remarkably well captured by our\nlog-Gaussian limit. Moreover, our analysis reveals that ReLU ResNets at\ninitialization are hypoactivated: fewer than half of the ReLUs are activated.\nAdditionally, we calculate the interlayer correlations, which have the effect\nof exponentially increasing the variance of the network output. Based on our\nanalysis, we introduce Balanced ResNets, a simple architecture modification,\nwhich eliminates hypoactivation and interlayer correlations and is more\namenable to theoretical analysis.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 23:47:37 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Li", "Mufan Bill", ""], ["Nica", "Mihai", ""], ["Roy", "Daniel M.", ""]]}, {"id": "2106.04018", "submitter": "Adam B. Block", "authors": "Adam Block, Zeyu Jia, Yury Polyanskiy, and Alexander Rakhlin", "title": "Intrinsic Dimension Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has long been thought that high-dimensional data encountered in many\npractical machine learning tasks have low-dimensional structure, i.e., the\nmanifold hypothesis holds. A natural question, thus, is to estimate the\nintrinsic dimension of a given population distribution from a finite sample. We\nintroduce a new estimator of the intrinsic dimension and provide finite sample,\nnon-asymptotic guarantees. We then apply our techniques to get new sample\ncomplexity bounds for Generative Adversarial Networks (GANs) depending only on\nthe intrinsic dimension of the data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 00:05:39 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Block", "Adam", ""], ["Jia", "Zeyu", ""], ["Polyanskiy", "Yury", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "2106.04096", "submitter": "Semih Cayci", "authors": "Semih Cayci, Niao He, R. Srikant", "title": "Linear Convergence of Entropy-Regularized Natural Policy Gradient with\n  Linear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural policy gradient (NPG) methods with function approximation achieve\nimpressive empirical success in reinforcement learning problems with large\nstate-action spaces. However, theoretical understanding of their convergence\nbehaviors remains limited in the function approximation setting. In this paper,\nwe perform a finite-time analysis of NPG with linear function approximation and\nsoftmax parameterization, and prove for the first time that widely used entropy\nregularization method, which encourages exploration, leads to linear\nconvergence rate. We adopt a Lyapunov drift analysis to prove the convergence\nresults and explain the effectiveness of entropy regularization in improving\nthe convergence rates.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 04:30:39 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Cayci", "Semih", ""], ["He", "Niao", ""], ["Srikant", "R.", ""]]}, {"id": "2106.04110", "submitter": "Gadi Naveh", "authors": "Gadi Naveh and Zohar Ringel", "title": "A self consistent theory of Gaussian Processes captures feature learning\n  effects in finite CNNs", "comments": "9 pages of main text, 23 pages of appendices, 5 figures total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) in the infinite width/channel limit have received\nmuch attention recently, as they provide a clear analytical window to deep\nlearning via mappings to Gaussian Processes (GPs). Despite its theoretical\nappeal, this viewpoint lacks a crucial ingredient of deep learning in finite\nDNNs, laying at the heart of their success -- feature learning. Here we\nconsider DNNs trained with noisy gradient descent on a large training set and\nderive a self consistent Gaussian Process theory accounting for strong\nfinite-DNN and feature learning effects. Applying this to a toy model of a\ntwo-layer linear convolutional neural network (CNN) shows good agreement with\nexperiments. We further identify, both analytical and numerically, a sharp\ntransition between a feature learning regime and a lazy learning regime in this\nmodel. Strong finite-DNN effects are also derived for a non-linear two-layer\nfully connected network. Our self consistent theory provides a rich and\nversatile analytical framework for studying feature learning and other non-lazy\neffects in finite DNNs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 05:20:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Naveh", "Gadi", ""], ["Ringel", "Zohar", ""]]}, {"id": "2106.04145", "submitter": "Laetitia Chapel", "authors": "Laetitia Chapel, R\\'emi Flamary, Haoran Wu, C\\'edric F\\'evotte and\n  Gilles Gasso", "title": "Unbalanced Optimal Transport through Non-negative Penalized Linear\n  Regression", "comments": "Laetitia Chapel and R\\'emi Flamary have equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of Unbalanced Optimal Transport (UOT) in\nwhich the marginal conditions are relaxed (using weighted penalties in lieu of\nequality) and no additional regularization is enforced on the OT plan. In this\ncontext, we show that the corresponding optimization problem can be\nreformulated as a non-negative penalized linear regression problem. This\nreformulation allows us to propose novel algorithms inspired from inverse\nproblems and nonnegative matrix factorization. In particular, we consider\nmajorization-minimization which leads in our setting to efficient\nmultiplicative updates for a variety of penalties. Furthermore, we derive for\nthe first time an efficient algorithm to compute the regularization path of UOT\nwith quadratic penalties. The proposed algorithm provides a continuity of\npiece-wise linear OT plans converging to the solution of balanced OT\n(corresponding to infinite penalty weights). We perform several numerical\nexperiments on simulated and real data illustrating the new algorithms, and\nprovide a detailed discussion about more sophisticated optimization tools that\ncan further be used to solve OT problems thanks to our reformulation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 07:16:37 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chapel", "Laetitia", ""], ["Flamary", "R\u00e9mi", ""], ["Wu", "Haoran", ""], ["F\u00e9votte", "C\u00e9dric", ""], ["Gasso", "Gilles", ""]]}, {"id": "2106.04156", "submitter": "Jeff Z. HaoChen", "authors": "Jeff Z. HaoChen, Colin Wei, Adrien Gaidon, Tengyu Ma", "title": "Provable Guarantees for Self-Supervised Deep Learning with Spectral\n  Contrastive Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in self-supervised learning have advanced the state-of-the-art\nby relying on the contrastive learning paradigm, which learns representations\nby pushing positive pairs, or similar examples from the same class, closer\ntogether while keeping negative pairs far apart. Despite the empirical\nsuccesses, theoretical foundations are limited -- prior analyses assume\nconditional independence of the positive pairs given the same class label, but\nrecent empirical applications use heavily correlated positive pairs (i.e., data\naugmentations of the same image). Our work analyzes contrastive learning\nwithout assuming conditional independence of positive pairs using a novel\nconcept of the augmentation graph on data. Edges in this graph connect\naugmentations of the same data, and ground-truth classes naturally form\nconnected sub-graphs. We propose a loss that performs spectral decomposition on\nthe population augmentation graph and can be succinctly written as a\ncontrastive learning objective on neural net representations. Minimizing this\nobjective leads to features with provable accuracy guarantees under linear\nprobe evaluation. By standard generalization bounds, these accuracy guarantees\nalso hold when minimizing the training contrastive loss. Empirically, the\nfeatures learned by our objective can match or outperform several strong\nbaselines on benchmark vision datasets. In all, this work provides the first\nprovable analysis for contrastive learning where guarantees for linear probe\nevaluation can apply to realistic empirical settings.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 07:41:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 01:25:06 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 07:39:31 GMT"}, {"version": "v4", "created": "Wed, 28 Jul 2021 18:49:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["HaoChen", "Jeff Z.", ""], ["Wei", "Colin", ""], ["Gaidon", "Adrien", ""], ["Ma", "Tengyu", ""]]}, {"id": "2106.04170", "submitter": "Tiangang Cui", "authors": "Tiangang Cui and Sergey Dolgov and Olivier Zahm", "title": "Conditional Deep Inverse Rosenblatt Transports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel offline-online method to mitigate the computational burden\nof the characterization of conditional beliefs in statistical learning. In the\noffline phase, the proposed method learns the joint law of the belief random\nvariables and the observational random variables in the tensor-train (TT)\nformat. In the online phase, it utilizes the resulting order-preserving\nconditional transport map to issue real-time characterization of the\nconditional beliefs given new observed information. Compared with the\nstate-of-the-art normalizing flows techniques, the proposed method relies on\nfunction approximation and is equipped with thorough performance analysis. This\nalso allows us to further extend the capability of transport maps in\nchallenging problems with high-dimensional observations and high-dimensional\nbelief variables. On the one hand, we present novel heuristics to reorder\nand/or reparametrize the variables to enhance the approximation power of TT. On\nthe other, we integrate the TT-based transport maps and the parameter\nreordering/reparametrization into layered compositions to further improve the\nperformance of the resulting transport maps. We demonstrate the efficiency of\nthe proposed method on various statistical learning tasks in ordinary\ndifferential equations (ODEs) and partial differential equations (PDEs).\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 08:23:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Cui", "Tiangang", ""], ["Dolgov", "Sergey", ""], ["Zahm", "Olivier", ""]]}, {"id": "2106.04186", "submitter": "Andreas Loukas", "authors": "Andreas Loukas, Marinos Poiitis, Stefanie Jegelka", "title": "What training reveals about neural network complexity", "comments": "31 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the hypothesis that the complexity of the function a deep\nneural network (NN) is learning can be deduced by how fast its weights change\nduring training. Our analysis provides evidence for this supposition by\nrelating the network's distribution of Lipschitz constants (i.e., the norm of\nthe gradient at different regions of the input space) during different training\nintervals with the behavior of the stochastic training procedure. We first\nobserve that the average Lipschitz constant close to the training data affects\nvarious aspects of the parameter trajectory, with more complex networks having\na longer trajectory, bigger variance, and often veering further from their\ninitialization. We then show that NNs whose biases are trained more steadily\nhave bounded complexity even in regions of the input space that are far from\nany training point. Finally, we find that steady training with Dropout implies\na training- and data-dependent generalization bound that grows\npoly-logarithmically with the number of parameters. Overall, our results\nsupport the hypothesis that good training behavior can be a useful bias towards\ngood generalization.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 08:58:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Loukas", "Andreas", ""], ["Poiitis", "Marinos", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "2106.04193", "submitter": "Louis Filstroff", "authors": "Louis Filstroff, Iiris Sundin, Petrus Mikkola, Aleksei Tiulpin, Juuso\n  Kylm\\\"aoja, Samuel Kaski", "title": "Targeted Active Learning for Bayesian Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is usually applied to acquire labels of informative data\npoints in supervised learning, to maximize accuracy in a sample-efficient way.\nHowever, maximizing the accuracy is not the end goal when the results are used\nfor decision-making, for example in personalized medicine or economics. We\nargue that when acquiring samples sequentially, separating learning and\ndecision-making is sub-optimal, and we introduce a novel active learning\nstrategy which takes the down-the-line decision problem into account.\nSpecifically, we introduce a novel active learning criterion which maximizes\nthe expected information gain on the posterior distribution of the optimal\ndecision. We compare our decision-making-aware active learning strategy to\nexisting alternatives on both simulated and real data, and show improved\nperformance in decision-making accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:05:43 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Filstroff", "Louis", ""], ["Sundin", "Iiris", ""], ["Mikkola", "Petrus", ""], ["Tiulpin", "Aleksei", ""], ["Kylm\u00e4oja", "Juuso", ""], ["Kaski", "Samuel", ""]]}, {"id": "2106.04197", "submitter": "Pengfei Xie", "authors": "Pengfei Xie, YanShu Yin, JiaGen Hou, Mei Chen and Lixin Wang", "title": "Seismic Inverse Modeling Method based on Generative Adversarial Network", "comments": "22 pages,13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Seismic inverse modeling is a common method in reservoir prediction and it\nplays a vital role in the exploration and development of oil and gas.\nConventional seismic inversion method is difficult to combine with complicated\nand abstract knowledge on geological mode and its uncertainty is difficult to\nbe assessed. The paper proposes an inversion modeling method based on GAN\nconsistent with geology, well logs, seismic data. GAN is a the most promising\ngeneration model algorithm that extracts spatial structure and abstract\nfeatures of training images. The trained GAN can reproduce the models with\nspecific mode. In our test, 1000 models were generated in 1 second. Based on\nthe trained GAN after assessment, the optimal result of models can be\ncalculated through Bayesian inversion frame. Results show that inversion models\nconform to observation data and have a low uncertainty under the premise of\nfast generation. This seismic inverse modeling method increases the efficiency\nand quality of inversion iteration. It is worthy of studying and applying in\nfusion of seismic data and geological knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:14:39 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Xie", "Pengfei", ""], ["Yin", "YanShu", ""], ["Hou", "JiaGen", ""], ["Chen", "Mei", ""], ["Wang", "Lixin", ""]]}, {"id": "2106.04210", "submitter": "Vito Giordano", "authors": "Vito Giordano, Filippo Chiarello, Elena Cervelli", "title": "Defining definition: a Text mining Approach to Define Innovative\n  Technological Fields", "comments": null, "journal-ref": "R&D MANAGEMENT CONFERENCE 2019 - DATA SCIENCE FOR INNOVATION R&D\n  MANAGEMENT CONFERENCE 2019 - DATA SCIENCE FOR INNOVATION R&D Management\n  Conference 2021 - Data Science for Innovatopm", "doi": null, "report-no": null, "categories": "cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the first task of an innovative project is delineating the scope of\nthe project itself or of the product/service to be developed. A wrong scope\ndefinition can determine (in the worst case) project failure. A good scope\ndefinition become even more relevant in technological intensive innovation\nprojects, nowadays characterized by a highly dynamic multidisciplinary,\nturbulent and uncertain environment. In these cases, the boundaries of the\nproject are not easily detectable and it is difficult to decide what it is\nin-scope and out-of-scope. The present work proposes a tool for the scope\ndelineation process, that automatically define an innovative technological\nfield or a new technology. The tool is based on Text Mining algorithm that\nexploits Elsevier's Scopus abstracts in order to the extract relevant data to\ndefine a technological scope. The automatic definition tool is then applied on\nfour case studies: Artificial Intelligence and Data Science. The results show\nhow the tool can provide many crucial information in the definition process of\na technological field. In particular for the target technological field (or\ntechnology), it provides the definition and other elements related to the\ntarget.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:42:05 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Giordano", "Vito", ""], ["Chiarello", "Filippo", ""], ["Cervelli", "Elena", ""]]}, {"id": "2106.04221", "submitter": "Florian Buettner", "authors": "Yinchong Yang, Florian Buettner", "title": "Multi-output Gaussian Processes for Uncertainty-aware Recommender\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recommender systems are often designed based on a collaborative filtering\napproach, where user preferences are predicted by modelling interactions\nbetween users and items. Many common approaches to solve the collaborative\nfiltering task are based on learning representations of users and items,\nincluding simple matrix factorization, Gaussian process latent variable models,\nand neural-network based embeddings. While matrix factorization approaches fail\nto model nonlinear relations, neural networks can potentially capture such\ncomplex relations with unprecedented predictive power and are highly scalable.\nHowever, neither of them is able to model predictive uncertainties. In\ncontrast, Gaussian Process based models can generate a predictive distribution,\nbut cannot scale to large amounts of data. In this manuscript, we propose a\nnovel approach combining the representation learning paradigm of collaborative\nfiltering with multi-output Gaussian processes in a joint framework to generate\nuncertainty-aware recommendations. We introduce an efficient strategy for model\ntraining and inference, resulting in a model that scales to very large and\nsparse datasets and achieves competitive performance in terms of classical\nmetrics quantifying the reconstruction error. In addition to accurately\npredicting user preferences, our model also provides meaningful uncertainty\nestimates about that prediction.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:01:14 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yang", "Yinchong", ""], ["Buettner", "Florian", ""]]}, {"id": "2106.04228", "submitter": "Etienne Boursier", "authors": "Flore Sentenac and Etienne Boursier and Vianney Perchet", "title": "Decentralized Learning in Online Queuing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by packet routing in computer networks, online queuing systems are\ncomposed of queues receiving packets at different rates. Repeatedly, they send\npackets to servers, each of them treating only at most one packet at a time. In\nthe centralized case, the number of accumulated packets remains bounded (i.e.,\nthe system is \\textit{stable}) as long as the ratio between service rates and\narrival rates is larger than $1$. In the decentralized case, individual\nno-regret strategies ensures stability when this ratio is larger than $2$. Yet,\nmyopically minimizing regret disregards the long term effects due to the\ncarryover of packets to further rounds. On the other hand, minimizing long term\ncosts leads to stable Nash equilibria as soon as the ratio exceeds\n$\\frac{e}{e-1}$. Stability with decentralized learning strategies with a ratio\nbelow $2$ was a major remaining question. We first argue that for ratios up to\n$2$, cooperation is required for stability of learning strategies, as selfish\nminimization of policy regret, a \\textit{patient} notion of regret, might\nindeed still be unstable in this case. We therefore consider cooperative queues\nand propose the first learning decentralized algorithm guaranteeing stability\nof the system as long as the ratio of rates is larger than $1$, thus reaching\nperformances comparable to centralized strategies.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 10:10:21 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sentenac", "Flore", ""], ["Boursier", "Etienne", ""], ["Perchet", "Vianney", ""]]}, {"id": "2106.04271", "submitter": "Tyler McCormick", "authors": "Mengjie Pan, Tyler H. McCormick, Bailey K. Fosdick", "title": "Inference for Network Regression Models with Community Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.SI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Network regression models, where the outcome comprises the valued edge in a\nnetwork and the predictors are actor or dyad-level covariates, are used\nextensively in the social and biological sciences. Valid inference relies on\naccurately modeling the residual dependencies among the relations. Frequently\nhomogeneity assumptions are placed on the errors which are commonly incorrect\nand ignore critical, natural clustering of the actors. In this work, we present\na novel regression modeling framework that models the errors as resulting from\na community-based dependence structure and exploits the subsequent\nexchangeability properties of the error distribution to obtain parsimonious\nstandard errors for regression parameters.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 12:04:31 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Pan", "Mengjie", ""], ["McCormick", "Tyler H.", ""], ["Fosdick", "Bailey K.", ""]]}, {"id": "2106.04330", "submitter": "Hankui Peng", "authors": "Hankui Peng, Nicos G. Pavlidis", "title": "Weighted Sparse Subspace Representation: A Unified Framework for\n  Subspace Clustering, Constrained Clustering, and Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral-based subspace clustering methods have proved successful in many\nchallenging applications such as gene sequencing, image recognition, and motion\nsegmentation. In this work, we first propose a novel spectral-based subspace\nclustering algorithm that seeks to represent each point as a sparse convex\ncombination of a few nearby points. We then extend the algorithm to constrained\nclustering and active learning settings. Our motivation for developing such a\nframework stems from the fact that typically either a small amount of labelled\ndata is available in advance; or it is possible to label some points at a cost.\nThe latter scenario is typically encountered in the process of validating a\ncluster assignment. Extensive experiments on simulated and real data sets show\nthat the proposed approach is effective and competitive with state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:39:43 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Peng", "Hankui", ""], ["Pavlidis", "Nicos G.", ""]]}, {"id": "2106.04335", "submitter": "Ping-Chun Hsieh", "authors": "Bing-Jing Hsieh, Ping-Chun Hsieh, Xi Liu", "title": "Reinforced Few-Shot Acquisition Function Learning for Bayesian\n  Optimization", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) conventionally relies on handcrafted acquisition\nfunctions (AFs) to sequentially determine the sample points. However, it has\nbeen widely observed in practice that the best-performing AF in terms of regret\ncan vary significantly under different types of black-box functions. It has\nremained a challenge to design one AF that can attain the best performance over\na wide variety of black-box functions. This paper aims to attack this challenge\nthrough the perspective of reinforced few-shot AF learning (FSAF).\nSpecifically, we first connect the notion of AFs with Q-functions and view a\ndeep Q-network (DQN) as a surrogate differentiable AF. While it serves as a\nnatural idea to combine DQN and an existing few-shot learning method, we\nidentify that such a direct combination does not perform well due to severe\noverfitting, which is particularly critical in BO due to the need of a\nversatile sampling policy. To address this, we present a Bayesian variant of\nDQN with the following three features: (i) It learns a distribution of\nQ-networks as AFs based on the Kullback-Leibler regularization framework. This\ninherently provides the uncertainty required in sampling for BO and mitigates\noverfitting. (ii) For the prior of the Bayesian DQN, we propose to use a demo\npolicy induced by an off-the-shelf AF for better training stability. (iii) On\nthe meta-level, we leverage the meta-loss of Bayesian model-agnostic\nmeta-learning, which serves as a natural companion to the proposed FSAF.\nMoreover, with the proper design of the Q-networks, FSAF is general-purpose in\nthat it is agnostic to the dimension and the cardinality of the input domain.\nThrough extensive experiments, we demonstrate that the FSAF achieves comparable\nor better regrets than the state-of-the-art benchmarks on a wide variety of\nsynthetic and real-world test functions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 13:46:46 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Hsieh", "Bing-Jing", ""], ["Hsieh", "Ping-Chun", ""], ["Liu", "Xi", ""]]}, {"id": "2106.04378", "submitter": "Christopher Jung", "authors": "Varun Gupta, Christopher Jung, Seth Neel, Aaron Roth, Saeed\n  Sharifi-Malvajerdi, Chris Waites", "title": "Adaptive Machine Unlearning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data deletion algorithms aim to remove the influence of deleted data points\nfrom trained models at a cheaper computational cost than fully retraining those\nmodels. However, for sequences of deletions, most prior work in the non-convex\nsetting gives valid guarantees only for sequences that are chosen independently\nof the models that are published. If people choose to delete their data as a\nfunction of the published models (because they don't like what the models\nreveal about them, for example), then the update sequence is adaptive. In this\npaper, we give a general reduction from deletion guarantees against adaptive\nsequences to deletion guarantees against non-adaptive sequences, using\ndifferential privacy and its connection to max information. Combined with ideas\nfrom prior work which give guarantees for non-adaptive deletion sequences, this\nleads to extremely flexible algorithms able to handle arbitrary model classes\nand training methodologies, giving strong provable deletion guarantees for\nadaptive deletion sequences. We show in theory how prior work for non-convex\nmodels fails against adaptive deletion sequences, and use this intuition to\ndesign a practical attack against the SISA algorithm of Bourtoule et al. [2021]\non CIFAR-10, MNIST, Fashion-MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 14:11:53 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Gupta", "Varun", ""], ["Jung", "Christopher", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Sharifi-Malvajerdi", "Saeed", ""], ["Waites", "Chris", ""]]}, {"id": "2106.04379", "submitter": "Cameron Allen", "authors": "Cameron Allen, Neev Parikh, Omer Gottesman, George Konidaris", "title": "Learning Markov State Abstractions for Deep Reinforcement Learning", "comments": "Code available at\n  https://github.com/camall3n/markov-state-abstractions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental assumption of reinforcement learning in Markov decision\nprocesses (MDPs) is that the relevant decision process is, in fact, Markov.\nHowever, when MDPs have rich observations, agents typically learn by way of an\nabstract state representation, and such representations are not guaranteed to\npreserve the Markov property. We introduce a novel set of conditions and prove\nthat they are sufficient for learning a Markov abstract state representation.\nWe then describe a practical training procedure that combines inverse model\nestimation and temporal contrastive learning to learn an abstraction that\napproximately satisfies these conditions. Our novel training objective is\ncompatible with both online and offline training: it does not require a reward\nsignal, but agents can capitalize on reward information when available. We\nempirically evaluate our approach on a visual gridworld domain and a set of\ncontinuous control benchmarks. Our approach learns representations that capture\nthe underlying structure of the domain and lead to improved sample efficiency\nover state-of-the-art deep reinforcement learning with visual features -- often\nmatching or exceeding the performance achieved with hand-designed compact state\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 14:12:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Allen", "Cameron", ""], ["Parikh", "Neev", ""], ["Gottesman", "Omer", ""], ["Konidaris", "George", ""]]}, {"id": "2106.04455", "submitter": "Henry WJ Reeve", "authors": "Henry W. J. Reeve, Timothy I. Cannings, Richard J. Samworth", "title": "Adaptive transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In transfer learning, we wish to make inference about a target population\nwhen we have access to data both from the distribution itself, and from a\ndifferent but related source distribution. We introduce a flexible framework\nfor transfer learning in the context of binary classification, allowing for\ncovariate-dependent relationships between the source and target distributions\nthat are not required to preserve the Bayes decision boundary. Our main\ncontributions are to derive the minimax optimal rates of convergence (up to\npoly-logarithmic factors) in this problem, and show that the optimal rate can\nbe achieved by an algorithm that adapts to key aspects of the unknown transfer\nrelationship, as well as the smoothness and tail parameters of our\ndistributional classes. This optimal rate turns out to have several regimes,\ndepending on the interplay between the relative sample sizes and the strength\nof the transfer relationship, and our algorithm achieves optimality by careful,\ndecision tree-based calibration of local nearest-neighbour procedures.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 15:39:43 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Reeve", "Henry W. J.", ""], ["Cannings", "Timothy I.", ""], ["Samworth", "Richard J.", ""]]}, {"id": "2106.04492", "submitter": "Yohei Kawaguchi", "authors": "Yohei Kawaguchi, Keisuke Imoto, Yuma Koizumi, Noboru Harada, Daisuke\n  Niizumi, Kota Dohi, Ryo Tanabe, Harsh Purohit, and Takashi Endo", "title": "Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised\n  Anomalous Sound Detection for Machine Condition Monitoring under Domain\n  Shifted Conditions", "comments": "Submitted to DCASE 2021 Workshop. arXiv admin note: text overlap with\n  arXiv:2006.05822", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the task description and discussion on the results of the DCASE\n2021 Challenge Task 2. Last year, we organized unsupervised anomalous sound\ndetection (ASD) task; identifying whether the given sound is normal or\nanomalous without anomalous training data. In this year, we organize an\nadvanced unsupervised ASD task under domain-shift conditions which focuses on\nthe inevitable problem for the practical use of ASD systems. The main challenge\nof this task is to detect unknown anomalous sounds where the acoustic\ncharacteristics of the training and testing samples are different, i.e.\ndomain-shifted. This problem is frequently occurs due to changes in seasons,\nmanufactured products, and/or environmental noise. After the challenge\nsubmission deadline, we will add challenge results and analysis of the\nsubmissions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:26:10 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Kawaguchi", "Yohei", ""], ["Imoto", "Keisuke", ""], ["Koizumi", "Yuma", ""], ["Harada", "Noboru", ""], ["Niizumi", "Daisuke", ""], ["Dohi", "Kota", ""], ["Tanabe", "Ryo", ""], ["Purohit", "Harsh", ""], ["Endo", "Takashi", ""]]}, {"id": "2106.04502", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak, Renbo Tu, Tian Li, Liam Li, Maria-Florina Balcan,\n  Virginia Smith, Ameet Talwalkar", "title": "Federated Hyperparameter Tuning: Challenges, Baselines, and Connections\n  to Weight-Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning hyperparameters is a crucial but arduous part of the machine learning\npipeline. Hyperparameter optimization is even more challenging in federated\nlearning, where models are learned over a distributed network of heterogeneous\ndevices; here, the need to keep data on device and perform local training makes\nit difficult to efficiently train and evaluate configurations. In this work, we\ninvestigate the problem of federated hyperparameter tuning. We first identify\nkey challenges and show how standard approaches may be adapted to form\nbaselines for the federated setting. Then, by making a novel connection to the\nneural architecture search technique of weight-sharing, we introduce a new\nmethod, FedEx, to accelerate federated hyperparameter tuning that is applicable\nto widely-used federated optimization methods such as FedAvg and recent\nvariants. Theoretically, we show that a FedEx variant correctly tunes the\non-device learning rate in the setting of online convex optimization across\ndevices. Empirically, we show that FedEx can outperform natural baselines for\nfederated hyperparameter tuning by several percentage points on the\nShakespeare, FEMNIST, and CIFAR-10 benchmarks, obtaining higher accuracy using\nthe same training budget.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:42:37 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Khodak", "Mikhail", ""], ["Tu", "Renbo", ""], ["Li", "Tian", ""], ["Li", "Liam", ""], ["Balcan", "Maria-Florina", ""], ["Smith", "Virginia", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2106.04530", "submitter": "Peilin Yu", "authors": "Peilin Yu, Tiffany Ding, Stephen H. Bach", "title": "Learning from Multiple Noisy Partial Labelers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmatic weak supervision creates models without hand-labeled training\ndata by combining the outputs of noisy, user-written rules and other heuristic\nlabelers. Existing frameworks make the restrictive assumption that labelers\noutput a single class label. Enabling users to create partial labelers that\noutput subsets of possible class labels would greatly expand the expressivity\nof programmatic weak supervision. We introduce this capability by defining a\nprobabilistic generative model that can estimate the underlying accuracies of\nmultiple noisy partial labelers without ground truth labels. We prove that this\nclass of models is generically identifiable up to label swapping under mild\nconditions. We also show how to scale up learning to 100k examples in one\nminute, a 300X speed up compared to a naive implementation. We evaluate our\nframework on three text classification and six object classification tasks. On\ntext tasks, adding partial labels increases average accuracy by 9.6 percentage\npoints. On image tasks, we show that partial labels allow us to approach some\nzero-shot object classification problems with programmatic weak supervision by\nusing class attributes as partial labelers. Our framework is able to achieve\naccuracy comparable to recent embedding-based zero-shot learning methods using\nonly pre-trained attribute detectors\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:12:16 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yu", "Peilin", ""], ["Ding", "Tiffany", ""], ["Bach", "Stephen H.", ""]]}, {"id": "2106.04546", "submitter": "Yuan Yin", "authors": "Yuan Yin, Ibrahim Ayed, Emmanuel de B\\'ezenac, Nicolas Baskiotis,\n  Patrick Gallinari", "title": "LEADS: Learning Dynamical Systems that Generalize Across Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When modeling dynamical systems from real-world data samples, the\ndistribution of data often changes according to the environment in which they\nare captured, and the dynamics of the system itself vary from one environment\nto another. Generalizing across environments thus challenges the conventional\nframeworks. The classical settings suggest either considering data as i.i.d.\nand learning a single model to cover all situations or learning\nenvironment-specific models. Both are sub-optimal: the former disregards the\ndiscrepancies between environments leading to biased solutions, while the\nlatter does not exploit their potential commonalities and is prone to scarcity\nproblems. We propose LEADS, a novel framework that leverages the commonalities\nand discrepancies among known environments to improve model generalization.\nThis is achieved with a tailored training formulation aiming at capturing\ncommon dynamics within a shared model while additional terms capture\nenvironment-specific dynamics. We ground our approach in theory, exhibiting a\ndecrease in sample complexity with our approach and corroborate these results\nempirically, instantiating it for linear dynamics. Moreover, we concretize this\nframework for neural networks and evaluate it experimentally on representative\nfamilies of nonlinear dynamics. We show that this new setting can exploit\nknowledge extracted from environment-dependent data and improves generalization\nfor both known and novel environments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:28:19 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yin", "Yuan", ""], ["Ayed", "Ibrahim", ""], ["de B\u00e9zenac", "Emmanuel", ""], ["Baskiotis", "Nicolas", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2106.04615", "submitter": "Sherjil Ozair", "authors": "Sherjil Ozair, Yazhe Li, Ali Razavi, Ioannis Antonoglou, A\\\"aron van\n  den Oord, Oriol Vinyals", "title": "Vector Quantized Models for Planning", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent developments in the field of model-based RL have proven successful in\na range of environments, especially ones where planning is essential. However,\nsuch successes have been limited to deterministic fully-observed environments.\nWe present a new approach that handles stochastic and partially-observable\nenvironments. Our key insight is to use discrete autoencoders to capture the\nmultiple possible effects of an action in a stochastic environment. We use a\nstochastic variant of Monte Carlo tree search to plan over both the agent's\nactions and the discrete latent variables representing the environment's\nresponse. Our approach significantly outperforms an offline version of MuZero\non a stochastic interpretation of chess where the opponent is considered part\nof the environment. We also show that our approach scales to DeepMind Lab, a\nfirst-person 3D environment with large visual observations and partial\nobservability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:12:32 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 07:02:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Ozair", "Sherjil", ""], ["Li", "Yazhe", ""], ["Razavi", "Ali", ""], ["Antonoglou", "Ioannis", ""], ["Oord", "A\u00e4ron van den", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2106.04619", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Yash Sharma, Luigi Gresele, Wieland Brendel,\n  Bernhard Sch\\\"olkopf, Michel Besserve, Francesco Locatello", "title": "Self-Supervised Learning with Data Augmentations Provably Isolates\n  Content from Style", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning has shown remarkable success in a\nnumber of domains. A common practice is to perform data augmentation via\nhand-crafted transformations intended to leave the semantics of the data\ninvariant. We seek to understand the empirical success of this approach from a\ntheoretical perspective. We formulate the augmentation process as a latent\nvariable model by postulating a partition of the latent representation into a\ncontent component, which is assumed invariant to augmentation, and a style\ncomponent, which is allowed to change. Unlike prior work on disentanglement and\nindependent component analysis, we allow for both nontrivial statistical and\ncausal dependencies in the latent space. We study the identifiability of the\nlatent representation based on pairs of views of the observations and prove\nsufficient conditions that allow us to identify the invariant content partition\nup to an invertible mapping in both generative and discriminative settings. We\nfind numerical simulations with dependent latent variables are consistent with\nour theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,\nvisually complex images with rich causal dependencies, which we use to study\nthe effect of data augmentations performed in practice.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:18:09 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Sharma", "Yash", ""], ["Gresele", "Luigi", ""], ["Brendel", "Wieland", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Besserve", "Michel", ""], ["Locatello", "Francesco", ""]]}, {"id": "2106.04636", "submitter": "Andrew Chia", "authors": "Andrew Chia", "title": "Automatically Differentiable Random Coefficient Logistic Demand\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.DC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the random coefficient logistic demand (BLP) model can be phrased\nas an automatically differentiable moment function, including the incorporation\nof numerical safeguards proposed in the literature. This allows gradient-based\nfrequentist and quasi-Bayesian estimation using the Continuously Updating\nEstimator (CUE). Drawing from the machine learning literature, we outline\nhitherto under-utilized best practices in both frequentist and Bayesian\nestimation techniques. Our Monte Carlo experiments compare the performance of\nCUE, 2S-GMM, and LTE estimation. Preliminary findings indicate that the CUE\nestimated using LTE and frequentist optimization has a lower bias but higher\nMAE compared to the traditional 2-Stage GMM (2S-GMM) approach. We also find\nthat using credible intervals from MCMC sampling for the non-linear parameters\ntogether with frequentist analytical standard errors for the concentrated out\nlinear parameters provides empirical coverage closest to the nominal level. The\naccompanying admest Python package provides a platform for replication and\nextensibility.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:50:11 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Chia", "Andrew", ""]]}, {"id": "2106.04682", "submitter": "Aryan Deshwal", "authors": "Aryan Deshwal, Syrine Belakaria, Janardhan Rao Doppa", "title": "Bayesian Optimization over Hybrid Spaces", "comments": "14 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of optimizing hybrid structures (mixture of discrete\nand continuous input variables) via expensive black-box function evaluations.\nThis problem arises in many real-world applications. For example, in materials\ndesign optimization via lab experiments, discrete and continuous variables\ncorrespond to the presence/absence of primitive elements and their relative\nconcentrations respectively. The key challenge is to accurately model the\ncomplex interactions between discrete and continuous variables. In this paper,\nwe propose a novel approach referred as Hybrid Bayesian Optimization (HyBO) by\nutilizing diffusion kernels, which are naturally defined over continuous and\ndiscrete variables. We develop a principled approach for constructing diffusion\nkernels over hybrid spaces by utilizing the additive kernel formulation, which\nallows additive interactions of all orders in a tractable manner. We\ntheoretically analyze the modeling strength of additive hybrid kernels and\nprove that it has the universal approximation property. Our experiments on\nsynthetic and six diverse real-world benchmarks show that HyBO significantly\noutperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 20:47:21 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Deshwal", "Aryan", ""], ["Belakaria", "Syrine", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2106.04692", "submitter": "Junjie Yang", "authors": "Junjie Yang, Kaiyi Ji, Yingbin Liang", "title": "Provably Faster Algorithms for Bilevel Optimization", "comments": "This paper was submitted in May 2021 for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization has been widely applied in many important machine\nlearning applications such as hyperparameter optimization and meta-learning.\nRecently, several momentum-based algorithms have been proposed to solve bilevel\noptimization problems faster. However, those momentum-based algorithms do not\nachieve provably better computational complexity than\n$\\mathcal{O}(\\epsilon^{-2})$ of the SGD-based algorithm. In this paper, we\npropose two new algorithms for bilevel optimization, where the first algorithm\nadopts momentum-based recursive iterations, and the second algorithm adopts\nrecursive gradient estimations in nested loops to decrease the variance. We\nshow that both algorithms achieve the complexity of\n$\\mathcal{O}(\\epsilon^{-1.5})$, which outperforms all existing algorithms by\nthe order of magnitude. Our experiments validate our theoretical results and\ndemonstrate the superior empirical performance of our algorithms in\nhyperparameter applications. Our codes for MRBO, VRBO and other benchmarks are\navailable $\\text{online}^1$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 21:05:30 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Yang", "Junjie", ""], ["Ji", "Kaiyi", ""], ["Liang", "Yingbin", ""]]}, {"id": "2106.04700", "submitter": "Sudeep Raja Putta", "authors": "Sudeep Raja Putta, Shipra Agrawal", "title": "Scale Free Adversarial Multi Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the Scale-Free Adversarial Multi Armed Bandit(MAB) problem, where\nthe player only knows the number of arms $n$ and not the scale or magnitude of\nthe losses. It sees bandit feedback about the loss vectors $l_1,\\dots, l_T \\in\n\\mathbb{R}^n$. The goal is to bound its regret as a function of $n$ and\n$l_1,\\dots, l_T$. We design a Follow The Regularized Leader(FTRL) algorithm,\nwhich comes with the first scale-free regret guarantee for MAB. It uses the log\nbarrier regularizer, the importance weighted estimator, an adaptive learning\nrate, and an adaptive exploration parameter. In the analysis, we introduce a\nsimple, unifying technique for obtaining regret inequalities for FTRL and\nOnline Mirror Descent(OMD) on the probability simplex using Potential Functions\nand Mixed Bregmans. We also develop a new technique for obtaining local-norm\nlower bounds for Bregman Divergences, which are crucial in bandit regret\nbounds. These tools could be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 21:26:57 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Putta", "Sudeep Raja", ""], ["Agrawal", "Shipra", ""]]}, {"id": "2106.04741", "submitter": "Dar Gilboa", "authors": "Dar Gilboa, Ari Pakman, Thibault Vatter", "title": "Marginalizable Density Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probability density models based on deep networks have achieved remarkable\nsuccess in modeling complex high-dimensional datasets. However, unlike kernel\ndensity estimators, modern neural models do not yield marginals or conditionals\nin closed form, as these quantities require the evaluation of seldom tractable\nintegrals. In this work, we present the Marginalizable Density Model\nApproximator (MDMA), a novel deep network architecture which provides closed\nform expressions for the probabilities, marginals and conditionals of any\nsubset of the variables. The MDMA learns deep scalar representations for each\nindividual variable and combines them via learned hierarchical tensor\ndecompositions into a tractable yet expressive CDF, from which marginals and\nconditional densities are easily obtained. We illustrate the advantage of exact\nmarginalizability in several tasks that are out of reach of previous deep\nnetwork-based density estimation models, such as estimating mutual information\nbetween arbitrary subsets of variables, inferring causality by testing for\nconditional independence, and inference with missing data without the need for\ndata imputation, outperforming state-of-the-art models on these tasks. The\nmodel also allows for parallelized sampling with only a logarithmic dependence\nof the time complexity on the number of variables.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 23:54:48 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Gilboa", "Dar", ""], ["Pakman", "Ari", ""], ["Vatter", "Thibault", ""]]}, {"id": "2106.04770", "submitter": "Sho Sonoda Dr", "authors": "Sho Sonoda, Isao Ishikawa, Masahiro Ikeda", "title": "Ghosts in Neural Networks: Existence, Structure and Role of\n  Infinite-Dimensional Null Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparametrization has been remarkably successful for deep learning studies.\nThis study investigates an overlooked but important aspect of overparametrized\nneural networks, that is, the null components in the parameters of neural\nnetworks, or the ghosts. Since deep learning is not explicitly regularized,\ntypical deep learning solutions contain null components. In this paper, we\npresent a structure theorem of the null space for a general class of neural\nnetworks. Specifically, we show that any null element can be uniquely written\nby the linear combination of ridgelet transforms. In general, it is quite\ndifficult to fully characterize the null space of an arbitrarily given\noperator. Therefore, the structure theorem is a great advantage for\nunderstanding a complicated landscape of neural network parameters. As\napplications, we discuss the roles of ghosts on the generalization performance\nof deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 02:05:38 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Sonoda", "Sho", ""], ["Ishikawa", "Isao", ""], ["Ikeda", "Masahiro", ""]]}, {"id": "2106.04795", "submitter": "Huiyuan Wang", "authors": "Huiyuan Wang and Wei Lin", "title": "Harmless Overparametrization in Two-layer Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Overparametrized neural networks, where the number of active parameters is\nlarger than the sample size, prove remarkably effective in modern deep learning\npractice. From the classical perspective, however, much fewer parameters are\nsufficient for optimal estimation and prediction, whereas overparametrization\ncan be harmful even in the presence of explicit regularization. To reconcile\nthis conflict, we present a generalization theory for overparametrized ReLU\nnetworks by incorporating an explicit regularizer based on the scaled variation\nnorm. Interestingly, this regularizer is equivalent to the ridge from the angle\nof gradient-based optimization, but is similar to the group lasso in terms of\ncontrolling model complexity. By exploiting this ridge-lasso duality, we show\nthat overparametrization is generally harmless to two-layer ReLU networks. In\nparticular, the overparametrized estimators are minimax optimal up to a\nlogarithmic factor. By contrast, we show that overparametrized random feature\nmodels suffer from the curse of dimensionality and thus are suboptimal.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 03:52:18 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Wang", "Huiyuan", ""], ["Lin", "Wei", ""]]}, {"id": "2106.04800", "submitter": "Tianxi Li", "authors": "Quinlan Dawkins, Tianxi Li, Haifeng Xu", "title": "Diffusion Source Identification on Networks with Statistical Confidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion source identification on networks is a problem of fundamental\nimportance in a broad class of applications, including rumor controlling and\nvirus identification. Though this problem has received significant recent\nattention, most studies have focused only on very restrictive settings and lack\ntheoretical guarantees for more realistic networks. We introduce a statistical\nframework for the study of diffusion source identification and develop a\nconfidence set inference approach inspired by hypothesis testing. Our method\nefficiently produces a small subset of nodes, which provably covers the source\nnode with any pre-specified confidence level without restrictive assumptions on\nnetwork structures. Moreover, we propose multiple Monte Carlo strategies for\nthe inference procedure based on network topology and the probabilistic\nproperties that significantly improve the scalability. To our knowledge, this\nis the first diffusion source identification method with a practically useful\ntheoretical guarantee on general networks. We demonstrate our approach via\nextensive synthetic experiments on well-known random network models and a\nmobility network between cities concerning the COVID-19 spreading.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 04:21:03 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 15:18:38 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Dawkins", "Quinlan", ""], ["Li", "Tianxi", ""], ["Xu", "Haifeng", ""]]}, {"id": "2106.04805", "submitter": "Yuchen Wu", "authors": "Yuchen Wu, MohammadHossein Bateni, Andre Linhares, Filipe Miguel\n  Goncalves de Almeida, Andrea Montanari, Ashkan Norouzi-Fard, Jakab Tardos", "title": "Streaming Belief Propagation for Community Detection", "comments": "36 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The community detection problem requires to cluster the nodes of a network\ninto a small number of well-connected \"communities\". There has been substantial\nrecent progress in characterizing the fundamental statistical limits of\ncommunity detection under simple stochastic block models. However, in\nreal-world applications, the network structure is typically dynamic, with nodes\nthat join over time. In this setting, we would like a detection algorithm to\nperform only a limited number of updates at each node arrival. While standard\nvoting approaches satisfy this constraint, it is unclear whether they exploit\nthe network information optimally. We introduce a simple model for networks\ngrowing over time which we refer to as streaming stochastic block model\n(StSBM). Within this model, we prove that voting algorithms have fundamental\nlimitations. We also develop a streaming belief-propagation (StreamBP)\napproach, for which we prove optimality in certain regimes. We validate our\ntheoretical findings on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 04:36:09 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 18:13:03 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wu", "Yuchen", ""], ["Bateni", "MohammadHossein", ""], ["Linhares", "Andre", ""], ["de Almeida", "Filipe Miguel Goncalves", ""], ["Montanari", "Andrea", ""], ["Norouzi-Fard", "Ashkan", ""], ["Tardos", "Jakab", ""]]}, {"id": "2106.04844", "submitter": "Feng Zhou", "authors": "Feng Zhou, Quyu Kong, Yixuan Zhang, Cheng Feng, Jun Zhu", "title": "Nonlinear Hawkes Processes in Time-Varying System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hawkes processes are a class of point processes that have the ability to\nmodel the self- and mutual-exciting phenomena. Although the classic Hawkes\nprocesses cover a wide range of applications, their expressive ability is\nlimited due to three key hypotheses: parametric, linear and homogeneous. Recent\nwork has attempted to address these limitations separately. This work aims to\novercome all three assumptions simultaneously by proposing the flexible\nstate-switching Hawkes processes: a flexible, nonlinear and nonhomogeneous\nvariant where a state process is incorporated to interact with the point\nprocesses. The proposed model empowers Hawkes processes to be applied to\ntime-varying systems. For inference, we utilize the latent variable\naugmentation technique to design two efficient Bayesian inference algorithms:\nGibbs sampler and mean-field variational inference, with analytical iterative\nupdates to estimate the posterior. In experiments, our model achieves superior\nperformance compared to the state-of-the-art competitors.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 07:06:05 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Zhou", "Feng", ""], ["Kong", "Quyu", ""], ["Zhang", "Yixuan", ""], ["Feng", "Cheng", ""], ["Zhu", "Jun", ""]]}, {"id": "2106.04862", "submitter": "Boyao Zhang", "authors": "Boyao Zhang, Colin Griesbach, Cora Kim, Nadia M\\\"uller-Voggel,\n  Elisabeth Bergherr", "title": "Bayesian Boosting for Linear Mixed Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting methods are widely used in statistical learning to deal with\nhigh-dimensional data due to their variable selection feature. However, those\nmethods lack straightforward ways to construct estimators for the precision of\nthe parameters such as variance or confidence interval, which can be achieved\nby conventional statistical methods like Bayesian inference. In this paper, we\npropose a new inference method \"BayesBoost\" that combines boosting and Bayesian\nfor linear mixed models to make the uncertainty estimation for the random\neffects possible on the one hand. On the other hand, the new method overcomes\nthe shortcomings of Bayesian inference in giving precise and unambiguous\nguidelines for the selection of covariates by benefiting from boosting\ntechniques. The implementation of Bayesian inference leads to the randomness of\nmodel selection criteria like the conditional AIC (cAIC), so we also propose a\ncAIC-based model selection criteria that focus on the stabilized regions\ninstead of the global minimum. The effectiveness of the new approach can be\nobserved via simulation and in a data example from the field of neurophysiology\nfocussing on the mechanisms in the brain while listening to unpleasant sounds.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 07:40:00 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Zhang", "Boyao", ""], ["Griesbach", "Colin", ""], ["Kim", "Cora", ""], ["M\u00fcller-Voggel", "Nadia", ""], ["Bergherr", "Elisabeth", ""]]}, {"id": "2106.04881", "submitter": "Alexander Camuto", "authors": "Alexander Camuto, George Deligiannidis, Murat A. Erdogdu, Mert\n  G\\\"urb\\\"uzbalaban, Umut \\c{S}im\\c{s}ekli, Lingjiong Zhu", "title": "Fractal Structure and Generalization Properties of Stochastic\n  Optimization Algorithms", "comments": "34 pages including Supplement, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding generalization in deep learning has been one of the major\nchallenges in statistical learning theory over the last decade. While recent\nwork has illustrated that the dataset and the training algorithm must be taken\ninto account in order to obtain meaningful generalization bounds, it is still\ntheoretically not clear which properties of the data and the algorithm\ndetermine the generalization performance. In this study, we approach this\nproblem from a dynamical systems theory perspective and represent stochastic\noptimization algorithms as random iterated function systems (IFS). Well studied\nin the dynamical systems literature, under mild assumptions, such IFSs can be\nshown to be ergodic with an invariant measure that is often supported on sets\nwith a fractal structure. As our main contribution, we prove that the\ngeneralization error of a stochastic optimization algorithm can be bounded\nbased on the `complexity' of the fractal structure that underlies its invariant\nmeasure. Leveraging results from dynamical systems theory, we show that the\ngeneralization error can be explicitly linked to the choice of the algorithm\n(e.g., stochastic gradient descent -- SGD), algorithm hyperparameters (e.g.,\nstep-size, batch-size), and the geometry of the problem (e.g., Hessian of the\nloss). We further specialize our results to specific problems (e.g.,\nlinear/logistic regression, one hidden-layered neural networks) and algorithms\n(e.g., SGD and preconditioned variants), and obtain analytical estimates for\nour bound.For modern neural networks, we develop an efficient algorithm to\ncompute the developed bound and support our theory with various experiments on\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:05:36 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Camuto", "Alexander", ""], ["Deligiannidis", "George", ""], ["Erdogdu", "Murat A.", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""], ["\u015eim\u015fekli", "Umut", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "2106.04886", "submitter": "Gert-Jan Both", "authors": "Gert-Jan Both, Remy Kusters", "title": "Fully differentiable model discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model discovery aims at autonomously discovering differential equations\nunderlying a dataset. Approaches based on Physics Informed Neural Networks\n(PINNs) have shown great promise, but a fully-differentiable model which\nexplicitly learns the equation has remained elusive. In this paper we propose\nsuch an approach by combining neural network based surrogates with Sparse\nBayesian Learning (SBL). We start by reinterpreting PINNs as multitask models,\napplying multitask learning using uncertainty, and show that this leads to a\nnatural framework for including Bayesian regression techniques. We then\nconstruct a robust model discovery algorithm by using SBL, which we showcase on\nvarious datasets. Concurrently, the multitask approach allows the use of\nprobabilistic approximators, and we show a proof of concept using normalizing\nflows to directly learn a density model from single particle data. Our work\nexpands PINNs to various types of neural network architectures, and connects\nneural network-based surrogates to the rich field of Bayesian parameter\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:11:23 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Both", "Gert-Jan", ""], ["Kusters", "Remy", ""]]}, {"id": "2106.04887", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, John Langford, Paul Mineiro, Ida Momennejad", "title": "Interaction-Grounded Learning", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a prosthetic arm, learning to adapt to its user's control signals.\nWe propose Interaction-Grounded Learning for this novel setting, in which a\nlearner's goal is to interact with the environment with no grounding or\nexplicit reward to optimize its policies. Such a problem evades common RL\nsolutions which require an explicit reward. The learning agent observes a\nmultidimensional context vector, takes an action, and then observes a\nmultidimensional feedback vector. This multidimensional feedback vector has no\nexplicit reward information. In order to succeed, the algorithm must learn how\nto evaluate the feedback vector to discover a latent reward signal, with which\nit can ground its policies without supervision. We show that in an\nInteraction-Grounded Learning setting, with certain natural assumptions, a\nlearner can discover the latent reward and ground its policy for successful\ninteraction. We provide theoretical guarantees and a proof-of-concept empirical\nevaluation to demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:13:29 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 23:24:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Xie", "Tengyang", ""], ["Langford", "John", ""], ["Mineiro", "Paul", ""], ["Momennejad", "Ida", ""]]}, {"id": "2106.04895", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Nan Jiang, Huan Wang, Caiming Xiong, Yu Bai", "title": "Policy Finetuning: Bridging Sample-Efficient Offline and Online\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical work studies sample-efficient reinforcement learning (RL)\nextensively in two settings: learning interactively in the environment (online\nRL), or learning from an offline dataset (offline RL). However, existing\nalgorithms and theories for learning near-optimal policies in these two\nsettings are rather different and disconnected. Towards bridging this gap, this\npaper initiates the theoretical study of policy finetuning, that is, online RL\nwhere the learner has additional access to a \"reference policy\" $\\mu$ close to\nthe optimal policy $\\pi_\\star$ in a certain sense. We consider the policy\nfinetuning problem in episodic Markov Decision Processes (MDPs) with $S$\nstates, $A$ actions, and horizon length $H$. We first design a sharp offline\nreduction algorithm -- which simply executes $\\mu$ and runs offline policy\noptimization on the collected dataset -- that finds an $\\varepsilon$\nnear-optimal policy within $\\widetilde{O}(H^3SC^\\star/\\varepsilon^2)$ episodes,\nwhere $C^\\star$ is the single-policy concentrability coefficient between $\\mu$\nand $\\pi_\\star$. This offline result is the first that matches the sample\ncomplexity lower bound in this setting, and resolves a recent open question in\noffline RL. We then establish an $\\Omega(H^3S\\min\\{C^\\star, A\\}/\\varepsilon^2)$\nsample complexity lower bound for any policy finetuning algorithm, including\nthose that can adaptively explore the environment. This implies that -- perhaps\nsurprisingly -- the optimal policy finetuning algorithm is either offline\nreduction or a purely online RL algorithm that does not use $\\mu$. Finally, we\ndesign a new hybrid offline/online algorithm for policy finetuning that\nachieves better sample complexity than both vanilla offline reduction and\npurely online RL algorithms, in a relaxed setting where $\\mu$ only satisfies\nconcentrability partially up to a certain time step.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:28:55 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Xie", "Tengyang", ""], ["Jiang", "Nan", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""], ["Bai", "Yu", ""]]}, {"id": "2106.04913", "submitter": "Marco Bressan", "authors": "Marco Bressan, Nicol\\`o Cesa-Bianchi, Silvio Lattanzi, Andrea Paudice", "title": "On Margin-Based Cluster Recovery with Oracle Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an active cluster recovery problem where, given a set of $n$ points\nand an oracle answering queries like \"are these two points in the same\ncluster?\", the task is to recover exactly all clusters using as few queries as\npossible. We begin by introducing a simple but general notion of margin between\nclusters that captures, as special cases, the margins used in previous work,\nthe classic SVM margin, and standard notions of stability for center-based\nclusterings. Then, under our margin assumptions we design algorithms that, in a\nvariety of settings, recover all clusters exactly using only $O(\\log n)$\nqueries. For the Euclidean case, $\\mathbb{R}^m$, we give an algorithm that\nrecovers arbitrary convex clusters, in polynomial time, and with a number of\nqueries that is lower than the best existing algorithm by $\\Theta(m^m)$\nfactors. For general pseudometric spaces, where clusters might not be convex or\nmight not have any notion of shape, we give an algorithm that achieves the\n$O(\\log n)$ query bound, and is provably near-optimal as a function of the\npacking number of the space. Finally, for clusterings realized by binary\nconcept classes, we give a combinatorial characterization of recoverability\nwith $O(\\log n)$ queries, and we show that, for many concept classes in\nEuclidean spaces, this characterization is equivalent to our margin condition.\nOur results show a deep connection between cluster margins and active cluster\nrecoverability.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:48:23 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Bressan", "Marco", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""], ["Lattanzi", "Silvio", ""], ["Paudice", "Andrea", ""]]}, {"id": "2106.04923", "submitter": "L\\'eo And\\'eol", "authors": "L\\'eo And\\'eol, Yusei Kawakami, Yuichiro Wada, Takafumi Kanamori,\n  Klaus-Robert M\\\"uller, Gr\\'egoire Montavon", "title": "Learning Domain Invariant Representations by Joint Wasserstein Distance\n  Minimization", "comments": "20 pages including appendix. Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain shifts in the training data are common in practical applications of\nmachine learning, they occur for instance when the data is coming from\ndifferent sources. Ideally, a ML model should work well independently of these\nshifts, for example, by learning a domain-invariant representation. Moreover,\nprivacy concerns regarding the source also require a domain-invariant\nrepresentation. In this work, we provide theoretical results that link domain\ninvariant representations -- measured by the Wasserstein distance on the joint\ndistributions -- to a practical semi-supervised learning objective based on a\ncross-entropy classifier and a novel domain critic. Quantitative experiments\ndemonstrate that the proposed approach is indeed able to practically learn such\nan invariant representation (between two domains), and the latter also supports\nmodels with higher predictive accuracy on both domains, comparing favorably to\nexisting techniques.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 09:08:51 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["And\u00e9ol", "L\u00e9o", ""], ["Kawakami", "Yusei", ""], ["Wada", "Yuichiro", ""], ["Kanamori", "Takafumi", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Montavon", "Gr\u00e9goire", ""]]}, {"id": "2106.04929", "submitter": "Diptesh Das", "authors": "Diptesh Das, Vo Nguyen Le Duy, Hiroyuki Hanada, Koji Tsuda, Ichiro\n  Takeuchi", "title": "Fast and More Powerful Selective Inference for Sparse High-order\n  Interaction Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated high-stake decision-making such as medical diagnosis requires\nmodels with high interpretability and reliability. As one of the interpretable\nand reliable models with good prediction ability, we consider Sparse High-order\nInteraction Model (SHIM) in this study. However, finding statistically\nsignificant high-order interactions is challenging due to the intrinsic high\ndimensionality of the combinatorial effects. Another problem in data-driven\nmodeling is the effect of \"cherry-picking\" a.k.a. selection bias. Our main\ncontribution is to extend the recently developed parametric programming\napproach for selective inference to high-order interaction models. Exhaustive\nsearch over the cherry tree (all possible interactions) can be daunting and\nimpractical even for a small-sized problem. We introduced an efficient pruning\nstrategy and demonstrated the computational efficiency and statistical power of\nthe proposed method using both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 09:22:42 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Das", "Diptesh", ""], ["Duy", "Vo Nguyen Le", ""], ["Hanada", "Hiroyuki", ""], ["Tsuda", "Koji", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2106.04944", "submitter": "Danial Dervovic", "authors": "Danial Dervovic, Parisa Hassanzadeh, Samuel Assefa, Prashant Reddy", "title": "Non-Parametric Stochastic Sequential Assignment With Random Arrival\n  Times", "comments": "Accepted to IJCAI '21, full version with Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem wherein jobs arrive at random times and assume random\nvalues. Upon each job arrival, the decision-maker must decide immediately\nwhether or not to accept the job and gain the value on offer as a reward, with\nthe constraint that they may only accept at most $n$ jobs over some reference\ntime period. The decision-maker only has access to $M$ independent realisations\nof the job arrival process. We propose an algorithm, Non-Parametric Sequential\nAllocation (NPSA), for solving this problem. Moreover, we prove that the\nexpected reward returned by the NPSA algorithm converges in probability to\noptimality as $M$ grows large. We demonstrate the effectiveness of the\nalgorithm empirically on synthetic data and on public fraud-detection datasets,\nfrom where the motivation for this work is derived.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 09:41:38 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Dervovic", "Danial", ""], ["Hassanzadeh", "Parisa", ""], ["Assefa", "Samuel", ""], ["Reddy", "Prashant", ""]]}, {"id": "2106.04967", "submitter": "Jens Petersen", "authors": "Jens Petersen, Gregor K\\\"ohler, David Zimmerer, Fabian Isensee, Paul\n  F. J\\\"ager, Klaus H. Maier-Hein", "title": "GP-ConvCNP: Better Generalization for Convolutional Conditional Neural\n  Processes on Time Series Data", "comments": "UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Processes (NPs) are a family of conditional generative models that are\nable to model a distribution over functions, in a way that allows them to\nperform predictions at test time conditioned on a number of context points. A\nrecent addition to this family, Convolutional Conditional Neural Processes\n(ConvCNP), have shown remarkable improvement in performance over prior art, but\nwe find that they sometimes struggle to generalize when applied to time series\ndata. In particular, they are not robust to distribution shifts and fail to\nextrapolate observed patterns into the future. By incorporating a Gaussian\nProcess into the model, we are able to remedy this and at the same time improve\nperformance within distribution. As an added benefit, the Gaussian Process\nreintroduces the possibility to sample from the model, a key feature of other\nmembers in the NP family.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 10:26:39 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 13:46:13 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Petersen", "Jens", ""], ["K\u00f6hler", "Gregor", ""], ["Zimmerer", "David", ""], ["Isensee", "Fabian", ""], ["J\u00e4ger", "Paul F.", ""], ["Maier-Hein", "Klaus H.", ""]]}, {"id": "2106.04972", "submitter": "Tim Pearce", "authors": "Tim Pearce, Alexandra Brintrup, Jun Zhu", "title": "Understanding Softmax Confidence and Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often remarked that neural networks fail to increase their uncertainty\nwhen predicting on data far from the training distribution. Yet naively using\nsoftmax confidence as a proxy for uncertainty achieves modest success in tasks\nexclusively testing for this, e.g., out-of-distribution (OOD) detection. This\npaper investigates this contradiction, identifying two implicit biases that do\nencourage softmax confidence to correlate with epistemic uncertainty: 1)\nApproximately optimal decision boundary structure, and 2) Filtering effects of\ndeep networks. It describes why low-dimensional intuitions about softmax\nconfidence are misleading. Diagnostic experiments quantify reasons softmax\nconfidence can fail, finding that extrapolations are less to blame than overlap\nbetween training and OOD data in final-layer representations.\nPre-trained/fine-tuned networks reduce this overlap.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 10:37:29 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Pearce", "Tim", ""], ["Brintrup", "Alexandra", ""], ["Zhu", "Jun", ""]]}, {"id": "2106.04982", "submitter": "Riccardo Della Vecchia", "authors": "Tommaso R. Cesari, Riccardo Della Vecchia", "title": "Cooperative Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this preliminary (and unpolished) version of the paper, we study an\nasynchronous online learning setting with a network of agents. At each time\nstep, some of the agents are activated, requested to make a prediction, and pay\nthe corresponding loss. Some feedback is then revealed to these agents and is\nlater propagated through the network. We consider the case of full, bandit, and\nsemi-bandit feedback. In particular, we construct a reduction to delayed\nsingle-agent learning that applies to both the full and the bandit feedback\ncase and allows to obtain regret guarantees for both settings. We complement\nthese results with a near-matching lower bound.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 11:01:55 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 10:48:22 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Cesari", "Tommaso R.", ""], ["Della Vecchia", "Riccardo", ""]]}, {"id": "2106.05001", "submitter": "Mi Luo", "authors": "Mi Luo, Fei Chen, Dapeng Hu, Yifan Zhang, Jian Liang, Jiashi Feng", "title": "No Fear of Heterogeneity: Classifier Calibration for Federated Learning\n  with Non-IID Data", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge in training classification models in the real-world\nfederated system is learning with non-IID data. To cope with this, most of the\nexisting works involve enforcing regularization in local optimization or\nimproving the model aggregation scheme at the server. Other works also share\npublic datasets or synthesized samples to supplement the training of\nunder-represented classes or introduce a certain level of personalization.\nThough effective, they lack a deep understanding of how the data heterogeneity\naffects each layer of a deep classification model. In this paper, we bridge\nthis gap by performing an experimental analysis of the representations learned\nby different layers. Our observations are surprising: (1) there exists a\ngreater bias in the classifier than other layers, and (2) the classification\nperformance can be significantly improved by post-calibrating the classifier\nafter federated training. Motivated by the above findings, we propose a novel\nand simple algorithm called Classifier Calibration with Virtual Representations\n(CCVR), which adjusts the classifier using virtual representations sampled from\nan approximated gaussian mixture model. Experimental results demonstrate that\nCCVR achieves state-of-the-art performance on popular federated learning\nbenchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple\nyet effective method can shed some light on the future research of federated\nlearning with non-IID data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 12:02:29 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Luo", "Mi", ""], ["Chen", "Fei", ""], ["Hu", "Dapeng", ""], ["Zhang", "Yifan", ""], ["Liang", "Jian", ""], ["Feng", "Jiashi", ""]]}, {"id": "2106.05010", "submitter": "Futoshi Futami", "authors": "Futoshi Futami, Tomoharu Iwata, Naonori Ueda, Issei Sato, and Masashi\n  Sugiyama", "title": "Loss function based second-order Jensen inequality and its application\n  to particle variational inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian model averaging, obtained as the expectation of a likelihood\nfunction by a posterior distribution, has been widely used for prediction,\nevaluation of uncertainty, and model selection. Various approaches have been\ndeveloped to efficiently capture the information in the posterior distribution;\none such approach is the optimization of a set of models simultaneously with\ninteraction to ensure the diversity of the individual models in the same way as\nensemble learning. A representative approach is particle variational inference\n(PVI), which uses an ensemble of models as an empirical approximation for the\nposterior distribution. PVI iteratively updates each model with a repulsion\nforce to ensure the diversity of the optimized models. However, despite its\npromising performance, a theoretical understanding of this repulsion and its\nassociation with the generalization ability remains unclear. In this paper, we\ntackle this problem in light of PAC-Bayesian analysis. First, we provide a new\nsecond-order Jensen inequality, which has the repulsion term based on the loss\nfunction. Thanks to the repulsion term, it is tighter than the standard Jensen\ninequality. Then, we derive a novel generalization error bound and show that it\ncan be reduced by enhancing the diversity of models. Finally, we derive a new\nPVI that optimizes the generalization error bound directly. Numerical\nexperiments demonstrate that the performance of the proposed PVI compares\nfavorably with existing methods in the experiment.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 12:13:51 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 00:43:30 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Futami", "Futoshi", ""], ["Iwata", "Tomoharu", ""], ["Ueda", "Naonori", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2106.05031", "submitter": "Shosei Sakaguchi", "authors": "Shosei Sakaguchi", "title": "Estimation of Optimal Dynamic Treatment Assignment Rules under Policy\n  Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies statistical decisions for dynamic treatment assignment\nproblems. Many policies involve dynamics in their treatment assignments where\ntreatments are sequentially assigned to individuals across multiple stages and\nthe effect of treatment at each stage is usually heterogeneous with respect to\nthe prior treatments, past outcomes, and observed covariates. We consider\nestimating an optimal dynamic treatment rule that guides the optimal treatment\nassignment for each individual at each stage based on the individual's history.\nThis paper proposes an empirical welfare maximization approach in a dynamic\nframework. The approach estimates the optimal dynamic treatment rule from panel\ndata taken from an experimental or quasi-experimental study. The paper proposes\ntwo estimation methods: one solves the treatment assignment problem at each\nstage through backward induction, and the other solves the whole dynamic\ntreatment assignment problem simultaneously across all stages. We derive\nfinite-sample upper bounds on the worst-case average welfare-regrets for the\nproposed methods and show $n^{-1/2}$-minimax convergence rates. We also modify\nthe simultaneous estimation method to incorporate intertemporal budget/capacity\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 12:42:53 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 17:14:06 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sakaguchi", "Shosei", ""]]}, {"id": "2106.05042", "submitter": "Margarita Vinaroz", "authors": "Mijung Park, Margarita Vinaroz, Mohammad-Amin Charusaie, Frederik\n  Harder", "title": "Polynomial magic! Hermite polynomials for private data generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel mean embedding is a useful tool to compare probability measures.\nDespite its usefulness, kernel mean embedding considers infinite-dimensional\nfeatures, which are challenging to handle in the context of differentially\nprivate data generation. A recent work proposes to approximate the kernel mean\nembedding of data distribution using finite-dimensional random features, where\nthe sensitivity of the features becomes analytically tractable. More\nimportantly, this approach significantly reduces the privacy cost, compared to\nother known privatization methods (e.g., DP-SGD), as the approximate kernel\nmean embedding of the data distribution is privatized only once and can then be\nrepeatedly used during training of a generator without incurring any further\nprivacy cost. However, the required number of random features is excessively\nhigh, often ten thousand to a hundred thousand, which worsens the sensitivity\nof the approximate kernel mean embedding. To improve the sensitivity, we\npropose to replace random features with Hermite polynomial features. Unlike the\nrandom features, the Hermite polynomial features are ordered, where the\nfeatures at the low orders contain more information on the distribution than\nthose at the high orders. Hence, a relatively low order of Hermite polynomial\nfeatures can more accurately approximate the mean embedding of the data\ndistribution compared to a significantly higher number of random features. As a\nresult, using the Hermite polynomial features, we significantly improve the\nprivacy-accuracy trade-off, reflected in the high quality and diversity of the\ngenerated data, when tested on several heterogeneous tabular datasets, as well\nas several image benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 12:56:41 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Park", "Mijung", ""], ["Vinaroz", "Margarita", ""], ["Charusaie", "Mohammad-Amin", ""], ["Harder", "Frederik", ""]]}, {"id": "2106.05061", "submitter": "Firas Jarboui", "authors": "Firas Jarboui, Viannet Perchet", "title": "Quickest change detection with unknown parameters: Constant complexity\n  and near optimality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quickest change detection problem where both the parameters\nof pre- and post- change distributions are unknown, which prevents the use of\nclassical simple hypothesis testing. Without additional assumptions, optimal\nsolutions are not tractable as they rely on some minimax and robust variant of\nthe objective. As a consequence, change points might be detected too late for\npractical applications (in economics, health care or maintenance for instance).\nAvailable constant complexity techniques typically solve a relaxed version of\nthe problem, deeply relying on very specific probability distributions and/or\nsome very precise additional knowledge. We consider a totally different\napproach that leverages the theoretical asymptotic properties of optimal\nsolutions to derive a new scalable approximate algorithm with near optimal\nperformance that runs~in~$\\mathcal{O}(1)$, adapted to even more complex\nMarkovian settings.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 13:29:26 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Jarboui", "Firas", ""], ["Perchet", "Viannet", ""]]}, {"id": "2106.05109", "submitter": "Daniel Frisch", "authors": "Daniel Frisch and Uwe D. Hanebeck", "title": "Gaussian Mixture Estimation from Weighted Samples", "comments": "7 pages, 2 (10) figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimating the parameters of a Gaussian mixture density with a\ngiven number of components best representing a given set of weighted samples.\nWe adopt a density interpretation of the samples by viewing them as a discrete\nDirac mixture density over a continuous domain with weighted components. Hence,\nGaussian mixture fitting is viewed as density re-approximation. In order to\nspeed up computation, an expectation-maximization method is proposed that\nproperly considers not only the sample locations, but also the corresponding\nweights. It is shown that methods from literature do not treat the weights\ncorrectly, resulting in wrong estimates. This is demonstrated with simple\ncounterexamples. The proposed method works in any number of dimensions with the\nsame computational load as standard Gaussian mixture estimators for unweighted\nsamples.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 14:38:46 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Frisch", "Daniel", ""], ["Hanebeck", "Uwe D.", ""]]}, {"id": "2106.05165", "submitter": "Yilin Zheng", "authors": "Semih Cayci, Yilin Zheng, Atilla Eryilmaz", "title": "A Lyapunov-Based Methodology for Constrained Optimization with Bandit\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a wide variety of applications including online advertising, contractual\nhiring, and wireless scheduling, the controller is constrained by a stringent\nbudget constraint on the available resources, which are consumed in a random\namount by each action, and a stochastic feasibility constraint that may impose\nimportant operational limitations on decision-making. In this work, we consider\na general model to address such problems, where each action returns a random\nreward, cost, and penalty from an unknown joint distribution, and the\ndecision-maker aims to maximize the total reward under a budget constraint $B$\non the total cost and a stochastic constraint on the time-average penalty. We\npropose a novel low-complexity algorithm based on Lyapunov optimization\nmethodology, named ${\\tt LyOn}$, and prove that it achieves $O(\\sqrt{B\\log B})$\nregret and $O(\\log B/B)$ constraint-violation. The low computational cost and\nsharp performance bounds of ${\\tt LyOn}$ suggest that Lyapunov-based algorithm\ndesign methodology can be effective in solving constrained bandit optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:12:07 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Cayci", "Semih", ""], ["Zheng", "Yilin", ""], ["Eryilmaz", "Atilla", ""]]}, {"id": "2106.05172", "submitter": "Bradley Price", "authors": "Ben Sherwood and Bradley S. Price", "title": "On the Use of Minimum Penalties in Statistical Learning", "comments": "35 pages 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern multivariate machine learning and statistical methodologies estimate\nparameters of interest while leveraging prior knowledge of the association\nbetween outcome variables. The methods that do allow for estimation of\nrelationships do so typically through an error covariance matrix in\nmultivariate regression which does not scale to other types of models. In this\narticle we proposed the MinPEN framework to simultaneously estimate regression\ncoefficients associated with the multivariate regression model and the\nrelationships between outcome variables using mild assumptions. The MinPen\nframework utilizes a novel penalty based on the minimum function to exploit\ndetected relationships between responses. An iterative algorithm that\ngeneralizes current state of the art methods is proposed as a solution to the\nnon-convex optimization that is required to obtain estimates. Theoretical\nresults such as high dimensional convergence rates, model selection\nconsistency, and a framework for post selection inference are provided. We\nextend the proposed MinPen framework to other exponential family loss\nfunctions, with a specific focus on multiple binomial responses. Tuning\nparameter selection is also addressed. Finally, simulations and two data\nexamples are presented to show the finite sample properties of this framework.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:15:46 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Sherwood", "Ben", ""], ["Price", "Bradley S.", ""]]}, {"id": "2106.05190", "submitter": "Thanh Binh Nguyen", "authors": "Thu Nguyen, Khoi Minh Nguyen-Duy, Duy Ho Minh Nguyen, Binh T. Nguyen,\n  and Bruce Alan Wade", "title": "DPER: Efficient Parameter Estimation for Randomly Missing Data", "comments": "28 pages, 3 tables, 40 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The missing data problem has been broadly studied in the last few decades and\nhas various applications in different areas such as statistics or\nbioinformatics. Even though many methods have been developed to tackle this\nchallenge, most of those are imputation techniques that require multiple\niterations through the data before yielding convergence. In addition, such\napproaches may introduce extra biases and noises to the estimated parameters.\nIn this work, we propose novel algorithms to find the maximum likelihood\nestimates (MLEs) for a one-class/multiple-class randomly missing data set under\nsome mild assumptions. As the computation is direct without any imputation, our\nalgorithms do not require multiple iterations through the data, thus promising\nto be less time-consuming than other methods while maintaining superior\nestimation performance. We validate these claims by empirical results on\nvarious data sets of different sizes and release all codes in a GitHub\nrepository to contribute to the research community related to this problem.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 16:37:48 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Nguyen", "Thu", ""], ["Nguyen-Duy", "Khoi Minh", ""], ["Nguyen", "Duy Ho Minh", ""], ["Nguyen", "Binh T.", ""], ["Wade", "Bruce Alan", ""]]}, {"id": "2106.05194", "submitter": "Yixuan He", "authors": "Yixuan He and Gesine Reinert and Mihai Cucuringu", "title": "DIGRAC: Digraph Clustering with Flow Imbalance", "comments": "33 pages (10 pages for main text)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Node clustering is a powerful tool in the analysis of networks. Here, we\nintroduce a graph neural network framework with a novel scalable Directed Mixed\nPath Aggregation(DIMPA) scheme to obtain node embeddings for directed networks\nin a self-supervised manner, including a novel probabilistic imbalance loss.\nThe method is end-to-end in combining embedding generation and clustering\nwithout an intermediate step. In contrast to standard approaches in the\nliterature, in this paper, directionality is not treated as a nuisance, but\nrather contains the main signal. In particular, we leverage the recently\nintroduced cut flow imbalance measure, which is tightly related to\ndirectionality; cut flow imbalance is optimized without resorting to spectral\nmethods or cluster labels. Experimental results on synthetic data, in the form\nof directed stochastic block models and real-world data at different scales,\ndemonstrate that our method attains state-of-the-art results on directed\nclustering, for a wide range of noise and sparsity levels, as well as graph\nstructures.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:33:13 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["He", "Yixuan", ""], ["Reinert", "Gesine", ""], ["Cucuringu", "Mihai", ""]]}, {"id": "2106.05200", "submitter": "Julius von K\\\"ugelgen", "authors": "Luigi Gresele, Julius von K\\\"ugelgen, Vincent Stimper, Bernhard\n  Sch\\\"olkopf, Michel Besserve", "title": "Independent mechanism analysis, a new concept?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis provides a principled framework for\nunsupervised representation learning, with solid theory on the identifiability\nof the latent code that generated the data, given only observations of mixtures\nthereof. Unfortunately, when the mixing is nonlinear, the model is provably\nnonidentifiable, since statistical independence alone does not sufficiently\nconstrain the problem. Identifiability can be recovered in settings where\nadditional, typically observed variables are included in the generative\nprocess. We investigate an alternative path and consider instead including\nassumptions reflecting the principle of independent causal mechanisms exploited\nin the field of causality. Specifically, our approach is motivated by thinking\nof each source as independently influencing the mixing process. This gives rise\nto a framework which we term independent mechanism analysis. We provide\ntheoretical and empirical evidence that our approach circumvents a number of\nnonidentifiability issues arising in nonlinear blind source separation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:45:00 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Gresele", "Luigi", ""], ["von K\u00fcgelgen", "Julius", ""], ["Stimper", "Vincent", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Besserve", "Michel", ""]]}, {"id": "2106.05203", "submitter": "Peter Richt\\'arik", "authors": "Peter Richt\\'arik and Igor Sokolov and Ilyas Fatkhullin", "title": "EF21: A New, Simpler, Theoretically Better, and Practically Faster Error\n  Feedback", "comments": "37 pages, 5 algorithms, 3 Theorems, 8 Lemmas, 15 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error feedback (EF), also known as error compensation, is an immensely\npopular convergence stabilization mechanism in the context of distributed\ntraining of supervised machine learning models enhanced by the use of\ncontractive communication compression mechanisms, such as Top-$k$. First\nproposed by Seide et al (2014) as a heuristic, EF resisted any theoretical\nunderstanding until recently [Stich et al., 2018, Alistarh et al., 2018].\nHowever, all existing analyses either i) apply to the single node setting only,\nii) rely on very strong and often unreasonable assumptions, such global\nboundedness of the gradients, or iterate-dependent assumptions that cannot be\nchecked a-priori and may not hold in practice, or iii) circumvent these issues\nvia the introduction of additional unbiased compressors, which increase the\ncommunication cost. In this work we fix all these deficiencies by proposing and\nanalyzing a new EF mechanism, which we call EF21, which consistently and\nsubstantially outperforms EF in practice. Our theoretical analysis relies on\nstandard assumptions only, works in the distributed heterogeneous data setting,\nand leads to better and more meaningful rates. In particular, we prove that\nEF21 enjoys a fast $O(1/T)$ convergence rate for smooth nonconvex problems,\nbeating the previous bound of $O(1/T^{2/3})$, which was shown a bounded\ngradients assumption. We further improve this to a fast linear rate for PL\nfunctions, which is the first linear convergence result for an EF-type method\nnot relying on unbiased compressors. Since EF has a large number of\napplications where it reigns supreme, we believe that our 2021 variant, EF21,\ncan a large impact on the practice of communication efficient distributed\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:45:53 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Richt\u00e1rik", "Peter", ""], ["Sokolov", "Igor", ""], ["Fatkhullin", "Ilyas", ""]]}, {"id": "2106.05232", "submitter": "Gowtham Raghunath Kurri", "authors": "Gowtham R. Kurri, Tyler Sypherd, and Lalitha Sankar", "title": "Realizing GANs via a Tunable Loss Function", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a tunable GAN, called $\\alpha$-GAN, parameterized by $\\alpha \\in\n(0,\\infty]$, which interpolates between various $f$-GANs and Integral\nProbability Metric based GANs (under constrained discriminator set). We\nconstruct $\\alpha$-GAN using a supervised loss function, namely, $\\alpha$-loss,\nwhich is a tunable loss function capturing several canonical losses. We show\nthat $\\alpha$-GAN is intimately related to the Arimoto divergence, which was\nfirst proposed by \\\"{O}sterriecher (1996), and later studied by Liese and Vajda\n(2006). We posit that the holistic understanding that $\\alpha$-GAN introduces\nwill have practical benefits of addressing both the issues of vanishing\ngradients and mode collapse.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 17:18:21 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kurri", "Gowtham R.", ""], ["Sypherd", "Tyler", ""], ["Sankar", "Lalitha", ""]]}, {"id": "2106.05233", "submitter": "Benjamin Walter", "authors": "Benjamin Walter", "title": "Analysis of convolutional neural network image classifiers in a\n  hierarchical max-pooling model with additional local pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification is considered, and a hierarchical max-pooling model with\nadditional local pooling is introduced. Here the additional local pooling\nenables the hierachical model to combine parts of the image which have a\nvariable relative distance towards each other. Various convolutional neural\nnetwork image classifiers are introduced and compared in view of their rate of\nconvergence. The finite sample size performance of the estimates is analyzed by\napplying them to simulated and real data.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 16:08:00 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Walter", "Benjamin", ""]]}, {"id": "2106.05238", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Brooks Paige", "title": "I Don't Need $\\mathbf{u}$: Identifiable Non-Linear ICA Without Side\n  Information", "comments": "11 pages plus appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a new approach for identifiable non-linear ICA\nmodels. Recently there has been a renaissance in identifiability results in\ndeep generative models, not least for non-linear ICA. These prior works,\nhowever, have assumed access to a sufficiently-informative auxiliary set of\nobservations, denoted $\\mathbf{u}$. We show here how identifiability can be\nobtained in the absence of this side-information, rendering possible\nfully-unsupervised identifiable non-linear ICA. While previous theoretical\nresults have established the impossibility of identifiable non-linear ICA in\nthe presence of infinitely-flexible universal function approximators, here we\nrely on the intrinsically-finite modelling capacity of any particular chosen\nparameterisation of a deep generative model. In particular, we focus on\ngenerative models which perform clustering in their latent space -- a model\nstructure which matches previous identifiable models, but with the learnt\nclustering providing a synthetic form of auxiliary information. We evaluate our\nproposals using VAEs, on synthetic and image datasets, and find that the\nlearned clusterings function effectively: deep generative models with latent\nclusterings are empirically identifiable, to the same degree as models which\nrely on side information.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 17:22:08 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Willetts", "Matthew", ""], ["Paige", "Brooks", ""]]}, {"id": "2106.05241", "submitter": "Fabian Falck", "authors": "Fabian Falck, Haoting Zhang, Matthew Willetts, George Nicholson,\n  Christopher Yau, Christopher C Holmes", "title": "Multi-Facet Clustering Variational Autoencoders", "comments": "main text: 15 pages, appendices: 33 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work in deep clustering focuses on finding a single partition of data.\nHowever, high-dimensional data, such as images, typically feature multiple\ninteresting characteristics one could cluster over. For example, images of\nobjects against a background could be clustered over the shape of the object\nand separately by the colour of the background. In this paper, we introduce\nMulti-Facet Clustering Variational Autoencoders (MFCVAE), a novel class of\nvariational autoencoders with a hierarchy of latent variables, each with a\nMixture-of-Gaussians prior, that learns multiple clusterings simultaneously,\nand is trained fully unsupervised and end-to-end. MFCVAE uses a\nprogressively-trained ladder architecture which leads to highly stable\nperformance. We provide novel theoretical results for optimising the ELBO\nanalytically with respect to the categorical variational posterior\ndistribution, and corrects earlier influential theoretical work. On image\nbenchmarks, we demonstrate that our approach separates out and clusters over\ndifferent aspects of the data in a disentangled manner. We also show other\nadvantages of our model: the compositionality of its latent space and that it\nprovides controlled generation of samples.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 17:36:38 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Falck", "Fabian", ""], ["Zhang", "Haoting", ""], ["Willetts", "Matthew", ""], ["Nicholson", "George", ""], ["Yau", "Christopher", ""], ["Holmes", "Christopher C", ""]]}, {"id": "2106.05251", "submitter": "Shujian Zhang", "authors": "Shujian Zhang, Xinjie Fan, Bo Chen, Mingyuan Zhou", "title": "Bayesian Attention Belief Networks", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention-based neural networks have achieved state-of-the-art results on a\nwide range of tasks. Most such models use deterministic attention while\nstochastic attention is less explored due to the optimization difficulties or\ncomplicated model design. This paper introduces Bayesian attention belief\nnetworks, which construct a decoder network by modeling unnormalized attention\nweights with a hierarchy of gamma distributions, and an encoder network by\nstacking Weibull distributions with a deterministic-upward-stochastic-downward\nstructure to approximate the posterior. The resulting auto-encoding networks\ncan be optimized in a differentiable way with a variational lower bound. It is\nsimple to convert any models with deterministic attention, including pretrained\nones, to the proposed Bayesian attention belief networks. On a variety of\nlanguage understanding tasks, we show that our method outperforms deterministic\nattention and state-of-the-art stochastic attention in accuracy, uncertainty\nestimation, generalization across domains, and robustness to adversarial\nattacks. We further demonstrate the general applicability of our method on\nneural machine translation and visual question answering, showing great\npotential of incorporating our method into various attention-related tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 17:46:22 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Zhang", "Shujian", ""], ["Fan", "Xinjie", ""], ["Chen", "Bo", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2106.05275", "submitter": "Brendan Ross", "authors": "Brendan Leigh Ross, Jesse C. Cresswell", "title": "Tractable Density Estimation on Learned Manifolds with Conformal\n  Embedding Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are generative models that provide tractable density\nestimation by transforming a simple base distribution into a complex target\ndistribution. However, this technique cannot directly model data supported on\nan unknown low-dimensional manifold, a common occurrence in real-world domains\nsuch as image data. Recent attempts to remedy this limitation have introduced\ngeometric complications that defeat a central benefit of normalizing flows:\nexact density estimation. We recover this benefit with Conformal Embedding\nFlows, a framework for designing flows that learn manifolds with tractable\ndensities. We argue that composing a standard flow with a trainable conformal\nembedding is the most natural way to model manifold-supported data. To this\nend, we present a series of conformal building blocks and apply them in\nexperiments with real-world and synthetic data to demonstrate that flows can\nmodel manifold-supported distributions without sacrificing tractable\nlikelihoods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 18:00:00 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Ross", "Brendan Leigh", ""], ["Cresswell", "Jesse C.", ""]]}, {"id": "2106.05319", "submitter": "Uiwon Hwang", "authors": "Uiwon Hwang, Heeseung Kim, Dahuin Jung, Hyemi Jang, Hyungyu Lee,\n  Sungroh Yoon", "title": "Stein Latent Optimization for GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) with clustered latent spaces can\nperform conditional generation in a completely unsupervised manner. However,\nthe salient attributes of unlabeled data in the real-world are mostly\nimbalanced. Existing unsupervised conditional GANs cannot properly cluster the\nattributes in their latent spaces because they assume uniform distributions of\nthe attributes. To address this problem, we theoretically derive Stein latent\noptimization that provides reparameterizable gradient estimations of the latent\ndistribution parameters assuming a Gaussian mixture prior in a continuous\nlatent space. Structurally, we introduce an encoder network and a novel\ncontrastive loss to help generated data from a single mixture component to\nrepresent a single attribute. We confirm that the proposed method, named Stein\nLatent Optimization for GANs (SLOGAN), successfully learns the balanced or\nimbalanced attributes and performs unsupervised tasks such as unsupervised\nconditional generation, unconditional generation, and cluster assignment even\nin the absence of information of the attributes (e.g. the imbalance ratio).\nMoreover, we demonstrate that the attributes to be learned can be manipulated\nusing a small amount of probe data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 18:15:30 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 04:10:53 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hwang", "Uiwon", ""], ["Kim", "Heeseung", ""], ["Jung", "Dahuin", ""], ["Jang", "Hyemi", ""], ["Lee", "Hyungyu", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2106.05367", "submitter": "Miguel Gonz\\'alez-Duque", "authors": "Georgios Arvanitidis, Miguel Gonz\\'alez-Duque, Alison Pouplin,\n  Dimitris Kalatzis, S{\\o}ren Hauberg", "title": "Pulling back information geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Latent space geometry has shown itself to provide a rich and rigorous\nframework for interacting with the latent variables of deep generative models.\nThe existing theory, however, relies on the decoder being a Gaussian\ndistribution as its simple reparametrization allows us to interpret the\ngenerating process as a random projection of a deterministic manifold.\nConsequently, this approach breaks down when applied to decoders that are not\nas easily reparametrized. We here propose to use the Fisher-Rao metric\nassociated with the space of decoder distributions as a reference metric, which\nwe pull back to the latent space. We show that we can achieve meaningful latent\ngeometries for a wide range of decoder distributions for which the previous\ntheory was not applicable, opening the door to `black box' latent geometries.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 20:16:28 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Arvanitidis", "Georgios", ""], ["Gonz\u00e1lez-Duque", "Miguel", ""], ["Pouplin", "Alison", ""], ["Kalatzis", "Dimitris", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "2106.05397", "submitter": "Lorenzo Rosasco", "authors": "Bernhard Stankewitz, Nicole M\\\"ucke, Lorenzo Rosasco", "title": "From inexact optimization to learning via gradient concentration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization was recently shown to control the inductive bias in a learning\nprocess, a property referred to as implicit, or iterative regularization. The\nestimator obtained iteratively minimizing the training error can generalise\nwell with no need of further penalties or constraints. In this paper, we\ninvestigate this phenomenon in the context of linear models with smooth loss\nfunctions. In particular, we investigate and propose a proof technique\ncombining ideas from inexact optimization and probability theory, specifically\ngradient concentration. The proof is easy to follow and allows to obtain sharp\nlearning bounds. More generally, it highlights a way to develop optimization\nresults into learning guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 21:23:29 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 20:11:34 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Stankewitz", "Bernhard", ""], ["M\u00fccke", "Nicole", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "2106.05414", "submitter": "Torsten Ensslin", "authors": "Torsten En{\\ss}lin, Viktoria Kainz, C\\'eline B{\\oe}hm", "title": "Theoretical Modeling of Communication Dynamics", "comments": "49 pages, 28 figures, 3 tables, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a cornerstone of social interactions, be it with human or\nartificial intelligence (AI). Yet it can be harmful, depending on the honesty\nof the exchanged information. To study this, an agent based sociological\nsimulation framework is presented, the reputation game. This illustrates the\nimpact of different communication strategies on the agents' reputation. The\ngame focuses on the trustworthiness of the participating agents, their honesty\nas perceived by others. In the game, each agent exchanges statements with the\nothers about their own and each other's honesty, which lets their judgments\nevolve. Various sender and receiver strategies are studied, like sycophant,\negocentricity, pathological lying, and aggressiveness for senders as well as\nawareness and lack thereof for receivers. Minimalist malicious strategies are\nidentified, like being manipulative, dominant, or destructive, which\nsignificantly increase reputation at others' costs. Phenomena such as echo\nchambers, self-deception, deception symbiosis, clique formation, freezing of\ngroup opinions emerge from the dynamics. This indicates that the reputation\ngame can be studied for complex group phenomena, to test behavioral hypothesis,\nand to analyze AI influenced social media. With refined rules it may help to\nunderstand social interactions, and to safeguard the design of non-abusive AI\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 22:02:19 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["En\u00dflin", "Torsten", ""], ["Kainz", "Viktoria", ""], ["B\u0153hm", "C\u00e9line", ""]]}, {"id": "2106.05459", "submitter": "Ilia Kulikov", "authors": "Ilia Kulikov, Sean Welleck, Kyunghyun Cho", "title": "Mode recovery in neural autoregressive sequence modeling", "comments": "ACL-IJCNLP 2021 5th Workshop on Structured Prediction for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite its wide use, recent studies have revealed unexpected and undesirable\nproperties of neural autoregressive sequence models trained with maximum\nlikelihood, such as an unreasonably high affinity to short sequences after\ntraining and to infinitely long sequences at decoding time. We propose to study\nthese phenomena by investigating how the modes, or local maxima, of a\ndistribution are maintained throughout the full learning chain of the\nground-truth, empirical, learned and decoding-induced distributions, via the\nnewly proposed mode recovery cost. We design a tractable testbed where we build\nthree types of ground-truth distributions: (1) an LSTM based structured\ndistribution, (2) an unstructured distribution where probability of a sequence\ndoes not depend on its content, and (3) a product of these two which we call a\nsemi-structured distribution. Our study reveals both expected and unexpected\nfindings. First, starting with data collection, mode recovery cost strongly\nrelies on the ground-truth distribution and is most costly with the\nsemi-structured distribution. Second, after learning, mode recovery cost from\nthe ground-truth distribution may increase or decrease compared to data\ncollection, with the largest cost degradation occurring with the\nsemi-structured ground-truth distribution. Finally, the ability of the\ndecoding-induced distribution to recover modes from the learned distribution is\nhighly impacted by the choices made earlier in the learning chain. We conclude\nthat future research must consider the entire learning chain in order to fully\nunderstand the potentials and perils and to further improve neural\nautoregressive sequence models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 02:17:28 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kulikov", "Ilia", ""], ["Welleck", "Sean", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2106.05472", "submitter": "Zengjing Chen", "authors": "Zengjing Chen, Larry G. Epstein, Guodong Zhang", "title": "A Central Limit Theorem, Loss Aversion and Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG econ.TH stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a central limit theorem under the assumption that\nconditional variances can vary in a largely unstructured history-dependent way\nacross experiments subject only to the restriction that they lie in a fixed\ninterval. Limits take a novel and tractable form, and are expressed in terms of\noscillating Brownian motion. A second contribution is application of this\nresult to a class of multi-armed bandit problems where the decision-maker is\nloss averse.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 03:15:11 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Chen", "Zengjing", ""], ["Epstein", "Larry G.", ""], ["Zhang", "Guodong", ""]]}, {"id": "2106.05480", "submitter": "Kevin Tian", "authors": "Yin Tat Lee, Ruoqi Shen, Kevin Tian", "title": "Lower Bounds on Metropolized Sampling Methods for Well-Conditioned\n  Distributions", "comments": "47 pages, 1 figure, comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give lower bounds on the performance of two of the most popular sampling\nmethods in practice, the Metropolis-adjusted Langevin algorithm (MALA) and\nmulti-step Hamiltonian Monte Carlo (HMC) with a leapfrog integrator, when\napplied to well-conditioned distributions. Our main result is a nearly-tight\nlower bound of $\\widetilde{\\Omega}(\\kappa d)$ on the mixing time of MALA from\nan exponentially warm start, matching a line of algorithmic results up to\nlogarithmic factors and answering an open question of Chewi et. al. We also\nshow that a polynomial dependence on dimension is necessary for the relaxation\ntime of HMC under any number of leapfrog steps, and bound the gains achievable\nby changing the step count. Our HMC analysis draws upon a novel connection\nbetween leapfrog integration and Chebyshev polynomials, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 03:47:39 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Lee", "Yin Tat", ""], ["Shen", "Ruoqi", ""], ["Tian", "Kevin", ""]]}, {"id": "2106.05515", "submitter": "Yu Bai", "authors": "Yu Bai, Song Mei, Huan Wang, Caiming Xiong", "title": "Understanding the Under-Coverage Bias in Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the data uncertainty in regression tasks is often done by learning\na quantile function or a prediction interval of the true label conditioned on\nthe input. It is frequently observed that quantile regression -- a vanilla\nalgorithm for learning quantiles with asymptotic guarantees -- tends to\n\\emph{under-cover} than the desired coverage level in reality. While various\nfixes have been proposed, a more fundamental understanding of why this\nunder-coverage bias happens in the first place remains elusive.\n  In this paper, we present a rigorous theoretical study on the coverage of\nuncertainty estimation algorithms in learning quantiles. We prove that quantile\nregression suffers from an inherent under-coverage bias, in a vanilla setting\nwhere we learn a realizable linear quantile function and there is more data\nthan parameters. More quantitatively, for $\\alpha>0.5$ and small $d/n$, the\n$\\alpha$-quantile learned by quantile regression roughly achieves coverage\n$\\alpha - (\\alpha-1/2)\\cdot d/n$ regardless of the noise distribution, where\n$d$ is the input dimension and $n$ is the number of training data. Our theory\nreveals that this under-coverage bias stems from a certain high-dimensional\nparameter estimation error that is not implied by existing theories on quantile\nregression. Experiments on simulated and real data verify our theory and\nfurther illustrate the effect of various factors such as sample size and model\ncapacity on the under-coverage bias in more practical setups.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:11:55 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Bai", "Yu", ""], ["Mei", "Song", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""]]}, {"id": "2106.05521", "submitter": "Michael Thrun PhD", "authors": "Michael C. Thrun and Alfred Ultsch", "title": "Swarm Intelligence for Self-Organized Clustering", "comments": "54 pages, 21 figures", "journal-ref": "Artificial intelligence, Vol. 290, pp. 103237. 2021", "doi": "10.1016/j.artint.2020.103237", "report-no": null, "categories": "cs.NE cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms implementing populations of agents which interact with one another\nand sense their environment may exhibit emergent behavior such as\nself-organization and swarm intelligence. Here a swarm system, called\nDatabionic swarm (DBS), is introduced which is able to adapt itself to\nstructures of high-dimensional data characterized by distance and/or\ndensity-based structures in the data space. By exploiting the interrelations of\nswarm intelligence, self-organization and emergence, DBS serves as an\nalternative approach to the optimization of a global objective function in the\ntask of clustering. The swarm omits the usage of a global objective function\nand is parameter-free because it searches for the Nash equilibrium during its\nannealing process. To our knowledge, DBS is the first swarm combining these\napproaches. Its clustering can outperform common clustering methods such as\nK-means, PAM, single linkage, spectral clustering, model-based clustering, and\nWard, if no prior knowledge about the data is available. A central problem in\nclustering is the correct estimation of the number of clusters. This is\naddressed by a DBS visualization called topographic map which allows assessing\nthe number of clusters. It is known that all clustering algorithms construct\nclusters, irrespective of the data set contains clusters or not. In contrast to\nmost other clustering algorithms, the topographic map identifies, that\nclustering of the data is meaningless if the data contains no (natural)\nclusters. The performance of DBS is demonstrated on a set of benchmark data,\nwhich are constructed to pose difficult clustering problems and in two\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:21:48 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Thrun", "Michael C.", ""], ["Ultsch", "Alfred", ""]]}, {"id": "2106.05527", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, Il-Chul Moon", "title": "Score Matching Model for Unbounded Data Score", "comments": "24 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advance in score-based models incorporates the stochastic differential\nequation (SDE), which brings the state-of-the art performance on image\ngeneration tasks. This paper improves such score-based models by analyzing the\nmodel at the zero perturbation noise. In real datasets, the score function\ndiverges as the perturbation noise ($\\sigma$) decreases to zero, and this\nobservation leads an argument that the score estimation fails at $\\sigma=0$\nwith any neural network structure. Subsequently, we introduce Unbounded Noise\nConditional Score Network (UNCSN) that resolves the score diverging problem\nwith an easily applicable modification to any noise conditional score-based\nmodels. Additionally, we introduce a new type of SDE, so the exact log\nlikelihood can be calculated from the newly suggested SDE. On top of that, the\nassociated loss function mitigates the loss imbalance issue in a mini-batch,\nand we present a theoretic analysis on the proposed loss to uncover the behind\nmechanism of the data distribution modeling by the score-based models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:30:16 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kim", "Dongjun", ""], ["Shin", "Seungjae", ""], ["Song", "Kyungwoo", ""], ["Kang", "Wanmo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2106.05536", "submitter": "Johann Pfitzinger", "authors": "Johann Pfitzinger", "title": "An Interpretable Neural Network for Parameter Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adoption of deep neural networks in fields such as economics or finance has\nbeen constrained by the lack of interpretability of model outcomes. This paper\nproposes a generative neural network architecture - the parameter encoder\nneural network (PENN) - capable of estimating local posterior distributions for\nthe parameters of a regression model. The parameters fully explain predictions\nin terms of the inputs and permit visualization, interpretation and inference\nin the presence of complex heterogeneous effects and feature dependencies. The\nuse of Bayesian inference techniques offers an intuitive mechanism to\nregularize local parameter estimates towards a stable solution, and to reduce\nnoise-fitting in settings of limited data availability. The proposed neural\nnetwork is particularly well-suited to applications in economics and finance,\nwhere parameter inference plays an important role. An application to an asset\npricing problem demonstrates how the PENN can be used to explore nonlinear risk\ndynamics in financial markets, and to compare empirical nonlinear effects to\nbehavior posited by financial theory.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:56:01 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Pfitzinger", "Johann", ""]]}, {"id": "2106.05565", "submitter": "Quanjun Lang", "authors": "Quanjun Lang and Fei Lu", "title": "Identifiability of interaction kernels in mean-field equations of\n  interacting particles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the identifiability of the interaction kernels in mean-field\nequations for intreacting particle systems. The key is to identify function\nspaces on which a probabilistic loss functional has a unique minimizer. We\nprove that identifiability holds on any subspace of two reproducing kernel\nHilbert spaces (RKHS), whose reproducing kernels are intrinsic to the system\nand are data-adaptive. Furthermore, identifiability holds on two ambient L2\nspaces if and only if the integral operators associated with the reproducing\nkernels are strictly positive. Thus, the inverse problem is ill-posed in\ngeneral. We also discuss the implications of identifiability in computational\npractice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 07:45:48 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Lang", "Quanjun", ""], ["Lu", "Fei", ""]]}, {"id": "2106.05566", "submitter": "Jean-Yves Franceschi", "authors": "Jean-Yves Franceschi (MLIA), Emmanuel de B\\'ezenac (MLIA), Ibrahim\n  Ayed (MLIA), Micka\\\"el Chen, Sylvain Lamprier (MLIA), Patrick Gallinari\n  (MLIA)", "title": "A Neural Tangent Kernel Perspective of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical analyses for Generative Adversarial Networks (GANs) generally\nassume an arbitrarily large family of discriminators and do not consider the\ncharacteristics of the architectures used in practice. We show that this\nframework of analysis is too simplistic to properly analyze GAN training. To\ntackle this issue, we leverage the theory of infinite-width neural networks to\nmodel neural discriminator training for a wide range of adversarial losses via\nits Neural Tangent Kernel (NTK). Our analytical results show that GAN\ntrainability primarily depends on the discriminator's architecture. We further\nstudy the discriminator for specific architectures and losses, and highlight\nproperties providing a new understanding of GAN training. For example, we find\nthat GANs trained with the integral probability metric loss minimize the\nmaximum mean discrepancy with the NTK as kernel. Our conclusions demonstrate\nthe analysis opportunities provided by the proposed framework, which paves the\nway for better and more principled GAN models. We release a generic GAN\nanalysis toolkit based on our framework that supports the empirical part of our\nstudy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 07:46:02 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Franceschi", "Jean-Yves", "", "MLIA"], ["de B\u00e9zenac", "Emmanuel", "", "MLIA"], ["Ayed", "Ibrahim", "", "MLIA"], ["Chen", "Micka\u00ebl", "", "MLIA"], ["Lamprier", "Sylvain", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2106.05582", "submitter": "Magnus Ross", "authors": "Magnus Ross, Michael T. Smith, Mauricio A. \\'Alvarez", "title": "Learning Nonparametric Volterra Kernels with Gaussian Processes", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a method for the nonparametric Bayesian learning of\nnonlinear operators, through the use of the Volterra series with kernels\nrepresented using Gaussian processes (GPs), which we term the nonparametric\nVolterra kernels model (NVKM). When the input function to the operator is\nunobserved and has a GP prior, the NVKM constitutes a powerful method for both\nsingle and multiple output regression, and can be viewed as a nonlinear and\nnonparametric latent force model. When the input function is observed, the NVKM\ncan be used to perform Bayesian system identification. We use recent advances\nin efficient sampling of explicit functions from GPs to map process\nrealisations through the Volterra series without resorting to numerical\nintegration, allowing scalability through doubly stochastic variational\ninference, and avoiding the need for Gaussian approximations of the output\nprocesses. We demonstrate the performance of the model for both multiple output\nregression and system identification using standard benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 08:21:00 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Ross", "Magnus", ""], ["Smith", "Michael T.", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "2106.05586", "submitter": "Laurence Aitchison", "authors": "Seth Nabarro, Stoil Ganev, Adri\\`a Garriga-Alonso, Vincent Fortuin,\n  Mark van der Wilk and Laurence Aitchison", "title": "Data augmentation in Bayesian neural networks and the cold posterior\n  effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a highly effective approach for improving performance in\ndeep neural networks. The standard view is that it creates an enlarged dataset\nby adding synthetic data, which raises a problem when combining it with\nBayesian inference: how much data are we really conditioning on? This question\nis particularly relevant to recent observations linking data augmentation to\nthe cold posterior effect. We investigate various principled ways of finding a\nlog-likelihood for augmented datasets. Our approach prescribes augmenting the\nsame underlying image multiple times, both at test and train-time, and\naveraging either the logits or the predictive probabilities. Empirically, we\nobserve the best performance with averaging probabilities. While there are\ninteractions with the cold posterior effect, neither averaging logits or\naveraging probabilities eliminates it.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 08:39:10 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Nabarro", "Seth", ""], ["Ganev", "Stoil", ""], ["Garriga-Alonso", "Adri\u00e0", ""], ["Fortuin", "Vincent", ""], ["van der Wilk", "Mark", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2106.05608", "submitter": "Joey Hong", "authors": "Joey Hong, Branislav Kveton, Manzil Zaheer, Mohammad Ghavamzadeh,\n  Craig Boutilier", "title": "Thompson Sampling with a Mixture Prior", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study Thompson sampling (TS) in online decision-making problems where the\nuncertain environment is sampled from a mixture distribution. This is relevant\nto multi-task settings, where a learning agent is faced with different classes\nof problems. We incorporate this structure in a natural way by initializing TS\nwith a mixture prior -- dubbed MixTS -- and develop a novel, general technique\nfor analyzing the regret of TS with such priors. We apply this technique to\nderive Bayes regret bounds for MixTS in both linear bandits and tabular Markov\ndecision processes (MDPs). Our regret bounds reflect the structure of the\nproblem and depend on the number of components and confidence width of each\ncomponent of the prior. Finally, we demonstrate the empirical effectiveness of\nMixTS in both synthetic and real-world experiments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 09:21:07 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Hong", "Joey", ""], ["Kveton", "Branislav", ""], ["Zaheer", "Manzil", ""], ["Ghavamzadeh", "Mohammad", ""], ["Boutilier", "Craig", ""]]}, {"id": "2106.05658", "submitter": "Tianlin Xu", "authors": "Tianlin Xu and Beatrice Acciaio", "title": "Quantized Conditional COT-GAN for Video Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal Optimal Transport (COT) results from imposing a temporal causality\nconstraint on classic optimal transport problems, which naturally generates a\nnew concept of distances between distributions on path spaces. The first\napplication of the COT theory for sequential learning was given in Xu et al.\n(2020), where COT-GAN was introduced as an adversarial algorithm to train\nimplicit generative models optimized for producing sequential data. Relying on\nXu et al. (2020), the contribution of the present paper is twofold. First, we\ndevelop a conditional version of COT-GAN suitable for sequence prediction. This\nmeans that the dataset is now used in order to learn how a sequence will evolve\ngiven the observation of its past evolution. Second, we improve on the\nconvergence results by working with modifications of the empirical measures via\na specific type of quantization due to Backhoff et al. (2020). The resulting\nquantized conditional COT-GAN algorithm is illustrated with an application for\nvideo prediction.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 11:10:53 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Xu", "Tianlin", ""], ["Acciaio", "Beatrice", ""]]}, {"id": "2106.05710", "submitter": "Benjamin Dupuis", "authors": "Benjamin Dupuis and Arthur Jacot", "title": "DNN-Based Topology Optimisation: Spatial Invariance and Neural Tangent\n  Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the SIMP method with a density field generated by a fully-connected\nneural network, taking the coordinates as inputs. In the large width limit, we\nshow that the use of DNNs leads to a filtering effect similar to traditional\nfiltering techniques for SIMP, with a filter described by the Neural Tangent\nKernel (NTK). This filter is however not invariant under translation, leading\nto visual artifacts and non-optimal shapes. We propose two embeddings of the\ninput coordinates, which lead to (approximate) spatial invariance of the NTK\nand of the filter. We empirically confirm our theoretical observations and\nstudy how the filter size is affected by the architecture of the network. Our\nsolution can easily be applied to any other coordinates-based generation\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 12:49:55 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Dupuis", "Benjamin", ""], ["Jacot", "Arthur", ""]]}, {"id": "2106.05738", "submitter": "Jingyi Cui", "authors": "Jingyi Cui, Hanyuan Hang, Yisen Wang, Zhouchen Lin", "title": "GBHT: Gradient Boosting Histogram Transform for Density Estimation", "comments": "Accepted to ICML2021. arXiv admin note: text overlap with\n  arXiv:2106.01986", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a density estimation algorithm called\n\\textit{Gradient Boosting Histogram Transform} (GBHT), where we adopt the\n\\textit{Negative Log Likelihood} as the loss function to make the boosting\nprocedure available for the unsupervised tasks. From a learning theory\nviewpoint, we first prove fast convergence rates for GBHT with the smoothness\nassumption that the underlying density function lies in the space\n$C^{0,\\alpha}$. Then when the target density function lies in spaces\n$C^{1,\\alpha}$, we present an upper bound for GBHT which is smaller than the\nlower bound of its corresponding base learner, in the sense of convergence\nrates. To the best of our knowledge, we make the first attempt to theoretically\nexplain why boosting can enhance the performance of its base learners for\ndensity estimation problems. In experiments, we not only conduct performance\ncomparisons with the widely used KDE, but also apply GBHT to anomaly detection\nto showcase a further application of GBHT.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:40:28 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Cui", "Jingyi", ""], ["Hang", "Hanyuan", ""], ["Wang", "Yisen", ""], ["Lin", "Zhouchen", ""]]}, {"id": "2106.05739", "submitter": "Carles Domingo-Enrich", "authors": "Carles Domingo-Enrich, Youssef Mroueh", "title": "Separation Results between Fixed-Kernel and Feature-Learning Probability\n  Metrics", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works in implicit and explicit generative modeling empirically\nobserved that feature-learning discriminators outperform fixed-kernel\ndiscriminators in terms of the sample quality of the models. We provide\nseparation results between probability metrics with fixed-kernel and\nfeature-learning discriminators using the function classes $\\mathcal{F}_2$ and\n$\\mathcal{F}_1$ respectively, which were developed to study overparametrized\ntwo-layer neural networks. In particular, we construct pairs of distributions\nover hyper-spheres that can not be discriminated by fixed kernel\n$(\\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD)\nin high dimensions, but that can be discriminated by their feature learning\n($\\mathcal{F}_1$) counterparts. To further study the separation we provide\nlinks between the $\\mathcal{F}_1$ and $\\mathcal{F}_2$ IPMs with sliced\nWasserstein distances. Our work suggests that fixed-kernel discriminators\nperform worse than their feature learning counterparts because their\ncorresponding metrics are weaker.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:41:33 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 19:47:34 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 18:49:24 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Domingo-Enrich", "Carles", ""], ["Mroueh", "Youssef", ""]]}, {"id": "2106.05763", "submitter": "Ricards Marcinkevics", "authors": "Laura Manduchi, Ri\\v{c}ards Marcinkevi\\v{c}s, Michela C. Massi, Verena\n  Gotta, Timothy M\\\"uller, Flavio Vasella, Marian C. Neidert, Marc Pfister and\n  Julia E. Vogt", "title": "A Deep Variational Approach to Clustering Survival Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Survival analysis has gained significant attention in the medical domain and\nhas many far-reaching applications. Although a variety of machine learning\nmethods have been introduced for tackling time-to-event prediction in\nunstructured data with complex dependencies, clustering of survival data\nremains an under-explored problem. The latter is particularly helpful in\ndiscovering patient subpopulations whose survival is regulated by different\ngenerative mechanisms, a critical problem in precision medicine. To this end,\nwe introduce a novel probabilistic approach to cluster survival data in a\nvariational deep clustering setting. Our proposed method employs a deep\ngenerative model to uncover the underlying distribution of both the explanatory\nvariables and the potentially censored survival times. We compare our model to\nthe related work on survival clustering in comprehensive experiments on a range\nof synthetic, semi-synthetic, and real-world datasets. Our proposed method\nperforms better at identifying clusters and is competitive at predicting\nsurvival times in terms of the concordance index and relative absolute error.\nTo further demonstrate the usefulness of our approach, we show that our method\nidentifies meaningful clusters from an observational cohort of hemodialysis\npatients that are consistent with previous clinical findings.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:10:25 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Manduchi", "Laura", ""], ["Marcinkevi\u010ds", "Ri\u010dards", ""], ["Massi", "Michela C.", ""], ["Gotta", "Verena", ""], ["M\u00fcller", "Timothy", ""], ["Vasella", "Flavio", ""], ["Neidert", "Marian C.", ""], ["Pfister", "Marc", ""], ["Vogt", "Julia E.", ""]]}, {"id": "2106.05767", "submitter": "Pieter Gijsbers", "authors": "Pieter Gijsbers, Florian Pfisterer, Jan N. van Rijn, Bernd Bischl and\n  Joaquin Vanschoren", "title": "Meta-Learning for Symbolic Hyperparameter Defaults", "comments": "Pieter Gijsbers and Florian Pfisterer contributed equally to the\n  paper. V1: Two page GECCO poster paper accepted at GECCO 2021. V2: The\n  original full length paper (8 pages) with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization in machine learning (ML) deals with the problem\nof empirically learning an optimal algorithm configuration from data, usually\nformulated as a black-box optimization problem. In this work, we propose a\nzero-shot method to meta-learn symbolic default hyperparameter configurations\nthat are expressed in terms of the properties of the dataset. This enables a\nmuch faster, but still data-dependent, configuration of the ML algorithm,\ncompared to standard hyperparameter optimization approaches. In the past,\nsymbolic and static default values have usually been obtained as hand-crafted\nheuristics. We propose an approach of learning such symbolic configurations as\nformulas of dataset properties from a large set of prior evaluations on\nmultiple datasets by optimizing over a grammar of expressions using an\nevolutionary algorithm. We evaluate our method on surrogate empirical\nperformance models as well as on real data across 6 ML algorithms on more than\n100 datasets and demonstrate that our method indeed finds viable symbolic\ndefaults.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 14:20:28 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 08:55:58 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Gijsbers", "Pieter", ""], ["Pfisterer", "Florian", ""], ["van Rijn", "Jan N.", ""], ["Bischl", "Bernd", ""], ["Vanschoren", "Joaquin", ""]]}, {"id": "2106.05797", "submitter": "Mike Li", "authors": "Paul Glasserman, Mike Li", "title": "Linear Classifiers Under Infinite Imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.RM stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the behavior of linear discriminant functions for binary\nclassification in the infinite-imbalance limit, where the sample size of one\nclass grows without bound while the sample size of the other remains fixed. The\ncoefficients of the classifier minimize an expected loss specified through a\nweight function. We show that for a broad class of weight functions, the\nintercept diverges but the rest of the coefficient vector has a finite limit\nunder infinite imbalance, extending prior work on logistic regression. The\nlimit depends on the left tail of the weight function, for which we distinguish\nthree cases: bounded, asymptotically polynomial, and asymptotically\nexponential. The limiting coefficient vectors reflect robustness or\nconservatism properties in the sense that they optimize against certain\nworst-case alternatives. In the bounded and polynomial cases, the limit is\nequivalent to an implicit choice of upsampling distribution for the minority\nclass. We apply these ideas in a credit risk setting, with particular emphasis\non performance in the high-sensitivity and high-specificity regions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:01:54 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Glasserman", "Paul", ""], ["Li", "Mike", ""]]}, {"id": "2106.05807", "submitter": "Minh-Ngoc Tran", "authors": "Anna Lopatnikova and Minh-Ngoc Tran", "title": "Quantum Natural Gradient for Variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational Bayes (VB) is a critical method in machine learning and\nstatistics, underpinning the recent success of Bayesian deep learning. The\nnatural gradient is an essential component of efficient VB estimation, but it\nis prohibitively computationally expensive in high dimensions. We propose a\nhybrid quantum-classical algorithm to improve the scaling properties of natural\ngradient computation and make VB a truly computationally efficient method for\nBayesian inference in highdimensional settings. The algorithm leverages matrix\ninversion from the linear systems algorithm by Harrow, Hassidim, and Lloyd\n[Phys. Rev. Lett. 103, 15 (2009)] (HHL). We demonstrate that the matrix to be\ninverted is sparse and the classical-quantum-classical handoffs are\nsufficiently economical to preserve computational efficiency, making the\nproblem of natural gradient for VB an ideal application of HHL. We prove that,\nunder standard conditions, the VB algorithm with quantum natural gradient is\nguaranteed to converge. Our regression-based natural gradient formulation is\nalso highly useful for classical VB.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:15:07 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 16:46:58 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lopatnikova", "Anna", ""], ["Tran", "Minh-Ngoc", ""]]}, {"id": "2106.05810", "submitter": "Xavier Renard", "authors": "Rafael Poyiadzi, Xavier Renard, Thibault Laugel, Raul\n  Santos-Rodriguez, Marcin Detyniecki", "title": "On the overlooked issue of defining explanation objectives for\n  local-surrogate explainers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local surrogate approaches for explaining machine learning model predictions\nhave appealing properties, such as being model-agnostic and flexible in their\nmodelling. Several methods exist that fit this description and share this goal.\nHowever, despite their shared overall procedure, they set out different\nobjectives, extract different information from the black-box, and consequently\nproduce diverse explanations, that are -- in general -- incomparable. In this\nwork we review the similarities and differences amongst multiple methods, with\na particular focus on what information they extract from the model, as this has\nlarge impact on the output: the explanation. We discuss the implications of the\nlack of agreement, and clarity, amongst the methods' objectives on the research\nand practice of explainability.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:24:49 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Renard", "Xavier", ""], ["Laugel", "Thibault", ""], ["Santos-Rodriguez", "Raul", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2106.05824", "submitter": "Bruno Sudret", "authors": "P.-R. Wagner, S. Marelli, I. Papaioannou, D. Straub, B. Sudret", "title": "Rare event estimation using stochastic spectral embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": "RSUQ-2021-003", "categories": "cs.LG stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the probability of rare failure events is an essential step in the\nreliability assessment of engineering systems. Computing this failure\nprobability for complex non-linear systems is challenging, and has recently\nspurred the development of active-learning reliability methods. These methods\napproximate the limit-state function (LSF) using surrogate models trained with\na sequentially enriched set of model evaluations. A recently proposed method\ncalled stochastic spectral embedding (SSE) aims to improve the local\napproximation accuracy of global, spectral surrogate modelling techniques by\nsequentially embedding local residual expansions in subdomains of the input\nspace. In this work we apply SSE to the LSF, giving rise to a stochastic\nspectral embedding-based reliability (SSER) method. The resulting partition of\nthe input space decomposes the failure probability into a set of\neasy-to-compute domain-wise failure probabilities. We propose a set of\nmodifications that tailor the algorithm to efficiently solve rare event\nestimation problems. These modifications include specialized refinement domain\nselection, partitioning and enrichment strategies. We showcase the algorithm\nperformance on four benchmark problems of various dimensionality and complexity\nin the LSF.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:10:33 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Wagner", "P. -R.", ""], ["Marelli", "S.", ""], ["Papaioannou", "I.", ""], ["Straub", "D.", ""], ["Sudret", "B.", ""]]}, {"id": "2106.05838", "submitter": "Jingyi Zhang", "authors": "Cheng Meng, Yuan Ke, Jingyi Zhang, Mengrui Zhang, Wenxuan Zhong, Ping\n  Ma", "title": "Large-scale optimal transport map estimation using projection pursuit", "comments": null, "journal-ref": "Meng, C. \"Large-scale optimal transport map estimation using\n  projection pursuit.\" NeurIPS 2019 (2019); Ke, Y. \"Large-scale optimal\n  transport map estimation using projection pursuit.\" NeurIPS 2019 (2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the estimation of large-scale optimal transport maps\n(OTM), which is a well-known challenging problem owing to the curse of\ndimensionality. Existing literature approximates the large-scale OTM by a\nseries of one-dimensional OTM problems through iterative random projection.\nSuch methods, however, suffer from slow or none convergence in practice due to\nthe nature of randomly selected projection directions. Instead, we propose an\nestimation method of large-scale OTM by combining the idea of projection\npursuit regression and sufficient dimension reduction. The proposed method,\nnamed projection pursuit Monge map (PPMM), adaptively selects the most\n``informative'' projection direction in each iteration. We theoretically show\nthe proposed dimension reduction method can consistently estimate the most\n``informative'' projection direction in each iteration. Furthermore, the PPMM\nalgorithm weakly convergences to the target large-scale OTM in a reasonable\nnumber of steps. Empirically, PPMM is computationally easy and converges fast.\nWe assess its finite sample performance through the applications of Wasserstein\ndistance estimation and generative models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 03:53:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Meng", "Cheng", ""], ["Ke", "Yuan", ""], ["Zhang", "Jingyi", ""], ["Zhang", "Mengrui", ""], ["Zhong", "Wenxuan", ""], ["Ma", "Ping", ""]]}, {"id": "2106.05848", "submitter": "Haitao Liu", "authors": "Haitao Liu, Changjun Liu, Xiaomo Jiang, Xudong Chen, Shuhua Yang,\n  Xiaofang Wang", "title": "Deep Probabilistic Time Series Forecasting using Augmented Recurrent\n  Input for Dynamic Systems", "comments": "25 pages, 7 figures, 4 tables, preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The demand of probabilistic time series forecasting has been recently raised\nin various dynamic system scenarios, for example, system identification and\nprognostic and health management of machines. To this end, we combine the\nadvances in both deep generative models and state space model (SSM) to come up\nwith a novel, data-driven deep probabilistic sequence model. Specially, we\nfollow the popular encoder-decoder generative structure to build the recurrent\nneural networks (RNN) assisted variational sequence model on an augmented\nrecurrent input space, which could induce rich stochastic sequence dependency.\nBesides, in order to alleviate the issue of inconsistency between training and\npredicting as well as improving the mining of dynamic patterns, we (i) propose\nusing a hybrid output as input at next time step, which brings training and\npredicting into alignment; and (ii) further devise a generalized\nauto-regressive strategy that encodes all the historical dependencies at\ncurrent time step. Thereafter, we first investigate the methodological\ncharacteristics of the proposed deep probabilistic sequence model on toy cases,\nand then comprehensively demonstrate the superiority of our model against\nexisting deep probabilistic SSM models through extensive numerical experiments\non eight system identification benchmarks from various dynamic systems.\nFinally, we apply our sequence model to a real-world centrifugal compressor\nsensor data forecasting problem, and again verify its outstanding performance\nby quantifying the time series predictive distribution.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 23:41:11 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Liu", "Haitao", ""], ["Liu", "Changjun", ""], ["Jiang", "Xiaomo", ""], ["Chen", "Xudong", ""], ["Yang", "Shuhua", ""], ["Wang", "Xiaofang", ""]]}, {"id": "2106.05850", "submitter": "Jiayi Wang", "authors": "Jiayi Wang, Raymond K. W. Wong, Xiaojun Mao, Kwun Chuen Gary Chan", "title": "Matrix Completion with Model-free Weighting", "comments": "Proceedings of the 38th International Conference on Machine Learning,\n  PMLR 139, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for matrix completion under general\nnon-uniform missing structures. By controlling an upper bound of a novel\nbalancing error, we construct weights that can actively adjust for the\nnon-uniformity in the empirical risk without explicitly modeling the\nobservation probabilities, and can be computed efficiently via convex\noptimization. The recovered matrix based on the proposed weighted empirical\nrisk enjoys appealing theoretical guarantees. In particular, the proposed\nmethod achieves a stronger guarantee than existing work in terms of the scaling\nwith respect to the observation probabilities, under asymptotically\nheterogeneous missing settings (where entry-wise observation probabilities can\nbe of different orders). These settings can be regarded as a better theoretical\nmodel of missing patterns with highly varying probabilities. We also provide a\nnew minimax lower bound under a class of heterogeneous settings. Numerical\nexperiments are also provided to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 06:28:20 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Wang", "Jiayi", ""], ["Wong", "Raymond K. W.", ""], ["Mao", "Xiaojun", ""], ["Chan", "Kwun Chuen Gary", ""]]}, {"id": "2106.05860", "submitter": "Kin Gutierrez Olivares", "authors": "Cristian Challu, Kin G. Olivares, Gus Welter, Artur Dubrawski", "title": "DMIDAS: Deep Mixed Data Sampling Regression for Long Multi-Horizon Time\n  Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural forecasting has shown significant improvements in the accuracy of\nlarge-scale systems, yet predicting extremely long horizons remains a\nchallenging task. Two common problems are the volatility of the predictions and\ntheir computational complexity; we addressed them by incorporating smoothness\nregularization and mixed data sampling techniques to a well-performing\nmulti-layer perceptron based architecture (NBEATS). We validate our proposed\nmethod, DMIDAS, on high-frequency healthcare and electricity price data with\nlong forecasting horizons (~1000 timestamps) where we improve the prediction\naccuracy by 5% over state-of-the-art models, reducing the number of parameters\nof NBEATS by nearly 70%.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 22:36:38 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Challu", "Cristian", ""], ["Olivares", "Kin G.", ""], ["Welter", "Gus", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2106.05886", "submitter": "Jin Xu", "authors": "Jin Xu, Hyunjik Kim, Tom Rainforth, Yee Whye Teh", "title": "Group Equivariant Subsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Subsampling is used in convolutional neural networks (CNNs) in the form of\npooling or strided convolutions, to reduce the spatial dimensions of feature\nmaps and to allow the receptive fields to grow exponentially with depth.\nHowever, it is known that such subsampling operations are not translation\nequivariant, unlike convolutions that are translation equivariant. Here, we\nfirst introduce translation equivariant subsampling/upsampling layers that can\nbe used to construct exact translation equivariant CNNs. We then generalise\nthese layers beyond translations to general groups, thus proposing group\nequivariant subsampling/upsampling. We use these layers to construct group\nequivariant autoencoders (GAEs) that allow us to learn low-dimensional\nequivariant representations. We empirically verify on images that the\nrepresentations are indeed equivariant to input translations and rotations, and\nthus generalise well to unseen positions and orientations. We further use GAEs\nin models that learn object-centric representations on multi-object datasets,\nand show improved data efficiency and decomposition compared to non-equivariant\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 16:14:00 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Xu", "Jin", ""], ["Kim", "Hyunjik", ""], ["Rainforth", "Tom", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2106.05891", "submitter": "Jiayuan Mao", "authors": "Jiayuan Mao, Zhezheng Luo, Chuang Gan, Joshua B. Tenenbaum, Jiajun Wu,\n  Leslie Pack Kaelbling, Tomer D. Ullman", "title": "Temporal and Object Quantification Networks", "comments": "IJCAI 2021. First two authors contributed equally. Project page:\n  http://toqnet.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Temporal and Object Quantification Networks (TOQ-Nets), a new\nclass of neuro-symbolic networks with a structural bias that enables them to\nlearn to recognize complex relational-temporal events. This is done by\nincluding reasoning layers that implement finite-domain quantification over\nobjects and time. The structure allows them to generalize directly to input\ninstances with varying numbers of objects in temporal sequences of varying\nlengths. We evaluate TOQ-Nets on input domains that require recognizing\nevent-types in terms of complex temporal relational patterns. We demonstrate\nthat TOQ-Nets can generalize from small amounts of data to scenarios containing\nmore objects than were present during training and to temporal warpings of\ninput sequences.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 16:18:21 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mao", "Jiayuan", ""], ["Luo", "Zhezheng", ""], ["Gan", "Chuang", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""], ["Kaelbling", "Leslie Pack", ""], ["Ullman", "Tomer D.", ""]]}, {"id": "2106.05931", "submitter": "Arash Vahdat", "authors": "Arash Vahdat, Karsten Kreis, Jan Kautz", "title": "Score-based Generative Modeling in Latent Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score-based generative models (SGMs) have recently demonstrated impressive\nresults in terms of both sample quality and distribution coverage. However,\nthey are usually applied directly in data space and often require thousands of\nnetwork evaluations for sampling. Here, we propose the Latent Score-based\nGenerative Model (LSGM), a novel approach that trains SGMs in a latent space,\nrelying on the variational autoencoder framework. Moving from data to latent\nspace allows us to train more expressive generative models, apply SGMs to\nnon-continuous data, and learn smoother SGMs in a smaller space, resulting in\nfewer network evaluations and faster sampling. To enable training LSGMs\nend-to-end in a scalable and stable manner, we (i) introduce a new\nscore-matching objective suitable to the LSGM setting, (ii) propose a novel\nparameterization of the score function that allows SGM to focus on the mismatch\nof the target distribution with respect to a simple Normal one, and (iii)\nanalytically derive multiple techniques for variance reduction of the training\nobjective. LSGM obtains a state-of-the-art FID score of 2.10 on CIFAR-10,\noutperforming all existing generative results on this dataset. On\nCelebA-HQ-256, LSGM is on a par with previous SGMs in sample quality while\noutperforming them in sampling time by two orders of magnitude. In modeling\nbinary images, LSGM achieves state-of-the-art likelihood on the binarized\nOMNIGLOT dataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:26:35 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Vahdat", "Arash", ""], ["Kreis", "Karsten", ""], ["Kautz", "Jan", ""]]}, {"id": "2106.05932", "submitter": "Matus Telgarsky", "authors": "Ziwei Ji, Justin D. Li, Matus Telgarsky", "title": "Early-stopped neural networks are consistent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the behavior of neural networks trained with the logistic\nloss via gradient descent on binary classification data where the underlying\ndata distribution is general, and the (optimal) Bayes risk is not necessarily\nzero. In this setting, it is shown that gradient descent with early stopping\nachieves population risk arbitrarily close to optimal in terms of not just\nlogistic and misclassification losses, but also in terms of calibration,\nmeaning the sigmoid mapping of its outputs approximates the true underlying\nconditional distribution arbitrarily finely. Moreover, the necessary iteration,\nsample, and architectural complexities of this analysis all scale naturally\nwith a certain complexity measure of the true conditional model. Lastly, while\nit is not shown that early stopping is necessary, it is shown that any\nunivariate classifier satisfying a local interpolation property is necessarily\ninconsistent.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:26:40 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Ji", "Ziwei", ""], ["Li", "Justin D.", ""], ["Telgarsky", "Matus", ""]]}, {"id": "2106.05945", "submitter": "Andrew Wilson", "authors": "Samuel Stanton, Pavel Izmailov, Polina Kirichenko, Alexander A. Alemi,\n  Andrew Gordon Wilson", "title": "Does Knowledge Distillation Really Work?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is a popular technique for training a small student\nnetwork to emulate a larger teacher model, such as an ensemble of networks. We\nshow that while knowledge distillation can improve student generalization, it\ndoes not typically work as it is commonly understood: there often remains a\nsurprisingly large discrepancy between the predictive distributions of the\nteacher and the student, even in cases when the student has the capacity to\nperfectly match the teacher. We identify difficulties in optimization as a key\nreason for why the student is unable to match the teacher. We also show how the\ndetails of the dataset used for distillation play a role in how closely the\nstudent matches the teacher -- and that more closely matching the teacher\nparadoxically does not always lead to better student generalization.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:44:02 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Stanton", "Samuel", ""], ["Izmailov", "Pavel", ""], ["Kirichenko", "Polina", ""], ["Alemi", "Alexander A.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2106.05951", "submitter": "Soumyabrata Pal", "authors": "Venkata Gandikota, Arya Mazumdar, Soumyabrata Pal", "title": "Support Recovery of Sparse Signals from a Mixture of Linear Measurements", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovery of support of a sparse vector from simple measurements is a widely\nstudied problem, considered under the frameworks of compressed sensing, 1-bit\ncompressed sensing, and more general single index models. We consider\ngeneralizations of this problem: mixtures of linear regressions, and mixtures\nof linear classifiers, where the goal is to recover supports of multiple sparse\nvectors using only a small number of possibly noisy linear, and 1-bit\nmeasurements respectively. The key challenge is that the measurements from\ndifferent vectors are randomly mixed. Both of these problems were also\nextensively studied recently. In mixtures of linear classifiers, the\nobservations correspond to the side of queried hyperplane a random unknown\nvector lies in, whereas in mixtures of linear regressions we observe the\nprojection of a random unknown vector on the queried hyperplane. The primary\nstep in recovering the unknown vectors from the mixture is to first identify\nthe support of all the individual component vectors. In this work, we study the\nnumber of measurements sufficient for recovering the supports of all the\ncomponent vectors in a mixture in both these models. We provide algorithms that\nuse a number of measurements polynomial in $k, \\log n$ and quasi-polynomial in\n$\\ell$, to recover the support of all the $\\ell$ unknown vectors in the mixture\nwith high probability when each individual component is a $k$-sparse\n$n$-dimensional vector.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:48:13 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Gandikota", "Venkata", ""], ["Mazumdar", "Arya", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "2106.05960", "submitter": "Thomas M. McDonald", "authors": "Thomas M. McDonald, Mauricio A. \\'Alvarez", "title": "Compositional Modeling of Nonlinear Dynamical Systems with ODE-based\n  Random Features", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively modeling phenomena present in highly nonlinear dynamical systems\nwhilst also accurately quantifying uncertainty is a challenging task, which\noften requires problem-specific techniques. We present a novel, domain-agnostic\napproach to tackling this problem, using compositions of physics-informed\nrandom features, derived from ordinary differential equations. The architecture\nof our model leverages recent advances in approximate inference for deep\nGaussian processes, such as layer-wise weight-space approximations which allow\nus to incorporate random Fourier features, and stochastic variational inference\nfor approximate Bayesian inference. We provide evidence that our model is\ncapable of capturing highly nonlinear behaviour in real-world multivariate time\nseries data. In addition, we find that our approach achieves comparable\nperformance to a number of other probabilistic models on benchmark regression\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:55:13 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["McDonald", "Thomas M.", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "2106.05964", "submitter": "Anay Mehrotra", "authors": "L. Elisa Celis, Anay Mehrotra, Nisheeth K. Vishnoi", "title": "Fair Classification with Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fair classification in the presence of an omniscient adversary that,\ngiven an $\\eta$, is allowed to choose an arbitrary $\\eta$-fraction of the\ntraining samples and arbitrarily perturb their protected attributes. The\nmotivation comes from settings in which protected attributes can be incorrect\ndue to strategic misreporting, malicious actors, or errors in imputation; and\nprior approaches that make stochastic or independence assumptions on errors may\nnot satisfy their guarantees in this adversarial setting. Our main contribution\nis an optimization framework to learn fair classifiers in this adversarial\nsetting that comes with provable guarantees on accuracy and fairness. Our\nframework works with multiple and non-binary protected attributes, is designed\nfor the large class of linear-fractional fairness metrics, and can also handle\nperturbations besides protected attributes. We prove near-tightness of our\nframework's guarantees for natural hypothesis classes: no algorithm can have\nsignificantly better accuracy and any algorithm with better fairness must have\nlower accuracy. Empirically, we evaluate the classifiers produced by our\nframework for statistical rate on real-world and synthetic datasets for a\nfamily of adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:56:59 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Celis", "L. Elisa", ""], ["Mehrotra", "Anay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2106.05974", "submitter": "Carlos Riquelme Ruiz", "authors": "Carlos Riquelme, Joan Puigcerver, Basil Mustafa, Maxim Neumann,\n  Rodolphe Jenatton, Andr\\'e Susano Pinto, Daniel Keysers, Neil Houlsby", "title": "Scaling Vision with Sparse Mixture of Experts", "comments": "44 pages, 38 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent\nscalability in Natural Language Processing. In Computer Vision, however, almost\nall performant networks are \"dense\", that is, every input is processed by every\nparameter. We present a Vision MoE (V-MoE), a sparse version of the Vision\nTransformer, that is scalable and competitive with the largest dense networks.\nWhen applied to image recognition, V-MoE matches the performance of\nstate-of-the-art networks, while requiring as little as half of the compute at\ninference time. Further, we propose an extension to the routing algorithm that\ncan prioritize subsets of each input across the entire batch, leading to\nadaptive per-image compute. This allows V-MoE to trade-off performance and\ncompute smoothly at test-time. Finally, we demonstrate the potential of V-MoE\nto scale vision models, and train a 15B parameter model that attains 90.35% on\nImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 17:10:56 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Riquelme", "Carlos", ""], ["Puigcerver", "Joan", ""], ["Mustafa", "Basil", ""], ["Neumann", "Maxim", ""], ["Jenatton", "Rodolphe", ""], ["Pinto", "Andr\u00e9 Susano", ""], ["Keysers", "Daniel", ""], ["Houlsby", "Neil", ""]]}, {"id": "2106.05992", "submitter": "Shengyang Sun", "authors": "Shengyang Sun, Jiaxin Shi, Andrew Gordon Wilson, Roger Grosse", "title": "Scalable Variational Gaussian Processes via Harmonic Kernel\n  Decomposition", "comments": "ICML2021, 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new scalable variational Gaussian process approximation which\nprovides a high fidelity approximation while retaining general applicability.\nWe propose the harmonic kernel decomposition (HKD), which uses Fourier series\nto decompose a kernel as a sum of orthogonal kernels. Our variational\napproximation exploits this orthogonality to enable a large number of inducing\npoints at a low computational cost. We demonstrate that, on a range of\nregression and classification problems, our approach can exploit input space\nsymmetries such as translations and reflections, and it significantly\noutperforms standard variational methods in scalability and accuracy. Notably,\nour approach achieves state-of-the-art results on CIFAR-10 among pure GP\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 18:17:57 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Sun", "Shengyang", ""], ["Shi", "Jiaxin", ""], ["Wilson", "Andrew Gordon", ""], ["Grosse", "Roger", ""]]}, {"id": "2106.06020", "submitter": "Maurice Weiler", "authors": "Maurice Weiler, Patrick Forr\\'e, Erik Verlinde, Max Welling", "title": "Coordinate Independent Convolutional Networks -- Isometry and Gauge\n  Equivariant Convolutions on Riemannian Manifolds", "comments": "The implementation of orientation independent M\\\"obius convolutions\n  is publicly available at https://github.com/mauriceweiler/MobiusCNNs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the vast success of deep convolutional networks, there is a\ngreat interest in generalizing convolutions to non-Euclidean manifolds. A major\ncomplication in comparison to flat spaces is that it is unclear in which\nalignment a convolution kernel should be applied on a manifold. The underlying\nreason for this ambiguity is that general manifolds do not come with a\ncanonical choice of reference frames (gauge). Kernels and features therefore\nhave to be expressed relative to arbitrary coordinates. We argue that the\nparticular choice of coordinatization should not affect a network's inference\n-- it should be coordinate independent. A simultaneous demand for coordinate\nindependence and weight sharing is shown to result in a requirement on the\nnetwork to be equivariant under local gauge transformations (changes of local\nreference frames). The ambiguity of reference frames depends thereby on the\nG-structure of the manifold, such that the necessary level of gauge\nequivariance is prescribed by the corresponding structure group G. Coordinate\nindependent convolutions are proven to be equivariant w.r.t. those isometries\nthat are symmetries of the G-structure. The resulting theory is formulated in a\ncoordinate free fashion in terms of fiber bundles. To exemplify the design of\ncoordinate independent convolutions, we implement a convolutional network on\nthe M\\\"obius strip. The generality of our differential geometric formulation of\nconvolutional networks is demonstrated by an extensive literature review which\nexplains a large number of Euclidean CNNs, spherical CNNs and CNNs on general\nsurfaces as specific instances of coordinate independent convolutions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 19:54:19 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Weiler", "Maurice", ""], ["Forr\u00e9", "Patrick", ""], ["Verlinde", "Erik", ""], ["Welling", "Max", ""]]}, {"id": "2106.06044", "submitter": "Ruitu Xu", "authors": "Ganlin Song, Ruitu Xu, John Lafferty", "title": "Convergence and Alignment of Gradient Descent with Random Back\n  Propagation Weights", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent with backpropagation is the workhorse of\nartificial neural networks. It has long been recognized that backpropagation\nfails to be a biologically plausible algorithm. Fundamentally, it is a\nnon-local procedure -- updating one neuron's synaptic weights requires\nknowledge of synaptic weights or receptive fields of downstream neurons. This\nlimits the use of artificial neural networks as a tool for understanding the\nbiological principles of information processing in the brain. Lillicrap et al.\n(2016) propose a more biologically plausible \"feedback alignment\" algorithm\nthat uses random and fixed backpropagation weights, and show promising\nsimulations. In this paper we study the mathematical properties of the feedback\nalignment procedure by analyzing convergence and alignment for two-layer\nnetworks under squared error loss. In the overparameterized setting, we prove\nthat the error converges to zero exponentially fast, and also that\nregularization is necessary in order for the parameters to become aligned with\nthe random backpropagation weights. Simulations are given that are consistent\nwith this analysis and suggest further generalizations. These results\ncontribute to our understanding of how biologically plausible algorithms might\ncarry out weight learning in a manner different from Hebbian learning, with\nperformance that is comparable with the full non-local backpropagation\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 20:58:05 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 19:31:48 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Song", "Ganlin", ""], ["Xu", "Ruitu", ""], ["Lafferty", "John", ""]]}, {"id": "2106.06064", "submitter": "Soumyasundar Pal", "authors": "Soumyasundar Pal and Liheng Ma and Yingxue Zhang and Mark Coates", "title": "RNN with Particle Flow for Probabilistic Spatio-temporal Forecasting", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spatio-temporal forecasting has numerous applications in analyzing wireless,\ntraffic, and financial networks. Many classical statistical models often fall\nshort in handling the complexity and high non-linearity present in time-series\ndata. Recent advances in deep learning allow for better modelling of spatial\nand temporal dependencies. While most of these models focus on obtaining\naccurate point forecasts, they do not characterize the prediction uncertainty.\nIn this work, we consider the time-series data as a random realization from a\nnonlinear state-space model and target Bayesian inference of the hidden states\nfor probabilistic forecasting. We use particle flow as the tool for\napproximating the posterior distribution of the states, as it is shown to be\nhighly effective in complex, high-dimensional settings. Thorough\nexperimentation on several real world time-series datasets demonstrates that\nour approach provides better characterization of uncertainty while maintaining\ncomparable accuracy to the state-of-the art point forecasting methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 21:49:23 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Pal", "Soumyasundar", ""], ["Ma", "Liheng", ""], ["Zhang", "Yingxue", ""], ["Coates", "Mark", ""]]}, {"id": "2106.06075", "submitter": "Babak Barazandeh", "authors": "Babak Barazandeh, Tianjian Huang, George Michailidis", "title": "A Decentralized Adaptive Momentum Method for Solving a Class of Min-Max\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Min-max saddle point games have recently been intensely studied, due to their\nwide range of applications, including training Generative Adversarial Networks\n(GANs). However, most of the recent efforts for solving them are limited to\nspecial regimes such as convex-concave games. Further, it is customarily\nassumed that the underlying optimization problem is solved either by a single\nmachine or in the case of multiple machines connected in centralized fashion,\nwherein each one communicates with a central node. The latter approach becomes\nchallenging, when the underlying communications network has low bandwidth. In\naddition, privacy considerations may dictate that certain nodes can communicate\nwith a subset of other nodes. Hence, it is of interest to develop methods that\nsolve min-max games in a decentralized manner. To that end, we develop a\ndecentralized adaptive momentum (ADAM)-type algorithm for solving min-max\noptimization problem under the condition that the objective function satisfies\na Minty Variational Inequality condition, which is a generalization to\nconvex-concave case. The proposed method overcomes shortcomings of recent\nnon-adaptive gradient-based decentralized algorithms for min-max optimization\nproblems that do not perform well in practice and require careful tuning. In\nthis paper, we obtain non-asymptotic rates of convergence of the proposed\nalgorithm (coined DADAM$^3$) for finding a (stochastic) first-order Nash\nequilibrium point and subsequently evaluate its performance on training GANs.\nThe extensive empirical evaluation shows that DADAM$^3$ outperforms recently\ndeveloped methods, including decentralized optimistic stochastic gradient for\nsolving such min-max problems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 22:32:01 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 19:49:15 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Barazandeh", "Babak", ""], ["Huang", "Tianjian", ""], ["Michailidis", "George", ""]]}, {"id": "2106.06079", "submitter": "David Eriksson", "authors": "Eric Hans Lee, David Eriksson, Valerio Perrone, Matthias Seeger", "title": "A Nonmyopic Approach to Cost-Constrained Bayesian Optimization", "comments": "To appear in UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular method for optimizing\nexpensive-to-evaluate black-box functions. BO budgets are typically given in\niterations, which implicitly assumes each evaluation has the same cost. In\nfact, in many BO applications, evaluation costs vary significantly in different\nregions of the search space. In hyperparameter optimization, the time spent on\nneural network training increases with layer size; in clinical trials, the\nmonetary cost of drug compounds vary; and in optimal control, control actions\nhave differing complexities. Cost-constrained BO measures convergence with\nalternative cost metrics such as time, money, or energy, for which the sample\nefficiency of standard BO methods is ill-suited. For cost-constrained BO, cost\nefficiency is far more important than sample efficiency. In this paper, we\nformulate cost-constrained BO as a constrained Markov decision process (CMDP),\nand develop an efficient rollout approximation to the optimal CMDP policy that\ntakes both the cost and future iterations into account. We validate our method\non a collection of hyperparameter optimization problems as well as a sensor set\nselection application.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 22:44:37 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Lee", "Eric Hans", ""], ["Eriksson", "David", ""], ["Perrone", "Valerio", ""], ["Seeger", "Matthias", ""]]}, {"id": "2106.06095", "submitter": "Sebastian Ament", "authors": "Sebastian Ament and Carla Gomes", "title": "Sparse Bayesian Learning via Stepwise Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Bayesian Learning (SBL) is a powerful framework for attaining sparsity\nin probabilistic models. Herein, we propose a coordinate ascent algorithm for\nSBL termed Relevance Matching Pursuit (RMP) and show that, as its noise\nvariance parameter goes to zero, RMP exhibits a surprising connection to\nStepwise Regression. Further, we derive novel guarantees for Stepwise\nRegression algorithms, which also shed light on RMP. Our guarantees for Forward\nRegression improve on deterministic and probabilistic results for Orthogonal\nMatching Pursuit with noise. Our analysis of Backward Regression on determined\nsystems culminates in a bound on the residual of the optimal solution to the\nsubset selection problem that, if satisfied, guarantees the optimality of the\nresult. To our knowledge, this bound is the first that can be computed in\npolynomial time and depends chiefly on the smallest singular value of the\nmatrix. We report numerical experiments using a variety of feature selection\nalgorithms. Notably, RMP and its limiting variant are both efficient and\nmaintain strong performance with correlated features.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 00:20:27 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ament", "Sebastian", ""], ["Gomes", "Carla", ""]]}, {"id": "2106.06097", "submitter": "Yueming Lyu", "authors": "Yueming Lyu, Ivor Tsang", "title": "Neural Optimization Kernel: Towards Robust Deep Learning", "comments": "Deep Learning, Kernel Methods, Deep Learning Theory, Kernel\n  Approximation, Integral Approximation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show a close connection between neural networks (NN) and\nkernel methods. However, most of these analyses (e.g., NTK) focus on the\ninfluence of (infinite) width instead of the depth of NN models. There remains\na gap between theory and practical network designs that benefit from the depth.\nThis paper first proposes a novel kernel family named Neural Optimization\nKernel (NOK). Our kernel is defined as the inner product between two $T$-step\nupdated functionals in RKHS w.r.t. a regularized optimization problem.\nTheoretically, we proved the monotonic descent property of our update rule for\nboth convex and non-convex problems, and a $O(1/T)$ convergence rate of our\nupdates for convex problems. Moreover, we propose a data-dependent structured\napproximation of our NOK, which builds the connection between training deep NNs\nand kernel methods associated with NOK. The resultant computational graph is a\nResNet-type finite width NN. Our structured approximation preserved the\nmonotonic descent property and $O(1/T)$ convergence rate. Namely, a $T$-layer\nNN performs $T$-step monotonic descent updates. Notably, we show our\n$T$-layered structured NN with ReLU maintains a $O(1/T)$ convergence rate\nw.r.t. a convex regularized problem, which explains the success of ReLU on\ntraining deep NN from a NN architecture optimization perspective. For the\nunsupervised learning and the shared parameter case, we show the equivalence of\ntraining structured NN with GD and performing functional gradient descent in\nRKHS associated with a fixed (data-dependent) NOK at an infinity-width regime.\nFor finite NOKs, we prove generalization bounds. Remarkably, we show that\noverparameterized deep NN (NOK) can increase the expressive power to reduce\nempirical risk and reduce the generalization bound at the same time. Extensive\nexperiments verify the robustness of our structured NOK blocks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 00:34:55 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:36:37 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lyu", "Yueming", ""], ["Tsang", "Ivor", ""]]}, {"id": "2106.06123", "submitter": "Zhiyong Zhou", "authors": "Zhiyong Zhou", "title": "A Unified Framework for Constructing Nonconvex Regularizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Over the past decades, many individual nonconvex methods have been proposed\nto achieve better sparse recovery performance in various scenarios. However,\nhow to construct a valid nonconvex regularization function remains open in\npractice. In this paper, we fill in this gap by presenting a unified framework\nfor constructing the nonconvex regularization based on the probability density\nfunction. Meanwhile, a new nonconvex sparse recovery method constructed via the\nWeibull distribution is studied.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 02:10:01 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Zhou", "Zhiyong", ""]]}, {"id": "2106.06134", "submitter": "Yao Ma", "authors": "Yao Ma, Xiaorui Liu, Neil Shah, Jiliang Tang", "title": "Is Homophily a Necessity for Graph Neural Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks (GNNs) have shown great prowess in learning\nrepresentations suitable for numerous graph-based machine learning tasks. When\napplied to semi-supervised node classification, GNNs are widely believed to\nwork well due to the homophily assumption (``like attracts like''), and fail to\ngeneralize to heterophilous graphs where dissimilar nodes connect. Recent works\ndesign new architectures to overcome such heterophily-related limitations,\nciting poor baseline performance and new architecture improvements on a few\nheterophilous graph benchmark datasets as evidence for this notion. In our\nexperiments, we empirically find that standard graph convolutional networks\n(GCNs) can actually achieve better performance than such carefully designed\nmethods on some commonly used heterophilous graphs. This motivates us to\nreconsider whether homophily is truly necessary for good GNN performance. We\nfind that this claim is not quite true, and in fact, GCNs can achieve strong\nperformance on heterophilous graphs under certain conditions. Our work\ncarefully characterizes these conditions, and provides supporting theoretical\nunderstanding and empirical observations. Finally, we examine existing\nheterophilous graphs benchmarks and reconcile how the GCN (under)performs on\nthem based on this understanding.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 02:44:00 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ma", "Yao", ""], ["Liu", "Xiaorui", ""], ["Shah", "Neil", ""], ["Tang", "Jiliang", ""]]}, {"id": "2106.06142", "submitter": "Runtian Zhai", "authors": "Runtian Zhai, Chen Dan, J. Zico Kolter, Pradeep Ravikumar", "title": "DORO: Distributional and Outlier Robust Optimization", "comments": "ICML 2021. Codes: https://github.com/RuntianZ/doro", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many machine learning tasks involve subpopulation shift where the testing\ndata distribution is a subpopulation of the training distribution. For such\nsettings, a line of recent work has proposed the use of a variant of empirical\nrisk minimization(ERM) known as distributionally robust optimization (DRO). In\nthis work, we apply DRO to real, large-scale tasks with subpopulation shift,\nand observe that DRO performs relatively poorly, and moreover has severe\ninstability. We identify one direct cause of this phenomenon: sensitivity of\nDRO to outliers in the datasets. To resolve this issue, we propose the\nframework of DORO, for Distributional and Outlier Robust Optimization. At the\ncore of this approach is a refined risk function which prevents DRO from\noverfitting to potential outliers. We instantiate DORO for the Cressie-Read\nfamily of R\\'enyi divergence, and delve into two specific instances of this\nfamily: CVaR and $\\chi^2$-DRO. We theoretically prove the effectiveness of the\nproposed method, and empirically show that DORO improves the performance and\nstability of DRO with experiments on large modern datasets, thereby positively\naddressing the open question raised by Hashimoto et al., 2018.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 02:59:54 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Zhai", "Runtian", ""], ["Dan", "Chen", ""], ["Kolter", "J. Zico", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "2106.06153", "submitter": "Jiaye Teng", "authors": "Jiaye Teng, Jianhao Ma, Yang Yuan", "title": "Towards Understanding Generalization via Decomposing Excess Risk\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is one of the critical issues in machine learning. However,\ntraditional methods like uniform convergence are not powerful enough to fully\nexplain generalization because they may yield vacuous bounds even in\noverparameterized linear regression regimes. An alternative solution is to\nanalyze the generalization dynamics to derive algorithm-dependent bounds, e.g.,\nstability. Unfortunately, the stability-based bound is still far from\nexplaining the remarkable generalization ability of neural networks due to the\ncoarse-grained analysis of the signal and noise. Inspired by the observation\nthat neural networks show a slow convergence rate when fitting noise, we\npropose decomposing the excess risk dynamics and applying stability-based bound\nonly on the variance part (which measures how the model performs on pure\nnoise). We provide two applications for the framework, including a linear case\n(overparameterized linear regression with gradient descent) and a non-linear\ncase (matrix recovery with gradient flow). Under the decomposition framework,\nthe new bound accords better with the theoretical and empirical evidence\ncompared to the stability-based bound and uniform convergence bound.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 03:42:45 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Teng", "Jiaye", ""], ["Ma", "Jianhao", ""], ["Yuan", "Yang", ""]]}, {"id": "2106.06189", "submitter": "Xiaohui Chen", "authors": "Xiaohui Chen, Xu Han, Jiajing Hu, Francisco J. R. Ruiz, Liping Liu", "title": "Order Matters: Probabilistic Modeling of Node Sequence for Graph\n  Generation", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A graph generative model defines a distribution over graphs. One type of\ngenerative model is constructed by autoregressive neural networks, which\nsequentially add nodes and edges to generate a graph. However, the likelihood\nof a graph under the autoregressive model is intractable, as there are numerous\nsequences leading to the given graph; this makes maximum likelihood estimation\nchallenging. Instead, in this work we derive the exact joint probability over\nthe graph and the node ordering of the sequential process. From the joint, we\napproximately marginalize out the node orderings and compute a lower bound on\nthe log-likelihood using variational inference. We train graph generative\nmodels by maximizing this bound, without using the ad-hoc node orderings of\nprevious methods. Our experiments show that the log-likelihood bound is\nsignificantly tighter than the bound of previous schemes. Moreover, the models\nfitted with the proposed algorithm can generate high-quality graphs that match\nthe structures of target graphs not seen during training. We have made our code\npublicly available at\n\\hyperref[https://github.com/tufts-ml/graph-generation-vi]{https://github.com/tufts-ml/graph-generation-vi}.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 06:37:52 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 09:51:52 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Xiaohui", ""], ["Han", "Xu", ""], ["Hu", "Jiajing", ""], ["Ruiz", "Francisco J. R.", ""], ["Liu", "Liping", ""]]}, {"id": "2106.06239", "submitter": "Sanae Amani", "authors": "Sanae Amani, Christos Thrampoulidis, Lin F. Yang", "title": "Safe Reinforcement Learning with Linear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety in reinforcement learning has become increasingly important in recent\nyears. Yet, existing solutions either fail to strictly avoid choosing unsafe\nactions, which may lead to catastrophic results in safety-critical systems, or\nfail to provide regret guarantees for settings where safety constraints need to\nbe learned. In this paper, we address both problems by first modeling safety as\nan unknown linear cost function of states and actions, which must always fall\nbelow a certain threshold. We then present algorithms, termed SLUCB-QVI and\nRSLUCB-QVI, for episodic Markov decision processes (MDPs) with linear function\napproximation. We show that SLUCB-QVI and RSLUCB-QVI, while with \\emph{no\nsafety violation}, achieve a\n$\\tilde{\\mathcal{O}}\\left(\\kappa\\sqrt{d^3H^3T}\\right)$ regret, nearly matching\nthat of state-of-the-art unsafe algorithms, where $H$ is the duration of each\nepisode, $d$ is the dimension of the feature mapping, $\\kappa$ is a constant\ncharacterizing the safety constraints, and $T$ is the total number of action\nplays. We further present numerical simulations that corroborate our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:46:57 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Amani", "Sanae", ""], ["Thrampoulidis", "Christos", ""], ["Yang", "Lin F.", ""]]}, {"id": "2106.06243", "submitter": "Sevvandi Kandanaarachchi", "authors": "Sevvandi Kandanaarachchi", "title": "Unsupervised Anomaly Detection Ensembles using Item Response Theory", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constructing an ensemble from a heterogeneous set of unsupervised anomaly\ndetection methods is challenging because the class labels or the ground truth\nis unknown. Thus, traditional ensemble techniques that use the response\nvariable or the class labels cannot be used to construct an ensemble for\nunsupervised anomaly detection.\n  We use Item Response Theory (IRT) -- a class of models used in educational\npsychometrics to assess student and test question characteristics -- to\nconstruct an unsupervised anomaly detection ensemble. IRT's latent trait\ncomputation lends itself to anomaly detection because the latent trait can be\nused to uncover the hidden ground truth. Using a novel IRT mapping to the\nanomaly detection problem, we construct an ensemble that can downplay noisy,\nnon-discriminatory methods and accentuate sharper methods. We demonstrate the\neffectiveness of the IRT ensemble on an extensive data repository, by comparing\nits performance to other ensemble techniques.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:51:26 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kandanaarachchi", "Sevvandi", ""]]}, {"id": "2106.06245", "submitter": "Simone Rossi", "authors": "Ba-Hien Tran and Simone Rossi and Dimitrios Milios and Pietro\n  Michiardi and Edwin V. Bonilla and Maurizio Filippone", "title": "Model Selection for Bayesian Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a novel method for carrying out model selection for Bayesian\nautoencoders (BAEs) by means of prior hyper-parameter optimization. Inspired by\nthe common practice of type-II maximum likelihood optimization and its\nequivalence to Kullback-Leibler divergence minimization, we propose to optimize\nthe distributional sliced-Wasserstein distance (DSWD) between the output of the\nautoencoder and the empirical data distribution. The advantages of this\nformulation are that we can estimate the DSWD based on samples and handle\nhigh-dimensional problems. We carry out posterior estimation of the BAE\nparameters via stochastic gradient Hamiltonian Monte Carlo and turn our BAE\ninto a generative model by fitting a flexible Dirichlet mixture model in the\nlatent space. Consequently, we obtain a powerful alternative to variational\nautoencoders, which are the preferred choice in modern applications of\nautoencoders for representation learning with uncertainty. We evaluate our\napproach qualitatively and quantitatively using a vast experimental campaign on\na number of unsupervised learning tasks and show that, in small-data regimes\nwhere priors matter, our approach provides state-of-the-art results,\noutperforming multiple competitive baselines.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:55:00 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Tran", "Ba-Hien", ""], ["Rossi", "Simone", ""], ["Milios", "Dimitrios", ""], ["Michiardi", "Pietro", ""], ["Bonilla", "Edwin V.", ""], ["Filippone", "Maurizio", ""]]}, {"id": "2106.06251", "submitter": "Shunta Akiyama", "authors": "Shunta Akiyama and Taiji Suzuki", "title": "On Learnability via Gradient Method for Two-Layer ReLU Neural Networks\n  in Teacher-Student Setting", "comments": "47 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning empirically achieves high performance in many applications, but\nits training dynamics has not been fully understood theoretically. In this\npaper, we explore theoretical analysis on training two-layer ReLU neural\nnetworks in a teacher-student regression model, in which a student network\nlearns an unknown teacher network through its outputs. We show that with a\nspecific regularization and sufficient over-parameterization, the student\nnetwork can identify the parameters of the teacher network with high\nprobability via gradient descent with a norm dependent stepsize even though the\nobjective function is highly non-convex. The key theoretical tool is the\nmeasure representation of the neural networks and a novel application of a dual\ncertificate argument for sparse estimation on a measure space. We analyze the\nglobal minima and global convergence property in the measure space.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 09:05:41 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 03:22:38 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Akiyama", "Shunta", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2106.06279", "submitter": "Pierre Menard", "authors": "Tadashi Kozuno, Pierre M\\'enard, R\\'emi Munos, Michal Valko", "title": "Model-Free Learning for Two-Player Zero-Sum Partially Observable Markov\n  Games with Perfect Recall", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of learning a Nash equilibrium (NE) in an imperfect\ninformation game (IIG) through self-play. Precisely, we focus on two-player,\nzero-sum, episodic, tabular IIG under the perfect-recall assumption where the\nonly feedback is realizations of the game (bandit feedback). In particular, the\ndynamic of the IIG is not known -- we can only access it by sampling or\ninteracting with a game simulator. For this learning setting, we provide the\nImplicit Exploration Online Mirror Descent (IXOMD) algorithm. It is a\nmodel-free algorithm with a high-probability bound on the convergence rate to\nthe NE of order $1/\\sqrt{T}$ where $T$ is the number of played games. Moreover,\nIXOMD is computationally efficient as it needs to perform the updates only\nalong the sampled trajectory.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 09:51:29 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kozuno", "Tadashi", ""], ["M\u00e9nard", "Pierre", ""], ["Munos", "R\u00e9mi", ""], ["Valko", "Michal", ""]]}, {"id": "2106.06308", "submitter": "Davin Choo", "authors": "Davin Choo, Tommaso d'Orsi", "title": "The Complexity of Sparse Tensor PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sparse tensor principal component analysis: given a\ntensor $\\pmb Y = \\pmb W + \\lambda x^{\\otimes p}$ with $\\pmb W \\in\n\\otimes^p\\mathbb{R}^n$ having i.i.d. Gaussian entries, the goal is to recover\nthe $k$-sparse unit vector $x \\in \\mathbb{R}^n$. The model captures both sparse\nPCA (in its Wigner form) and tensor PCA.\n  For the highly sparse regime of $k \\leq \\sqrt{n}$, we present a family of\nalgorithms that smoothly interpolates between a simple polynomial-time\nalgorithm and the exponential-time exhaustive search algorithm. For any $1 \\leq\nt \\leq k$, our algorithms recovers the sparse vector for signal-to-noise ratio\n$\\lambda \\geq \\tilde{\\mathcal{O}} (\\sqrt{t} \\cdot (k/t)^{p/2})$ in time\n$\\tilde{\\mathcal{O}}(n^{p+t})$, capturing the state-of-the-art guarantees for\nthe matrix settings (in both the polynomial-time and sub-exponential time\nregimes).\n  Our results naturally extend to the case of $r$ distinct $k$-sparse signals\nwith disjoint supports, with guarantees that are independent of the number of\nspikes. Even in the restricted case of sparse PCA, known algorithms only\nrecover the sparse vectors for $\\lambda \\geq \\tilde{\\mathcal{O}}(k \\cdot r)$\nwhile our algorithms require $\\lambda \\geq \\tilde{\\mathcal{O}}(k)$.\n  Finally, by analyzing the low-degree likelihood ratio, we complement these\nalgorithmic results with rigorous evidence illustrating the trade-offs between\nsignal-to-noise ratio and running time. This lower bound captures the known\nlower bounds for both sparse PCA and tensor PCA. In this general model, we\nobserve a more intricate three-way trade-off between the number of samples $n$,\nthe sparsity $k$, and the tensor power $p$.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:57:00 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Choo", "Davin", ""], ["d'Orsi", "Tommaso", ""]]}, {"id": "2106.06333", "submitter": "Yifei Shen", "authors": "Bo Li, Yifei Shen, Yezhen Wang, Wenzhen Zhu, Colorado J. Reed, Jun\n  Zhang, Dongsheng Li, Kurt Keutzer, Han Zhao", "title": "Invariant Information Bottleneck for Domain Generalization", "comments": "The work is in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main challenge for domain generalization (DG) is to overcome the\npotential distributional shift between multiple training domains and unseen\ntest domains. One popular class of DG algorithms aims to learn representations\nthat have an invariant causal relation across the training domains. However,\ncertain features, called \\emph{pseudo-invariant features}, may be invariant in\nthe training domain but not the test domain and can substantially decreases the\nperformance of existing algorithms. To address this issue, we propose a novel\nalgorithm, called Invariant Information Bottleneck (IIB), that learns a\nminimally sufficient representation that is invariant across training and\ntesting domains. By minimizing the mutual information between the\nrepresentation and inputs, IIB alleviates its reliance on pseudo-invariant\nfeatures, which is desirable for DG. To verify the effectiveness of the IIB\nprinciple, we conduct extensive experiments on large-scale DG benchmarks. The\nresults show that IIB outperforms invariant learning baseline (e.g. IRM) by an\naverage of 2.8\\% and 3.8\\% accuracy over two evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 12:12:40 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 17:31:00 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Bo", ""], ["Shen", "Yifei", ""], ["Wang", "Yezhen", ""], ["Zhu", "Wenzhen", ""], ["Reed", "Colorado J.", ""], ["Zhang", "Jun", ""], ["Li", "Dongsheng", ""], ["Keutzer", "Kurt", ""], ["Zhao", "Han", ""]]}, {"id": "2106.06338", "submitter": "Beno\\^it Mal\\'ezieux", "authors": "Beno\\^it Mal\\'ezieux, Thomas Moreau, Matthieu Kowalski", "title": "Dictionary and prior learning with unrolled algorithms for unsupervised\n  inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems consist in recovering a signal given noisy observations. One\nclassical resolution approach is to leverage sparsity and integrate prior\nknowledge of the signal to the reconstruction algorithm to get a plausible\nsolution. Still, this prior might not be sufficiently adapted to the data. In\nthis work, we study Dictionary and Prior learning from degraded measurements as\na bi-level problem, and we take advantage of unrolled algorithms to solve\napproximate formulations of Synthesis and Analysis. We provide an empirical and\ntheoretical analysis of automatic differentiation for Dictionary Learning to\nunderstand better the pros and cons of unrolling in this context. We find that\nunrolled algorithms speed up the recovery process for a small number of\niterations by improving the gradient estimation. Then we compare Analysis and\nSynthesis by evaluating the performance of unrolled algorithms for inverse\nproblems, without access to any ground truth data for several classes of\ndictionaries and priors. While Analysis can achieve good results,Synthesis is\nmore robust and performs better. Finally, we illustrate our method on pattern\nand structure learning tasks from degraded measurements.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 12:21:26 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Mal\u00e9zieux", "Beno\u00eet", ""], ["Moreau", "Thomas", ""], ["Kowalski", "Matthieu", ""]]}, {"id": "2106.06406", "submitter": "Sang-gil Lee", "authors": "Sang-gil Lee, Heeseung Kim, Chaehun Shin, Xu Tan, Chang Liu, Qi Meng,\n  Tao Qin, Wei Chen, Sungroh Yoon, Tie-Yan Liu", "title": "PriorGrad: Improving Conditional Denoising Diffusion Models with\n  Data-Driven Adaptive Prior", "comments": "16 pages, 5 figures, 7 tables. Audio samples:\n  https://speechresearch.github.io/priorgrad/", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising diffusion probabilistic models have been recently proposed to\ngenerate high-quality samples by estimating the gradient of the data density.\nThe framework assumes the prior noise as a standard Gaussian distribution,\nwhereas the corresponding data distribution may be more complicated than the\nstandard Gaussian distribution, which potentially introduces inefficiency in\ndenoising the prior noise into the data sample because of the discrepancy\nbetween the data and the prior. In this paper, we propose PriorGrad to improve\nthe efficiency of the conditional diffusion model (for example, a vocoder using\na mel-spectrogram as the condition) by applying an adaptive prior derived from\nthe data statistics based on the conditional information. We formulate the\ntraining and sampling procedures of PriorGrad and demonstrate the advantages of\nan adaptive prior through a theoretical analysis. Focusing on the audio domain,\nwe consider the recently proposed diffusion-based audio generative models based\non both the spectral and time domains and show that PriorGrad achieves a faster\nconvergence leading to data and parameter efficiency and improved quality, and\nthereby demonstrating the efficiency of a data-driven adaptive prior.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 14:04:03 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Lee", "Sang-gil", ""], ["Kim", "Heeseung", ""], ["Shin", "Chaehun", ""], ["Tan", "Xu", ""], ["Liu", "Chang", ""], ["Meng", "Qi", ""], ["Qin", "Tao", ""], ["Chen", "Wei", ""], ["Yoon", "Sungroh", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2106.06430", "submitter": "Laura M. Wolf", "authors": "Laura M. Wolf and Marcus Baum", "title": "Continuous Herded Gibbs Sampling", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herding is a technique to sequentially generate deterministic samples from a\nprobability distribution. In this work, we propose a continuous herded Gibbs\nsampler, that combines kernel herding on continuous densities with Gibbs\nsampling. Our algorithm allows for deterministically sampling from\nhigh-dimensional multivariate probability densities, without directly sampling\nfrom the joint density. Experiments with Gaussian mixture densities indicate\nthat the L2 error decreases similarly to kernel herding, while the computation\ntime is significantly lower, i.e., linear in the number of dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 14:37:40 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wolf", "Laura M.", ""], ["Baum", "Marcus", ""]]}, {"id": "2106.06468", "submitter": "Ofir Lindenbaum", "authors": "Junchen Yang, Ofir Lindenbaum, Yuval Kluger", "title": "Locally Sparse Networks for Interpretable Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the enormous success of neural networks, they are still hard to\ninterpret and often overfit when applied to low-sample-size (LSS) datasets. To\ntackle these obstacles, we propose a framework for training locally sparse\nneural networks where the local sparsity is learned via a sample-specific\ngating mechanism that identifies the subset of most relevant features for each\nmeasurement. The sample-specific sparsity is predicted via a \\textit{gating}\nnetwork, which is trained in tandem with the \\textit{prediction} network. By\nlearning these subsets and weights of a prediction model, we obtain an\ninterpretable neural network that can handle LSS data and can remove nuisance\nvariables, which are irrelevant for the supervised learning task. Using both\nsynthetic and real-world datasets, we demonstrate that our method outperforms\nstate-of-the-art models when predicting the target function with far fewer\nfeatures per instance.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 15:46:50 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Yang", "Junchen", ""], ["Lindenbaum", "Ofir", ""], ["Kluger", "Yuval", ""]]}, {"id": "2106.06478", "submitter": "Liwei Wang", "authors": "Liwei Wang, Anton van Beek, Daicong Da, Yu-Chin Chan, Ping Zhu, Wei\n  Chen", "title": "Data-Driven Multiscale Design of Cellular Composites with Multiclass\n  Microstructures for Natural Frequency Maximization", "comments": "Preprint submitted to Composite Structures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For natural frequency optimization of engineering structures, cellular\ncomposites have been shown to possess an edge over solid. However, existing\nmultiscale design methods for cellular composites are either computationally\nexhaustive or confined to a single class of microstructures. In this paper, we\npropose a data-driven topology optimization (TO) approach to enable the\nmultiscale design of cellular structures with various choices of microstructure\nclasses. The key component is a newly proposed latent-variable Gaussian process\n(LVGP) model through which different classes of microstructures are mapped into\na low-dimensional continuous latent space. It provides an interpretable\ndistance metric between classes and captures their effects on the homogenized\nstiffness tensors. By introducing latent vectors as design variables, a\ndifferentiable transition of stiffness matrix between classes can be easily\nachieved with an analytical gradient. After integrating LVGP with the\ndensity-based TO, an efficient data-driven cellular composite optimization\nprocess is developed to enable concurrent exploration of microstructure\nconcepts and the associated volume fractions for natural frequency\noptimization. Examples reveal that the proposed cellular designs with\nmulticlass microstructures achieve higher natural frequencies than both\nsingle-scale and single-class designs. This framework can be easily extended to\nother multi-scale TO problems, such as thermal compliance and dynamic response\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 15:59:33 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wang", "Liwei", ""], ["van Beek", "Anton", ""], ["Da", "Daicong", ""], ["Chan", "Yu-Chin", ""], ["Zhu", "Ping", ""], ["Chen", "Wei", ""]]}, {"id": "2106.06483", "submitter": "Sanath Kumar Krishnamurthy", "authors": "Sanath Kumar Krishnamurthy, Susan Athey", "title": "Optimal Model Selection in Contextual Bandits with Many Classes via\n  Offline Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of model selection for contextual bandits, in which the\nalgorithm must balance the bias-variance trade-off for model estimation while\nalso balancing the exploration-exploitation trade-off. In this paper, we\npropose the first reduction of model selection in contextual bandits to offline\nmodel selection oracles, allowing for flexible general purpose algorithms with\ncomputational requirements no worse than those for model selection for\nregression. Our main result is a new model selection guarantee for stochastic\ncontextual bandits. When one of the classes in our set is realizable, up to a\nlogarithmic dependency on the number of classes, our algorithm attains optimal\nrealizability-based regret bounds for that class under one of two conditions:\nif the time-horizon is large enough, or if an assumption that helps with\ndetecting misspecification holds. Hence our algorithm adapts to the complexity\nof this unknown class. Even when this realizable class is known, we prove\nimproved regret guarantees in early rounds by relying on simpler model classes\nfor those rounds and hence further establish the importance of model selection\nin contextual bandits.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 16:08:03 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Krishnamurthy", "Sanath Kumar", ""], ["Athey", "Susan", ""]]}, {"id": "2106.06510", "submitter": "Soumya Ghosh", "authors": "William T. Stephenson, Soumya Ghosh, Tin D. Nguyen, Mikhail Yurochkin,\n  Sameer K. Deshpande, Tamara Broderick", "title": "Measuring the sensitivity of Gaussian processes to kernel choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian processes (GPs) are used to make medical and scientific decisions,\nincluding in cardiac care and monitoring of carbon dioxide emissions. But the\nchoice of GP kernel is often somewhat arbitrary. In particular, uncountably\nmany kernels typically align with qualitative prior knowledge (e.g. function\nsmoothness or stationarity). But in practice, data analysts choose among a\nhandful of convenient standard kernels (e.g. squared exponential). In the\npresent work, we ask: Would decisions made with a GP differ under other,\nqualitatively interchangeable kernels? We show how to formulate this\nsensitivity analysis as a constrained optimization problem over a\nfinite-dimensional space. We can then use standard optimizers to identify\nsubstantive changes in relevant decisions made with a GP. We demonstrate in\nboth synthetic and real-world examples that decisions made with a GP can\nexhibit substantial sensitivity to kernel choice, even when prior draws are\nqualitatively interchangeable to a user.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:09:53 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Stephenson", "William T.", ""], ["Ghosh", "Soumya", ""], ["Nguyen", "Tin D.", ""], ["Yurochkin", "Mikhail", ""], ["Deshpande", "Sameer K.", ""], ["Broderick", "Tamara", ""]]}, {"id": "2106.06513", "submitter": "Luca Ratti", "authors": "Giovanni S. Alberti, Ernesto De Vito, Matti Lassas, Luca Ratti, Matteo\n  Santacesaria", "title": "Learning the optimal regularizer for inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the linear inverse problem $y=Ax+\\epsilon$, where\n$A\\colon X\\to Y$ is a known linear operator between the separable Hilbert\nspaces $X$ and $Y$, $x$ is a random variable in $X$ and $\\epsilon$ is a\nzero-mean random process in $Y$. This setting covers several inverse problems\nin imaging including denoising, deblurring, and X-ray tomography. Within the\nclassical framework of regularization, we focus on the case where the\nregularization functional is not given a priori but learned from data. Our\nfirst result is a characterization of the optimal generalized Tikhonov\nregularizer, with respect to the mean squared error. We find that it is\ncompletely independent of the forward operator $A$ and depends only on the mean\nand covariance of $x$. Then, we consider the problem of learning the\nregularizer from a finite training set in two different frameworks: one\nsupervised, based on samples of both $x$ and $y$, and one unsupervised, based\nonly on samples of $x$. In both cases, we prove generalization bounds, under\nsome weak assumptions on the distribution of $x$ and $\\epsilon$, including the\ncase of sub-Gaussian variables. Our bounds hold in infinite-dimensional spaces,\nthereby showing that finer and finer discretizations do not make this learning\nproblem harder. The results are validated through numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:14:27 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Alberti", "Giovanni S.", ""], ["De Vito", "Ernesto", ""], ["Lassas", "Matti", ""], ["Ratti", "Luca", ""], ["Santacesaria", "Matteo", ""]]}, {"id": "2106.06515", "submitter": "Zhiyuan Lin", "authors": "Zhiyuan Lin, Hao Sheng, Sharad Goel", "title": "Probability Paths and the Structure of Predictions over Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In settings ranging from weather forecasts to political prognostications to\nfinancial projections, probability estimates of future binary outcomes often\nevolve over time. For example, the estimated likelihood of rain on a specific\nday changes by the hour as new information becomes available. Given a\ncollection of such probability paths, we introduce a Bayesian framework --\nwhich we call the Gaussian latent information martingale, or GLIM -- for\nmodeling the structure of dynamic predictions over time. Suppose, for example,\nthat the likelihood of rain in a week is 50%, and consider two hypothetical\nscenarios. In the first, one expects the forecast is equally likely to become\neither 25% or 75% tomorrow; in the second, one expects the forecast to stay\nconstant for the next several days. A time-sensitive decision-maker might\nselect a course of action immediately in the latter scenario, but may postpone\ntheir decision in the former, knowing that new information is imminent. We\nmodel these trajectories by assuming predictions update according to a latent\nprocess of information flow, which is inferred from historical data. In\ncontrast to general methods for time series analysis, this approach preserves\nthe martingale structure of probability paths and better quantifies future\nuncertainties around probability paths. We show that GLIM outperforms three\npopular baseline methods, producing better estimated posterior probability path\ndistributions measured by three different metrics. By elucidating the dynamic\nstructure of predictions over time, we hope to help individuals make more\ninformed choices.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:18:05 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Lin", "Zhiyuan", ""], ["Sheng", "Hao", ""], ["Goel", "Sharad", ""]]}, {"id": "2106.06526", "submitter": "Shiji Zhou", "authors": "Shiji Zhou, Han Zhao, Shanghang Zhang, Lianzhe Wang, Heng Chang, Zhi\n  Wang, Wenwu Zhu", "title": "Online Continual Adaptation with Active Self-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models trained with offline data often suffer from continual distribution\nshifts and expensive labeling in changing environments. This calls for a new\nonline learning paradigm where the learner can continually adapt to changing\nenvironments with limited labels. In this paper, we propose a new online\nsetting -- Online Active Continual Adaptation, where the learner aims to\ncontinually adapt to changing distributions using both unlabeled samples and\nactive queries of limited labels. To this end, we propose Online Self-Adaptive\nMirror Descent (OSAMD), which adopts an online teacher-student structure to\nenable online self-training from unlabeled data, and a margin-based criterion\nthat decides whether to query the labels to track changing distributions.\nTheoretically, we show that, in the separable case, OSAMD has an $O({T}^{1/2})$\ndynamic regret bound under mild assumptions, which is even tighter than the\nlower bound $\\Omega(T^{2/3})$ of traditional online learning with full labels.\nIn the general case, we show a regret bound of $O({\\alpha^*}^{1/3} {T}^{2/3} +\n\\alpha^* T)$, where $\\alpha^*$ denotes the separability of domains and is\nusually small. Our theoretical results show that OSAMD can fast adapt to\nchanging environments with active queries. Empirically, we demonstrate that\nOSAMD achieves favorable regrets under changing environments with limited\nlabels on both simulated and real-world data, which corroborates our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:51:25 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Zhou", "Shiji", ""], ["Zhao", "Han", ""], ["Zhang", "Shanghang", ""], ["Wang", "Lianzhe", ""], ["Chang", "Heng", ""], ["Wang", "Zhi", ""], ["Zhu", "Wenwu", ""]]}, {"id": "2106.06528", "submitter": "Yi-Lin Tuan", "authors": "Yi-Lin Tuan, Connor Pryor, Wenhu Chen, Lise Getoor, William Yang Wang", "title": "Local Explanation of Dialogue Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In comparison to the interpretation of classification models, the explanation\nof sequence generation models is also an important problem, however it has seen\nlittle attention. In this work, we study model-agnostic explanations of a\nrepresentative text generation task -- dialogue response generation. Dialog\nresponse generation is challenging with its open-ended sentences and multiple\nacceptable responses. To gain insights into the reasoning process of a\ngeneration model, we propose anew method, local explanation of response\ngeneration (LERG) that regards the explanations as the mutual interaction of\nsegments in input and output sentences. LERG views the sequence prediction as\nuncertainty estimation of a human response and then creates explanations by\nperturbing the input and calculating the certainty change over the human\nresponse. We show that LERG adheres to desired properties of explanations for\ntext generation including unbiased approximation, consistency and cause\nidentification. Empirically, our results show that our method consistently\nimproves other widely used methods on proposed automatic- and human- evaluation\nmetrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can\nextract both explicit and implicit relations between input and output segments.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:58:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Tuan", "Yi-Lin", ""], ["Pryor", "Connor", ""], ["Chen", "Wenhu", ""], ["Getoor", "Lise", ""], ["Wang", "William Yang", ""]]}, {"id": "2106.06529", "submitter": "Geoff Pleiss", "authors": "Geoff Pleiss, John P. Cunningham", "title": "The Limitations of Large Width in Neural Networks: A Deep Gaussian\n  Process Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large width limits have been a recent focus of deep learning research: modulo\ncomputational practicalities, do wider networks outperform narrower ones?\nAnswering this question has been challenging, as conventional networks gain\nrepresentational power with width, potentially masking any negative effects.\nOur analysis in this paper decouples capacity and width via the generalization\nof neural networks to Deep Gaussian Processes (Deep GP), a class of\nhierarchical models that subsume neural nets. In doing so, we aim to understand\nhow width affects standard neural networks once they have sufficient capacity\nfor a given modeling task. Our theoretical and empirical results on Deep GP\nsuggest that large width is generally detrimental to hierarchical models.\nSurprisingly, we prove that even nonparametric Deep GP converge to Gaussian\nprocesses, effectively becoming shallower without any increase in\nrepresentational power. The posterior, which corresponds to a mixture of\ndata-adaptable basis functions, becomes less data-dependent with width. Our\ntail analysis demonstrates that width and depth have opposite effects: depth\naccentuates a model's non-Gaussianity, while width makes models increasingly\nGaussian. We find there is a \"sweet spot\" that maximizes test set performance\nbefore the limiting GP behavior prevents adaptability, occurring at width = 1\nor width = 2 for nonparametric Deep GP. These results make strong predictions\nabout the same phenomenon in conventional neural networks: we show empirically\nthat many neural network architectures need 10 - 500 hidden units for\nsufficient capacity - depending on the dataset - but further width degrades\ntest performance.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:58:58 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Pleiss", "Geoff", ""], ["Cunningham", "John P.", ""]]}, {"id": "2106.06530", "submitter": "Alex Damian", "authors": "Alex Damian, Tengyu Ma, Jason Lee", "title": "Label Noise SGD Provably Prefers Flat Global Minimizers", "comments": "53 pages, 4 figures, under review for NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In overparametrized models, the noise in stochastic gradient descent (SGD)\nimplicitly regularizes the optimization trajectory and determines which local\nminimum SGD converges to. Motivated by empirical studies that demonstrate that\ntraining with noisy labels improves generalization, we study the implicit\nregularization effect of SGD with label noise. We show that SGD with label\nnoise converges to a stationary point of a regularized loss $L(\\theta) +\\lambda\nR(\\theta)$, where $L(\\theta)$ is the training loss, $\\lambda$ is an effective\nregularization parameter depending on the step size, strength of the label\nnoise, and the batch size, and $R(\\theta)$ is an explicit regularizer that\npenalizes sharp minimizers. Our analysis uncovers an additional regularization\neffect of large learning rates beyond the linear scaling rule that penalizes\nlarge eigenvalues of the Hessian more than small ones. We also prove extensions\nto classification with general loss functions, SGD with momentum, and SGD with\ngeneral noise covariance, significantly strengthening the prior work of Blanc\net al. to global convergence and large learning rates and of HaoChen et al. to\ngeneral models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:59:07 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Damian", "Alex", ""], ["Ma", "Tengyu", ""], ["Lee", "Jason", ""]]}, {"id": "2106.06573", "submitter": "Xiang Wang", "authors": "Rong Ge, Yunwei Ren, Xiang Wang, Mo Zhou", "title": "Understanding Deflation Process in Over-parametrized Tensor\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the training dynamics for gradient flow on\nover-parametrized tensor decomposition problems. Empirically, such training\nprocess often first fits larger components and then discovers smaller\ncomponents, which is similar to a tensor deflation process that is commonly\nused in tensor decomposition algorithms. We prove that for orthogonally\ndecomposable tensor, a slightly modified version of gradient flow would follow\na tensor deflation process and recover all the tensor components. Our proof\nsuggests that for orthogonal tensors, gradient flow dynamics works similarly as\ngreedy low-rank learning in the matrix setting, which is a first step towards\nunderstanding the implicit regularization effect of over-parametrized models\nfor low-rank tensors.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 18:51:36 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ge", "Rong", ""], ["Ren", "Yunwei", ""], ["Wang", "Xiang", ""], ["Zhou", "Mo", ""]]}, {"id": "2106.06607", "submitter": "Kartik Ahuja", "authors": "Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Yoshua Bengio, Ioannis\n  Mitliagkas, Irina Rish", "title": "Invariance Principle Meets Information Bottleneck for\n  Out-of-Distribution Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The invariance principle from causality is at the heart of notable approaches\nsuch as invariant risk minimization (IRM) that seek to address\nout-of-distribution (OOD) generalization failures. Despite the promising\ntheory, invariance principle-based approaches fail in common classification\ntasks, where invariant (causal) features capture all the information about the\nlabel. Are these failures due to the methods failing to capture the invariance?\nOr is the invariance principle itself insufficient? To answer these questions,\nwe revisit the fundamental assumptions in linear regression tasks, where\ninvariance-based approaches were shown to provably generalize OOD. In contrast\nto the linear regression tasks, we show that for linear classification tasks we\nneed much stronger restrictions on the distribution shifts, or otherwise OOD\ngeneralization is impossible. Furthermore, even with appropriate restrictions\non distribution shifts in place, we show that the invariance principle alone is\ninsufficient. We prove that a form of the information bottleneck constraint\nalong with invariance helps address key failures when invariant features\ncapture all the information about the label and also retains the existing\nsuccess when they do not. We propose an approach that incorporates both of\nthese principles and demonstrate its effectiveness in several experiments.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 20:42:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ahuja", "Kartik", ""], ["Caballero", "Ethan", ""], ["Zhang", "Dinghuai", ""], ["Bengio", "Yoshua", ""], ["Mitliagkas", "Ioannis", ""], ["Rish", "Irina", ""]]}, {"id": "2106.06608", "submitter": "Nhat Ho", "authors": "Nhat Ho, Stephen G. Walker", "title": "Statistical Analysis from the Fourier Integral Theorem", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking the Fourier integral theorem as our starting point, in this paper we\nfocus on natural Monte Carlo and fully nonparametric estimators of multivariate\ndistributions and conditional distribution functions. We do this without the\nneed for any estimated covariance matrix or dependence structure between\nvariables. These aspects arise immediately from the integral theorem. Being\nable to model multivariate data sets using conditional distribution functions\nwe can study a number of problems, such as prediction for Markov processes,\nestimation of mixing distribution functions which depend on covariates, and\ngeneral multivariate data. Estimators are explicit Monte Carlo based and\nrequire no recursive or iterative algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 20:44:54 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ho", "Nhat", ""], ["Walker", "Stephen G.", ""]]}, {"id": "2106.06610", "submitter": "Soledad Villar", "authors": "Soledad Villar (JHU), David W.Hogg (Flatiron, NYU), Kate Storey-Fisher\n  (NYU), Weichi Yao (NYU), Ben Blum-Smith (NYU)", "title": "Scalars are universal: Gauge-equivariant machine learning, structured\n  like classical physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been enormous progress in the last few years in designing\nconceivable (though not always practical) neural networks that respect the\ngauge symmetries -- or coordinate freedom -- of physical law. Some of these\nframeworks make use of irreducible representations, some make use of higher\norder tensor objects, and some apply symmetry-enforcing constraints. Different\nphysical laws obey different combinations of fundamental symmetries, but a\nlarge fraction (possibly all) of classical physics is equivariant to\ntranslation, rotation, reflection (parity), boost (relativity), and\npermutations. Here we show that it is simple to parameterize universally\napproximating polynomial functions that are equivariant under these symmetries,\nor under the Euclidean, Lorentz, and Poincar\\'e groups, at any dimensionality\n$d$. The key observation is that nonlinear O($d$)-equivariant (and\nrelated-group-equivariant) functions can be expressed in terms of a lightweight\ncollection of scalars -- scalar products and scalar contractions of the scalar,\nvector, and tensor inputs. These results demonstrate theoretically that\ngauge-invariant deep learning models for classical physics with good scaling\nfor large problems are feasible right now.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 20:51:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Villar", "Soledad", "", "JHU"], ["Hogg", "David W.", "", "Flatiron, NYU"], ["Storey-Fisher", "Kate", "", "NYU"], ["Yao", "Weichi", "", "NYU"], ["Blum-Smith", "Ben", "", "NYU"]]}, {"id": "2106.06691", "submitter": "Aaron Schein", "authors": "Aaron Schein, Anjali Nagulpally, Hanna Wallach, Patrick Flaherty", "title": "Doubly Non-Central Beta Matrix Factorization for DNA Methylation Data", "comments": "To appear in the Proceedings of the Conference on Uncertainty in\n  Artificial Intelligence (UAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new non-negative matrix factorization model for $(0,1)$\nbounded-support data based on the doubly non-central beta (DNCB) distribution,\na generalization of the beta distribution. The expressiveness of the DNCB\ndistribution is particularly useful for modeling DNA methylation datasets,\nwhich are typically highly dispersed and multi-modal; however, the model\nstructure is sufficiently general that it can be adapted to many other domains\nwhere latent representations of $(0,1)$ bounded-support data are of interest.\nAlthough the DNCB distribution lacks a closed-form conjugate prior, several\naugmentations let us derive an efficient posterior inference algorithm composed\nentirely of analytic updates. Our model improves out-of-sample predictive\nperformance on both real and synthetic DNA methylation datasets over\nstate-of-the-art methods in bioinformatics. In addition, our model yields\nmeaningful latent representations that accord with existing biological\nknowledge.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 05:36:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Schein", "Aaron", ""], ["Nagulpally", "Anjali", ""], ["Wallach", "Hanna", ""], ["Flaherty", "Patrick", ""]]}, {"id": "2106.06695", "submitter": "Sanyam Kapoor", "authors": "Sanyam Kapoor, Marc Finzi, Ke Alexander Wang, Andrew Gordon Wilson", "title": "SKIing on Simplices: Kernel Interpolation on the Permutohedral Lattice\n  for Scalable Gaussian Processes", "comments": "International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods for scalable Gaussian processes use iterative\nalgorithms, requiring fast matrix vector multiplies (MVMs) with the covariance\nkernel. The Structured Kernel Interpolation (SKI) framework accelerates these\nMVMs by performing efficient MVMs on a grid and interpolating back to the\noriginal space. In this work, we develop a connection between SKI and the\npermutohedral lattice used for high-dimensional fast bilateral filtering. Using\na sparse simplicial grid instead of a dense rectangular one, we can perform GP\ninference exponentially faster in the dimension than SKI. Our approach,\nSimplex-GP, enables scaling SKI to high dimensions, while maintaining strong\npredictive performance. We additionally provide a CUDA implementation of\nSimplex-GP, which enables significant GPU acceleration of MVM based inference.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 06:04:56 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kapoor", "Sanyam", ""], ["Finzi", "Marc", ""], ["Wang", "Ke Alexander", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2106.06741", "submitter": "Mengmeng Li", "authors": "Mengmeng Li, Tobias Sutter, Daniel Kuhn", "title": "Distributionally Robust Optimization with Markovian Data", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a stochastic program where the probability distribution of the\nuncertain problem parameters is unknown and only indirectly observed via\nfinitely many correlated samples generated by an unknown Markov chain with $d$\nstates. We propose a data-driven distributionally robust optimization model to\nestimate the problem's objective function and optimal solution. By leveraging\nresults from large deviations theory, we derive statistical guarantees on the\nquality of these estimators. The underlying worst-case expectation problem is\nnonconvex and involves $\\mathcal O(d^2)$ decision variables. Thus, it cannot be\nsolved efficiently for large $d$. By exploiting the structure of this problem,\nwe devise a customized Frank-Wolfe algorithm with convex direction-finding\nsubproblems of size $\\mathcal O(d)$. We prove that this algorithm finds a\nstationary point efficiently under mild conditions. The efficiency of the\nmethod is predicated on a dimensionality reduction enabled by a dual\nreformulation. Numerical experiments indicate that our approach has better\ncomputational and statistical properties than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 10:59:02 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Mengmeng", ""], ["Sutter", "Tobias", ""], ["Kuhn", "Daniel", ""]]}, {"id": "2106.06845", "submitter": "Rongguang Wang", "authors": "Rongguang Wang, Pratik Chaudhari, Christos Davatzikos", "title": "Harmonization with Flow-based Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heterogeneity in medical data, e.g., from data collected at different sites\nand with different protocols in a clinical study, is a fundamental hurdle for\naccurate prediction using machine learning models, as such models often fail to\ngeneralize well. This paper leverages a recently proposed\nnormalizing-flow-based method to perform counterfactual inference upon a\nstructural causal model (SCM), in order to achieve harmonization of such data.\nA causal model is used to model observed effects (brain magnetic resonance\nimaging data) that result from known confounders (site, gender and age) and\nexogenous noise variables. Our formulation exploits the bijection induced by\nflow for the purpose of harmonization. We infer the posterior of exogenous\nvariables, intervene on observations, and draw samples from the resultant SCM\nto obtain counterfactuals. This approach is evaluated extensively on multiple,\nlarge, real-world medical datasets and displayed better cross-domain\ngeneralization compared to state-of-the-art algorithms. Further experiments\nthat evaluate the quality of confounder-independent data generated by our model\nusing regression and classification tasks are provided.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 19:57:35 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 19:17:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Rongguang", ""], ["Chaudhari", "Pratik", ""], ["Davatzikos", "Christos", ""]]}, {"id": "2106.06854", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, David Meger, Doina Precup", "title": "A Deep Reinforcement Learning Approach to Marginalized Importance\n  Sampling with the Successor Representation", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Marginalized importance sampling (MIS), which measures the density ratio\nbetween the state-action occupancy of a target policy and that of a sampling\ndistribution, is a promising approach for off-policy evaluation. However,\ncurrent state-of-the-art MIS methods rely on complex optimization tricks and\nsucceed mostly on simple toy problems. We bridge the gap between MIS and deep\nreinforcement learning by observing that the density ratio can be computed from\nthe successor representation of the target policy. The successor representation\ncan be trained through deep reinforcement learning methodology and decouples\nthe reward optimization from the dynamics of the environment, making the\nresulting algorithm stable and applicable to high-dimensional domains. We\nevaluate the empirical performance of our approach on a variety of challenging\nAtari and MuJoCo environments.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 20:21:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fujimoto", "Scott", ""], ["Meger", "David", ""], ["Precup", "Doina", ""]]}, {"id": "2106.06860", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, Shixiang Shane Gu", "title": "A Minimalist Approach to Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offline reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data. Due to errors in value estimation from out-of-distribution\nactions, most offline RL algorithms take the approach of constraining or\nregularizing the policy with the actions contained in the dataset. Built on\npre-existing RL algorithms, modifications to make an RL algorithm work offline\ncomes at the cost of additional complexity. Offline RL algorithms introduce new\nhyperparameters and often leverage secondary components such as generative\nmodels, while adjusting the underlying RL algorithm. In this paper we aim to\nmake a deep RL algorithm work while making minimal changes. We find that we can\nmatch the performance of state-of-the-art offline RL algorithms by simply\nadding a behavior cloning term to the policy update of an online RL algorithm\nand normalizing the data. The resulting algorithm is a simple to implement and\ntune baseline, while more than halving the overall run time by removing the\nadditional computational overheads of previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 20:38:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fujimoto", "Scott", ""], ["Gu", "Shixiang Shane", ""]]}, {"id": "2106.06885", "submitter": "Genevieve Flaspohler", "authors": "Genevieve Flaspohler, Francesco Orabona, Judah Cohen, Soukayna\n  Mouatadid, Miruna Oprescu, Paulo Orenstein and Lester Mackey", "title": "Online Learning with Optimism and Delay", "comments": "ICML 2021. 9 pages of main paper and 26 pages of appendix text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inspired by the demands of real-time climate and weather forecasting, we\ndevelop optimistic online learning algorithms that require no parameter tuning\nand have optimal regret guarantees under delayed feedback. Our algorithms --\nDORM, DORM+, and AdaHedgeD -- arise from a novel reduction of delayed online\nlearning to optimistic online learning that reveals how optimistic hints can\nmitigate the regret penalty caused by delay. We pair this delay-as-optimism\nperspective with a new analysis of optimistic learning that exposes its\nrobustness to hinting errors and a new meta-algorithm for learning effective\nhinting strategies in the presence of delay. We conclude by benchmarking our\nalgorithms on four subseasonal climate forecasting tasks, demonstrating low\nregret relative to state-of-the-art forecasting models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 00:14:43 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 02:27:59 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 01:44:12 GMT"}, {"version": "v4", "created": "Mon, 12 Jul 2021 15:13:09 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Flaspohler", "Genevieve", ""], ["Orabona", "Francesco", ""], ["Cohen", "Judah", ""], ["Mouatadid", "Soukayna", ""], ["Oprescu", "Miruna", ""], ["Orenstein", "Paulo", ""], ["Mackey", "Lester", ""]]}, {"id": "2106.06891", "submitter": "Weiyu Li", "authors": "Feng Lin, Weiyu Li, Qing Ling", "title": "Stochastic Alternating Direction Method of Multipliers for\n  Byzantine-Robust Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to solve a distributed learning problem under Byzantine\nattacks. In the underlying distributed system, a number of unknown but\nmalicious workers (termed as Byzantine workers) can send arbitrary messages to\nthe master and bias the learning process, due to data corruptions, computation\nerrors or malicious attacks. Prior work has considered a total variation (TV)\nnorm-penalized approximation formulation to handle the Byzantine attacks, where\nthe TV norm penalty forces the regular workers' local variables to be close,\nand meanwhile, tolerates the outliers sent by the Byzantine workers. To solve\nthe TV norm-penalized approximation formulation, we propose a Byzantine-robust\nstochastic alternating direction method of multipliers (ADMM) that fully\nutilizes the separable problem structure. Theoretically, we prove that the\nproposed method converges to a bounded neighborhood of the optimal solution at\na rate of O(1/k) under mild assumptions, where k is the number of iterations\nand the size of neighborhood is determined by the number of Byzantine workers.\nNumerical experiments on the MNIST and COVERTYPE datasets demonstrate the\neffectiveness of the proposed method to various Byzantine attacks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 01:17:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lin", "Feng", ""], ["Li", "Weiyu", ""], ["Ling", "Qing", ""]]}, {"id": "2106.06916", "submitter": "Lixu Wang", "authors": "Lixu Wang, Shichao Xu, Ruiqi Xu, Xiao Wang, Qi Zhu", "title": "Non-Transferable Learning: A New Approach for Model Verification and\n  Authorization", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As Artificial Intelligence as a Service gains popularity, protecting\nwell-trained models as intellectual property is becoming increasingly\nimportant. Generally speaking, there are two common protection methods:\nownership verification and usage authorization. In this paper, we propose\nNon-Transferable Learning (NTL), a novel approach that captures the exclusive\ndata representation in the learned model and restricts the model generalization\nability to certain domains. This approach provides effective solutions to both\nmodel verification and authorization. For ownership verification, watermarking\ntechniques are commonly used but are often vulnerable to sophisticated\nwatermark removal methods. Our NTL-based model verification approach instead\nprovides robust resistance to state-of-the-art watermark removal methods, as\nshown in extensive experiments for four of such methods over the digits,\nCIFAR10 & STL10, and VisDA datasets. For usage authorization, prior solutions\nfocus on authorizing specific users to use the model, but authorized users can\nstill apply the model to any data without restriction. Our NTL-based\nauthorization approach instead provides data-centric usage protection by\nsignificantly degrading the performance of usage on unauthorized data. Its\neffectiveness is also shown through experiments on a variety of datasets.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 04:57:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wang", "Lixu", ""], ["Xu", "Shichao", ""], ["Xu", "Ruiqi", ""], ["Wang", "Xiao", ""], ["Zhu", "Qi", ""]]}, {"id": "2106.06926", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Ching-An Cheng, Nan Jiang, Paul Mineiro, Alekh Agarwal", "title": "Bellman-consistent Pessimism for Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of pessimism, when reasoning about datasets lacking exhaustive\nexploration has recently gained prominence in offline reinforcement learning.\nDespite the robustness it adds to the algorithm, overly pessimistic reasoning\ncan be equally damaging in precluding the discovery of good policies, which is\nan issue for the popular bonus-based pessimism. In this paper, we introduce the\nnotion of Bellman-consistent pessimism for general function approximation:\ninstead of calculating a point-wise lower bound for the value function, we\nimplement pessimism at the initial state over the set of functions consistent\nwith the Bellman equations. Our theoretical guarantees only require Bellman\nclosedness as standard in the exploratory setting, in which case bonus-based\npessimism fails to provide guarantees. Even in the special case of linear MDPs\nwhere stronger function-approximation assumptions hold, our result improves\nupon a recent bonus-based approach by $\\mathcal{O}(d)$ in its sample complexity\nwhen the action space is finite. Remarkably, our algorithms automatically adapt\nto the best bias-variance tradeoff in the hindsight, whereas most prior\napproaches require tuning extra hyperparameters a priori.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 05:50:36 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 21:58:54 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Xie", "Tengyang", ""], ["Cheng", "Ching-An", ""], ["Jiang", "Nan", ""], ["Mineiro", "Paul", ""], ["Agarwal", "Alekh", ""]]}, {"id": "2106.06997", "submitter": "Meet Vadera", "authors": "Meet P. Vadera, Soumya Ghosh, Kenney Ng, Benjamin M. Marlin", "title": "Post-hoc loss-calibration for Bayesian neural networks", "comments": "Accepted to Conference on Uncertainty in AI (UAI) '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian decision theory provides an elegant framework for acting optimally\nunder uncertainty when tractable posterior distributions are available. Modern\nBayesian models, however, typically involve intractable posteriors that are\napproximated with, potentially crude, surrogates. This difficulty has\nengendered loss-calibrated techniques that aim to learn posterior\napproximations that favor high-utility decisions. In this paper, focusing on\nBayesian neural networks, we develop methods for correcting approximate\nposterior predictive distributions encouraging them to prefer high-utility\ndecisions. In contrast to previous work, our approach is agnostic to the choice\nof the approximate inference algorithm, allows for efficient test time decision\nmaking through amortization, and empirically produces higher quality decisions.\nWe demonstrate the effectiveness of our approach through controlled experiments\nspanning a diversity of tasks and datasets.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 13:53:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Vadera", "Meet P.", ""], ["Ghosh", "Soumya", ""], ["Ng", "Kenney", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2106.07035", "submitter": "Tingting Zhao", "authors": "Tingting Zhao, Zifeng Wang, Aria Masoomi, Jennifer Dy", "title": "Deep Bayesian Unsupervised Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lifelong Learning (LL) refers to the ability to continually learn and solve\nnew problems with incremental available information over time while retaining\nprevious knowledge. Much attention has been given lately to Supervised Lifelong\nLearning (SLL) with a stream of labelled data. In contrast, we focus on\nresolving challenges in Unsupervised Lifelong Learning (ULL) with streaming\nunlabelled data when the data distribution and the unknown class labels evolve\nover time. Bayesian framework is natural to incorporate past knowledge and\nsequentially update the belief with new data. We develop a fully Bayesian\ninference framework for ULL with a novel end-to-end Deep Bayesian Unsupervised\nLifelong Learning (DBULL) algorithm, which can progressively discover new\nclusters without forgetting the past with unlabelled data while learning latent\nrepresentations. To efficiently maintain past knowledge, we develop a novel\nknowledge preservation mechanism via sufficient statistics of the latent\nrepresentation for raw data. To detect the potential new clusters on the fly,\nwe develop an automatic cluster discovery and redundancy removal strategy in\nour inference inspired by Nonparametric Bayesian statistics techniques. We\ndemonstrate the effectiveness of our approach using image and text corpora\nbenchmark datasets in both LL and batch settings.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 16:24:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Zhao", "Tingting", ""], ["Wang", "Zifeng", ""], ["Masoomi", "Aria", ""], ["Dy", "Jennifer", ""]]}, {"id": "2106.07052", "submitter": "Beau Coker", "authors": "Beau Coker, Weiwei Pan, Finale Doshi-Velez", "title": "Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational inference enables approximate posterior inference of the highly\nover-parameterized neural networks that are popular in modern machine learning.\nUnfortunately, such posteriors are known to exhibit various pathological\nbehaviors. We prove that as the number of hidden units in a single-layer\nBayesian neural network tends to infinity, the function-space posterior mean\nunder mean-field variational inference actually converges to zero, completely\nignoring the data. This is in contrast to the true posterior, which converges\nto a Gaussian process. Our work provides insight into the over-regularization\nof the KL divergence in variational inference.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 17:36:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Coker", "Beau", ""], ["Pan", "Weiwei", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2106.07062", "submitter": "Eric Korman", "authors": "Eric O. Korman", "title": "Atlas Based Representation and Metric Learning on Manifolds", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of a topological manifold, represented as a collection of\ncharts, as the target space of neural network based representation learning\ntasks. This is achieved by a simple adjustment to the output of an encoder's\nnetwork architecture plus the addition of a maximal mean discrepancy (MMD)\nbased loss function for regularization. Most algorithms in representation and\nmetric learning are easily adaptable to our framework and we demonstrate its\neffectiveness by adjusting SimCLR (for representation learning) and standard\ntriplet loss training (for metric learning) to have manifold encoding spaces.\nOur experiments show that we obtain a substantial performance boost over the\nbaseline for low dimensional encodings. In the case of triplet training, we\nalso find, independent of the manifold setup, that the MMD loss alone (i.e.\nkeeping a flat, euclidean target space but using an MMD loss to regularize it)\nincreases performance over the baseline in the typical, high-dimensional\nEuclidean target spaces. Code for reproducing experiments is provided at\nhttps://github.com/ekorman/neurve .\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 18:05:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Korman", "Eric O.", ""]]}, {"id": "2106.07094", "submitter": "Abolfazl Hashemi", "authors": "Rudrajit Das, Abolfazl Hashemi, Sujay Sanghavi, Inderjit S. Dhillon", "title": "DP-NormFedAvg: Normalizing Client Updates for Privacy-Preserving\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on facilitating differentially private quantized\ncommunication between the clients and server in federated learning (FL).\nTowards this end, we propose to have the clients send a \\textit{private\nquantized} version of only the \\textit{unit vector} along the change in their\nlocal parameters to the server, \\textit{completely throwing away the magnitude\ninformation}. We call this algorithm \\texttt{DP-NormFedAvg} and show that it\nhas the same order-wise convergence rate as \\texttt{FedAvg} on smooth\nquasar-convex functions (an important class of non-convex functions for\nmodeling optimization of deep neural networks), thereby establishing that\ndiscarding the magnitude information is not detrimental from an optimization\npoint of view. We also introduce QTDL, a new differentially private\nquantization mechanism for unit-norm vectors, which we use in\n\\texttt{DP-NormFedAvg}. QTDL employs \\textit{discrete} noise having a\nLaplacian-like distribution on a \\textit{finite support} to provide privacy. We\nshow that under a growth-condition assumption on the per-sample client losses,\nthe extra per-coordinate communication cost in each round incurred due to\nprivacy by our method is $\\mathcal{O}(1)$ with respect to the model dimension,\nwhich is an improvement over prior work. Finally, we show the efficacy of our\nproposed method with experiments on fully-connected neural networks trained on\nCIFAR-10 and Fashion-MNIST.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 21:23:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Das", "Rudrajit", ""], ["Hashemi", "Abolfazl", ""], ["Sanghavi", "Sujay", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "2106.07103", "submitter": "Liao Zhu", "authors": "Liao Zhu, Haoxuan Wu, Martin T. Wells", "title": "A News-based Machine Learning Model for Adaptive Asset Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a new asset pricing model -- the News Embedding UMAP\nSelection (NEUS) model, to explain and predict the stock returns based on the\nfinancial news. Using a combination of various machine learning algorithms, we\nfirst derive a company embedding vector for each basis asset from the financial\nnews. Then we obtain a collection of the basis assets based on their company\nembedding. After that for each stock, we select the basis assets to explain and\npredict the stock return with high-dimensional statistical methods. The new\nmodel is shown to have a significantly better fitting and prediction power than\nthe Fama-French 5-factor model.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 22:38:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhu", "Liao", ""], ["Wu", "Haoxuan", ""], ["Wells", "Martin T.", ""]]}, {"id": "2106.07106", "submitter": "Kevin O'Connor", "authors": "Kevin O'Connor, Bongsoo Yi, Kevin McGoff, Andrew B. Nobel", "title": "Graph Optimal Transport with Transition Couplings of Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to optimal transport between graphs from the\nperspective of stationary Markov chains. A weighted graph may be associated\nwith a stationary Markov chain by means of a random walk on the vertex set with\ntransition distributions depending on the edge weights of the graph. After\ndrawing this connection, we describe how optimal transport techniques for\nstationary Markov chains may be used in order to perform comparison and\nalignment of the graphs under study. In particular, we propose the graph\noptimal transition coupling problem, referred to as GraphOTC, in which the\nMarkov chains associated to two given graphs are optimally synchronized to\nminimize an expected cost. The joint synchronized chain yields an alignment of\nthe vertices and edges in the two graphs, and the expected cost of the\nsynchronized chain acts as a measure of distance or dissimilarity between the\ntwo graphs. We demonstrate that GraphOTC performs equal to or better than\nexisting state-of-the-art techniques in graph optimal transport for several\ntasks and datasets. Finally, we also describe a generalization of the GraphOTC\nproblem, called the FusedOTC problem, from which we recover the GraphOTC and OT\ncosts as special cases.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 23:02:53 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["O'Connor", "Kevin", ""], ["Yi", "Bongsoo", ""], ["McGoff", "Kevin", ""], ["Nobel", "Andrew B.", ""]]}, {"id": "2106.07115", "submitter": "Qi Lyu", "authors": "Qi Lyu, Xiao Fu, Weiran Wang and Songtao Lu", "title": "Latent Correlation-Based Multiview Learning and Self-Supervision: A\n  Unifying Perspective", "comments": "fixed some typos in the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple views of data, both naturally acquired (e.g., image and audio) and\nartificially produced (e.g., via adding different noise to data samples), have\nproven useful in enhancing representation learning. Natural views are often\nhandled by multiview analysis tools, e.g., (deep) canonical correlation\nanalysis [(D)CCA], while the artificial ones are frequently used in\nself-supervised learning (SSL) paradigms, e.g., SimCLR and Barlow Twins. Both\ntypes of approaches often involve learning neural feature extractors such that\nthe embeddings of data exhibit high cross-view correlations. Although\nintuitive, the effectiveness of correlation-based neural embedding is only\nempirically validated. This work puts forth a theory-backed framework for\nunsupervised multiview learning. Our development starts with proposing a\nmultiview model, where each view is a nonlinear mixture of shared and private\ncomponents. Consequently, the learning problem boils down to shared/private\ncomponent identification and disentanglement. Under this model, latent\ncorrelation maximization is shown to guarantee the extraction of the shared\ncomponents across views (up to certain ambiguities). In addition, the private\ninformation in each view can be provably disentangled from the shared using\nproper regularization design. The method is tested on a series of tasks, e.g.,\ndownstream clustering, which all show promising performance. Our development\nalso provides a unifying perspective for understanding various DCCA and SSL\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 00:12:36 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 16:51:29 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lyu", "Qi", ""], ["Fu", "Xiao", ""], ["Wang", "Weiran", ""], ["Lu", "Songtao", ""]]}, {"id": "2106.07138", "submitter": "Shulei Wang", "authors": "Shulei Wang", "title": "Self-Supervised Metric Learning in Multi-View Data: A Downstream Task\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised metric learning has been a successful approach for learning a\ndistance from an unlabeled dataset. The resulting distance is broadly useful\nfor improving various distance-based downstream tasks, even when no information\nfrom downstream tasks is utilized in the metric learning stage. To gain\ninsights into this approach, we develop a statistical framework to\ntheoretically study how self-supervised metric learning can benefit downstream\ntasks in the context of multi-view data. Under this framework, we show that the\ntarget distance of metric learning satisfies several desired properties for the\ndownstream tasks. On the other hand, our investigation suggests the target\ndistance can be further improved by moderating each direction's weights. In\naddition, our analysis precisely characterizes the improvement by\nself-supervised metric learning on four commonly used downstream tasks: sample\nidentification, two-sample testing, $k$-means clustering, and $k$-nearest\nneighbor classification. As a by-product, we propose a simple spectral method\nfor self-supervised metric learning, which is computationally efficient and\nminimax optimal for estimating target distance. Finally, numerical experiments\nare presented to support the theoretical results in the paper.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 02:34:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wang", "Shulei", ""]]}, {"id": "2106.07148", "submitter": "Alberto Bietti", "authors": "Alberto Bietti, Luca Venturi, Joan Bruna", "title": "On the Sample Complexity of Learning with Geometric Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many supervised learning problems involve high-dimensional data such as\nimages, text, or graphs. In order to make efficient use of data, it is often\nuseful to leverage certain geometric priors in the problem at hand, such as\ninvariance to translations, permutation subgroups, or stability to small\ndeformations. We study the sample complexity of learning problems where the\ntarget function presents such invariance and stability properties, by\nconsidering spherical harmonic decompositions of such functions on the sphere.\nWe provide non-parametric rates of convergence for kernel methods, and show\nimprovements in sample complexity by a factor equal to the size of the group\nwhen using an invariant kernel over the group, compared to the corresponding\nnon-invariant kernel. These improvements are valid when the sample size is\nlarge enough, with an asymptotic behavior that depends on spectral properties\nof the group. Finally, these gains are extended beyond invariance groups to\nalso cover geometric stability to small deformations, modeled here as subsets\n(not necessarily subgroups) of permutations.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 03:51:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Bietti", "Alberto", ""], ["Venturi", "Luca", ""], ["Bruna", "Joan", ""]]}, {"id": "2106.07197", "submitter": "Yue Yu", "authors": "Yue Yu, Tian Gao, Naiyu Yin, Qiang Ji", "title": "DAGs with No Curl: An Efficient DAG Structure Learning Approach", "comments": "ICML2021, Code is available at\n  https://github.com/fishmoon1234/DAG-NoCurl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently directed acyclic graph (DAG) structure learning is formulated as a\nconstrained continuous optimization problem with continuous acyclicity\nconstraints and was solved iteratively through subproblem optimization. To\nfurther improve efficiency, we propose a novel learning framework to model and\nlearn the weighted adjacency matrices in the DAG space directly. Specifically,\nwe first show that the set of weighted adjacency matrices of DAGs are\nequivalent to the set of weighted gradients of graph potential functions, and\none may perform structure learning by searching in this equivalent set of DAGs.\nTo instantiate this idea, we propose a new algorithm, DAG-NoCurl, which solves\nthe optimization problem efficiently with a two-step procedure: 1) first we\nfind an initial cyclic solution to the optimization problem, and 2) then we\nemploy the Hodge decomposition of graphs and learn an acyclic graph by\nprojecting the cyclic graph to the gradient of a potential function.\nExperimental studies on benchmark datasets demonstrate that our method provides\ncomparable accuracy but better efficiency than baseline DAG structure learning\nmethods on both linear and generalized structural equation models, often by\nmore than one order of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 07:11:36 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yu", "Yue", ""], ["Gao", "Tian", ""], ["Yin", "Naiyu", ""], ["Ji", "Qiang", ""]]}, {"id": "2106.07203", "submitter": "Dingwen Kong", "authors": "Dingwen Kong, Ruslan Salakhutdinov, Ruosong Wang, Lin F. Yang", "title": "Online Sub-Sampling for Reinforcement Learning with General Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing provably efficient algorithms with general function approximation\nis an important open problem in reinforcement learning. Recently, Wang et\nal.~[2020c] establish a value-based algorithm with general function\napproximation that enjoys\n$\\widetilde{O}(\\mathrm{poly}(dH)\\sqrt{K})$\\footnote{Throughout the paper, we\nuse $\\widetilde{O}(\\cdot)$ to suppress logarithm factors. } regret bound, where\n$d$ depends on the complexity of the function class, $H$ is the planning\nhorizon, and $K$ is the total number of episodes. However, their algorithm\nrequires $\\Omega(K)$ computation time per round, rendering the algorithm\ninefficient for practical use. In this paper, by applying online sub-sampling\ntechniques, we develop an algorithm that takes\n$\\widetilde{O}(\\mathrm{poly}(dH))$ computation time per round on average, and\nenjoys nearly the same regret bound. Furthermore, the algorithm achieves low\nswitching cost, i.e., it changes the policy only\n$\\widetilde{O}(\\mathrm{poly}(dH))$ times during its execution, making it\nappealing to be implemented in real-life scenarios. Moreover, by using an\nupper-confidence based exploration-driven reward function, the algorithm\nprovably explores the environment in the reward-free setting. In particular,\nafter $\\widetilde{O}(\\mathrm{poly}(dH))/\\epsilon^2$ rounds of exploration, the\nalgorithm outputs an $\\epsilon$-optimal policy for any given reward function.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 07:36:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kong", "Dingwen", ""], ["Salakhutdinov", "Ruslan", ""], ["Wang", "Ruosong", ""], ["Yang", "Lin F.", ""]]}, {"id": "2106.07221", "submitter": "Guillaume Vidot", "authors": "Guillaume Vidot (IRIT-ARGOS), Christophe Gabreau, Ileana Ober\n  (IRIT-ARGOS), Iulian Ober (IRIT-ARGOS)", "title": "Certification of embedded systems based on Machine Learning: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine learning (ML) open the way to innovating functions in the\navionic domain, such as navigation/surveillance assistance (e.g. vision-based\nnavigation, obstacle sensing, virtual sensing), speechto-text applications,\nautonomous flight, predictive maintenance or cockpit assistance. Current\ncertification standards and practices, which were defined and refined decades\nover decades with classical programming in mind, do not however support this\nnew development paradigm. This article provides an overview of the main\nchallenges raised by the use ML in the demonstration of compliance with\nregulation requirements, and a survey of literature relevant to these\nchallenges, with particular focus on the issues of robustness and\nexplainability of ML results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:12:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Vidot", "Guillaume", "", "IRIT-ARGOS"], ["Gabreau", "Christophe", "", "IRIT-ARGOS"], ["Ober", "Ileana", "", "IRIT-ARGOS"], ["Ober", "Iulian", "", "IRIT-ARGOS"]]}, {"id": "2106.07222", "submitter": "Messan Martial Amovin-Assagba", "authors": "Martial Amovin-Assagba (ERIC, AMK), Ir\\`ene Gannaz, Julien Jacques\n  (ERIC)", "title": "Outlier detection in multivariate functional data through a contaminated\n  mixture model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is motivated by an application in an industrial context, where the\nactivity of sensors is recorded at a high frequency. The objective is to\nautomatically detect abnormal measurement behaviour. Considering the sensor\nmeasures as functional data, we are formally interested in detecting outliers\nin a multivariate functional data set. Due to the heterogeneity of this data\nset, the proposed contaminated mixture model both clusters the multivariate\nfunctional data into homogeneous groups and detects outliers. The main\nadvantage of this procedure over its competitors is that it does not require us\nto specify the proportion of outliers. Model inference is performed through an\nExpectation-Conditional Maximization algorithm, and the BIC criterion is used\nto select the number of clusters. Numerical experiments on simulated data\ndemonstrate the high performance achieved by the inference algorithm. In\nparticular, the proposed model outperforms competitors. Its application on the\nreal data which motivated this study allows us to correctly detect abnormal\nbehaviours.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:17:42 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Amovin-Assagba", "Martial", "", "ERIC, AMK"], ["Gannaz", "Ir\u00e8ne", "", "ERIC"], ["Jacques", "Julien", "", "ERIC"]]}, {"id": "2106.07250", "submitter": "Hidetaka Kamigaito", "authors": "Hidetaka Kamigaito, Katsuhiko Hayashi", "title": "Unified Interpretation of Softmax Cross-Entropy and Negative Sampling:\n  With Case Study for Knowledge Graph Embedding", "comments": "Accepted at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In knowledge graph embedding, the theoretical relationship between the\nsoftmax cross-entropy and negative sampling loss functions has not been\ninvestigated. This makes it difficult to fairly compare the results of the two\ndifferent loss functions. We attempted to solve this problem by using the\nBregman divergence to provide a unified interpretation of the softmax\ncross-entropy and negative sampling loss functions. Under this interpretation,\nwe can derive theoretical findings for fair comparison. Experimental results on\nthe FB15k-237 and WN18RR datasets show that the theoretical findings are valid\nin practical settings.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 09:07:02 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 07:12:21 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kamigaito", "Hidetaka", ""], ["Hayashi", "Katsuhiko", ""]]}, {"id": "2106.07255", "submitter": "Chuyang Ke", "authors": "Chuyang Ke, Jean Honorio", "title": "Federated Myopic Community Detection with One-shot Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of recovering the community structure of\na network under federated myopic learning. Under this paradigm, we have several\nclients, each of them having a myopic view, i.e., observing a small subgraph of\nthe network. Each client sends a censored evidence graph to a central server.\nWe provide an efficient algorithm, which computes a consensus signed weighted\ngraph from clients evidence, and recovers the underlying network structure in\nthe central server. We analyze the topological structure conditions of the\nnetwork, as well as the signal and noise levels of the clients that allow for\nrecovery of the network structure. Our analysis shows that exact recovery is\npossible and can be achieved in polynomial time. We also provide\ninformation-theoretic limits for the central server to recover the network\nstructure from any single client evidence. Finally, as a byproduct of our\nanalysis, we provide a novel Cheeger-type inequality for general signed\nweighted graphs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 09:17:00 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ke", "Chuyang", ""], ["Honorio", "Jean", ""]]}, {"id": "2106.07263", "submitter": "Yongyi Guo", "authors": "Yongyi Guo, Dominic Coey, Mikael Konutgan, Wenting Li, Chris Schoener,\n  Matt Goldman", "title": "Machine Learning for Variance Reduction in Online Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of variance reduction in randomized controlled\ntrials, through the use of covariates correlated with the outcome but\nindependent of the treatment. We propose a machine learning regression-adjusted\ntreatment effect estimator, which we call MLRATE. MLRATE uses machine learning\npredictors of the outcome to reduce estimator variance. It employs\ncross-fitting to avoid overfitting biases, and we prove consistency and\nasymptotic normality under general conditions. MLRATE is robust to poor\npredictions from the machine learning step: if the predictions are uncorrelated\nwith the outcomes, the estimator performs asymptotically no worse than the\nstandard difference-in-means estimator, while if predictions are highly\ncorrelated with outcomes, the efficiency gains are large. In A/A tests, for a\nset of 48 outcome metrics commonly monitored in Facebook experiments the\nestimator has over 70% lower variance than the simple difference-in-means\nestimator, and about 19% lower variance than the common univariate procedure\nwhich adjusts only for pre-experiment values of the outcome.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 09:35:54 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 22:28:27 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Guo", "Yongyi", ""], ["Coey", "Dominic", ""], ["Konutgan", "Mikael", ""], ["Li", "Wenting", ""], ["Schoener", "Chris", ""], ["Goldman", "Matt", ""]]}, {"id": "2106.07329", "submitter": "Yiming Zhang", "authors": "Yiming Zhang, Keith W. Ross", "title": "On-Policy Deep Reinforcement Learning for the Average-Reward Criterion", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop theory and algorithms for average-reward on-policy Reinforcement\nLearning (RL). We first consider bounding the difference of the long-term\naverage reward for two policies. We show that previous work based on the\ndiscounted return (Schulman et al., 2015; Achiam et al., 2017) results in a\nnon-meaningful bound in the average-reward setting. By addressing the\naverage-reward criterion directly, we then derive a novel bound which depends\non the average divergence between the two policies and Kemeny's constant. Based\non this bound, we develop an iterative procedure which produces a sequence of\nmonotonically improved policies for the average reward criterion. This\niterative procedure can then be combined with classic DRL (Deep Reinforcement\nLearning) methods, resulting in practical DRL algorithms that target the\nlong-run average reward criterion. In particular, we demonstrate that\nAverage-Reward TRPO (ATRPO), which adapts the on-policy TRPO algorithm to the\naverage-reward criterion, significantly outperforms TRPO in the most\nchallenging MuJuCo environments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 12:12:09 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Yiming", ""], ["Ross", "Keith W.", ""]]}, {"id": "2106.07445", "submitter": "Carl-Johann Simon-Gabriel", "authors": "Carl-Johann Simon-Gabriel and Noman Ahmed Sheikh and Andreas Krause", "title": "PopSkipJump: Decision-Based Attack for Probabilistic Classifiers", "comments": "ICML'21. Code available at https://github.com/cjsg/PopSkipJump . 9\n  pages & 7 figures in main part, 14 pages & 10 figures in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current classifiers are vulnerable to adversarial examples, small input\nperturbations that change the classification output. Many existing attack\nalgorithms cover various settings, from white-box to black-box classifiers, but\ntypically assume that the answers are deterministic and often fail when they\nare not. We therefore propose a new adversarial decision-based attack\nspecifically designed for classifiers with probabilistic outputs. It is based\non the HopSkipJump attack by Chen et al. (2019, arXiv:1904.02144v5 ), a strong\nand query efficient decision-based attack originally designed for deterministic\nclassifiers. Our P(robabilisticH)opSkipJump attack adapts its amount of queries\nto maintain HopSkipJump's original output quality across various noise levels,\nwhile converging to its query efficiency as the noise level decreases. We test\nour attack on various noise models, including state-of-the-art off-the-shelf\nrandomized defenses, and show that they offer almost no extra robustness to\ndecision-based attacks. Code is available at\nhttps://github.com/cjsg/PopSkipJump .\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:13:12 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Simon-Gabriel", "Carl-Johann", ""], ["Sheikh", "Noman Ahmed", ""], ["Krause", "Andreas", ""]]}, {"id": "2106.07452", "submitter": "Saad Hamid", "authors": "Saad Hamid, Sebastian Schulze, Michael A. Osborne, Stephen J. Roberts", "title": "Marginalising over Stationary Kernels with Bayesian Quadrature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginalising over families of Gaussian Process kernels produces flexible\nmodel classes with well-calibrated uncertainty estimates. Existing approaches\nrequire likelihood evaluations of many kernels, rendering them prohibitively\nexpensive for larger datasets. We propose a Bayesian Quadrature scheme to make\nthis marginalisation more efficient and thereby more practical. Through use of\nthe maximum mean discrepancies between distributions, we define a kernel over\nkernels that captures invariances between Spectral Mixture (SM) Kernels. Kernel\nsamples are selected by generalising an information-theoretic acquisition\nfunction for warped Bayesian Quadrature. We show that our framework achieves\nmore accurate predictions with better calibrated uncertainty than\nstate-of-the-art baselines, especially when given limited (wall-clock) time\nbudgets.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:23:34 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hamid", "Saad", ""], ["Schulze", "Sebastian", ""], ["Osborne", "Michael A.", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "2106.07454", "submitter": "Minghan Yang", "authors": "Minghan Yang, Dong Xu, Qiwen Cui, Zaiwen Wen and Pengxiang Xu", "title": "NG+ : A Multi-Step Matrix-Product Natural Gradient Method for Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel second-order method called NG+ is proposed. By\nfollowing the rule ``the shape of the gradient equals the shape of the\nparameter\", we define a generalized fisher information matrix (GFIM) using the\nproducts of gradients in the matrix form rather than the traditional\nvectorization. Then, our generalized natural gradient direction is simply the\ninverse of the GFIM multiplies the gradient in the matrix form. Moreover, the\nGFIM and its inverse keeps the same for multiple steps so that the\ncomputational cost can be controlled and is comparable with the first-order\nmethods. A global convergence is established under some mild conditions and a\nregret bound is also given for the online learning setting. Numerical results\non image classification with ResNet50, quantum chemistry modeling with Schnet,\nneural machine translation with Transformer and recommendation system with DLRM\nillustrate that GN+ is competitive with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:31:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yang", "Minghan", ""], ["Xu", "Dong", ""], ["Cui", "Qiwen", ""], ["Wen", "Zaiwen", ""], ["Xu", "Pengxiang", ""]]}, {"id": "2106.07462", "submitter": "Hanwen Xing", "authors": "Hanwen Xing", "title": "Improving Bridge estimators via $f$-GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bridge sampling is a powerful Monte Carlo method for estimating ratios of\nnormalizing constants. Various methods have been introduced to improve its\nefficiency. These methods aim to increase the overlap between the densities by\napplying appropriate transformations to them without changing their normalizing\nconstants. In this paper, we first give a new estimator of the asymptotic\nrelative mean square error (RMSE) of the optimal Bridge estimator by\nequivalently estimating an $f$-divergence between the two densities. We then\nutilize this framework and propose $f$-GAN-Bridge estimator ($f$-GB) based on a\nbijective transformation that maps one density to the other and minimizes the\nasymptotic RMSE of the optimal Bridge estimator with respect to the densities.\nThis transformation is chosen by minimizing a specific $f$-divergence between\nthe densities using an $f$-GAN. We show $f$-GB is optimal in the sense that\nwithin any given set of candidate transformations, the $f$-GB estimator can\nasymptotically achieve an RMSE lower than or equal to that achieved by Bridge\nestimators based on any other transformed densities. Numerical experiments show\nthat $f$-GB outperforms existing methods in simulated and real-world examples.\nIn addition, we discuss how Bridge estimators naturally arise from the problem\nof $f$-divergence estimation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:40:29 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 17:24:43 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Xing", "Hanwen", ""]]}, {"id": "2106.07472", "submitter": "Anas Barakat", "authors": "Anas Barakat, Pascal Bianchi, Julien Lehmann", "title": "Analysis of a Target-Based Actor-Critic Algorithm with Linear Function\n  Approximation", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Actor-critic methods integrating target networks have exhibited a stupendous\nempirical success in deep reinforcement learning. However, a theoretical\nunderstanding of the use of target networks in actor-critic methods is largely\nmissing in the literature. In this paper, we bridge this gap between theory and\npractice by proposing the first theoretical analysis of an online target-based\nactor-critic algorithm with linear function approximation in the discounted\nreward setting. Our algorithm uses three different timescales: one for the\nactor and two for the critic. Instead of using the standard single timescale\ntemporal difference (TD) learning algorithm as a critic, we use a two\ntimescales target-based version of TD learning closely inspired from practical\nactor-critic algorithms implementing target networks. First, we establish\nasymptotic convergence results for both the critic and the actor under\nMarkovian sampling. Then, we provide a finite-time analysis showing the impact\nof incorporating a target network into actor-critic methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 14:59:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Barakat", "Anas", ""], ["Bianchi", "Pascal", ""], ["Lehmann", "Julien", ""]]}, {"id": "2106.07479", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Zihang Meng, Rudrasis Chakraborty, Vikas Singh", "title": "An Online Riemannian PCA for Stochastic Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an efficient stochastic algorithm (RSG+) for canonical correlation\nanalysis (CCA) using a reparametrization of the projection matrices. We show\nhow this reparametrization (into structured matrices), simple in hindsight,\ndirectly presents an opportunity to repurpose/adjust mature techniques for\nnumerical optimization on Riemannian manifolds. Our developments nicely\ncomplement existing methods for this problem which either require $O(d^3)$ time\ncomplexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where\n$d$ is the dimensionality) or only extract the top $1$ component with\n$O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm offers a strict\nimprovement for this classical problem: it achieves $O(d^2k)$ runtime\ncomplexity per iteration for extracting the top $k$ canonical components with\n$O(\\frac{1}{t})$ convergence rate. While the paper primarily focuses on the\nformulation and technical analysis of its properties, our experiments show that\nthe empirical behavior on common datasets is quite promising. We also explore a\npotential application in training fair models where the label of protected\nattribute is missing or otherwise unavailable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 23:38:29 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Meng", "Zihang", ""], ["Chakraborty", "Rudrasis", ""], ["Singh", "Vikas", ""]]}, {"id": "2106.07492", "submitter": "Yaoyi Chen", "authors": "Yaoyi Chen, Andreas Kr\\\"amer, Nicholas E. Charron, Brooke E. Husic,\n  Cecilia Clementi, Frank No\\'e", "title": "Machine Learning Implicit Solvation for Molecular Dynamics", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph physics.bio-ph physics.chem-ph q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate modeling of the solvent environment for biological molecules is\ncrucial for computational biology and drug design. A popular approach to\nachieve long simulation time scales for large system sizes is to incorporate\nthe effect of the solvent in a mean-field fashion with implicit solvent models.\nHowever, a challenge with existing implicit solvent models is that they often\nlack accuracy or certain physical properties compared to explicit solvent\nmodels, as the many-body effects of the neglected solvent molecules is\ndifficult to model as a mean field. Here, we leverage machine learning (ML) and\nmulti-scale coarse graining (CG) in order to learn implicit solvent models that\ncan approximate the energetic and thermodynamic properties of a given explicit\nsolvent model with arbitrary accuracy, given enough training data. Following\nthe previous ML--CG models CGnet and CGSchnet, we introduce ISSNet, a graph\nneural network, to model the implicit solvent potential of mean force. ISSNet\ncan learn from explicit solvent simulation data and be readily applied to MD\nsimulations. We compare the solute conformational distributions under different\nsolvation treatments for two peptide systems. The results indicate that ISSNet\nmodels can outperform widely-used generalized Born and surface area models in\nreproducing the thermodynamics of small protein systems with respect to\nexplicit solvent. The success of this novel method demonstrates the potential\nbenefit of applying machine learning methods in accurate modeling of solvent\neffects for in silico research and biomedical applications.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 15:21:45 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Yaoyi", ""], ["Kr\u00e4mer", "Andreas", ""], ["Charron", "Nicholas E.", ""], ["Husic", "Brooke E.", ""], ["Clementi", "Cecilia", ""], ["No\u00e9", "Frank", ""]]}, {"id": "2106.07512", "submitter": "Martin J{\\o}rgensen", "authors": "Pola Schw\\\"obel, Martin J{\\o}rgensen, Sebastian W. Ober, Mark van der\n  Wilk", "title": "Last Layer Marginal Likelihood for Invariance Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is often used to incorporate inductive biases into models.\nTraditionally, these are hand-crafted and tuned with cross validation. The\nBayesian paradigm for model selection provides a path towards end-to-end\nlearning of invariances using only the training data, by optimising the\nmarginal likelihood. We work towards bringing this approach to neural networks\nby using an architecture with a Gaussian process in the last layer, a model for\nwhich the marginal likelihood can be computed. Experimentally, we improve\nperformance by learning appropriate invariances in standard benchmarks, the low\ndata regime and in a medical imaging task. Optimisation challenges for\ninvariant Deep Kernel Gaussian processes are identified, and a systematic\nanalysis is presented to arrive at a robust training scheme. We introduce a new\nlower bound to the marginal likelihood, which allows us to perform inference\nfor a larger class of likelihood functions than before, thereby overcoming some\nof the training challenges that existed with previous approaches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 15:40:51 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Schw\u00f6bel", "Pola", ""], ["J\u00f8rgensen", "Martin", ""], ["Ober", "Sebastian W.", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2106.07537", "submitter": "Theo Diamandis", "authors": "Theo Diamandis, Yonina C. Eldar, Alireza Fallah, Farzan Farnia, Asuman\n  Ozdaglar", "title": "A Wasserstein Minimax Framework for Mixed Linear Regression", "comments": "To appear in 38th International Conference on Machine Learning (ICML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal distributions are commonly used to model clustered data in\nstatistical learning tasks. In this paper, we consider the Mixed Linear\nRegression (MLR) problem. We propose an optimal transport-based framework for\nMLR problems, Wasserstein Mixed Linear Regression (WMLR), which minimizes the\nWasserstein distance between the learned and target mixture regression models.\nThrough a model-based duality analysis, WMLR reduces the underlying MLR task to\na nonconvex-concave minimax optimization problem, which can be provably solved\nto find a minimax stationary point by the Gradient Descent Ascent (GDA)\nalgorithm. In the special case of mixtures of two linear regression models, we\nshow that WMLR enjoys global convergence and generalization guarantees. We\nprove that WMLR's sample complexity grows linearly with the dimension of data.\nFinally, we discuss the application of WMLR to the federated learning task\nwhere the training samples are collected by multiple agents in a network.\nUnlike the Expectation Maximization algorithm, WMLR directly extends to the\ndistributed, federated learning setting. We support our theoretical results\nthrough several numerical experiments, which highlight our framework's ability\nto handle the federated learning setting with mixture models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 16:03:51 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 14:45:42 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Diamandis", "Theo", ""], ["Eldar", "Yonina C.", ""], ["Fallah", "Alireza", ""], ["Farnia", "Farzan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2106.07548", "submitter": "Karthik R. Ramaswamy", "authors": "Stefanie J.M. Fonken, Karthik R. Ramaswamy, Paul M.J. Van den Hof", "title": "A scalable multi-step least squares method for network identification\n  with unknown disturbance topology", "comments": "16 pages, 4 figures, Submitted to Automatica on 14th June 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification methods for dynamic networks typically require prior knowledge\nof the network and disturbance topology, and often rely on solving poorly\nscalable non-convex optimization problems. While methods for estimating network\ntopology are available in the literature, less attention has been paid to\nestimating the disturbance topology, i.e., the (spatial) noise correlation\nstructure and the noise rank. In this work we present an identification method\nfor dynamic networks, in which an estimation of the disturbance topology\nprecedes the identification of the full dynamic network with known network\ntopology. To this end we extend the multi-step Sequential Linear Regression and\nWeighted Null Space Fitting methods to deal with reduced rank noise, and use\nthese methods to estimate the disturbance topology and the network dynamics. As\na result, we provide a multi-step least squares algorithm with parallel\ncomputation capabilities and that rely only on explicit analytical solutions,\nthereby avoiding the usual non-convex optimizations involved. Consequently we\nconsistently estimate dynamic networks of Box Jenkins model structure, while\nkeeping the computational burden low. We provide a consistency proof that\nincludes path-based data informativity conditions for allocation of excitation\nsignals in the experimental design. Numerical simulations performed on a\ndynamic network with reduced rank noise clearly illustrate the potential of\nthis method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 16:12:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fonken", "Stefanie J. M.", ""], ["Ramaswamy", "Karthik R.", ""], ["Hof", "Paul M. J. Van den", ""]]}, {"id": "2106.07635", "submitter": "Yashas Annadani", "authors": "Yashas Annadani, Jonas Rothfuss, Alexandre Lacoste, Nino Scherrer,\n  Anirudh Goyal, Yoshua Bengio, Stefan Bauer", "title": "Variational Causal Networks: Approximate Bayesian Inference over Causal\n  Structures", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning the causal structure that underlies data is a crucial step towards\nrobust real-world decision making. The majority of existing work in causal\ninference focuses on determining a single directed acyclic graph (DAG) or a\nMarkov equivalence class thereof. However, a crucial aspect to acting\nintelligently upon the knowledge about causal structure which has been inferred\nfrom finite data demands reasoning about its uncertainty. For instance,\nplanning interventions to find out more about the causal mechanisms that govern\nour data requires quantifying epistemic uncertainty over DAGs. While Bayesian\ncausal inference allows to do so, the posterior over DAGs becomes intractable\neven for a small number of variables. Aiming to overcome this issue, we propose\na form of variational inference over the graphs of Structural Causal Models\n(SCMs). To this end, we introduce a parametric variational family modelled by\nan autoregressive distribution over the space of discrete DAGs. Its number of\nparameters does not grow exponentially with the number of variables and can be\ntractably learned by maximising an Evidence Lower Bound (ELBO). In our\nexperiments, we demonstrate that the proposed variational posterior is able to\nprovide a good approximation of the true posterior.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:52:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Annadani", "Yashas", ""], ["Rothfuss", "Jonas", ""], ["Lacoste", "Alexandre", ""], ["Scherrer", "Nino", ""], ["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""], ["Bauer", "Stefan", ""]]}, {"id": "2106.07636", "submitter": "Danica J. Sutherland", "authors": "Feng Liu and Wenkai Xu and Jie Lu and Danica J. Sutherland", "title": "Meta Two-Sample Testing: Learning Kernels for Testing with Limited Data", "comments": "Code is available from https://github.com/fengliu90/MetaTesting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern kernel-based two-sample tests have shown great success in\ndistinguishing complex, high-dimensional distributions with appropriate learned\nkernels. Previous work has demonstrated that this kernel learning procedure\nsucceeds, assuming a considerable number of observed samples from each\ndistribution. In realistic scenarios with very limited numbers of data samples,\nhowever, it can be challenging to identify a kernel powerful enough to\ndistinguish complex distributions. We address this issue by introducing the\nproblem of meta two-sample testing (M2ST), which aims to exploit (abundant)\nauxiliary data on related tasks to find an algorithm that can quickly identify\na powerful test on new target tasks. We propose two specific algorithms for\nthis task: a generic scheme which improves over baselines and amore tailored\napproach which performs even better. We provide both theoretical justification\nand empirical evidence that our proposed meta-testing schemes out-perform\nlearning kernel-based tests directly from scarce observations, and identify\nwhen such schemes will be successful.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:52:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liu", "Feng", ""], ["Xu", "Wenkai", ""], ["Lu", "Jie", ""], ["Sutherland", "Danica J.", ""]]}, {"id": "2106.07644", "submitter": "Mathieu Even", "authors": "Mathieu Even, Rapha\\\"el Berthier, Francis Bach, Nicolas Flammarion,\n  Pierre Gaillard, Hadrien Hendrikx, Laurent Massouli\\'e, Adrien Taylor", "title": "A Continuized View on Nesterov Acceleration for Stochastic Gradient\n  Descent and Randomized Gossip", "comments": "arXiv admin note: substantial text overlap with arXiv:2102.06035", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the continuized Nesterov acceleration, a close variant of\nNesterov acceleration whose variables are indexed by a continuous time\nparameter. The two variables continuously mix following a linear ordinary\ndifferential equation and take gradient steps at random times. This continuized\nvariant benefits from the best of the continuous and the discrete frameworks:\nas a continuous process, one can use differential calculus to analyze\nconvergence and obtain analytical expressions for the parameters; and a\ndiscretization of the continuized process can be computed exactly with\nconvergence rates similar to those of Nesterov original acceleration. We show\nthat the discretization has the same structure as Nesterov acceleration, but\nwith random parameters. We provide continuized Nesterov acceleration under\ndeterministic as well as stochastic gradients, with either additive or\nmultiplicative noise. Finally, using our continuized framework and expressing\nthe gossip averaging problem as the stochastic minimization of a certain energy\nfunction, we provide the first rigorous acceleration of asynchronous gossip\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 08:35:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Even", "Mathieu", ""], ["Berthier", "Rapha\u00ebl", ""], ["Bach", "Francis", ""], ["Flammarion", "Nicolas", ""], ["Gaillard", "Pierre", ""], ["Hendrikx", "Hadrien", ""], ["Massouli\u00e9", "Laurent", ""], ["Taylor", "Adrien", ""]]}, {"id": "2106.07682", "submitter": "Yamini Bansal", "authors": "Yamini Bansal, Preetum Nakkiran, Boaz Barak", "title": "Revisiting Model Stitching to Compare Neural Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit and extend model stitching (Lenc & Vedaldi 2015) as a methodology\nto study the internal representations of neural networks. Given two trained and\nfrozen models $A$ and $B$, we consider a \"stitched model'' formed by connecting\nthe bottom-layers of $A$ to the top-layers of $B$, with a simple trainable\nlayer between them. We argue that model stitching is a powerful and perhaps\nunder-appreciated tool, which reveals aspects of representations that measures\nsuch as centered kernel alignment (CKA) cannot. Through extensive experiments,\nwe use model stitching to obtain quantitative verifications for intuitive\nstatements such as \"good networks learn similar representations'', by\ndemonstrating that good networks of the same architecture, but trained in very\ndifferent ways (e.g.: supervised vs. self-supervised learning), can be stitched\nto each other without drop in performance. We also give evidence for the\nintuition that \"more is better'' by showing that representations learnt with\n(1) more data, (2) bigger width, or (3) more training time can be \"plugged in''\nto weaker models to improve performance. Finally, our experiments reveal a new\nstructural property of SGD which we call \"stitching connectivity'', akin to\nmode-connectivity: typical minima reached by SGD can all be stitched to each\nother with minimal change in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 18:05:10 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bansal", "Yamini", ""], ["Nakkiran", "Preetum", ""], ["Barak", "Boaz", ""]]}, {"id": "2106.07717", "submitter": "Si Kai Lee", "authors": "Y. Samuel Wang, Si Kai Lee, Panos Toulis, Mladen Kolar", "title": "Robust Inference for High-Dimensional Linear Models via Residual\n  Randomization", "comments": null, "journal-ref": "International Conference on Machine Learning 2021", "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a residual randomization procedure designed for robust Lasso-based\ninference in the high-dimensional setting. Compared to earlier work that\nfocuses on sub-Gaussian errors, the proposed procedure is designed to work\nrobustly in settings that also include heavy-tailed covariates and errors.\nMoreover, our procedure can be valid under clustered errors, which is important\nin practice, but has been largely overlooked by earlier work. Through extensive\nsimulations, we illustrate our method's wider range of applicability as\nsuggested by theory. In particular, we show that our method outperforms\nstate-of-art methods in challenging, yet more realistic, settings where the\ndistribution of covariates is heavy-tailed or the sample size is small, while\nit remains competitive in standard, ``well behaved\" settings previously studied\nin the literature.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 19:27:51 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wang", "Y. Samuel", ""], ["Lee", "Si Kai", ""], ["Toulis", "Panos", ""], ["Kolar", "Mladen", ""]]}, {"id": "2106.07724", "submitter": "Kartik Sreenivasan", "authors": "Shashank Rajput, Kartik Sreenivasan, Dimitris Papailiopoulos, Amin\n  Karbasi", "title": "An Exponential Improvement on the Memorization Capacity of Deep\n  Threshold Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that modern deep neural networks are powerful enough to\nmemorize datasets even when the labels have been randomized. Recently,\nVershynin (2020) settled a long standing question by Baum (1988), proving that\n\\emph{deep threshold} networks can memorize $n$ points in $d$ dimensions using\n$\\widetilde{\\mathcal{O}}(e^{1/\\delta^2}+\\sqrt{n})$ neurons and\n$\\widetilde{\\mathcal{O}}(e^{1/\\delta^2}(d+\\sqrt{n})+n)$ weights, where $\\delta$\nis the minimum distance between the points. In this work, we improve the\ndependence on $\\delta$ from exponential to almost linear, proving that\n$\\widetilde{\\mathcal{O}}(\\frac{1}{\\delta}+\\sqrt{n})$ neurons and\n$\\widetilde{\\mathcal{O}}(\\frac{d}{\\delta}+n)$ weights are sufficient. Our\nconstruction uses Gaussian random weights only in the first layer, while all\nthe subsequent layers use binary or integer weights. We also prove new lower\nbounds by connecting memorization in neural networks to the purely geometric\nproblem of separating $n$ points on a sphere using hyperplanes.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 19:42:32 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Rajput", "Shashank", ""], ["Sreenivasan", "Kartik", ""], ["Papailiopoulos", "Dimitris", ""], ["Karbasi", "Amin", ""]]}, {"id": "2106.07754", "submitter": "Daniele Regoli", "authors": "Riccardo Crupi, Alessandro Castelnovo, Daniele Regoli, Beatriz San\n  Miguel Gonzalez", "title": "Counterfactual Explanations as Interventions in Latent Space", "comments": "34 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable Artificial Intelligence (XAI) is a set of techniques that allows\nthe understanding of both technical and non-technical aspects of Artificial\nIntelligence (AI) systems. XAI is crucial to help satisfying the increasingly\nimportant demand of \\emph{trustworthy} Artificial Intelligence, characterized\nby fundamental characteristics such as respect of human autonomy, prevention of\nharm, transparency, accountability, etc. Within XAI techniques, counterfactual\nexplanations aim to provide to end users a set of features (and their\ncorresponding values) that need to be changed in order to achieve a desired\noutcome. Current approaches rarely take into account the feasibility of actions\nneeded to achieve the proposed explanations, and in particular they fall short\nof considering the causal impact of such actions. In this paper, we present\nCounterfactual Explanations as Interventions in Latent Space (CEILS), a\nmethodology to generate counterfactual explanations capturing by design the\nunderlying causal relations from the data, and at the same time to provide\nfeasible recommendations to reach the proposed profile. Moreover, our\nmethodology has the advantage that it can be set on top of existing\ncounterfactuals generator algorithms, thus minimising the complexity of\nimposing additional causal constrains. We demonstrate the effectiveness of our\napproach with a set of different experiments using synthetic and real datasets\n(including a proprietary dataset of the financial domain).\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 20:48:48 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Crupi", "Riccardo", ""], ["Castelnovo", "Alessandro", ""], ["Regoli", "Daniele", ""], ["Gonzalez", "Beatriz San Miguel", ""]]}, {"id": "2106.07761", "submitter": "Nicholas Kr\\\"amer", "authors": "Nicholas Kr\\\"amer and Philipp Hennig", "title": "Linear-Time Probabilistic Solutions of Boundary Value Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a fast algorithm for the probabilistic solution of boundary value\nproblems (BVPs), which are ordinary differential equations subject to boundary\nconditions. In contrast to previous work, we introduce a Gauss--Markov prior\nand tailor it specifically to BVPs, which allows computing a posterior\ndistribution over the solution in linear time, at a quality and cost comparable\nto that of well-established, non-probabilistic methods. Our model further\ndelivers uncertainty quantification, mesh refinement, and hyperparameter\nadaptation. We demonstrate how these practical considerations positively impact\nthe efficiency of the scheme. Altogether, this results in a practically usable\nprobabilistic BVP solver that is (in contrast to non-probabilistic algorithms)\nnatively compatible with other parts of the statistical modelling tool-chain.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 21:19:17 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kr\u00e4mer", "Nicholas", ""], ["Hennig", "Philipp", ""]]}, {"id": "2106.07767", "submitter": "Jiong Zhu", "authors": "Jiong Zhu, Junchen Jin, Michael T. Schaub, Danai Koutra", "title": "Improving Robustness of Graph Neural Networks with Heterophily-Inspired\n  Designs", "comments": "preprint with appendix; 30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have exposed that many graph neural networks (GNNs) are\nsensitive to adversarial attacks, and can suffer from performance loss if the\ngraph structure is intentionally perturbed. A different line of research has\nshown that many GNN architectures implicitly assume that the underlying graph\ndisplays homophily, i.e., connected nodes are more likely to have similar\nfeatures and class labels, and perform poorly if this assumption is not\nfulfilled. In this work, we formalize the relation between these two seemingly\ndifferent issues. We theoretically show that in the standard scenario in which\nnode features exhibit homophily, impactful structural attacks always lead to\nincreased levels of heterophily. Then, inspired by GNN architectures that\ntarget heterophily, we present two designs -- (i) separate aggregators for ego-\nand neighbor-embeddings, and (ii) a reduced scope of aggregation -- that can\nsignificantly improve the robustness of GNNs. Our extensive empirical\nevaluations show that GNNs featuring merely these two designs can achieve\nsignificantly improved robustness compared to the best-performing unvaccinated\nmodel with 24.99% gain in average performance under targeted attacks, while\nhaving smaller computational overhead than existing defense mechanisms.\nFurthermore, these designs can be readily combined with explicit defense\nmechanisms to yield state-of-the-art robustness with up to 18.33% increase in\nperformance under attacks compared to the best-performing vaccinated model.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 21:39:36 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhu", "Jiong", ""], ["Jin", "Junchen", ""], ["Schaub", "Michael T.", ""], ["Koutra", "Danai", ""]]}, {"id": "2106.07769", "submitter": "Daniel LeJeune", "authors": "Daniel LeJeune and Hamid Javadi and Richard G. Baraniuk", "title": "The Flip Side of the Reweighted Coin: Duality of Adaptive Dropout and\n  Regularization", "comments": "19 pages, 2 figures. Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Among the most successful methods for sparsifying deep (neural) networks are\nthose that adaptively mask the network weights throughout training. By\nexamining this masking, or dropout, in the linear case, we uncover a duality\nbetween such adaptive methods and regularization through the so-called\n\"$\\eta$-trick\" that casts both as iteratively reweighted optimizations. We show\nthat any dropout strategy that adapts to the weights in a monotonic way\ncorresponds to an effective subquadratic regularization penalty, and therefore\nleads to sparse solutions. We obtain the effective penalties for several\npopular sparsification strategies, which are remarkably similar to classical\npenalties commonly used in sparse optimization. Considering variational dropout\nas a case study, we demonstrate similar empirical behavior between the adaptive\ndropout method and classical methods on the task of deep network\nsparsification, validating our theory.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 21:47:17 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["LeJeune", "Daniel", ""], ["Javadi", "Hamid", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "2106.07779", "submitter": "Jessica Sorrell", "authors": "Ilias Diakonikolas, Russell Impagliazzo, Daniel Kane, Rex Lei, Jessica\n  Sorrell, Christos Tzamos", "title": "Boosting in the Presence of Massart Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of boosting the accuracy of a weak learner in the\n(distribution-independent) PAC model with Massart noise. In the Massart noise\nmodel, the label of each example $x$ is independently misclassified with\nprobability $\\eta(x) \\leq \\eta$, where $\\eta<1/2$. The Massart model lies\nbetween the random classification noise model and the agnostic model. Our main\npositive result is the first computationally efficient boosting algorithm in\nthe presence of Massart noise that achieves misclassification error arbitrarily\nclose to $\\eta$. Prior to our work, no non-trivial booster was known in this\nsetting. Moreover, we show that this error upper bound is best possible for\npolynomial-time black-box boosters, under standard cryptographic assumptions.\nOur upper and lower bounds characterize the complexity of boosting in the\ndistribution-independent PAC model with Massart noise. As a simple application\nof our positive result, we give the first efficient Massart learner for unions\nof high-dimensional rectangles.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 22:21:25 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Impagliazzo", "Russell", ""], ["Kane", "Daniel", ""], ["Lei", "Rex", ""], ["Sorrell", "Jessica", ""], ["Tzamos", "Christos", ""]]}, {"id": "2106.07804", "submitter": "Sungyong Seo", "authors": "Sungyong Seo, Sercan O. Arik, Jinsung Yoon, Xiang Zhang, Kihyuk Sohn,\n  Tomas Pfister", "title": "Controlling Neural Networks with Rule Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel training method to integrate rules into deep learning, in\na way their strengths are controllable at inference. Deep Neural Networks with\nControllable Rule Representations (DeepCTRL) incorporates a rule encoder into\nthe model coupled with a rule-based objective, enabling a shared representation\nfor decision making. DeepCTRL is agnostic to data type and model architecture.\nIt can be applied to any kind of rule defined for inputs and outputs. The key\naspect of DeepCTRL is that it does not require retraining to adapt the rule\nstrength -- at inference, the user can adjust it based on the desired operation\npoint on accuracy vs. rule verification ratio. In real-world domains where\nincorporating rules is critical -- such as Physics, Retail and Healthcare -- we\nshow the effectiveness of DeepCTRL in teaching rules for deep learning.\nDeepCTRL improves the trust and reliability of the trained models by\nsignificantly increasing their rule verification ratio, while also providing\naccuracy gains at downstream tasks. Additionally, DeepCTRL enables novel use\ncases such as hypothesis testing of the rules on data samples, and unsupervised\nadaptation based on shared rules between datasets.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 23:28:56 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Seo", "Sungyong", ""], ["Arik", "Sercan O.", ""], ["Yoon", "Jinsung", ""], ["Zhang", "Xiang", ""], ["Sohn", "Kihyuk", ""], ["Pfister", "Tomas", ""]]}, {"id": "2106.07814", "submitter": "Dhruv Malik", "authors": "Dhruv Malik, Aldo Pacchiano, Vishwak Srinivasan, Yuanzhi Li", "title": "Sample Efficient Reinforcement Learning In Continuous State Spaces: A\n  Perspective Beyond Linearity", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is empirically successful in complex nonlinear\nMarkov decision processes (MDPs) with continuous state spaces. By contrast, the\nmajority of theoretical RL literature requires the MDP to satisfy some form of\nlinear structure, in order to guarantee sample efficient RL. Such efforts\ntypically assume the transition dynamics or value function of the MDP are\ndescribed by linear functions of the state features. To resolve this\ndiscrepancy between theory and practice, we introduce the Effective Planning\nWindow (EPW) condition, a structural condition on MDPs that makes no linearity\nassumptions. We demonstrate that the EPW condition permits sample efficient RL,\nby providing an algorithm which provably solves MDPs satisfying this condition.\nOur algorithm requires minimal assumptions on the policy class, which can\ninclude multi-layer neural networks with nonlinear activation functions.\nNotably, the EPW condition is directly motivated by popular gaming benchmarks,\nand we show that many classic Atari games satisfy this condition. We\nadditionally show the necessity of conditions like EPW, by demonstrating that\nsimple MDPs with slight nonlinearities cannot be solved sample efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 00:06:59 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Malik", "Dhruv", ""], ["Pacchiano", "Aldo", ""], ["Srinivasan", "Vishwak", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2106.07816", "submitter": "Anna Neufeld", "authors": "Anna C. Neufeld, Lucy L. Gao, Daniela M. Witten", "title": "Tree-Values: selective inference for regression trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider conducting inference on the output of the Classification and\nRegression Tree (CART) [Breiman et al., 1984] algorithm. A naive approach to\ninference that does not account for the fact that the tree was estimated from\nthe data will not achieve standard guarantees, such as Type 1 error rate\ncontrol and nominal coverage. Thus, we propose a selective inference framework\nfor conducting inference on a fitted CART tree. In a nutshell, we condition on\nthe fact that the tree was estimated from the data. We propose a test for the\ndifference in the mean response between a pair of terminal nodes that controls\nthe selective Type 1 error rate, and a confidence interval for the mean\nresponse within a single terminal node that attains the nominal selective\ncoverage. Efficient algorithms for computing the necessary conditioning sets\nare provided. We apply these methods in simulation and to a dataset involving\nthe association between portion control interventions and caloric intake.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 00:25:11 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Neufeld", "Anna C.", ""], ["Gao", "Lucy L.", ""], ["Witten", "Daniela M.", ""]]}, {"id": "2106.07830", "submitter": "Hua Wang", "authors": "Zhiqi Bu, Hua Wang, Qi Long, Weijie J. Su", "title": "On the Convergence of Deep Learning with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep learning with differential privacy (DP), the neural network achieves\nthe privacy usually at the cost of slower convergence (and thus lower\nperformance) than its non-private counterpart. This work gives the first\nconvergence analysis of the DP deep learning, through the lens of training\ndynamics and the neural tangent kernel (NTK). Our convergence theory\nsuccessfully characterizes the effects of two key components in the DP\ntraining: the per-sample clipping (flat or layerwise) and the noise addition.\nOur analysis not only initiates a general principled framework to understand\nthe DP deep learning with any network architecture and loss function, but also\nmotivates a new clipping method -- the global clipping, that significantly\nimproves the convergence while preserving the same privacy guarantee as the\nexisting local clipping.\n  In terms of theoretical results, we establish the precise connection between\nthe per-sample clipping and NTK matrix. We show that in the gradient flow,\ni.e., with infinitesimal learning rate, the noise level of DP optimizers does\nnot affect the convergence. We prove that DP gradient descent (GD) with global\nclipping guarantees the monotone convergence to zero loss, which can be\nviolated by the existing DP-GD with local clipping. Notably, our analysis\nframework easily extends to other optimizers, e.g., DP-Adam. Empirically\nspeaking, DP optimizers equipped with global clipping perform strongly on a\nwide range of classification and regression tasks. In particular, our global\nclipping is surprisingly effective at learning calibrated classifiers, in\ncontrast to the existing DP classifiers which are oftentimes over-confident and\nunreliable. Implementation-wise, the new clipping can be realized by adding one\nline of code into the Opacus library.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 01:32:29 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 04:11:06 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bu", "Zhiqi", ""], ["Wang", "Hua", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "2106.07832", "submitter": "Priyank Jaini", "authors": "Priyank Jaini, Lars Holdijk and Max Welling", "title": "Learning Equivariant Energy Based Models with Equivariant Stein\n  Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus on the problem of efficient sampling and learning of probability\ndensities by incorporating symmetries in probabilistic models. We first\nintroduce Equivariant Stein Variational Gradient Descent algorithm -- an\nequivariant sampling method based on Stein's identity for sampling from\ndensities with symmetries. Equivariant SVGD explicitly incorporates symmetry\ninformation in a density through equivariant kernels which makes the resultant\nsampler efficient both in terms of sample complexity and the quality of\ngenerated samples. Subsequently, we define equivariant energy based models to\nmodel invariant densities that are learned using contrastive divergence. By\nutilizing our equivariant SVGD for training equivariant EBMs, we propose new\nways of improving and scaling up training of energy based models. We apply\nthese equivariant energy models for modelling joint densities in regression and\nclassification tasks for image datasets, many-body particle systems and\nmolecular structure generation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 01:35:17 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 14:44:17 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Jaini", "Priyank", ""], ["Holdijk", "Lars", ""], ["Welling", "Max", ""]]}, {"id": "2106.07836", "submitter": "Omid Sadeghi", "authors": "Omid Sadeghi, Prasanna Raut and Maryam Fazel", "title": "Improved Regret Bounds for Online Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an online optimization problem over $T$ rounds\nwhere at each step $t\\in[T]$, the algorithm chooses an action $x_t$ from the\nfixed convex and compact domain set $\\mathcal{K}$. A utility function\n$f_t(\\cdot)$ is then revealed and the algorithm receives the payoff $f_t(x_t)$.\nThis problem has been previously studied under the assumption that the\nutilities are adversarially chosen monotone DR-submodular functions and\n$\\mathcal{O}(\\sqrt{T})$ regret bounds have been derived. We first characterize\nthe class of strongly DR-submodular functions and then, we derive regret bounds\nfor the following new online settings: $(1)$ $\\{f_t\\}_{t=1}^T$ are monotone\nstrongly DR-submodular and chosen adversarially, $(2)$ $\\{f_t\\}_{t=1}^T$ are\nmonotone submodular (while the average $\\frac{1}{T}\\sum_{t=1}^T f_t$ is\nstrongly DR-submodular) and chosen by an adversary but they arrive in a\nuniformly random order, $(3)$ $\\{f_t\\}_{t=1}^T$ are drawn i.i.d. from some\nunknown distribution $f_t\\sim \\mathcal{D}$ where the expected function\n$f(\\cdot)=\\mathbb{E}_{f_t\\sim\\mathcal{D}}[f_t(\\cdot)]$ is monotone\nDR-submodular. For $(1)$, we obtain the first logarithmic regret bounds. In\nterms of the second framework, we show that it is possible to obtain similar\nlogarithmic bounds with high probability. Finally, for the i.i.d. model, we\nprovide algorithms with $\\tilde{\\mathcal{O}}(\\sqrt{T})$ stochastic regret\nbound, both in expectation and with high probability. Experimental results\ndemonstrate that our algorithms outperform the previous techniques in the\naforementioned three settings.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 02:05:35 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Sadeghi", "Omid", ""], ["Raut", "Prasanna", ""], ["Fazel", "Maryam", ""]]}, {"id": "2106.07841", "submitter": "Qiwen Cui", "authors": "Haque Ishfaq, Qiwen Cui, Viet Nguyen, Alex Ayoub, Zhuoran Yang,\n  Zhaoran Wang, Doina Precup, Lin F. Yang", "title": "Randomized Exploration for Reinforcement Learning with General Value\n  Function Approximation", "comments": "32 page, 5 figures, in Proceedings of the 38th International\n  Conference on Machine Learning, PMLR 139, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a model-free reinforcement learning algorithm inspired by the\npopular randomized least squares value iteration (RLSVI) algorithm as well as\nthe optimism principle. Unlike existing upper-confidence-bound (UCB) based\napproaches, which are often computationally intractable, our algorithm drives\nexploration by simply perturbing the training data with judiciously chosen\ni.i.d. scalar noises. To attain optimistic value function estimation without\nresorting to a UCB-style bonus, we introduce an optimistic reward sampling\nprocedure. When the value functions can be represented by a function class\n$\\mathcal{F}$, our algorithm achieves a worst-case regret bound of\n$\\widetilde{O}(\\mathrm{poly}(d_EH)\\sqrt{T})$ where $T$ is the time elapsed, $H$\nis the planning horizon and $d_E$ is the $\\textit{eluder dimension}$ of\n$\\mathcal{F}$. In the linear setting, our algorithm reduces to LSVI-PHE, a\nvariant of RLSVI, that enjoys an $\\widetilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$\nregret. We complement the theory with an empirical evaluation across known\ndifficult exploration tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 02:23:07 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ishfaq", "Haque", ""], ["Cui", "Qiwen", ""], ["Nguyen", "Viet", ""], ["Ayoub", "Alex", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Precup", "Doina", ""], ["Yang", "Lin F.", ""]]}, {"id": "2106.07847", "submitter": "Yujia Bao", "authors": "Yujia Bao, Shiyu Chang, Regina Barzilay", "title": "Learning Stable Classifiers by Transferring Unstable Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study transfer learning in the presence of spurious correlations. We\nexperimentally demonstrate that directly transferring the stable feature\nextractor learned on the source task may not eliminate these biases for the\ntarget task. However, we hypothesize that the unstable features in the source\ntask and those in the target task are directly related. By explicitly informing\nthe target classifier of the source task's unstable features, we can regularize\nthe biases in the target task. Specifically, we derive a representation that\nencodes the unstable features by contrasting different data environments in the\nsource task. On the target task, we cluster data from this representation, and\nachieve robustness by minimizing the worst-case risk across all clusters. We\nevaluate our method on both text and image classifications. Empirical results\ndemonstrate that our algorithm is able to maintain robustness on the target\ntask, outperforming the best baseline by 22.9% in absolute accuracy across 12\ntransfer settings. Our code is available at https://github.com/YujiaBao/Tofu.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 02:41:12 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bao", "Yujia", ""], ["Chang", "Shiyu", ""], ["Barzilay", "Regina", ""]]}, {"id": "2106.07875", "submitter": "Zhengze Zhou", "authors": "Zhengze Zhou, Giles Hooker, Fei Wang", "title": "S-LIME: Stabilized-LIME for Model Explanation", "comments": "In Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD '21), August 14--18, 2021, Virtual Event,\n  Singapore", "journal-ref": null, "doi": "10.1145/3447548.3467274", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An increasing number of machine learning models have been deployed in domains\nwith high stakes such as finance and healthcare. Despite their superior\nperformances, many models are black boxes in nature which are hard to explain.\nThere are growing efforts for researchers to develop methods to interpret these\nblack-box models. Post hoc explanations based on perturbations, such as LIME,\nare widely used approaches to interpret a machine learning model after it has\nbeen built. This class of methods has been shown to exhibit large instability,\nposing serious challenges to the effectiveness of the method itself and harming\nuser trust. In this paper, we propose S-LIME, which utilizes a hypothesis\ntesting framework based on central limit theorem for determining the number of\nperturbation points needed to guarantee stability of the resulting explanation.\nExperiments on both simulated and real world data sets are provided to\ndemonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 04:24:59 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhou", "Zhengze", ""], ["Hooker", "Giles", ""], ["Wang", "Fei", ""]]}, {"id": "2106.07898", "submitter": "Lang Liu", "authors": "Lang Liu, Krishna Pillutla, Sean Welleck, Sewoong Oh, Yejin Choi, Zaid\n  Harchaoui", "title": "Divergence Frontiers for Generative Models: Sample Complexity,\n  Quantization Level, and Frontier Integral", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spectacular success of deep generative models calls for quantitative\ntools to measure their statistical performance. Divergence frontiers have\nrecently been proposed as an evaluation framework for generative models, due to\ntheir ability to measure the quality-diversity trade-off inherent to deep\ngenerative modeling. However, the statistical behavior of divergence frontiers\nestimated from data remains unknown to this day. In this paper, we establish\nnon-asymptotic bounds on the sample complexity of the plug-in estimator of\ndivergence frontiers. Along the way, we introduce a novel integral summary of\ndivergence frontiers. We derive the corresponding non-asymptotic bounds and\ndiscuss the choice of the quantization level by balancing the two types of\napproximation errors arisen from its computation. We also augment the\ndivergence frontier framework by investigating the statistical performance of\nsmoothed distribution estimators such as the Good-Turing estimator. We\nillustrate the theoretical results with numerical examples from natural\nlanguage processing and computer vision.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 06:26:25 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Liu", "Lang", ""], ["Pillutla", "Krishna", ""], ["Welleck", "Sean", ""], ["Oh", "Sewoong", ""], ["Choi", "Yejin", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2106.07908", "submitter": "Truong-Vinh Hoang", "authors": "Truong-Vinh Hoang (1), Sebastian Krumscheid (1), Hermann G. Matthies\n  (2) and Ra\\'ul Tempone (1 and 3) ((1) Chair of Mathematics for Uncertainty\n  Quantification, RWTH Aachen University, (2) Technische Universit\\\"at\n  Braunschweig (3) Computer, Electrical and Mathematical Sciences and\n  Engineering, KAUST, and Alexander von Humboldt professor in Mathematics of\n  Uncertainty Quantification, RWTH Aachen University)", "title": "Machine learning-based conditional mean filter: a generalization of the\n  ensemble Kalman filter for nonlinear data assimilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Filtering is a data assimilation technique that performs the sequential\ninference of dynamical systems states from noisy observations. Herein, we\npropose a machine learning-based ensemble conditional mean filter (ML-EnCMF)\nfor tracking possibly high-dimensional non-Gaussian state models with nonlinear\ndynamics based on sparse observations. The proposed filtering method is\ndeveloped based on the conditional expectation and numerically implemented\nusing machine learning (ML) techniques combined with the ensemble method. The\ncontribution of this work is twofold. First, we demonstrate that the ensembles\nassimilated using the ensemble conditional mean filter (EnCMF) provide an\nunbiased estimator of the Bayesian posterior mean, and their variance matches\nthe expected conditional variance. Second, we implement the EnCMF using\nartificial neural networks, which have a significant advantage in representing\nnonlinear functions over high-dimensional domains such as the conditional mean.\nFinally, we demonstrate the effectiveness of the ML-EnCMF for tracking the\nstates of Lorenz-63 and Lorenz-96 systems under the chaotic regime. Numerical\nresults show that the ML-EnCMF outperforms the ensemble Kalman filter.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 06:40:32 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Hoang", "Truong-Vinh", "", "1 and 3"], ["Krumscheid", "Sebastian", "", "1 and 3"], ["Matthies", "Hermann G.", "", "1 and 3"], ["Tempone", "Ra\u00fal", "", "1 and 3"]]}, {"id": "2106.07911", "submitter": "Quentin Merigot", "authors": "Quentin Merigot (LMO, IUF), Filippo Santambrogio (ICJ, IUF), Cl\\'ement\n  Sarrazin (LMO)", "title": "Non-asymptotic convergence bounds for Wasserstein approximation using\n  point clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several issues in machine learning and inverse problems require to generate\ndiscrete data, as if sampled from a model probability distribution. A common\nway to do so relies on the construction of a uniform probability distribution\nover a set of $N$ points which minimizes the Wasserstein distance to the model\ndistribution. This minimization problem, where the unknowns are the positions\nof the atoms, is non-convex. Yet, in most cases, a suitably adjusted version of\nLloyd's algorithm -- in which Voronoi cells are replaced by Power cells --\nleads to configurations with small Wasserstein error. This is surprising\nbecause, again, of the non-convex nature of the problem, as well as the\nexistence of spurious critical points. We provide explicit upper bounds for the\nconvergence speed of this Lloyd-type algorithm, starting from a cloud of points\nsufficiently far from each other. This already works after one step of the\niteration procedure, and similar bounds can be deduced, for the corresponding\ngradient descent. These bounds naturally lead to a modified Poliak-Lojasiewicz\ninequality for the Wasserstein distance cost, with an error term depending on\nthe distances between Dirac masses in the discrete distribution.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 06:53:08 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Merigot", "Quentin", "", "LMO, IUF"], ["Santambrogio", "Filippo", "", "ICJ, IUF"], ["Sarrazin", "Cl\u00e9ment", "", "LMO"]]}, {"id": "2106.07992", "submitter": "Cheng Feng", "authors": "Cheng Feng, Pengwei Tian", "title": "Time Series Anomaly Detection for Cyber-physical Systems via Neural\n  System Identification and Bayesian Filtering", "comments": "Accepted to appear in KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467137", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in AIoT technologies have led to an increasing popularity of\nutilizing machine learning algorithms to detect operational failures for\ncyber-physical systems (CPS). In its basic form, an anomaly detection module\nmonitors the sensor measurements and actuator states from the physical plant,\nand detects anomalies in these measurements to identify abnormal operation\nstatus. Nevertheless, building effective anomaly detection models for CPS is\nrather challenging as the model has to accurately detect anomalies in presence\nof highly complicated system dynamics and unknown amount of sensor noise. In\nthis work, we propose a novel time series anomaly detection method called\nNeural System Identification and Bayesian Filtering (NSIBF) in which a\nspecially crafted neural network architecture is posed for system\nidentification, i.e., capturing the dynamics of CPS in a dynamical state-space\nmodel; then a Bayesian filtering algorithm is naturally applied on top of the\n\"identified\" state-space model for robust anomaly detection by tracking the\nuncertainty of the hidden state of the system recursively over time. We provide\nqualitative as well as quantitative experiments with the proposed method on a\nsynthetic and three real-world CPS datasets, showing that NSIBF compares\nfavorably to the state-of-the-art methods with considerable improvements on\nanomaly detection in CPS.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 09:11:35 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Feng", "Cheng", ""], ["Tian", "Pengwei", ""]]}, {"id": "2106.08027", "submitter": "Peter Pfeiffer", "authors": "Peter Pfeiffer, Johannes Lahann and Peter Fettke", "title": "Multivariate Business Process Representation Learning utilizing Gramian\n  Angular Fields and Convolutional Neural Networks", "comments": "Accepted at the Business Process Management Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning meaningful representations of data is an important aspect of machine\nlearning and has recently been successfully applied to many domains like\nlanguage understanding or computer vision. Instead of training a model for one\nspecific task, representation learning is about training a model to capture all\nuseful information in the underlying data and make it accessible for a\npredictor. For predictive process analytics, it is essential to have all\nexplanatory characteristics of a process instance available when making\npredictions about the future, as well as for clustering and anomaly detection.\nDue to the large variety of perspectives and types within business process\ndata, generating a good representation is a challenging task. In this paper, we\npropose a novel approach for representation learning of business process\ninstances which can process and combine most perspectives in an event log. In\nconjunction with a self-supervised pre-training method, we show the\ncapabilities of the approach through a visualization of the representation\nspace and case retrieval. Furthermore, the pre-trained model is fine-tuned to\nmultiple process prediction tasks and demonstrates its effectiveness in\ncomparison with existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 10:21:14 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Pfeiffer", "Peter", ""], ["Lahann", "Johannes", ""], ["Fettke", "Peter", ""]]}, {"id": "2106.08056", "submitter": "Zhe Dong", "authors": "Zhe Dong, Andriy Mnih, George Tucker", "title": "Coupled Gradient Estimators for Discrete Latent Variables", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training models with discrete latent variables is challenging due to the high\nvariance of unbiased gradient estimators. While low-variance reparameterization\ngradients of a continuous relaxation can provide an effective solution, a\ncontinuous relaxation is not always available or tractable. Dong et al. (2020)\nand Yin et al. (2020) introduced a performant estimator that does not rely on\ncontinuous relaxations; however, it is limited to binary random variables. We\nintroduce a novel derivation of their estimator based on importance sampling\nand statistical couplings, which we extend to the categorical setting.\nMotivated by the construction of a stick-breaking coupling, we introduce\ngradient estimators based on reparameterizing categorical variables as\nsequences of binary variables and Rao-Blackwellization. In systematic\nexperiments, we show that our proposed categorical gradient estimators provide\nstate-of-the-art performance, whereas even with additional\nRao-Blackwellization, previous estimators (Yin et al., 2019) underperform a\nsimpler REINFORCE with a leave-one-out-baseline estimator (Kool et al., 2019).\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 11:28:44 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Dong", "Zhe", ""], ["Mnih", "Andriy", ""], ["Tucker", "George", ""]]}, {"id": "2106.08068", "submitter": "Stefano Sarao Mannelli", "authors": "Luca Saglietti, Stefano Sarao Mannelli, and Andrew Saxe", "title": "An Analytical Theory of Curriculum Learning in Teacher-Student Networks", "comments": "10 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In humans and animals, curriculum learning -- presenting data in a curated\norder - is critical to rapid learning and effective pedagogy. Yet in machine\nlearning, curricula are not widely used and empirically often yield only\nmoderate benefits. This stark difference in the importance of curriculum raises\na fundamental theoretical question: when and why does curriculum learning help?\n  In this work, we analyse a prototypical neural network model of curriculum\nlearning in the high-dimensional limit, employing statistical physics methods.\nCurricula could in principle change both the learning speed and asymptotic\nperformance of a model. To study the former, we provide an exact description of\nthe online learning setting, confirming the long-standing experimental\nobservation that curricula can modestly speed up learning. To study the latter,\nwe derive performance in a batch learning setting, in which a network trains to\nconvergence in successive phases of learning on dataset slices of varying\ndifficulty. With standard training losses, curriculum does not provide\ngeneralisation benefit, in line with empirical observations. However, we show\nthat by connecting different learning phases through simple Gaussian priors,\ncurriculum can yield a large improvement in test performance. Taken together,\nour reduced analytical descriptions help reconcile apparently conflicting\nempirical results and trace regimes where curriculum learning yields the\nlargest gains. More broadly, our results suggest that fully exploiting a\ncurriculum may require explicit changes to the loss function at curriculum\nboundaries.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 11:48:52 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Saglietti", "Luca", ""], ["Mannelli", "Stefano Sarao", ""], ["Saxe", "Andrew", ""]]}, {"id": "2106.08086", "submitter": "Gunnar K\\\"onig", "authors": "Gunnar K\\\"onig, Timo Freiesleben, Bernd Bischl, Giuseppe Casalicchio,\n  Moritz Grosse-Wentrup", "title": "Decomposition of Global Feature Importance into Direct and Associative\n  Components (DEDACT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Global model-agnostic feature importance measures either quantify whether\nfeatures are directly used for a model's predictions (direct importance) or\nwhether they contain prediction-relevant information (associative importance).\nDirect importance provides causal insight into the model's mechanism, yet it\nfails to expose the leakage of information from associated but not directly\nused variables. In contrast, associative importance exposes information leakage\nbut does not provide causal insight into the model's mechanism. We introduce\nDEDACT - a framework to decompose well-established direct and associative\nimportance measures into their respective associative and direct components.\nDEDACT provides insight into both the sources of prediction-relevant\ninformation in the data and the direct and indirect feature pathways by which\nthe information enters the model. We demonstrate the method's usefulness on\nsimulated examples.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 12:25:23 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["K\u00f6nig", "Gunnar", ""], ["Freiesleben", "Timo", ""], ["Bischl", "Bernd", ""], ["Casalicchio", "Giuseppe", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "2106.08105", "submitter": "Andrea Bommert", "authors": "Andrea Bommert, J\\\"org Rahnenf\\\"uhrer, Michel Lang", "title": "Employing an Adjusted Stability Measure for Multi-Criteria Model Fitting\n  on Data Sets with Similar Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting models with high predictive accuracy that include all relevant but no\nirrelevant or redundant features is a challenging task on data sets with\nsimilar (e.g. highly correlated) features. We propose the approach of tuning\nthe hyperparameters of a predictive model in a multi-criteria fashion with\nrespect to predictive accuracy and feature selection stability. We evaluate\nthis approach based on both simulated and real data sets and we compare it to\nthe standard approach of single-criteria tuning of the hyperparameters as well\nas to the state-of-the-art technique \"stability selection\". We conclude that\nour approach achieves the same or better predictive performance compared to the\ntwo established approaches. Considering the stability during tuning does not\ndecrease the predictive accuracy of the resulting models. Our approach succeeds\nat selecting the relevant features while avoiding irrelevant or redundant\nfeatures. The single-criteria approach fails at avoiding irrelevant or\nredundant features and the stability selection approach fails at selecting\nenough relevant features for achieving acceptable predictive accuracy. For our\napproach, for data sets with many similar features, the feature selection\nstability must be evaluated with an adjusted stability measure, that is, a\nmeasure that considers similarities between features. For data sets with only\nfew similar features, an unadjusted stability measure suffices and is faster to\ncompute.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 12:48:07 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bommert", "Andrea", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""], ["Lang", "Michel", ""]]}, {"id": "2106.08161", "submitter": "Adam Foster", "authors": "Adam Foster, \\'Arpi Vez\\'er, Craig A Glastonbury, P\\'aid\\'i Creed, Sam\n  Abujudeh, Aaron Sim", "title": "Contrastive Mixture of Posteriors for Counterfactual Inference, Data\n  Integration and Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful representations of data that can address challenges such\nas batch effect correction, data integration and counterfactual inference is a\ncentral problem in many domains including computational biology. Adopting a\nConditional VAE framework, we identify the mathematical principle that unites\nthese challenges: learning a representation that is marginally independent of a\ncondition variable. We therefore propose the Contrastive Mixture of Posteriors\n(CoMP) method that uses a novel misalignment penalty to enforce this\nindependence. This penalty is defined in terms of mixtures of the variational\nposteriors themselves, unlike prior work which uses external discrepancy\nmeasures such as MMD to ensure independence in latent space. We show that CoMP\nhas attractive theoretical properties compared to previous approaches,\nespecially when there is complex global structure in latent space. We further\ndemonstrate state of the art performance on a number of real-world problems,\nincluding the challenging tasks of aligning human tumour samples with cancer\ncell-lines and performing counterfactual inference on single-cell RNA\nsequencing data. Incidentally, we find parallels with the fair representation\nlearning literature, and demonstrate CoMP has competitive performance in\nlearning fair yet expressive latent representations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 14:04:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Foster", "Adam", ""], ["Vez\u00e9r", "\u00c1rpi", ""], ["Glastonbury", "Craig A", ""], ["Creed", "P\u00e1id\u00ed", ""], ["Abujudeh", "Sam", ""], ["Sim", "Aaron", ""]]}, {"id": "2106.08171", "submitter": "Ganqu Cui", "authors": "Ganqu Cui, Yufeng Du, Cheng Yang, Jie Zhou, Liang Xu, Lifeng Wang,\n  Zhiyuan Liu", "title": "Evaluating Modules in Graph Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent emergence of contrastive learning approaches facilitates the\nresearch on graph representation learning (GRL), introducing graph contrastive\nlearning (GCL) into the literature. These methods contrast semantically similar\nand dissimilar sample pairs to encode the semantics into node or graph\nembeddings. However, most existing works only performed model-level evaluation,\nand did not explore the combination space of modules for more comprehensive and\nsystematic studies. For effective module-level evaluation, we propose a\nframework that decomposes GCL models into four modules: (1) a sampler to\ngenerate anchor, positive and negative data samples (nodes or graphs); (2) an\nencoder and a readout function to get sample embeddings; (3) a discriminator to\nscore each sample pair (anchor-positive and anchor-negative); and (4) an\nestimator to define the loss function. Based on this framework, we conduct\ncontrolled experiments over a wide range of architectural designs and\nhyperparameter settings on node and graph classification tasks. Specifically,\nwe manage to quantify the impact of a single module, investigate the\ninteraction between modules, and compare the overall performance with current\nmodel architectures. Our key findings include a set of module-level guidelines\nfor GCL, e.g., simple samplers from LINE and DeepWalk are strong and robust; an\nMLP encoder associated with Sum readout could achieve competitive performance\non graph classification. Finally, we release our implementations and results as\nOpenGCL, a modularized toolkit that allows convenient reproduction, standard\nmodel and module evaluation, and easy extension.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 14:14:23 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Cui", "Ganqu", ""], ["Du", "Yufeng", ""], ["Yang", "Cheng", ""], ["Zhou", "Jie", ""], ["Xu", "Liang", ""], ["Wang", "Lifeng", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "2106.08185", "submitter": "Fergus Simpson", "authors": "Fergus Simpson, Ian Davies, Vidhi Lalchand, Alessandro Vullo, Nicolas\n  Durrande, Carl Rasmussen", "title": "Kernel Identification Through Transformers", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel selection plays a central role in determining the performance of\nGaussian Process (GP) models, as the chosen kernel determines both the\ninductive biases and prior support of functions under the GP prior. This work\naddresses the challenge of constructing custom kernel functions for\nhigh-dimensional GP regression models. Drawing inspiration from recent progress\nin deep learning, we introduce a novel approach named KITT: Kernel\nIdentification Through Transformers. KITT exploits a transformer-based\narchitecture to generate kernel recommendations in under 0.1 seconds, which is\nseveral orders of magnitude faster than conventional kernel search algorithms.\nWe train our model using synthetic data generated from priors over a vocabulary\nof known kernels. By exploiting the nature of the self-attention mechanism,\nKITT is able to process datasets with inputs of arbitrary dimension. We\ndemonstrate that kernels chosen by KITT yield strong performance over a diverse\ncollection of regression benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 14:32:38 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Simpson", "Fergus", ""], ["Davies", "Ian", ""], ["Lalchand", "Vidhi", ""], ["Vullo", "Alessandro", ""], ["Durrande", "Nicolas", ""], ["Rasmussen", "Carl", ""]]}, {"id": "2106.08217", "submitter": "Cansu Alakus", "authors": "Cansu Alakus, Denis Larocque, Aurelie Labbe", "title": "RFpredInterval: An R Package for Prediction Intervals with Random\n  Forests and Boosted Forests", "comments": "32 pages, 14 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like many predictive models, random forests provide a point prediction for a\nnew observation. Besides the point prediction, it is important to quantify the\nuncertainty in the prediction. Prediction intervals provide information about\nthe reliability of the point predictions. We have developed a comprehensive R\npackage, RFpredInterval, that integrates 16 methods to build prediction\nintervals with random forests and boosted forests. The methods implemented in\nthe package are a new method to build prediction intervals with boosted forests\n(PIBF) and 15 different variants to produce prediction intervals with random\nforests proposed by Roy and Larocque (2020). We perform an extensive simulation\nstudy and apply real data analyses to compare the performance of the proposed\nmethod to ten existing methods to build prediction intervals with random\nforests. The results show that the proposed method is very competitive and,\nglobally, it outperforms the competing methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 15:27:50 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Alakus", "Cansu", ""], ["Larocque", "Denis", ""], ["Labbe", "Aurelie", ""]]}, {"id": "2106.08247", "submitter": "Sikai Zhang", "authors": "Sikai Zhang, Tingna Wang, Keith Worden, Elizabeth J. Cross", "title": "Canonical-Correlation-Based Fast Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper proposes a canonical-correlation-based filter method for feature\nselection. The sum of squared canonical correlation coefficients is adopted as\nthe feature ranking criterion. The proposed method boosts the computational\nspeed of the ranking criterion in greedy search. The supporting theorems\ndeveloped for the feature selection method are fundamental to the understanding\nof the canonical correlation analysis. In empirical studies, a synthetic\ndataset is used to demonstrate the speed advantage of the proposed method, and\neight real datasets are applied to show the effectiveness of the proposed\nfeature ranking criterion in both classification and regression. The results\nshow that the proposed method is considerably faster than the definition-based\nmethod, and the proposed ranking criterion is competitive compared with the\nseven mutual-information-based criteria.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 15:55:17 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhang", "Sikai", ""], ["Wang", "Tingna", ""], ["Worden", "Keith", ""], ["Cross", "Elizabeth J.", ""]]}, {"id": "2106.08285", "submitter": "Tim Prangemeier", "authors": "Christoph Reich, Tim Prangemeier, Christian Wildner and Heinz Koeppl", "title": "Multi-StyleGAN: Towards Image-Based Simulation of Time-Lapse Live-Cell\n  Microscopy", "comments": "revised -- accepted to MICCAI 2021. (Tim Prangemeier and Christoph\n  Reich --- both authors contributed equally)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-lapse fluorescent microscopy (TLFM) combined with predictive\nmathematical modelling is a powerful tool to study the inherently dynamic\nprocesses of life on the single-cell level. Such experiments are costly,\ncomplex and labour intensive. A complimentary approach and a step towards in\nsilico experimentation, is to synthesise the imagery itself. Here, we propose\nMulti-StyleGAN as a descriptive approach to simulate time-lapse fluorescence\nmicroscopy imagery of living cells, based on a past experiment. This novel\ngenerative adversarial network synthesises a multi-domain sequence of\nconsecutive timesteps. We showcase Multi-StyleGAN on imagery of multiple live\nyeast cells in microstructured environments and train on a dataset recorded in\nour laboratory. The simulation captures underlying biophysical factors and time\ndependencies, such as cell morphology, growth, physical interactions, as well\nas the intensity of a fluorescent reporter protein. An immediate application is\nto generate additional training and validation data for feature extraction\nalgorithms or to aid and expedite development of advanced experimental\ntechniques such as online monitoring or control of cells.\n  Code and dataset is available at\nhttps://git.rwth-aachen.de/bcs/projects/tp/multi-stylegan.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 16:51:16 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 14:37:52 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Reich", "Christoph", ""], ["Prangemeier", "Tim", ""], ["Wildner", "Christian", ""], ["Koeppl", "Heinz", ""]]}, {"id": "2106.08320", "submitter": "Danica J. Sutherland", "authors": "Yazhe Li and Roman Pogodin and Danica J. Sutherland and Arthur Gretton", "title": "Self-Supervised Learning with Kernel Dependence Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach self-supervised learning of image representations from a\nstatistical dependence perspective, proposing Self-Supervised Learning with the\nHilbert-Schmidt Independence Criterion (SSL-HSIC). SSL-HSIC maximizes\ndependence between representations of transformed versions of an image and the\nimage identity, while minimizing the kernelized variance of those features.\nThis self-supervised learning framework yields a new understanding of InfoNCE,\na variational lower bound on the mutual information (MI) between different\ntransformations. While the MI itself is known to have pathologies which can\nresult in meaningless representations being learned, its bound is much better\nbehaved: we show that it implicitly approximates SSL-HSIC (with a slightly\ndifferent regularizer). Our approach also gives us insight into BYOL, since\nSSL-HSIC similarly learns local neighborhoods of samples. SSL-HSIC allows us to\ndirectly optimize statistical dependence in time linear in the batch size,\nwithout restrictive data assumptions or indirect mutual information estimators.\nTrained with or without a target network, SSL-HSIC matches the current\nstate-of-the-art for standard linear evaluation on ImageNet, semi-supervised\nlearning and transfer to other classification and vision tasks such as semantic\nsegmentation, depth estimation and object recognition.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 17:51:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Li", "Yazhe", ""], ["Pogodin", "Roman", ""], ["Sutherland", "Danica J.", ""], ["Gretton", "Arthur", ""]]}, {"id": "2106.08365", "submitter": "Xu Ji", "authors": "Xu Ji, Razvan Pascanu, Devon Hjelm, Andrea Vedaldi, Balaji\n  Lakshminarayanan, Yoshua Bengio", "title": "Predicting Unreliable Predictions by Shattering a Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Piecewise linear neural networks can be split into subfunctions, each with\nits own activation pattern, domain, and empirical error. Empirical error for\nthe full network can be written as an expectation over empirical error of\nsubfunctions. Constructing a generalization bound on subfunction empirical\nerror indicates that the more densely a subfunction is surrounded by training\nsamples in representation space, the more reliable its predictions are.\nFurther, it suggests that models with fewer activation regions generalize\nbetter, and models that abstract knowledge to a greater degree generalize\nbetter, all else equal. We propose not only a theoretical framework to reason\nabout subfunction error bounds but also a pragmatic way of approximately\nevaluating it, which we apply to predicting which samples the network will not\nsuccessfully generalize to. We test our method on detection of\nmisclassification and out-of-distribution samples, finding that it performs\ncompetitively in both cases. In short, some network activation patterns are\nassociated with higher reliability than others, and these can be identified\nusing subfunction error bounds.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 18:34:41 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ji", "Xu", ""], ["Pascanu", "Razvan", ""], ["Hjelm", "Devon", ""], ["Vedaldi", "Andrea", ""], ["Lakshminarayanan", "Balaji", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2106.08377", "submitter": "Liyu Chen", "authors": "Liyu Chen, Mehdi Jafarnia-Jahromi, Rahul Jain, Haipeng Luo", "title": "Implicit Finite-Horizon Approximation and Efficient Optimal Algorithms\n  for Stochastic Shortest Path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generic template for developing regret minimization algorithms\nin the Stochastic Shortest Path (SSP) model, which achieves minimax optimal\nregret as long as certain properties are ensured. The key of our analysis is a\nnew technique called implicit finite-horizon approximation, which approximates\nthe SSP model by a finite-horizon counterpart only in the analysis without\nexplicit implementation. Using this template, we develop two new algorithms:\nthe first one is model-free (the first in the literature to our knowledge) and\nminimax optimal under strictly positive costs; the second one is model-based\nand minimax optimal even with zero-cost state-action pairs, matching the best\nexisting result from [Tarbouriech et al., 2021b]. Importantly, both algorithms\nadmit highly sparse updates, making them computationally more efficient than\nall existing algorithms. Moreover, both can be made completely parameter-free.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 19:15:17 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Chen", "Liyu", ""], ["Jafarnia-Jahromi", "Mehdi", ""], ["Jain", "Rahul", ""], ["Luo", "Haipeng", ""]]}, {"id": "2106.08414", "submitter": "Amrit Singh Bedi", "authors": "Amrit Singh Bedi, Anjaly Parayil, Junyu Zhang, Mengdi Wang, Alec\n  Koppel", "title": "On the Sample Complexity and Metastability of Heavy-tailed Policy Search\n  in Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a framework for interactive decision-making with\nincentives sequentially revealed across time without a system dynamics model.\nDue to its scaling to continuous spaces, we focus on policy search where one\niteratively improves a parameterized policy with stochastic policy gradient\n(PG) updates. In tabular Markov Decision Problems (MDPs), under persistent\nexploration and suitable parameterization, global optimality may be obtained.\nBy contrast, in continuous space, the non-convexity poses a pathological\nchallenge as evidenced by existing convergence results being mostly limited to\nstationarity or arbitrary local extrema. To close this gap, we step towards\npersistent exploration in continuous space through policy parameterizations\ndefined by distributions of heavier tails defined by tail-index parameter\nalpha, which increases the likelihood of jumping in state space. Doing so\ninvalidates smoothness conditions of the score function common to PG. Thus, we\nestablish how the convergence rate to stationarity depends on the policy's tail\nindex alpha, a Holder continuity parameter, integrability conditions, and an\nexploration tolerance parameter introduced here for the first time. Further, we\ncharacterize the dependence of the set of local maxima on the tail index\nthrough an exit and transition time analysis of a suitably defined Markov\nchain, identifying that policies associated with Levy Processes of a heavier\ntail converge to wider peaks. This phenomenon yields improved stability to\nperturbations in supervised learning, which we corroborate also manifests in\nimproved performance of policy search, especially when myopic and farsighted\nincentives are misaligned.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 20:12:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Bedi", "Amrit Singh", ""], ["Parayil", "Anjaly", ""], ["Zhang", "Junyu", ""], ["Wang", "Mengdi", ""], ["Koppel", "Alec", ""]]}, {"id": "2106.08441", "submitter": "Pouya M Ghari", "authors": "Pouya M Ghari, Yanning Shen", "title": "Online Learning with Uncertain Feedback Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Online learning with expert advice is widely used in various machine learning\ntasks. It considers the problem where a learner chooses one from a set of\nexperts to take advice and make a decision. In many learning problems, experts\nmay be related, henceforth the learner can observe the losses associated with a\nsubset of experts that are related to the chosen one. In this context, the\nrelationship among experts can be captured by a feedback graph, which can be\nused to assist the learner's decision making. However, in practice, the nominal\nfeedback graph often entails uncertainties, which renders it impossible to\nreveal the actual relationship among experts. To cope with this challenge, the\npresent work studies various cases of potential uncertainties, and develops\nnovel online learning algorithms to deal with uncertainties while making use of\nthe uncertain feedback graph. The proposed algorithms are proved to enjoy\nsublinear regret under mild conditions. Experiments on real datasets are\npresented to demonstrate the effectiveness of the novel algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:21:30 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ghari", "Pouya M", ""], ["Shen", "Yanning", ""]]}, {"id": "2106.08443", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Reproducing Kernel Hilbert Space, Mercer's Theorem, Eigenfunctions,\n  Nystr\\\"om Method, and Use of Kernels in Machine Learning: Tutorial and Survey", "comments": "To appear as a part of an upcoming textbook on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a tutorial and survey paper on kernels, kernel methods, and related\nfields. We start with reviewing the history of kernels in functional analysis\nand machine learning. Then, Mercer kernel, Hilbert and Banach spaces,\nReproducing Kernel Hilbert Space (RKHS), Mercer's theorem and its proof,\nfrequently used kernels, kernel construction from distance metric, important\nclasses of kernels (including bounded, integrally positive definite, universal,\nstationary, and characteristic kernels), kernel centering and normalization,\nand eigenfunctions are explained in detail. Then, we introduce types of use of\nkernels in machine learning including kernel methods (such as kernel support\nvector machines), kernel learning by semi-definite programming, Hilbert-Schmidt\nindependence criterion, maximum mean discrepancy, kernel mean embedding, and\nkernel dimensionality reduction. We also cover rank and factorization of kernel\nmatrix as well as the approximation of eigenfunctions and kernels using the\nNystr{\\\"o}m method. This paper can be useful for various fields of science\nincluding machine learning, dimensionality reduction, functional analysis in\nmathematics, and mathematical physics in quantum mechanics.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:29:12 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2106.08444", "submitter": "Xiaoli Li", "authors": "Xiaoli Li", "title": "CODA: Constructivism Learning for Instance-Dependent Dropout\n  Architecture Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dropout is attracting intensive research interest in deep learning as an\nefficient approach to prevent overfitting. Recently incorporating structural\ninformation when deciding which units to drop out produced promising results\ncomparing to methods that ignore the structural information. However, a major\nissue of the existing work is that it failed to differentiate among instances\nwhen constructing the dropout architecture. This can be a significant\ndeficiency for many applications. To solve this issue, we propose\nConstructivism learning for instance-dependent Dropout Architecture (CODA),\nwhich is inspired from a philosophical theory, constructivism learning.\nSpecially, based on the theory we have designed a better drop out technique,\nUniform Process Mixture Models, using a Bayesian nonparametric method Uniform\nprocess. We have evaluated our proposed method on 5 real-world datasets and\ncompared the performance with other state-of-the-art dropout techniques. The\nexperimental results demonstrated the effectiveness of CODA.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:32:28 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Li", "Xiaoli", ""]]}, {"id": "2106.08453", "submitter": "Akhilan Boopathy", "authors": "Akhilan Boopathy, Ila Fiete", "title": "Gradient-trained Weights in Wide Neural Networks Align Layerwise to\n  Error-scaled Input Correlations", "comments": "22 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have examined how deep neural networks, which can solve a\nvariety of difficult problems, incorporate the statistics of training data to\nachieve their success. However, existing results have been established only in\nlimited settings. In this work, we derive the layerwise weight dynamics of\ninfinite-width neural networks with nonlinear activations trained by gradient\ndescent. We show theoretically that weight updates are aligned with input\ncorrelations from intermediate layers weighted by error, and demonstrate\nempirically that the result also holds in finite-width wide networks. The\nalignment result allows us to formulate backpropagation-free learning rules,\nnamed Align-zero and Align-ada, that theoretically achieve the same alignment\nas backpropagation. Finally, we test these learning rules on benchmark problems\nin feedforward and recurrent neural networks and demonstrate, in wide networks,\ncomparable performance to backpropagation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:56:38 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Boopathy", "Akhilan", ""], ["Fiete", "Ila", ""]]}, {"id": "2106.08477", "submitter": "Rongpeng Li", "authors": "Rongpeng Li", "title": "Fundamental Limits of Reinforcement Learning in Environment with\n  Endogeneous and Exogeneous Uncertainty", "comments": "Manuscript has been submitted to an IEEE journal. Copyright may be\n  transferred without further notice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online reinforcement learning (RL) has been widely applied in information\nprocessing scenarios, which usually exhibit much uncertainty due to the\nintrinsic randomness of channels and service demands. In this paper, we\nconsider an un-discounted RL in general Markov decision processes (MDPs) with\nboth endogeneous and exogeneous uncertainty, where both the rewards and state\ntransition probability are unknown to the RL agent and evolve with the time as\nlong as their respective variations do not exceed certain dynamic budget (i.e.,\nupper bound). We first develop a variation-aware Bernstein-based upper\nconfidence reinforcement learning (VB-UCRL), which we allow to restart\naccording to a schedule dependent on the variations. We successfully overcome\nthe challenges due to the exogeneous uncertainty and establish a regret bound\nof saving at most $\\sqrt{S}$ or $S^{\\frac{1}{6}}T^{\\frac{1}{12}}$ compared with\nthe latest results in the literature, where $S$ denotes the state size of the\nMDP and $T$ indicates the iteration index of learning steps.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 22:57:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Li", "Rongpeng", ""]]}, {"id": "2106.08537", "submitter": "Kevin Tian", "authors": "Ilias Diakonikolas, Daniel M. Kane, Daniel Kongsgaard, Jerry Li, Kevin\n  Tian", "title": "Clustering Mixture Models in Almost-Linear Time via List-Decodable Mean\n  Estimation", "comments": "64 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of list-decodable mean estimation, where an adversary\ncan corrupt a majority of the dataset. Specifically, we are given a set $T$ of\n$n$ points in $\\mathbb{R}^d$ and a parameter $0< \\alpha <\\frac 1 2$ such that\nan $\\alpha$-fraction of the points in $T$ are i.i.d. samples from a\nwell-behaved distribution $\\mathcal{D}$ and the remaining $(1-\\alpha)$-fraction\nof the points are arbitrary. The goal is to output a small list of vectors at\nleast one of which is close to the mean of $\\mathcal{D}$. As our main\ncontribution, we develop new algorithms for list-decodable mean estimation,\nachieving nearly-optimal statistical guarantees, with running time $n^{1 +\no(1)} d$. All prior algorithms for this problem had additional polynomial\nfactors in $\\frac 1 \\alpha$. As a corollary, we obtain the first almost-linear\ntime algorithms for clustering mixtures of $k$ separated well-behaved\ndistributions, nearly-matching the statistical guarantees of spectral methods.\nPrior clustering algorithms inherently relied on an application of $k$-PCA,\nthereby incurring runtimes of $\\Omega(n d k)$. This marks the first runtime\nimprovement for this basic statistical problem in nearly two decades.\n  The starting point of our approach is a novel and simpler near-linear time\nrobust mean estimation algorithm in the $\\alpha \\to 1$ regime, based on a\none-shot matrix multiplicative weights-inspired potential decrease. We\ncrucially leverage this new algorithmic framework in the context of the\niterative multi-filtering technique of Diakonikolas et. al. '18, '20, providing\na method to simultaneously cluster and downsample points using one-dimensional\nprojections -- thus, bypassing the $k$-PCA subroutines required by prior\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 03:34:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Kongsgaard", "Daniel", ""], ["Li", "Jerry", ""], ["Tian", "Kevin", ""]]}, {"id": "2106.08544", "submitter": "Zhili Feng", "authors": "Zhili Feng, Fred Roosta, David P. Woodruff", "title": "Non-PSD Matrix Sketching with Applications to Regression and\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of dimensionality reduction techniques have been applied for\ncomputations involving large matrices. The underlying matrix is randomly\ncompressed into a smaller one, while approximately retaining many of its\noriginal properties. As a result, much of the expensive computation can be\nperformed on the small matrix. The sketching of positive semidefinite (PSD)\nmatrices is well understood, but there are many applications where the related\nmatrices are not PSD, including Hessian matrices in non-convex optimization and\ncovariance matrices in regression applications involving complex numbers. In\nthis paper, we present novel dimensionality reduction methods for non-PSD\nmatrices, as well as their ``square-roots\", which involve matrices with complex\nentries. We show how these techniques can be used for multiple downstream\ntasks. In particular, we show how to use the proposed matrix sketching\ntechniques for both convex and non-convex optimization, $\\ell_p$-regression for\nevery $1 \\leq p \\leq \\infty$, and vector-matrix-vector queries.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 04:07:48 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Feng", "Zhili", ""], ["Roosta", "Fred", ""], ["Woodruff", "David P.", ""]]}, {"id": "2106.08597", "submitter": "Wei-Ning Chen", "authors": "Wei-Ning Chen, Peter Kairouz, Ayfer \\\"Ozg\\\"ur", "title": "Breaking The Dimension Dependence in Sparse Distribution Estimation\n  under Communication Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of estimating a $d$-dimensional $s$-sparse discrete\ndistribution from its samples observed under a $b$-bit communication\nconstraint. The best-known previous result on $\\ell_2$ estimation error for\nthis problem is $O\\left( \\frac{s\\log\\left( {d}/{s}\\right)}{n2^b}\\right)$.\nSurprisingly, we show that when sample size $n$ exceeds a minimum threshold\n$n^*(s, d, b)$, we can achieve an $\\ell_2$ estimation error of $O\\left(\n\\frac{s}{n2^b}\\right)$. This implies that when $n>n^*(s, d, b)$ the convergence\nrate does not depend on the ambient dimension $d$ and is the same as knowing\nthe support of the distribution beforehand.\n  We next ask the question: ``what is the minimum $n^*(s, d, b)$ that allows\ndimension-free convergence?''. To upper bound $n^*(s, d, b)$, we develop novel\nlocalization schemes to accurately and efficiently localize the unknown\nsupport. For the non-interactive setting, we show that $n^*(s, d, b) = O\\left(\n\\min \\left( {d^2\\log^2 d}/{2^b}, {s^4\\log^2 d}/{2^b}\\right) \\right)$. Moreover,\nwe connect the problem with non-adaptive group testing and obtain a\npolynomial-time estimation scheme when $n = \\tilde{\\Omega}\\left({s^4\\log^4\nd}/{2^b}\\right)$. This group testing based scheme is adaptive to the sparsity\nparameter $s$, and hence can be applied without knowing it. For the interactive\nsetting, we propose a novel tree-based estimation scheme and show that the\nminimum sample-size needed to achieve dimension-free convergence can be further\nreduced to $n^*(s, d, b) = \\tilde{O}\\left( {s^2\\log^2 d}/{2^b} \\right)$.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 07:52:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Chen", "Wei-Ning", ""], ["Kairouz", "Peter", ""], ["\u00d6zg\u00fcr", "Ayfer", ""]]}, {"id": "2106.08598", "submitter": "Marco Rando", "authors": "Marco Rando, Luigi Carratino, Silvia Villa and Lorenzo Rosasco", "title": "Ada-BKB: Scalable Gaussian Process Optimization on Continuous Domain by\n  Adaptive Discretization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process optimization is a successful class of algorithms (e.g.\nGP-UCB) to optimize a black-box function through sequential evaluations.\nHowever, when the domain of the function is continuous, Gaussian process\noptimization has to either rely on a fixed discretization of the space, or\nsolve a non-convex optimization subproblem at each evaluation. The first\napproach can negatively affect performance, while the second one puts a heavy\ncomputational burden on the algorithm. A third option, that only recently has\nbeen theoretically studied, is to adaptively discretize the function domain.\nEven though this approach avoids the extra non-convex optimization costs, the\noverall computational complexity is still prohibitive. An algorithm such as\nGP-UCB has a runtime of $O(T^4)$, where $T$ is the number of iterations. In\nthis paper, we introduce Ada-BKB (Adaptive Budgeted Kernelized Bandit), a\nno-regret Gaussian process optimization algorithm for functions on continuous\ndomains, that provably runs in $O(T^2 d_\\text{eff}^2)$, where $d_\\text{eff}$ is\nthe effective dimension of the explored space, and which is typically much\nsmaller than $T$. We corroborate our findings with experiments on synthetic\nnon-convex functions and on the real-world problem of hyper-parameter\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 07:55:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Rando", "Marco", ""], ["Carratino", "Luigi", ""], ["Villa", "Silvia", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "2106.08619", "submitter": "Francesco Cagnetta", "authors": "Alessandro Favero, Francesco Cagnetta, Matthieu Wyart", "title": "Locality defeats the curse of dimensionality in convolutional\n  teacher-student scenarios", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks perform a local and translationally-invariant\ntreatment of the data: quantifying which of these two aspects is central to\ntheir success remains a challenge. We study this problem within a\nteacher-student framework for kernel regression, using `convolutional' kernels\ninspired by the neural tangent kernel of simple convolutional architectures of\ngiven filter size. Using heuristic methods from physics, we find in the\nridgeless case that locality is key in determining the learning curve exponent\n$\\beta$ (that relates the test error $\\epsilon_t\\sim P^{-\\beta}$ to the size of\nthe training set $P$), whereas translational invariance is not. In particular,\nif the filter size of the teacher $t$ is smaller than that of the student $s$,\n$\\beta$ is a function of $s$ only and does not depend on the input dimension.\nWe confirm our predictions on $\\beta$ empirically. Theoretically, in some cases\n(including when teacher and student are equal) it can be shown that this\nprediction is an upper bound on performance. We conclude by proving, using a\nnatural universality assumption, that performing kernel regression with a ridge\nthat decreases with the size of the training set leads to similar learning\ncurve exponents to those we obtain in the ridgeless case.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 08:27:31 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Favero", "Alessandro", ""], ["Cagnetta", "Francesco", ""], ["Wyart", "Matthieu", ""]]}, {"id": "2106.08678", "submitter": "Aaron Sim", "authors": "Aaron Sim, Maciej Wiatrak, Angus Brayne, P\\'aid\\'i Creed, Saee Paliwal", "title": "Directed Graph Embeddings in Pseudo-Riemannian Manifolds", "comments": "Accepted at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The inductive biases of graph representation learning algorithms are often\nencoded in the background geometry of their embedding space. In this paper, we\nshow that general directed graphs can be effectively represented by an\nembedding model that combines three components: a pseudo-Riemannian metric\nstructure, a non-trivial global topology, and a unique likelihood function that\nexplicitly incorporates a preferred direction in embedding space. We\ndemonstrate the representational capabilities of this method by applying it to\nthe task of link prediction on a series of synthetic and real directed graphs\nfrom natural language applications and biology. In particular, we show that\nlow-dimensional cylindrical Minkowski and anti-de Sitter spacetimes can produce\nequal or better graph representations than curved Riemannian manifolds of\nhigher dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 10:31:37 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Sim", "Aaron", ""], ["Wiatrak", "Maciej", ""], ["Brayne", "Angus", ""], ["Creed", "P\u00e1id\u00ed", ""], ["Paliwal", "Saee", ""]]}, {"id": "2106.08687", "submitter": "Zhongjie Yu", "authors": "Zhongjie Yu, Mingye Zhu, Martin Trapp, Arseny Skryagin, Kristian\n  Kersting", "title": "Leveraging Probabilistic Circuits for Nonparametric Multi-Output\n  Regression", "comments": "Accepted for the 37th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Inspired by recent advances in the field of expert-based approximations of\nGaussian processes (GPs), we present an expert-based approach to large-scale\nmulti-output regression using single-output GP experts. Employing a deeply\nstructured mixture of single-output GPs encoded via a probabilistic circuit\nallows us to capture correlations between multiple output dimensions\naccurately. By recursively partitioning the covariate space and the output\nspace, posterior inference in our model reduces to inference on single-output\nGP experts, which only need to be conditioned on a small subset of the\nobservations. We show that inference can be performed exactly and efficiently\nin our model, that it can capture correlations between output dimensions and,\nhence, often outperforms approaches that do not incorporate inter-output\ncorrelations, as demonstrated on several data sets in terms of the negative log\npredictive density.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 10:49:55 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Yu", "Zhongjie", ""], ["Zhu", "Mingye", ""], ["Trapp", "Martin", ""], ["Skryagin", "Arseny", ""], ["Kersting", "Kristian", ""]]}, {"id": "2106.08750", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Yuhao Zhou, Tongzheng Ren, Jun Zhu", "title": "Scalable Quasi-Bayesian Inference for Instrumental Variable Regression", "comments": "ZW and YZ contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed an upsurge of interest in employing flexible\nmachine learning models for instrumental variable (IV) regression, but the\ndevelopment of uncertainty quantification methodology is still lacking. In this\nwork we present a scalable quasi-Bayesian procedure for IV regression, building\nupon the recently developed kernelized IV models. Contrary to Bayesian modeling\nfor IV, our approach does not require additional assumptions on the data\ngenerating process, and leads to a scalable approximate inference algorithm\nwith time cost comparable to the corresponding point estimation methods. Our\nalgorithm can be further extended to work with neural network models. We\nanalyze the theoretical properties of the proposed quasi-posterior, and\ndemonstrate through empirical evaluation the competitive performance of our\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 12:52:19 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wang", "Ziyu", ""], ["Zhou", "Yuhao", ""], ["Ren", "Tongzheng", ""], ["Zhu", "Jun", ""]]}, {"id": "2106.08769", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan, Siddharth Swaroop", "title": "Knowledge-Adaptation Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans and animals have a natural ability to quickly adapt to their\nsurroundings, but machine-learning models, when subjected to changes, often\nrequire a complete retraining from scratch. We present Knowledge-adaptation\npriors (K-priors) to reduce the cost of retraining by enabling quick and\naccurate adaptation for a wide-variety of tasks and models. This is made\npossible by a combination of weight and function-space priors to reconstruct\nthe gradients of the past, which recovers and generalizes many existing, but\nseemingly-unrelated, adaptation strategies. Training with simple first-order\ngradient methods can often recover the exact retrained model to an arbitrary\naccuracy by choosing a sufficiently large memory of the past data. Empirical\nresults confirm that the adaptation can be cheap and accurate, and a promising\nalternative to retraining.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:27:22 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Swaroop", "Siddharth", ""]]}, {"id": "2106.08775", "submitter": "Cameron Wolfe", "authors": "Junhyung Lyle Kim, Jose Antonio Lara Benitez, Mohammad Taha Toghani,\n  Cameron Wolfe, Zhiwei Zhang, Anastasios Kyrillidis", "title": "Momentum-inspired Low-Rank Coordinate Descent for Diagonally Constrained\n  SDPs", "comments": "10 pages, 8 figures, preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG cs.MS math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel, practical, and provable approach for solving diagonally\nconstrained semi-definite programming (SDP) problems at scale using accelerated\nnon-convex programming. Our algorithm non-trivially combines acceleration\nmotions from convex optimization with coordinate power iteration and matrix\nfactorization techniques. The algorithm is extremely simple to implement, and\nadds only a single extra hyperparameter -- momentum. We prove that our method\nadmits local linear convergence in the neighborhood of the optimum and always\nconverges to a first-order critical point. Experimentally, we showcase the\nmerits of our method on three major application domains: MaxCut, MaxSAT, and\nMIMO signal detection. In all cases, our methodology provides significant\nspeedups over non-convex and convex SDP solvers -- 5X faster than\nstate-of-the-art non-convex solvers, and 9 to 10^3 X faster than convex SDP\nsolvers -- with comparable or improved solution quality.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:35:40 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 00:13:34 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kim", "Junhyung Lyle", ""], ["Benitez", "Jose Antonio Lara", ""], ["Toghani", "Mohammad Taha", ""], ["Wolfe", "Cameron", ""], ["Zhang", "Zhiwei", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "2106.08808", "submitter": "Pietro Gori", "authors": "Benoit Dufumier, Pietro Gori, Julie Victor, Antoine Grigis, Michel\n  Wessa, Paolo Brambilla, Pauline Favre, Mircea Polosan, Colm McDonald, Camille\n  Marie Piguet, Edouard Duchesnay", "title": "Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI\n  Classification", "comments": "MICCAI 2021", "journal-ref": "MICCAI 2021", "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional supervised learning with deep neural networks requires a\ntremendous amount of labelled data to converge to a good solution. For 3D\nmedical images, it is often impractical to build a large homogeneous annotated\ndataset for a specific pathology. Self-supervised methods offer a new way to\nlearn a representation of the images in an unsupervised manner with a neural\nnetwork. In particular, contrastive learning has shown great promises by\n(almost) matching the performance of fully-supervised CNN on vision tasks.\nNonetheless, this method does not take advantage of available meta-data, such\nas participant's age, viewed as prior knowledge. Here, we propose to leverage\ncontinuous proxy metadata, in the contrastive learning framework, by\nintroducing a new loss called y-Aware InfoNCE loss. Specifically, we improve\nthe positive sampling during pre-training by adding more positive examples with\nsimilar proxy meta-data with the anchor, assuming they share similar\ndiscriminative semantic features.With our method, a 3D CNN model pre-trained on\n$10^4$ multi-site healthy brain MRI scans can extract relevant features for\nthree classification tasks: schizophrenia, bipolar diagnosis and Alzheimer's\ndetection. When fine-tuned, it also outperforms 3D CNN trained from scratch on\nthese tasks, as well as state-of-the-art self-supervised methods. Our code is\nmade publicly available here.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:17:04 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Dufumier", "Benoit", ""], ["Gori", "Pietro", ""], ["Victor", "Julie", ""], ["Grigis", "Antoine", ""], ["Wessa", "Michel", ""], ["Brambilla", "Paolo", ""], ["Favre", "Pauline", ""], ["Polosan", "Mircea", ""], ["McDonald", "Colm", ""], ["Piguet", "Camille Marie", ""], ["Duchesnay", "Edouard", ""]]}, {"id": "2106.08812", "submitter": "Han Zhao", "authors": "Han Zhao", "title": "Costs and Benefits of Wasserstein Fair Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications of machine learning tools in high-stakes domains are\noften regulated to be fair, in the sense that the predicted target should\nsatisfy some quantitative notion of parity with respect to a protected\nattribute. However, the exact tradeoff between fairness and accuracy with a\nreal-valued target is not clear. In this paper, we characterize the inherent\ntradeoff between statistical parity and accuracy in the regression setting by\nproviding a lower bound on the error of any fair regressor. Our lower bound is\nsharp, algorithm-independent, and admits a simple interpretation: when the\nmoments of the target differ between groups, any fair algorithm has to make a\nlarge error on at least one of the groups. We further extend this result to\ngive a lower bound on the joint error of any (approximately) fair algorithm,\nusing the Wasserstein distance to measure the quality of the approximation. On\nthe upside, we establish the first connection between individual fairness,\naccuracy parity, and the Wasserstein distance by showing that if a regressor is\nindividually fair, it also approximately verifies the accuracy parity, where\nthe gap is given by the Wasserstein distance between the two groups. Inspired\nby our theoretical results, we develop a practical algorithm for fair\nregression through the lens of representation learning, and conduct experiments\non a real-world dataset to corroborate our findings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:24:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Zhao", "Han", ""]]}, {"id": "2106.08814", "submitter": "Peter Rousseeuw", "authors": "Jakob Raymaekers and Peter J. Rousseeuw", "title": "Silhouettes and quasi residual plots for neural nets and tree-based\n  classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification by neural nets and by tree-based methods are powerful tools of\nmachine learning. There exist interesting visualizations of the inner workings\nof these and other classifiers. Here we pursue a different goal, which is to\nvisualize the cases being classified, either in training data or in test data.\nAn important aspect is whether a case has been classified to its given class\n(label) or whether the classifier wants to assign it to different class. This\nis reflected in the (conditional and posterior) probability of the alternative\nclass (PAC). A high PAC indicates label bias, i.e. the possibility that the\ncase was mislabeled. The PAC is used to construct a silhouette plot which is\nsimilar in spirit to the silhouette plot for cluster analysis (Rousseeuw,\n1987). The average silhouette width can be used to compare different\nclassifications of the same dataset. We will also draw quasi residual plots of\nthe PAC versus a data feature, which may lead to more insight in the data. One\nof these data features is how far each case lies from its given class. The\ngraphical displays are illustrated and interpreted on benchmark data sets\ncontaining images, mixed features, and tweets.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 14:26:31 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Raymaekers", "Jakob", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "2106.08852", "submitter": "Xiaoli Li", "authors": "Xiaoli Li", "title": "Multilinear Dirichlet Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dependent Dirichlet processes (DDP) have been widely applied to model data\nfrom distributions over collections of measures which are correlated in some\nway. On the other hand, in recent years, increasing research efforts in machine\nlearning and data mining have been dedicated to dealing with data involving\ninteractions from two or more factors. However, few researchers have addressed\nthe heterogeneous relationship in data brought by modulation of multiple\nfactors using techniques of DDP. In this paper, we propose a novel technique,\nMultiLinear Dirichlet Processes (MLDP), to constructing DDPs by combining DP\nwith a state-of-the-art factor analysis technique, multilinear factor analyzers\n(MLFA). We have evaluated MLDP on real-word data sets for different\napplications and have achieved state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 15:18:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Li", "Xiaoli", ""]]}, {"id": "2106.08855", "submitter": "Gaspard Beugnot", "authors": "Gaspard Beugnot, Julien Mairal, Alessandro Rudi", "title": "Beyond Tikhonov: Faster Learning with Self-Concordant Losses via\n  Iterative Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The theory of spectral filtering is a remarkable tool to understand the\nstatistical properties of learning with kernels. For least squares, it allows\nto derive various regularization schemes that yield faster convergence rates of\nthe excess risk than with Tikhonov regularization. This is typically achieved\nby leveraging classical assumptions called source and capacity conditions,\nwhich characterize the difficulty of the learning task. In order to understand\nestimators derived from other loss functions, Marteau-Ferey et al. have\nextended the theory of Tikhonov regularization to generalized self concordant\nloss functions (GSC), which contain, e.g., the logistic loss. In this paper, we\ngo a step further and show that fast and optimal rates can be achieved for GSC\nby using the iterated Tikhonov regularization scheme, which is intrinsically\nrelated to the proximal point method in optimization, and overcomes the\nlimitation of the classical Tikhonov regularization.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 15:25:41 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Beugnot", "Gaspard", ""], ["Mairal", "Julien", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2106.08864", "submitter": "Yuzhou Cao", "authors": "Yuzhou Cao, Lei Feng, Senlin Shu, Yitian Xu, Bo An, Gang Niu, Masashi\n  Sugiyama", "title": "Multi-Class Classification from Single-Class Data with Confidences", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we learn a multi-class classifier from only data of a single class? We\nshow that without any assumptions on the loss functions, models, and\noptimizers, we can successfully learn a multi-class classifier from only data\nof a single class with a rigorous consistency guarantee when confidences (i.e.,\nthe class-posterior probabilities for all the classes) are available.\nSpecifically, we propose an empirical risk minimization framework that is\nloss-/model-/optimizer-independent. Instead of constructing a boundary between\nthe given class and other classes, our method can conduct discriminative\nclassification between all the classes even if no data from the other classes\nare provided. We further theoretically and experimentally show that our method\ncan be Bayes-consistent with a simple modification even if the provided\nconfidences are highly noisy. Then, we provide an extension of our method for\nthe case where data from a subset of all the classes are available.\nExperimental results demonstrate the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 15:38:13 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Cao", "Yuzhou", ""], ["Feng", "Lei", ""], ["Shu", "Senlin", ""], ["Xu", "Yitian", ""], ["An", "Bo", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2106.08882", "submitter": "Abolfazl Hashemi", "authors": "Anish Acharya, Abolfazl Hashemi, Prateek Jain, Sujay Sanghavi,\n  Inderjit S. Dhillon, Ufuk Topcu", "title": "Robust Training in High Dimensions via Block Coordinate Geometric Median\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Geometric median (\\textsc{Gm}) is a classical method in statistics for\nachieving a robust estimation of the uncorrupted data; under gross corruption,\nit achieves the optimal breakdown point of 0.5. However, its computational\ncomplexity makes it infeasible for robustifying stochastic gradient descent\n(SGD) for high-dimensional optimization problems. In this paper, we show that\nby applying \\textsc{Gm} to only a judiciously chosen block of coordinates at a\ntime and using a memory mechanism, one can retain the breakdown point of 0.5\nfor smooth non-convex problems, with non-asymptotic convergence rates\ncomparable to the SGD with \\textsc{Gm}.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 15:55:50 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Acharya", "Anish", ""], ["Hashemi", "Abolfazl", ""], ["Jain", "Prateek", ""], ["Sanghavi", "Sujay", ""], ["Dhillon", "Inderjit S.", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2106.08900", "submitter": "Lukas Gonon", "authors": "Lukas Gonon", "title": "Random feature neural networks learn Black-Scholes type PDEs without\n  curse of dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR q-fin.MF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the use of random feature neural networks for\nlearning Kolmogorov partial (integro-)differential equations associated to\nBlack-Scholes and more general exponential L\\'evy models. Random feature neural\nnetworks are single-hidden-layer feedforward neural networks in which only the\noutput weights are trainable. This makes training particularly simple, but (a\npriori) reduces expressivity. Interestingly, this is not the case for\nBlack-Scholes type PDEs, as we show here. We derive bounds for the prediction\nerror of random neural networks for learning sufficiently non-degenerate\nBlack-Scholes type models. A full error analysis is provided and it is shown\nthat the derived bounds do not suffer from the curse of dimensionality. We also\ninvestigate an application of these results to basket options and validate the\nbounds numerically.\n  These results prove that neural networks are able to \\textit{learn} solutions\nto Black-Scholes type PDEs without the curse of dimensionality. In addition,\nthis provides an example of a relevant learning problem in which random feature\nneural networks are provably efficient.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 10:03:36 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Gonon", "Lukas", ""]]}, {"id": "2106.08902", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh, Abishek Sankararaman and Kannan Ramchandran", "title": "Collaborative Learning and Personalization in Multi-Agent Stochastic\n  Linear Bandits", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing regret in an $N$ agent heterogeneous\nstochastic linear bandits framework, where the agents (users) are similar but\nnot all identical. We model user heterogeneity using two popularly used ideas\nin practice; (i) A clustering framework where users are partitioned into groups\nwith users in the same group being identical to each other, but different\nacross groups, and (ii) a personalization framework where no two users are\nnecessarily identical, but a user's parameters are close to that of the\npopulation average. In the clustered users' setup, we propose a novel\nalgorithm, based on successive refinement of cluster identities and regret\nminimization. We show that, for any agent, the regret scales as\n$\\mathcal{O}(\\sqrt{T/N})$, if the agent is in a `well separated' cluster, or\nscales as $\\mathcal{O}(T^{\\frac{1}{2} + \\varepsilon}/(N)^{\\frac{1}{2}\n-\\varepsilon})$ if its cluster is not well separated, where $\\varepsilon$ is\npositive and arbitrarily close to $0$. Our algorithm is adaptive to the cluster\nseparation, and is parameter free -- it does not need to know the number of\nclusters, separation and cluster size, yet the regret guarantee adapts to the\ninherent complexity. In the personalization framework, we introduce a natural\nalgorithm where, the personal bandit instances are initialized with the\nestimates of the global average model. We show that, an agent $i$ whose\nparameter deviates from the population average by $\\epsilon_i$, attains a\nregret scaling of $\\widetilde{O}(\\epsilon_i\\sqrt{T})$. This demonstrates that\nif the user representations are close (small $\\epsilon_i)$, the resulting\nregret is low, and vice-versa. The results are empirically validated and we\nobserve superior performance of our adaptive algorithms over non-adaptive\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 00:45:55 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ghosh", "Avishek", ""], ["Sankararaman", "Abishek", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2106.08903", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Florian Becker, Stephan G\\\"unnemann", "title": "GemNet: Universal Directional Graph Neural Networks for Molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effectively predicting molecular interactions has the potential to accelerate\nmolecular dynamics by multiple orders of magnitude and thus revolutionize\nchemical simulations. Graph neural networks (GNNs) have recently shown great\nsuccesses for this task, overtaking classical methods based on fixed molecular\nkernels. However, they still appear very limited from a theoretical\nperspective, since regular GNNs cannot distinguish certain types of graphs. In\nthis work we close this gap between theory and practice. We show that GNNs with\ndirected edge embeddings and two-hop message passing are indeed universal\napproximators for predictions that are invariant to global rotation and\ntranslation, and equivariant to permutation. We then leverage these insights\nand multiple structural improvements to propose the geometric message passing\nneural network (GemNet). We demonstrate the benefits of the proposed changes in\nmultiple ablation studies. GemNet outperforms previous models on the COLL and\nMD17 molecular dynamics datasets by 34% and 40%, performing especially well on\nthe most challenging molecules.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 15:44:55 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 15:37:29 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Klicpera", "Johannes", ""], ["Becker", "Florian", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2106.08909", "submitter": "David Brandfonbrener", "authors": "David Brandfonbrener, William F. Whitney, Rajesh Ranganath, Joan Bruna", "title": "Offline RL Without Off-Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most prior approaches to offline reinforcement learning (RL) have taken an\niterative actor-critic approach involving off-policy evaluation. In this paper\nwe show that simply doing one step of constrained/regularized policy\nimprovement using an on-policy Q estimate of the behavior policy performs\nsurprisingly well. This one-step algorithm beats the previously reported\nresults of iterative algorithms on a large portion of the D4RL benchmark. The\nsimple one-step baseline achieves this strong performance without many of the\ntricks used by previously proposed iterative algorithms and is more robust to\nhyperparameters. We argue that the relatively poor performance of iterative\napproaches is a result of the high variance inherent in doing off-policy\nevaluation and magnified by the repeated optimization of policies against those\nhigh-variance estimates. In addition, we hypothesize that the strong\nperformance of the one-step algorithm is due to a combination of favorable\nstructure in the environment and behavior policy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 16:04:26 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 13:45:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Brandfonbrener", "David", ""], ["Whitney", "William F.", ""], ["Ranganath", "Rajesh", ""], ["Bruna", "Joan", ""]]}, {"id": "2106.08929", "submitter": "Pierre Glaser", "authors": "Pierre Glaser, Michael Arbel, Arthur Gretton", "title": "KALE Flow: A Relaxed KL Gradient Flow for Probabilities with Disjoint\n  Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the gradient flow for a relaxed approximation to the\nKullback-Leibler (KL) divergence between a moving source and a fixed target\ndistribution. This approximation, termed the KALE (KL approximate lower-bound\nestimator), solves a regularized version of the Fenchel dual problem defining\nthe KL over a restricted class of functions. When using a Reproducing Kernel\nHilbert Space (RKHS) to define the function class, we show that the KALE\ncontinuously interpolates between the KL and the Maximum Mean Discrepancy\n(MMD). Like the MMD and other Integral Probability Metrics, the KALE remains\nwell defined for mutually singular distributions. Nonetheless, the KALE\ninherits from the limiting KL a greater sensitivity to mismatch in the support\nof the distributions, compared with the MMD. These two properties make the KALE\ngradient flow particularly well suited when the target distribution is\nsupported on a low-dimensional manifold. Under an assumption of sufficient\nsmoothness of the trajectories, we show the global convergence of the KALE\nflow. We propose a particle implementation of the flow given initial samples\nfrom the source and the target distribution, which we use to empirically\nconfirm the KALE's properties.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 16:37:43 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Glaser", "Pierre", ""], ["Arbel", "Michael", ""], ["Gretton", "Arthur", ""]]}, {"id": "2106.08943", "submitter": "Jiatai Huang", "authors": "Jiatai Huang, Longbo Huang", "title": "Banker Online Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Banker-OMD, a novel framework generalizing the classical Online\nMirror Descent (OMD) technique in online learning algorithm design. Banker-OMD\nallows algorithms to robustly handle delayed feedback, and offers a general\nmethodology for achieving $\\tilde{O}(\\sqrt{T} + \\sqrt{D})$-style regret bounds\nin various delayed-feedback online learning tasks, where $T$ is the time\nhorizon length and $D$ is the total feedback delay. We demonstrate the power of\nBanker-OMD with applications to three important bandit scenarios with delayed\nfeedback, including delayed adversarial Multi-armed bandits (MAB), delayed\nadversarial linear bandits, and a novel delayed best-of-both-worlds MAB\nsetting. Banker-OMD achieves nearly-optimal performance in all the three\nsettings. In particular, it leads to the first delayed adversarial linear\nbandit algorithm achieving $\\tilde{O}(\\text{poly}(n)(\\sqrt{T} + \\sqrt{D}))$\nregret.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 16:57:05 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Huang", "Jiatai", ""], ["Huang", "Longbo", ""]]}, {"id": "2106.08990", "submitter": "Spencer Matthews", "authors": "Spencer Matthews and Brian Hartman", "title": "mSHAP: SHAP Values for Two-Part Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two-part models are important to and used throughout insurance and actuarial\nscience. Since insurance is required for registering a car, obtaining a\nmortgage, and participating in certain businesses, it is especially important\nthat the models which price insurance policies are fair and non-discriminatory.\nBlack box models can make it very difficult to know which covariates are\ninfluencing the results. SHAP values enable interpretation of various black box\nmodels, but little progress has been made in two-part models. In this paper, we\npropose mSHAP (or multiplicative SHAP), a method for computing SHAP values of\ntwo-part models using the SHAP values of the individual models. This method\nwill allow for the predictions of two-part models to be explained at an\nindividual observation level. After developing mSHAP, we perform an in-depth\nsimulation study. Although the kernelSHAP algorithm is also capable of\ncomputing approximate SHAP values for a two-part model, a comparison with our\nmethod demonstrates that mSHAP is exponentially faster. Ultimately, we apply\nmSHAP to a two-part ratemaking model for personal auto property damage\ninsurance coverage. Additionally, an R package (mshap) is available to easily\nimplement the method in a wide variety of applications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:45:07 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Matthews", "Spencer", ""], ["Hartman", "Brian", ""]]}, {"id": "2106.09017", "submitter": "Haoxiang Wang", "authors": "Haoxiang Wang, Han Zhao, Bo Li", "title": "Bridging Multi-Task Learning and Meta-Learning: Towards Efficient\n  Training and Effective Adaptation", "comments": "ICML 2021 camera-ready version. Code is released at\n  https://github.com/AI-secure/multi-task-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) aims to improve the generalization of several\nrelated tasks by learning them jointly. As a comparison, in addition to the\njoint training scheme, modern meta-learning allows unseen tasks with limited\nlabels during the test phase, in the hope of fast adaptation over them. Despite\nthe subtle difference between MTL and meta-learning in the problem formulation,\nboth learning paradigms share the same insight that the shared structure\nbetween existing training tasks could lead to better generalization and\nadaptation. In this paper, we take one important step further to understand the\nclose connection between these two learning paradigms, through both theoretical\nanalysis and empirical investigation. Theoretically, we first demonstrate that\nMTL shares the same optimization formulation with a class of gradient-based\nmeta-learning (GBML) algorithms. We then prove that for over-parameterized\nneural networks with sufficient depth, the learned predictive functions of MTL\nand GBML are close. In particular, this result implies that the predictions\ngiven by these two models are similar over the same unseen task. Empirically,\nwe corroborate our theoretical findings by showing that, with proper\nimplementation, MTL is competitive against state-of-the-art GBML algorithms on\na set of few-shot image classification benchmarks. Since existing GBML\nalgorithms often involve costly second-order bi-level optimization, our\nfirst-order MTL method is an order of magnitude faster on large-scale datasets\nsuch as mini-ImageNet. We believe this work could help bridge the gap between\nthese two learning paradigms, and provide a computationally efficient\nalternative to GBML that also supports fast task adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:58:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wang", "Haoxiang", ""], ["Zhao", "Han", ""], ["Li", "Bo", ""]]}, {"id": "2106.09028", "submitter": "Hayata Yamasaki", "authors": "Hayata Yamasaki, Sho Sonoda", "title": "Exponential Error Convergence in Data Classification with Optimized\n  Random Features: Acceleration by Quantum Machine Learning", "comments": "28 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random features are a central technique for scalable learning algorithms\nbased on kernel methods. A recent work has shown that an algorithm for machine\nlearning by quantum computer, quantum machine learning (QML), can exponentially\nspeed up sampling of optimized random features, even without imposing\nrestrictive assumptions on sparsity and low-rankness of matrices that had\nlimited applicability of conventional QML algorithms; this QML algorithm makes\nit possible to significantly reduce and provably minimize the required number\nof features for regression tasks. However, a major interest in the field of QML\nis how widely the advantages of quantum computation can be exploited, not only\nin the regression tasks. We here construct a QML algorithm for a classification\ntask accelerated by the optimized random features. We prove that the QML\nalgorithm for sampling optimized random features, combined with stochastic\ngradient descent (SGD), can achieve state-of-the-art exponential convergence\nspeed of reducing classification error in a classification task under a\nlow-noise condition; at the same time, our algorithm with optimized random\nfeatures can take advantage of the significant reduction of the required number\nof features so as to accelerate each iteration in the SGD and evaluation of the\nclassifier obtained from our algorithm. These results discover a promising\napplication of QML to significant acceleration of the leading classification\nalgorithm based on kernel methods, without ruining its applicability to a\npractical class of data sets and the exponential error-convergence speed.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 18:00:00 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yamasaki", "Hayata", ""], ["Sonoda", "Sho", ""]]}, {"id": "2106.09070", "submitter": "Qi Lyu", "authors": "Qi Lyu and Xiao Fu", "title": "Identifiability-Guaranteed Simplex-Structured Post-Nonlinear Mixture\n  Learning via Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on the problem of unraveling nonlinearly mixed latent\ncomponents in an unsupervised manner. The latent components are assumed to\nreside in the probability simplex, and are transformed by an unknown\npost-nonlinear mixing system. This problem finds various applications in signal\nand data analytics, e.g., nonlinear hyperspectral unmixing, image embedding,\nand nonlinear clustering. Linear mixture learning problems are already\nill-posed, as identifiability of the target latent components is hard to\nestablish in general. With unknown nonlinearity involved, the problem is even\nmore challenging. Prior work offered a function equation-based formulation for\nprovable latent component identification. However, the identifiability\nconditions are somewhat stringent and unrealistic. In addition, the\nidentifiability analysis is based on the infinite sample (i.e., population)\ncase, while the understanding for practical finite sample cases has been\nelusive. Moreover, the algorithm in the prior work trades model expressiveness\nwith computational convenience, which often hinders the learning performance.\nOur contribution is threefold. First, new identifiability conditions are\nderived under largely relaxed assumptions. Second, comprehensive sample\ncomplexity results are presented -- which are the first of the kind. Third, a\nconstrained autoencoder-based algorithmic framework is proposed for\nimplementation, which effectively circumvents the challenges in the existing\nalgorithm. Synthetic and real experiments corroborate our theoretical analyses.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 18:20:58 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lyu", "Qi", ""], ["Fu", "Xiao", ""]]}, {"id": "2106.09071", "submitter": "Xu Han", "authors": "Xu Han, Ethan X Fang, Cheng Yong Tang", "title": "Pre-processing with Orthogonal Decompositions for High-dimensional\n  Explanatory Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Strong correlations between explanatory variables are problematic for\nhigh-dimensional regularized regression methods. Due to the violation of the\nIrrepresentable Condition, the popular LASSO method may suffer from false\ninclusions of inactive variables. In this paper, we propose pre-processing with\northogonal decompositions (PROD) for the explanatory variables in\nhigh-dimensional regressions. The PROD procedure is constructed based upon a\ngeneric orthogonal decomposition of the design matrix. We demonstrate by two\nconcrete cases that the PROD approach can be effectively constructed for\nimproving the performance of high-dimensional penalized regression. Our\ntheoretical analysis reveals their properties and benefits for high-dimensional\npenalized linear regression with LASSO. Extensive numerical studies with\nsimulations and data analysis show the promising performance of the PROD.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 18:22:16 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Han", "Xu", ""], ["Fang", "Ethan X", ""], ["Tang", "Cheng Yong", ""]]}, {"id": "2106.09111", "submitter": "Lev Utkin", "authors": "Lev V. Utkin and Andrei V. Konstantinov and Kirill A. Vishniakov", "title": "An Imprecise SHAP as a Tool for Explaining the Class Probability\n  Distributions under Limited Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most popular methods of the machine learning prediction\nexplanation is the SHapley Additive exPlanations method (SHAP). An imprecise\nSHAP as a modification of the original SHAP is proposed for cases when the\nclass probability distributions are imprecise and represented by sets of\ndistributions. The first idea behind the imprecise SHAP is a new approach for\ncomputing the marginal contribution of a feature, which fulfils the important\nefficiency property of Shapley values. The second idea is an attempt to\nconsider a general approach to calculating and reducing interval-valued Shapley\nvalues, which is similar to the idea of reachable probability intervals in the\nimprecise probability theory. A simple special implementation of the general\napproach in the form of linear optimization problems is proposed, which is\nbased on using the Kolmogorov-Smirnov distance and imprecise contamination\nmodels. Numerical examples with synthetic and real data illustrate the\nimprecise SHAP.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 20:30:26 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Utkin", "Lev V.", ""], ["Konstantinov", "Andrei V.", ""], ["Vishniakov", "Kirill A.", ""]]}, {"id": "2106.09114", "submitter": "Daniel Kowal", "authors": "Daniel R. Kowal and Bohan Wu", "title": "Semiparametric count data regression for self-reported mental health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"For how many days during the past 30 days was your mental health not good?\"\nThe responses to this question measure self-reported mental health and can be\nlinked to important covariates in the National Health and Nutrition Examination\nSurvey (NHANES). However, these count variables present major distributional\nchallenges: the data are overdispersed, zero-inflated, bounded by 30, and\nheaped in five- and seven-day increments. To meet these challenges, we design a\nsemiparametric estimation and inference framework for count data regression.\nThe data-generating process is defined by simultaneously transforming and\nrounding (STAR) a latent Gaussian regression model. The transformation is\nestimated nonparametrically and the rounding operator ensures the correct\nsupport for the discrete and bounded data. Maximum likelihood estimators are\ncomputed using an EM algorithm that is compatible with any continuous data\nmodel estimable by least squares. STAR regression includes asymptotic\nhypothesis testing and confidence intervals, variable selection via information\ncriteria, and customized diagnostics. Simulation studies validate the utility\nof this framework. STAR is deployed to study the factors associated with\nself-reported mental health and demonstrates substantial improvements in\ngoodness-of-fit compared to existing count data regression models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 20:38:13 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kowal", "Daniel R.", ""], ["Wu", "Bohan", ""]]}, {"id": "2106.09136", "submitter": "Yonghoon Lee", "authors": "Yonghoon Lee and Rina Foygel Barber", "title": "Binary classification with corrupted labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a binary classification problem where the goal is to fit an accurate\npredictor, the presence of corrupted labels in the training data set may create\nan additional challenge. However, in settings where likelihood maximization is\npoorly behaved-for example, if positive and negative labels are perfectly\nseparable-then a small fraction of corrupted labels can improve performance by\nensuring robustness. In this work, we establish that in such settings,\ncorruption acts as a form of regularization, and we compute precise upper\nbounds on estimation error in the presence of corruptions. Our results suggest\nthat the presence of corrupted data points is beneficial only up to a small\nfraction of the total sample, scaling with the square root of the sample size.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 21:23:48 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lee", "Yonghoon", ""], ["Barber", "Rina Foygel", ""]]}, {"id": "2106.09179", "submitter": "Yuxin Xiao", "authors": "Yuxin Xiao, Eric P. Xing, Willie Neiswanger", "title": "Amortized Auto-Tuning: Cost-Efficient Transfer Optimization for\n  Hyperparameter Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. Although methods have been proposed to speed up tuning via knowledge\ntransfer, they typically require the final performance of hyperparameters and\ndo not focus on low-fidelity information. Nevertheless, this common practice is\nsuboptimal and can incur an unnecessary use of resources. It is more\ncost-efficient to instead leverage the low-fidelity tuning observations to\nmeasure inter-task similarity and transfer knowledge from existing to new tasks\naccordingly. However, performing multi-fidelity tuning comes with its own\nchallenges in the transfer setting: the noise in the additional observations\nand the need for performance forecasting. Therefore, we conduct a thorough\nanalysis of the multi-task multi-fidelity Bayesian optimization framework,\nwhich leads to the best instantiation--amortized auto-tuning (AT2). We further\npresent an offline-computed 27-task hyperparameter recommendation (HyperRec)\ndatabase to serve the community. Extensive experiments on HyperRec and other\nreal-world databases illustrate the effectiveness of our AT2 method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 00:01:18 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Xiao", "Yuxin", ""], ["Xing", "Eric P.", ""], ["Neiswanger", "Willie", ""]]}, {"id": "2106.09207", "submitter": "Dhruv Rohatgi", "authors": "Jonathan Kelner, Frederic Koehler, Raghu Meka, Dhruv Rohatgi", "title": "On the Power of Preconditioning in Sparse Linear Regression", "comments": "73 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear regression is a fundamental problem in high-dimensional\nstatistics, but strikingly little is known about how to efficiently solve it\nwithout restrictive conditions on the design matrix. We consider the\n(correlated) random design setting, where the covariates are independently\ndrawn from a multivariate Gaussian $N(0,\\Sigma)$ with $\\Sigma : n \\times n$,\nand seek estimators $\\hat{w}$ minimizing $(\\hat{w}-w^*)^T\\Sigma(\\hat{w}-w^*)$,\nwhere $w^*$ is the $k$-sparse ground truth. Information theoretically, one can\nachieve strong error bounds with $O(k \\log n)$ samples for arbitrary $\\Sigma$\nand $w^*$; however, no efficient algorithms are known to match these guarantees\neven with $o(n)$ samples, without further assumptions on $\\Sigma$ or $w^*$. As\nfar as hardness, computational lower bounds are only known with worst-case\ndesign matrices. Random-design instances are known which are hard for the\nLasso, but these instances can generally be solved by Lasso after a simple\nchange-of-basis (i.e. preconditioning).\n  In this work, we give upper and lower bounds clarifying the power of\npreconditioning in sparse linear regression. First, we show that the\npreconditioned Lasso can solve a large class of sparse linear regression\nproblems nearly optimally: it succeeds whenever the dependency structure of the\ncovariates, in the sense of the Markov property, has low treewidth -- even if\n$\\Sigma$ is highly ill-conditioned. Second, we construct (for the first time)\nrandom-design instances which are provably hard for an optimally preconditioned\nLasso. In fact, we complete our treewidth classification by proving that for\nany treewidth-$t$ graph, there exists a Gaussian Markov Random Field on this\ngraph such that the preconditioned Lasso, with any choice of preconditioner,\nrequires $\\Omega(t^{1/20})$ samples to recover $O(\\log n)$-sparse signals when\ncovariates are drawn from this model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 02:12:01 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kelner", "Jonathan", ""], ["Koehler", "Frederic", ""], ["Meka", "Raghu", ""], ["Rohatgi", "Dhruv", ""]]}, {"id": "2106.09215", "submitter": "Wenjie Li", "authors": "Wenjie Li, Chihua Wang, Guang Cheng", "title": "Optimum-statistical collaboration towards efficient black-box\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasingly more hyperparameters involved in their training, machine\nlearning systems demand a better understanding of hyperparameter tuning\nautomation. This has raised interest in studies of provably black-box\noptimization, which is made more practical by better exploration mechanism\nimplemented in algorithm design, managing the flux of both optimization and\nstatistical errors. Prior efforts focus on delineating optimization errors, but\nthis is deficient: black-box optimization algorithms can be inefficient without\nconsidering heterogeneity among reward samples. In this paper, we make the key\ndelineation on the role of statistical uncertainty in black-box optimization,\nguiding a more efficient algorithm design. We introduce\n\\textit{optimum-statistical collaboration}, a framework of managing the\ninteraction between optimization error flux and statistical error flux evolving\nin the optimization process. Inspired by this framework, we propose the\n\\texttt{VHCT} algorithms for objective functions with only local-smoothness\nassumptions. In theory, we prove our algorithm enjoys rate-optimal regret\nbounds; in experiments, we show the algorithm outperforms prior efforts in\nextensive settings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 02:37:39 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Li", "Wenjie", ""], ["Wang", "Chihua", ""], ["Cheng", "Guang", ""]]}, {"id": "2106.09222", "submitter": "Ousmane Dia", "authors": "Ousmane Amadou Dia, Theofanis Karaletsos, Caner Hazirbas, Cristian\n  Canton Ferrer, Ilknur Kaynar Kabul, Erik Meijer", "title": "Localized Uncertainty Attacks", "comments": "CVPR 2021 Workshop on Adversarial Machine Learning in Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The susceptibility of deep learning models to adversarial perturbations has\nstirred renewed attention in adversarial examples resulting in a number of\nattacks. However, most of these attacks fail to encompass a large spectrum of\nadversarial perturbations that are imperceptible to humans. In this paper, we\npresent localized uncertainty attacks, a novel class of threat models against\ndeterministic and stochastic classifiers. Under this threat model, we create\nadversarial examples by perturbing only regions in the inputs where a\nclassifier is uncertain. To find such regions, we utilize the predictive\nuncertainty of the classifier when the classifier is stochastic or, we learn a\nsurrogate model to amortize the uncertainty when it is deterministic. Unlike\n$\\ell_p$ ball or functional attacks which perturb inputs indiscriminately, our\ntargeted changes can be less perceptible. When considered under our threat\nmodel, these attacks still produce strong adversarial examples; with the\nexamples retaining a greater degree of similarity with the inputs.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 03:07:22 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Dia", "Ousmane Amadou", ""], ["Karaletsos", "Theofanis", ""], ["Hazirbas", "Caner", ""], ["Ferrer", "Cristian Canton", ""], ["Kabul", "Ilknur Kaynar", ""], ["Meijer", "Erik", ""]]}, {"id": "2106.09226", "submitter": "Colin Wei", "authors": "Colin Wei, Sang Michael Xie, Tengyu Ma", "title": "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis\n  of Head and Prompt Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models have achieved state-of-the-art performance when\nadapted to a downstream NLP task. However, theoretical analysis of these models\nis scarce and challenging since the pretraining and downstream tasks can be\nvery different. We propose an analysis framework that links the pretraining and\ndownstream tasks with an underlying latent variable generative model of text --\nthe downstream classifier must recover a function of the posterior distribution\nover the latent variables. We analyze head tuning (learning a classifier on top\nof the frozen pretrained model) and prompt tuning in this setting. The\ngenerative model in our analysis is either a Hidden Markov Model (HMM) or an\nHMM augmented with a latent memory component, motivated by long-term\ndependencies in natural language. We show that 1) under certain non-degeneracy\nconditions on the HMM, simple classification heads can solve the downstream\ntask, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy\nconditions, and 3) our recovery guarantees for the memory-augmented HMM are\nstronger than for the vanilla HMM because task-relevant information is easier\nto recover from the long-term memory. Experiments on synthetically generated\ndata from HMMs back our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 03:31:47 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wei", "Colin", ""], ["Xie", "Sang Michael", ""], ["Ma", "Tengyu", ""]]}, {"id": "2106.09246", "submitter": "Jong Chul Ye", "authors": "Joonyoung Song, Jong Chul Ye", "title": "Federated CycleGAN for Privacy-Preserving Image-to-Image Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised image-to-image translation methods such as CycleGAN learn to\nconvert images from one domain to another using unpaired training data sets\nfrom different domains. Unfortunately, these approaches still require centrally\ncollected unpaired records, potentially violating privacy and security issues.\nAlthough the recent federated learning (FL) allows a neural network to be\ntrained without data exchange, the basic assumption of the FL is that all\nclients have their own training data from a similar domain, which is different\nfrom our image-to-image translation scenario in which each client has images\nfrom its unique domain and the goal is to learn image translation between\ndifferent domains without accessing the target domain data. To address this,\nhere we propose a novel federated CycleGAN architecture that can learn image\ntranslation in an unsupervised manner while maintaining the data privacy.\nSpecifically, our approach arises from a novel observation that CycleGAN loss\ncan be decomposed into the sum of client specific local objectives that can be\nevaluated using only their data. This local objective decomposition allows\nmultiple clients to participate in federated CycleGAN training without\nsacrificing performance. Furthermore, our method employs novel switchable\ngenerator and discriminator architecture using Adaptive Instance Normalization\n(AdaIN) that significantly reduces the band-width requirement of the federated\nlearning. Our experimental results on various unsupervised image translation\ntasks show that our federated CycleGAN provides comparable performance compared\nto the non-federated counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 05:01:59 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Song", "Joonyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2106.09269", "submitter": "Daiki Chijiwa", "authors": "Daiki Chijiwa, Shin'ya Yamaguchi, Yasutoshi Ida, Kenji Umakoshi,\n  Tomohiro Inoue", "title": "Pruning Randomly Initialized Neural Networks with Iterative\n  Randomization", "comments": "Code will be available at https://github.com/dchiji-ntt/iterand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning the weights of randomly initialized neural networks plays an\nimportant role in the context of lottery ticket hypothesis. Ramanujan et al.\n(2020) empirically showed that only pruning the weights can achieve remarkable\nperformance instead of optimizing the weight values. However, to achieve the\nsame level of performance as the weight optimization, the pruning approach\nrequires more parameters in the networks before pruning and thus more memory\nspace. To overcome this parameter inefficiency, we introduce a novel framework\nto prune randomly initialized neural networks with iteratively randomizing\nweight values (IteRand). Theoretically, we prove an approximation theorem in\nour framework, which indicates that the randomizing operations are provably\neffective to reduce the required number of the parameters. We also empirically\ndemonstrate the parameter efficiency in multiple experiments on CIFAR-10 and\nImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 06:32:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Chijiwa", "Daiki", ""], ["Yamaguchi", "Shin'ya", ""], ["Ida", "Yasutoshi", ""], ["Umakoshi", "Kenji", ""], ["Inoue", "Tomohiro", ""]]}, {"id": "2106.09276", "submitter": "Danica J. Sutherland", "authors": "Frederic Koehler and Lijia Zhou and Danica J. Sutherland and Nathan\n  Srebro", "title": "Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and\n  Benign Overfitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider interpolation learning in high-dimensional linear regression with\nGaussian data, and prove a generic uniform convergence guarantee on the\ngeneralization error of interpolators in an arbitrary hypothesis class in terms\nof the class's Gaussian width. Applying the generic bound to Euclidean norm\nballs recovers the consistency result of Bartlett et al. (2020) for\nminimum-norm interpolators, and confirms a prediction of Zhou et al. (2020) for\nnear-minimal-norm interpolators in the special case of Gaussian data. We\ndemonstrate the generality of the bound by applying it to the simplex,\nobtaining a novel consistency result for minimum l1-norm interpolators (basis\npursuit). Our results show how norm-based generalization bounds can explain and\nbe used to analyze benign overfitting, at least in some settings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 06:58:10 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Koehler", "Frederic", ""], ["Zhou", "Lijia", ""], ["Sutherland", "Danica J.", ""], ["Srebro", "Nathan", ""]]}, {"id": "2106.09291", "submitter": "Xian-Jin Gui", "authors": "Xian-Jin Gui, Wei Wang, Zhang-Hao Tian", "title": "Towards Understanding Deep Learning from Noisy Labels with Small-Loss\n  Criterion", "comments": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCAI) 2021, includes non-archival supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks need large amounts of labeled data to achieve good\nperformance. In real-world applications, labels are usually collected from\nnon-experts such as crowdsourcing to save cost and thus are noisy. In the past\nfew years, deep learning methods for dealing with noisy labels have been\ndeveloped, many of which are based on the small-loss criterion. However, there\nare few theoretical analyses to explain why these methods could learn well from\nnoisy labels. In this paper, we theoretically explain why the widely-used\nsmall-loss criterion works. Based on the explanation, we reformalize the\nvanilla small-loss criterion to better tackle noisy labels. The experimental\nresults verify our theoretical explanation and also demonstrate the\neffectiveness of the reformalization.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 07:53:12 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Gui", "Xian-Jin", ""], ["Wang", "Wei", ""], ["Tian", "Zhang-Hao", ""]]}, {"id": "2106.09327", "submitter": "Guillaume Dalle", "authors": "Guillaume Dalle (CERMICS), Yohann de Castro (ICJ, ECL)", "title": "Minimax Estimation of Partially-Observed Vector AutoRegressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the behavior of large dynamical systems like transportation\nnetworks, one must often rely on measurements transmitted by a set of sensors,\nfor instance individual vehicles. Such measurements are likely to be incomplete\nand imprecise, which makes it hard to recover the underlying signal of\ninterest.Hoping to quantify this phenomenon, we study the properties of a\npartially-observed state-space model. In our setting, the latent state $X$\nfollows a high-dimensional Vector AutoRegressive process $X_t = \\theta X_{t-1}\n+ \\varepsilon_t$. Meanwhile, the observations $Y$ are given by a\nnoise-corrupted random sample from the state $Y_t = \\Pi_t X_t + \\eta_t$.\nSeveral random sampling mechanisms are studied, allowing us to investigate the\neffect of spatial and temporal correlations in the distribution of the sampling\nmatrices $\\Pi_t$.We first prove a lower bound on the minimax estimation error\nfor the transition matrix $\\theta$. We then describe a sparse estimator based\non the Dantzig selector and upper bound its non-asymptotic error, showing that\nit achieves the optimal convergence rate for most of our sampling mechanisms.\nNumerical experiments on simulated time series validate our theoretical\nfindings, while an application to open railway data highlights the relevance of\nthis model for public transport traffic analysis.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 08:46:53 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Dalle", "Guillaume", "", "CERMICS"], ["de Castro", "Yohann", "", "ICJ, ECL"]]}, {"id": "2106.09350", "submitter": "Yuhao Wang", "authors": "Yuhao Wang, Arnab Bhattacharyya", "title": "Identifiability of AMP chain graph models", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study identifiability of Andersson-Madigan-Perlman (AMP) chain graph\nmodels, which are a common generalization of linear structural equation models\nand Gaussian graphical models. AMP models are described by DAGs on chain\ncomponents which themselves are undirected graphs.\n  For a known chain component decomposition, we show that the DAG on the chain\ncomponents is identifiable if the determinants of the residual covariance\nmatrices of the chain components are monotone non-decreasing in topological\norder. This condition extends the equal variance identifiability criterion for\nBayes nets, and it can be generalized from determinants to any super-additive\nfunction on positive semidefinite matrices. When the component decomposition is\nunknown, we describe conditions that allow recovery of the full structure using\na polynomial time algorithm based on submodular function minimization. We also\nconduct experiments comparing our algorithm's performance against existing\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 10:09:30 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Yuhao", ""], ["Bhattacharyya", "Arnab", ""]]}, {"id": "2106.09370", "submitter": "Jonathan Dumas", "authors": "Jonathan Dumas and Antoine Wehenkel Damien Lanaspeze and Bertrand\n  Corn\\'elusse and Antonio Sutera", "title": "Deep generative modeling for probabilistic forecasting in power systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Greater direct electrification of end-use sectors with a higher share of\nrenewables is one of the pillars to power a carbon-neutral society by 2050.\nThis study uses a recent deep learning technique, the normalizing flows, to\nproduce accurate probabilistic forecasts that are crucial for decision-makers\nto face the new challenges in power systems applications. Through comprehensive\nempirical evaluations using the open data of the Global Energy Forecasting\nCompetition 2014, we demonstrate that our methodology is competitive with other\nstate-of-the-art deep learning generative models: generative adversarial\nnetworks and variational autoencoders. The models producing weather-based wind,\nsolar power, and load scenarios are properly compared both in terms of forecast\nvalue, by considering the case study of an energy retailer, and quality using\nseveral complementary metrics.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 10:41:57 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 16:14:33 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Dumas", "Jonathan", ""], ["Lanaspeze", "Antoine Wehenkel Damien", ""], ["Corn\u00e9lusse", "Bertrand", ""], ["Sutera", "Antonio", ""]]}, {"id": "2106.09387", "submitter": "Feng Ruan", "authors": "Feng Ruan, Keli Liu, Michael I. Jordan", "title": "Taming Nonconvexity in Kernel Feature Selection---Favorable Properties\n  of the Laplace Kernel", "comments": "28 pages main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based feature selection is an important tool in nonparametric\nstatistics. Despite many practical applications of kernel-based feature\nselection, there is little statistical theory available to support the method.\nA core challenge is the objective function of the optimization problems used to\ndefine kernel-based feature selection are nonconvex. The literature has only\nstudied the statistical properties of the \\emph{global optima}, which is a\nmismatch, given that the gradient-based algorithms available for nonconvex\noptimization are only able to guarantee convergence to local minima. Studying\nthe full landscape associated with kernel-based methods, we show that feature\nselection objectives using the Laplace kernel (and other $\\ell_1$ kernels) come\nwith statistical guarantees that other kernels, including the ubiquitous\nGaussian kernel (or other $\\ell_2$ kernels) do not possess. Based on a sharp\ncharacterization of the gradient of the objective function, we show that\n$\\ell_1$ kernels eliminate unfavorable stationary points that appear when using\nan $\\ell_2$ kernel. Armed with this insight, we establish statistical\nguarantees for $\\ell_1$ kernel-based feature selection which do not require\nreaching the global minima. In particular, we establish model-selection\nconsistency of $\\ell_1$-kernel-based feature selection in recovering main\neffects and hierarchical interactions in the nonparametric setting with $n \\sim\n\\log p$ samples.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 11:05:48 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 05:15:48 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ruan", "Feng", ""], ["Liu", "Keli", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2106.09467", "submitter": "Agnieszka Maria S{\\l}owik", "authors": "Agnieszka S{\\l}owik, L\\'eon Bottou", "title": "Algorithmic Bias and Data Bias: Understanding the Relation between\n  Distributionally Robust Optimization and Data Curation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems based on minimizing average error have been shown to\nperform inconsistently across notable subsets of the data, which is not exposed\nby a low average error for the entire dataset. In consequential social and\neconomic applications, where data represent people, this can lead to\ndiscrimination of underrepresented gender and ethnic groups. Given the\nimportance of bias mitigation in machine learning, the topic leads to\ncontentious debates on how to ensure fairness in practice (data bias versus\nalgorithmic bias). Distributionally Robust Optimization (DRO) seemingly\naddresses this problem by minimizing the worst expected risk across\nsubpopulations. We establish theoretical results that clarify the relation\nbetween DRO and the optimization of the same loss averaged on an adequately\nweighted training dataset. The results cover finite and infinite number of\ntraining distributions, as well as convex and non-convex loss functions. We\nshow that neither DRO nor curating the training set should be construed as a\ncomplete solution for bias mitigation: in the same way that there is no\nuniversally robust training set, there is no universal way to setup a DRO\nproblem and ensure a socially acceptable set of results. We then leverage these\ninsights to provide a mininal set of practical recommendations for addressing\nbias with DRO. Finally, we discuss ramifications of our results in other\nrelated applications of DRO, using an example of adversarial robustness. Our\nresults show that there is merit to both the algorithm-focused and the\ndata-focused side of the bias debate, as long as arguments in favor of these\npositions are precisely qualified and backed by relevant mathematics known\ntoday.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 13:18:03 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "2106.09473", "submitter": "Antonio Sutera", "authors": "Antonio Sutera", "title": "Importance measures derived from random forests: characterisation and\n  extension", "comments": "PhD thesis, Li\\`ege, Belgium, June 2019. Permalink :\n  http://hdl.handle.net/2268/236868", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays new technologies, and especially artificial intelligence, are more\nand more established in our society. Big data analysis and machine learning,\ntwo sub-fields of artificial intelligence, are at the core of many recent\nbreakthroughs in many application fields (e.g., medicine, communication,\nfinance, ...), including some that are strongly related to our day-to-day life\n(e.g., social networks, computers, smartphones, ...). In machine learning,\nsignificant improvements are usually achieved at the price of an increasing\ncomputational complexity and thanks to bigger datasets. Currently, cutting-edge\nmodels built by the most advanced machine learning algorithms typically became\nsimultaneously very efficient and profitable but also extremely complex. Their\ncomplexity is to such an extent that these models are commonly seen as\nblack-boxes providing a prediction or a decision which can not be interpreted\nor justified. Nevertheless, whether these models are used autonomously or as a\nsimple decision-making support tool, they are already being used in machine\nlearning applications where health and human life are at stake. Therefore, it\nappears to be an obvious necessity not to blindly believe everything coming out\nof those models without a detailed understanding of their predictions or\ndecisions. Accordingly, this thesis aims at improving the interpretability of\nmodels built by a specific family of machine learning algorithms, the so-called\ntree-based methods. Several mechanisms have been proposed to interpret these\nmodels and we aim along this thesis to improve their understanding, study their\nproperties, and define their limitations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 13:23:57 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 08:15:29 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Sutera", "Antonio", ""]]}, {"id": "2106.09512", "submitter": "Sebastian Lerch", "authors": "Benedikt Schulz and Sebastian Lerch", "title": "Machine learning methods for postprocessing ensemble forecasts of wind\n  gusts: A systematic comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Postprocessing ensemble weather predictions to correct systematic errors has\nbecome a standard practice in research and operations. However, only few recent\nstudies have focused on ensemble postprocessing of wind gust forecasts, despite\nits importance for severe weather warnings. Here, we provide a comprehensive\nreview and systematic comparison of eight statistical and machine learning\nmethods for probabilistic wind gust forecasting via ensemble postprocessing,\nthat can be divided in three groups: State of the art postprocessing techniques\nfrom statistics (ensemble model output statistics (EMOS), member-by-member\npostprocessing, isotonic distributional regression), established machine\nlearning methods (gradient-boosting extended EMOS, quantile regression forests)\nand neural network-based approaches (distributional regression network,\nBernstein quantile network, histogram estimation network). The methods are\nsystematically compared using six years of data from a high-resolution,\nconvection-permitting ensemble prediction system that was run operationally at\nthe German weather service, and hourly observations at 175 surface weather\nstations in Germany. While all postprocessing methods yield calibrated\nforecasts and are able to correct the systematic errors of the raw ensemble\npredictions, incorporating information from additional meteorological predictor\nvariables beyond wind gusts leads to significant improvements in forecast\nskill. In particular, we propose a flexible framework of locally adaptive\nneural networks with different probabilistic forecast types as output, which\nnot only significantly outperform all benchmark postprocessing methods but also\nlearn physically consistent relations associated with the diurnal cycle,\nespecially the evening transition of the planetary boundary layer.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 14:03:29 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Schulz", "Benedikt", ""], ["Lerch", "Sebastian", ""]]}, {"id": "2106.09533", "submitter": "Graham Tierney", "authors": "Graham Tierney and Christopher Bail and Alexander Volfovsky", "title": "Author Clustering and Topic Estimation for Short Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of short text, such as social media posts, is extremely difficult\nbecause it relies on observing many document-level word co-occurrence pairs.\nBeyond topic distributions, a common downstream task of the modeling is\ngrouping the authors of these documents for subsequent analyses. Traditional\nmodels estimate the document groupings and identify user clusters with an\nindependent procedure. We propose a novel model that expands on the Latent\nDirichlet Allocation by modeling strong dependence among the words in the same\ndocument, with user-level topic distributions. We also simultaneously cluster\nusers, removing the need for post-hoc cluster estimation and improving topic\nestimation by shrinking noisy user-level topic distributions towards typical\nvalues. Our method performs as well as -- or better -- than traditional\napproaches to problems arising in short text, and we demonstrate its usefulness\non a dataset of tweets from United States Senators, recovering both meaningful\ntopics and clusters that reflect partisan ideology.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 20:55:55 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Tierney", "Graham", ""], ["Bail", "Christopher", ""], ["Volfovsky", "Alexander", ""]]}, {"id": "2106.09556", "submitter": "Yifei Bi", "authors": "Yifei Bi, Xinyi Chen, Caihui Xiao", "title": "A Deep Reinforcement Learning Approach towards Pendulum Swing-up Problem\n  based on TF-Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adapting the idea of training CartPole with Deep Q-learning agent, we are\nable to find a promising result that prevent the pole from falling down. The\ncapacity of reinforcement learning (RL) to learn from the interaction between\nthe environment and agent provides an optimal control strategy. In this paper,\nwe aim to solve the classic pendulum swing-up problem that making the learned\npendulum to be in upright position and balanced. Deep Deterministic Policy\nGradient algorithm is introduced to operate over continuous action domain in\nthis problem. Salient results of optimal pendulum are proved with increasing\naverage return, decreasing loss, and live video in the code part.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 14:35:48 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bi", "Yifei", ""], ["Chen", "Xinyi", ""], ["Xiao", "Caihui", ""]]}, {"id": "2106.09564", "submitter": "Pietro Gori", "authors": "Minhao Hu, Matthis Maillard, Ya Zhang, Tommaso Ciceri, Giammarco La\n  Barbera, Isabelle Bloch, Pietro Gori", "title": "Knowledge distillation from multi-modal to mono-modal segmentation\n  networks", "comments": "MICCAI 2020", "journal-ref": "MICCAI 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint use of multiple imaging modalities for medical image segmentation\nhas been widely studied in recent years. The fusion of information from\ndifferent modalities has demonstrated to improve the segmentation accuracy,\nwith respect to mono-modal segmentations, in several applications. However,\nacquiring multiple modalities is usually not possible in a clinical setting due\nto a limited number of physicians and scanners, and to limit costs and scan\ntime. Most of the time, only one modality is acquired. In this paper, we\npropose KD-Net, a framework to transfer knowledge from a trained multi-modal\nnetwork (teacher) to a mono-modal one (student). The proposed method is an\nadaptation of the generalized distillation framework where the student network\nis trained on a subset (1 modality) of the teacher's inputs (n modalities). We\nillustrate the effectiveness of the proposed framework in brain tumor\nsegmentation with the BraTS 2018 dataset. Using different architectures, we\nshow that the student network effectively learns from the teacher and always\noutperforms the baseline mono-modal network in terms of segmentation accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 14:46:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Hu", "Minhao", ""], ["Maillard", "Matthis", ""], ["Zhang", "Ya", ""], ["Ciceri", "Tommaso", ""], ["La Barbera", "Giammarco", ""], ["Bloch", "Isabelle", ""], ["Gori", "Pietro", ""]]}, {"id": "2106.09613", "submitter": "Ondrej Bohdal", "authors": "Ondrej Bohdal, Yongxin Yang, Timothy Hospedales", "title": "Meta-Calibration: Meta-Learning of Model Calibration Using\n  Differentiable Expected Calibration Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration of neural networks is a topical problem that is becoming\nincreasingly important for real-world use of neural networks. The problem is\nespecially noticeable when using modern neural networks, for which there is\nsignificant difference between the model confidence and the confidence it\nshould have. Various strategies have been successfully proposed, yet there is\nmore space for improvements. We propose a novel approach that introduces a\ndifferentiable metric for expected calibration error and successfully uses it\nas an objective for meta-learning, achieving competitive results with\nstate-of-the-art approaches. Our approach presents a new direction of using\nmeta-learning to directly optimize model calibration, which we believe will\ninspire further work in this promising and new direction.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 15:47:50 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Bohdal", "Ondrej", ""], ["Yang", "Yongxin", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2106.09620", "submitter": "Hermanni H\\\"alv\\\"a", "authors": "Hermanni H\\\"alv\\\"a, Sylvain Le Corff, Luc Leh\\'ericy, Jonathan So,\n  Yongjie Zhu, Elisabeth Gassiat, Aapo Hyvarinen", "title": "Disentangling Identifiable Features from Noisy Data with Structured\n  Nonlinear ICA", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new general identifiable framework for principled\ndisentanglement referred to as Structured Nonlinear Independent Component\nAnalysis (SNICA). Our contribution is to extend the identifiability theory of\ndeep generative models for a very broad class of structured models. While\nprevious works have shown identifiability for specific classes of time-series\nmodels, our theorems extend this to more general temporal structures as well as\nto models with more complex structures such as spatial dependencies. In\nparticular, we establish the major result that identifiability for this\nframework holds even in the presence of noise of unknown distribution. The\nSNICA setting therefore subsumes all the existing nonlinear ICA models for\ntime-series and also allows for new much richer identifiable models. Finally,\nas an example of our framework's flexibility, we introduce the first nonlinear\nICA model for time-series that combines the following very useful properties:\nit accounts for both nonstationarity and autocorrelation in a fully\nunsupervised setting; performs dimensionality reduction; models hidden states;\nand enables principled estimation and inference by variational\nmaximum-likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 15:56:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["H\u00e4lv\u00e4", "Hermanni", ""], ["Corff", "Sylvain Le", ""], ["Leh\u00e9ricy", "Luc", ""], ["So", "Jonathan", ""], ["Zhu", "Yongjie", ""], ["Gassiat", "Elisabeth", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "2106.09647", "submitter": "Robert Baldock", "authors": "Robert J. N. Baldock, Hartmut Maennel and Behnam Neyshabur", "title": "Deep Learning Through the Lens of Example Difficulty", "comments": "Main paper: 15 pages, 8 figures. Appendix: 31 pages, 40 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work on understanding deep learning often employs measures that\ncompress all data-dependent information into a few numbers. In this work, we\nadopt a perspective based on the role of individual examples. We introduce a\nmeasure of the computational difficulty of making a prediction for a given\ninput: the (effective) prediction depth. Our extensive investigation reveals\nsurprising yet simple relationships between the prediction depth of a given\ninput and the model's uncertainty, confidence, accuracy and speed of learning\nfor that data point. We further categorize difficult examples into three\ninterpretable groups, demonstrate how these groups are processed differently\ninside deep models and showcase how this understanding allows us to improve\nprediction accuracy. Insights from our study lead to a coherent view of a\nnumber of separately reported phenomena in the literature: early layers\ngeneralize while later layers memorize; early layers converge faster and\nnetworks learn easy data and simple functions first.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 16:48:12 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 16:36:37 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Baldock", "Robert J. N.", ""], ["Maennel", "Hartmut", ""], ["Neyshabur", "Behnam", ""]]}, {"id": "2106.09663", "submitter": "Zhize Li", "authors": "Zhize Li", "title": "A Short Note of PAGE: Optimal Convergence Rates for Nonconvex\n  Optimization", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we first recall the nonconvex problem setting and introduce the\noptimal PAGE algorithm (Li et al., ICML'21). Then we provide a simple and clean\nconvergence analysis of PAGE for achieving optimal convergence rates. Moreover,\nPAGE and its analysis can be easily adopted and generalized to other works. We\nhope that this note provides the insights and is helpful for future works.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:11:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Li", "Zhize", ""]]}, {"id": "2106.09683", "submitter": "Lydia Zakynthinou", "authors": "Peter Gr\\\"unwald, Thomas Steinke, Lydia Zakynthinou", "title": "PAC-Bayes, MAC-Bayes and Conditional Mutual Information: Fast rate\n  bounds that handle general VC classes", "comments": "24 pages, accepted for publication at COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a novel, unified derivation of conditional PAC-Bayesian and mutual\ninformation (MI) generalization bounds. We derive conditional MI bounds as an\ninstance, with special choice of prior, of conditional MAC-Bayesian (Mean\nApproximately Correct) bounds, itself derived from conditional PAC-Bayesian\nbounds, where `conditional' means that one can use priors conditioned on a\njoint training and ghost sample. This allows us to get nontrivial PAC-Bayes and\nMI-style bounds for general VC classes, something recently shown to be\nimpossible with standard PAC-Bayesian/MI bounds. Second, it allows us to get\nfaster rates of order $O \\left(({\\text{KL}}/n)^{\\gamma}\\right)$ for $\\gamma >\n1/2$ if a Bernstein condition holds and for exp-concave losses (with\n$\\gamma=1$), which is impossible with both standard PAC-Bayes generalization\nand MI bounds. Our work extends the recent work by Steinke and Zakynthinou\n[2020] who handle MI with VC but neither PAC-Bayes nor fast rates, the recent\nwork of Hellstr\\\"om and Durisi [2020] who extend the latter to the PAC-Bayes\nsetting via a unifying exponential inequality, and Mhammedi et al. [2019] who\ninitiated fast rate PAC-Bayes generalization error bounds but handle neither MI\nnor general VC classes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:35:29 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Gr\u00fcnwald", "Peter", ""], ["Steinke", "Thomas", ""], ["Zakynthinou", "Lydia", ""]]}, {"id": "2106.09689", "submitter": "Ankit Pensia", "authors": "Ilias Diakonikolas, Daniel M. Kane, Ankit Pensia, Thanasis Pittas,\n  Alistair Stewart", "title": "Statistical Query Lower Bounds for List-Decodable Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of list-decodable linear regression, where an adversary\ncan corrupt a majority of the examples. Specifically, we are given a set $T$ of\nlabeled examples $(x, y) \\in \\mathbb{R}^d \\times \\mathbb{R}$ and a parameter\n$0< \\alpha <1/2$ such that an $\\alpha$-fraction of the points in $T$ are i.i.d.\nsamples from a linear regression model with Gaussian covariates, and the\nremaining $(1-\\alpha)$-fraction of the points are drawn from an arbitrary noise\ndistribution. The goal is to output a small list of hypothesis vectors such\nthat at least one of them is close to the target regression vector. Our main\nresult is a Statistical Query (SQ) lower bound of $d^{\\mathrm{poly}(1/\\alpha)}$\nfor this problem. Our SQ lower bound qualitatively matches the performance of\npreviously developed algorithms, providing evidence that current upper bounds\nfor this task are nearly best possible.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:45:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Pensia", "Ankit", ""], ["Pittas", "Thanasis", ""], ["Stewart", "Alistair", ""]]}, {"id": "2106.09702", "submitter": "Tyler McCormick", "authors": "Shane Lubold and Bolun Liu and Tyler H. McCormick", "title": "Spectral goodness-of-fit tests for complete and partial network data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.SI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Networks describe the, often complex, relationships between individual\nactors. In this work, we address the question of how to determine whether a\nparametric model, such as a stochastic block model or latent space model, fits\na dataset well and will extrapolate to similar data. We use recent results in\nrandom matrix theory to derive a general goodness-of-fit test for dyadic data.\nWe show that our method, when applied to a specific model of interest, provides\nan straightforward, computationally fast way of selecting parameters in a\nnumber of commonly used network models. For example, we show how to select the\ndimension of the latent space in latent space models. Unlike other network\ngoodness-of-fit methods, our general approach does not require simulating from\na candidate parametric model, which can be cumbersome with large graphs, and\neliminates the need to choose a particular set of statistics on the graph for\ncomparison. It also allows us to perform goodness-of-fit tests on partial\nnetwork data, such as Aggregated Relational Data. We show with simulations that\nour method performs well in many situations of interest. We analyze several\nempirically relevant networks and show that our method leads to improved\ncommunity detection algorithms. R code to implement our method is available on\nGithub.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:56:30 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lubold", "Shane", ""], ["Liu", "Bolun", ""], ["McCormick", "Tyler H.", ""]]}, {"id": "2106.09756", "submitter": "Haiping Lu", "authors": "Haiping Lu, Xianyuan Liu, Robert Turner, Peizhen Bai, Raivo E Koot,\n  Shuo Zhou, Mustafa Chasmai, Lawrence Schobs", "title": "PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python", "comments": "This library is available at https://github.com/pykale/pykale", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a general-purpose technology holding promises for many\ninterdisciplinary research problems. However, significant barriers exist in\ncrossing disciplinary boundaries when most machine learning tools are developed\nin different areas separately. We present Pykale - a Python library for\nknowledge-aware machine learning on graphs, images, texts, and videos to enable\nand accelerate interdisciplinary research. We formulate new green machine\nlearning guidelines based on standard software engineering practices and\npropose a novel pipeline-based application programming interface (API). PyKale\nfocuses on leveraging knowledge from multiple sources for accurate and\ninterpretable prediction, thus supporting multimodal learning and transfer\nlearning (particularly domain adaptation) with latest deep learning and\ndimensionality reduction models. We build PyKale on PyTorch and leverage the\nrich PyTorch ecosystem. Our pipeline-based API design enforces standardization\nand minimalism, embracing green machine learning concepts via reducing\nrepetitions and redundancy, reusing existing resources, and recycling learning\nmodels across areas. We demonstrate its interdisciplinary nature via examples\nin bioinformatics, knowledge graph, image/video recognition, and medical\nimaging.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:35:37 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Lu", "Haiping", ""], ["Liu", "Xianyuan", ""], ["Turner", "Robert", ""], ["Bai", "Peizhen", ""], ["Koot", "Raivo E", ""], ["Zhou", "Shuo", ""], ["Chasmai", "Mustafa", ""], ["Schobs", "Lawrence", ""]]}, {"id": "2106.09762", "submitter": "Gianluca Detommaso", "authors": "Gianluca Detommaso, Michael Br\\\"uckner, Philip Schulz, Victor\n  Chernozhukov", "title": "Causal Bias Quantification for Continuous Treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we develop a novel characterization of marginal causal effect\nand causal bias in the continuous treatment setting. We show they can be\nexpressed as an expectation with respect to a conditional probability\ndistribution, which can be estimated via standard statistical and probabilistic\nmethods. All terms in the expectations can be computed via automatic\ndifferentiation, also for highly non-linear models. We further develop a new\ncomplete criterion for identifiability of causal effects via covariate\nadjustment, showing the bias equals zero if the criterion is met. We study the\neffectiveness of our framework in three different scenarios: linear models\nunder confounding, overcontrol and endogenous selection bias; a non-linear\nmodel where full identifiability cannot be achieved because of missing data; a\nsimulated medical study of statins and atherosclerotic cardiovascular disease.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:44:48 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Detommaso", "Gianluca", ""], ["Br\u00fcckner", "Michael", ""], ["Schulz", "Philip", ""], ["Chernozhukov", "Victor", ""]]}, {"id": "2106.09777", "submitter": "Kia Khezeli", "authors": "Kia Khezeli, Arno Blaas, Frank Soboczenski, Nicholas Chia, John\n  Kalantari", "title": "On Invariance Penalties for Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Invariant Risk Minimization (IRM) principle was first proposed by\nArjovsky et al. [2019] to address the domain generalization problem by\nleveraging data heterogeneity from differing experimental conditions.\nSpecifically, IRM seeks to find a data representation under which an optimal\nclassifier remains invariant across all domains. Despite the conceptual appeal\nof IRM, the effectiveness of the originally proposed invariance penalty has\nrecently been brought into question. In particular, there exists\ncounterexamples for which that invariance penalty can be arbitrarily small for\nnon-invariant data representations. We propose an alternative invariance\npenalty by revisiting the Gramian matrix of the data representation. We discuss\nthe role of its eigenvalues in the relationship between the risk and the\ninvariance penalty, and demonstrate that it is ill-conditioned for said\ncounterexamples. The proposed approach is guaranteed to recover an invariant\nrepresentation for linear settings under mild non-degeneracy conditions. Its\neffectiveness is substantiated by experiments on DomainBed and\nInvarianceUnitTest, two extensive test beds for domain generalization.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 19:40:31 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Khezeli", "Kia", ""], ["Blaas", "Arno", ""], ["Soboczenski", "Frank", ""], ["Chia", "Nicholas", ""], ["Kalantari", "John", ""]]}, {"id": "2106.09779", "submitter": "Andrew Lowy", "authors": "Andrew Lowy and Meisam Razaviyayn", "title": "Locally Differentially Private Federated Learning: Efficient Algorithms\n  with Tight Risk Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is a distributed learning paradigm in which many\nclients with heterogeneous, unbalanced, and often sensitive local data,\ncollaborate to learn a model. Local Differential Privacy (LDP) provides a\nstrong guarantee that each client's data cannot be leaked during and after\ntraining, without relying on a trusted third party. While LDP is often believed\nto be too stringent to allow for satisfactory utility, our paper challenges\nthis belief. We consider a general setup with unbalanced, heterogeneous data,\ndisparate privacy needs across clients, and unreliable communication, where a\nrandom number/subset of clients is available each round. We propose three LDP\nalgorithms for smooth (strongly) convex FL; each are noisy variations of\ndistributed minibatch SGD. One is accelerated and one involves novel\ntime-varying noise, which we use to obtain the first non-trivial LDP excess\nrisk bound for the fully general non-i.i.d. FL problem. Specializing to i.i.d.\nclients, our risk bounds interpolate between the best known and/or optimal\nbounds in the centralized setting and the cross-device setting, where each\nclient represents just one person's data. Furthermore, we show that in certain\nregimes, our convergence rate (nearly) matches the corresponding non-private\nlower bound or outperforms state of the art non-private algorithms (``privacy\nfor free''). Finally, we validate our theoretical results and illustrate the\npractical utility of our algorithm with numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 19:41:23 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Lowy", "Andrew", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "2106.09798", "submitter": "Eugenio Clerico", "authors": "Eugenio Clerico, George Deligiannidis, Arnaud Doucet", "title": "Wide stochastic networks: Gaussian limit and PAC-Bayesian training", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The limit of infinite width allows for substantial simplifications in the\nanalytical study of overparameterized neural networks. With a suitable random\ninitialization, an extremely large network is well approximated by a Gaussian\nprocess, both before and during training. In the present work, we establish a\nsimilar result for a simple stochastic architecture whose parameters are random\nvariables. The explicit evaluation of the output distribution allows for a\nPAC-Bayesian training procedure that directly optimizes the generalization\nbound. For a large but finite-width network, we show empirically on MNIST that\nthis training approach can outperform standard PAC-Bayesian methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 20:25:38 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Clerico", "Eugenio", ""], ["Deligiannidis", "George", ""], ["Doucet", "Arnaud", ""]]}, {"id": "2106.09815", "submitter": "Mateo Diaz", "authors": "Damek Davis and Mateo D\\'iaz and Dmitriy Drusvyatskiy", "title": "Escaping strict saddle points of the Moreau envelope in nonsmooth\n  optimization", "comments": "29 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that stochastically perturbed gradient methods can\nefficiently escape strict saddle points of smooth functions. We extend this\nbody of work to nonsmooth optimization, by analyzing an inexact analogue of a\nstochastically perturbed gradient method applied to the Moreau envelope. The\nmain conclusion is that a variety of algorithms for nonsmooth optimization can\nescape strict saddle points of the Moreau envelope at a controlled rate. The\nmain technical insight is that typical algorithms applied to the proximal\nsubproblem yield directions that approximate the gradient of the Moreau\nenvelope in relative terms.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 20:58:28 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Davis", "Damek", ""], ["D\u00edaz", "Mateo", ""], ["Drusvyatskiy", "Dmitriy", ""]]}, {"id": "2106.09848", "submitter": "Sangdon Park", "authors": "Sangdon Park and Edgar Dobriban and Insup Lee and Osbert Bastani", "title": "PAC Prediction Sets Under Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge facing modern machine learning is how to rigorously\nquantify the uncertainty of model predictions. Conveying uncertainty is\nespecially important when there are changes to the underlying data distribution\nthat might invalidate the predictive model. Yet, most existing uncertainty\nquantification algorithms break down in the presence of such shifts. We propose\na novel approach that addresses this challenge by constructing \\emph{probably\napproximately correct (PAC)} prediction sets in the presence of covariate\nshift. Our approach focuses on the setting where there is a covariate shift\nfrom the source distribution (where we have labeled training examples) to the\ntarget distribution (for which we want to quantify uncertainty). Our algorithm\nassumes given importance weights that encode how the probabilities of the\ntraining examples change under the covariate shift. In practice, importance\nweights typically need to be estimated; thus, we extend our algorithm to the\nsetting where we are given confidence intervals for the importance weights\nrather than their true value. We demonstrate the effectiveness of our approach\non various covariate shifts designed based on the DomainNet and ImageNet\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 23:28:42 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Park", "Sangdon", ""], ["Dobriban", "Edgar", ""], ["Lee", "Insup", ""], ["Bastani", "Osbert", ""]]}, {"id": "2106.09884", "submitter": "Shibo Li", "authors": "Shibo Li, Robert M. Kirby, Shandian Zhe", "title": "Batch Multi-Fidelity Bayesian Optimization with Deep Auto-Regressive\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian optimization (BO) is a powerful approach for optimizing black-box,\nexpensive-to-evaluate functions. To enable a flexible trade-off between the\ncost and accuracy, many applications allow the function to be evaluated at\ndifferent fidelities. In order to reduce the optimization cost while maximizing\nthe benefit-cost ratio, in this paper, we propose Batch Multi-fidelity Bayesian\nOptimization with Deep Auto-Regressive Networks (BMBO-DARN). We use a set of\nBayesian neural networks to construct a fully auto-regressive model, which is\nexpressive enough to capture strong yet complex relationships across all the\nfidelities, so as to improve the surrogate learning and optimization\nperformance. Furthermore, to enhance the quality and diversity of queries, we\ndevelop a simple yet efficient batch querying method, without any combinatorial\nsearch over the fidelities. We propose a batch acquisition function based on\nMax-value Entropy Search (MES) principle, which penalizes highly correlated\nqueries and encourages diversity. We use posterior samples and moment matching\nto fulfill efficient computation of the acquisition function and conduct\nalternating optimization over every fidelity-input pair, which guarantees an\nimprovement at each step. We demonstrate the advantage of our approach on four\nreal-world hyperparameter optimization applications.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 02:55:48 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Li", "Shibo", ""], ["Kirby", "Robert M.", ""], ["Zhe", "Shandian", ""]]}, {"id": "2106.09910", "submitter": "Xing Gao", "authors": "Xing Gao, Wenrui Dai, Chenglin Li, Junni Zou, Hongkai Xiong, Pascal\n  Frossard", "title": "Message Passing in Graph Convolution Networks via Adaptive Filter Banks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution networks, like message passing graph convolution networks\n(MPGCNs), have been a powerful tool in representation learning of networked\ndata. However, when data is heterogeneous, most architectures are limited as\nthey employ a single strategy to handle multi-channel graph signals and they\ntypically focus on low-frequency information. In this paper, we present a novel\ngraph convolution operator, termed BankGCN, which keeps benefits of message\npassing models, but extends their capabilities beyond `low-pass' features. It\ndecomposes multi-channel signals on graphs into subspaces and handles\nparticular information in each subspace with an adapted filter. The filters of\nall subspaces have different frequency responses and together form a filter\nbank. Furthermore, each filter in the spectral domain corresponds to a message\npassing scheme, and diverse schemes are implemented via the filter bank.\nImportantly, the filter bank and the signal decomposition are jointly learned\nto adapt to the spectral characteristics of data and to target applications.\nFurthermore, this is implemented almost without extra parameters in comparison\nwith most existing MPGCNs. Experimental results show that the proposed\nconvolution operator permits to achieve excellent performance in graph\nclassification on a collection of benchmark graph datasets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 04:23:34 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Gao", "Xing", ""], ["Dai", "Wenrui", ""], ["Li", "Chenglin", ""], ["Zou", "Junni", ""], ["Xiong", "Hongkai", ""], ["Frossard", "Pascal", ""]]}, {"id": "2106.09913", "submitter": "Yining Chen", "authors": "Yining Chen, Elan Rosenfeld, Mark Sellke, Tengyu Ma, Andrej Risteski", "title": "Iterative Feature Matching: Toward Provable Domain Generalization with\n  Logarithmic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization aims at performing well on unseen test environments\nwith data from a limited number of training environments. Despite a\nproliferation of proposal algorithms for this task, assessing their\nperformance, both theoretically and empirically is still very challenging.\nMoreover, recent approaches such as Invariant Risk Minimization (IRM) require a\nprohibitively large number of training environments - linear in the dimension\nof the spurious feature space $d_s$ - even on simple data models like the one\nproposed by [Rosenfeld et al., 2021]. Under a variant of this model, we show\nthat both ERM and IRM cannot generalize with $o(d_s)$ environments. We then\npresent a new algorithm based on performing iterative feature matching that is\nguaranteed with high probability to yield a predictor that generalizes after\nseeing only $O(\\log{d_s})$ environments.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 04:39:19 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Chen", "Yining", ""], ["Rosenfeld", "Elan", ""], ["Sellke", "Mark", ""], ["Ma", "Tengyu", ""], ["Risteski", "Andrej", ""]]}, {"id": "2106.09943", "submitter": "Dipendra Misra", "authors": "Jordan T. Ash, Surbhi Goel, Akshay Krishnamurthy and Dipendra Misra", "title": "Investigating the Role of Negatives in Contrastive Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise contrastive learning is a popular technique for unsupervised\nrepresentation learning. In this approach, a representation is obtained via\nreduction to supervised learning, where given a notion of semantic similarity,\nthe learner tries to distinguish a similar (positive) example from a collection\nof random (negative) examples. The success of modern contrastive learning\npipelines relies on many parameters such as the choice of data augmentation,\nthe number of negative examples, and the batch size; however, there is limited\nunderstanding as to how these parameters interact and affect downstream\nperformance. We focus on disambiguating the role of one of these parameters:\nthe number of negative examples. Theoretically, we show the existence of a\ncollision-coverage trade-off suggesting that the optimal number of negative\nexamples should scale with the number of underlying concepts in the data.\nEmpirically, we scrutinize the role of the number of negatives in both NLP and\nvision tasks. In the NLP task, we find that the results broadly agree with our\ntheory, while our vision experiments are murkier with performance sometimes\neven being insensitive to the number of negatives. We discuss plausible\nexplanations for this behavior and suggest future directions to better align\ntheory and practice.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 06:44:16 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Ash", "Jordan T.", ""], ["Goel", "Surbhi", ""], ["Krishnamurthy", "Akshay", ""], ["Misra", "Dipendra", ""]]}, {"id": "2106.09946", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar, Javad Heydari, Samarth Tripathi, Unmesh Kurup, Mohak\n  Shah", "title": "Evolving GANs: When Contradictions Turn into Compliance", "comments": "Generative Adversarial Networks, Universum Learning, Semi-Supervised\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited availability of labeled-data makes any supervised learning problem\nchallenging. Alternative learning settings like semi-supervised and universum\nlearning alleviate the dependency on labeled data, but still require a large\namount of unlabeled data, which may be unavailable or expensive to acquire.\nGAN-based synthetic data generation methods have recently shown promise by\ngenerating synthetic samples to improve task at hand. However, these samples\ncannot be used for other purposes. In this paper, we propose a GAN game which\nprovides improved discriminator accuracy under limited data settings, while\ngenerating realistic synthetic data. This provides the added advantage that now\nthe generated data can be used for other similar tasks. We provide the\ntheoretical guarantees and empirical results in support of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 06:51:35 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Dhar", "Sauptik", ""], ["Heydari", "Javad", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "2106.09994", "submitter": "Boris Muzellec", "authors": "Boris Muzellec, Francis Bach, Alessandro Rudi", "title": "A Note on Optimizing Distributions using Kernel Mean Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Kernel mean embeddings are a popular tool that consists in representing\nprobability measures by their infinite-dimensional mean embeddings in a\nreproducing kernel Hilbert space. When the kernel is characteristic, mean\nembeddings can be used to define a distance between probability measures, known\nas the maximum mean discrepancy (MMD). A well-known advantage of mean\nembeddings and MMD is their low computational cost and low sample complexity.\nHowever, kernel mean embeddings have had limited applications to problems that\nconsist in optimizing distributions, due to the difficulty of characterizing\nwhich Hilbert space vectors correspond to a probability distribution. In this\nnote, we propose to leverage the kernel sums-of-squares parameterization of\npositive functions of Marteau-Ferey et al. [2020] to fit distributions in the\nMMD geometry. First, we show that when the kernel is characteristic,\ndistributions with a kernel sum-of-squares density are dense. Then, we provide\nalgorithms to optimize such distributions in the finite-sample setting, which\nwe illustrate in a density fitting numerical experiment.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 08:33:45 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 15:36:02 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Muzellec", "Boris", ""], ["Bach", "Francis", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2106.10052", "submitter": "Emile Mathieu", "authors": "Emile Mathieu, Adam Foster, Yee Whye Teh", "title": "On Contrastive Representations of Stochastic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations of stochastic processes is an emerging problem in\nmachine learning with applications from meta-learning to physical object models\nto time series. Typical methods rely on exact reconstruction of observations,\nbut this approach breaks down as observations become high-dimensional or noise\ndistributions become complex. To address this, we propose a unifying framework\nfor learning contrastive representations of stochastic processes (CRESP) that\ndoes away with exact reconstruction. We dissect potential use cases for\nstochastic process representations, and propose methods that accommodate each.\nEmpirically, we show that our methods are effective for learning\nrepresentations of periodic functions, 3D objects and dynamical processes. Our\nmethods tolerate noisy high-dimensional observations better than traditional\napproaches, and the learned representations transfer to a range of downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:00:24 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Mathieu", "Emile", ""], ["Foster", "Adam", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2106.10056", "submitter": "Wensheng Xia", "authors": "Wensheng Xia, Ying Li, Lan Zhang, Zhonghai Wu, Xiaoyong Yuan", "title": "A Vertical Federated Learning Framework for Horizontally Partitioned\n  Labels", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertical federated learning is a collaborative machine learning framework to\ntrain deep leaning models on vertically partitioned data with\nprivacy-preservation. It attracts much attention both from academia and\nindustry. Unfortunately, applying most existing vertical federated learning\nmethods in real-world applications still faces two daunting challenges. First,\nmost existing vertical federated learning methods have a strong assumption that\nat least one party holds the complete set of labels of all data samples, while\nthis assumption is not satisfied in many practical scenarios, where labels are\nhorizontally partitioned and the parties only hold partial labels. Existing\nvertical federated learning methods can only utilize partial labels, which may\nlead to inadequate model update in end-to-end backpropagation. Second,\ncomputational and communication resources vary in parties. Some parties with\nlimited computational and communication resources will become the stragglers\nand slow down the convergence of training. Such straggler problem will be\nexaggerated in the scenarios of horizontally partitioned labels in vertical\nfederated learning. To address these challenges, we propose a novel vertical\nfederated learning framework named Cascade Vertical Federated Learning (CVFL)\nto fully utilize all horizontally partitioned labels to train neural networks\nwith privacy-preservation. To mitigate the straggler problem, we design a novel\noptimization objective which can increase straggler's contribution to the\ntrained models. We conduct a series of qualitative experiments to rigorously\nverify the effectiveness of CVFL. It is demonstrated that CVFL can achieve\ncomparable performance (e.g., accuracy for classification tasks) with\ncentralized training. The new optimization objective can further mitigate the\nstraggler problem comparing with only using the asynchronous aggregation\nmechanism during training.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:10:11 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Xia", "Wensheng", ""], ["Li", "Ying", ""], ["Zhang", "Lan", ""], ["Wu", "Zhonghai", ""], ["Yuan", "Xiaoyong", ""]]}, {"id": "2106.10064", "submitter": "Guillaume Bellec", "authors": "Guillaume Bellec, Shuqi Wang, Alireza Modirshanechi, Johanni Brea,\n  Wulfram Gerstner", "title": "Fitting summary statistics of neural data with a differentiable spiking\n  network simulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fitting network models to neural activity is becoming an important tool in\nneuroscience. A popular approach is to model a brain area with a probabilistic\nrecurrent spiking network whose parameters maximize the likelihood of the\nrecorded activity. Although this is widely used, we show that the resulting\nmodel does not produce realistic neural activity and wrongly estimates the\nconnectivity matrix when neurons that are not recorded have a substantial\nimpact on the recorded network. To correct for this, we suggest to augment the\nlog-likelihood with terms that measure the dissimilarity between simulated and\nrecorded activity. This dissimilarity is defined via summary statistics\ncommonly used in neuroscience, and the optimization is efficient because it\nrelies on back-propagation through the stochastically simulated spike trains.\nWe analyze this method theoretically and show empirically that it generates\nmore realistic activity statistics and recovers the connectivity matrix better\nthan other methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:21:30 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Bellec", "Guillaume", ""], ["Wang", "Shuqi", ""], ["Modirshanechi", "Alireza", ""], ["Brea", "Johanni", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "2106.10065", "submitter": "Agustinus Kristiadi", "authors": "Agustinus Kristiadi and Matthias Hein and Philipp Hennig", "title": "Being a Bit Frequentist Improves Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their compelling theoretical properties, Bayesian neural networks\n(BNNs) tend to perform worse than frequentist methods in classification-based\nuncertainty quantification (UQ) tasks such as out-of-distribution (OOD)\ndetection and dataset-shift robustness. In this work, based on empirical\nfindings in prior works, we hypothesize that this issue is due to the avoidance\nof Bayesian methods in the so-called \"OOD training\" -- a family of techniques\nfor incorporating OOD data during training process, which has since been an\nintegral part of state-of-the-art frequentist UQ methods. To validate this, we\ntreat OOD data as a first-class citizen in BNN training by exploring four\ndifferent ways of incorporating OOD data in Bayesian inference. We show in\nextensive experiments that OOD-trained BNNs are competitive to, if not better\nthan recent frequentist baselines. This work thus provides strong baselines for\nfuture work in both Bayesian and frequentist UQ.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 11:22:42 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Kristiadi", "Agustinus", ""], ["Hein", "Matthias", ""], ["Hennig", "Philipp", ""]]}, {"id": "2106.10086", "submitter": "An-Phi Nguyen", "authors": "An-phi Nguyen, Maria Rodriguez Martinez", "title": "It's FLAN time! Summing feature-wise latent representations for\n  interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability has become a necessary feature for machine learning models\ndeployed in critical scenarios, e.g. legal systems, healthcare. In these\nsituations, algorithmic decisions may have (potentially negative) long-lasting\neffects on the end-user affected by the decision. In many cases, the\nrepresentational power of deep learning models is not needed, therefore simple\nand interpretable models (e.g. linear models) should be preferred. However, in\nhigh-dimensional and/or complex domains (e.g. computer vision), the universal\napproximation capabilities of neural networks is required. Inspired by linear\nmodels and the Kolmogorov-Arnol representation theorem, we propose a novel\nclass of structurally-constrained neural networks, which we call FLANs\n(Feature-wise Latent Additive Networks). Crucially, FLANs process each input\nfeature separately, computing for each of them a representation in a common\nlatent space. These feature-wise latent representations are then simply summed,\nand the aggregated representation is used for prediction. These constraints\n(which are at the core of the interpretability of linear models) allow an user\nto estimate the effect of each individual feature independently from the\nothers, enhancing interpretability. In a set of experiments across different\ndomains, we show how without compromising excessively the test performance, the\nstructural constraints proposed in FLANs indeed increase the interpretability\nof deep learning models.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 12:19:33 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Nguyen", "An-phi", ""], ["Martinez", "Maria Rodriguez", ""]]}, {"id": "2106.10121", "submitter": "Tijin Yan", "authors": "Tijin Yan, Hongwei Zhang, Tong Zhou, Yufeng Zhan, Yuanqing Xia", "title": "ScoreGrad: Multivariate Probabilistic Time Series Forecasting with\n  Continuous Energy-based Generative Models", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series prediction has attracted a lot of attention because\nof its wide applications such as intelligence transportation, AIOps. Generative\nmodels have achieved impressive results in time series modeling because they\ncan model data distribution and take noise into consideration. However, many\nexisting works can not be widely used because of the constraints of functional\nform of generative models or the sensitivity to hyperparameters. In this paper,\nwe propose ScoreGrad, a multivariate probabilistic time series forecasting\nframework based on continuous energy-based generative models. ScoreGrad is\ncomposed of time series feature extraction module and conditional stochastic\ndifferential equation based score matching module. The prediction can be\nachieved by iteratively solving reverse-time SDE. To the best of our knowledge,\nScoreGrad is the first continuous energy based generative model used for time\nseries forecasting. Furthermore, ScoreGrad achieves state-of-the-art results on\nsix real-world datasets. The impact of hyperparameters and sampler types on the\nperformance are also explored. Code is available at\nhttps://github.com/yantijin/ScoreGradPred.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 13:22:12 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Yan", "Tijin", ""], ["Zhang", "Hongwei", ""], ["Zhou", "Tong", ""], ["Zhan", "Yufeng", ""], ["Xia", "Yuanqing", ""]]}, {"id": "2106.10151", "submitter": "Odelia Melamed", "authors": "Adi Shamir, Odelia Melamed, Oriel BenShmuel", "title": "The Dimpled Manifold Model of Adversarial Examples in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extreme fragility of deep neural networks when presented with tiny\nperturbations in their inputs was independently discovered by several research\ngroups in 2013, but in spite of enormous effort these adversarial examples\nremained a baffling phenomenon with no clear explanation. In this paper we\nintroduce a new conceptual framework (which we call the Dimpled Manifold Model)\nwhich provides a simple explanation for why adversarial examples exist, why\ntheir perturbations have such tiny norms, why these perturbations look like\nrandom noise, and why a network which was adversarially trained with\nincorrectly labeled images can still correctly classify test images. In the\nlast part of the paper we describe the results of numerous experiments which\nstrongly support this new model, and in particular our assertion that\nadversarial perturbations are roughly perpendicular to the low dimensional\nmanifold which contains all the training examples.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 14:32:55 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Shamir", "Adi", ""], ["Melamed", "Odelia", ""], ["BenShmuel", "Oriel", ""]]}, {"id": "2106.10165", "submitter": "Sho Yaida", "authors": "Daniel A. Roberts, Sho Yaida, Boris Hanin", "title": "The Principles of Deep Learning Theory", "comments": "451 pages, to be published by Cambridge University Press", "journal-ref": null, "doi": null, "report-no": "MIT-CTP/5306", "categories": "cs.LG cs.AI hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book develops an effective theory approach to understanding deep neural\nnetworks of practical relevance. Beginning from a first-principles\ncomponent-level picture of networks, we explain how to determine an accurate\ndescription of the output of trained networks by solving layer-to-layer\niteration equations and nonlinear learning dynamics. A main result is that the\npredictions of networks are described by nearly-Gaussian distributions, with\nthe depth-to-width aspect ratio of the network controlling the deviations from\nthe infinite-width Gaussian description. We explain how these effectively-deep\nnetworks learn nontrivial representations from training and more broadly\nanalyze the mechanism of representation learning for nonlinear models. From a\nnearly-kernel-methods perspective, we find that the dependence of such models'\npredictions on the underlying learning algorithm can be expressed in a simple\nand universal way. To obtain these results, we develop the notion of\nrepresentation group flow (RG flow) to characterize the propagation of signals\nthrough the network. By tuning networks to criticality, we give a practical\nsolution to the exploding and vanishing gradient problem. We further explain\nhow RG flow leads to near-universal behavior and lets us categorize networks\nbuilt from different activation functions into universality classes.\nAltogether, we show that the depth-to-width ratio governs the effective model\ncomplexity of the ensemble of trained networks. By using information-theoretic\ntechniques, we estimate the optimal aspect ratio at which we expect the network\nto be practically most useful and show how residual connections can be used to\npush this scale to arbitrary depths. With these tools, we can learn in detail\nabout the inductive bias of architectures, hyperparameters, and optimizers.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:00:00 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Roberts", "Daniel A.", ""], ["Yaida", "Sho", ""], ["Hanin", "Boris", ""]]}, {"id": "2106.10166", "submitter": "Pierre Menard", "authors": "James Cheshire, Pierre M\\'enard, Alexandra Carpentier", "title": "Problem Dependent View on Structured Thresholding Bandit Problems", "comments": "25 pages. arXiv admin note: text overlap with arXiv:2006.10006", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the problem dependent regime in the stochastic Thresholding\nBandit problem (TBP) under several shape constraints. In the TBP, the objective\nof the learner is to output, at the end of a sequential game, the set of arms\nwhose means are above a given threshold. The vanilla, unstructured, case is\nalready well studied in the literature. Taking $K$ as the number of arms, we\nconsider the case where (i) the sequence of arm's means $(\\mu_k)_{k=1}^K$ is\nmonotonically increasing (MTBP) and (ii) the case where $(\\mu_k)_{k=1}^K$ is\nconcave (CTBP). We consider both cases in the problem dependent regime and\nstudy the probability of error - i.e. the probability to mis-classify at least\none arm. In the fixed budget setting, we provide upper and lower bounds for the\nprobability of error in both the concave and monotone settings, as well as\nassociated algorithms. In both settings the bounds match in the problem\ndependent regime up to universal constants in the exponential.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:01:01 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Cheshire", "James", ""], ["M\u00e9nard", "Pierre", ""], ["Carpentier", "Alexandra", ""]]}, {"id": "2106.10196", "submitter": "Junyuan Hong", "authors": "Junyuan Hong, Haotao Wang, Zhangyang Wang, Jiayu Zhou", "title": "Federated Robustness Propagation: Sharing Adversarial Robustness in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) emerges as a popular distributed learning schema that\nlearns a model from a set of participating users without requiring raw data to\nbe shared. One major challenge of FL comes from heterogeneity in users, which\nmay have distributionally different (or non-iid) data and varying computation\nresources. Just like in centralized learning, FL users also desire model\nrobustness against malicious attackers at test time. Whereas adversarial\ntraining (AT) provides a sound solution for centralized learning, extending its\nusage for FL users has imposed significant challenges, as many users may have\nvery limited training data as well as tight computational budgets, to afford\nthe data-hungry and costly AT. In this paper, we study a novel learning setting\nthat propagates adversarial robustness from high-resource users that can afford\nAT, to those low-resource users that cannot afford it, during the FL process.\nWe show that existing FL techniques cannot effectively propagate adversarial\nrobustness among non-iid users, and propose a simple yet effective propagation\napproach that transfers robustness through carefully designed\nbatch-normalization statistics. We demonstrate the rationality and\neffectiveness of our method through extensive experiments. Especially, the\nproposed method is shown to grant FL remarkable robustness even when only a\nsmall portion of users afford AT during learning. Codes will be published upon\nacceptance.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:52:33 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Hong", "Junyuan", ""], ["Wang", "Haotao", ""], ["Wang", "Zhangyang", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2106.10210", "submitter": "Will Tebbutt", "authors": "Will Tebbutt and Arno Solin and Richard E. Turner", "title": "Combining Pseudo-Point and State Space Approximations for Sum-Separable\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are important probabilistic tools for inference and\nlearning in spatio-temporal modelling problems such as those in climate science\nand epidemiology. However, existing GP approximations do not simultaneously\nsupport large numbers of off-the-grid spatial data-points and long time-series\nwhich is a hallmark of many applications.\n  Pseudo-point approximations, one of the gold-standard methods for scaling GPs\nto large data sets, are well suited for handling off-the-grid spatial data.\nHowever, they cannot handle long temporal observation horizons effectively\nreverting to cubic computational scaling in the time dimension. State space GP\napproximations are well suited to handling temporal data, if the temporal GP\nprior admits a Markov form, leading to linear complexity in the number of\ntemporal observations, but have a cubic spatial cost and cannot handle\noff-the-grid spatial data.\n  In this work we show that there is a simple and elegant way to combine\npseudo-point methods with the state space GP approximation framework to get the\nbest of both worlds. The approach hinges on a surprising conditional\nindependence property which applies to space--time separable GPs. We\ndemonstrate empirically that the combined approach is more scalable and\napplicable to a greater range of spatio-temporal problems than either method on\nits own.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 16:30:09 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Tebbutt", "Will", ""], ["Solin", "Arno", ""], ["Turner", "Richard E.", ""]]}, {"id": "2106.10212", "submitter": "Hossein Aboutalebi", "authors": "Hossein Aboutalebi, Mohammad Javad Shafiee, Michelle Karg, Christian\n  Scharfenberger, Alexander Wong", "title": "Residual Error: a New Performance Measure for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant advances in deep learning over the past decade, a\nmajor challenge that limits the wide-spread adoption of deep learning has been\ntheir fragility to adversarial attacks. This sensitivity to making erroneous\npredictions in the presence of adversarially perturbed data makes deep neural\nnetworks difficult to adopt for certain real-world, mission-critical\napplications. While much of the research focus has revolved around adversarial\nexample creation and adversarial hardening, the area of performance measures\nfor assessing adversarial robustness is not well explored. Motivated by this,\nthis study presents the concept of residual error, a new performance measure\nfor not only assessing the adversarial robustness of a deep neural network at\nthe individual sample level, but also can be used to differentiate between\nadversarial and non-adversarial examples to facilitate for adversarial example\ndetection. Furthermore, we introduce a hybrid model for approximating the\nresidual error in a tractable manner. Experimental results using the case of\nimage classification demonstrates the effectiveness and efficacy of the\nproposed residual error metric for assessing several well-known deep neural\nnetwork architectures. These results thus illustrate that the proposed measure\ncould be a useful tool for not only assessing the robustness of deep neural\nnetworks used in mission-critical scenarios, but also in the design of\nadversarially robust models.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 16:34:23 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Aboutalebi", "Hossein", ""], ["Shafiee", "Mohammad Javad", ""], ["Karg", "Michelle", ""], ["Scharfenberger", "Christian", ""], ["Wong", "Alexander", ""]]}, {"id": "2106.10236", "submitter": "Anand Deo", "authors": "Anand Deo, Karthyek Murthy", "title": "Efficient Black-Box Importance Sampling for VaR and CVaR Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG math.PR stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers Importance Sampling (IS) for the estimation of tail\nrisks of a loss defined in terms of a sophisticated object such as a machine\nlearning feature map or a mixed integer linear optimisation formulation.\nAssuming only black-box access to the loss and the distribution of the\nunderlying random vector, the paper presents an efficient IS algorithm for\nestimating the Value at Risk and Conditional Value at Risk. The key challenge\nin any IS procedure, namely, identifying an appropriate change-of-measure, is\nautomated with a self-structuring IS transformation that learns and replicates\nthe concentration properties of the conditional excess from less rare samples.\nThe resulting estimators enjoy asymptotically optimal variance reduction when\nviewed in the logarithmic scale. Simulation experiments highlight the efficacy\nand practicality of the proposed scheme\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 01:29:11 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Deo", "Anand", ""], ["Murthy", "Karthyek", ""]]}, {"id": "2106.10238", "submitter": "Fabian Zaiser", "authors": "Carol Mak, Fabian Zaiser, Luke Ong", "title": "Nonparametric Hamiltonian Monte Carlo", "comments": "33 pages, 13 figures. To appear in Proceedings of the 38th\n  International Conference on Machine Learning, PMLR 139, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probabilistic programming uses programs to express generative models whose\nposterior probability is then computed by built-in inference engines. A\nchallenging goal is to develop general purpose inference algorithms that work\nout-of-the-box for arbitrary programs in a universal probabilistic programming\nlanguage (PPL). The densities defined by such programs, which may use\nstochastic branching and recursion, are (in general) nonparametric, in the\nsense that they correspond to models on an infinite-dimensional parameter\nspace. However standard inference algorithms, such as the Hamiltonian Monte\nCarlo (HMC) algorithm, target distributions with a fixed number of parameters.\nThis paper introduces the Nonparametric Hamiltonian Monte Carlo (NP-HMC)\nalgorithm which generalises HMC to nonparametric models. Inputs to NP-HMC are a\nnew class of measurable functions called \"tree representable\", which serve as a\nlanguage-independent representation of the density functions of probabilistic\nprograms in a universal PPL. We provide a correctness proof of NP-HMC, and\nempirically demonstrate significant performance improvements over existing\napproaches on several nonparametric examples.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:03:05 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Mak", "Carol", ""], ["Zaiser", "Fabian", ""], ["Ong", "Luke", ""]]}, {"id": "2106.10241", "submitter": "Mayana Pereira", "authors": "Mayana Pereira, Meghana Kshirsagar, Sumit Mukherjee, Rahul Dodhia,\n  Juan Lavista Ferres", "title": "An Analysis of the Deployment of Models Trained on Private Tabular\n  Synthetic Data: Unexpected Surprises", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diferentially private (DP) synthetic datasets are a powerful approach for\ntraining machine learning models while respecting the privacy of individual\ndata providers. The effect of DP on the fairness of the resulting trained\nmodels is not yet well understood. In this contribution, we systematically\nstudy the effects of differentially private synthetic data generation on\nclassification. We analyze disparities in model utility and bias caused by the\nsynthetic dataset, measured through algorithmic fairness metrics. Our first set\nof results show that although there seems to be a clear negative correlation\nbetween privacy and utility (the more private, the less accurate) across all\ndata synthesizers we evaluated, more privacy does not necessarily imply more\nbias. Additionally, we assess the effects of utilizing synthetic datasets for\nmodel training and model evaluation. We show that results obtained on synthetic\ndata can misestimate the actual model performance when it is deployed on real\ndata. We hence advocate on the need for defining proper testing protocols in\nscenarios where differentially private synthetic datasets are utilized for\nmodel training and evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:00:57 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Pereira", "Mayana", ""], ["Kshirsagar", "Meghana", ""], ["Mukherjee", "Sumit", ""], ["Dodhia", "Rahul", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "2106.10251", "submitter": "Yutian Chen", "authors": "Ksenia Konyushkova, Yutian Chen, Thomas Paine, Caglar Gulcehre, Cosmin\n  Paduraru, Daniel J Mankowitz, Misha Denil, Nando de Freitas", "title": "Active Offline Policy Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of policy selection in domains with abundant\nlogged data, but with a very restricted interaction budget. Solving this\nproblem would enable safe evaluation and deployment of offline reinforcement\nlearning policies in industry, robotics, and healthcare domain among others.\nSeveral off-policy evaluation (OPE) techniques have been proposed to assess the\nvalue of policies using only logged data. However, there is still a big gap\nbetween the evaluation by OPE and the full online evaluation in the real\nenvironment. To reduce this gap, we introduce a novel \\emph{active offline\npolicy selection} problem formulation, which combined logged data and limited\nonline interactions to identify the best policy. We rely on the advances in OPE\nto warm start the evaluation. We build upon Bayesian optimization to\niteratively decide which policies to evaluate in order to utilize the limited\nenvironment interactions wisely. Many candidate policies could be proposed,\nthus, we focus on making our approach scalable and introduce a kernel function\nto model similarity between policies. We use several benchmark environments to\nshow that the proposed approach improves upon state-of-the-art OPE estimates\nand fully online policy evaluation with limited budget. Additionally, we show\nthat each component of the proposed method is important, it works well with\nvarious number and quality of OPE estimates and even with a large number of\ncandidate policies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:33:13 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Konyushkova", "Ksenia", ""], ["Chen", "Yutian", ""], ["Paine", "Thomas", ""], ["Gulcehre", "Caglar", ""], ["Paduraru", "Cosmin", ""], ["Mankowitz", "Daniel J", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""]]}, {"id": "2106.10262", "submitter": "Xinjie Lan", "authors": "Xinjie Lan, Kenneth Barner", "title": "A Probabilistic Representation of DNNs: Bridging Mutual Information and\n  Generalization", "comments": "To appear in the ICML 2021 Workshop on Theoretic Foundation,\n  Criticism, and Application Trend of Explainable AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, Mutual Information (MI) has attracted attention in bounding the\ngeneralization error of Deep Neural Networks (DNNs). However, it is intractable\nto accurately estimate the MI in DNNs, thus most previous works have to relax\nthe MI bound, which in turn weakens the information theoretic explanation for\ngeneralization. To address the limitation, this paper introduces a\nprobabilistic representation of DNNs for accurately estimating the MI.\nLeveraging the proposed MI estimator, we validate the information theoretic\nexplanation for generalization, and derive a tighter generalization bound than\nthe state-of-the-art relaxations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:51:48 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Lan", "Xinjie", ""], ["Barner", "Kenneth", ""]]}, {"id": "2106.10268", "submitter": "Paria Rashidinejad", "authors": "Tianjun Zhang, Paria Rashidinejad, Jiantao Jiao, Yuandong Tian, Joseph\n  Gonzalez, Stuart Russell", "title": "MADE: Exploration via Maximizing Deviation from Explored Regions", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online reinforcement learning (RL), efficient exploration remains\nparticularly challenging in high-dimensional environments with sparse rewards.\nIn low-dimensional environments, where tabular parameterization is possible,\ncount-based upper confidence bound (UCB) exploration methods achieve minimax\nnear-optimal rates. However, it remains unclear how to efficiently implement\nUCB in realistic RL tasks that involve non-linear function approximation. To\naddress this, we propose a new exploration approach via \\textit{maximizing} the\ndeviation of the occupancy of the next policy from the explored regions. We add\nthis term as an adaptive regularizer to the standard RL objective to balance\nexploration vs. exploitation. We pair the new objective with a provably\nconvergent algorithm, giving rise to a new intrinsic reward that adjusts\nexisting bonuses. The proposed intrinsic reward is easy to implement and\ncombine with other existing RL algorithms to conduct exploration. As a proof of\nconcept, we evaluate the new intrinsic reward on tabular examples across a\nvariety of model-based and model-free algorithms, showing improvements over\ncount-only exploration strategies. When tested on navigation and locomotion\ntasks from MiniGrid and DeepMind Control Suite benchmarks, our approach\nsignificantly improves sample efficiency over state-of-the-art methods. Our\ncode is available at https://github.com/tianjunz/MADE.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:57:00 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Zhang", "Tianjun", ""], ["Rashidinejad", "Paria", ""], ["Jiao", "Jiantao", ""], ["Tian", "Yuandong", ""], ["Gonzalez", "Joseph", ""], ["Russell", "Stuart", ""]]}, {"id": "2106.10272", "submitter": "Brandon Amos", "authors": "Samuel Cohen, Brandon Amos, Yaron Lipman", "title": "Riemannian Convex Potential Maps", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling distributions on Riemannian manifolds is a crucial component in\nunderstanding non-Euclidean data that arises, e.g., in physics and geology. The\nbudding approaches in this space are limited by representational and\ncomputational tradeoffs. We propose and study a class of flows that uses convex\npotentials from Riemannian optimal transport. These are universal and can model\ndistributions on any compact Riemannian manifold without requiring domain\nknowledge of the manifold to be integrated into the architecture. We\ndemonstrate that these flows can model standard distributions on spheres, and\ntori, on synthetic and geological data. Our source code is freely available\nonline at http://github.com/facebookresearch/rcpm\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 17:59:06 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Cohen", "Samuel", ""], ["Amos", "Brandon", ""], ["Lipman", "Yaron", ""]]}, {"id": "2106.10302", "submitter": "Salva R\\\"uhling Cachay", "authors": "Salva R\\\"uhling Cachay, Benedikt Boecking, Artur Dubrawski", "title": "Dependency Structure Misspecification in Multi-Source Weak Supervision\n  Models", "comments": "Oral presentation at the Workshop on Weakly Supervised Learning at\n  ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data programming (DP) has proven to be an attractive alternative to costly\nhand-labeling of data.\n  In DP, users encode domain knowledge into \\emph{labeling functions} (LF),\nheuristics that label a subset of the data noisily and may have complex\ndependencies. A label model is then fit to the LFs to produce an estimate of\nthe unknown class label.\n  The effects of label model misspecification on test set performance of a\ndownstream classifier are understudied. This presents a serious awareness gap\nto practitioners, in particular since the dependency structure among LFs is\nfrequently ignored in field applications of DP.\n  We analyse modeling errors due to structure over-specification.\n  We derive novel theoretical bounds on the modeling error and empirically show\nthat this error can be substantial, even when modeling a seemingly sensible\nstructure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 18:15:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Cachay", "Salva R\u00fchling", ""], ["Boecking", "Benedikt", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2106.10314", "submitter": "Adam \\'Scibior", "authors": "Adam \\'Scibior, Vaden Masrani, Frank Wood", "title": "Differentiable Particle Filtering without Modifying the Forward Pass", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In recent years particle filters have being used as components in systems\noptimized end-to-end with gradient descent. However, the resampling step in a\nparticle filter is not differentiable, which biases gradients and interferes\nwith optimization. To remedy this problem, several differentiable variants of\nresampling have been proposed, all of which modify the behavior of the particle\nfilter in significant and potentially undesirable ways. In this paper, we show\nhow to obtain unbiased estimators of the gradient of the marginal likelihood by\nonly modifying messages used in backpropagation, leaving the standard forward\npass of a particle filter unchanged. Our method is simple to implement, has a\nlow computational overhead, does not introduce additional hyperparameters, and\nextends to derivatives of higher orders. We call it stop-gradient resampling,\nsince it can easily be implemented with automatic differentiation libraries\nusing the stop-gradient operator instead of explicitly modifying the backward\nmessages.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 18:58:52 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["\u015acibior", "Adam", ""], ["Masrani", "Vaden", ""], ["Wood", "Frank", ""]]}, {"id": "2106.10324", "submitter": "Farzan Farnia", "authors": "Farzan Farnia, Amirali Aghazadeh, James Zou, David Tse", "title": "Group-Structured Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robust training methods against perturbations to the input data have received\ngreat attention in the machine learning literature. A standard approach in this\ndirection is adversarial training which learns a model using\nadversarially-perturbed training samples. However, adversarial training\nperforms suboptimally against perturbations structured across samples such as\nuniversal and group-sparse shifts that are commonly present in biological data\nsuch as gene expression levels of different tissues. In this work, we seek to\nclose this optimality gap and introduce Group-Structured Adversarial Training\n(GSAT) which learns a model robust to perturbations structured across samples.\nWe formulate GSAT as a non-convex concave minimax optimization problem which\nminimizes a group-structured optimal transport cost. Specifically, we focus on\nthe applications of GSAT for group-sparse and rank-constrained perturbations\nmodeled using group and nuclear norm penalties. In order to solve GSAT's\nnon-smooth optimization problem in those cases, we propose a new minimax\noptimization algorithm called GDADMM by combining Gradient Descent Ascent (GDA)\nand Alternating Direction Method of Multipliers (ADMM). We present several\napplications of the GSAT framework to gain robustness against structured\nperturbations for image recognition and computational biology datasets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 19:32:40 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Farnia", "Farzan", ""], ["Aghazadeh", "Amirali", ""], ["Zou", "James", ""], ["Tse", "David", ""]]}, {"id": "2106.10333", "submitter": "Audra McMillan", "authors": "Joerg Drechsler, Ira Globus-Harris, Audra McMillan, Jayshree Sarathy,\n  and Adam Smith", "title": "Non-parametric Differentially Private Confidence Intervals for the\n  Median", "comments": "44 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a restriction on data processing algorithms that\nprovides strong confidentiality guarantees for individual records in the data.\nHowever, research on proper statistical inference, that is, research on\nproperly quantifying the uncertainty of the (noisy) sample estimate regarding\nthe true value in the population, is currently still limited. This paper\nproposes and evaluates several strategies to compute valid differentially\nprivate confidence intervals for the median. Instead of computing a\ndifferentially private point estimate and deriving its uncertainty, we directly\nestimate the interval bounds and discuss why this approach is superior if\nensuring privacy is important. We also illustrate that addressing both sources\nof uncertainty--the error from sampling and the error from protecting the\noutput--simultaneously should be preferred over simpler approaches that\nincorporate the uncertainty in a sequential fashion. We evaluate the\nperformance of the different algorithms under various parameter settings in\nextensive simulation studies and demonstrate how the findings could be applied\nin practical settings using data from the 1940 Decennial Census.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 19:45:37 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 18:05:54 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Drechsler", "Joerg", ""], ["Globus-Harris", "Ira", ""], ["McMillan", "Audra", ""], ["Sarathy", "Jayshree", ""], ["Smith", "Adam", ""]]}, {"id": "2106.10370", "submitter": "Rajat Sen", "authors": "Pranjal Awasthi, Abhimanyu Das, Rajat Sen, Ananda Theertha Suresh", "title": "On the benefits of maximum likelihood estimation for Regression and\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate for a practical Maximum Likelihood Estimation (MLE) approach for\nregression and forecasting, as an alternative to the typical approach of\nEmpirical Risk Minimization (ERM) for a specific target metric. This approach\nis better suited to capture inductive biases such as prior domain knowledge in\ndatasets, and can output post-hoc estimators at inference time that can\noptimize different types of target metrics. We present theoretical results to\ndemonstrate that our approach is always competitive with any estimator for the\ntarget metric under some general conditions, and in many practical settings\n(such as Poisson Regression) can actually be much superior to ERM. We\ndemonstrate empirically that our method instantiated with a well-designed\ngeneral purpose mixture likelihood family can obtain superior performance over\nERM for a variety of tasks across time-series forecasting and regression\ndatasets with different data distributions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 22:10:43 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Das", "Abhimanyu", ""], ["Sen", "Rajat", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2106.10374", "submitter": "Pan Peng", "authors": "Pan Peng, Jiapeng Zhang", "title": "Towards a Query-Optimal and Time-Efficient Algorithm for Clustering with\n  a Faulty Oracle", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in crowdsourced entity resolution in database,\nsigned edge prediction in social networks and correlation clustering, Mazumdar\nand Saha [NIPS 2017] proposed an elegant theoretical model for studying\nclustering with a faulty oracle. In this model, given a set of $n$ items which\nbelong to $k$ unknown groups (or clusters), our goal is to recover the clusters\nby asking pairwise queries to an oracle. This oracle can answer the query that\n``do items $u$ and $v$ belong to the same cluster?''. However, the answer to\neach pairwise query errs with probability $\\varepsilon$, for some\n$\\varepsilon\\in(0,\\frac12)$. Mazumdar and Saha provided two algorithms under\nthis model: one algorithm is query-optimal while time-inefficient (i.e.,\nrunning in quasi-polynomial time), the other is time efficient (i.e., in\npolynomial time) while query-suboptimal. Larsen, Mitzenmacher and Tsourakakis\n[WWW 2020] then gave a new time-efficient algorithm for the special case of $2$\nclusters, which is query-optimal if the bias $\\delta:=1-2\\varepsilon$ of the\nmodel is large. It was left as an open question whether one can obtain a\nquery-optimal, time-efficient algorithm for the general case of $k$ clusters\nand other regimes of $\\delta$.\n  In this paper, we make progress on the above question and provide a\ntime-efficient algorithm with nearly-optimal query complexity (up to a factor\nof $O(\\log^2 n)$) for all constant $k$ and any $\\delta$ in the regime when\ninformation-theoretic recovery is possible. Our algorithm is built on a\nconnection to the stochastic block model.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 22:20:12 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Peng", "Pan", ""], ["Zhang", "Jiapeng", ""]]}, {"id": "2106.10394", "submitter": "Cassidy Laidlaw", "authors": "Cassidy Laidlaw and Stuart Russell", "title": "Learning the Preferences of Uncertain Humans with Inverse Decision\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing observational approaches for learning human preferences, such as\ninverse reinforcement learning, usually make strong assumptions about the\nobservability of the human's environment. However, in reality, people make many\nimportant decisions under uncertainty. To better understand preference learning\nin these cases, we study the setting of inverse decision theory (IDT), a\npreviously proposed framework where a human is observed making non-sequential\nbinary decisions under uncertainty. In IDT, the human's preferences are\nconveyed through their loss function, which expresses a tradeoff between\ndifferent types of mistakes. We give the first statistical analysis of IDT,\nproviding conditions necessary to identify these preferences and characterizing\nthe sample complexity -- the number of decisions that must be observed to learn\nthe tradeoff the human is making to a desired precision. Interestingly, we show\nthat it is actually easier to identify preferences when the decision problem is\nmore uncertain. Furthermore, uncertain decision problems allow us to relax the\nunrealistic assumption that the human is an optimal decision maker but still\nidentify their exact preferences; we give sample complexities in this\nsuboptimal case as well. Our analysis contradicts the intuition that partial\nobservability should make preference learning more difficult. It also provides\na first step towards understanding and improving preference learning methods\nfor uncertain and suboptimal humans.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 00:11:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Laidlaw", "Cassidy", ""], ["Russell", "Stuart", ""]]}, {"id": "2106.10414", "submitter": "Junwen Yao", "authors": "Junwen Yao, Jonas Mueller, Jane-Ling Wang", "title": "Deep Learning for Functional Data Analysis with Adaptive Basis Layers", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their widespread success, the application of deep neural networks to\nfunctional data remains scarce today. The infinite dimensionality of functional\ndata means standard learning algorithms can be applied only after appropriate\ndimension reduction, typically achieved via basis expansions. Currently, these\nbases are chosen a priori without the information for the task at hand and thus\nmay not be effective for the designated task. We instead propose to adaptively\nlearn these bases in an end-to-end fashion. We introduce neural networks that\nemploy a new Basis Layer whose hidden units are each basis functions themselves\nimplemented as a micro neural network. Our architecture learns to apply\nparsimonious dimension reduction to functional inputs that focuses only on\ninformation relevant to the target rather than irrelevant variation in the\ninput function. Across numerous classification/regression tasks with functional\ndata, our method empirically outperforms other types of neural networks, and we\nprove that our approach is statistically consistent with low generalization\nerror. Code is available at: \\url{https://github.com/jwyyy/AdaFNN}.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 04:05:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yao", "Junwen", ""], ["Mueller", "Jonas", ""], ["Wang", "Jane-Ling", ""]]}, {"id": "2106.10417", "submitter": "Chao Tao", "authors": "Pinyan Lu, Chao Tao, Xiaojin Zhang", "title": "Variance-Dependent Best Arm Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of identifying the best arm in a stochastic multi-armed\nbandit game. Given a set of $n$ arms indexed from $1$ to $n$, each arm $i$ is\nassociated with an unknown reward distribution supported on $[0,1]$ with mean\n$\\theta_i$ and variance $\\sigma_i^2$. Assume $\\theta_1 > \\theta_2 \\geq \\cdots\n\\geq\\theta_n$. We propose an adaptive algorithm which explores the gaps and\nvariances of the rewards of the arms and makes future decisions based on the\ngathered information using a novel approach called \\textit{grouped median\nelimination}. The proposed algorithm guarantees to output the best arm with\nprobability $(1-\\delta)$ and uses at most $O \\left(\\sum_{i = 1}^n\n\\left(\\frac{\\sigma_i^2}{\\Delta_i^2} + \\frac{1}{\\Delta_i}\\right)(\\ln \\delta^{-1}\n+ \\ln \\ln \\Delta_i^{-1})\\right)$ samples, where $\\Delta_i$ ($i \\geq 2$) denotes\nthe reward gap between arm $i$ and the best arm and we define $\\Delta_1 =\n\\Delta_2$. This achieves a significant advantage over the variance-independent\nalgorithms in some favorable scenarios and is the first result that removes the\nextra $\\ln n$ factor on the best arm compared with the state-of-the-art. We\nfurther show that $\\Omega \\left( \\sum_{i = 1}^n \\left(\n\\frac{\\sigma_i^2}{\\Delta_i^2} + \\frac{1}{\\Delta_i} \\right) \\ln \\delta^{-1}\n\\right)$ samples are necessary for an algorithm to achieve the same goal,\nthereby illustrating that our algorithm is optimal up to doubly logarithmic\nterms.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 04:13:54 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 15:19:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lu", "Pinyan", ""], ["Tao", "Chao", ""], ["Zhang", "Xiaojin", ""]]}, {"id": "2106.10422", "submitter": "Yicong He", "authors": "Yicong He and George K. Atia", "title": "Robust M-estimation-based Tensor Ring Completion: a Half-quadratic\n  Minimization Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tensor completion is the problem of estimating the missing values of\nhigh-order data from partially observed entries. Among several definitions of\ntensor rank, tensor ring rank affords the flexibility and accuracy needed to\nmodel tensors of different orders, which motivated recent efforts on\ntensor-ring completion. However, data corruption due to prevailing outliers\nposes major challenges to existing algorithms. In this paper, we develop a\nrobust approach to tensor ring completion that uses an M-estimator as its error\nstatistic, which can significantly alleviate the effect of outliers. Leveraging\na half-quadratic (HQ) method, we reformulate the problem as one of weighted\ntensor completion. We present two HQ-based algorithms based on truncated\nsingular value decomposition and matrix factorization along with their\nconvergence and complexity analysis. Extendibility of the proposed approach to\nalternative definitions of tensor rank is also discussed. The experimental\nresults demonstrate the superior performance of the proposed approach over\nstate-of-the-art robust algorithms for tensor completion.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 04:37:50 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["He", "Yicong", ""], ["Atia", "George K.", ""]]}, {"id": "2106.10435", "submitter": "Prashant Khanduri", "authors": "Prashant Khanduri, Pranay Sharma, Haibo Yang, Mingyi Hong, Jia Liu,\n  Ketan Rajawat, and Pramod K. Varshney", "title": "STEM: A Stochastic Two-Sided Momentum Algorithm Achieving Near-Optimal\n  Sample and Communication Complexities for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) refers to the paradigm where multiple worker nodes\n(WNs) build a joint model by using local data. Despite extensive research, for\na generic non-convex FL problem, it is not clear, how to choose the WNs' and\nthe server's update directions, the minibatch sizes, and the local update\nfrequency, so that the WNs use the minimum number of samples and communication\nrounds to achieve the desired solution. This work addresses the above question\nand considers a class of stochastic algorithms where the WNs perform a few\nlocal updates before communication. We show that when both the WN's and the\nserver's directions are chosen based on a stochastic momentum estimator, the\nalgorithm requires $\\tilde{\\mathcal{O}}(\\epsilon^{-3/2})$ samples and\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ communication rounds to compute an\n$\\epsilon$-stationary solution. To the best of our knowledge, this is the first\nFL algorithm that achieves such {\\it near-optimal} sample and communication\ncomplexities simultaneously. Further, we show that there is a trade-off curve\nbetween local update frequencies and local minibatch sizes, on which the above\nsample and communication complexities can be maintained. Finally, we show that\nfor the classical FedAvg (a.k.a. Local SGD, which is a momentum-less special\ncase of the STEM), a similar trade-off curve exists, albeit with worse sample\nand communication complexities. Our insights on this trade-off provides\nguidelines for choosing the four important design elements for FL algorithms,\nthe update frequency, directions, and minibatch sizes to achieve the best\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 06:13:45 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Khanduri", "Prashant", ""], ["Sharma", "Pranay", ""], ["Yang", "Haibo", ""], ["Hong", "Mingyi", ""], ["Liu", "Jia", ""], ["Rajawat", "Ketan", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "2106.10442", "submitter": "Giovanni Di Gennaro", "authors": "Francesco A.N. Palmieri and Krishna R. Pattipati and Giovanni Di\n  Gennaro and Giovanni Fioretti and Francesco Verolla and Amedeo Buonanno", "title": "A Unified View of Algorithms for Path Planning Using Probabilistic\n  Inference on Factor Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even if path planning can be solved using standard techniques from dynamic\nprogramming and control, the problem can also be approached using probabilistic\ninference. The algorithms that emerge using the latter framework bear some\nappealing characteristics that qualify the probabilistic approach as a powerful\nalternative to the more traditional control formulations. The idea of using\nestimation on stochastic models to solve control problems is not new and the\ninference approach considered here falls under the rubric of Active Inference\n(AI) and Control as Inference (CAI). In this work, we look at the specific\nrecursions that arise from various cost functions that, although they may\nappear similar in scope, bear noticeable differences, at least when applied to\ntypical path planning problems. We start by posing the path planning problem on\na probabilistic factor graph, and show how the various algorithms translate\ninto specific message composition rules. We then show how this unified\napproach, presented both in probability space and in log space, provides a very\ngeneral framework that includes the Sum-product, the Max-product, Dynamic\nprogramming and mixed Reward/Entropy criteria-based algorithms. The framework\nalso expands algorithmic design options for smoother or sharper policy\ndistributions, including generalized Sum/Max-product algorithm, a Smooth\nDynamic programming algorithm and modified versions of the Reward/Entropy\nrecursions. We provide a comprehensive table of recursions and a comparison\nthrough simulations, first on a synthetic small grid with a single goal with\nobstacles, and then on a grid extrapolated from a real-world scene with\nmultiple goals and a semantic map.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 07:13:15 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Palmieri", "Francesco A. N.", ""], ["Pattipati", "Krishna R.", ""], ["Di Gennaro", "Giovanni", ""], ["Fioretti", "Giovanni", ""], ["Verolla", "Francesco", ""], ["Buonanno", "Amedeo", ""]]}, {"id": "2106.10471", "submitter": "Zhenyue Qin", "authors": "Zhenyue Qin and Dongwoo Kim and Tom Gedeon", "title": "Neural Network Classifier as Mutual Information Evaluator", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.10688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-entropy loss with softmax output is a standard choice to train neural\nnetwork classifiers. We give a new view of neural network classifiers with\nsoftmax and cross-entropy as mutual information evaluators. We show that when\nthe dataset is balanced, training a neural network with cross-entropy maximises\nthe mutual information between inputs and labels through a variational form of\nmutual information. Thereby, we develop a new form of softmax that also\nconverts a classifier to a mutual information evaluator when the dataset is\nimbalanced. Experimental results show that the new form leads to better\nclassification accuracy, in particular for imbalanced datasets.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 10:55:46 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Qin", "Zhenyue", ""], ["Kim", "Dongwoo", ""], ["Gedeon", "Tom", ""]]}, {"id": "2106.10558", "submitter": "Robert Webber", "authors": "Robert J. Webber, Michael Lindsey", "title": "Rayleigh-Gauss-Newton optimization with enhanced sampling for\n  variational Monte Carlo", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Monte Carlo (VMC) is an approach for computing ground-state\nwavefunctions that has recently become more powerful due to the introduction of\nneural network-based wavefunction parametrizations. However, efficiently\ntraining neural wavefunctions to converge to an energy minimum remains a\ndifficult problem. In this work, we analyze optimization and sampling methods\nused in VMC and introduce alterations to improve their performance. First,\nbased on theoretical convergence analysis in a noiseless setting, we motivate a\nnew optimizer that we call the Rayleigh-Gauss-Newton method, which can improve\nupon gradient descent and natural gradient descent to achieve superlinear\nconvergence with little added computational cost. Second, in order to realize\nthis favorable comparison in the presence of stochastic noise, we analyze the\neffect of sampling error on VMC parameter updates and experimentally\ndemonstrate that it can be reduced by the parallel tempering method. In\nparticular, we demonstrate that RGN can be made robust to energy spikes that\noccur when new regions of configuration space become available to the sampler\nover the course of optimization. Finally, putting theory into practice, we\napply our enhanced optimization and sampling methods to the transverse-field\nIsing and XXZ models on large lattices, yielding ground-state energy estimates\nwith remarkably high accuracy after just 200-500 parameter updates.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 19:05:52 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 13:54:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Webber", "Robert J.", ""], ["Lindsey", "Michael", ""]]}, {"id": "2106.10575", "submitter": "Ondrej Bohdal", "authors": "Ondrej Bohdal, Yongxin Yang, Timothy Hospedales", "title": "EvoGrad: Efficient Gradient-Based Meta-Learning and Hyperparameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learning and hyperparameter optimization have seen\nsignificant progress recently, enabling practical end-to-end training of neural\nnetworks together with many hyperparameters. Nevertheless, existing approaches\nare relatively expensive as they need to compute second-order derivatives and\nstore a longer computational graph. This cost prevents scaling them to larger\nnetwork architectures. We present EvoGrad, a new approach to meta-learning that\ndraws upon evolutionary techniques to more efficiently compute hypergradients.\nEvoGrad estimates hypergradient with respect to hyperparameters without\ncalculating second-order gradients, or storing a longer computational graph,\nleading to significant improvements in efficiency. We evaluate EvoGrad on two\nsubstantial recent meta-learning applications, namely cross-domain few-shot\nlearning with feature-wise transformations and noisy label learning with\nMetaWeightNet. The results show that EvoGrad significantly improves efficiency\nand enables scaling meta-learning to bigger CNN architectures such as from\nResNet18 to ResNet34.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 21:51:39 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Bohdal", "Ondrej", ""], ["Yang", "Yongxin", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2106.10591", "submitter": "Magda Amiridi", "authors": "Magda Amiridi, Nikos Kargas, and Nicholas D. Sidiropoulos", "title": "Low-rank Characteristic Tensor Density Estimation Part II: Compression\n  and Latent Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning generative probabilistic models is a core problem in machine\nlearning, which presents significant challenges due to the curse of\ndimensionality. This paper proposes a joint dimensionality reduction and\nnon-parametric density estimation framework, using a novel estimator that can\nexplicitly capture the underlying distribution of appropriate reduced-dimension\nrepresentations of the input data. The idea is to jointly design a nonlinear\ndimensionality reducing auto-encoder to model the training data in terms of a\nparsimonious set of latent random variables, and learn a canonical low-rank\ntensor model of the joint distribution of the latent variables in the Fourier\ndomain. The proposed latent density model is non-parametric and universal, as\nopposed to the predefined prior that is assumed in variational auto-encoders.\nJoint optimization of the auto-encoder and the latent density estimator is\npursued via a formulation which learns both by minimizing a combination of the\nnegative log-likelihood in the latent domain and the auto-encoder\nreconstruction loss. We demonstrate that the proposed model achieves very\npromising results on toy, tabular, and image datasets on regression tasks,\nsampling, and anomaly detection.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 00:38:56 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Amiridi", "Magda", ""], ["Kargas", "Nikos", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "2106.10656", "submitter": "Hamed Shirzad", "authors": "Hamed Shirzad, Hossein Hajimirsadeghi, Amir H. Abdi, Greg Mori", "title": "TD-GEN: Graph Generation With Tree Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose TD-GEN, a graph generation framework based on tree decomposition,\nand introduce a reduced upper bound on the maximum number of decisions needed\nfor graph generation. The framework includes a permutation invariant tree\ngeneration model which forms the backbone of graph generation. Tree nodes are\nsupernodes, each representing a cluster of nodes in the graph. Graph nodes and\nedges are incrementally generated inside the clusters by traversing the tree\nsupernodes, respecting the structure of the tree decomposition, and following\nnode sharing decisions between the clusters. Finally, we discuss the\nshortcomings of standard evaluation criteria based on statistical properties of\nthe generated graphs as performance measures. We propose to compare the\nperformance of models based on likelihood. Empirical results on a variety of\nstandard graph generation datasets demonstrate the superior performance of our\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 08:57:43 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shirzad", "Hamed", ""], ["Hajimirsadeghi", "Hossein", ""], ["Abdi", "Amir H.", ""], ["Mori", "Greg", ""]]}, {"id": "2106.10669", "submitter": "Jacob John", "authors": "Jacob John", "title": "Outlier Detection and Spatial Analysis Algorithms", "comments": "7 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Outlier detection is a significant area in data mining. It can be either used\nto pre-process the data prior to an analysis or post the processing phase\n(before visualization) depending on the effectiveness of the outlier and its\nimportance. Outlier detection extends to several fields such as detection of\ncredit card fraud, network intrusions, machine failure prediction, potential\nterrorist attacks, and so on. Outliers are those data points with\ncharacteristics considerably different. They deviate from the data set causing\ninconsistencies, noise and anomalies during analysis and result in modification\nof the original points However, a common misconception is that outliers have to\nbe immediately eliminated or replaced from the data set. Such points could be\nconsidered useful if analyzed separately as they could be obtained from a\nseparate mechanism entirely making it important to the research question. This\nstudy surveys the different methods of outlier detection for spatial analysis.\nSpatial data or geospatial data are those that exhibit geographic properties or\nattributes such as position or areas. An example would be weather data such as\nprecipitation, temperature, wind velocity, and so on collected for a defined\nregion.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 10:00:49 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["John", "Jacob", ""]]}, {"id": "2106.10671", "submitter": "Thee Chanyaswad", "authors": "Thee Chanyaswad, J. Morris Chang, S.Y. Kung", "title": "A compressive multi-kernel method for privacy-preserving machine\n  learning", "comments": "Published in 2017 International Joint Conference on Neural Networks\n  (IJCNN). IEEE, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the analytic tools become more powerful, and more data are generated on a\ndaily basis, the issue of data privacy arises. This leads to the study of the\ndesign of privacy-preserving machine learning algorithms. Given two objectives,\nnamely, utility maximization and privacy-loss minimization, this work is based\non two previously non-intersecting regimes -- Compressive Privacy and\nmulti-kernel method. Compressive Privacy is a privacy framework that employs\nutility-preserving lossy-encoding scheme to protect the privacy of the data,\nwhile multi-kernel method is a kernel based machine learning regime that\nexplores the idea of using multiple kernels for building better predictors. The\ncompressive multi-kernel method proposed consists of two stages -- the\ncompression stage and the multi-kernel stage. The compression stage follows the\nCompressive Privacy paradigm to provide the desired privacy protection. Each\nkernel matrix is compressed with a lossy projection matrix derived from the\nDiscriminant Component Analysis (DCA). The multi-kernel stage uses the\nsignal-to-noise ratio (SNR) score of each kernel to non-uniformly combine\nmultiple compressive kernels. The proposed method is evaluated on two\nmobile-sensing datasets -- MHEALTH and HAR -- where activity recognition is\ndefined as utility and person identification is defined as privacy. The results\nshow that the compression regime is successful in privacy preservation as the\nprivacy classification accuracies are almost at the random-guess level in all\nexperiments. On the other hand, the novel SNR-based multi-kernel shows utility\nclassification accuracy improvement upon the state-of-the-art in both datasets.\nThese results indicate a promising direction for research in privacy-preserving\nmachine learning.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 10:27:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chanyaswad", "Thee", ""], ["Chang", "J. Morris", ""], ["Kung", "S. Y.", ""]]}, {"id": "2106.10704", "submitter": "Tiffany Vlaar", "authors": "Benedict Leimkuhler, Tiffany Vlaar, Timoth\\'ee Pouchon and Amos\n  Storkey", "title": "Better Training using Weight-Constrained Stochastic Dynamics", "comments": "ICML 2021 camera-ready. arXiv admin note: substantial text overlap\n  with arXiv:2006.10114", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ constraints to control the parameter space of deep neural networks\nthroughout training. The use of customized, appropriately designed constraints\ncan reduce the vanishing/exploding gradients problem, improve smoothness of\nclassification boundaries, control weight magnitudes and stabilize deep neural\nnetworks, and thus enhance the robustness of training algorithms and the\ngeneralization capabilities of neural networks. We provide a general approach\nto efficiently incorporate constraints into a stochastic gradient Langevin\nframework, allowing enhanced exploration of the loss landscape. We also present\nspecific examples of constrained training methods motivated by orthogonality\npreservation for weight matrices and explicit weight normalizations.\nDiscretization schemes are provided both for the overdamped formulation of\nLangevin dynamics and the underdamped form, in which momenta further improve\nsampling efficiency. These optimization schemes can be used directly, without\nneeding to adapt neural network architecture design choices or to modify the\nobjective with regularization terms, and see performance improvements in\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 14:41:06 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Leimkuhler", "Benedict", ""], ["Vlaar", "Tiffany", ""], ["Pouchon", "Timoth\u00e9e", ""], ["Storkey", "Amos", ""]]}, {"id": "2106.10744", "submitter": "Min Jae Song", "authors": "Min Jae Song, Ilias Zadik, Joan Bruna", "title": "On the Cryptographic Hardness of Learning Single Periodic Neurons", "comments": "54 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a simple reduction which demonstrates the cryptographic hardness of\nlearning a single periodic neuron over isotropic Gaussian distributions in the\npresence of noise. More precisely, our reduction shows that any polynomial-time\nalgorithm (not necessarily gradient-based) for learning such functions under\nsmall noise implies a polynomial-time quantum algorithm for solving worst-case\nlattice problems, whose hardness form the foundation of lattice-based\ncryptography. Our core hard family of functions, which are well-approximated by\none-layer neural networks, take the general form of a univariate periodic\nfunction applied to an affine projection of the data. These functions have\nappeared in previous seminal works which demonstrate their hardness against\ngradient-based (Shamir'18), and Statistical Query (SQ) algorithms (Song et\nal.'17). We show that if (polynomially) small noise is added to the labels, the\nintractability of learning these functions applies to all polynomial-time\nalgorithms under the aforementioned cryptographic assumptions.\n  Moreover, we demonstrate the necessity of noise in the hardness result by\ndesigning a polynomial-time algorithm for learning certain families of such\nfunctions under exponentially small adversarial noise. Our proposed algorithm\nis not a gradient-based or an SQ algorithm, but is rather based on the\ncelebrated Lenstra-Lenstra-Lov\\'asz (LLL) lattice basis reduction algorithm.\nFurthermore, in the absence of noise, this algorithm can be directly applied to\nsolve CLWE detection (Bruna et al.'21) and phase retrieval with an optimal\nsample complexity of $d+1$ samples. In the former case, this improves upon the\nquadratic-in-$d$ sample complexity required in (Bruna et al.'21). In the latter\ncase, this improves upon the state-of-the-art AMP-based algorithm, which\nrequires approximately $1.128d$ samples (Barbier et al.'19).\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 20:03:52 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Song", "Min Jae", ""], ["Zadik", "Ilias", ""], ["Bruna", "Joan", ""]]}, {"id": "2106.10760", "submitter": "Francesco D'Angelo", "authors": "Francesco D'Angelo, Vincent Fortuin, Florian Wenzel", "title": "On Stein Variational Neural Network Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of deep neural networks have achieved great success recently, but\nthey do not offer a proper Bayesian justification. Moreover, while they allow\nfor averaging of predictions over several hypotheses, they do not provide any\nguarantees for their diversity, leading to redundant solutions in function\nspace. In contrast, particle-based inference methods, such as Stein variational\ngradient descent (SVGD), offer a Bayesian framework, but rely on the choice of\na kernel to measure the similarity between ensemble members. In this work, we\nstudy different SVGD methods operating in the weight space, function space, and\nin a hybrid setting. We compare the SVGD approaches to other ensembling-based\nmethods in terms of their theoretical properties and assess their empirical\nperformance on synthetic and real-world tasks. We find that SVGD using\nfunctional and hybrid kernels can overcome the limitations of deep ensembles.\nIt improves on functional diversity and uncertainty estimation and approaches\nthe true Bayesian posterior more closely. Moreover, we show that using\nstochastic SVGD updates, as opposed to the standard deterministic ones, can\nfurther improve the performance.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 21:52:46 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 07:53:17 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["D'Angelo", "Francesco", ""], ["Fortuin", "Vincent", ""], ["Wenzel", "Florian", ""]]}, {"id": "2106.10761", "submitter": "Moshe Shenfeld", "authors": "Moshe Shenfeld and Katrina Ligett", "title": "Generalization in the Face of Adaptivity: A Bayesian Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Repeated use of a data sample via adaptively chosen queries can rapidly lead\nto overfitting, wherein the issued queries yield answers on the sample that\ndiffer wildly from the values of those queries on the underlying data\ndistribution. Differential privacy provides a tool to ensure generalization\ndespite adaptively-chosen queries, but its worst-case nature means that it\ncannot, for example, yield improved results for low-variance queries. In this\npaper, we give a simple new characterization that illuminates the core problem\nof adaptive data analysis. We show explicitly that the harms of adaptivity come\nfrom the covariance between the behavior of future queries and a Bayes\nfactor-based measure of how much information about the data sample was encoded\nin the responses given to past queries. We leverage this intuition to introduce\na new stability notion; we then use it to prove new generalization results for\nthe most basic noise-addition mechanisms (Laplace and Gaussian noise addition),\nwith guarantees that scale with the variance of the queries rather than the\nsquare of their range. Our characterization opens the door to new insights and\nnew algorithms for the fundamental problem of achieving generalization in\nadaptive data analysis.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 22:06:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shenfeld", "Moshe", ""], ["Ligett", "Katrina", ""]]}, {"id": "2106.10771", "submitter": "Tiffany Vlaar", "authors": "Tiffany Vlaar and Benedict Leimkuhler", "title": "Multirate Training of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose multirate training of neural networks: partitioning neural network\nparameters into \"fast\" and \"slow\" parts which are trained simultaneously using\ndifferent learning rates. By choosing appropriate partitionings we can obtain\nlarge computational speed-ups for transfer learning tasks. We show that for\nvarious transfer learning applications in vision and NLP we can fine-tune deep\nneural networks in almost half the time, without reducing the generalization\nperformance of the resulting model. We also discuss other splitting choices for\nthe neural network parameters which are beneficial in enhancing generalization\nperformance in settings where neural networks are trained from scratch.\nFinally, we propose an additional multirate technique which can learn different\nfeatures present in the data by training the full network on different time\nscales simultaneously. The benefits of using this approach are illustrated for\nResNet architectures on image data. Our paper unlocks the potential of using\nmultirate techniques for neural network training and provides many starting\npoints for future work in this area.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 22:44:55 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Vlaar", "Tiffany", ""], ["Leimkuhler", "Benedict", ""]]}, {"id": "2106.10773", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu and Haoyun Wang and Xiuyuan Cheng and Yao Xie", "title": "Neural Spectral Marked Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self- and mutually-exciting point processes are popular models in machine\nlearning and statistics for dependent discrete event data. To date, most\nexisting models assume stationary kernels (including the classical Hawkes\nprocesses) and simple parametric models. Modern applications with complex event\ndata require more general point process models that can incorporate contextual\ninformation of the events, called marks, besides the temporal and location\ninformation. Moreover, such applications often require non-stationary models to\ncapture more complex spatio-temporal dependence. To tackle these challenges, a\nkey question is to devise a versatile influence kernel in the point process\nmodel. In this paper, we introduce a novel and general neural network-based\nnon-stationary influence kernel with high expressiveness for handling complex\ndiscrete events data while providing theoretical performance guarantees. We\ndemonstrate the superior performance of our proposed method compared with the\nstate-of-the-art on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 23:00:37 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zhu", "Shixiang", ""], ["Wang", "Haoyun", ""], ["Cheng", "Xiuyuan", ""], ["Xie", "Yao", ""]]}, {"id": "2106.10800", "submitter": "Yann Dubois", "authors": "Yann Dubois, Benjamin Bloem-Reddy, Karen Ullrich, Chris J. Maddison", "title": "Lossy Compression for Lossless Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most data is automatically collected and only ever \"seen\" by algorithms. Yet,\ndata compressors preserve perceptual fidelity rather than just the information\nneeded by algorithms performing downstream tasks. In this paper, we\ncharacterize the bit-rate required to ensure high performance on all predictive\ntasks that are invariant under a set of transformations, such as data\naugmentations. Based on our theory, we design unsupervised objectives for\ntraining neural compressors. Using these objectives, we train a generic image\ncompressor that achieves substantial rate savings (more than $1000\\times$ on\nImageNet) compared to JPEG on 8 datasets, without decreasing downstream\nclassification performance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 01:31:44 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 14:26:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Dubois", "Yann", ""], ["Bloem-Reddy", "Benjamin", ""], ["Ullrich", "Karen", ""], ["Maddison", "Chris J.", ""]]}, {"id": "2106.10820", "submitter": "N. Benjamin Erichson", "authors": "Alejandro Queiruga, N. Benjamin Erichson, Liam Hodgkinson, Michael W.\n  Mahoney", "title": "Compressing Deep ODE-Nets using Basis Function Expansions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently-introduced class of ordinary differential equation networks\n(ODE-Nets) establishes a fruitful connection between deep learning and\ndynamical systems. In this work, we reconsider formulations of the weights as\ncontinuous-depth functions using linear combinations of basis functions. This\nperspective allows us to compress the weights through a change of basis,\nwithout retraining, while maintaining near state-of-the-art performance. In\nturn, both inference time and the memory footprint are reduced, enabling quick\nand rigorous adaptation between computational environments. Furthermore, our\nframework enables meaningful continuous-in-time batch normalization layers\nusing function projections. The performance of basis function compression is\ndemonstrated by applying continuous-depth models to (a) image classification\ntasks using convolutional units and (b) sentence-tagging tasks using\ntransformer encoder units.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 03:04:51 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Queiruga", "Alejandro", ""], ["Erichson", "N. Benjamin", ""], ["Hodgkinson", "Liam", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2106.10860", "submitter": "Davis Blalock", "authors": "Davis Blalock, John Guttag", "title": "Multiplying Matrices Without Multiplying", "comments": "To appear at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplying matrices is among the most fundamental and compute-intensive\noperations in machine learning. Consequently, there has been significant work\non efficiently approximating matrix multiplies. We introduce a learning-based\nalgorithm for this task that greatly outperforms existing methods. Experiments\nusing hundreds of matrices from diverse domains show that it often runs\n$100\\times$ faster than exact matrix products and $10\\times$ faster than\ncurrent approximate methods. In the common case that one matrix is known ahead\nof time, our method also has the interesting property that it requires zero\nmultiply-adds. These results suggest that a mixture of hashing, averaging, and\nbyte shuffling$-$the core operations of our method$-$could be a more promising\nbuilding block for machine learning than the sparsified, factorized, and/or\nscalar quantized matrix products that have recently been the focus of\nsubstantial research and hardware investment.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 05:08:54 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Blalock", "Davis", ""], ["Guttag", "John", ""]]}, {"id": "2106.10865", "submitter": "Ke Wang", "authors": "Ke Wang, Vidya Muthukumar, Christos Thrampoulidis", "title": "Benign Overfitting in Multiclass Classification: All Roads Lead to\n  Interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The growing literature on \"benign overfitting\" in overparameterized models\nhas been mostly restricted to regression or binary classification settings;\nhowever, most success stories of modern machine learning have been recorded in\nmulticlass settings. Motivated by this discrepancy, we study benign overfitting\nin multiclass linear classification. Specifically, we consider the following\npopular training algorithms on separable data: (i) empirical risk minimization\n(ERM) with cross-entropy loss, which converges to the multiclass support vector\nmachine (SVM) solution; (ii) ERM with least-squares loss, which converges to\nthe min-norm interpolating (MNI) solution; and, (iii) the one-vs-all SVM\nclassifier. First, we provide a simple sufficient condition under which all\nthree algorithms lead to classifiers that interpolate the training data and\nhave equal accuracy. When the data is generated from Gaussian mixtures or a\nmultinomial logistic model, this condition holds under high enough effective\noverparameterization. Second, we derive novel error bounds on the accuracy of\nthe MNI classifier, thereby showing that all three training algorithms lead to\nbenign overfitting under sufficient overparameterization. Ultimately, our\nanalysis shows that good generalization is possible for SVM solutions beyond\nthe realm in which typical margin-based bounds apply.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 05:34:36 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wang", "Ke", ""], ["Muthukumar", "Vidya", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2106.10905", "submitter": "Pashupati Hegde", "authors": "Pashupati Hegde, \\c{C}a\\u{g}atay Y{\\i}ld{\\i}z, Harri L\\\"ahdesm\\\"aki,\n  Samuel Kaski, Markus Heinonen", "title": "Bayesian inference of ODEs with Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent machine learning advances have proposed black-box estimation of\nunknown continuous-time system dynamics directly from data. However, earlier\nworks are based on approximative ODE solutions or point estimates. We propose a\nnovel Bayesian nonparametric model that uses Gaussian processes to infer\nposteriors of unknown ODE systems directly from data. We derive sparse\nvariational inference with decoupled functional sampling to represent vector\nfield posteriors. We also introduce a probabilistic shooting augmentation to\nenable efficient inference from arbitrarily long trajectories. The method\ndemonstrates the benefit of computing vector field posteriors, with predictive\nuncertainty scores outperforming alternative methods on multiple ODE learning\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 08:09:17 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Hegde", "Pashupati", ""], ["Y\u0131ld\u0131z", "\u00c7a\u011fatay", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""], ["Kaski", "Samuel", ""], ["Heinonen", "Markus", ""]]}, {"id": "2106.10934", "submitter": "Benjamin Chamberlain", "authors": "Benjamin Paul Chamberlain, James Rowbottom, Maria Gorinova, Stefan\n  Webb, Emanuele Rossi and Michael M. Bronstein", "title": "GRAND: Graph Neural Diffusion", "comments": "15 pages, 4 figures. Proceedings of the 38th International Conference\n  on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Graph Neural Diffusion (GRAND) that approaches deep learning on\ngraphs as a continuous diffusion process and treats Graph Neural Networks\n(GNNs) as discretisations of an underlying PDE. In our model, the layer\nstructure and topology correspond to the discretisation choices of temporal and\nspatial operators. Our approach allows a principled development of a broad new\nclass of GNNs that are able to address the common plights of graph learning\nmodels such as depth, oversmoothing, and bottlenecks. Key to the success of our\nmodels are stability with respect to perturbations in the data and this is\naddressed for both implicit and explicit discretisation schemes. We develop\nlinear and nonlinear versions of GRAND, which achieve competitive results on\nmany standard graph benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 09:10:57 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chamberlain", "Benjamin Paul", ""], ["Rowbottom", "James", ""], ["Gorinova", "Maria", ""], ["Webb", "Stefan", ""], ["Rossi", "Emanuele", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "2106.10952", "submitter": "Elena Ehrlich", "authors": "Elena Ehrlich, Laurent Callot, Fran\\c{c}ois-Xavier Aubet", "title": "Spliced Binned-Pareto Distribution for Robust Modeling of Heavy-tailed\n  Time Series", "comments": "Accepted at RobustWorkshop@ICLR2021:\n  <https://sites.google.com/connect.hku.hk/robustml-2021/accepted-papers/paper-041>", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work proposes a novel method to robustly and accurately model time\nseries with heavy-tailed noise, in non-stationary scenarios. In many practical\napplication time series have heavy-tailed noise that significantly impacts the\nperformance of classical forecasting models; in particular, accurately modeling\na distribution over extreme events is crucial to performing accurate time\nseries anomaly detection. We propose a Spliced Binned-Pareto distribution which\nis both robust to extreme observations and allows accurate modeling of the full\ndistribution. Our method allows the capture of time dependencies in the higher\norder moments of the distribution such as the tail heaviness. We compare the\nrobustness and the accuracy of the tail estimation of our method to other state\nof the art methods on Twitter mentions count time series.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 09:48:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ehrlich", "Elena", ""], ["Callot", "Laurent", ""], ["Aubet", "Fran\u00e7ois-Xavier", ""]]}, {"id": "2106.11064", "submitter": "Hoil Lee", "authors": "Paul Jung, Hoil Lee, Jiho Lee, and Hongseok Yang", "title": "$\\alpha$-Stable convergence of heavy-tailed infinitely-wide neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider infinitely-wide multi-layer perceptrons (MLPs) which are limits\nof standard deep feed-forward neural networks. We assume that, for each layer,\nthe weights of an MLP are initialized with i.i.d. samples from either a\nlight-tailed (finite variance) or heavy-tailed distribution in the domain of\nattraction of a symmetric $\\alpha$-stable distribution, where $\\alpha\\in(0,2]$\nmay depend on the layer. For the bias terms of the layer, we assume i.i.d.\ninitializations with a symmetric $\\alpha$-stable distribution having the same\n$\\alpha$ parameter of that layer. We then extend a recent result of Favaro,\nFortini, and Peluchetti (2020), to show that the vector of pre-activation\nvalues at all nodes of a given hidden layer converges in the limit, under a\nsuitable scaling, to a vector of i.i.d. random variables with symmetric\n$\\alpha$-stable distributions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 01:36:41 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Jung", "Paul", ""], ["Lee", "Hoil", ""], ["Lee", "Jiho", ""], ["Yang", "Hongseok", ""]]}, {"id": "2106.11068", "submitter": "Guillaume Staerman", "authors": "Guillaume Staerman, Pavlo Mozharovskyi, St\\'ephan Cl\\'emen\\c{c}on", "title": "Affine-Invariant Integrated Rank-Weighted Depth: Definition, Properties\n  and Finite Sample Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Because it determines a center-outward ordering of observations in\n$\\mathbb{R}^d$ with $d\\geq 2$, the concept of statistical depth permits to\ndefine quantiles and ranks for multivariate data and use them for various\nstatistical tasks (\\textit{e.g.} inference, hypothesis testing). Whereas many\ndepth functions have been proposed \\textit{ad-hoc} in the literature since the\nseminal contribution of \\cite{Tukey75}, not all of them possess the properties\ndesirable to emulate the notion of quantile function for univariate probability\ndistributions. In this paper, we propose an extension of the \\textit{integrated\nrank-weighted} statistical depth (IRW depth in abbreviated form) originally\nintroduced in \\cite{IRW}, modified in order to satisfy the property of\n\\textit{affine-invariance}, fulfilling thus all the four key axioms listed in\nthe nomenclature elaborated by \\cite{ZuoS00a}. The variant we propose, referred\nto as the Affine-Invariant IRW depth (AI-IRW in short), involves the\ncovariance/precision matrices of the (supposedly square integrable)\n$d$-dimensional random vector $X$ under study, in order to take into account\nthe directions along which $X$ is most variable to assign a depth value to any\npoint $x\\in \\mathbb{R}^d$. The accuracy of the sampling version of the AI-IRW\ndepth is investigated from a nonasymptotic perspective. Namely, a concentration\nresult for the statistical counterpart of the AI-IRW depth is proved. Beyond\nthe theoretical analysis carried out, applications to anomaly detection are\nconsidered and numerical results are displayed, providing strong empirical\nevidence of the relevance of the depth function we propose here.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 12:53:37 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Staerman", "Guillaume", ""], ["Mozharovskyi", "Pavlo", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""]]}, {"id": "2106.11072", "submitter": "Sever Topan", "authors": "Sever Topan, David Rolnick, Xujie Si", "title": "Techniques for Symbol Grounding with SATNet", "comments": "Code available at https://github.com/SeverTopan/SATNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many experts argue that the future of artificial intelligence is limited by\nthe field's ability to integrate symbolic logical reasoning into deep learning\narchitectures. The recently proposed differentiable MAXSAT solver, SATNet, was\na breakthrough in its capacity to integrate with a traditional neural network\nand solve visual reasoning problems. For instance, it can learn the rules of\nSudoku purely from image examples. Despite its success, SATNet was shown to\nsuccumb to a key challenge in neurosymbolic systems known as the Symbol\nGrounding Problem: the inability to map visual inputs to symbolic variables\nwithout explicit supervision (\"label leakage\"). In this work, we present a\nself-supervised pre-training pipeline that enables SATNet to overcome this\nlimitation, thus broadening the class of problems that SATNet architectures can\nsolve to include datasets where no intermediary labels are available at all. We\ndemonstrate that our method allows SATNet to attain full accuracy even with a\nharder problem setup that prevents any label leakage. We additionally introduce\na proofreading method that further improves the performance of SATNet\narchitectures, beating the state-of-the-art on Visual Sudoku.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 18:42:12 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Topan", "Sever", ""], ["Rolnick", "David", ""], ["Si", "Xujie", ""]]}, {"id": "2106.11086", "submitter": "Luong-Ha Nguyen", "authors": "Luong Ha, Nguyen and James-A. Goulet", "title": "Analytically Tractable Bayesian Deep Q-Learning", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) has gained increasing interest since the\ndemonstration it was able to reach human performance on video game benchmarks\nusing deep Q-learning (DQN). The current consensus for training neural networks\non such complex environments is to rely on gradient-based optimization.\nAlthough alternative Bayesian deep learning methods exist, most of them still\nrely on gradient-based optimization, and they typically do not scale on\nbenchmarks such as the Atari game environment. Moreover none of these\napproaches allow performing the analytical inference for the weights and biases\ndefining the neural network. In this paper, we present how we can adapt the\ntemporal difference Q-learning framework to make it compatible with the\ntractable approximate Gaussian inference (TAGI), which allows learning the\nparameters of a neural network using a closed-form analytical method.\nThroughout the experiments with on- and off-policy reinforcement learning\napproaches, we demonstrate that TAGI can reach a performance comparable to\nbackpropagation-trained networks while using fewer hyperparameters, and without\nrelying on gradient-based optimization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 13:11:52 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ha", "Luong", ""], ["Nguyen", "", ""], ["Goulet", "James-A.", ""]]}, {"id": "2106.11166", "submitter": "Radu P Horaud", "authors": "Avinash Sharma, Radu Horaud and Diana Mateus", "title": "3D Shape Registration Using Spectral Graph Embedding and Probabilistic\n  Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of 3D shape registration and we propose a novel\ntechnique based on spectral graph theory and probabilistic matching. The task\nof 3D shape analysis involves tracking, recognition, registration, etc.\nAnalyzing 3D data in a single framework is still a challenging task considering\nthe large variability of the data gathered with different acquisition devices.\n3D shape registration is one such challenging shape analysis task. The main\ncontribution of this chapter is to extend the spectral graph matching methods\nto very large graphs by combining spectral graph matching with Laplacian\nembedding. Since the embedded representation of a graph is obtained by\ndimensionality reduction we claim that the existing spectral-based methods are\nnot easily applicable. We discuss solutions for the exact and inexact graph\nisomorphism problems and recall the main spectral properties of the\ncombinatorial graph Laplacian; We provide a novel analysis of the commute-time\nembedding that allows us to interpret the latter in terms of the PCA of a\ngraph, and to select the appropriate dimension of the associated embedded\nmetric space; We derive a unit hyper-sphere normalization for the commute-time\nembedding that allows us to register two shapes with different samplings; We\npropose a novel method to find the eigenvalue-eigenvector ordering and the\neigenvector signs using the eigensignature (histogram) which is invariant to\nthe isometric shape deformations and fits well in the spectral graph matching\nframework, and we present a probabilistic shape matching formulation using an\nexpectation maximization point registration algorithm which alternates between\naligning the eigenbases and finding a vertex-to-vertex assignment.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:02:31 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Sharma", "Avinash", ""], ["Horaud", "Radu", ""], ["Mateus", "Diana", ""]]}, {"id": "2106.11211", "submitter": "Maximilian Autenrieth", "authors": "Maximilian Autenrieth, David A. van Dyk, Roberto Trotta, David C.\n  Stenning", "title": "Stratified Learning: a general-purpose statistical method for improved\n  learning under Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.CO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Covariate shift arises when the labelled training (source) data is not\nrepresentative of the unlabelled (target) data due to systematic differences in\nthe covariate distributions. A supervised model trained on the source data\nsubject to covariate shift may suffer from poor generalization on the target\ndata. We propose a novel, statistically principled and theoretically justified\nmethod to improve learning under covariate shift conditions, based on\npropensity score stratification, a well-established methodology in causal\ninference. We show that the effects of covariate shift can be reduced or\naltogether eliminated by conditioning on propensity scores. In practice, this\nis achieved by fitting learners on subgroups (\"strata\") constructed by\npartitioning the data based on the estimated propensity scores, leading to\nbalanced covariates and much-improved target prediction. We demonstrate the\neffectiveness of our general-purpose method on contemporary research questions\nin observational cosmology, and on additional benchmark examples, matching or\noutperforming state-of-the-art importance weighting methods, widely studied in\nthe covariate shift literature. We obtain the best reported AUC (0.958) on the\nupdated \"Supernovae photometric classification challenge\" and improve upon\nexisting conditional density estimation of galaxy redshift from Sloan Data Sky\nSurvey (SDSS) data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 15:53:20 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Autenrieth", "Maximilian", ""], ["van Dyk", "David A.", ""], ["Trotta", "Roberto", ""], ["Stenning", "David C.", ""]]}, {"id": "2106.11220", "submitter": "Yifang Chen", "authors": "Yifang Chen, Simon S. Du, Kevin Jamieson", "title": "Corruption Robust Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct theoretical studies on streaming-based active learning for binary\nclassification under unknown adversarial label corruptions. In this setting,\nevery time before the learner observes a sample, the adversary decides whether\nto corrupt the label or not. First, we show that, in a benign corruption\nsetting (which includes the misspecification setting as a special case), with a\nslight enlargement on the hypothesis elimination threshold, the classical\nRobustCAL framework can (surprisingly) achieve nearly the same label complexity\nguarantee as in the non-corrupted setting. However, this algorithm can fail in\nthe general corruption setting. To resolve this drawback, we propose a new\nalgorithm which is provably correct without any assumptions on the presence of\ncorruptions. Furthermore, this algorithm enjoys the minimax label complexity in\nthe non-corrupted setting (which is achieved by RobustCAL) and only requires\n$\\tilde{\\mathcal{O}}(C_{\\mathrm{total}})$ additional labels in the corrupted\nsetting to achieve $\\mathcal{O}(\\varepsilon + \\frac{C_{\\mathrm{total}}}{n})$,\nwhere $\\varepsilon$ is the target accuracy, $C_{\\mathrm{total}}$ is the total\nnumber of corruptions and $n$ is the total number of unlabeled samples.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 16:06:38 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Yifang", ""], ["Du", "Simon S.", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2106.11234", "submitter": "Elis Ailer", "authors": "Elisabeth Ailer, Christian L. M\\\"uller, Niki Kilbertus", "title": "A causal view on compositional data", "comments": "Code available on https://github.com/EAiler/comp-iv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientific datasets are compositional in nature. Important examples\ninclude species abundances in ecology, rock compositions in geology, topic\ncompositions in large-scale text corpora, and sequencing count data in\nmolecular biology. Here, we provide a causal view on compositional data in an\ninstrumental variable setting where the composition acts as the cause.\nThroughout, we pay particular attention to the interpretation of compositional\ncauses from the viewpoint of interventions and crisply articulate potential\npitfalls for practitioners. Focusing on modern high-dimensional microbiome\nsequencing data as a timely illustrative use case, our analysis first reveals\nthat popular one-dimensional information-theoretic summary statistics, such as\ndiversity and richness, may be insufficient for drawing causal conclusions from\necological data. Instead, we advocate for multivariate alternatives using\nstatistical data transformations and regression techniques that take the\nspecial structure of the compositional sample space into account. In a\ncomparative analysis on synthetic and semi-synthetic data we show the\nadvantages and limitations of our proposal. We posit that our framework may\nprovide a useful starting point for cause-effect estimation in the context of\ncompositional data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 16:29:41 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ailer", "Elisabeth", ""], ["M\u00fcller", "Christian L.", ""], ["Kilbertus", "Niki", ""]]}, {"id": "2106.11299", "submitter": "Andreas Mayr", "authors": "Andreas Mayr, Sebastian Lehner, Arno Mayrhofer, Christoph Kloss, Sepp\n  Hochreiter, Johannes Brandstetter", "title": "Boundary Graph Neural Networks for 3D Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of data has given machine learning huge momentum in natural\nsciences and engineering. However, the modeling of simulated physical processes\nremains difficult. A key problem in doing so is the correct handling of\ngeometric boundaries. While triangularized geometric boundaries are very common\nin engineering applications, they are notoriously difficult to model by machine\nlearning approaches due to their heterogeneity with respect to size and\norientation. In this work, we introduce Boundary Graph Neural Networks (BGNNs),\nwhich dynamically modify graph structures to address boundary conditions.\nBoundary graph structures are constructed via modifying edges, augmenting node\nfeatures, and dynamically inserting virtual nodes. The new BGNNs are tested on\ncomplex 3D granular flow processes of hoppers and rotating drums which are\nstandard parts of industrial machinery. Using precise simulations that are\nobtained by an expensive and complex discrete element method, BGNNs are\nevaluated in terms of computational efficiency as well as prediction accuracy\nof particle flows and mixing entropies. Even if complex boundaries are present,\nBGNNs are able to accurately reproduce 3D granular flows within simulation\nuncertainties over hundreds of thousands of simulation timesteps, and most\nnotably particles completely stay within the geometric objects without using\nhandcrafted conditions or restrictions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 17:56:07 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Mayr", "Andreas", ""], ["Lehner", "Sebastian", ""], ["Mayrhofer", "Arno", ""], ["Kloss", "Christoph", ""], ["Hochreiter", "Sepp", ""], ["Brandstetter", "Johannes", ""]]}, {"id": "2106.11302", "submitter": "Heiko Zimmermann", "authors": "Heiko Zimmermann, Hao Wu, Babak Esmaeili, Jan-Willem van de Meent", "title": "Nested Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop nested variational inference (NVI), a family of methods that learn\nproposals for nested importance samplers by minimizing an forward or reverse KL\ndivergence at each level of nesting. NVI is applicable to many commonly-used\nimportance sampling strategies and provides a mechanism for learning\nintermediate densities, which can serve as heuristics to guide the sampler. Our\nexperiments apply NVI to (a) sample from a multimodal distribution using a\nlearned annealing path (b) learn heuristics that approximate the likelihood of\nfuture observations in a hidden Markov model and (c) to perform amortized\ninference in hierarchical deep generative models. We observe that optimizing\nnested objectives leads to improved sample quality in terms of log average\nweight and effective sample size.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 17:56:59 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zimmermann", "Heiko", ""], ["Wu", "Hao", ""], ["Esmaeili", "Babak", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "2106.11312", "submitter": "Ye Tu", "authors": "Ye Tu, Chun Lo, Yiping Yuan, Shaunak Chatterjee", "title": "Feedback Shaping: A Modeling Approach to Nurture Content Creation", "comments": null, "journal-ref": "KDD 2019: Proceedings of the 25th ACM SIGKDD International\n  Conference on Knowledge Discovery & Data Mining", "doi": "10.1145/3292500.3330764", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms bring together content creators and content consumers\nthrough recommender systems like newsfeed. The focus of such recommender\nsystems has thus far been primarily on modeling the content consumer\npreferences and optimizing for their experience. However, it is equally\ncritical to nurture content creation by prioritizing the creators' interests,\nas quality content forms the seed for sustainable engagement and conversations,\nbringing in new consumers while retaining existing ones. In this work, we\npropose a modeling approach to predict how feedback from content consumers\nincentivizes creators. We then leverage this model to optimize the newsfeed\nexperience for content creators by reshaping the feedback distribution, leading\nto a more active content ecosystem. Practically, we discuss how we balance the\nuser experience for both consumers and creators, and how we carry out online\nA/B tests with strong network effects. We present a deployed use case on the\nLinkedIn newsfeed, where we used this approach to improve content creation\nsignificantly without compromising the consumers' experience.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 22:53:16 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Tu", "Ye", ""], ["Lo", "Chun", ""], ["Yuan", "Yiping", ""], ["Chatterjee", "Shaunak", ""]]}, {"id": "2106.11389", "submitter": "Jean Pauphilet", "authors": "Jean Pauphilet", "title": "Robust and Heterogenous Odds Ratio: Estimating Price Sensitivity for\n  Unbought Items", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Problem definition: Mining for heterogeneous responses to an intervention is\na crucial step for data-driven operations, for instance to personalize\ntreatment or pricing. We investigate how to estimate price sensitivity from\ntransaction-level data. In causal inference terms, we estimate heterogeneous\ntreatment effects when (a) the response to treatment (here, whether a customer\nbuys a product) is binary, and (b) treatment assignments are partially observed\n(here, full information is only available for purchased items).\nMethodology/Results: We propose a recursive partitioning procedure to estimate\nheterogeneous odds ratio, a widely used measure of treatment effect in medicine\nand social sciences. We integrate an adversarial imputation step to allow for\nrobust inference even in presence of partially observed treatment assignments.\nWe validate our methodology on synthetic data and apply it to three case\nstudies from political science, medicine, and revenue management. Managerial\nImplications: Our robust heterogeneous odds ratio estimation method is a simple\nand intuitive tool to quantify heterogeneity in patients or customers and\npersonalize interventions, while lifting a central limitation in many revenue\nmanagement data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 19:50:32 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Pauphilet", "Jean", ""]]}, {"id": "2106.11438", "submitter": "Ajil Jalal", "authors": "Ajil Jalal and Sushrut Karmalkar and Alexandros G. Dimakis and Eric\n  Price", "title": "Instance-Optimal Compressed Sensing via Posterior Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We characterize the measurement complexity of compressed sensing of signals\ndrawn from a known prior distribution, even when the support of the prior is\nthe entire space (rather than, say, sparse vectors). We show for Gaussian\nmeasurements and \\emph{any} prior distribution on the signal, that the\nposterior sampling estimator achieves near-optimal recovery guarantees.\nMoreover, this result is robust to model mismatch, as long as the distribution\nestimate (e.g., from an invertible generative model) is close to the true\ndistribution in Wasserstein distance. We implement the posterior sampling\nestimator for deep generative priors using Langevin dynamics, and empirically\nfind that it produces accurate estimates with more diversity than MAP.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 22:51:56 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Jalal", "Ajil", ""], ["Karmalkar", "Sushrut", ""], ["Dimakis", "Alexandros G.", ""], ["Price", "Eric", ""]]}, {"id": "2106.11577", "submitter": "Xiantao Xiao", "authors": "Liwei Zhang and Yule Zhang and Jia Wu and Xiantao Xiao", "title": "A stochastic linearized proximal method of multipliers for convex\n  stochastic optimization with expectation constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers the problem of minimizing a convex expectation function\nwith a set of inequality convex expectation constraints. We present a\ncomputable stochastic approximation type algorithm, namely the stochastic\nlinearized proximal method of multipliers, to solve this convex stochastic\noptimization problem. This algorithm can be roughly viewed as a hybrid of\nstochastic approximation and the traditional proximal method of multipliers.\nUnder mild conditions, we show that this algorithm exhibits $O(K^{-1/2})$\nexpected convergence rates for both objective reduction and constraint\nviolation if parameters in the algorithm are properly chosen, where $K$ denotes\nthe number of iterations. Moreover, we show that, with high probability, the\nalgorithm has $O(\\log(K)K^{-1/2})$ constraint violation bound and\n$O(\\log^{3/2}(K)K^{-1/2})$ objective bound. Some preliminary numerical results\ndemonstrate the performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 07:24:17 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Zhang", "Liwei", ""], ["Zhang", "Yule", ""], ["Wu", "Jia", ""], ["Xiao", "Xiantao", ""]]}, {"id": "2106.11581", "submitter": "Michael Poli", "authors": "Michael Poli, Stefano Massaroli, Clayton M. Rabideau, Junyoung Park,\n  Atsushi Yamashita, Hajime Asama, Jinkyoo Park", "title": "Continuous-Depth Neural Models for Dynamic Graph Prediction", "comments": "Extended version of the workshop paper \"Graph Neural Ordinary\n  Differential Equations\". arXiv admin note: substantial text overlap with\n  arXiv:1911.07532", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the framework of continuous-depth graph neural networks (GNNs).\nNeural graph differential equations (Neural GDEs) are formalized as the\ncounterpart to GNNs where the input-output relationship is determined by a\ncontinuum of GNN layers, blending discrete topological structures and\ndifferential equations. The proposed framework is shown to be compatible with\nstatic GNN models and is extended to dynamic and stochastic settings through\nhybrid dynamical system theory. Here, Neural GDEs improve performance by\nexploiting the underlying dynamics geometry, further introducing the ability to\naccommodate irregularly sampled data. Results prove the effectiveness of the\nproposed models across applications, such as traffic forecasting or prediction\nin genetic regulatory networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 07:30:35 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Poli", "Michael", ""], ["Massaroli", "Stefano", ""], ["Rabideau", "Clayton M.", ""], ["Park", "Junyoung", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2106.11609", "submitter": "Philippe Wenk", "authors": "Lenart Treven, Philippe Wenk, Florian D\\\"orfler, Andreas Krause", "title": "Distributional Gradient Matching for Learning Uncertain Neural Dynamics\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential equations in general and neural ODEs in particular are an\nessential technique in continuous-time system identification. While many\ndeterministic learning algorithms have been designed based on numerical\nintegration via the adjoint method, many downstream tasks such as active\nlearning, exploration in reinforcement learning, robust control, or filtering\nrequire accurate estimates of predictive uncertainties. In this work, we\npropose a novel approach towards estimating epistemically uncertain neural\nODEs, avoiding the numerical integration bottleneck. Instead of modeling\nuncertainty in the ODE parameters, we directly model uncertainties in the state\nspace. Our algorithm - distributional gradient matching (DGM) - jointly trains\na smoother and a dynamics model and matches their gradients via minimizing a\nWasserstein loss. Our experiments show that, compared to traditional\napproximate inference methods based on numerical integration, our approach is\nfaster to train, faster at predicting previously unseen trajectories, and in\nthe context of neural ODEs, significantly more accurate.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 08:40:51 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Treven", "Lenart", ""], ["Wenk", "Philippe", ""], ["D\u00f6rfler", "Florian", ""], ["Krause", "Andreas", ""]]}, {"id": "2106.11612", "submitter": "Quanquan Gu", "authors": "Jiafan He and Dongruo Zhou and Quanquan Gu", "title": "Uniform-PAC Bounds for Reinforcement Learning with Linear Function\n  Approximation", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning (RL) with linear function approximation.\nExisting algorithms for this problem only have high-probability regret and/or\nProbably Approximately Correct (PAC) sample complexity guarantees, which cannot\nguarantee the convergence to the optimal policy. In this paper, in order to\novercome the limitation of existing algorithms, we propose a new algorithm\ncalled FLUTE, which enjoys uniform-PAC convergence to the optimal policy with\nhigh probability. The uniform-PAC guarantee is the strongest possible guarantee\nfor reinforcement learning in the literature, which can directly imply both PAC\nand high probability regret bounds, making our algorithm superior to all\nexisting algorithms with linear function approximation. At the core of our\nalgorithm is a novel minimax value function estimator and a multi-level\npartition scheme to select the training samples from historical observations.\nBoth of these techniques are new and of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 08:48:56 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["He", "Jiafan", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "2106.11640", "submitter": "\\'Agoston Reguly", "authors": "\\'Agoston Reguly", "title": "Heterogeneous Treatment Effects in Regression Discontinuity Designs", "comments": "36 pages, 8 tables, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper proposes a supervised machine learning algorithm to uncover\ntreatment effect heterogeneity in classical regression discontinuity (RD)\ndesigns. Extending Athey and Imbens (2016), I develop a criterion for building\nan honest ``regression discontinuity tree'', where each leaf of the tree\ncontains the RD estimate of a treatment (assigned by a common cutoff rule)\nconditional on the values of some pre-treatment covariates. It is a priori\nunknown which covariates are relevant for capturing treatment effect\nheterogeneity, and it is the task of the algorithm to discover them, without\ninvalidating inference. I study the performance of the method through Monte\nCarlo simulations and apply it to the data set compiled by Pop-Eleches and\nUrquiola (2013) to uncover various sources of heterogeneity in the impact of\nattending a better secondary school in Romania.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 09:47:28 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Reguly", "\u00c1goston", ""]]}, {"id": "2106.11642", "submitter": "Francesco D'Angelo", "authors": "Francesco D'Angelo, Vincent Fortuin", "title": "Repulsive Deep Ensembles are Bayesian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep ensembles have recently gained popularity in the deep learning community\nfor their conceptual simplicity and efficiency. However, maintaining functional\ndiversity between ensemble members that are independently trained with gradient\ndescent is challenging. This can lead to pathologies when adding more ensemble\nmembers, such as a saturation of the ensemble performance, which converges to\nthe performance of a single model. Moreover, this does not only affect the\nquality of its predictions, but even more so the uncertainty estimates of the\nensemble, and thus its performance on out-of-distribution data. We hypothesize\nthat this limitation can be overcome by discouraging different ensemble members\nfrom collapsing to the same function. To this end, we introduce a kernelized\nrepulsive term in the update rule of the deep ensembles. We show that this\nsimple modification not only enforces and maintains diversity among the members\nbut, even more importantly, transforms the maximum a posteriori inference into\nproper Bayesian inference. Namely, we show that the training dynamics of our\nproposed repulsive ensembles follow a Wasserstein gradient flow of the KL\ndivergence with the true posterior. We study repulsive terms in weight and\nfunction space and empirically compare their performance to standard ensembles\nand Bayesian baselines on synthetic and real-world prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 09:50:28 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 21:42:51 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["D'Angelo", "Francesco", ""], ["Fortuin", "Vincent", ""]]}, {"id": "2106.11692", "submitter": "Yunchang Yang", "authors": "Yunchang Yang, Tianhao Wu, Han Zhong, Evrard Garcelon, Matteo Pirotta,\n  Alessandro Lazaric, Liwei Wang, Simon S. Du", "title": "A Unified Framework for Conservative Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study bandits and reinforcement learning (RL) subject to a conservative\nconstraint where the agent is asked to perform at least as well as a given\nbaseline policy. This setting is particular relevant in real-world domains\nincluding digital marketing, healthcare, production, finance, etc. For\nmulti-armed bandits, linear bandits and tabular RL, specialized algorithms and\ntheoretical analyses were proposed in previous work. In this paper, we present\na unified framework for conservative bandits and RL, in which our core\ntechnique is to calculate the necessary and sufficient budget obtained from\nrunning the baseline policy. For lower bounds, our framework gives a black-box\nreduction that turns a certain lower bound in the nonconservative setting into\na new lower bound in the conservative setting. We strengthen the existing lower\nbound for conservative multi-armed bandits and obtain new lower bounds for\nconservative linear bandits, tabular RL and low-rank MDP. For upper bounds, our\nframework turns a certain nonconservative upper-confidence-bound (UCB)\nalgorithm into a conservative algorithm with a simple analysis. For multi-armed\nbandits, linear bandits and tabular RL, our new upper bounds tighten or match\nexisting ones with significantly simpler analyses. We also obtain a new upper\nbound for conservative low-rank MDP.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 11:52:04 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Yang", "Yunchang", ""], ["Wu", "Tianhao", ""], ["Zhong", "Han", ""], ["Garcelon", "Evrard", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""], ["Wang", "Liwei", ""], ["Du", "Simon S.", ""]]}, {"id": "2106.11712", "submitter": "Armand Jordana", "authors": "Armand Jordana, Justin Carpentier, Ludovic Righetti", "title": "Learning Dynamical Systems from Noisy Sensor Measurements using Multiple\n  Shooting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling dynamical systems plays a crucial role in capturing and\nunderstanding complex physical phenomena. When physical models are not\nsufficiently accurate or hardly describable by analytical formulas, one can use\ngeneric function approximators such as neural networks to capture the system\ndynamics directly from sensor measurements. As for now, current methods to\nlearn the parameters of these neural networks are highly sensitive to the\ninherent instability of most dynamical systems of interest, which in turn\nprevents the study of very long sequences. In this work, we introduce a generic\nand scalable method based on multiple shooting to learn latent representations\nof indirectly observed dynamical systems. We achieve state-of-the-art\nperformances on systems observed directly from raw images. Further, we\ndemonstrate that our method is robust to noisy measurements and can handle\ncomplex dynamical systems, such as chaotic ones.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 12:30:18 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Jordana", "Armand", ""], ["Carpentier", "Justin", ""], ["Righetti", "Ludovic", ""]]}, {"id": "2106.11719", "submitter": "Andreas Kirsch", "authors": "Andreas Kirsch, Tom Rainforth, Yarin Gal", "title": "Active Learning under Pool Set Distribution Shift and Noisy Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Learning is essential for more label-efficient deep learning. Bayesian\nActive Learning has focused on BALD, which reduces model parameter uncertainty.\nHowever, we show that BALD gets stuck on out-of-distribution or junk data that\nis not relevant for the task. We examine a novel *Expected Predictive\nInformation Gain (EPIG)* to deal with distribution shifts of the pool set. EPIG\nreduces the uncertainty of *predictions* on an unlabelled *evaluation set*\nsampled from the test data distribution whose distribution might be different\nto the pool set distribution. Based on this, our new EPIG-BALD acquisition\nfunction for Bayesian Neural Networks selects samples to improve the\nperformance on the test data distribution instead of selecting samples that\nreduce model uncertainty everywhere, including for out-of-distribution regions\nwith low density in the test data distribution. Our method outperforms\nstate-of-the-art Bayesian active learning methods on high-dimensional datasets\nand avoids out-of-distribution junk data in cases where current\nstate-of-the-art methods fail.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 12:39:30 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Kirsch", "Andreas", ""], ["Rainforth", "Tom", ""], ["Gal", "Yarin", ""]]}, {"id": "2106.11721", "submitter": "Hanxuan Yang", "authors": "Hanxuan Yang, Qingchao Kong, Wenji Mao", "title": "A Deep Latent Space Model for Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning is a fundamental problem for modeling\nrelational data and benefits a number of downstream applications. Traditional\nBayesian-based graph models and recent deep learning based GNN either suffer\nfrom impracticability or lack interpretability, thus combined models for\nundirected graphs have been proposed to overcome the weaknesses. As a large\nportion of real-world graphs are directed graphs (of which undirected graphs\nare special cases), in this paper, we propose a Deep Latent Space Model (DLSM)\nfor directed graphs to incorporate the traditional latent variable based\ngenerative model into deep learning frameworks. Our proposed model consists of\na graph convolutional network (GCN) encoder and a stochastic decoder, which are\nlayer-wise connected by a hierarchical variational auto-encoder architecture.\nBy specifically modeling the degree heterogeneity using node random factors,\nour model possesses better interpretability in both community structure and\ndegree heterogeneity. For fast inference, the stochastic gradient variational\nBayes (SGVB) is adopted using a non-iterative recognition model, which is much\nmore scalable than traditional MCMC-based methods. The experiments on\nreal-world datasets show that the proposed model achieves the state-of-the-art\nperformances on both link prediction and community detection tasks while\nlearning interpretable node embeddings. The source code is available at\nhttps://github.com/upperr/DLSM.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 12:41:19 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Yang", "Hanxuan", ""], ["Kong", "Qingchao", ""], ["Mao", "Wenji", ""]]}, {"id": "2106.11732", "submitter": "Eugenia Iofinova", "authors": "Eugenia Iofinova, Nikola Konstantinov, Christoph H. Lampert", "title": "FLEA: Provably Fair Multisource Learning from Unreliable Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness-aware learning aims at constructing classifiers that not only make\naccurate predictions, but do not discriminate against specific groups. It is a\nfast-growing area of machine learning with far-reaching societal impact.\nHowever, existing fair learning methods are vulnerable to accidental or\nmalicious artifacts in the training data, which can cause them to unknowingly\nproduce unfair classifiers. In this work we address the problem of fair\nlearning from unreliable training data in the robust multisource setting, where\nthe available training data comes from multiple sources, a fraction of which\nmight be not representative of the true data distribution. We introduce FLEA, a\nfiltering-based algorithm that allows the learning system to identify and\nsuppress those data sources that would have a negative impact on fairness or\naccuracy if they were used for training. We show the effectiveness of our\napproach by a diverse range of experiments on multiple datasets. Additionally\nwe prove formally that, given enough data, FLEA protects the learner against\nunreliable data as long as the fraction of affected data sources is less than\nhalf.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 13:09:45 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Iofinova", "Eugenia", ""], ["Konstantinov", "Nikola", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2106.11767", "submitter": "Zhiqi Bu", "authors": "Matteo Sordello, Zhiqi Bu, Jinshuo Dong", "title": "Privacy Amplification via Iteration for Shuffled and Online PNSGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the framework of privacy amplification via\niteration, which is originally proposed by Feldman et al. and subsequently\nsimplified by Asoodeh et al. in their analysis via the contraction coefficient.\nThis line of work focuses on the study of the privacy guarantees obtained by\nthe projected noisy stochastic gradient descent (PNSGD) algorithm with hidden\nintermediate updates. A limitation in the existing literature is that only the\nearly stopped PNSGD has been studied, while no result has been proved on the\nmore widely-used PNSGD applied on a shuffled dataset. Moreover, no scheme has\nbeen yet proposed regarding how to decrease the injected noise when new data\nare received in an online fashion. In this work, we first prove a privacy\nguarantee for shuffled PNSGD, which is investigated asymptotically when the\nnoise is fixed for each sample size $n$ but reduced at a predetermined rate\nwhen $n$ increases, in order to achieve the convergence of privacy loss. We\nthen analyze the online setting and provide a faster decaying scheme for the\nmagnitude of the injected noise that also guarantees the convergence of privacy\nloss.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 17:48:06 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Sordello", "Matteo", ""], ["Bu", "Zhiqi", ""], ["Dong", "Jinshuo", ""]]}, {"id": "2106.11779", "submitter": "Ray Jiang", "authors": "Ray Jiang, Tom Zahavy, Zhongwen Xu, Adam White, Matteo Hessel, Charles\n  Blundell, Hado van Hasselt", "title": "Emphatic Algorithms for Deep Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy learning allows us to learn about possible policies of behavior\nfrom experience generated by a different behavior policy. Temporal difference\n(TD) learning algorithms can become unstable when combined with function\napproximation and off-policy sampling - this is known as the ''deadly triad''.\nEmphatic temporal difference (ETD($\\lambda$)) algorithm ensures convergence in\nthe linear case by appropriately weighting the TD($\\lambda$) updates. In this\npaper, we extend the use of emphatic methods to deep reinforcement learning\nagents. We show that naively adapting ETD($\\lambda$) to popular deep\nreinforcement learning algorithms, which use forward view multi-step returns,\nresults in poor performance. We then derive new emphatic algorithms for use in\nthe context of such algorithms, and we demonstrate that they provide noticeable\nbenefits in small problems designed to highlight the instability of TD methods.\nFinally, we observed improved performance when applying these algorithms at\nscale on classic Atari games from the Arcade Learning Environment.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 12:11:39 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Jiang", "Ray", ""], ["Zahavy", "Tom", ""], ["Xu", "Zhongwen", ""], ["White", "Adam", ""], ["Hessel", "Matteo", ""], ["Blundell", "Charles", ""], ["van Hasselt", "Hado", ""]]}, {"id": "2106.11847", "submitter": "\\'Angel Gonz\\'alez-Prieto", "authors": "\\'Angel Gonz\\'alez-Prieto, Antonio Br\\'u, Juan Carlos Nu\\~no, Jos\\'e\n  Luis Gonz\\'alez-\\'Alvarez", "title": "Machine learning for risk assessment in gender-based crime", "comments": "17 pages, 5 figures, 4 tables. This work has been submitted to the\n  IEEE for possible publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gender-based crime is one of the most concerning scourges of contemporary\nsociety. Governments worldwide have invested lots of economic and human\nresources to radically eliminate this threat. Despite these efforts, providing\naccurate predictions of the risk that a victim of gender violence has of being\nattacked again is still a very hard open problem. The development of new\nmethods for issuing accurate, fair and quick predictions would allow police\nforces to select the most appropriate measures to prevent recidivism. In this\nwork, we propose to apply Machine Learning (ML) techniques to create models\nthat accurately predict the recidivism risk of a gender-violence offender. The\nrelevance of the contribution of this work is threefold: (i) the proposed ML\nmethod outperforms the preexisting risk assessment algorithm based on classical\nstatistical techniques, (ii) the study has been conducted through an official\nspecific-purpose database with more than 40,000 reports of gender violence, and\n(iii) two new quality measures are proposed for assessing the effective police\nprotection that a model supplies and the overload in the invested resources\nthat it generates. Additionally, we propose a hybrid model that combines the\nstatistical prediction methods with the ML method, permitting authorities to\nimplement a smooth transition from the preexisting model to the ML-based model.\nThis hybrid nature enables a decision-making process to optimally balance\nbetween the efficiency of the police system and aggressiveness of the\nprotection measures taken.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:05:20 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Gonz\u00e1lez-Prieto", "\u00c1ngel", ""], ["Br\u00fa", "Antonio", ""], ["Nu\u00f1o", "Juan Carlos", ""], ["Gonz\u00e1lez-\u00c1lvarez", "Jos\u00e9 Luis", ""]]}, {"id": "2106.11849", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Nikita Agarwal, Jakob Zeitler, Afsaneh\n  Mastouri, Bernhard Sch\\\"olkopf", "title": "Algorithmic Recourse in Partially and Fully Confounded Settings Through\n  Bounding Counterfactual Effects", "comments": "Preliminary workshop version; work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic recourse aims to provide actionable recommendations to\nindividuals to obtain a more favourable outcome from an automated\ndecision-making system. As it involves reasoning about interventions performed\nin the physical world, recourse is fundamentally a causal problem. Existing\nmethods compute the effect of recourse actions using a causal model learnt from\ndata under the assumption of no hidden confounding and modelling assumptions\nsuch as additive noise. Building on the seminal work of Balke and Pearl (1994),\nwe propose an alternative approach for discrete random variables which relaxes\nthese assumptions and allows for unobserved confounding and arbitrary\nstructural equations. The proposed approach only requires specification of the\ncausal graph and confounding structure and bounds the expected counterfactual\neffect of recourse actions. If the lower bound is above a certain threshold,\ni.e., on the other side of the decision boundary, recourse is guaranteed in\nexpectation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:07:49 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Agarwal", "Nikita", ""], ["Zeitler", "Jakob", ""], ["Mastouri", "Afsaneh", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2106.11853", "submitter": "Julian Lienen", "authors": "Julian Lienen, Eyke H\\\"ullermeier", "title": "Credal Self-Supervised Learning", "comments": "17 pages, 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-training is an effective approach to semi-supervised learning. The key\nidea is to let the learner itself iteratively generate \"pseudo-supervision\" for\nunlabeled instances based on its current hypothesis. In combination with\nconsistency regularization, pseudo-labeling has shown promising performance in\nvarious domains, for example in computer vision. To account for the\nhypothetical nature of the pseudo-labels, these are commonly provided in the\nform of probability distributions. Still, one may argue that even a probability\ndistribution represents an excessive level of informedness, as it suggests that\nthe learner precisely knows the ground-truth conditional probabilities. In our\napproach, we therefore allow the learner to label instances in the form of\ncredal sets, that is, sets of (candidate) probability distributions. Thanks to\nthis increased expressiveness, the learner is able to represent uncertainty and\na lack of knowledge in a more flexible and more faithful manner. To learn from\nweakly labeled data of that kind, we leverage methods that have recently been\nproposed in the realm of so-called superset learning. In an exhaustive\nempirical evaluation, we compare our methodology to state-of-the-art\nself-supervision approaches, showing competitive to superior performance\nespecially in low-label scenarios incorporating a high degree of uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:19:04 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Lienen", "Julian", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2106.11880", "submitter": "Samuel Sharpe", "authors": "Nima Chitsazan, Samuel Sharpe, Dwipam Katariya, Qianyu Cheng, Karthik\n  Rajasethupathy", "title": "Dynamic Customer Embeddings for Financial Service Applications", "comments": "ICML Workshop on Representation Learning for Finance and E-Commerce\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As financial services (FS) companies have experienced drastic technology\ndriven changes, the availability of new data streams provides the opportunity\nfor more comprehensive customer understanding. We propose Dynamic Customer\nEmbeddings (DCE), a framework that leverages customers' digital activity and a\nwide range of financial context to learn dense representations of customers in\nthe FS industry. Our method examines customer actions and pageviews within a\nmobile or web digital session, the sequencing of the sessions themselves, and\nsnapshots of common financial features across our organization at the time of\nlogin. We test our customer embeddings using real world data in three\nprediction problems: 1) the intent of a customer in their next digital session,\n2) the probability of a customer calling the call centers after a session, and\n3) the probability of a digital session to be fraudulent. DCE showed\nperformance lift in all three downstream problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:51:49 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chitsazan", "Nima", ""], ["Sharpe", "Samuel", ""], ["Katariya", "Dwipam", ""], ["Cheng", "Qianyu", ""], ["Rajasethupathy", "Karthik", ""]]}, {"id": "2106.11899", "submitter": "Alexander Von Rohr", "authors": "Sarah M\\\"uller, Alexander von Rohr, Sebastian Trimpe", "title": "Local policy search with Bayesian optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) aims to find an optimal policy by interaction\nwith an environment. Consequently, learning complex behavior requires a vast\nnumber of samples, which can be prohibitive in practice. Nevertheless, instead\nof systematically reasoning and actively choosing informative samples, policy\ngradients for local search are often obtained from random perturbations. These\nrandom samples yield high variance estimates and hence are sub-optimal in terms\nof sample complexity. Actively selecting informative samples is at the core of\nBayesian optimization, which constructs a probabilistic surrogate of the\nobjective from past samples to reason about informative subsequent ones. In\nthis paper, we propose to join both worlds. We develop an algorithm utilizing a\nprobabilistic model of the objective function and its gradient. Based on the\nmodel, the algorithm decides where to query a noisy zeroth-order oracle to\nimprove the gradient estimates. The resulting algorithm is a novel type of\npolicy search method, which we compare to existing black-box algorithms. The\ncomparison reveals improved sample complexity and reduced variance in extensive\nempirical evaluations on synthetic objectives. Further, we highlight the\nbenefits of active sampling on popular RL benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 16:07:02 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["M\u00fcller", "Sarah", ""], ["von Rohr", "Alexander", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2106.11905", "submitter": "Andrew Wilson", "authors": "Pavel Izmailov, Patrick Nicholson, Sanae Lotfi, Andrew Gordon Wilson", "title": "Dangers of Bayesian Model Averaging under Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian inference for neural networks is considered a robust\nalternative to standard training, often providing good performance on\nout-of-distribution data. However, Bayesian neural networks (BNNs) with\nhigh-fidelity approximate inference via full-batch Hamiltonian Monte Carlo\nachieve poor generalization under covariate shift, even underperforming\nclassical estimation. We explain this surprising result, showing how a Bayesian\nmodel average can in fact be problematic under covariate shift, particularly in\ncases where linear dependencies in the input features cause a lack of posterior\ncontraction. We additionally show why the same issue does not affect many\napproximate inference procedures, or classical maximum a-posteriori (MAP)\ntraining. Finally, we propose novel priors that improve the robustness of BNNs\nto many sources of covariate shift.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 16:19:52 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Izmailov", "Pavel", ""], ["Nicholson", "Patrick", ""], ["Lotfi", "Sanae", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2106.11926", "submitter": "Rem-Sophia Mouradi", "authors": "Rem-Sophia Mouradi and C\\'edric Goeury and Olivier Thual and Fabrice\n  Zaoui and Pablo Tassi", "title": "Surrogate-based variational data assimilation for tidal modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data assimilation (DA) is widely used to combine physical knowledge and\nobservations. It is nowadays commonly used in geosciences to perform parametric\ncalibration. In a context of climate change, old calibrations can not\nnecessarily be used for new scenarios. This raises the question of DA\ncomputational cost, as costly physics-based numerical models need to be\nreanalyzed. Reduction and metamodelling represent therefore interesting\nperspectives, for example proposed in recent contributions as hybridization\nbetween ensemble and variational methods, to combine their advantages\n(efficiency, non-linear framework). They are however often based on Monte Carlo\n(MC) type sampling, which often requires considerable increase of the ensemble\nsize for better efficiency, therefore representing a computational burden in\nensemble-based methods as well. To address these issues, two methods to replace\nthe complex model by a surrogate are proposed and confronted : (i) PODEn3DVAR\ndirectly inspired from PODEn4DVAR, relies on an ensemble-based joint\nparameter-state Proper Orthogonal Decomposition (POD), which provides a linear\nmetamodel ; (ii) POD-PCE-3DVAR, where the model states are POD reduced then\nlearned using Polynomial Chaos Expansion (PCE), resulting in a non-linear\nmetamodel. Both metamodels allow to write an approximate cost function whose\nminimum can be analytically computed, or deduced by a gradient descent at\nnegligible cost. Furthermore, adapted metamodelling error covariance matrix is\ngiven for POD-PCE-3DVAR, allowing to substantially improve the metamodel-based\nDA analysis. Proposed methods are confronted on a twin experiment, and compared\nto classical 3DVAR on a measurement-based problem. Results are promising, in\nparticular superior with POD-PCE-3DVAR, showing good convergence to classical\n3DVAR and robustness to noise.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 07:39:38 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Mouradi", "Rem-Sophia", ""], ["Goeury", "C\u00e9dric", ""], ["Thual", "Olivier", ""], ["Zaoui", "Fabrice", ""], ["Tassi", "Pablo", ""]]}, {"id": "2106.11935", "submitter": "Quanquan Gu", "authors": "Weitong Zhang and Jiafan He and Dongruo Zhou and Amy Zhang and\n  Quanquan Gu", "title": "Provably Efficient Representation Learning in Low-rank Markov Decision\n  Processes", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep reinforcement learning (DRL) is due to the power of\nlearning a representation that is suitable for the underlying exploration and\nexploitation task. However, existing provable reinforcement learning algorithms\nwith linear function approximation often assume the feature representation is\nknown and fixed. In order to understand how representation learning can improve\nthe efficiency of RL, we study representation learning for a class of low-rank\nMarkov Decision Processes (MDPs) where the transition kernel can be represented\nin a bilinear form. We propose a provably efficient algorithm called ReLEX that\ncan simultaneously learn the representation and perform exploration. We show\nthat ReLEX always performs no worse than a state-of-the-art algorithm without\nrepresentation learning, and will be strictly better in terms of sample\nefficiency if the function class of representations enjoys a certain mild\n\"coverage'' property over the whole state-action space.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:16:50 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Zhang", "Weitong", ""], ["He", "Jiafan", ""], ["Zhou", "Dongruo", ""], ["Zhang", "Amy", ""], ["Gu", "Quanquan", ""]]}, {"id": "2106.11936", "submitter": "Georges Tod", "authors": "Georges Tod and Gert-Jan Both and Remy Kusters", "title": "Sparsistent Model Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discovering the partial differential equations underlying a spatio-temporal\ndatasets from very limited observations is of paramount interest in many\nscientific fields. However, it remains an open question to know when model\ndiscovery algorithms based on sparse regression can actually recover the\nunderlying physical processes. We trace back the poor of performance of Lasso\nbased model discovery algorithms to its potential variable selection\ninconsistency: meaning that even if the true model is present in the library,\nit might not be selected. By first revisiting the irrepresentability condition\n(IRC) of the Lasso, we gain some insights of when this might occur. We then\nshow that the adaptive Lasso will have more chances of verifying the IRC than\nthe Lasso and propose to integrate it within a deep learning model discovery\nframework with stability selection and error control. Experimental results show\nwe can recover several nonlinear and chaotic canonical PDEs with a single set\nof hyperparameters from a very limited number of samples at high noise levels.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:19:36 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Tod", "Georges", ""], ["Both", "Gert-Jan", ""], ["Kusters", "Remy", ""]]}, {"id": "2106.11938", "submitter": "Kevin Tian", "authors": "Arun Jambulapati, Jerry Li, Tselil Schramm, Kevin Tian", "title": "Robust Regression Revisited: Acceleration and Improved Estimation Rates", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study fast algorithms for statistical regression problems under the strong\ncontamination model, where the goal is to approximately optimize a generalized\nlinear model (GLM) given adversarially corrupted samples. Prior works in this\nline of research were based on the robust gradient descent framework of Prasad\net. al., a first-order method using biased gradient queries, or the Sever\nframework of Diakonikolas et. al., an iterative outlier-removal method calling\na stationary point finder.\n  We present nearly-linear time algorithms for robust regression problems with\nimproved runtime or estimation guarantees compared to the state-of-the-art. For\nthe general case of smooth GLMs (e.g. logistic regression), we show that the\nrobust gradient descent framework of Prasad et. al. can be accelerated, and\nshow our algorithm extends to optimizing the Moreau envelopes of Lipschitz GLMs\n(e.g. support vector machines), answering several open questions in the\nliterature.\n  For the well-studied case of robust linear regression, we present an\nalternative approach obtaining improved estimation rates over prior\nnearly-linear time algorithms. Interestingly, our method starts with an\nidentifiability proof introduced in the context of the sum-of-squares algorithm\nof Bakshi and Prasad, which achieved optimal error rates while requiring large\npolynomial runtime and sample complexity. We reinterpret their proof within the\nSever framework and obtain a dramatically faster and more sample-efficient\nalgorithm under fewer distributional assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:21:56 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Jambulapati", "Arun", ""], ["Li", "Jerry", ""], ["Schramm", "Tselil", ""], ["Tian", "Kevin", ""]]}, {"id": "2106.11950", "submitter": "Joshua Behne", "authors": "Joshua K. Behne and Galen Reeves", "title": "Rank-one matrix estimation with groupwise heteroskedasticity", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of estimating a rank-one matrix from Gaussian\nobservations where different blocks of the matrix are observed under different\nnoise levels. This problem is motivated by applications in clustering and\ncommunity detection where latent variables can be partitioned into a fixed\nnumber of known groups (e.g., users and items) and the blocks of the matrix\ncorrespond to different types of pairwise interactions (e.g., user-user,\nuser-item, or item-item interactions). In the setting where the number of\nblocks is fixed while the number of variables tends to infinity, we prove\nasymptotically exact formulas for the minimum mean-squared error in estimating\nboth the matrix and the latent variables. These formulas describe the weak\nrecovery thresholds for the problem and reveal invariance properties with\nrespect to certain scalings of the noise variance. We also derive an\napproximate message passing algorithm and a gradient descent algorithm and show\nempirically that these algorithms achieve the information-theoretic limits in\ncertain regimes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:48:36 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Behne", "Joshua K.", ""], ["Reeves", "Galen", ""]]}, {"id": "2106.11960", "submitter": "Quanquan Gu", "authors": "Yifei Min and Tianhao Wang and Dongruo Zhou and Quanquan Gu", "title": "Variance-Aware Off-Policy Evaluation with Linear Function Approximation", "comments": "70 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the off-policy evaluation (OPE) problem in reinforcement learning\nwith linear function approximation, which aims to estimate the value function\nof a target policy based on the offline data collected by a behavior policy. We\npropose to incorporate the variance information of the value function to\nimprove the sample efficiency of OPE. More specifically, for time-inhomogeneous\nepisodic linear Markov decision processes (MDPs), we propose an algorithm,\nVA-OPE, which uses the estimated variance of the value function to reweight the\nBellman residual in Fitted Q-Iteration. We show that our algorithm achieves a\ntighter error bound than the best-known result. We also provide a fine-grained\ncharacterization of the distribution shift between the behavior policy and the\ntarget policy. Extensive numerical experiments corroborate our theory.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:58:46 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Min", "Yifei", ""], ["Wang", "Tianhao", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "2106.12012", "submitter": "Celestine Mendler-D\\\"unner", "authors": "Celestine Mendler-D\\\"unner, Wenshuo Guo, Stephen Bates, Michael I.\n  Jordan", "title": "Test-time Collective Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An increasingly common setting in machine learning involves multiple parties,\neach with their own data, who want to jointly make predictions on future test\npoints. Agents wish to benefit from the collective expertise of the full set of\nagents to make better predictions than they would individually, but may not be\nwilling to release their data or model parameters. In this work, we explore a\ndecentralized mechanism to make collective predictions at test time, leveraging\neach agent's pre-trained model without relying on external validation, model\nretraining, or data pooling. Our approach takes inspiration from the literature\nin social science on human consensus-making. We analyze our mechanism\ntheoretically, showing that it converges to inverse meansquared-error (MSE)\nweighting in the large-sample limit. To compute error bars on the collective\npredictions we propose a decentralized Jackknife procedure that evaluates the\nsensitivity of our mechanism to a single agent's prediction. Empirically, we\ndemonstrate that our scheme effectively combines models with differing quality\nacross the input space. The proposed consensus prediction achieves significant\ngains over classical model averaging, and even outperforms weighted averaging\nschemes that have access to additional validation data.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 18:29:58 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Mendler-D\u00fcnner", "Celestine", ""], ["Guo", "Wenshuo", ""], ["Bates", "Stephen", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2106.12034", "submitter": "Yinglun Zhu", "authors": "Yinglun Zhu, Dongruo Zhou, Ruoxi Jiang, Quanquan Gu, Rebecca Willett,\n  Robert Nowak", "title": "Pure Exploration in Kernel and Neural Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pure exploration in bandits, where the dimension of the feature\nrepresentation can be much larger than the number of arms. To overcome the\ncurse of dimensionality, we propose to adaptively embed the feature\nrepresentation of each arm into a lower-dimensional space and carefully deal\nwith the induced model misspecifications. Our approach is conceptually very\ndifferent from existing works that can either only handle low-dimensional\nlinear bandits or passively deal with model misspecifications. We showcase the\napplication of our approach to two pure exploration settings that were\npreviously under-studied: (1) the reward function belongs to a possibly\ninfinite-dimensional Reproducing Kernel Hilbert Space, and (2) the reward\nfunction is nonlinear and can be approximated by neural networks. Our main\nresults provide sample complexity guarantees that only depend on the effective\ndimension of the feature spaces in the kernel or neural representations.\nExtensive experiments conducted on both synthetic and real-world datasets\ndemonstrate the efficacy of our methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 19:51:59 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zhu", "Yinglun", ""], ["Zhou", "Dongruo", ""], ["Jiang", "Ruoxi", ""], ["Gu", "Quanquan", ""], ["Willett", "Rebecca", ""], ["Nowak", "Robert", ""]]}, {"id": "2106.12059", "submitter": "Andreas Kirsch", "authors": "Andreas Kirsch, Sebastian Farquhar, Yarin Gal", "title": "A Simple Baseline for Batch Active Learning with Stochastic Acquisition\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In active learning, new labels are commonly acquired in batches. However,\ncommon acquisition functions are only meant for one-sample acquisition rounds\nat a time, and when their scores are used naively for batch acquisition, they\nresult in batches lacking diversity, which deteriorates performance. On the\nother hand, state-of-the-art batch acquisition functions are costly to compute.\nIn this paper, we present a novel class of stochastic acquisition functions\nthat extend one-sample acquisition functions to the batch setting by observing\nhow one-sample acquisition scores change as additional samples are acquired and\nmodelling this difference for additional batch samples. We simply acquire new\nsamples by sampling from the pool set using a Gibbs distribution based on the\nacquisition scores. Our acquisition functions are both vastly cheaper to\ncompute and out-perform other batch acquisition functions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 21:07:50 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Kirsch", "Andreas", ""], ["Farquhar", "Sebastian", ""], ["Gal", "Yarin", ""]]}, {"id": "2106.12062", "submitter": "Andreas Kirsch", "authors": "Andreas Kirsch, Yarin Gal", "title": "A Practical & Unified Notation for Information-Theoretic Quantities in\n  ML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory is of importance to machine learning, but the notation for\ninformation-theoretic quantities is sometimes opaque. The right notation can\nconvey valuable intuitions and concisely express new ideas. We propose such a\nnotation for machine learning users and expand it to include\ninformation-theoretic quantities between events (outcomes) and random\nvariables. We apply this notation to a popular information-theoretic\nacquisition function in Bayesian active learning which selects the most\ninformative (unlabelled) samples to be labelled by an expert. We demonstrate\nthe value of our notation when extending the acquisition function to the\ncore-set problem, which consists of selecting the most informative samples\n\\emph{given} the labels.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 21:18:17 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Kirsch", "Andreas", ""], ["Gal", "Yarin", ""]]}, {"id": "2106.12068", "submitter": "Jie Ding", "authors": "Gen Li, Yuantao Gu, Jie Ding", "title": "The Rate of Convergence of Variation-Constrained Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-layer feedforward networks have been used to approximate a wide range\nof nonlinear functions. An important and fundamental problem is to understand\nthe learnability of a network model through its statistical risk, or the\nexpected prediction error on future data. To the best of our knowledge, the\nrate of convergence of neural networks shown by existing works is bounded by at\nmost the order of $n^{-1/4}$ for a sample size of $n$. In this paper, we show\nthat a class of variation-constrained neural networks, with arbitrary width,\ncan achieve near-parametric rate $n^{-1/2+\\delta}$ for an arbitrarily small\npositive constant $\\delta$. It is equivalent to $n^{-1 +2\\delta}$ under the\nmean squared error. This rate is also observed by numerical experiments. The\nresult indicates that the neural function space needed for approximating smooth\nfunctions may not be as large as what is often perceived. Our result also\nprovides insight to the phenomena that deep neural networks do not easily\nsuffer from overfitting when the number of neurons and learning parameters\nrapidly grow with $n$ or even surpass $n$. We also discuss the rate of\nconvergence regarding other network parameters, including the input dimension,\nnetwork layer, and coefficient norm.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 21:28:00 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Li", "Gen", ""], ["Gu", "Yuantao", ""], ["Ding", "Jie", ""]]}, {"id": "2106.12096", "submitter": "Marissa Connor", "authors": "Marissa Connor, Kion Fallah, Christopher Rozell", "title": "Learning Identity-Preserving Transformations on Data Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning techniques incorporate identity-preserving\ntransformations into their models to generalize their performance to previously\nunseen data. These transformations are typically selected from a set of\nfunctions that are known to maintain the identity of an input when applied\n(e.g., rotation, translation, flipping, and scaling). However, there are many\nnatural variations that cannot be labeled for supervision or defined through\nexamination of the data. As suggested by the manifold hypothesis, many of these\nnatural variations live on or near a low-dimensional, nonlinear manifold.\nSeveral techniques represent manifold variations through a set of learned Lie\ngroup operators that define directions of motion on the manifold. However\ntheses approaches are limited because they require transformation labels when\ntraining their models and they lack a method for determining which regions of\nthe manifold are appropriate for applying each specific operator. We address\nthese limitations by introducing a learning strategy that does not require\ntransformation labels and developing a method that learns the local regions\nwhere each operator is likely to be used while preserving the identity of\ninputs. Experiments on MNIST and Fashion MNIST highlight our model's ability to\nlearn identity-preserving transformations on multi-class datasets.\nAdditionally, we train on CelebA to showcase our model's ability to learn\nsemantically meaningful transformations on complex datasets in an unsupervised\nmanner.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 23:10:25 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Connor", "Marissa", ""], ["Fallah", "Kion", ""], ["Rozell", "Christopher", ""]]}, {"id": "2106.12105", "submitter": "Wenkai Xu", "authors": "Wenkai Xu", "title": "Generalised Kernel Stein Discrepancy(GKSD): A Unifying Approach for\n  Non-parametric Goodness-of-fit Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-parametric goodness-of-fit testing procedures based on kernel Stein\ndiscrepancies (KSD) are promising approaches to validate general unnormalised\ndistributions in various scenarios. Existing works have focused on studying\noptimal kernel choices to boost test performances. However, the Stein operators\nare generally non-unique, while different choices of Stein operators can also\nhave considerable effect on the test performances. In this work, we propose a\nunifying framework, the generalised kernel Stein discrepancy (GKSD), to\ntheoretically compare and interpret different Stein operators in performing the\nKSD-based goodness-of-fit tests. We derive explicitly that how the proposed\nGKSD framework generalises existing Stein operators and their corresponding\ntests. In addition, we show thatGKSD framework can be used as a guide to\ndevelop kernel-based non-parametric goodness-of-fit tests for complex new data\nscenarios, e.g. truncated distributions or compositional data. Experimental\nresults demonstrate that the proposed tests control type-I error well and\nachieve higher test power than existing approaches, including the test based on\nmaximum-mean-discrepancy (MMD).\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 00:44:31 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Xu", "Wenkai", ""]]}, {"id": "2106.12108", "submitter": "Qi Lei", "authors": "Qi Lei, Wei Hu, Jason D. Lee", "title": "Near-Optimal Linear Regression under Distribution Shift", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Transfer learning is essential when sufficient data comes from the source\ndomain, with scarce labeled data from the target domain. We develop estimators\nthat achieve minimax linear risk for linear regression problems under\ndistribution shift. Our algorithms cover different transfer learning settings\nincluding covariate shift and model shift. We also consider when data are\ngenerated from either linear or general nonlinear models. We show that linear\nminimax estimators are within an absolute constant of the minimax risk even\namong nonlinear estimators for various source/target distributions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 00:52:50 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lei", "Qi", ""], ["Hu", "Wei", ""], ["Lee", "Jason D.", ""]]}, {"id": "2106.12135", "submitter": "Kalvik Jakkala", "authors": "Kalvik Jakkala", "title": "Deep Gaussian Processes: A Survey", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Gaussian processes are one of the dominant approaches in Bayesian learning.\nAlthough the approach has been applied to numerous problems with great success,\nit has a few fundamental limitations. Multiple methods in literature have\naddressed these limitations. However, there has not been a comprehensive survey\nof the topics as of yet. Most existing surveys focus on only one particular\nvariant of Gaussian processes and their derivatives. This survey details the\ncore motivations for using Gaussian processes, their mathematical formulations,\nlimitations, and research themes that have flourished over the years to address\nsaid limitations. Furthermore, one particular research area is Deep Gaussian\nProcesses (DGPs), it has improved substantially in the past decade. The\nsignificant publications that advanced the forefront of this research area are\noutlined in their survey. Finally, a brief discussion on open problems and\nresearch directions for future work is presented at the end.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 13:59:47 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Jakkala", "Kalvik", ""]]}, {"id": "2106.12182", "submitter": "Ajil Jalal", "authors": "Ajil Jalal and Sushrut Karmalkar and Jessica Hoffmann and Alexandros\n  G. Dimakis and Eric Price", "title": "Fairness for Image Generation with Uncertain Sensitive Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work tackles the issue of fairness in the context of generative\nprocedures, such as image super-resolution, which entail different definitions\nfrom the standard classification setting. Moreover, while traditional group\nfairness definitions are typically defined with respect to specified protected\ngroups -- camouflaging the fact that these groupings are artificial and carry\nhistorical and political motivations -- we emphasize that there are no ground\ntruth identities. For instance, should South and East Asians be viewed as a\nsingle group or separate groups? Should we consider one race as a whole or\nfurther split by gender? Choosing which groups are valid and who belongs in\nthem is an impossible dilemma and being \"fair\" with respect to Asians may\nrequire being \"unfair\" with respect to South Asians. This motivates the\nintroduction of definitions that allow algorithms to be \\emph{oblivious} to the\nrelevant groupings.\n  We define several intuitive notions of group fairness and study their\nincompatibilities and trade-offs. We show that the natural extension of\ndemographic parity is strongly dependent on the grouping, and \\emph{impossible}\nto achieve obliviously. On the other hand, the conceptually new definition we\nintroduce, Conditional Proportional Representation, can be achieved obliviously\nthrough Posterior Sampling. Our experiments validate our theoretical results\nand achieve fair image reconstruction using state-of-the-art generative models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 06:17:17 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 10:23:09 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Jalal", "Ajil", ""], ["Karmalkar", "Sushrut", ""], ["Hoffmann", "Jessica", ""], ["Dimakis", "Alexandros G.", ""], ["Price", "Eric", ""]]}, {"id": "2106.12190", "submitter": "Mostafa Rahmani", "authors": "Mostafa Rahmani and Ping Li", "title": "Closed-Form, Provable, and Robust PCA via Leverage Statistics and\n  Innovation Search", "comments": "Published in IEEE Transactions on Signal Processing. arXiv admin\n  note: text overlap with arXiv:1912.12988", "journal-ref": null, "doi": "10.1109/TSP.2021.3079817", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of Innovation Search, which was initially proposed for data\nclustering, was recently used for outlier detection. In the application of\nInnovation Search for outlier detection, the directions of innovation were\nutilized to measure the innovation of the data points. We study the Innovation\nValues computed by the Innovation Search algorithm under a quadratic cost\nfunction and it is proved that Innovation Values with the new cost function are\nequivalent to Leverage Scores. This interesting connection is utilized to\nestablish several theoretical guarantees for a Leverage Score based robust PCA\nmethod and to design a new robust PCA method. The theoretical results include\nperformance guarantees with different models for the distribution of outliers\nand the distribution of inliers. In addition, we demonstrate the robustness of\nthe algorithms against the presence of noise. The numerical and theoretical\nstudies indicate that while the presented approach is fast and closed-form, it\ncan outperform most of the existing algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 06:36:36 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Li", "Ping", ""]]}, {"id": "2106.12200", "submitter": "Branislav Kveton", "authors": "Rong Zhu and Branislav Kveton", "title": "Random Effect Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies regret minimization in multi-armed bandits, a classical\nonline learning problem. To develop more statistically-efficient algorithms, we\npropose to use the assumption of a random-effect model. In this model, the mean\nrewards of arms are drawn independently from an unknown distribution, whose\nparameters we estimate. We provide an estimator of the arm means in this model\nand also analyze its uncertainty. Based on these results, we design a UCB\nalgorithm, which we call ReUCB. We analyze ReUCB and prove a Bayes regret bound\non its $n$-round regret, which matches an existing lower bound. Our experiments\nshow that ReUCB can outperform Thompson sampling in various scenarios, without\nassuming that the prior distribution of arm means is known.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 07:15:31 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zhu", "Rong", ""], ["Kveton", "Branislav", ""]]}, {"id": "2106.12228", "submitter": "Martin Jullum PhD", "authors": "Martin Jullum, Annabelle Redelmeier, Kjersti Aas", "title": "groupShapley: Efficient prediction explanation with Shapley values for\n  feature groups", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAMBA/20/21", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley values has established itself as one of the most appropriate and\ntheoretically sound frameworks for explaining predictions from complex machine\nlearning models. The popularity of Shapley values in the explanation setting is\nprobably due to its unique theoretical properties. The main drawback with\nShapley values, however, is that its computational complexity grows\nexponentially in the number of input features, making it unfeasible in many\nreal world situations where there could be hundreds or thousands of features.\nFurthermore, with many (dependent) features, presenting/visualizing and\ninterpreting the computed Shapley values also becomes challenging. The present\npaper introduces groupShapley: a conceptually simple approach for dealing with\nthe aforementioned bottlenecks. The idea is to group the features, for example\nby type or dependence, and then compute and present Shapley values for these\ngroups instead of for all individual features. Reducing hundreds or thousands\nof features to half a dozen or so, makes precise computations practically\nfeasible and the presentation and knowledge extraction greatly simplified. We\nprove that under certain conditions, groupShapley is equivalent to summing the\nfeature-wise Shapley values within each feature group. Moreover, we provide a\nsimulation study exemplifying the differences when these conditions are not\nmet. We illustrate the usability of the approach in a real world car insurance\nexample, where groupShapley is used to provide simple and intuitive\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 08:16:14 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Jullum", "Martin", ""], ["Redelmeier", "Annabelle", ""], ["Aas", "Kjersti", ""]]}, {"id": "2106.12231", "submitter": "Luigi Carratino", "authors": "Luigi Carratino, Stefano Vigogna, Daniele Calandriello, Lorenzo\n  Rosasco", "title": "ParK: Sound and Efficient Kernel Ridge Regression by Feature Space\n  Partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce ParK, a new large-scale solver for kernel ridge regression. Our\napproach combines partitioning with random projections and iterative\noptimization to reduce space and time complexity while provably maintaining the\nsame statistical accuracy. In particular, constructing suitable partitions\ndirectly in the feature space rather than in the input space, we promote\northogonality between the local estimators, thus ensuring that key quantities\nsuch as local effective dimension and bias remain under control. We\ncharacterize the statistical-computational tradeoff of our model, and\ndemonstrate the effectiveness of our method by numerical experiments on\nlarge-scale datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 08:24:36 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Carratino", "Luigi", ""], ["Vigogna", "Stefano", ""], ["Calandriello", "Daniele", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "2106.12242", "submitter": "Gilles Stoltz", "authors": "Evgenii Chzhen (LMO, CELESTE), Christophe Giraud (LMO, CELESTE),\n  Gilles Stoltz (LMO, CELESTE)", "title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a setting and a general approach to fair online learning with\nstochastic sensitive and non-sensitive contexts. The setting is a repeated game\nbetween the Player and Nature, where at each stage both pick actions based on\nthe contexts. Inspired by the notion of unawareness, we assume that the Player\ncan only access the non-sensitive context before making a decision, while we\ndiscuss both cases of Nature accessing the sensitive contexts and Nature\nunaware of the sensitive contexts. Adapting Blackwell's approachability theory\nto handle the case of an unknown contexts' distribution, we provide a general\nnecessary and sufficient condition for learning objectives to be compatible\nwith some fairness constraints. This condition is instantiated on (group-wise)\nno-regret and (group-wise) calibration objectives, and on demographic parity as\nan additional constraint. When the objective is not compatible with the\nconstraint, the provided framework permits to characterise the optimal\ntrade-off between the two.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:00:12 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Chzhen", "Evgenii", "", "LMO, CELESTE"], ["Giraud", "Christophe", "", "LMO, CELESTE"], ["Stoltz", "Gilles", "", "LMO, CELESTE"]]}, {"id": "2106.12248", "submitter": "Louis Rouillard", "authors": "Louis Rouillard (PARIETAL, Inria, CEA), Demian Wassermann (PARIETAL,\n  Inria, CEA)", "title": "ADAVI: Automatic Dual Amortized Variational Inference Applied To\n  Pyramidal Bayesian Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequently, population studies feature pyramidally-organized data represented\nusing Hierarchical Bayesian Models (HBM) enriched with plates. These models can\nbecome prohibitively large in settings such as neuroimaging, where a sample is\ncomposed of a functional MRI signal measured on 64 thousand brain locations,\nacross 4 measurement sessions, and at least tens of subjects. Even a reduced\nexample on a specific cortical region of 300 brain locations features around 1\nmillion parameters, hampering the usage of modern density estimation techniques\nsuch as Simulation-Based Inference (SBI). To infer parameter posterior\ndistributions in this challenging class of problems, we designed a novel\nmethodology that automatically produces a variational family dual to a target\nHBM. This variatonal family, represented as a neural network, consists in the\ncombination of an attention-based hierarchical encoder feeding summary\nstatistics to a set of normalizing flows. Our automatically-derived neural\nnetwork exploits exchangeability in the plate-enriched HBM and factorizes its\nparameter space. The resulting architecture reduces by orders of magnitude its\nparameterization with respect to that of a typical SBI representation, while\nmaintaining expressivity. Our method performs inference on the specified HBM in\nan amortized setup: once trained, it can readily be applied to a new data\nsample to compute the parameters' full posterior. We demonstrate the capability\nof our method on simulated data, as well as a challenging high-dimensional\nbrain parcellation experiment. We also open up several questions that lie at\nthe intersection between SBI techniques and structured Variational Inference.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 09:09:01 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Rouillard", "Louis", "", "PARIETAL, Inria, CEA"], ["Wassermann", "Demian", "", "PARIETAL,\n  Inria, CEA"]]}, {"id": "2106.12307", "submitter": "Mats Richter", "authors": "Mats L. Richter, Julius Sch\\\"oning, Ulf Krumnack", "title": "Should You Go Deeper? Optimizing Convolutional Neural Network\n  Architectures without Training by Receptive Field Analysis", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applying artificial neural networks (ANN) to specific tasks, researchers,\nprogrammers, and other specialists usually overshot the number of convolutional\nlayers in their designs. By implication, these ANNs hold too many parameters,\nwhich needed unnecessarily trained without impacting the result. The features,\na convolutional layer can process, are strictly limited by its receptive field.\nBy layer-wise analyzing the expansion of the receptive fields, we can reliably\npredict sequences of layers that will not contribute qualitatively to the\ninference in thegiven ANN architecture. Based on these analyses, we propose\ndesign strategies to resolve these inefficiencies, optimizing the\nexplainability and the computational performance of ANNs. Since neither the\nstrategies nor the analysis requires training of the actual model, these\ninsights allow for a very efficient design process of ANNs architectures which\nmight be automated in the future.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 11:04:16 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Richter", "Mats L.", ""], ["Sch\u00f6ning", "Julius", ""], ["Krumnack", "Ulf", ""]]}, {"id": "2106.12312", "submitter": "Salvatore Scognamiglio Dr.", "authors": "Salvatore Scognamiglio", "title": "Calibrating the Lee-Carter and the Poisson Lee-Carter models via Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a neural network approach for fitting the Lee-Carter\nand the Poisson Lee-Carter model on multiple populations. We develop some\nneural networks that replicate the structure of the individual LC models and\nallow their joint fitting by analysing the mortality data of all the considered\npopulations simultaneously. The neural network architecture is specifically\ndesigned to calibrate each individual model using all available information\ninstead of using a population-specific subset of data as in the traditional\nestimation schemes. A large set of numerical experiments performed on all the\ncountries of the Human Mortality Database (HMD) shows the effectiveness of our\napproach. In particular, the resulting parameter estimates appear smooth and\nless sensitive to the random fluctuations often present in the mortality rates'\ndata, especially for low-population countries. In addition, the forecasting\nperformance results significantly improved as well.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 11:20:44 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 20:40:06 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Scognamiglio", "Salvatore", ""]]}, {"id": "2106.12382", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Lang Tong", "title": "Innovations Autoencoder and its Application in One-class Anomalous\n  Sequence Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An innovations sequence of a time series is a sequence of independent and\nidentically distributed random variables with which the original time series\nhas a causal representation. The innovation at a time is statistically\nindependent of the history of the time series. As such, it represents the new\ninformation contained at present but not in the past. Because of its simple\nprobability structure, an innovations sequence is the most efficient signature\nof the original. Unlike the principle or independent component analysis\nrepresentations, an innovations sequence preserves not only the complete\nstatistical properties but also the temporal order of the original time series.\nAn long-standing open problem is to find a computationally tractable way to\nextract an innovations sequence of non-Gaussian processes. This paper presents\na deep learning approach, referred to as Innovations Autoencoder (IAE), that\nextracts innovations sequences using a causal convolutional neural network. An\napplication of IAE to the one-class anomalous sequence detection problem with\nunknown anomaly and anomaly-free models is also presented.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 13:24:17 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 15:37:42 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Wang", "Xinyi", ""], ["Tong", "Lang", ""]]}, {"id": "2106.12408", "submitter": "Raj Agrawal", "authors": "Raj Agrawal and Tamara Broderick", "title": "The SKIM-FA Kernel: High-Dimensional Variable Selection and Nonlinear\n  Interaction Discovery in Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientific problems require identifying a small set of covariates that\nare associated with a target response and estimating their effects. Often,\nthese effects are nonlinear and include interactions, so linear and additive\nmethods can lead to poor estimation and variable selection. The Bayesian\nframework makes it straightforward to simultaneously express sparsity,\nnonlinearity, and interactions in a hierarchical model. But, as for the few\nother methods that handle this trifecta, inference is computationally\nintractable - with runtime at least quadratic in the number of covariates, and\noften worse. In the present work, we solve this computational bottleneck. We\nfirst show that suitable Bayesian models can be represented as Gaussian\nprocesses (GPs). We then demonstrate how a kernel trick can reduce computation\nwith these GPs to O(# covariates) time for both variable selection and\nestimation. Our resulting fit corresponds to a sparse orthogonal decomposition\nof the regression function in a Hilbert space (i.e., a functional ANOVA\ndecomposition), where interaction effects represent all variation that cannot\nbe explained by lower-order effects. On a variety of synthetic and real\ndatasets, our approach outperforms existing methods used for large,\nhigh-dimensional datasets while remaining competitive (or being orders of\nmagnitude faster) in runtime.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 13:53:36 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Agrawal", "Raj", ""], ["Broderick", "Tamara", ""]]}, {"id": "2106.12417", "submitter": "Michael Hagmann", "authors": "Michael Hagmann, Stefan Riezler", "title": "False perfection in machine prediction: Detecting and assessing\n  circularity problems in machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms train models from patterns of input data and\ntarget outputs, with the goal of predicting correct outputs for unseen test\ninputs. Here we demonstrate a problem of machine learning in vital application\nareas such as medical informatics or patent law that consists of the inclusion\nof measurements on which target outputs are deterministically defined in the\nrepresentations of input data. This leads to perfect, but circular predictions\nbased on a machine reconstruction of the known target definition, but fails on\nreal-world data where the defining measurements may not or only incompletely be\navailable. We present a circularity test that shows, for given datasets and\nblack-box machine learning models, whether the target functional definition can\nbe reconstructed and has been used in training. We argue that a transfer of\nresearch results to real-world applications requires to avoid circularity by\nseparating measurements that define target outcomes from data representations\nin machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:11:06 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Hagmann", "Michael", ""], ["Riezler", "Stefan", ""]]}, {"id": "2106.12423", "submitter": "Samuli Laine", "authors": "Tero Karras, Miika Aittala, Samuli Laine, Erik H\\\"ark\\\"onen, Janne\n  Hellsten, Jaakko Lehtinen, Timo Aila", "title": "Alias-Free Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that despite their hierarchical convolutional nature, the\nsynthesis process of typical generative adversarial networks depends on\nabsolute pixel coordinates in an unhealthy manner. This manifests itself as,\ne.g., detail appearing to be glued to image coordinates instead of the surfaces\nof depicted objects. We trace the root cause to careless signal processing that\ncauses aliasing in the generator network. Interpreting all signals in the\nnetwork as continuous, we derive generally applicable, small architectural\nchanges that guarantee that unwanted information cannot leak into the\nhierarchical synthesis process. The resulting networks match the FID of\nStyleGAN2 but differ dramatically in their internal representations, and they\nare fully equivariant to translation and rotation even at subpixel scales. Our\nresults pave the way for generative models better suited for video and\nanimation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:20:01 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 14:43:18 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Karras", "Tero", ""], ["Aittala", "Miika", ""], ["Laine", "Samuli", ""], ["H\u00e4rk\u00f6nen", "Erik", ""], ["Hellsten", "Janne", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "2106.12491", "submitter": "Abir De", "authors": "Durga Sivasubramanian, Rishabh Iyer, Ganesh Ramakrishnan, Abir De", "title": "Training Data Subset Selection for Regression with Controlled\n  Generalization Error", "comments": null, "journal-ref": "ICML 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data subset selection from a large number of training instances has been a\nsuccessful approach toward efficient and cost-effective machine learning.\nHowever, models trained on a smaller subset may show poor generalization\nability. In this paper, our goal is to design an algorithm for selecting a\nsubset of the training data, so that the model can be trained quickly, without\nsignificantly sacrificing on accuracy. More specifically, we focus on data\nsubset selection for L2 regularized regression problems and provide a novel\nproblem formulation which seeks to minimize the training loss with respect to\nboth the trainable parameters and the subset of training data, subject to error\nbounds on the validation set. We tackle this problem using several technical\ninnovations. First, we represent this problem with simplified constraints using\nthe dual of the original training problem and show that the objective of this\nnew representation is a monotone and alpha-submodular function, for a wide\nvariety of modeling choices. Such properties lead us to develop SELCON, an\nefficient majorization-minimization algorithm for data subset selection, that\nadmits an approximation guarantee even when the training provides an imperfect\nestimate of the trained model. Finally, our experiments on several datasets\nshow that SELCON trades off accuracy and efficiency more effectively than the\ncurrent state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:03:55 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Sivasubramanian", "Durga", ""], ["Iyer", "Rishabh", ""], ["Ramakrishnan", "Ganesh", ""], ["De", "Abir", ""]]}, {"id": "2106.12498", "submitter": "Yao Wang", "authors": "Shao-Bo Lin, Kaidong Wang, Yao Wang, Ding-Xuan Zhou", "title": "Universal Consistency of Deep Convolutional Neural Networks", "comments": "9pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compared with avid research activities of deep convolutional neural networks\n(DCNNs) in practice, the study of theoretical behaviors of DCNNs lags heavily\nbehind. In particular, the universal consistency of DCNNs remains open. In this\npaper, we prove that implementing empirical risk minimization on DCNNs with\nexpansive convolution (with zero-padding) is strongly universally consistent.\nMotivated by the universal consistency, we conduct a series of experiments to\nshow that without any fully connected layers, DCNNs with expansive convolution\nperform not worse than the widely used deep neural networks with hybrid\nstructure containing contracting (without zero-padding) convolution layers and\nseveral fully connected layers.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:17:21 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lin", "Shao-Bo", ""], ["Wang", "Kaidong", ""], ["Wang", "Yao", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "2106.12506", "submitter": "Jiaxin Shi", "authors": "Jiaxin Shi, Chang Liu, Lester Mackey", "title": "Sampling with Mirrored Stein Operators", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new family of particle evolution samplers suitable for\nconstrained domains and non-Euclidean geometries. Stein Variational Mirror\nDescent and Mirrored Stein Variational Gradient Descent minimize the\nKullback-Leibler (KL) divergence to constrained target distributions by\nevolving particles in a dual space defined by a mirror map. Stein Variational\nNatural Gradient exploits non-Euclidean geometry to more efficiently minimize\nthe KL divergence to unconstrained targets. We derive these samplers from a new\nclass of mirrored Stein operators and adaptive kernels developed in this work.\nWe demonstrate that these new samplers yield accurate approximations to\ndistributions on the simplex, deliver valid confidence intervals in\npost-selection inference, and converge more rapidly than prior methods in\nlarge-scale unconstrained posterior inference. Finally, we establish the\nconvergence of our new procedures under verifiable conditions on the target\ndistribution.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:23:34 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Shi", "Jiaxin", ""], ["Liu", "Chang", ""], ["Mackey", "Lester", ""]]}, {"id": "2106.12532", "submitter": "Udit Bhatia", "authors": "Nidhin Harilal, Udit Bhatia, Auroop R. Ganguly", "title": "Bayesian Deep Learning Hyperparameter Search for Robust Function Mapping\n  to Polynomials with Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in neural architecture search, as well as explainability and\ninterpretability of connectionist architectures, have been reported in the\nrecent literature. However, our understanding of how to design Bayesian Deep\nLearning (BDL) hyperparameters, specifically, the depth, width and ensemble\nsize, for robust function mapping with uncertainty quantification, is still\nemerging. This paper attempts to further our understanding by mapping Bayesian\nconnectionist representations to polynomials of different orders with varying\nnoise types and ratios. We examine the noise-contaminated polynomials to search\nfor the combination of hyperparameters that can extract the underlying\npolynomial signals while quantifying uncertainties based on the noise\nattributes. Specifically, we attempt to study the question that an appropriate\nneural architecture and ensemble configuration can be found to detect a signal\nof any n-th order polynomial contaminated with noise having different\ndistributions and signal-to-noise (SNR) ratios and varying noise attributes.\nOur results suggest the possible existence of an optimal network depth as well\nas an optimal number of ensembles for prediction skills and uncertainty\nquantification, respectively. However, optimality is not discernible for width,\neven though the performance gain reduces with increasing width at high values\nof width. Our experiments and insights can be directional to understand\ntheoretical properties of BDL representations and to design practical\nsolutions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:54:55 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Harilal", "Nidhin", ""], ["Bhatia", "Udit", ""], ["Ganguly", "Auroop R.", ""]]}, {"id": "2106.12535", "submitter": "Valentina Zantedeschi Dr", "authors": "Valentina Zantedeschi, Paul Viallard, Emilie Morvant, R\\'emi Emonet,\n  Amaury Habrard, Pascal Germain, Benjamin Guedj", "title": "Learning Stochastic Majority Votes by Minimizing a PAC-Bayes\n  Generalization Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate a stochastic counterpart of majority votes over finite\nensembles of classifiers, and study its generalization properties. While our\napproach holds for arbitrary distributions, we instantiate it with Dirichlet\ndistributions: this allows for a closed-form and differentiable expression for\nthe expected risk, which then turns the generalization bound into a tractable\ntraining objective. The resulting stochastic majority vote learning algorithm\nachieves state-of-the-art accuracy and benefits from (non-vacuous) tight\ngeneralization bounds, in a series of numerical experiments when compared to\ncompeting algorithms which also minimize PAC-Bayes objectives -- both with\nuninformed (data-independent) and informed (data-dependent) priors.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:57:23 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zantedeschi", "Valentina", ""], ["Viallard", "Paul", ""], ["Morvant", "Emilie", ""], ["Emonet", "R\u00e9mi", ""], ["Habrard", "Amaury", ""], ["Germain", "Pascal", ""], ["Guedj", "Benjamin", ""]]}, {"id": "2106.12543", "submitter": "Colin White", "authors": "Yang Liu, Sujay Khandagale, Colin White, Willie Neiswanger", "title": "Synthetic Benchmarks for Scientific Research in Explainable Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning models grow more complex and their applications become\nmore high-stakes, tools for explaining model predictions have become\nincreasingly important. Despite the widespread use of explainability\ntechniques, evaluating and comparing different feature attribution methods\nremains challenging: evaluations ideally require human studies, and empirical\nevaluation metrics are often computationally prohibitive on real-world\ndatasets. In this work, we address this issue by releasing XAI-Bench: a suite\nof synthetic datasets along with a library for benchmarking feature attribution\nalgorithms. Unlike real-world datasets, synthetic datasets allow the efficient\ncomputation of conditional expected values that are needed to evaluate\nground-truth Shapley values and other metrics. The synthetic datasets we\nrelease offer a wide variety of parameters that can be configured to simulate\nreal-world data. We demonstrate the power of our library by benchmarking\npopular explainability techniques across several evaluation metrics and\nidentifying failure modes for popular explainers. The efficiency of our library\nwill help bring new explainability methods from development to deployment.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:10:21 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Liu", "Yang", ""], ["Khandagale", "Sujay", ""], ["White", "Colin", ""], ["Neiswanger", "Willie", ""]]}, {"id": "2106.12548", "submitter": "Sai Sukruth Bezugam", "authors": "Sai Sukruth Bezugam", "title": "Multi-Class Classification of Blood Cells -- End to End Computer Vision\n  based diagnosis case study", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.CB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diagnosis of blood-based diseases often involves identifying and\ncharacterizing patient blood samples. Automated methods to detect and classify\nblood cell subtypes have important medical applications. Automated medical\nimage processing and analysis offers a powerful tool for medical diagnosis. In\nthis work we tackle the problem of white blood cell classification based on the\nmorphological characteristics of their outer contour, color. The work we would\nexplore a set of preprocessing and segmentation (Color-based segmentation,\nMorphological processing, contouring) algorithms along with a set of features\nextraction methods (Corner detection algorithms and Histogram of\nGradients(HOG)), dimensionality reduction algorithms (Principal Component\nAnalysis(PCA)) that are able to recognize and classify through various\nUnsupervised(k-nearest neighbors) and Supervised (Support Vector Machine,\nDecision Trees, Linear Discriminant Analysis, Quadratic Discriminant Analysis,\nNaive Bayes) algorithms different categories of white blood cells to\nEosinophil, Lymphocyte, Monocyte, and Neutrophil. We even take a step forwards\nto explore various Deep Convolutional Neural network architecture (Sqeezent,\nMobilenetV1,MobilenetV2, InceptionNet etc.) without preprocessing/segmentation\nand with preprocessing. We would like to explore many algorithms to identify\nthe robust algorithm with least time complexity and low resource requirement.\nThe outcome of this work can be a cue to selection of algorithms as per\nrequirement for automated blood cell classification.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:18:19 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Bezugam", "Sai Sukruth", ""]]}, {"id": "2106.12555", "submitter": "Joel Dyer", "authors": "Joel Dyer, Patrick Cannon, Sebastian M Schmon", "title": "Approximate Bayesian Computation with Path Signatures", "comments": "27 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation models of scientific interest often lack a tractable likelihood\nfunction, precluding standard likelihood-based statistical inference. A popular\nlikelihood-free method for inferring simulator parameters is approximate\nBayesian computation, where an approximate posterior is sampled by comparing\nsimulator output and observed data. However, effective measures of closeness\nbetween simulated and observed data are generally difficult to construct,\nparticularly for time series data which are often high-dimensional and\nstructurally complex. Existing approaches typically involve manually\nconstructing summary statistics, requiring substantial domain expertise and\nexperimentation, or rely on unrealistic assumptions such as iid data. Others\nare inappropriate in more complex settings like multivariate or irregularly\nsampled time series data. In this paper, we introduce the use of path\nsignatures as a natural candidate feature set for constructing distances\nbetween time series data for use in approximate Bayesian computation\nalgorithms. Our experiments show that such an approach can generate more\naccurate approximate Bayesian posteriors than existing techniques for time\nseries models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:25:43 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Dyer", "Joel", ""], ["Cannon", "Patrick", ""], ["Schmon", "Sebastian M", ""]]}, {"id": "2106.12566", "submitter": "Shengjie Luo", "authors": "Shengjie Luo, Shanda Li, Tianle Cai, Di He, Dinglan Peng, Shuxin\n  Zheng, Guolin Ke, Liwei Wang, Tie-Yan Liu", "title": "Stable, Fast and Accurate: Kernelized Attention with Relative Positional\n  Encoding", "comments": "Preprint. Work in Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The attention module, which is a crucial component in Transformer, cannot\nscale efficiently to long sequences due to its quadratic complexity. Many works\nfocus on approximating the dot-then-exponentiate softmax function in the\noriginal attention, leading to sub-quadratic or even linear-complexity\nTransformer architectures. However, we show that these methods cannot be\napplied to more powerful attention modules that go beyond the\ndot-then-exponentiate style, e.g., Transformers with relative positional\nencoding (RPE). Since in many state-of-the-art models, relative positional\nencoding is used as default, designing efficient Transformers that can\nincorporate RPE is appealing. In this paper, we propose a novel way to\naccelerate attention calculation for Transformers with RPE on top of the\nkernelized attention. Based upon the observation that relative positional\nencoding forms a Toeplitz matrix, we mathematically show that kernelized\nattention with RPE can be calculated efficiently using Fast Fourier Transform\n(FFT). With FFT, our method achieves $\\mathcal{O}(n\\log n)$ time complexity.\nInterestingly, we further demonstrate that properly using relative positional\nencoding can mitigate the training instability problem of vanilla kernelized\nattention. On a wide range of tasks, we empirically show that our models can be\ntrained from scratch without any optimization issues. The learned model\nperforms better than many efficient Transformer variants and is faster than\nstandard Transformer in the long-sequence regime.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:51:26 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Luo", "Shengjie", ""], ["Li", "Shanda", ""], ["Cai", "Tianle", ""], ["He", "Di", ""], ["Peng", "Dinglan", ""], ["Zheng", "Shuxin", ""], ["Ke", "Guolin", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2106.12575", "submitter": "Fabrizio Frasca", "authors": "Cristian Bodnar, Fabrizio Frasca, Nina Otter, Yu Guang Wang, Pietro\n  Li\\`o, Guido Mont\\'ufar, Michael Bronstein", "title": "Weisfeiler and Lehman Go Cellular: CW Networks", "comments": "28 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are limited in their expressive power, struggle\nwith long-range interactions and lack a principled way to model higher-order\nstructures. These problems can be attributed to the strong coupling between the\ncomputational graph and the input graph structure. The recently proposed\nMessage Passing Simplicial Networks naturally decouple these elements by\nperforming message passing on the clique complex of the graph. Nevertheless,\nthese models are severely constrained by the rigid combinatorial structure of\nSimplicial Complexes (SCs). In this work, we extend recent theoretical results\non SCs to regular Cell Complexes, topological objects that flexibly subsume SCs\nand graphs. We show that this generalisation provides a powerful set of graph\n``lifting'' transformations, each leading to a unique hierarchical message\npassing procedure. The resulting methods, which we collectively call CW\nNetworks (CWNs), are strictly more powerful than the WL test and, in certain\ncases, not less powerful than the 3-WL test. In particular, we demonstrate the\neffectiveness of one such scheme, based on rings, when applied to molecular\ngraph problems. The proposed architecture benefits from provably larger\nexpressivity than commonly used GNNs, principled modelling of higher-order\nsignals and from compressing the distances between nodes. We demonstrate that\nour model achieves state-of-the-art results on a variety of molecular datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 17:59:16 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Bodnar", "Cristian", ""], ["Frasca", "Fabrizio", ""], ["Otter", "Nina", ""], ["Wang", "Yu Guang", ""], ["Li\u00f2", "Pietro", ""], ["Mont\u00fafar", "Guido", ""], ["Bronstein", "Michael", ""]]}, {"id": "2106.12611", "submitter": "Yeshwanth Cherapanamjeri", "authors": "Peter L. Bartlett, S\\'ebastien Bubeck and Yeshwanth Cherapanamjeri", "title": "Adversarial Examples in Multi-Layer Random ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the phenomenon of adversarial examples in ReLU networks with\nindependent gaussian parameters. For networks of constant depth and with a\nlarge range of widths (for instance, it suffices if the width of each layer is\npolynomial in that of any other layer), small perturbations of input vectors\nlead to large changes of outputs. This generalizes results of Daniely and\nSchacham (2020) for networks of rapidly decreasing width and of Bubeck et al\n(2021) for two-layer networks. The proof shows that adversarial examples arise\nin these networks because the functions that they compute are very close to\nlinear. Bottleneck layers in the network play a key role: the minimal width up\nto some point in the network determines scales and sensitivities of mappings\ncomputed up to that point. The main result is for networks with constant depth,\nbut we also show that some constraint on depth is necessary for a result of\nthis kind, because there are suitably deep networks that, with constant\nprobability, compute a function that is close to constant.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 18:16:34 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Bubeck", "S\u00e9bastien", ""], ["Cherapanamjeri", "Yeshwanth", ""]]}, {"id": "2106.12639", "submitter": "Robin Schmucker", "authors": "Robin Schmucker, Michele Donini, Muhammad Bilal Zafar, David Salinas,\n  C\\'edric Archambeau", "title": "Multi-objective Asynchronous Successive Halving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization (HPO) is increasingly used to automatically tune\nthe predictive performance (e.g., accuracy) of machine learning models.\nHowever, in a plethora of real-world applications, accuracy is only one of the\nmultiple -- often conflicting -- performance criteria, necessitating the\nadoption of a multi-objective (MO) perspective. While the literature on MO\noptimization is rich, few prior studies have focused on HPO. In this paper, we\npropose algorithms that extend asynchronous successive halving (ASHA) to the MO\nsetting. Considering multiple evaluation metrics, we assess the performance of\nthese methods on three real world tasks: (i) Neural architecture search, (ii)\nalgorithmic fairness and (iii) language model optimization. Our empirical\nanalysis shows that MO ASHA enables to perform MO HPO at scale. Further, we\nobserve that that taking the entire Pareto front into account for candidate\nselection consistently outperforms multi-fidelity HPO based on MO scalarization\nin terms of wall-clock time. Our algorithms (to be open-sourced) establish new\nbaselines for future research in the area.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 19:39:31 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Schmucker", "Robin", ""], ["Donini", "Michele", ""], ["Zafar", "Muhammad Bilal", ""], ["Salinas", "David", ""], ["Archambeau", "C\u00e9dric", ""]]}, {"id": "2106.12674", "submitter": "Mengnan Du", "authors": "Mengnan Du, Subhabrata Mukherjee, Guanchu Wang, Ruixiang Tang, Ahmed\n  Hassan Awadallah, Xia Hu", "title": "Fairness via Representation Neutralization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing bias mitigation methods for DNN models primarily work on learning\ndebiased encoders. This process not only requires a lot of instance-level\nannotations for sensitive attributes, it also does not guarantee that all\nfairness sensitive information has been removed from the encoder. To address\nthese limitations, we explore the following research question: Can we reduce\nthe discrimination of DNN models by only debiasing the classification head,\neven with biased representations as inputs? To this end, we propose a new\nmitigation technique, namely, Representation Neutralization for Fairness (RNF)\nthat achieves fairness by debiasing only the task-specific classification head\nof DNN models. To this end, we leverage samples with the same ground-truth\nlabel but different sensitive attributes, and use their neutralized\nrepresentations to train the classification head of the DNN model. The key idea\nof RNF is to discourage the classification head from capturing spurious\ncorrelation between fairness sensitive information in encoder representations\nwith specific class labels. To address low-resource settings with no access to\nsensitive attribute annotations, we leverage a bias-amplified model to generate\nproxy annotations for sensitive attributes. Experimental results over several\nbenchmark datasets demonstrate our RNF framework to effectively reduce\ndiscrimination of DNN models with minimal degradation in task-specific\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 22:26:29 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Du", "Mengnan", ""], ["Mukherjee", "Subhabrata", ""], ["Wang", "Guanchu", ""], ["Tang", "Ruixiang", ""], ["Awadallah", "Ahmed Hassan", ""], ["Hu", "Xia", ""]]}, {"id": "2106.12694", "submitter": "Bram van de Weg Ir.", "authors": "Bram van de Weg, Lars Greve, Bojana Rosic", "title": "Long short-term relevance learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  To incorporate prior knowledge as well as measurement uncertainties in the\ntraditional long short term memory (LSTM) neural networks, an efficient sparse\nBayesian training algorithm is introduced to the network architecture. The\nproposed scheme automatically determines relevant neural connections and adapts\naccordingly, in contrast to the classical LSTM solution. Due to its\nflexibility, the new LSTM scheme is less prone to overfitting, and hence can\napproximate time dependent solutions by use of a smaller data set. On a\nstructural nonlinear finite element application we show that the\nself-regulating framework does not require prior knowledge of a suitable\nnetwork architecture and size, while ensuring satisfying accuracy at reasonable\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 09:07:17 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["van de Weg", "Bram", ""], ["Greve", "Lars", ""], ["Rosic", "Bojana", ""]]}, {"id": "2106.12729", "submitter": "Zaiwei Chen", "authors": "Zaiwei Chen, Siva Theja Maguluri, Sanjay Shakkottai, and Karthikeyan\n  Shanmugam", "title": "Finite-Sample Analysis of Off-Policy TD-Learning via Generalized Bellman\n  Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In temporal difference (TD) learning, off-policy sampling is known to be more\npractical than on-policy sampling, and by decoupling learning from data\ncollection, it enables data reuse. It is known that policy evaluation\n(including multi-step off-policy importance sampling) has the interpretation of\nsolving a generalized Bellman equation. In this paper, we derive finite-sample\nbounds for any general off-policy TD-like stochastic approximation algorithm\nthat solves for the fixed-point of this generalized Bellman operator. Our key\nstep is to show that the generalized Bellman operator is simultaneously a\ncontraction mapping with respect to a weighted $\\ell_p$-norm for each $p$ in\n$[1,\\infty)$, with a common contraction factor.\n  Off-policy TD-learning is known to suffer from high variance due to the\nproduct of importance sampling ratios. A number of algorithms (e.g.\n$Q^\\pi(\\lambda)$, Tree-Backup$(\\lambda)$, Retrace$(\\lambda)$, and $Q$-trace)\nhave been proposed in the literature to address this issue. Our results\nimmediately imply finite-sample bounds of these algorithms. In particular, we\nprovide first-known finite-sample guarantees for $Q^\\pi(\\lambda)$,\nTree-Backup$(\\lambda)$, and Retrace$(\\lambda)$, and improve the best known\nbounds of $Q$-trace in [19]. Moreover, we show the bias-variance trade-offs in\neach of these algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 02:22:36 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Chen", "Zaiwei", ""], ["Maguluri", "Siva Theja", ""], ["Shakkottai", "Sanjay", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "2106.12751", "submitter": "Wei-Cheng Chang", "authors": "Xuanqing Liu, Wei-Cheng Chang, Hsiang-Fu Yu, Cho-Jui Hsieh, Inderjit\n  S. Dhillon", "title": "Label Disentanglement in Partition-based Extreme Multilabel\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partition-based methods are increasingly-used in extreme multi-label\nclassification (XMC) problems due to their scalability to large output spaces\n(e.g., millions or more). However, existing methods partition the large label\nspace into mutually exclusive clusters, which is sub-optimal when labels have\nmulti-modality and rich semantics. For instance, the label \"Apple\" can be the\nfruit or the brand name, which leads to the following research question: can we\ndisentangle these multi-modal labels with non-exclusive clustering tailored for\ndownstream XMC tasks? In this paper, we show that the label assignment problem\nin partition-based XMC can be formulated as an optimization problem, with the\nobjective of maximizing precision rates. This leads to an efficient algorithm\nto form flexible and overlapped label clusters, and a method that can\nalternatively optimizes the cluster assignments and the model parameters for\npartition-based XMC. Experimental results on synthetic and real datasets show\nthat our method can successfully disentangle multi-modal labels, leading to\nstate-of-the-art (SOTA) results on four XMC benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 03:24:18 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Liu", "Xuanqing", ""], ["Chang", "Wei-Cheng", ""], ["Yu", "Hsiang-Fu", ""], ["Hsieh", "Cho-Jui", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "2106.12766", "submitter": "Moein Razavi", "authors": "Samira Ziyadidegan, Moein Razavi, Homa Pesarakli, Amir Hossein Javid,\n  Madhav Erraguntla", "title": "Factors affecting the COVID-19 risk in the US counties: an innovative\n  approach by combining unsupervised and supervised learning", "comments": "15 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The COVID-19 disease spreads swiftly, and nearly three months after the first\npositive case was confirmed in China, Coronavirus started to spread all over\nthe United States. Some states and counties reported high number of positive\ncases and deaths, while some reported lower COVID-19 related cases and\nmortality. In this paper, the factors that could affect the risk of COVID-19\ninfection and mortality were analyzed in county level. An innovative method by\nusing K-means clustering and several classification models is utilized to\ndetermine the most critical factors. Results showed that mean temperature,\npercent of people below poverty, percent of adults with obesity, air pressure,\npopulation density, wind speed, longitude, and percent of uninsured people were\nthe most significant attributes\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 04:29:00 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Ziyadidegan", "Samira", ""], ["Razavi", "Moein", ""], ["Pesarakli", "Homa", ""], ["Javid", "Amir Hossein", ""], ["Erraguntla", "Madhav", ""]]}, {"id": "2106.12772", "submitter": "Polina Kirichenko", "authors": "Polina Kirichenko, Mehrdad Farajtabar, Dushyant Rao, Balaji\n  Lakshminarayanan, Nir Levine, Ang Li, Huiyi Hu, Andrew Gordon Wilson, Razvan\n  Pascanu", "title": "Task-agnostic Continual Learning with Hybrid Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning new tasks continuously without forgetting on a constantly changing\ndata distribution is essential for real-world problems but extremely\nchallenging for modern deep learning. In this work we propose HCL, a Hybrid\ngenerative-discriminative approach to Continual Learning for classification. We\nmodel the distribution of each task and each class with a normalizing flow. The\nflow is used to learn the data distribution, perform classification, identify\ntask changes, and avoid forgetting, all leveraging the invertibility and exact\nlikelihood which are uniquely enabled by the normalizing flow model. We use the\ngenerative capabilities of the flow to avoid catastrophic forgetting through\ngenerative replay and a novel functional regularization technique. For task\nidentification, we use state-of-the-art anomaly detection techniques based on\nmeasuring the typicality of the model's statistics. We demonstrate the strong\nperformance of HCL on a range of continual learning benchmarks such as\nsplit-MNIST, split-CIFAR, and SVHN-MNIST.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 05:19:26 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Kirichenko", "Polina", ""], ["Farajtabar", "Mehrdad", ""], ["Rao", "Dushyant", ""], ["Lakshminarayanan", "Balaji", ""], ["Levine", "Nir", ""], ["Li", "Ang", ""], ["Hu", "Huiyi", ""], ["Wilson", "Andrew Gordon", ""], ["Pascanu", "Razvan", ""]]}, {"id": "2106.12796", "submitter": "Quentin Duchemin", "authors": "Quentin Duchemin, Yohann De Castro and Claire Lacour", "title": "Three rates of convergence or separation via U-statistics in a dependent\n  framework", "comments": "This submission completes the submission arXiv:2011.11435v1 which has\n  been split into two pieces: concentration inequalities arXiv:2011.11435v3 and\n  further versions, and this submission about three applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the ubiquity of U-statistics in modern Probability and Statistics,\ntheir non-asymptotic analysis in a dependent framework may have been\noverlooked. In a recent work, a new concentration inequality for U-statistics\nof order two for uniformly ergodic Markov chains has been proved. In this\npaper, we put this theoretical breakthrough into action by pushing further the\ncurrent state of knowledge in three different active fields of research. First,\nwe establish a new exponential inequality for the estimation of spectra of\ntrace class integral operators with MCMC methods. The novelty is that this\nresult holds for kernels with positive and negative eigenvalues, which is new\nas far as we know. In addition, we investigate generalization performance of\nonline algorithms working with pairwise loss functions and Markov chain\nsamples. We provide an online-to-batch conversion result by showing how we can\nextract a low risk hypothesis from the sequence of hypotheses generated by any\nonline learner. We finally give a non-asymptotic analysis of a goodness-of-fit\ntest on the density of the invariant measure of a Markov chain. We identify\nsome classes of alternatives over which our test based on the $L_2$ distance\nhas a prescribed power.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 07:10:36 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Duchemin", "Quentin", ""], ["De Castro", "Yohann", ""], ["Lacour", "Claire", ""]]}, {"id": "2106.12871", "submitter": "Subhadip Maji", "authors": "Subhadip Maji, Swapna Sourav Rout and Sudeep Choudhary", "title": "DCoM: A Deep Column Mapper for Semantic Data Type Detection", "comments": "9 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detection of semantic data types is a very crucial task in data science for\nautomated data cleaning, schema matching, data discovery, semantic data type\nnormalization and sensitive data identification. Existing methods include\nregular expression-based or dictionary lookup-based methods that are not robust\nto dirty as well unseen data and are limited to a very less number of semantic\ndata types to predict. Existing Machine Learning methods extract large number\nof engineered features from data and build logistic regression, random forest\nor feedforward neural network for this purpose. In this paper, we introduce\nDCoM, a collection of multi-input NLP-based deep neural networks to detect\nsemantic data types where instead of extracting large number of features from\nthe data, we feed the raw values of columns (or instances) to the model as\ntexts. We train DCoM on 686,765 data columns extracted from VizNet corpus with\n78 different semantic data types. DCoM outperforms other contemporary results\nwith a quite significant margin on the same dataset.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 10:12:35 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Maji", "Subhadip", ""], ["Rout", "Swapna Sourav", ""], ["Choudhary", "Sudeep", ""]]}, {"id": "2106.12886", "submitter": "Shosei Sakaguchi", "authors": "Toru Kitagawa, Shosei Sakaguchi, and Aleksey Tetenov", "title": "Constrained Classification and Policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern machine learning approaches to classification, including AdaBoost,\nsupport vector machines, and deep neural networks, utilize surrogate loss\ntechniques to circumvent the computational complexity of minimizing empirical\nclassification risk. These techniques are also useful for causal policy\nlearning problems, since estimation of individualized treatment rules can be\ncast as a weighted (cost-sensitive) classification problem. Consistency of the\nsurrogate loss approaches studied in Zhang (2004) and Bartlett et al. (2006)\ncrucially relies on the assumption of correct specification, meaning that the\nspecified set of classifiers is rich enough to contain a first-best classifier.\nThis assumption is, however, less credible when the set of classifiers is\nconstrained by interpretability or fairness, leaving the applicability of\nsurrogate loss based algorithms unknown in such second-best scenarios. This\npaper studies consistency of surrogate loss procedures under a constrained set\nof classifiers without assuming correct specification. We show that in the\nsetting where the constraint restricts the classifier's prediction set only,\nhinge losses (i.e., $\\ell_1$-support vector machines) are the only surrogate\nlosses that preserve consistency in second-best scenarios. If the constraint\nadditionally restricts the functional form of the classifier, consistency of a\nsurrogate loss approach is not guaranteed even with hinge loss. We therefore\ncharacterize conditions for the constrained set of classifiers that can\nguarantee consistency of hinge risk minimizing classifiers. Exploiting our\ntheoretical results, we develop robust and computationally attractive hinge\nloss based procedures for a monotone classification problem.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 10:43:00 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Kitagawa", "Toru", ""], ["Sakaguchi", "Shosei", ""], ["Tetenov", "Aleksey", ""]]}, {"id": "2106.12887", "submitter": "Ibrahim Alabdulmohsin", "authors": "Ibrahim Alabdulmohsin and Mario Lucic", "title": "A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable post-processing algorithm for debiasing trained models,\nincluding deep neural networks (DNNs), which we prove to be near-optimal by\nbounding its excess Bayes risk. We empirically validate its advantages on\nstandard benchmark datasets across both classical algorithms as well as modern\nDNN architectures and demonstrate that it outperforms previous post-processing\nmethods while performing on par with in-processing. In addition, we show that\nthe proposed algorithm is particularly effective for models trained at scale\nwhere post-processing is a natural and practical choice.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 09:45:37 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Alabdulmohsin", "Ibrahim", ""], ["Lucic", "Mario", ""]]}, {"id": "2106.12893", "submitter": "Thomas Viehmann", "authors": "Thomas Viehmann", "title": "Partial Wasserstein and Maximum Mean Discrepancy distances for bridging\n  the gap between outlier detection and drift detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of machine learning and deep learning based applications in\npractice, monitoring, i.e. verifying that these operate within specification,\nhas become an important practical problem. An important aspect of this\nmonitoring is to check whether the inputs (or intermediates) have strayed from\nthe distribution they were validated for, which can void the performance\nassurances obtained during testing.\n  There are two common approaches for this. The, perhaps, more classical one is\noutlier detection or novelty detection, where, for a single input we ask\nwhether it is an outlier, i.e. exceedingly unlikely to have originated from a\nreference distribution. The second, perhaps more recent approach, is to\nconsider a larger number of inputs and compare its distribution to a reference\ndistribution (e.g. sampled during testing). This is done under the label drift\ndetection.\n  In this work, we bridge the gap between outlier detection and drift detection\nthrough comparing a given number of inputs to an automatically chosen part of\nthe reference distribution.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 18:49:55 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 09:17:27 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Viehmann", "Thomas", ""]]}, {"id": "2106.12936", "submitter": "Kweku Abraham", "authors": "Kweku Abraham, Zacharie Naulet, Elisabeth Gassiat", "title": "Fundamental limits for learning hidden Markov model parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the frontier between learnable and unlearnable hidden Markov models\n(HMMs). HMMs are flexible tools for clustering dependent data coming from\nunknown populations. The model parameters are known to be identifiable as soon\nas the clusters are distinct and the hidden chain is ergodic with a full rank\ntransition matrix. In the limit as any one of these conditions fails, it\nbecomes impossible to identify parameters. For a chain with two hidden states\nwe prove nonasymptotic minimax upper and lower bounds, matching up to\nconstants, which exhibit thresholds at which the parameters become learnable.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 12:02:33 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Abraham", "Kweku", ""], ["Naulet", "Zacharie", ""], ["Gassiat", "Elisabeth", ""]]}, {"id": "2106.12974", "submitter": "Jing Liu", "authors": "Jing Liu, Sujie Li, Jiang Zhang, Pan Zhang", "title": "Tensor networks for unsupervised machine learning", "comments": "12 pages, 9 figures, for Github page, see\n  https://github.com/bnuliujing/tn-for-unsup-ml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the joint distribution of high-dimensional data is a central task in\nunsupervised machine learning. In recent years, many interests have been\nattracted to developing learning models based on tensor networks, which have\nadvantages of theoretical understandings of the expressive power using\nentanglement properties, and as a bridge connecting the classical computation\nand the quantum computation. Despite the great potential, however, existing\ntensor-network-based unsupervised models only work as a proof of principle, as\ntheir performances are much worse than the standard models such as the\nrestricted Boltzmann machines and neural networks. In this work, we present the\nAutoregressive Matrix Product States (AMPS), a tensor-network-based model\ncombining the matrix product states from quantum many-body physics and the\nautoregressive models from machine learning. The model enjoys exact calculation\nof normalized probability and unbiased sampling, as well as a clear theoretical\nunderstanding of expressive power. We demonstrate the performance of our model\nusing two applications, the generative modeling on synthetic and real-world\ndata, and the reinforcement learning in statistical physics. Using extensive\nnumerical experiments, we show that the proposed model significantly\noutperforms the existing tensor-network-based models and the restricted\nBoltzmann machines, and is competitive with the state-of-the-art neural network\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 12:51:00 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Liu", "Jing", ""], ["Li", "Sujie", ""], ["Zhang", "Jiang", ""], ["Zhang", "Pan", ""]]}, {"id": "2106.12996", "submitter": "Subhro Ghosh", "authors": "Subhro Ghosh and Philippe Rigollet", "title": "Multi-Reference Alignment for sparse signals, Uniform Uncertainty\n  Principles and the Beltway Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by cutting-edge applications like cryo-electron microscopy\n(cryo-EM), the Multi-Reference Alignment (MRA) model entails the learning of an\nunknown signal from repeated measurements of its images under the latent action\nof a group of isometries and additive noise of magnitude $\\sigma$. Despite\nsignificant interest, a clear picture for understanding rates of estimation in\nthis model has emerged only recently, particularly in the high-noise regime\n$\\sigma \\gg 1$ that is highly relevant in applications. Recent investigations\nhave revealed a remarkable asymptotic sample complexity of order $\\sigma^6$ for\ncertain signals whose Fourier transforms have full support, in stark contrast\nto the traditional $\\sigma^2$ that arise in regular models. Often prohibitively\nlarge in practice, these results have prompted the investigation of variations\naround the MRA model where better sample complexity may be achieved. In this\npaper, we show that \\emph{sparse} signals exhibit an intermediate $\\sigma^4$\nsample complexity even in the classical MRA model. Our results explore and\nexploit connections of the MRA estimation problem with two classical topics in\napplied mathematics: the \\textit{beltway problem} from combinatorial\noptimization, and \\textit{uniform uncertainty principles} from harmonic\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 13:13:10 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Ghosh", "Subhro", ""], ["Rigollet", "Philippe", ""]]}, {"id": "2106.12997", "submitter": "Wesley Maddox", "authors": "Wesley J. Maddox, Maximilian Balandat, Andrew Gordon Wilson, Eytan\n  Bakshy", "title": "Bayesian Optimization with High-Dimensional Outputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian Optimization is a sample-efficient black-box optimization procedure\nthat is typically applied to problems with a small number of independent\nobjectives. However, in practice we often wish to optimize objectives defined\nover many correlated outcomes (or ``tasks\"). For example, scientists may want\nto optimize the coverage of a cell tower network across a dense grid of\nlocations. Similarly, engineers may seek to balance the performance of a robot\nacross dozens of different environments via constrained or robust optimization.\nHowever, the Gaussian Process (GP) models typically used as probabilistic\nsurrogates for multi-task Bayesian Optimization scale poorly with the number of\noutcomes, greatly limiting applicability. We devise an efficient technique for\nexact multi-task GP sampling that combines exploiting Kronecker structure in\nthe covariance matrices with Matheron's identity, allowing us to perform\nBayesian Optimization using exact multi-task GP models with tens of thousands\nof correlated outputs. In doing so, we achieve substantial improvements in\nsample efficiency compared to existing approaches that only model aggregate\nfunctions of the outcomes. We demonstrate how this unlocks a new class of\napplications for Bayesian Optimization across a range of tasks in science and\nengineering, including optimizing interference patterns of an optical\ninterferometer with more than 65,000 outputs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 13:15:12 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Maddox", "Wesley J.", ""], ["Balandat", "Maximilian", ""], ["Wilson", "Andrew Gordon", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2106.13015", "submitter": "Frank E. Curtis", "authors": "Albert S. Berahas, Frank E. Curtis, Michael J. O'Neill, Daniel P.\n  Robinson", "title": "A Stochastic Sequential Quadratic Optimization Algorithm for Nonlinear\n  Equality Constrained Optimization with Rank-Deficient Jacobians", "comments": null, "journal-ref": null, "doi": null, "report-no": "Lehigh ISE Technical Report 21T-013", "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sequential quadratic optimization algorithm is proposed for solving smooth\nnonlinear equality constrained optimization problems in which the objective\nfunction is defined by an expectation of a stochastic function. The algorithmic\nstructure of the proposed method is based on a step decomposition strategy that\nis known in the literature to be widely effective in practice, wherein each\nsearch direction is computed as the sum of a normal step (toward linearized\nfeasibility) and a tangential step (toward objective decrease in the null space\nof the constraint Jacobian). However, the proposed method is unique from others\nin the literature in that it both allows the use of stochastic objective\ngradient estimates and possesses convergence guarantees even in the setting in\nwhich the constraint Jacobians may be rank deficient. The results of numerical\nexperiments demonstrate that the algorithm offers superior performance when\ncompared to popular alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 13:46:52 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Berahas", "Albert S.", ""], ["Curtis", "Frank E.", ""], ["O'Neill", "Michael J.", ""], ["Robinson", "Daniel P.", ""]]}, {"id": "2106.13035", "submitter": "Andrea Zanetti", "authors": "Andrea Zanetti", "title": "Quantization Aware Training, ERNIE and Kurtosis Regularizer: a short\n  empirical study", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained language models like Ernie or Bert are currently used in many\napplications. These models come with a set of pre-trained weights typically\nobtained in unsupervised/self-supervised modality on a huge amount of data.\nAfter that, they are fine-tuned on a specific task. Applications then use these\nmodels for inference, and often some additional constraints apply, like low\npower-budget or low latency between input and output. The main avenue to meet\nthese additional requirements for the inference settings, is to use low\nprecision computation (e.g. INT8 rather than FP32), but this comes with a cost\nof deteriorating the functional performance (e.g. accuracy) of the model. Some\napproaches have been developed to tackle the problem and go beyond the\nlimitations of the PTO (Post-Training Quantization), more specifically the QAT\n(Quantization Aware Training, see [4]) is a procedure that interferes with the\ntraining process in order to make it affected (or simply disturbed) by the\nquantization phase during the training itself. Besides QAT, recently\nIntel-Habana Labs have proposed an additional and more direct way to make the\ntraining results more robust to subsequent quantization which uses a\nregularizer, therefore changing the loss function that drives the training\nprocedure. But their proposal does not work out-of-the-box for pre-trained\nmodels like Ernie, for example. In this short paper we show why this is not\nhappening (for the Ernie case) and we propose a very basic way to deal with it,\nsharing as well some initial results (increase in final INT8 accuracy) that\nmight be of interest to practitioners willing to use Ernie in their\napplications, in low precision regime.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 14:12:11 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 11:33:25 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zanetti", "Andrea", ""]]}, {"id": "2106.13041", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko", "title": "Unsupervised Learning of Depth and Depth-of-Field Effect from Natural\n  Images with Aperture Rendering Generative Adversarial Networks", "comments": "Accepted to CVPR 2021 (Oral). Project page:\n  https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/ar-gan/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the 3D world from 2D projected natural images is a fundamental\nchallenge in computer vision and graphics. Recently, an unsupervised learning\napproach has garnered considerable attention owing to its advantages in data\ncollection. However, to mitigate training limitations, typical methods need to\nimpose assumptions for viewpoint distribution (e.g., a dataset containing\nvarious viewpoint images) or object shape (e.g., symmetric objects). These\nassumptions often restrict applications; for instance, the application to\nnon-rigid objects or images captured from similar viewpoints (e.g., flower or\nbird images) remains a challenge. To complement these approaches, we propose\naperture rendering generative adversarial networks (AR-GANs), which equip\naperture rendering on top of GANs, and adopt focus cues to learn the depth and\ndepth-of-field (DoF) effect of unlabeled natural images. To address the\nambiguities triggered by unsupervised setting (i.e., ambiguities between smooth\ntexture and out-of-focus blurs, and between foreground and background blurs),\nwe develop DoF mixture learning, which enables the generator to learn real\nimage distribution while generating diverse DoF images. In addition, we devise\na center focus prior to guiding the learning direction. In the experiments, we\ndemonstrate the effectiveness of AR-GANs in various datasets, such as flower,\nbird, and face images, demonstrate their portability by incorporating them into\nother 3D representation learning GANs, and validate their applicability in\nshallow DoF rendering.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 14:15:50 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Kaneko", "Takuhiro", ""]]}, {"id": "2106.13055", "submitter": "Cooper Lorsung", "authors": "Cooper Lorsung", "title": "Understanding Uncertainty in Bayesian Deep Learning", "comments": "97 pages, 32 figures, Master of Engineering Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Linear Models (NLM) are deep Bayesian models that produce predictive\nuncertainty by learning features from the data and then performing Bayesian\nlinear regression over these features. Despite their popularity, few works have\nfocused on formally evaluating the predictive uncertainties of these models.\nFurthermore, existing works point out the difficulties of encoding domain\nknowledge in models like NLMs, making them unsuitable for applications where\ninterpretability is required. In this work, we show that traditional training\nprocedures for NLMs can drastically underestimate uncertainty in data-scarce\nregions. We identify the underlying reasons for this behavior and propose a\nnovel training method that can both capture useful predictive uncertainties as\nwell as allow for incorporation of domain knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 19:22:17 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Lorsung", "Cooper", ""]]}, {"id": "2106.13097", "submitter": "Shuang Li", "authors": "Shuang Li, Lu Wang, Xinyun Chen, Yixiang Fang, Yan Song", "title": "Understanding the Spread of COVID-19 Epidemic: A Spatio-Temporal Point\n  Process View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the first coronavirus case was identified in the U.S. on Jan. 21, more\nthan 1 million people in the U.S. have confirmed cases of COVID-19. This\ninfectious respiratory disease has spread rapidly across more than 3000\ncounties and 50 states in the U.S. and have exhibited evolutionary clustering\nand complex triggering patterns. It is essential to understand the complex\nspacetime intertwined propagation of this disease so that accurate prediction\nor smart external intervention can be carried out. In this paper, we model the\npropagation of the COVID-19 as spatio-temporal point processes and propose a\ngenerative and intensity-free model to track the spread of the disease. We\nfurther adopt a generative adversarial imitation learning framework to learn\nthe model parameters. In comparison with the traditional likelihood-based\nlearning methods, this imitation learning framework does not need to prespecify\nan intensity function, which alleviates the model-misspecification. Moreover,\nthe adversarial learning procedure bypasses the difficult-to-evaluate integral\ninvolved in the likelihood evaluation, which makes the model inference more\nscalable with the data and variables. We showcase the dynamic learning\nperformance on the COVID-19 confirmed cases in the U.S. and evaluate the social\ndistancing policy based on the learned generative model.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 15:26:46 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Li", "Shuang", ""], ["Wang", "Lu", ""], ["Chen", "Xinyun", ""], ["Fang", "Yixiang", ""], ["Song", "Yan", ""]]}, {"id": "2106.13194", "submitter": "Anna Bubnova", "authors": "Anna V. Bubnova, Irina Deeva, Anna V. Kalyuzhnaya", "title": "MIxBN: library for learning Bayesian networks from mixed data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new library for learning Bayesian networks from data\ncontaining discrete and continuous variables (mixed data). In addition to the\nclassical learning methods on discretized data, this library proposes its\nalgorithm that allows structural learning and parameters learning from mixed\ndata without discretization since data discretization leads to information\nloss. This algorithm based on mixed MI score function for structural learning,\nand also linear regression and Gaussian distribution approximation for\nparameters learning. The library also offers two algorithms for enumerating\ngraph structures - the greedy Hill-Climbing algorithm and the evolutionary\nalgorithm. Thus the key capabilities of the proposed library are as follows:\n(1) structural and parameters learning of a Bayesian network on discretized\ndata, (2) structural and parameters learning of a Bayesian network on mixed\ndata using the MI mixed score function and Gaussian approximation, (3)\nlaunching learning algorithms on one of two algorithms for enumerating graph\nstructures - Hill-Climbing and the evolutionary algorithm. Since the need for\nmixed data representation comes from practical necessity, the advantages of our\nimplementations are evaluated in the context of solving approximation and gap\nrecovery problems on synthetic data and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 17:19:58 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bubnova", "Anna V.", ""], ["Deeva", "Irina", ""], ["Kalyuzhnaya", "Anna V.", ""]]}, {"id": "2106.13275", "submitter": "Lesia Semenova", "authors": "Alex Oesterling, Angikar Ghosal, Haoyang Yu, Rui Xin, Yasa Baig, Lesia\n  Semenova, Cynthia Rudin", "title": "Multitask Learning for Citation Purpose Classification", "comments": "Second Workshop on Scholarly Document Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present our entry into the 2021 3C Shared Task Citation Context\nClassification based on Purpose competition. The goal of the competition is to\nclassify a citation in a scientific article based on its purpose. This task is\nimportant because it could potentially lead to more comprehensive ways of\nsummarizing the purpose and uses of scientific articles, but it is also\ndifficult, mainly due to the limited amount of available training data in which\nthe purposes of each citation have been hand-labeled, along with the\nsubjectivity of these labels. Our entry in the competition is a multi-task\nmodel that combines multiple modules designed to handle the problem from\ndifferent perspectives, including hand-generated linguistic features, TF-IDF\nfeatures, and an LSTM-with-attention model. We also provide an ablation study\nand feature analysis whose insights could lead to future work.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 18:57:26 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Oesterling", "Alex", ""], ["Ghosal", "Angikar", ""], ["Yu", "Haoyang", ""], ["Xin", "Rui", ""], ["Baig", "Yasa", ""], ["Semenova", "Lesia", ""], ["Rudin", "Cynthia", ""]]}, {"id": "2106.13326", "submitter": "Ruth Urner", "authors": "Sadia Chowdhury and Ruth Urner", "title": "On the (Un-)Avoidability of Adversarial Examples", "comments": "ICML 2021 Workshop on Theoretic Foundation, Criticism, and\n  Application Trend of Explainable AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phenomenon of adversarial examples in deep learning models has caused\nsubstantial concern over their reliability. While many deep neural networks\nhave shown impressive performance in terms of predictive accuracy, it has been\nshown that in many instances an imperceptible perturbation can falsely flip the\nnetwork's prediction. Most research has then focused on developing defenses\nagainst adversarial attacks or learning under a worst-case adversarial loss. In\nthis work, we take a step back and aim to provide a framework for determining\nwhether a model's label change under small perturbation is justified (and when\nit is not). We carefully argue that adversarial robustness should be defined as\na locally adaptive measure complying with the underlying distribution. We then\nsuggest a definition for an adaptive robust loss, derive an empirical version\nof it, and develop a resulting data-augmentation framework. We prove that our\nadaptive data-augmentation maintains consistency of 1-nearest neighbor\nclassification under deterministic labels and provide illustrative empirical\nevaluations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 21:35:25 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Chowdhury", "Sadia", ""], ["Urner", "Ruth", ""]]}, {"id": "2106.13379", "submitter": "Rui Meng", "authors": "Rui Meng, Kristofer Bouchard", "title": "Bayesian Inference in High-Dimensional Time-Serieswith the Orthogonal\n  Stochastic Linear Mixing Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern time-series datasets contain large numbers of output response\nvariables sampled for prolonged periods of time. For example, in neuroscience,\nthe activities of 100s-1000's of neurons are recorded during behaviors and in\nresponse to sensory stimuli. Multi-output Gaussian process models leverage the\nnonparametric nature of Gaussian processes to capture structure across multiple\noutputs. However, this class of models typically assumes that the correlations\nbetween the output response variables are invariant in the input space.\nStochastic linear mixing models (SLMM) assume the mixture coefficients depend\non input, making them more flexible and effective to capture complex output\ndependence. However, currently, the inference for SLMMs is intractable for\nlarge datasets, making them inapplicable to several modern time-series\nproblems. In this paper, we propose a new regression framework, the orthogonal\nstochastic linear mixing model (OSLMM) that introduces an orthogonal constraint\namongst the mixing coefficients. This constraint reduces the computational\nburden of inference while retaining the capability to handle complex output\ndependence. We provide Markov chain Monte Carlo inference procedures for both\nSLMM and OSLMM and demonstrate superior model scalability and reduced\nprediction error of OSLMM compared with state-of-the-art methods on several\nreal-world applications. In neurophysiology recordings, we use the inferred\nlatent functions for compact visualization of population responses to auditory\nstimuli, and demonstrate superior results compared to a competing method\n(GPFA). Together, these results demonstrate that OSLMM will be useful for the\nanalysis of diverse, large-scale time-series datasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 01:12:54 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Meng", "Rui", ""], ["Bouchard", "Kristofer", ""]]}, {"id": "2106.13414", "submitter": "Gautam Kamath", "authors": "Cl\\'ement L. Canonne, Ayush Jain, Gautam Kamath, Jerry Li", "title": "The Price of Tolerance in Distribution Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of tolerant distribution testing. That is, given\nsamples from an unknown distribution $p$ over $\\{1, \\dots, n\\}$, is it\n$\\varepsilon_1$-close to or $\\varepsilon_2$-far from a reference distribution\n$q$ (in total variation distance)? Despite significant interest over the past\ndecade, this problem is well understood only in the extreme cases. In the\nnoiseless setting (i.e., $\\varepsilon_1 = 0$) the sample complexity is\n$\\Theta(\\sqrt{n})$, strongly sublinear in the domain size. At the other end of\nthe spectrum, when $\\varepsilon_1 = \\varepsilon_2/2$, the sample complexity\njumps to the barely sublinear $\\Theta(n/\\log n)$. However, very little is known\nabout the intermediate regime. We fully characterize the price of tolerance in\ndistribution testing as a function of $n$, $\\varepsilon_1$, $\\varepsilon_2$, up\nto a single $\\log n$ factor. Specifically, we show the sample complexity to be\n\\[\\tilde \\Theta\\left(\\frac{\\sqrt{n}}{\\varepsilon_2^{2}} + \\frac{n}{\\log n}\n\\cdot \\max\n\\left\\{\\frac{\\varepsilon_1}{\\varepsilon_2^2},\\left(\\frac{\\varepsilon_1}{\\varepsilon_2^2}\\right)^{\\!\\!2}\\right\\}\\right),\\]\nproviding a smooth tradeoff between the two previously known cases. We also\nprovide a similar characterization for the problem of tolerant equivalence\ntesting, where both $p$ and $q$ are unknown. Surprisingly, in both cases, the\nmain quantity dictating the sample complexity is the ratio\n$\\varepsilon_1/\\varepsilon_2^2$, and not the more intuitive\n$\\varepsilon_1/\\varepsilon_2$. Of particular technical interest is our lower\nbound framework, which involves novel approximation-theoretic tools required to\nhandle the asymmetry between $\\varepsilon_1$ and $\\varepsilon_2$, a challenge\nabsent from previous works.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 03:59:42 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Jain", "Ayush", ""], ["Kamath", "Gautam", ""], ["Li", "Jerry", ""]]}, {"id": "2106.13423", "submitter": "Han Xie", "authors": "Han Xie, Jing Ma, Li Xiong, Carl Yang", "title": "Federated Graph Classification over Non-IID Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has emerged as an important paradigm for training machine\nlearning models in different domains. For graph-level tasks such as graph\nclassification, graphs can also be regarded as a special type of data samples,\nwhich can be collected and stored in separate local systems. Similar to other\ndomains, multiple local systems, each holding a small set of graphs, may\nbenefit from collaboratively training a powerful graph mining model, such as\nthe popular graph neural networks (GNNs). To provide more motivation towards\nsuch endeavors, we analyze real-world graphs from different domains to confirm\nthat they indeed share certain graph properties that are statistically\nsignificant compared with random graphs. However, we also find that different\nsets of graphs, even from the same domain or same dataset, are non-IID\nregarding both graph structures and node features. To handle this, we propose a\ngraph clustered federated learning (GCFL) framework that dynamically finds\nclusters of local systems based on the gradients of GNNs, and theoretically\njustify that such clusters can reduce the structure and feature heterogeneity\namong graphs owned by the local systems. Moreover, we observe the gradients of\nGNNs to be rather fluctuating in GCFL which impedes high-quality clustering,\nand design a gradient sequence-based clustering mechanism based on dynamic time\nwarping (GCFL+). Extensive experimental results and in-depth analysis\ndemonstrate the effectiveness of our proposed frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 04:25:29 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 14:04:43 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Xie", "Han", ""], ["Ma", "Jing", ""], ["Xiong", "Li", ""], ["Yang", "Carl", ""]]}, {"id": "2106.13624", "submitter": "Yi-Shan Wu", "authors": "Yi-Shan Wu, Andr\\'es R. Masegosa, Stephan S. Lorenzen, Christian Igel,\n  Yevgeny Seldin", "title": "Chebyshev-Cantelli PAC-Bayes-Bennett Inequality for the Weighted\n  Majority Vote", "comments": "arXiv admin note: text overlap with arXiv:2007.13532", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new second-order oracle bound for the expected risk of a\nweighted majority vote. The bound is based on a novel parametric form of the\nChebyshev-Cantelli inequality (a.k.a.\\ one-sided Chebyshev's), which is\namenable to efficient minimization. The new form resolves the optimization\nchallenge faced by prior oracle bounds based on the Chebyshev-Cantelli\ninequality, the C-bounds [Germain et al., 2015], and, at the same time, it\nimproves on the oracle bound based on second order Markov's inequality\nintroduced by Masegosa et al. [2020]. We also derive the PAC-Bayes-Bennett\ninequality, which we use for empirical estimation of the oracle bound. The\nPAC-Bayes-Bennett inequality improves on the PAC-Bayes-Bernstein inequality by\nSeldin et al. [2012]. We provide an empirical evaluation demonstrating that the\nnew bounds can improve on the work by Masegosa et al. [2020]. Both the\nparametric form of the Chebyshev-Cantelli inequality and the PAC-Bayes-Bennett\ninequality may be of independent interest for the study of concentration of\nmeasure in other domains.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 13:23:20 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Wu", "Yi-Shan", ""], ["Masegosa", "Andr\u00e9s R.", ""], ["Lorenzen", "Stephan S.", ""], ["Igel", "Christian", ""], ["Seldin", "Yevgeny", ""]]}, {"id": "2106.13642", "submitter": "Carolin Lawrence", "authors": "Jun Cheng, Carolin Lawrence, Mathias Niepert", "title": "VEGN: Variant Effect Prediction with Graph Neural Networks", "comments": "Accepted at Workshop on Computational Biology, co-located with the\n  38th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic mutations can cause disease by disrupting normal gene function.\nIdentifying the disease-causing mutations from millions of genetic variants\nwithin an individual patient is a challenging problem. Computational methods\nwhich can prioritize disease-causing mutations have, therefore, enormous\napplications. It is well-known that genes function through a complex regulatory\nnetwork. However, existing variant effect prediction models only consider a\nvariant in isolation. In contrast, we propose VEGN, which models variant effect\nprediction using a graph neural network (GNN) that operates on a heterogeneous\ngraph with genes and variants. The graph is created by assigning variants to\ngenes and connecting genes with an gene-gene interaction network. In this\ncontext, we explore an approach where a gene-gene graph is given and another\nwhere VEGN learns the gene-gene graph and therefore operates both on given and\nlearnt edges. The graph neural network is trained to aggregate information\nbetween genes, and between genes and variants. Variants can exchange\ninformation via the genes they connect to. This approach improves the\nperformance of existing state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 13:51:46 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Cheng", "Jun", ""], ["Lawrence", "Carolin", ""], ["Niepert", "Mathias", ""]]}, {"id": "2106.13669", "submitter": "Chengshuai Shi", "authors": "Chengshuai Shi, Cong Shen", "title": "Multi-player Multi-armed Bandits with Collision-Dependent Reward\n  Distributions", "comments": "17 pages, 14 figures. Accepted to IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a new stochastic multi-player multi-armed bandits (MP-MAB) problem,\nwhere the reward distribution changes if a collision occurs on the arm.\nExisting literature always assumes a zero reward for involved players if\ncollision happens, but for applications such as cognitive radio, the more\nrealistic scenario is that collision reduces the mean reward but not\nnecessarily to zero. We focus on the more practical no-sensing setting where\nplayers do not perceive collisions directly, and propose the Error-Correction\nCollision Communication (EC3) algorithm that models implicit communication as a\nreliable communication over noisy channel problem, for which random coding\nerror exponent is used to establish the optimal regret that no communication\nprotocol can beat. Finally, optimizing the tradeoff between code length and\ndecoding error rate leads to a regret that approaches the centralized MP-MAB\nregret, which represents a natural lower bound. Experiments with practical\nerror-correction codes on both synthetic and real-world datasets demonstrate\nthe superiority of EC3. In particular, the results show that the choice of\ncoding schemes has a profound impact on the regret performance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 14:39:34 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Shi", "Chengshuai", ""], ["Shen", "Cong", ""]]}, {"id": "2106.13681", "submitter": "Haiyan Jiang", "authors": "Haiyan Jiang, Shuyu Li, Luwei Zhang, Haoyi Xiong, Dejing Dou", "title": "Robust Matrix Factorization with Grouping Effect", "comments": "22 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many techniques have been applied to matrix factorization (MF), they\nmay not fully exploit the feature structure. In this paper, we incorporate the\ngrouping effect into MF and propose a novel method called Robust Matrix\nFactorization with Grouping effect (GRMF). The grouping effect is a\ngeneralization of the sparsity effect, which conducts denoising by clustering\nsimilar values around multiple centers instead of just around 0. Compared with\nexisting algorithms, the proposed GRMF can automatically learn the grouping\nstructure and sparsity in MF without prior knowledge, by introducing a\nnaturally adjustable non-convex regularization to achieve simultaneous sparsity\nand grouping effect. Specifically, GRMF uses an efficient alternating\nminimization framework to perform MF, in which the original non-convex problem\nis first converted into a convex problem through Difference-of-Convex (DC)\nprogramming, and then solved by Alternating Direction Method of Multipliers\n(ADMM). In addition, GRMF can be easily extended to the Non-negative Matrix\nFactorization (NMF) settings. Extensive experiments have been conducted using\nreal-world data sets with outliers and contaminated noise, where the\nexperimental results show that GRMF has promoted performance and robustness,\ncompared to five benchmark algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 15:03:52 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 12:04:14 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Jiang", "Haiyan", ""], ["Li", "Shuyu", ""], ["Zhang", "Luwei", ""], ["Xiong", "Haoyi", ""], ["Dou", "Dejing", ""]]}, {"id": "2106.13682", "submitter": "Zoe Guan", "authors": "Zoe Guan, Giovanni Parmigiani, Danielle Braun, and Lorenzo Trippa", "title": "Prediction of Hereditary Cancers Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Family history is a major risk factor for many types of cancer. Mendelian\nrisk prediction models translate family histories into cancer risk predictions\nbased on knowledge of cancer susceptibility genes. These models are widely used\nin clinical practice to help identify high-risk individuals. Mendelian models\nleverage the entire family history, but they rely on many assumptions about\ncancer susceptibility genes that are either unrealistic or challenging to\nvalidate due to low mutation prevalence. Training more flexible models, such as\nneural networks, on large databases of pedigrees can potentially lead to\naccuracy gains. In this paper, we develop a framework to apply neural networks\nto family history data and investigate their ability to learn inherited\nsusceptibility to cancer. While there is an extensive literature on neural\nnetworks and their state-of-the-art performance in many tasks, there is little\nwork applying them to family history data. We propose adaptations of\nfully-connected neural networks and convolutional neural networks to pedigrees.\nIn data simulated under Mendelian inheritance, we demonstrate that our proposed\nneural network models are able to achieve nearly optimal prediction\nperformance. Moreover, when the observed family history includes misreported\ncancer diagnoses, neural networks are able to outperform the Mendelian BRCAPRO\nmodel embedding the correct inheritance laws. Using a large dataset of over\n200,000 family histories, the Risk Service cohort, we train prediction models\nfor future risk of breast cancer. We validate the models using data from the\nCancer Genetics Network.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 15:06:16 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Guan", "Zoe", ""], ["Parmigiani", "Giovanni", ""], ["Braun", "Danielle", ""], ["Trippa", "Lorenzo", ""]]}, {"id": "2106.13683", "submitter": "Chengjing Wang", "authors": "Peipei Tang, Chengjing Wang and Bo Jiang", "title": "A proximal-proximal majorization-minimization algorithm for nonconvex\n  tuning-free robust regression problems", "comments": "31 pages, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we introduce a proximal-proximal majorization-minimization\n(PPMM) algorithm for nonconvex tuning-free robust regression problems. The\nbasic idea is to apply the proximal majorization-minimization algorithm to\nsolve the nonconvex problem with the inner subproblems solved by a sparse\nsemismooth Newton (SSN) method based proximal point algorithm (PPA). We must\nemphasize that the main difficulty in the design of the algorithm lies in how\nto overcome the singular difficulty of the inner subproblem. Furthermore, we\nalso prove that the PPMM algorithm converges to a d-stationary point. Due to\nthe Kurdyka-Lojasiewicz (KL) property of the problem, we present the\nconvergence rate of the PPMM algorithm. Numerical experiments demonstrate that\nour proposed algorithm outperforms the existing state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 15:07:13 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Tang", "Peipei", ""], ["Wang", "Chengjing", ""], ["Jiang", "Bo", ""]]}, {"id": "2106.13685", "submitter": "Haiyan Jiang", "authors": "Haiyan Jiang, Shanshan Qin, Dejing Dou", "title": "Feature Grouping and Sparse Principal Component Analysis", "comments": "21 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Principal Component Analysis (SPCA) is widely used in data processing\nand dimension reduction; it uses the lasso to produce modified principal\ncomponents with sparse loadings for better interpretability. However, sparse\nPCA never considers an additional grouping structure where the loadings share\nsimilar coefficients (i.e., feature grouping), besides a special group with all\ncoefficients being zero (i.e., feature selection). In this paper, we propose a\nnovel method called Feature Grouping and Sparse Principal Component Analysis\n(FGSPCA) which allows the loadings to belong to disjoint homogeneous groups,\nwith sparsity as a special case. The proposed FGSPCA is a subspace learning\nmethod designed to simultaneously perform grouping pursuit and feature\nselection, by imposing a non-convex regularization with naturally adjustable\nsparsity and grouping effect. To solve the resulting non-convex optimization\nproblem, we propose an alternating algorithm that incorporates the\ndifference-of-convex programming, augmented Lagrange and coordinate descent\nmethods. Additionally, the experimental results on real data sets show that the\nproposed FGSPCA benefits from the grouping effect compared with methods without\ngrouping effect.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 15:08:39 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Jiang", "Haiyan", ""], ["Qin", "Shanshan", ""], ["Dou", "Dejing", ""]]}, {"id": "2106.13694", "submitter": "Keisuke Yano", "authors": "Yukito Iba and Keisuke Yano", "title": "Posterior Covariance Information Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an information criterion, PCIC, for predictive evaluation based\non quasi-posterior distributions. It is regarded as a natural generalisation of\nthe widely applicable information criterion (WAIC) and can be computed via a\nsingle Markov chain Monte Carlo run. PCIC is useful in a variety of predictive\nsettings that are not well dealt with in WAIC, including weighted likelihood\ninference and quasi-Bayesian prediction\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 15:28:36 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 05:22:53 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 05:32:44 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Iba", "Yukito", ""], ["Yano", "Keisuke", ""]]}, {"id": "2106.13718", "submitter": "Onur Teymur", "authors": "Onur Teymur, Christopher N. Foley, Philip G. Breen, Toni Karvonen,\n  Chris. J. Oates", "title": "Black Box Probabilistic Numerics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic numerics casts numerical tasks, such the numerical solution of\ndifferential equations, as inference problems to be solved. One approach is to\nmodel the unknown quantity of interest as a random variable, and to constrain\nthis variable using data generated during the course of a traditional numerical\nmethod. However, data may be nonlinearly related to the quantity of interest,\nrendering the proper conditioning of random variables difficult and limiting\nthe range of numerical tasks that can be addressed. Instead, this paper\nproposes to construct probabilistic numerical methods based only on the final\noutput from a traditional method. A convergent sequence of approximations to\nthe quantity of interest constitute a dataset, from which the limiting quantity\nof interest can be extrapolated, in a probabilistic analogue of Richardson's\ndeferred approach to the limit. This black box approach (1) massively expands\nthe range of tasks to which probabilistic numerics can be applied, (2) inherits\nthe features and performance of state-of-the-art numerical methods, and (3)\nenables provably higher orders of convergence to be achieved. Applications are\npresented for nonlinear ordinary and partial differential equations, as well as\nfor eigenvalue problems-a setting for which no probabilistic numerical methods\nhave yet been developed.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 11:21:10 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Teymur", "Onur", ""], ["Foley", "Christopher N.", ""], ["Breen", "Philip G.", ""], ["Karvonen", "Toni", ""], ["Oates", "Chris. J.", ""]]}, {"id": "2106.13746", "submitter": "Ning Miao", "authors": "Ning Miao, Emile Mathieu, N. Siddharth, Yee Whye Teh, Tom Rainforth", "title": "InteL-VAEs: Adding Inductive Biases to Variational Auto-Encoders via\n  Intermediary Latents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a simple and effective method for learning VAEs with\ncontrollable inductive biases by using an intermediary set of latent variables.\nThis allows us to overcome the limitations of the standard Gaussian prior\nassumption. In particular, it allows us to impose desired properties like\nsparsity or clustering on learned representations, and incorporate prior\ninformation into the learned model. Our approach, which we refer to as the\nIntermediary Latent Space VAE (InteL-VAE), is based around controlling the\nstochasticity of the encoding process with the intermediary latent variables,\nbefore deterministically mapping them forward to our target latent\nrepresentation, from which reconstruction is performed. This allows us to\nmaintain all the advantages of the traditional VAE framework, while\nincorporating desired prior information, inductive biases, and even topological\ninformation through the latent mapping. We show that this, in turn, allows\nInteL-VAEs to learn both better generative models and representations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 16:34:05 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Miao", "Ning", ""], ["Mathieu", "Emile", ""], ["Siddharth", "N.", ""], ["Teh", "Yee Whye", ""], ["Rainforth", "Tom", ""]]}, {"id": "2106.13756", "submitter": "Alireza Fallah", "authors": "Hilal Asi, John Duchi, Alireza Fallah, Omid Javidbakht, Kunal Talwar", "title": "Private Adaptive Gradient Methods for Convex Optimization", "comments": "To appear in 38th International Conference on Machine Learning (ICML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adaptive methods for differentially private convex optimization,\nproposing and analyzing differentially private variants of a Stochastic\nGradient Descent (SGD) algorithm with adaptive stepsizes, as well as the\nAdaGrad algorithm. We provide upper bounds on the regret of both algorithms and\nshow that the bounds are (worst-case) optimal. As a consequence of our\ndevelopment, we show that our private versions of AdaGrad outperform adaptive\nSGD, which in turn outperforms traditional SGD in scenarios with non-isotropic\ngradients where (non-private) Adagrad provably outperforms SGD. The major\nchallenge is that the isotropic noise typically added for privacy dominates the\nsignal in gradient geometry for high-dimensional problems; approaches to this\nthat effectively optimize over lower-dimensional subspaces simply ignore the\nactual problems that varying gradient geometries introduce. In contrast, we\nstudy non-isotropic clipping and noise addition, developing a principled\ntheoretical approach; the consequent procedures also enjoy significantly\nstronger empirical performance than prior approaches.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 16:46:45 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Asi", "Hilal", ""], ["Duchi", "John", ""], ["Fallah", "Alireza", ""], ["Javidbakht", "Omid", ""], ["Talwar", "Kunal", ""]]}, {"id": "2106.13781", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Yuejiao Sun, and Wotao Yin", "title": "Tighter Analysis of Alternating Stochastic Gradient Method for\n  Stochastic Nested Problems", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic nested optimization, including stochastic compositional, min-max\nand bilevel optimization, is gaining popularity in many machine learning\napplications. While the three problems share the nested structure, existing\nworks often treat them separately, and thus develop problem-specific algorithms\nand their analyses. Among various exciting developments, simple SGD-type\nupdates (potentially on multiple variables) are still prevalent in solving this\nclass of nested problems, but they are believed to have slower convergence rate\ncompared to that of the non-nested problems. This paper unifies several\nSGD-type updates for stochastic nested problems into a single SGD approach that\nwe term ALternating Stochastic gradient dEscenT (ALSET) method. By leveraging\nthe hidden smoothness of the problem, this paper presents a tighter analysis of\nALSET for stochastic nested problems. Under the new analysis, to achieve an\n$\\epsilon$-stationary point of the nested problem, it requires ${\\cal\nO}(\\epsilon^{-2})$ samples. Under certain regularity conditions, applying our\nresults to stochastic compositional, min-max and reinforcement learning\nproblems either improves or matches the best-known sample complexity in the\nrespective cases. Our results explain why simple SGD-type algorithms in\nstochastic nested problems all work very well in practice without the need for\nfurther modifications.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:33:51 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Chen", "Tianyi", ""], ["Sun", "Yuejiao", ""], ["Yin", "Wotao", ""]]}, {"id": "2106.13790", "submitter": "Som Dhulipala", "authors": "S. L. N. Dhulipala, M. D. Shields, B. W. Spencer, C. Bolisetti, A. E.\n  Slaughter, V. M. Laboure, P. Chakroborty", "title": "Active Learning with Multifidelity Modeling for Efficient Rare Event\n  Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  While multifidelity modeling provides a cost-effective way to conduct\nuncertainty quantification with computationally expensive models, much greater\nefficiency can be achieved by adaptively deciding the number of required\nhigh-fidelity (HF) simulations, depending on the type and complexity of the\nproblem and the desired accuracy in the results. We propose a framework for\nactive learning with multifidelity modeling emphasizing the efficient\nestimation of rare events. Our framework works by fusing a low-fidelity (LF)\nprediction with an HF-inferred correction, filtering the corrected LF\nprediction to decide whether to call the high-fidelity model, and for enhanced\nsubsequent accuracy, adapting the correction for the LF prediction after every\nHF model call. The framework does not make any assumptions as to the LF model\ntype or its correlations with the HF model. In addition, for improved\nrobustness when estimating smaller failure probabilities, we propose using\ndynamic active learning functions that decide when to call the HF model. We\ndemonstrate our framework using several academic case studies and two finite\nelement (FE) model case studies: estimating Navier-Stokes velocities using the\nStokes approximation and estimating stresses in a transversely isotropic model\nsubjected to displacements via a coarsely meshed isotropic model. Across these\ncase studies, not only did the proposed framework estimate the failure\nprobabilities accurately, but compared with either Monte Carlo or a standard\nvariance reduction method, it also required only a small fraction of the calls\nto the HF model.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:44:28 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Dhulipala", "S. L. N.", ""], ["Shields", "M. D.", ""], ["Spencer", "B. W.", ""], ["Bolisetti", "C.", ""], ["Slaughter", "A. E.", ""], ["Laboure", "V. M.", ""], ["Chakroborty", "P.", ""]]}, {"id": "2106.13792", "submitter": "Quanquan Gu", "authors": "Spencer Frei and Quanquan Gu", "title": "Proxy Convexity: A Unified Framework for the Analysis of Neural Networks\n  Trained by Gradient Descent", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the optimization objectives for learning neural networks are highly\nnon-convex, gradient-based methods have been wildly successful at learning\nneural networks in practice. This juxtaposition has led to a number of recent\nstudies on provable guarantees for neural networks trained by gradient descent.\nUnfortunately, the techniques in these works are often highly specific to the\nproblem studied in each setting, relying on different assumptions on the\ndistribution, optimization parameters, and network architectures, making it\ndifficult to generalize across different settings. In this work, we propose a\nunified non-convex optimization framework for the analysis of neural network\ntraining. We introduce the notions of proxy convexity and proxy\nPolyak-Lojasiewicz (PL) inequalities, which are satisfied if the original\nobjective function induces a proxy objective function that is implicitly\nminimized when using gradient methods. We show that stochastic gradient descent\n(SGD) on objectives satisfying proxy convexity or the proxy PL inequality leads\nto efficient guarantees for proxy objective functions. We further show that\nmany existing guarantees for neural networks trained by gradient descent can be\nunified through proxy convexity and proxy PL inequalities.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:45:00 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 14:26:17 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Frei", "Spencer", ""], ["Gu", "Quanquan", ""]]}, {"id": "2106.13798", "submitter": "Babak Esmaeili", "authors": "Hao Wu, Babak Esmaeili, Michael Wick, Jean-Baptiste Tristan,\n  Jan-Willem van de Meent", "title": "Conjugate Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose conjugate energy-based models (CEBMs), a new class\nof energy-based models that define a joint density over data and latent\nvariables. The joint density of a CEBM decomposes into an intractable\ndistribution over data and a tractable posterior over latent variables. CEBMs\nhave similar use cases as variational autoencoders, in the sense that they\nlearn an unsupervised mapping from data to latent variables. However, these\nmodels omit a generator network, which allows them to learn more flexible\nnotions of similarity between data points. Our experiments demonstrate that\nconjugate EBMs achieve competitive results in terms of image modelling,\npredictive power of latent space, and out-of-domain detection on a variety of\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:51:41 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Wu", "Hao", ""], ["Esmaeili", "Babak", ""], ["Wick", "Michael", ""], ["Tristan", "Jean-Baptiste", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "2106.13799", "submitter": "Vaishnavh Nagarajan", "authors": "Yiding Jiang, Vaishnavh Nagarajan, Christina Baek, J. Zico Kolter", "title": "Assessing Generalization of SGD via Disagreement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically show that the test error of deep networks can be estimated by\nsimply training the same architecture on the same training set but with a\ndifferent run of Stochastic Gradient Descent (SGD), and measuring the\ndisagreement rate between the two networks on unlabeled test data. This builds\non -- and is a stronger version of -- the observation in Nakkiran & Bansal '20,\nwhich requires the second run to be on an altogether fresh training set. We\nfurther theoretically show that this peculiar phenomenon arises from the\n\\emph{well-calibrated} nature of \\emph{ensembles} of SGD-trained models. This\nfinding not only provides a simple empirical measure to directly predict the\ntest error using unlabeled test data, but also establishes a new conceptual\nconnection between generalization and calibration.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:53:09 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Jiang", "Yiding", ""], ["Nagarajan", "Vaishnavh", ""], ["Baek", "Christina", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2106.13805", "submitter": "Quanquan Gu", "authors": "Spencer Frei and Difan Zou and Zixiang Chen and Quanquan Gu", "title": "Self-training Converts Weak Learners to Strong Learners in Mixture\n  Models", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a binary classification problem when the data comes from a\nmixture of two isotropic distributions satisfying concentration and\nanti-concentration properties enjoyed by log-concave distributions among\nothers. We show that there exists a universal constant $C_{\\mathrm{err}}>0$\nsuch that if a pseudolabeler $\\boldsymbol{\\beta}_{\\mathrm{pl}}$ can achieve\nclassification error at most $C_{\\mathrm{err}}$, then for any $\\varepsilon>0$,\nan iterative self-training algorithm initialized at $\\boldsymbol{\\beta}_0 :=\n\\boldsymbol{\\beta}_{\\mathrm{pl}}$ using pseudolabels $\\hat y =\n\\mathrm{sgn}(\\langle \\boldsymbol{\\beta}_t, \\mathbf{x}\\rangle)$ and using at\nmost $\\tilde O(d/\\varepsilon^2)$ unlabeled examples suffices to learn the\nBayes-optimal classifier up to $\\varepsilon$ error, where $d$ is the ambient\ndimension. That is, self-training converts weak learners to strong learners\nusing only unlabeled examples. We additionally show that by running gradient\ndescent on the logistic loss one can obtain a pseudolabeler\n$\\boldsymbol{\\beta}_{\\mathrm{pl}}$ with classification error $C_{\\mathrm{err}}$\nusing only $O(d)$ labeled examples (i.e., independent of $\\varepsilon$).\nTogether our results imply that mixture models can be learned to within\n$\\varepsilon$ of the Bayes-optimal accuracy using at most $O(d)$ labeled\nexamples and $\\tilde O(d/\\varepsilon^2)$ unlabeled examples by way of a\nsemi-supervised self-training algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:59:16 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 02:27:34 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Frei", "Spencer", ""], ["Zou", "Difan", ""], ["Chen", "Zixiang", ""], ["Gu", "Quanquan", ""]]}, {"id": "2106.13870", "submitter": "Stephanie Tsuei", "authors": "Stephanie Tsuei, Aditya Golatkar, Stefano Soatto", "title": "Scene Uncertainty and the Wellington Posterior of Deterministic Image\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCLA CS Report #210001", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to estimate the uncertainty of the outcome of an image\nclassifier on a given input datum. Deep neural networks commonly used for image\nclassification are deterministic maps from an input image to an output class.\nAs such, their outcome on a given datum involves no uncertainty, so we must\nspecify what variability we are referring to when defining, measuring and\ninterpreting \"confidence.\" To this end, we introduce the Wellington Posterior,\nwhich is the distribution of outcomes that would have been obtained in response\nto data that could have been generated by the same scene that produced the\ngiven image. Since there are infinitely many scenes that could have generated\nthe given image, the Wellington Posterior requires induction from scenes other\nthan the one portrayed. We explore alternate methods using data augmentation,\nensembling, and model linearization. Additional alternatives include generative\nadversarial networks, conditional prior networks, and supervised single-view\nreconstruction. We test these alternatives against the empirical posterior\nobtained by inferring the class of temporally adjacent frames in a video. These\ndevelopments are only a small step towards assessing the reliability of deep\nnetwork classifiers in a manner that is compatible with safety-critical\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 20:10:00 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tsuei", "Stephanie", ""], ["Golatkar", "Aditya", ""], ["Soatto", "Stefano", ""]]}, {"id": "2106.13880", "submitter": "Zhao Kang", "authors": "Zhao Kang, Hongfei Liu, Jiangxin Li, Xiaofeng Zhu, and Ling Tian", "title": "Self-paced Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) has been widely used for dimensionality\nreduction and feature extraction. Robust PCA (RPCA), under different robust\ndistance metrics, such as l1-norm and l2, p-norm, can deal with noise or\noutliers to some extent. However, real-world data may display structures that\ncan not be fully captured by these simple functions. In addition, existing\nmethods treat complex and simple samples equally. By contrast, a learning\npattern typically adopted by human beings is to learn from simple to complex\nand less to more. Based on this principle, we propose a novel method called\nSelf-paced PCA (SPCA) to further reduce the effect of noise and outliers.\nNotably, the complexity of each sample is calculated at the beginning of each\niteration in order to integrate samples from simple to more complex into\ntraining. Based on an alternating optimization, SPCA finds an optimal\nprojection matrix and filters out outliers iteratively. Theoretical analysis is\npresented to show the rationality of SPCA. Extensive experiments on popular\ndata sets demonstrate that the proposed method can improve the state of-the-art\nresults considerably.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 20:50:45 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kang", "Zhao", ""], ["Liu", "Hongfei", ""], ["Li", "Jiangxin", ""], ["Zhu", "Xiaofeng", ""], ["Tian", "Ling", ""]]}, {"id": "2106.13897", "submitter": "Yatin Dandi", "authors": "Yatin Dandi, Luis Barba, Martin Jaggi", "title": "Implicit Gradient Alignment in Distributed and Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle to achieving global convergence in distributed and federated\nlearning is the misalignment of gradients across clients, or mini-batches due\nto heterogeneity and stochasticity of the distributed data. One way to\nalleviate this problem is to encourage the alignment of gradients across\ndifferent clients throughout training. Our analysis reveals that this goal can\nbe accomplished by utilizing the right optimization method that replicates the\nimplicit regularization effect of SGD, leading to gradient alignment as well as\nimprovements in test accuracies. Since the existence of this regularization in\nSGD completely relies on the sequential use of different mini-batches during\ntraining, it is inherently absent when training with large mini-batches. To\nobtain the generalization benefits of this regularization while increasing\nparallelism, we propose a novel GradAlign algorithm that induces the same\nimplicit regularization while allowing the use of arbitrarily large batches in\neach update. We experimentally validate the benefit of our algorithm in\ndifferent distributed and federated learning settings.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 22:01:35 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Dandi", "Yatin", ""], ["Barba", "Luis", ""], ["Jaggi", "Martin", ""]]}, {"id": "2106.13959", "submitter": "Avishek Chatterjee", "authors": "Avishek Chatterjee, Satyaki Mazumder, Koel Das", "title": "Functional Classwise Principal Component Analysis: A Novel\n  Classification Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, functional data analysis (FDA) has been successfully applied\nin the field of high dimensional data classification. In this paper, we present\na novel classification framework using functional data and classwise Principal\nComponent Analysis (PCA). Our proposed method can be used in high dimensional\ntime series data which typically suffers from small sample size problem. Our\nmethod extracts a piece wise linear functional feature space and is\nparticularly suitable for hard classification problems.The proposed framework\nconverts time series data into functional data and uses classwise functional\nPCA for feature extraction followed by classification using a Bayesian linear\nclassifier. We demonstrate the efficacy of our proposed method by applying it\nto both synthetic data sets and real time series data from diverse fields\nincluding but not limited to neuroscience, food science, medical sciences and\nchemometrics.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 07:10:58 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Chatterjee", "Avishek", ""], ["Mazumder", "Satyaki", ""], ["Das", "Koel", ""]]}, {"id": "2106.14015", "submitter": "Yuri Fonseca", "authors": "Omar Besbes, Yuri Fonseca, Ilan Lobel", "title": "Contextual Inverse Optimization: Offline and Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problems of offline and online contextual optimization with\nfeedback information, where instead of observing the loss, we observe,\nafter-the-fact, the optimal action an oracle with full knowledge of the\nobjective function would have taken. We aim to minimize regret, which is\ndefined as the difference between our losses and the ones incurred by an\nall-knowing oracle. In the offline setting, the decision-maker has information\navailable from past periods and needs to make one decision, while in the online\nsetting, the decision-maker optimizes decisions dynamically over time based a\nnew set of feasible actions and contextual functions in each period. For the\noffline setting, we characterize the optimal minimax policy, establishing the\nperformance that can be achieved as a function of the underlying geometry of\nthe information induced by the data. In the online setting, we leverage this\ngeometric characterization to optimize the cumulative regret. We develop an\nalgorithm that yields the first regret bound for this problem that is\nlogarithmic in the time horizon.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 13:09:52 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Besbes", "Omar", ""], ["Fonseca", "Yuri", ""], ["Lobel", "Ilan", ""]]}, {"id": "2106.14077", "submitter": "Masahiro Kato", "authors": "Masahiro Kato and Kaito Ariu", "title": "The Role of Contextual Information in Best Arm Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the best-arm identification problem with fixed confidence when\ncontextual (covariate) information is available in stochastic bandits. Although\nwe can use contextual information in each round, we are interested in the\nmarginalized mean reward over the contextual distribution. Our goal is to\nidentify the best arm with a minimal number of samplings under a given value of\nthe error rate. We show the instance-specific sample complexity lower bounds\nfor the problem. Then, we propose a context-aware version of the\n\"Track-and-Stop\" strategy, wherein the proportion of the arm draws tracks the\nset of optimal allocations and prove that the expected number of arm draws\nmatches the lower bound asymptotically. We demonstrate that contextual\ninformation can be used to improve the efficiency of the identification of the\nbest marginalized mean reward compared with the results of Garivier & Kaufmann\n(2016). We experimentally confirm that context information contributes to\nfaster best-arm identification.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 18:39:38 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kato", "Masahiro", ""], ["Ariu", "Kaito", ""]]}, {"id": "2106.14080", "submitter": "Nirbhay Modhe", "authors": "Nirbhay Modhe, Harish Kamath, Dhruv Batra, Ashwin Kalyan", "title": "Model-Advantage Optimization for Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-based Reinforcement Learning (MBRL) algorithms have been traditionally\ndesigned with the goal of learning accurate dynamics of the environment. This\nintroduces a mismatch between the objectives of model-learning and the overall\nlearning problem of finding an optimal policy. Value-aware model learning, an\nalternative model-learning paradigm to maximum likelihood, proposes to inform\nmodel-learning through the value function of the learnt policy. While this\nparadigm is theoretically sound, it does not scale beyond toy settings. In this\nwork, we propose a novel value-aware objective that is an upper bound on the\nabsolute performance difference of a policy across two models. Further, we\npropose a general purpose algorithm that modifies the standard MBRL pipeline --\nenabling learning with value aware objectives. Our proposed objective, in\nconjunction with this algorithm, is the first successful instantiation of\nvalue-aware MBRL on challenging continuous control environments, outperforming\nprevious value-aware objectives and with competitive performance w.r.t.\nMLE-based MBRL approaches.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 20:01:28 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Modhe", "Nirbhay", ""], ["Kamath", "Harish", ""], ["Batra", "Dhruv", ""], ["Kalyan", "Ashwin", ""]]}, {"id": "2106.14122", "submitter": "Lang Liu", "authors": "Lang Liu, Joseph Salmon, Zaid Harchaoui", "title": "Score-Based Change Detection for Gradient-Based Learning Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of machine learning algorithms calls for automatic change\ndetection algorithms to monitor their behavior over time. As a machine learning\nalgorithm learns from a continuous, possibly evolving, stream of data, it is\ndesirable and often critical to supplement it with a companion change detection\nalgorithm to facilitate its monitoring and control. We present a generic\nscore-based change detection method that can detect a change in any number of\ncomponents of a machine learning model trained via empirical risk minimization.\nThis proposed statistical hypothesis test can be readily implemented for such\nmodels designed within a differentiable programming framework. We establish the\nconsistency of the hypothesis test and show how to calibrate it to achieve a\nprescribed false alarm rate. We illustrate the versatility of the approach on\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 01:38:11 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Liu", "Lang", ""], ["Salmon", "Joseph", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2106.14177", "submitter": "Wing-Kin Ma", "authors": "Wing-Kin Ma", "title": "On Hyperspectral Unmixing", "comments": "to appear in IGARSS 2021, Special Session on \"The Contributions of\n  Jos\\'e Manuel Bioucas-Dias to Remote Sensing Data Processing\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article the author reviews Jos\\'e Bioucas-Dias' key contributions to\nhyperspectral unmixing (HU), in memory of him as an influential scholar and for\nhis many beautiful ideas introduced to the hyperspectral community. Our story\nwill start with vertex component analysis (VCA) -- one of the most celebrated\nHU algorithms, with more than 2,000 Google Scholar citations. VCA was\npioneering, invented at a time when HU research just began to emerge, and it\nshows sharp insights on a then less-understood subject. Then we will turn to\nSISAL, another widely-used algorithm. SISAL is not only a highly successful\nalgorithm, it is also a demonstration of its inventor's ingenuity on applied\noptimization and on smart formulation for practical noisy cases. Our tour will\nend with dependent component analysis (DECA), perhaps a less well-known\ncontribution. DECA adopts a statistical inference framework, and the author's\nlatest research indicates that such framework has great potential for further\ndevelopment, e.g., there are hidden connections between SISAL and DECA. The\ndevelopment of DECA shows foresight years ahead, in that regard.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 09:30:57 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ma", "Wing-Kin", ""]]}, {"id": "2106.14210", "submitter": "Micha\\\"el Fanuel", "authors": "Micha\\\"el Fanuel and R\\'emi Bardenet", "title": "Nonparametric estimation of continuous DPPs with kernel methods", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal Point Process (DPPs) are statistical models for repulsive point\npatterns. Both sampling and inference are tractable for DPPs, a rare feature\namong models with negative dependence that explains their popularity in machine\nlearning and spatial statistics. Parametric and nonparametric inference methods\nhave been proposed in the finite case, i.e. when the point patterns live in a\nfinite ground set. In the continuous case, only parametric methods have been\ninvestigated, while nonparametric maximum likelihood for DPPs -- an\noptimization problem over trace-class operators -- has remained an open\nquestion. In this paper, we show that a restricted version of this maximum\nlikelihood (MLE) problem falls within the scope of a recent representer theorem\nfor nonnegative functions in an RKHS. This leads to a finite-dimensional\nproblem, with strong statistical ties to the original MLE. Moreover, we\npropose, analyze, and demonstrate a fixed point algorithm to solve this\nfinite-dimensional problem. Finally, we also provide a controlled estimate of\nthe correlation kernel of the DPP, thus providing more interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 11:57:14 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Bardenet", "R\u00e9mi", ""]]}, {"id": "2106.14238", "submitter": "James Wilson", "authors": "James D. Wilson, Jihui Lee", "title": "Interpretable Network Representation Learning with Principal Component\n  Analysis", "comments": "33 pages. Submitted and currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of interpretable network representation learning for\nsamples of network-valued data. We propose the Principal Component Analysis for\nNetworks (PCAN) algorithm to identify statistically meaningful low-dimensional\nrepresentations of a network sample via subgraph count statistics. The PCAN\nprocedure provides an interpretable framework for which one can readily\nvisualize, explore, and formulate predictive models for network samples. We\nfurthermore introduce a fast sampling-based algorithm, sPCAN, which is\nsignificantly more computationally efficient than its counterpart, but still\nenjoys advantages of interpretability. We investigate the relationship between\nthese two methods and analyze their large-sample properties under the common\nregime where the sample of networks is a collection of kernel-based random\ngraphs. We show that under this regime, the embeddings of the sPCAN method\nenjoy a central limit theorem and moreover that the population level embeddings\nof PCAN and sPCAN are equivalent. We assess PCAN's ability to visualize,\ncluster, and classify observations in network samples arising in nature,\nincluding functional connectivity network samples and dynamic networks\ndescribing the political co-voting habits of the U.S. Senate. Our analyses\nreveal that our proposed algorithm provides informative and discriminatory\nfeatures describing the networks in each sample. The PCAN and sPCAN methods\nbuild on the current literature of network representation learning and set the\nstage for a new line of research in interpretable learning on network-valued\ndata. Publicly available software for the PCAN and sPCAN methods are available\nat https://www.github.com/jihuilee/.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 13:52:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wilson", "James D.", ""], ["Lee", "Jihui", ""]]}, {"id": "2106.14277", "submitter": "Rustem Takhanov", "authors": "Rustem Takhanov", "title": "How many moments does MMD compare?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new way of study of Mercer kernels, by corresponding to a\nspecial kernel $K$ a pseudo-differential operator $p({\\mathbf x}, D)$ such that\n$\\mathcal{F} p({\\mathbf x}, D)^\\dag p({\\mathbf x}, D) \\mathcal{F}^{-1}$ acts on\nsmooth functions in the same way as an integral operator associated with $K$\n(where $\\mathcal{F}$ is the Fourier transform). We show that kernels defined by\npseudo-differential operators are able to approximate uniformly any continuous\nMercer kernel on a compact set.\n  The symbol $p({\\mathbf x}, {\\mathbf y})$ encapsulates a lot of useful\ninformation about the structure of the Maximum Mean Discrepancy distance\ndefined by the kernel $K$. We approximate $p({\\mathbf x}, {\\mathbf y})$ with\nthe sum of the first $r$ terms of the Singular Value Decomposition of $p$,\ndenoted by $p_r({\\mathbf x}, {\\mathbf y})$. If ordered singular values of the\nintegral operator associated with $p({\\mathbf x}, {\\mathbf y})$ die down\nrapidly, the MMD distance defined by the new symbol $p_r$ differs from the\ninitial one only slightly. Moreover, the new MMD distance can be interpreted as\nan aggregated result of comparing $r$ local moments of two probability\ndistributions.\n  The latter results holds under the condition that right singular vectors of\nthe integral operator associated with $p$ are uniformly bounded. But even if\nthis is not satisfied we can still hold that the Hilbert-Schmidt distance\nbetween $p$ and $p_r$ vanishes. Thus, we report an interesting phenomenon: the\nMMD distance measures the difference of two probability distributions with\nrespect to a certain number of local moments, $r^\\ast$, and this number\n$r^\\ast$ depends on the speed with which singular values of $p$ die down.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 16:44:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Takhanov", "Rustem", ""]]}, {"id": "2106.14289", "submitter": "Simon Du", "authors": "Tian Ye and Simon S. Du", "title": "Global Convergence of Gradient Descent for Asymmetric Low-Rank Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymmetric low-rank factorization problem: \\[\\min_{\\mathbf{U}\n\\in \\mathbb{R}^{m \\times d}, \\mathbf{V} \\in \\mathbb{R}^{n \\times d}}\n\\frac{1}{2}\\|\\mathbf{U}\\mathbf{V}^\\top -\\mathbf{\\Sigma}\\|_F^2\\] where\n$\\mathbf{\\Sigma}$ is a given matrix of size $m \\times n$ and rank $d$. This is\na canonical problem that admits two difficulties in optimization: 1)\nnon-convexity and 2) non-smoothness (due to unbalancedness of $\\mathbf{U}$ and\n$\\mathbf{V}$). This is also a prototype for more complex problems such as\nasymmetric matrix sensing and matrix completion. Despite being non-convex and\nnon-smooth, it has been observed empirically that the randomly initialized\ngradient descent algorithm can solve this problem in polynomial time. Existing\ntheories to explain this phenomenon all require artificial modifications of the\nalgorithm, such as adding noise in each iteration and adding a balancing\nregularizer to balance the $\\mathbf{U}$ and $\\mathbf{V}$.\n  This paper presents the first proof that shows randomly initialized gradient\ndescent converges to a global minimum of the asymmetric low-rank factorization\nproblem with a polynomial rate. For the proof, we develop 1) a new\nsymmetrization technique to capture the magnitudes of the symmetry and\nasymmetry, and 2) a quantitative perturbation analysis to approximate matrix\nderivatives. We believe both are useful for other related non-convex problems.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 17:25:24 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ye", "Tian", ""], ["Du", "Simon S.", ""]]}, {"id": "2106.14323", "submitter": "Nathalie Deziderio", "authors": "Nathalie Deziderio and Hugo Tremonte de Carvalho", "title": "Use of Variational Inference in Music Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work was developed aiming to employ Statistical techniques to the field\nof Music Emotion Recognition, a well-recognized area within the Signal\nProcessing world, but hardly explored from the statistical point of view. Here,\nwe opened several possibilities within the field, applying modern Bayesian\nStatistics techniques and developing efficient algorithms, focusing on the\napplicability of the results obtained. Although the motivation for this project\nwas the development of a emotion-based music recommendation system, its main\ncontribution is a highly adaptable multivariate model that can be useful\ninterpreting any database where there is an interest in applying regularization\nin an efficient manner. Broadly speaking, we will explore what role a sound\ntheoretical statistical analysis can play in the modeling of an algorithm that\nis able to understand a well-known database and what can be gained with this\nkind of approach.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 21:41:08 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 18:26:31 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Deziderio", "Nathalie", ""], ["de Carvalho", "Hugo Tremonte", ""]]}, {"id": "2106.14324", "submitter": "Weimin Zhou", "authors": "Weimin Zhou, Sayantan Bhadra, Frank J. Brooks, Hua Li, Mark A.\n  Anastasio", "title": "Learning stochastic object models from medical imaging measurements by\n  use of advanced AmbientGANs", "comments": "Submitted to IEEE Transactions on Medical Imaging. arXiv admin note:\n  substantial text overlap with arXiv:2006.00033", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to objectively assess new medical imaging technologies via\ncomputer-simulations, it is important to account for all sources of variability\nthat contribute to image data. One important source of variability that can\nsignificantly limit observer performance is associated with the variability in\nthe ensemble of objects to-be-imaged. This source of variability can be\ndescribed by stochastic object models (SOMs), which are generative models that\ncan be employed to sample from a distribution of to-be-virtually-imaged\nobjects. It is generally desirable to establish SOMs from experimental imaging\nmeasurements acquired by use of a well-characterized imaging system, but this\ntask has remained challenging. Deep generative neural networks, such as\ngenerative adversarial networks (GANs) hold potential for such tasks. To\nestablish SOMs from imaging measurements, an AmbientGAN has been proposed that\naugments a GAN with a measurement operator. However, the original AmbientGAN\ncould not immediately benefit from modern training procedures and GAN\narchitectures, which limited its ability to be applied to realistically sized\nmedical image data. To circumvent this, in this work, a modified AmbientGAN\ntraining strategy is proposed that is suitable for modern progressive or\nmulti-resolution training approaches such as employed in the Progressive\nGrowing of GANs and Style-based GANs. AmbientGANs established by use of the\nproposed training procedure are systematically validated in a controlled way by\nuse of computer-simulated measurement data corresponding to a stylized imaging\nsystem. Finally, emulated single-coil experimental magnetic resonance imaging\ndata are employed to demonstrate the methods under less stylized conditions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 21:46:23 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhou", "Weimin", ""], ["Bhadra", "Sayantan", ""], ["Brooks", "Frank J.", ""], ["Li", "Hua", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2106.14338", "submitter": "Damianos Tranos", "authors": "Damianos Tranos and Alexandre Proutiere", "title": "Regret Analysis in Deterministic Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider Markov Decision Processes (MDPs) with deterministic transitions\nand study the problem of regret minimization, which is central to the analysis\nand design of optimal learning algorithms. We present logarithmic\nproblem-specific regret lower bounds that explicitly depend on the system\nparameter (in contrast to previous minimax approaches) and thus, truly quantify\nthe fundamental limit of performance achievable by any learning algorithm.\nDeterministic MDPs can be interpreted as graphs and analyzed in terms of their\ncycles, a fact which we leverage in order to identify a class of deterministic\nMDPs whose regret lower bound can be determined numerically. We further\nexemplify this result on a deterministic line search problem, and a\ndeterministic MDP with state-dependent rewards, whose regret lower bounds we\ncan state explicitly. These bounds share similarities with the known\nproblem-specific bound of the multi-armed bandit problem and suggest that\nnavigation on a deterministic MDP need not have an effect on the performance of\na learning algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 23:41:57 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tranos", "Damianos", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "2106.14342", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, Vladlen Koltun, J. Zico Kolter", "title": "Stabilizing Equilibrium Models by Jacobian Regularization", "comments": "ICML 2021 Short Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep equilibrium networks (DEQs) are a new class of models that eschews\ntraditional depth in favor of finding the fixed point of a single nonlinear\nlayer. These models have been shown to achieve performance competitive with the\nstate-of-the-art deep networks while using significantly less memory. Yet they\nare also slower, brittle to architectural choices, and introduce potential\ninstability to the model. In this paper, we propose a regularization scheme for\nDEQ models that explicitly regularizes the Jacobian of the fixed-point update\nequations to stabilize the learning of equilibrium models. We show that this\nregularization adds only minimal computational cost, significantly stabilizes\nthe fixed-point convergence in both forward and backward passes, and scales\nwell to high-dimensional, realistic domains (e.g., WikiText-103 language\nmodeling and ImageNet classification). Using this method, we demonstrate, for\nthe first time, an implicit-depth model that runs with approximately the same\nspeed and level of performance as popular conventional deep networks such as\nResNet-101, while still maintaining the constant memory footprint and\narchitectural simplicity of DEQs. Code is available at\nhttps://github.com/locuslab/deq .\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 00:14:11 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bai", "Shaojie", ""], ["Koltun", "Vladlen", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2106.14343", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky and Harsh Mehta", "title": "High-probability Bounds for Non-Convex Stochastic Optimization with\n  Heavy Tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non-convex stochastic optimization using first-order algorithms\nfor which the gradient estimates may have heavy tails. We show that a\ncombination of gradient clipping, momentum, and normalized gradient descent\nyields convergence to critical points in high-probability with best-known rates\nfor smooth losses when the gradients only have bounded $\\mathfrak{p}$th moments\nfor some $\\mathfrak{p}\\in(1,2]$. We then consider the case of second-order\nsmooth losses, which to our knowledge have not been studied in this setting,\nand again obtain high-probability bounds for any $\\mathfrak{p}$. Moreover, our\nresults hold for arbitrary smooth norms, in contrast to the typical SGD\nanalysis which requires a Hilbert space norm. Further, we show that after a\nsuitable \"burn-in\" period, the objective value will monotonically decrease for\nevery iteration until a critical point is identified, which provides intuition\nbehind the popular practice of learning rate \"warm-up\" and also yields a\nlast-iterate guarantee.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 00:17:01 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Mehta", "Harsh", ""]]}, {"id": "2106.14352", "submitter": "Eric Xia", "authors": "Koulik Khamaru, Eric Xia, Martin J. Wainwright, and Michael I. Jordan", "title": "Instance-optimality in optimal value estimation: Adaptivity via\n  variance-reduced Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Various algorithms in reinforcement learning exhibit dramatic variability in\ntheir convergence rates and ultimate accuracy as a function of the problem\nstructure. Such instance-specific behavior is not captured by existing global\nminimax bounds, which are worst-case in nature. We analyze the problem of\nestimating optimal $Q$-value functions for a discounted Markov decision process\nwith discrete states and actions and identify an instance-dependent functional\nthat controls the difficulty of estimation in the $\\ell_\\infty$-norm. Using a\nlocal minimax framework, we show that this functional arises in lower bounds on\nthe accuracy on any estimation procedure. In the other direction, we establish\nthe sharpness of our lower bounds, up to factors logarithmic in the state and\naction spaces, by analyzing a variance-reduced version of $Q$-learning. Our\ntheory provides a precise way of distinguishing \"easy\" problems from \"hard\"\nones in the context of $Q$-learning, as illustrated by an ensemble with a\ncontinuum of difficulty.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 00:38:54 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Khamaru", "Koulik", ""], ["Xia", "Eric", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2106.14384", "submitter": "Yihuang Kang", "authors": "Yihuang Kang, Yi-Wen Chiu, Ming-Yen Lin, Fang-yi Su, Sheng-Tai Huang", "title": "Towards Model-informed Precision Dosing with Expert-in-the-loop Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) and its applications have been transforming our lives\nbut it is also creating issues related to the development of fair, accountable,\ntransparent, and ethical Artificial Intelligence. As the ML models are not\nfully comprehensible yet, it is obvious that we still need humans to be part of\nalgorithmic decision-making processes. In this paper, we consider a ML\nframework that may accelerate model learning and improve its interpretability\nby incorporating human experts into the model learning loop. We propose a novel\nhuman-in-the-loop ML framework aimed at dealing with learning problems that the\ncost of data annotation is high and the lack of appropriate data to model the\nassociation between the target tasks and the input features. With an\napplication to precision dosing, our experimental results show that the\napproach can learn interpretable rules from data and may potentially lower\nexperts' workload by replacing data annotation with rule representation\nediting. The approach may also help remove algorithmic bias by introducing\nexperts' feedback into the iterative model learning process.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 03:45:09 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 03:11:03 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kang", "Yihuang", ""], ["Chiu", "Yi-Wen", ""], ["Lin", "Ming-Yen", ""], ["Su", "Fang-yi", ""], ["Huang", "Sheng-Tai", ""]]}, {"id": "2106.14406", "submitter": "Nayan Saxena", "authors": "Robert Wu, Nayan Saxena, Rohan Jain", "title": "Poisoning the Search Space in Neural Architecture Search", "comments": "All authors contributed equally. Appears in AdvML Workshop @\n  ICML2021: A Blessing in Disguise: The Prospects and Perils of Adversarial\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has proven to be a highly effective problem-solving tool for\nobject detection and image segmentation across various domains such as\nhealthcare and autonomous driving. At the heart of this performance lies neural\narchitecture design which relies heavily on domain knowledge and prior\nexperience on the researchers' behalf. More recently, this process of finding\nthe most optimal architectures, given an initial search space of possible\noperations, was automated by Neural Architecture Search (NAS). In this paper,\nwe evaluate the robustness of one such algorithm known as Efficient NAS (ENAS)\nagainst data agnostic poisoning attacks on the original search space with\ncarefully designed ineffective operations. By evaluating algorithm performance\non the CIFAR-10 dataset, we empirically demonstrate how our novel search space\npoisoning (SSP) approach and multiple-instance poisoning attacks exploit design\nflaws in the ENAS controller to result in inflated prediction error rates for\nchild networks. Our results provide insights into the challenges to surmount in\nusing NAS for more adversarially robust architecture search.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 05:45:57 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wu", "Robert", ""], ["Saxena", "Nayan", ""], ["Jain", "Rohan", ""]]}, {"id": "2106.14565", "submitter": "Anant Mathur", "authors": "Anant Mathur, Sarat Moka and Zdravko Botev", "title": "Variance Reduction for Matrix Computations with Applications to Gaussian\n  Processes", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In addition to recent developments in computing speed and memory,\nmethodological advances have contributed to significant gains in the\nperformance of stochastic simulation. In this paper, we focus on variance\nreduction for matrix computations via matrix factorization. We provide insights\ninto existing variance reduction methods for estimating the entries of large\nmatrices. Popular methods do not exploit the reduction in variance that is\npossible when the matrix is factorized. We show how computing the square root\nfactorization of the matrix can achieve in some important cases arbitrarily\nbetter stochastic performance. In addition, we propose a factorized estimator\nfor the trace of a product of matrices and numerically demonstrate that the\nestimator can be up to 1,000 times more efficient on certain problems of\nestimating the log-likelihood of a Gaussian process. Additionally, we provide a\nnew estimator of the log-determinant of a positive semi-definite matrix where\nthe log-determinant is treated as a normalizing constant of a probability\ndensity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 10:41:22 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 08:19:40 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mathur", "Anant", ""], ["Moka", "Sarat", ""], ["Botev", "Zdravko", ""]]}, {"id": "2106.14588", "submitter": "Zhou Lu", "authors": "Daogao Liu, Zhou Lu", "title": "The Convergence Rate of SGD's Final Iterate: Analysis on Dimension\n  Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is among the simplest and most popular\nmethods in optimization. The convergence rate for SGD has been extensively\nstudied and tight analyses have been established for the running average\nscheme, but the sub-optimality of the final iterate is still not\nwell-understood. shamir2013stochastic gave the best known upper bound for the\nfinal iterate of SGD minimizing non-smooth convex functions, which is $O(\\log\nT/\\sqrt{T})$ for Lipschitz convex functions and $O(\\log T/ T)$ with additional\nassumption on strongly convexity. The best known lower bounds, however, are\nworse than the upper bounds by a factor of $\\log T$. harvey2019tight gave\nmatching lower bounds but their construction requires dimension $d= T$. It was\nthen asked by koren2020open how to characterize the final-iterate convergence\nof SGD in the constant dimension setting.\n  In this paper, we answer this question in the more general setting for any\n$d\\leq T$, proving $\\Omega(\\log d/\\sqrt{T})$ and $\\Omega(\\log d/T)$ lower\nbounds for the sub-optimality of the final iterate of SGD in minimizing\nnon-smooth Lipschitz convex and strongly convex functions respectively with\nstandard step size schedules. Our results provide the first general dimension\ndependent lower bound on the convergence of SGD's final iterate, partially\nresolving a COLT open question raised by koren2020open. We also present further\nevidence to show the correct rate in one dimension should be\n$\\Theta(1/\\sqrt{T})$, such as a proof of a tight $O(1/\\sqrt{T})$ upper bound\nfor one-dimensional special cases in settings more general than koren2020open.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 11:51:04 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Liu", "Daogao", ""], ["Lu", "Zhou", ""]]}, {"id": "2106.14630", "submitter": "Yue Gao", "authors": "Yue Gao, Garvesh Raskutti", "title": "Improved Prediction and Network Estimation Using the Monotone Single\n  Index Multi-variate Autoregressive Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network estimation from multi-variate point process or time series data is a\nproblem of fundamental importance. Prior work has focused on parametric\napproaches that require a known parametric model, which makes estimation\nprocedures less robust to model mis-specification, non-linearities and\nheterogeneities. In this paper, we develop a semi-parametric approach based on\nthe monotone single-index multi-variate autoregressive model (SIMAM) which\naddresses these challenges. We provide theoretical guarantees for dependent\ndata and an alternating projected gradient descent algorithm. Significantly we\ndo not explicitly assume mixing conditions on the process (although we do\nrequire conditions analogous to restricted strong convexity) and we achieve\nrates of the form $O(T^{-\\frac{1}{3}} \\sqrt{s\\log(TM)})$ (optimal in the\nindependent design case) where $s$ is the threshold for the maximum in-degree\nof the network that indicates the sparsity level, $M$ is the number of actors\nand $T$ is the number of time points. In addition, we demonstrate the superior\nperformance both on simulated data and two real data examples where our SIMAM\napproach out-performs state-of-the-art parametric methods both in terms of\nprediction and network estimation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 12:32:29 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 02:00:22 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Gao", "Yue", ""], ["Raskutti", "Garvesh", ""]]}, {"id": "2106.14648", "submitter": "Lucile Ter-Minassian", "authors": "Sahra Ghalebikesabi, Lucile Ter-Minassian, Karla Diaz-Ordaz and Chris\n  Holmes", "title": "On Locality of Local Explanation Models", "comments": "Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Shapley values provide model agnostic feature attributions for model outcome\nat a particular instance by simulating feature absence under a global\npopulation distribution. The use of a global population can lead to potentially\nmisleading results when local model behaviour is of interest. Hence we consider\nthe formulation of neighbourhood reference distributions that improve the local\ninterpretability of Shapley values. By doing so, we find that the\nNadaraya-Watson estimator, a well-studied kernel regressor, can be expressed as\na self-normalised importance sampling estimator. Empirically, we observe that\nNeighbourhood Shapley values identify meaningful sparse feature relevance\nattributions that provide insight into local model behaviour, complimenting\nconventional Shapley analysis. They also increase on-manifold explainability\nand robustness to the construction of adversarial classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 16:20:38 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ghalebikesabi", "Sahra", ""], ["Ter-Minassian", "Lucile", ""], ["Diaz-Ordaz", "Karla", ""], ["Holmes", "Chris", ""]]}, {"id": "2106.14806", "submitter": "Agustinus Kristiadi", "authors": "Erik Daxberger and Agustinus Kristiadi and Alexander Immer and Runa\n  Eschenhagen and Matthias Bauer and Philipp Hennig", "title": "Laplace Redux -- Effortless Bayesian Deep Learning", "comments": "Source Code: https://github.com/AlexImmer/Laplace; Library\n  Documentation: https://aleximmer.github.io/Laplace/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian formulations of deep learning have been shown to have compelling\ntheoretical properties and offer practical functional benefits, such as\nimproved predictive uncertainty quantification and model selection. The Laplace\napproximation (LA) is a classic, and arguably the simplest family of\napproximations for the intractable posteriors of deep neural networks. Yet,\ndespite its simplicity, the LA is not as popular as alternatives like\nvariational Bayes or deep ensembles. This may be due to assumptions that the LA\nis expensive due to the involved Hessian computation, that it is difficult to\nimplement, or that it yields inferior results. In this work we show that these\nare misconceptions: we (i) review the range of variants of the LA including\nversions with minimal cost overhead; (ii) introduce \"laplace\", an easy-to-use\nsoftware library for PyTorch offering user-friendly access to all major flavors\nof the LA; and (iii) demonstrate through extensive experiments that the LA is\ncompetitive with more popular alternatives in terms of performance, while\nexcelling in terms of computational cost. We hope that this work will serve as\na catalyst to a wider adoption of the LA in practical deep learning, including\nin domains where Bayesian approaches are not typically considered at the\nmoment.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 15:30:40 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Daxberger", "Erik", ""], ["Kristiadi", "Agustinus", ""], ["Immer", "Alexander", ""], ["Eschenhagen", "Runa", ""], ["Bauer", "Matthias", ""], ["Hennig", "Philipp", ""]]}, {"id": "2106.14813", "submitter": "Feng Zhu", "authors": "David Simchi-Levi, Zeyu Zheng, Feng Zhu", "title": "Dynamic Planning and Learning under Recovering Rewards", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DM cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by emerging applications such as live-streaming e-commerce,\npromotions and recommendations, we introduce a general class of multi-armed\nbandit problems that have the following two features: (i) the decision maker\ncan pull and collect rewards from at most $K$ out of $N$ different arms in each\ntime period; (ii) the expected reward of an arm immediately drops after it is\npulled, and then non parametrically recovers as the idle time increases. With\nthe objective of maximizing expected cumulative rewards over $T$ time periods,\nwe propose, construct and prove performance guarantees for a class of \"Purely\nPeriodic Policies\". For the offline problem when all model parameters are\nknown, our proposed policy obtains an approximation ratio that is at the order\nof $1-\\mathcal O(1/\\sqrt{K})$, which is asymptotically optimal when $K$ grows\nto infinity. For the online problem when the model parameters are unknown and\nneed to be learned, we design an Upper Confidence Bound (UCB) based policy that\napproximately has $\\widetilde{\\mathcal O}(N\\sqrt{T})$ regret against the\noffline benchmark. Our framework and policy design may have the potential to be\nadapted into other offline planning and online learning applications with\nnon-stationary and recovering rewards.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 15:40:07 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Simchi-Levi", "David", ""], ["Zheng", "Zeyu", ""], ["Zhu", "Feng", ""]]}, {"id": "2106.14836", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Linjun Zhang, Zhun Deng", "title": "Understanding Dynamics of Nonlinear Representation Learning and Its\n  Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations of the world environment play a crucial role in machine\nintelligence. It is often inefficient to conduct reasoning and inference\ndirectly in the space of raw sensory representations, such as pixel values of\nimages. Representation learning allows us to automatically discover suitable\nrepresentations from raw sensory data. For example, given raw sensory data, a\nmultilayer perceptron learns nonlinear representations at its hidden layers,\nwhich are subsequently used for classification (or regression) at its output\nlayer. This happens implicitly during training through minimizing a supervised\nor unsupervised loss. In this paper, we study the dynamics of such implicit\nnonlinear representation learning. We identify a pair of a new assumption and a\nnovel condition, called the common model structure assumption and the\ndata-architecture alignment condition. Under the common model structure\nassumption, the data-architecture alignment condition is shown to be sufficient\nfor the global convergence and necessary for the global optimality. Our results\nprovide practical guidance for designing a model structure: e.g., the common\nmodel structure assumption can be used as a justification for using a\nparticular model structure instead of others. As an application, we then derive\na new training framework, which satisfies the data-architecture alignment\ncondition without assuming it by automatically modifying any given training\nalgorithm dependently on each data and architecture. Given a standard training\nalgorithm, the framework running its modified version is empirically shown to\nmaintain competitive (practical) test performances while providing global\nconvergence guarantees for ResNet-18 with convolutions, skip connections, and\nbatch normalization with standard benchmark datasets, including MNIST,\nCIFAR-10, CIFAR-100, Semeion, KMNIST and SVHN.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 16:31:30 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Zhang", "Linjun", ""], ["Deng", "Zhun", ""]]}, {"id": "2106.14857", "submitter": "Robert Lunde", "authors": "Robert Lunde, Purnamrita Sarkar, Rachel Ward", "title": "Bootstrapping the error of Oja's Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of quantifying uncertainty for the estimation error\nof the leading eigenvector from Oja's algorithm for streaming principal\ncomponent analysis, where the data are generated IID from some unknown\ndistribution. By combining classical tools from the U-statistics literature\nwith recent results on high-dimensional central limit theorems for quadratic\nforms of random vectors and concentration of matrix products, we establish a\n$\\chi^2$ approximation result for the $\\sin^2$ error between the population\neigenvector and the output of Oja's algorithm. Since estimating the covariance\nmatrix associated with the approximating distribution requires knowledge of\nunknown model parameters, we propose a multiplier bootstrap algorithm that may\nbe updated in an online manner. We establish conditions under which the\nbootstrap distribution is close to the corresponding sampling distribution with\nhigh probability, thereby establishing the bootstrap as a consistent\ninferential method in an appropriate asymptotic regime.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 17:27:26 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Lunde", "Robert", ""], ["Sarkar", "Purnamrita", ""], ["Ward", "Rachel", ""]]}, {"id": "2106.14866", "submitter": "Wenshuo Guo", "authors": "Wenshuo Guo, Kumar Krishna Agrawal, Aditya Grover, Vidya Muthukumar,\n  Ashwin Pananjady", "title": "Learning from an Exploring Demonstrator: Optimal Reward Estimation for\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG cs.RO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \"inverse bandit\" problem of estimating the rewards of a\nmulti-armed bandit instance from observing the learning process of a low-regret\ndemonstrator. Existing approaches to the related problem of inverse\nreinforcement learning assume the execution of an optimal policy, and thereby\nsuffer from an identifiability issue. In contrast, our paradigm leverages the\ndemonstrator's behavior en route to optimality, and in particular, the\nexploration phase, to obtain consistent reward estimates. We develop simple and\nefficient reward estimation procedures for demonstrations within a class of\nupper-confidence-based algorithms, showing that reward estimation gets\nprogressively easier as the regret of the algorithm increases. We match these\nupper bounds with information-theoretic lower bounds that apply to any\ndemonstrator algorithm, thereby characterizing the optimal tradeoff between\nexploration and reward estimation. Extensive empirical evaluations on both\nsynthetic data and simulated experimental design data from the natural sciences\ncorroborate our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 17:37:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Guo", "Wenshuo", ""], ["Agrawal", "Kumar Krishna", ""], ["Grover", "Aditya", ""], ["Muthukumar", "Vidya", ""], ["Pananjady", "Ashwin", ""]]}, {"id": "2106.14876", "submitter": "Ingmar Kanitscheider", "authors": "Ingmar Kanitscheider, Joost Huizinga, David Farhi, William Hebgen\n  Guss, Brandon Houghton, Raul Sampedro, Peter Zhokhov, Bowen Baker, Adrien\n  Ecoffet, Jie Tang, Oleg Klimov, Jeff Clune", "title": "Multi-task curriculum learning in a complex, visual, hard-exploration\n  domain: Minecraft", "comments": "first submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important challenge in reinforcement learning is training agents that can\nsolve a wide variety of tasks. If tasks depend on each other (e.g. needing to\nlearn to walk before learning to run), curriculum learning can speed up\nlearning by focusing on the next best task to learn. We explore curriculum\nlearning in a complex, visual domain with many hard exploration challenges:\nMinecraft. We find that learning progress (defined as a change in success\nprobability of a task) is a reliable measure of learnability for automatically\nconstructing an effective curriculum. We introduce a learning-progress based\ncurriculum and test it on a complex reinforcement learning problem (called\n\"Simon Says\") where an agent is instructed to obtain a desired goal item. Many\nof the required skills depend on each other. Experiments demonstrate that: (1)\na within-episode exploration bonus for obtaining new items improves\nperformance, (2) dynamically adjusting this bonus across training such that it\nonly applies to items the agent cannot reliably obtain yet further increases\nperformance, (3) the learning-progress based curriculum elegantly follows the\nlearning curve of the agent, and (4) when the learning-progress based\ncurriculum is combined with the dynamic exploration bonus it learns much more\nefficiently and obtains far higher performance than uniform baselines. These\nresults suggest that combining intra-episode and across-training exploration\nbonuses with learning progress creates a promising method for automated\ncurriculum generation, which may substantially increase our ability to train\nmore capable, generally intelligent agents.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 17:50:40 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kanitscheider", "Ingmar", ""], ["Huizinga", "Joost", ""], ["Farhi", "David", ""], ["Guss", "William Hebgen", ""], ["Houghton", "Brandon", ""], ["Sampedro", "Raul", ""], ["Zhokhov", "Peter", ""], ["Baker", "Bowen", ""], ["Ecoffet", "Adrien", ""], ["Tang", "Jie", ""], ["Klimov", "Oleg", ""], ["Clune", "Jeff", ""]]}, {"id": "2106.14956", "submitter": "Berkay Turan", "authors": "Berkay Turan, Cesar A. Uribe, Hoi-To Wai, Mahnoosh Alizadeh", "title": "Robust Distributed Optimization With Randomly Corrupted Gradients", "comments": "17 pages, 3 figures, submitted to IEEE TSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a first-order distributed optimization algorithm\nthat is provably robust to Byzantine failures-arbitrary and potentially\nadversarial behavior, where all the participating agents are prone to failure.\nWe model each agent's state over time as a two-state Markov chain that\nindicates Byzantine or trustworthy behaviors at different time instants. We set\nno restrictions on the maximum number of Byzantine agents at any given time. We\ndesign our method based on three layers of defense: 1) Temporal gradient\naveraging, 2) robust aggregation, and 3) gradient normalization. We study two\nsettings for stochastic optimization, namely Sample Average Approximation and\nStochastic Approximation, and prove that for strongly convex and smooth\nnon-convex cost functions, our algorithm achieves order-optimal statistical\nerror and convergence rates.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 19:45:25 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Turan", "Berkay", ""], ["Uribe", "Cesar A.", ""], ["Wai", "Hoi-To", ""], ["Alizadeh", "Mahnoosh", ""]]}, {"id": "2106.14979", "submitter": "Niki Kilbertus", "authors": "Jiri Hron, Karl Krauth, Michael I. Jordan, Niki Kilbertus", "title": "On component interactions in two-stage recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to their scalability, two-stage recommenders are used by many of\ntoday's largest online platforms, including YouTube, LinkedIn, and Pinterest.\nThese systems produce recommendations in two steps: (i) multiple nominators --\ntuned for low prediction latency -- preselect a small subset of candidates from\nthe whole item pool; (ii)~a slower but more accurate ranker further narrows\ndown the nominated items, and serves to the user. Despite their popularity, the\nliterature on two-stage recommenders is relatively scarce, and the algorithms\nare often treated as the sum of their parts. Such treatment presupposes that\nthe two-stage performance is explained by the behavior of individual components\nif they were deployed independently. This is not the case: using synthetic and\nreal-world data, we demonstrate that interactions between the ranker and the\nnominators substantially affect the overall performance. Motivated by these\nfindings, we derive a generalization lower bound which shows that careful\nchoice of each nominator's training set is sometimes the only difference\nbetween a poor and an optimal two-stage recommender. Since searching for a good\nchoice manually is difficult, we learn one instead. In particular, using a\nMixture-of-Experts approach, we train the nominators (experts) to specialize on\ndifferent subsets of the item pool. This significantly improves performance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 20:53:23 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Hron", "Jiri", ""], ["Krauth", "Karl", ""], ["Jordan", "Michael I.", ""], ["Kilbertus", "Niki", ""]]}, {"id": "2106.14981", "submitter": "Martin Jankowiak", "authors": "Martin Jankowiak", "title": "Fast Bayesian Variable Selection in Binomial and Negative Binomial\n  Regression", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian variable selection is a powerful tool for data analysis, as it\noffers a principled method for variable selection that accounts for prior\ninformation and uncertainty. However, wider adoption of Bayesian variable\nselection has been hampered by computational challenges, especially in\ndifficult regimes with a large number of covariates or non-conjugate\nlikelihoods. Generalized linear models for count data, which are prevalent in\nbiology, ecology, economics, and beyond, represent an important special case.\nHere we introduce an efficient MCMC scheme for variable selection in binomial\nand negative binomial regression that exploits Tempered Gibbs Sampling (Zanella\nand Roberts, 2019) and that includes logistic regression as a special case. In\nexperiments we demonstrate the effectiveness of our approach, including on\ncancer data with seventeen thousand covariates.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 20:54:41 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Jankowiak", "Martin", ""]]}, {"id": "2106.14993", "submitter": "Michael Chang", "authors": "Michael Chang, Sidhant Kaushik, Sergey Levine, Thomas L. Griffiths", "title": "Modularity in Reinforcement Learning via Algorithmic Independence in\n  Credit Assignment", "comments": "Long Presentation at the Thirty-eighth International Conference on\n  Machine Learning (ICML) 2021. 21 pages, 11 figures. v2: updated\n  acknowledgments. v3: clarified that the internal function nodes of the credit\n  assignment mechanism are not considered O(1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many transfer problems require re-using previously optimal decisions for\nsolving new tasks, which suggests the need for learning algorithms that can\nmodify the mechanisms for choosing certain actions independently of those for\nchoosing others. However, there is currently no formalism nor theory for how to\nachieve this kind of modular credit assignment. To answer this question, we\ndefine modular credit assignment as a constraint on minimizing the algorithmic\nmutual information among feedback signals for different decisions. We introduce\nwhat we call the modularity criterion for testing whether a learning algorithm\nsatisfies this constraint by performing causal analysis on the algorithm\nitself. We generalize the recently proposed societal decision-making framework\nas a more granular formalism than the Markov decision process to prove that for\ndecision sequences that do not contain cycles, certain single-step temporal\ndifference action-value methods meet this criterion while all policy-gradient\nmethods do not. Empirical evidence suggests that such action-value methods are\nmore sample efficient than policy-gradient methods on transfer problems that\nrequire only sparse changes to a sequence of previously optimal decisions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 21:29:13 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 21:42:55 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 17:07:10 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chang", "Michael", ""], ["Kaushik", "Sidhant", ""], ["Levine", "Sergey", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2106.14997", "submitter": "Jonathan Siegel", "authors": "Jonathan W. Siegel, Jinchao Xu", "title": "Sharp Lower Bounds on the Approximation Rate of Shallow Neural Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:2101.12365", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the approximation rates of shallow neural networks with respect\nto the variation norm. Upper bounds on these rates have been established for\nsigmoidal and ReLU activation functions, but it has remained an important open\nproblem whether these rates are sharp. In this article, we provide a solution\nto this problem by proving sharp lower bounds on the approximation rates for\nshallow neural networks, which are obtained by lower bounding the $L^2$-metric\nentropy of the convex hull of the neural network basis functions. In addition,\nour methods also give sharp lower bounds on the Kolmogorov $n$-widths of this\nconvex hull, which show that the variation spaces corresponding to shallow\nneural networks cannot be efficiently approximated by linear methods. These\nlower bounds apply to both sigmoidal activation functions with bounded\nvariation and to activation functions which are a power of the ReLU. Our\nresults also quantify how much stronger the Barron spectral norm is than the\nvariation norm and, combined with previous results, give the asymptotics of the\n$L^\\infty$-metric entropy up to logarithmic factors in the case of the ReLU\nactivation function.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 22:01:42 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Siegel", "Jonathan W.", ""], ["Xu", "Jinchao", ""]]}, {"id": "2106.14999", "submitter": "Chaithanya Kumar Mummadi", "authors": "Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny\n  Levinkov, Thomas Brox, Jan Hendrik Metzen", "title": "Test-Time Adaptation to Distribution Shift by Confidence Maximization\n  and Input Transformation", "comments": "16 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep neural networks often exhibit poor performance on data that is unlikely\nunder the train-time data distribution, for instance data affected by\ncorruptions. Previous works demonstrate that test-time adaptation to data\nshift, for instance using entropy minimization, effectively improves\nperformance on such shifted distributions. This paper focuses on the fully\ntest-time adaptation setting, where only unlabeled data from the target\ndistribution is required. This allows adapting arbitrary pretrained networks.\nSpecifically, we propose a novel loss that improves test-time adaptation by\naddressing both premature convergence and instability of entropy minimization.\nThis is achieved by replacing the entropy by a non-saturating surrogate and\nadding a diversity regularizer based on batch-wise entropy maximization that\nprevents convergence to trivial collapsed solutions. Moreover, we propose to\nprepend an input transformation module to the network that can partially undo\ntest-time distribution shifts. Surprisingly, this preprocessing can be learned\nsolely using the fully test-time adaptation loss in an end-to-end fashion\nwithout any target domain labels or source domain data. We show that our\napproach outperforms previous work in improving the robustness of publicly\navailable pretrained image classifiers to common corruptions on such\nchallenging benchmarks as ImageNet-C.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 22:06:10 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Mummadi", "Chaithanya Kumar", ""], ["Hutmacher", "Robin", ""], ["Rambach", "Kilian", ""], ["Levinkov", "Evgeny", ""], ["Brox", "Thomas", ""], ["Metzen", "Jan Hendrik", ""]]}, {"id": "2106.15002", "submitter": "Jonathan Siegel", "authors": "Jonathan W. Siegel, Jinchao Xu", "title": "Characterization of the Variation Spaces Corresponding to Shallow Neural\n  Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:2101.12365", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the variation space corresponding to a dictionary of functions in\n$L^2(\\Omega)$ and present the basic theory of approximation in these spaces.\nSpecifically, we compare the definition based on integral representations with\nthe definition in terms of convex hulls. We show that in many cases, including\nthe dictionaries corresponding to shallow ReLU$^k$ networks and a dictionary of\ndecaying Fourier modes, that the two definitions coincide. We also give a\npartial characterization of the variation space for shallow ReLU$^k$ networks\nand show that the variation space with respect to the dictionary of decaying\nFourier modes corresponds to the Barron spectral space.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 22:11:14 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Siegel", "Jonathan W.", ""], ["Xu", "Jinchao", ""]]}, {"id": "2106.15013", "submitter": "Dominik St\\\"oger", "authors": "Dominik St\\\"oger and Mahdi Soltanolkotabi", "title": "Small random initialization is akin to spectral learning: Optimization\n  and generalization guarantees for overparameterized low-rank matrix\n  reconstruction", "comments": "80 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been significant theoretical progress on understanding the\nconvergence and generalization of gradient-based methods on nonconvex losses\nwith overparameterized models. Nevertheless, many aspects of optimization and\ngeneralization and in particular the critical role of small random\ninitialization are not fully understood. In this paper, we take a step towards\ndemystifying this role by proving that small random initialization followed by\na few iterations of gradient descent behaves akin to popular spectral methods.\nWe also show that this implicit spectral bias from small random initialization,\nwhich is provably more prominent for overparameterized models, also puts the\ngradient descent iterations on a particular trajectory towards solutions that\nare not only globally optimal but also generalize well. Concretely, we focus on\nthe problem of reconstructing a low-rank matrix from a few measurements via a\nnatural nonconvex formulation. In this setting, we show that the trajectory of\nthe gradient descent iterations from small random initialization can be\napproximately decomposed into three phases: (I) a spectral or alignment phase\nwhere we show that that the iterates have an implicit spectral bias akin to\nspectral initialization allowing us to show that at the end of this phase the\ncolumn space of the iterates and the underlying low-rank matrix are\nsufficiently aligned, (II) a saddle avoidance/refinement phase where we show\nthat the trajectory of the gradient iterates moves away from certain degenerate\nsaddle points, and (III) a local refinement phase where we show that after\navoiding the saddles the iterates converge quickly to the underlying low-rank\nmatrix. Underlying our analysis are insights for the analysis of\noverparameterized nonconvex optimization schemes that may have implications for\ncomputational problems beyond low-rank reconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 22:52:39 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["St\u00f6ger", "Dominik", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2106.15127", "submitter": "David Blanco Mulero", "authors": "David Blanco-Mulero, Markus Heinonen, Ville Kyrki", "title": "Evolving-Graph Gaussian Processes", "comments": "Accepted for publication at ICML 2021 Time Series Workshop (TSW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Gaussian Processes (GGPs) provide a data-efficient solution on graph\nstructured domains. Existing approaches have focused on static structures,\nwhereas many real graph data represent a dynamic structure, limiting the\napplications of GGPs. To overcome this we propose evolving-Graph Gaussian\nProcesses (e-GGPs). The proposed method is capable of learning the transition\nfunction of graph vertices over time with a neighbourhood kernel to model the\nconnectivity and interaction changes between vertices. We assess the\nperformance of our method on time-series regression problems where graphs\nevolve over time. We demonstrate the benefits of e-GGPs over static graph\nGaussian Process approaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 07:16:04 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Blanco-Mulero", "David", ""], ["Heinonen", "Markus", ""], ["Kyrki", "Ville", ""]]}, {"id": "2106.15133", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata", "title": "Meta-learning for Matrix Factorization without Shared Rows or Columns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that meta-learns a knowledge on matrix factorization from\nvarious matrices, and uses the knowledge for factorizing unseen matrices. The\nproposed method uses a neural network that takes a matrix as input, and\ngenerates prior distributions of factorized matrices of the given matrix. The\nneural network is meta-learned such that the expected imputation error is\nminimized when the factorized matrices are adapted to each matrix by a maximum\na posteriori (MAP) estimation. We use a gradient descent method for the MAP\nestimation, which enables us to backpropagate the expected imputation error\nthrough the gradient descent steps for updating neural network parameters since\neach gradient descent step is written in a closed form and is differentiable.\nThe proposed method can meta-learn from matrices even when their rows and\ncolumns are not shared, and their sizes are different from each other. In our\nexperiments with three user-item rating datasets, we demonstrate that our\nproposed method can impute the missing values from a limited number of\nobservations in unseen matrices after being trained with different matrices.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 07:40:20 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Iwata", "Tomoharu", ""]]}, {"id": "2106.15185", "submitter": "Dongha Kim", "authors": "Dongha Kim, Yongchan Choi, Kunwoong Kim, Yongdai Kim", "title": "INN: A Method Identifying Clean-annotated Samples via Consistency Effect\n  in Deep Neural Networks", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many classification problems, collecting massive clean-annotated data is\nnot easy, and thus a lot of researches have been done to handle data with noisy\nlabels. Most recent state-of-art solutions for noisy label problems are built\non the small-loss strategy which exploits the memorization effect. While it is\na powerful tool, the memorization effect has several drawbacks. The\nperformances are sensitive to the choice of a training epoch required for\nutilizing the memorization effect. In addition, when the labels are heavily\ncontaminated or imbalanced, the memorization effect may not occur in which case\nthe methods based on the small-loss strategy fail to identify clean labeled\ndata. We introduce a new method called INN(Integration with the Nearest\nNeighborhoods) to refine clean labeled data from training data with noisy\nlabels. The proposed method is based on a new discovery that a prediction\npattern at neighbor regions of clean labeled data is consistently different\nfrom that of noisy labeled data regardless of training epochs. The INN method\nrequires more computation but is much stable and powerful than the small-loss\nstrategy. By carrying out various experiments, we demonstrate that the INN\nmethod resolves the shortcomings in the memorization effect successfully and\nthus is helpful to construct more accurate deep prediction models with training\ndata with noisy labels.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:06:21 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kim", "Dongha", ""], ["Choi", "Yongchan", ""], ["Kim", "Kunwoong", ""], ["Kim", "Yongdai", ""]]}, {"id": "2106.15207", "submitter": "Uri Sherman", "authors": "Uri Sherman, Tomer Koren, Yishay Mansour", "title": "Optimal Rates for Random Order Online Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online convex optimization in the random order model, recently\nproposed by \\citet{garber2020online}, where the loss functions may be chosen by\nan adversary, but are then presented to the online algorithm in a uniformly\nrandom order. Focusing on the scenario where the cumulative loss function is\n(strongly) convex, yet individual loss functions are smooth but might be\nnon-convex, we give algorithms that achieve the optimal bounds and\nsignificantly outperform the results of \\citet{garber2020online}, completely\nremoving the dimension dependence and improving their scaling with respect to\nthe strong convexity parameter. Our analysis relies on novel connections\nbetween algorithmic stability and generalization for sampling\nwithout-replacement analogous to those studied in the with-replacement\ni.i.d.~setting, as well as on a refined average stability analysis of\nstochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:48:46 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Sherman", "Uri", ""], ["Koren", "Tomer", ""], ["Mansour", "Yishay", ""]]}, {"id": "2106.15214", "submitter": "Arthur Marmin", "authors": "Arthur Marmin and Jos\\'e Henrique de Morais Goulart and C\\'edric\n  F\\'evotte", "title": "Joint Majorization-Minimization for Nonnegative Matrix Factorization\n  with the $\\beta$-divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes new multiplicative updates for nonnegative matrix\nfactorization (NMF) with the $\\beta$-divergence objective function. Our new\nupdates are derived from a joint majorization-minimization (MM) scheme, in\nwhich an auxiliary function (a tight upper bound of the objective function) is\nbuilt for the two factors jointly and minimized at each iteration. This is in\ncontrast with the classic approach in which the factors are optimized\nalternately and a MM scheme is applied to each factor individually. Like the\nclassic approach, our joint MM algorithm also results in multiplicative updates\nthat are simple to implement. They however yield a significant drop of\ncomputation time (for equally good solutions), in particular for some\n$\\beta$-divergences of important applicative interest, such as the squared\nEuclidean distance and the Kullback-Leibler or Itakura-Saito divergences. We\nreport experimental results using diverse datasets: face images, audio\nspectrograms, hyperspectral data and song play counts. Depending on the value\nof $\\beta$ and on the dataset, our joint MM approach yields a CPU time\nreduction of about $10\\%$ to $78\\%$ in comparison to the classic alternating\nscheme.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:58:21 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Marmin", "Arthur", ""], ["Goulart", "Jos\u00e9 Henrique de Morais", ""], ["F\u00e9votte", "C\u00e9dric", ""]]}, {"id": "2106.15216", "submitter": "Pengkun Yang", "authors": "Lili Su, Jiaming Xu, Pengkun Yang", "title": "Achieving Statistical Optimality of Federated Learning: Beyond\n  Stationary Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a promising framework that has great potentials in\nprivacy preservation and in lowering the computation load at the cloud. FedAvg\nand FedProx are two widely adopted algorithms. However, recent work raised\nconcerns on these two methods: (1) their fixed points do not correspond to the\nstationary points of the original optimization problem, and (2) the common\nmodel found might not generalize well locally.\n  In this paper, we alleviate these concerns. Towards this, we adopt the\nstatistical learning perspective yet allow the distributions to be\nheterogeneous and the local data to be unbalanced. We show, in the general\nkernel regression setting, that both FedAvg and FedProx converge to the\nminimax-optimal error rates. Moreover, when the kernel function has a finite\nrank, the convergence is exponentially fast. Our results further analytically\nquantify the impact of the model heterogeneity and characterize the federation\ngain - the reduction of the estimation error for a worker to join the federated\nlearning compared to the best local estimator. To the best of our knowledge, we\nare the first to show the achievability of minimax error rates under FedAvg and\nFedProx, and the first to characterize the gains in joining FL. Numerical\nexperiments further corroborate our theoretical findings on the statistical\noptimality of FedAvg and FedProx and the federation gains.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 09:59:43 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Su", "Lili", ""], ["Xu", "Jiaming", ""], ["Yang", "Pengkun", ""]]}, {"id": "2106.15307", "submitter": "Martin Bauw", "authors": "Martin Bauw, Santiago Velasco-Forero, Jesus Angulo, Claude Adnet,\n  Olivier Airiau", "title": "Deep Random Projection Outlyingness for Unsupervised Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random projection is a common technique for designing algorithms in a variety\nof areas, including information retrieval, compressive sensing and measuring of\noutlyingness. In this work, the original random projection outlyingness measure\nis modified and associated with a neural network to obtain an unsupervised\nanomaly detection method able to handle multimodal normality. Theoretical and\nexperimental arguments are presented to justify the choices of the anomaly\nscore estimator, the dimensions of the random projections, and the number of\nsuch projections. The contribution of adapted dropouts is investigated, along\nwith the affine stability of the proposed method. The performance of the\nproposed neural network approach is comparable to a state-of-the-art anomaly\ndetection method. Experiments conducted on the MNIST, Fashion-MNIST and\nCIFAR-10 datasets show the relevance of the proposed approach, and suggest a\npossible extension to a semi-supervised setup.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 14:13:43 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bauw", "Martin", ""], ["Velasco-Forero", "Santiago", ""], ["Angulo", "Jesus", ""], ["Adnet", "Claude", ""], ["Airiau", "Olivier", ""]]}, {"id": "2106.15356", "submitter": "Liwei Wang", "authors": "Liwei Wang, Suraj Yerramilli, Akshay Iyer, Daniel Apley, Ping Zhu, Wei\n  Chen", "title": "Scalable Gaussian Processes for Data-Driven Design using Big Data with\n  Categorical Factors", "comments": "Preprint submitted to Journal of Mechanical Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific and engineering problems often require the use of artificial\nintelligence to aid understanding and the search for promising designs. While\nGaussian processes (GP) stand out as easy-to-use and interpretable learners,\nthey have difficulties in accommodating big datasets, categorical inputs, and\nmultiple responses, which has become a common challenge for a growing number of\ndata-driven design applications. In this paper, we propose a GP model that\nutilizes latent variables and functions obtained through variational inference\nto address the aforementioned challenges simultaneously. The method is built\nupon the latent variable Gaussian process (LVGP) model where categorical\nfactors are mapped into a continuous latent space to enable GP modeling of\nmixed-variable datasets. By extending variational inference to LVGP models, the\nlarge training dataset is replaced by a small set of inducing points to address\nthe scalability issue. Output response vectors are represented by a linear\ncombination of independent latent functions, forming a flexible kernel\nstructure to handle multiple responses that might have distinct behaviors.\nComparative studies demonstrate that the proposed method scales well for large\ndatasets with over 10^4 data points, while outperforming state-of-the-art\nmachine learning methods without requiring much hyperparameter tuning. In\naddition, an interpretable latent space is obtained to draw insights into the\neffect of categorical factors, such as those associated with building blocks of\narchitectures and element choices in metamaterial and materials design. Our\napproach is demonstrated for machine learning of ternary oxide materials and\ntopology optimization of a multiscale compliant mechanism with aperiodic\nmicrostructures and multiple materials.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 02:17:23 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 01:59:01 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Wang", "Liwei", ""], ["Yerramilli", "Suraj", ""], ["Iyer", "Akshay", ""], ["Apley", "Daniel", ""], ["Zhu", "Ping", ""], ["Chen", "Wei", ""]]}, {"id": "2106.15358", "submitter": "Zhaoqiang Liu", "authors": "Zhaoqiang Liu, Subhroshekhar Ghosh, Jonathan Scarlett", "title": "Towards Sample-Optimal Compressive Phase Retrieval with Sparse and\n  Generative Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compressive phase retrieval is a popular variant of the standard compressive\nsensing problem, in which the measurements only contain magnitude information.\nIn this paper, motivated by recent advances in deep generative models, we\nprovide recovery guarantees with order-optimal sample complexity bounds for\nphase retrieval with generative priors. We first show that when using i.i.d.\nGaussian measurements and an $L$-Lipschitz continuous generative model with\nbounded $k$-dimensional inputs, roughly $O(k \\log L)$ samples suffice to\nguarantee that the signal is close to any vector that minimizes an\namplitude-based empirical loss function. Attaining this sample complexity with\na practical algorithm remains a difficult challenge, and a popular spectral\ninitialization method has been observed to pose a major bottleneck. To\npartially address this, we further show that roughly $O(k \\log L)$ samples\nensure sufficient closeness between the signal and any {\\em globally optimal}\nsolution to an optimization problem designed for spectral initialization\n(though finding such a solution may still be challenging). We adapt this result\nto sparse phase retrieval, and show that $O(s \\log n)$ samples are sufficient\nfor a similar guarantee when the underlying signal is $s$-sparse and\n$n$-dimensional, matching an information-theoretic lower bound. While our\nguarantees do not directly correspond to a practical algorithm, we propose a\npractical spectral initialization method motivated by our findings, and\nexperimentally observe significant performance gains over various existing\nspectral initialization methods of sparse phase retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 12:49:54 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Liu", "Zhaoqiang", ""], ["Ghosh", "Subhroshekhar", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2106.15379", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Unified Framework for Spectral Dimensionality Reduction, Maximum\n  Variance Unfolding, and Kernel Learning By Semidefinite Programming: Tutorial\n  and Survey", "comments": "To appear as a part of an upcoming textbook on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a tutorial and survey paper on unification of spectral dimensionality\nreduction methods, kernel learning by Semidefinite Programming (SDP), Maximum\nVariance Unfolding (MVU) or Semidefinite Embedding (SDE), and its variants. We\nfirst explain how the spectral dimensionality reduction methods can be unified\nas kernel Principal Component Analysis (PCA) with different kernels. This\nunification can be interpreted as eigenfunction learning or representation of\nkernel in terms of distance matrix. Then, since the spectral methods are\nunified as kernel PCA, we say let us learn the best kernel for unfolding the\nmanifold of data to its maximum variance. We first briefly introduce kernel\nlearning by SDP for the transduction task. Then, we explain MVU in detail.\nVarious versions of supervised MVU using nearest neighbors graph, by class-wise\nunfolding, by Fisher criterion, and by colored MVU are explained. We also\nexplain out-of-sample extension of MVU using eigenfunctions and kernel mapping.\nFinally, we introduce other variants of MVU including action respecting\nembedding, relaxed MVU, and landmark MVU for big data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 13:09:40 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2106.15400", "submitter": "Chuanhou Gao", "authors": "Qiuqiang Lin and Chuanhou Gao", "title": "Online Interaction Detection for Click-Through Rate Prediction", "comments": "11pages, 4 figures, 1 supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-Through Rate prediction aims to predict the ratio of clicks to\nimpressions of a specific link. This is a challenging task since (1) there are\nusually categorical features, and the inputs will be extremely high-dimensional\nif one-hot encoding is applied, (2) not only the original features but also\ntheir interactions are important, (3) an effective prediction may rely on\ndifferent features and interactions in different time periods. To overcome\nthese difficulties, we propose a new interaction detection method, named Online\nRandom Intersection Chains. The method, which is based on the idea of frequent\nitemset mining, detects informative interactions by observing the intersections\nof randomly chosen samples. The discovered interactions enjoy high\ninterpretability as they can be comprehended as logical expressions. ORIC can\nbe updated every time new data is collected, without being retrained on\nhistorical data. What's more, the importance of the historical and latest data\ncan be controlled by a tuning parameter. A framework is designed to deal with\nthe streaming interactions, so almost all existing models for CTR prediction\ncan be applied after interaction detection. Empirical results demonstrate the\nefficiency and effectiveness of ORIC on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 06:34:03 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Lin", "Qiuqiang", ""], ["Gao", "Chuanhou", ""]]}, {"id": "2106.15416", "submitter": "Alexander Gorban", "authors": "Alexander N. Gorban, Bogdan Grechuk, Evgeny M. Mirkes, Sergey V.\n  Stasenko, Ivan Y. Tyukin", "title": "High-dimensional separability for one- and few-shot learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work is driven by a practical question, corrections of Artificial\nIntelligence (AI) errors. Systematic re-training of a large AI system is hardly\npossible. To solve this problem, special external devices, correctors, are\ndeveloped. They should provide quick and non-iterative system fix without\nmodification of a legacy AI system. A common universal part of the AI corrector\nis a classifier that should separate undesired and erroneous behavior from\nnormal operation. Training of such classifiers is a grand challenge at the\nheart of the one- and few-shot learning methods. Effectiveness of one- and\nfew-short methods is based on either significant dimensionality reductions or\nthe blessing of dimensionality effects. Stochastic separability is a blessing\nof dimensionality phenomenon that allows one-and few-shot error correction: in\nhigh-dimensional datasets under broad assumptions each point can be separated\nfrom the rest of the set by simple and robust linear discriminant. The\nhierarchical structure of data universe is introduced where each data cluster\nhas a granular internal structure, etc. New stochastic separation theorems for\nthe data distributions with fine-grained structure are formulated and proved.\nSeparation theorems in infinite-dimensional limits are proven under assumptions\nof compact embedding of patterns into data space. New multi-correctors of AI\nsystems are presented and illustrated with examples of predicting errors and\nlearning new classes of objects by a deep convolutional neural network.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:58:14 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Gorban", "Alexander N.", ""], ["Grechuk", "Bogdan", ""], ["Mirkes", "Evgeny M.", ""], ["Stasenko", "Sergey V.", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "2106.15427", "submitter": "Kimia Nadjahi", "authors": "Kimia Nadjahi, Alain Durmus, Pierre E. Jacob, Roland Badeau, Umut\n  \\c{S}im\\c{s}ekli", "title": "Fast Approximation of the Sliced-Wasserstein Distance Using\n  Concentration of Random Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sliced-Wasserstein distance (SW) is being increasingly used in machine\nlearning applications as an alternative to the Wasserstein distance and offers\nsignificant computational and statistical benefits. Since it is defined as an\nexpectation over random projections, SW is commonly approximated by Monte\nCarlo. We adopt a new perspective to approximate SW by making use of the\nconcentration of measure phenomenon: under mild assumptions, one-dimensional\nprojections of a high-dimensional random vector are approximately Gaussian.\nBased on this observation, we develop a simple deterministic approximation for\nSW. Our method does not require sampling a number of random projections, and is\ntherefore both accurate and easy to use compared to the usual Monte Carlo\napproximation. We derive nonasymptotical guarantees for our approach, and show\nthat the approximation error goes to zero as the dimension increases, under a\nweak dependence condition on the data distribution. We validate our theoretical\nfindings on synthetic datasets, and illustrate the proposed approximation on a\ngenerative modeling problem.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 13:56:19 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Nadjahi", "Kimia", ""], ["Durmus", "Alain", ""], ["Jacob", "Pierre E.", ""], ["Badeau", "Roland", ""], ["\u015eim\u015fekli", "Umut", ""]]}, {"id": "2106.15481", "submitter": "Takanori Fujiwara", "authors": "Takanori Fujiwara, Xinhai Wei, Jian Zhao, Kwan-Liu Ma", "title": "Interactive Dimensionality Reduction for Comparative Analysis", "comments": "This manuscript is currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the similarities and differences between two or more groups of\ndatasets is a fundamental analysis task. For high-dimensional data,\ndimensionality reduction (DR) methods are often used to find the\ncharacteristics of each group. However, existing DR methods provide limited\ncapability and flexibility for such comparative analysis as each method is\ndesigned only for a narrow analysis target, such as identifying factors that\nmost differentiate groups. In this work, we introduce an interactive DR\nframework where we integrate our new DR method, called ULCA (unified linear\ncomparative analysis), with an interactive visual interface. ULCA unifies two\nDR schemes, discriminant analysis and contrastive learning, to support various\ncomparative analysis tasks. To provide flexibility for comparative analysis, we\ndevelop an optimization algorithm that enables analysts to interactively refine\nULCA results. Additionally, we provide an interactive visualization interface\nto examine ULCA results with a rich set of analysis libraries. We evaluate ULCA\nand the optimization algorithm to show their efficiency as well as present\nmultiple case studies using real-world datasets to demonstrate the usefulness\nof our framework.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:05:36 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Fujiwara", "Takanori", ""], ["Wei", "Xinhai", ""], ["Zhao", "Jian", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2106.15482", "submitter": "Idan Achituve", "authors": "Idan Achituve, Aviv Shamsian, Aviv Navon, Gal Chechik, Ethan Fetaya", "title": "Personalized Federated Learning with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Federated learning aims to learn a global model that performs well on client\ndevices with limited cross-client communication. Personalized federated\nlearning (PFL) further extends this setup to handle data heterogeneity between\nclients by learning personalized models. A key challenge in this setting is to\nlearn effectively across clients even though each client has unique data that\nis often limited in size. Here we present pFedGP, a solution to PFL that is\nbased on Gaussian processes (GPs) with deep kernel learning. GPs are highly\nexpressive models that work well in the low data regime due to their Bayesian\nnature. However, applying GPs to PFL raises multiple challenges. Mainly, GPs\nperformance depends heavily on access to a good kernel function, and learning a\nkernel requires a large training set. Therefore, we propose learning a shared\nkernel function across all clients, parameterized by a neural network, with a\npersonal GP classifier for each client. We further extend pFedGP to include\ninducing points using two novel methods, the first helps to improve\ngeneralization in the low data regime and the second reduces the computational\ncost. We derive a PAC-Bayes generalization bound on novel clients and\nempirically show that it gives non-vacuous guarantees. Extensive experiments on\nstandard PFL benchmarks with CIFAR-10, CIFAR-100, and CINIC-10, and on a new\nsetup of learning under input noise show that pFedGP achieves well-calibrated\npredictions while significantly outperforming baseline methods, reaching up to\n21% in accuracy gain.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:09:13 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Achituve", "Idan", ""], ["Shamsian", "Aviv", ""], ["Navon", "Aviv", ""], ["Chechik", "Gal", ""], ["Fetaya", "Ethan", ""]]}, {"id": "2106.15493", "submitter": "Shuyang Ling", "authors": "Shuyang Ling", "title": "Generalized Power Method for Generalized Orthogonal Procrustes Problem:\n  Global Convergence and Optimization Landscape Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a set of multiple point clouds, how to find the rigid transformations\n(rotation, reflection, and shifting) such that these point clouds are well\naligned? This problem, known as the generalized orthogonal Procrustes problem\n(GOPP), plays a fundamental role in several scientific disciplines including\nstatistics, imaging science and computer vision. Despite its tremendous\npractical importance, it is still a challenging computational problem due to\nthe inherent nonconvexity. In this paper, we study the semidefinite programming\n(SDP) relaxation of the generalized orthogonal Procrustes problems and prove\nthat the tightness of the SDP relaxation holds, i.e., the SDP estimator exactly\nequals the least squares estimator, if the signal-to-noise ratio (SNR) is\nrelatively large. We also prove that an efficient generalized power method with\na proper initialization enjoys global linear convergence to the least squares\nestimator. In addition, we analyze the Burer-Monteiro factorization and show\nthe corresponding optimization landscape is free of spurious local optima if\nthe SNR is large. This explains why first-order Riemannian gradient methods\nwith random initializations usually produce a satisfactory solution despite the\nnonconvexity. One highlight of our work is that the theoretical guarantees are\npurely algebraic and do not require any assumptions on the statistical property\nof the noise. Our results partially resolve one open problem posed in\n[Bandeira, Khoo, Singer, 2014] on the tightness of the SDP relaxation in\nsolving the generalized orthogonal Procrustes problem. Numerical simulations\nare provided to complement our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 15:19:25 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ling", "Shuyang", ""]]}, {"id": "2106.15563", "submitter": "Bohdan Kivva", "authors": "Bohdan Kivva, Goutham Rajendran, Pradeep Ravikumar and Bryon Aragam", "title": "Learning latent causal graphs via mixture oracles", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of reconstructing a causal graphical model from data in\nthe presence of latent variables. The main problem of interest is recovering\nthe causal structure over the latent variables while allowing for general,\npotentially nonlinear dependence between the variables. In many practical\nproblems, the dependence between raw observations (e.g. pixels in an image) is\nmuch less relevant than the dependence between certain high-level, latent\nfeatures (e.g. concepts or objects), and this is the setting of interest. We\nprovide conditions under which both the latent representations and the\nunderlying latent causal model are identifiable by a reduction to a mixture\noracle. The proof is constructive, and leads to several algorithms for\nexplicitly reconstructing the full graphical model. We discuss efficient\nalgorithms and provide experiments illustrating the algorithms in practice.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:53:34 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kivva", "Bohdan", ""], ["Rajendran", "Goutham", ""], ["Ravikumar", "Pradeep", ""], ["Aragam", "Bryon", ""]]}, {"id": "2106.15566", "submitter": "Lunjia Hu", "authors": "Moses Charikar, Lunjia Hu", "title": "Near-Optimal Explainable $k$-Means for All Dimensions", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many clustering algorithms are guided by certain cost functions such as the\nwidely-used $k$-means cost. These algorithms divide data points into clusters\nwith often complicated boundaries, creating difficulties in explaining the\nclustering decision. In a recent work, Dasgupta, Frost, Moshkovitz, and\nRashtchian (ICML'20) introduced explainable clustering, where the cluster\nboundaries are axis-parallel hyperplanes and the clustering is obtained by\napplying a decision tree to the data. The central question here is: how much\ndoes the explainability constraint increase the value of the cost function?\n  Given $d$-dimensional data points, we show an efficient algorithm that finds\nan explainable clustering whose $k$-means cost is at most $k^{1 -\n2/d}\\mathrm{poly}(d\\log k)$ times the minimum cost achievable by a clustering\nwithout the explainability constraint, assuming $k,d\\ge 2$. Combining this with\nan independent work by Makarychev and Shan (ICML'21), we get an improved bound\nof $k^{1 - 2/d}\\mathrm{polylog}(k)$, which we show is optimal for every choice\nof $k,d\\ge 2$ up to a poly-logarithmic factor in $k$. For $d = 2$ in\nparticular, we show an $O(\\log k\\log\\log k)$ bound, improving exponentially\nover the previous best bound of $\\widetilde O(k)$.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:59:03 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Charikar", "Moses", ""], ["Hu", "Lunjia", ""]]}, {"id": "2106.15577", "submitter": "Fiorella Wever", "authors": "Fiorella Wever, T. Anderson Keller, Victor Garcia, Laura Symul", "title": "As easy as APC: Leveraging self-supervised learning in the context of\n  time series classification with varying levels of sparsity and severe class\n  imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High levels of sparsity and strong class imbalance are ubiquitous challenges\nthat are often presented simultaneously in real-world time series data. While\nmost methods tackle each problem separately, our proposed approach handles both\nin conjunction, while imposing fewer assumptions on the data. In this work, we\npropose leveraging a self-supervised learning method, specifically\nAutoregressive Predictive Coding (APC), to learn relevant hidden\nrepresentations of time series data in the context of both missing data and\nclass imbalance. We apply APC using either a GRU or GRU-D encoder on two\nreal-world datasets, and show that applying one-step-ahead prediction with APC\nimproves the classification results in all settings. In fact, by applying GRU-D\n- APC, we achieve state-of-the-art AUPRC results on the Physionet benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:11:36 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Wever", "Fiorella", ""], ["Keller", "T. Anderson", ""], ["Garcia", "Victor", ""], ["Symul", "Laura", ""]]}, {"id": "2106.15580", "submitter": "Ruizhi Deng", "authors": "Ruizhi Deng, Marcus A. Brubaker, Greg Mori, Andreas M. Lehrmann", "title": "Continuous Latent Process Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial observations of continuous time-series dynamics at arbitrary time\nstamps exist in many disciplines. Fitting this type of data using statistical\nmodels with continuous dynamics is not only promising at an intuitive level but\nalso has practical benefits, including the ability to generate continuous\ntrajectories and to perform inference on previously unseen time stamps. Despite\nexciting progress in this area, the existing models still face challenges in\nterms of their representational power and the quality of their variational\napproximations. We tackle these challenges with continuous latent process flows\n(CLPF), a principled architecture decoding continuous latent processes into\ncontinuous observable processes using a time-dependent normalizing flow driven\nby a stochastic differential equation. To optimize our model using maximum\nlikelihood, we propose a novel piecewise construction of a variational\nposterior process and derive the corresponding variational lower bound using\ntrajectory re-weighting. Our ablation studies demonstrate the effectiveness of\nour contributions in various inference tasks on irregular time grids.\nComparisons to state-of-the-art baselines show our model's favourable\nperformance on both synthetic and real-world time-series data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:16:04 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Deng", "Ruizhi", ""], ["Brubaker", "Marcus A.", ""], ["Mori", "Greg", ""], ["Lehrmann", "Andreas M.", ""]]}, {"id": "2106.15662", "submitter": "Mingda Qiao", "authors": "Mingda Qiao, Gregory Valiant", "title": "Exponential Weights Algorithms for Selective Learning", "comments": "To appear in COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the selective learning problem introduced by Qiao and Valiant\n(2019), in which the learner observes $n$ labeled data points one at a time. At\na time of its choosing, the learner selects a window length $w$ and a model\n$\\hat\\ell$ from the model class $\\mathcal{L}$, and then labels the next $w$\ndata points using $\\hat\\ell$. The excess risk incurred by the learner is\ndefined as the difference between the average loss of $\\hat\\ell$ over those $w$\ndata points and the smallest possible average loss among all models in\n$\\mathcal{L}$ over those $w$ data points.\n  We give an improved algorithm, termed the hybrid exponential weights\nalgorithm, that achieves an expected excess risk of $O((\\log\\log|\\mathcal{L}| +\n\\log\\log n)/\\log n)$. This result gives a doubly exponential improvement in the\ndependence on $|\\mathcal{L}|$ over the best known bound of\n$O(\\sqrt{|\\mathcal{L}|/\\log n})$. We complement the positive result with an\nalmost matching lower bound, which suggests the worst-case optimality of the\nalgorithm.\n  We also study a more restrictive family of learning algorithms that are\nbounded-recall in the sense that when a prediction window of length $w$ is\nchosen, the learner's decision only depends on the most recent $w$ data points.\nWe analyze an exponential weights variant of the ERM algorithm in Qiao and\nValiant (2019). This new algorithm achieves an expected excess risk of\n$O(\\sqrt{\\log |\\mathcal{L}|/\\log n})$, which is shown to be nearly optimal\namong all bounded-recall learners. Our analysis builds on a generalized version\nof the selective mean prediction problem in Drucker (2013); Qiao and Valiant\n(2019), which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:14:01 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Qiao", "Mingda", ""], ["Valiant", "Gregory", ""]]}, {"id": "2106.15666", "submitter": "Jacob Miller", "authors": "Jacob Miller and Geoffrey Roeder and Tai-Danae Bradley", "title": "Probabilistic Graphical Models and Tensor Networks: A Hybrid Framework", "comments": "18 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a correspondence between two formalisms for discrete\nprobabilistic modeling: probabilistic graphical models (PGMs) and tensor\nnetworks (TNs), a powerful modeling framework for simulating complex quantum\nsystems. The graphical calculus of PGMs and TNs exhibits many similarities,\nwith discrete undirected graphical models (UGMs) being a special case of TNs.\nHowever, more general probabilistic TN models such as Born machines (BMs)\nemploy complex-valued hidden states to produce novel forms of correlation among\nthe probabilities. While representing a new modeling resource for capturing\nstructure in discrete probability distributions, this behavior also renders the\ndirect application of standard PGM tools impossible. We aim to bridge this gap\nby introducing a hybrid PGM-TN formalism that integrates quantum-like\ncorrelations into PGM models in a principled manner, using the\nphysically-motivated concept of decoherence. We first prove that applying\ndecoherence to the entirety of a BM model converts it into a discrete UGM, and\nconversely, that any subgraph of a discrete UGM can be represented as a\ndecohered BM. This method allows a broad family of probabilistic TN models to\nbe encoded as partially decohered BMs, a fact we leverage to combine the\nrepresentational strengths of both model families. We experimentally verify the\nperformance of such hybrid models in a sequential modeling task, and identify\npromising uses of our method within the context of existing applications of\ngraphical models.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:20:44 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Miller", "Jacob", ""], ["Roeder", "Geoffrey", ""], ["Bradley", "Tai-Danae", ""]]}, {"id": "2106.15685", "submitter": "Gabriel Ocker", "authors": "Gabriel Koch Ocker and Michael A. Buice", "title": "Tensor decomposition of higher-order correlations by nonlinear Hebbian\n  plasticity", "comments": "9 pages, 3 figures + supplemental 20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological synaptic plasticity exhibits nonlinearities that are not accounted\nfor by classic Hebbian learning rules. Here, we introduce a simple family of\ngeneralized, nonlinear Hebbian learning rules. We study the computations\nimplemented by their dynamics in the simple setting of a neuron receiving\nfeedforward inputs. We show that these nonlinear Hebbian rules allow a neuron\nto learn tensor decompositions of its higher-order input correlations. The\nparticular input correlation decomposed, and the form of the decomposition,\ndepend on the location of nonlinearities in the plasticity rule. For simple,\nbiologically motivated parameters, the neuron learns tensor eigenvectors of\nhigher-order input correlations. We prove that each tensor eigenvector is an\nattractor and determine their basins of attraction. We calculate the volume of\nthose basins, showing that the dominant eigenvector has the largest basin of\nattraction. We then study arbitrary learning rules, and find that any learning\nrule that admits a finite Taylor expansion into the neural input and output\nalso has stable equilibria at tensor eigenvectors of its higher-order input\ncorrelations. Nonlinearities in synaptic plasticity thus allow a neuron to\nencode higher-order input correlations in a simple fashion.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 19:24:35 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ocker", "Gabriel Koch", ""], ["Buice", "Michael A.", ""]]}, {"id": "2106.15735", "submitter": "Guangning Xu", "authors": "Geng Deng, Guangning Xu, Qiang Fu, Xindong Wang and Jing Qin", "title": "Active-set algorithms based statistical inference for shape-restricted\n  generalized additive Cox regression models", "comments": "Updated with new latex template, 33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the shape-restricted inference has gained popularity in statistical\nand econometric literature in order to relax the linear or quadratic covariate\neffect in regression analyses. The typical shape-restricted covariate effect\nincludes monotonic increasing, decreasing, convexity or concavity. In this\npaper, we introduce the shape-restricted inference to the celebrated Cox\nregression model (SR-Cox), in which the covariate response is modeled as\nshape-restricted additive functions. The SR-Cox regression approximates the\nshape-restricted functions using a spline basis expansion with data driven\nchoice of knots. The underlying minimization of negative log-likelihood\nfunction is formulated as a convex optimization problem, which is solved with\nan active-set optimization algorithm. The highlight of this algorithm is that\nit eliminates the superfluous knots automatically. When covariate effects\ninclude combinations of convex or concave terms with unknown forms and linear\nterms, the most interesting finding is that SR-Cox produces accurate linear\ncovariate effect estimates which are comparable to the maximum partial\nlikelihood estimates if indeed the forms are known. We conclude that concave or\nconvex SR-Cox models could significantly improve nonlinear covariate response\nrecovery and model goodness of fit.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 21:40:28 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 15:29:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Deng", "Geng", ""], ["Xu", "Guangning", ""], ["Fu", "Qiang", ""], ["Wang", "Xindong", ""], ["Qin", "Jing", ""]]}, {"id": "2106.15737", "submitter": "Laura Balzer PhD", "authors": "Laura B. Balzer, Mark van der Laan, James Ayieko, Moses Kamya, Gabriel\n  Chamie, Joshua Schwab, Diane V. Havlir, Maya L. Petersen", "title": "Two-Stage TMLE to Reduce Bias and Improve Efficiency in Cluster\n  Randomized Trials", "comments": "32 pages (16.5 pgs of main text); 1 figure; 3 main tables; 3 supp\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cluster randomized trials (CRTs) randomly assign an intervention to groups of\nindividuals (e.g., clinics or communities), and measure outcomes on individuals\nin those groups. While offering many advantages, this experimental design\nintroduces challenges that are only partially addressed by existing analytic\napproaches. First, outcomes are often missing for some individuals within\nclusters. Failing to appropriately adjust for differential outcome measurement\ncan result in biased estimates and inference. Second, CRTs often randomize\nlimited numbers of clusters, resulting in chance imbalances on baseline outcome\npredictors between arms. Failing to adaptively adjust for these imbalances and\nother predictive covariates can result in efficiency losses. To address these\nmethodological gaps, we propose and evaluate a novel two-stage targeted minimum\nloss-based estimator (TMLE) to adjust for baseline covariates in a manner that\noptimizes precision, after controlling for baseline and post-baseline causes of\nmissing outcomes. Finite sample simulations illustrate that our approach can\nnearly eliminate bias due to differential outcome measurement, while other\ncommon CRT estimators yield misleading results and inferences. Application to\nreal data from the SEARCH community randomized trial demonstrates the gains in\nefficiency afforded through adaptive adjustment for cluster-level covariates,\nafter controlling for missingness on individual-level outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 21:47:30 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Balzer", "Laura B.", ""], ["van der Laan", "Mark", ""], ["Ayieko", "James", ""], ["Kamya", "Moses", ""], ["Chamie", "Gabriel", ""], ["Schwab", "Joshua", ""], ["Havlir", "Diane V.", ""], ["Petersen", "Maya L.", ""]]}, {"id": "2106.15739", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ekaterina Lobacheva, Maxim Kodryan, Nadezhda Chirkova, Andrey Malinin,\n  Dmitry Vetrov", "title": "On the Periodic Behavior of Neural Network Training with Batch\n  Normalization and Weight Decay", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the conventional wisdom that using batch normalization with weight\ndecay may improve neural network training, some recent works show their joint\nusage may cause instabilities at the late stages of training. Other works, in\ncontrast, show convergence to the equilibrium, i.e., the stabilization of\ntraining metrics. In this paper, we study this contradiction and show that\ninstead of converging to a stable equilibrium, the training dynamics converge\nto consistent periodic behavior. That is, the training process regularly\nexhibits instabilities which, however, do not lead to complete training\nfailure, but cause a new period of training. We rigorously investigate the\nmechanism underlying this discovered periodic behavior both from an empirical\nand theoretical point of view and show that this periodic behavior is indeed\ncaused by the interaction between batch normalization and weight decay.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 21:53:14 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lobacheva", "Ekaterina", ""], ["Kodryan", "Maxim", ""], ["Chirkova", "Nadezhda", ""], ["Malinin", "Andrey", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2106.15812", "submitter": "Patrick Chao", "authors": "Patrick Chao, William Fithian", "title": "AdaPT-GMM: Powerful and robust covariate-assisted multiple testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new empirical Bayes method for covariate-assisted multiple\ntesting with false discovery rate (FDR) control, where we model the local false\ndiscovery rate for each hypothesis as a function of both its covariates and\np-value. Our method refines the adaptive p-value thresholding (AdaPT) procedure\nby generalizing its masking scheme to reduce the bias and variance of its false\ndiscovery proportion estimator, improving the power when the rejection set is\nsmall or some null p-values concentrate near 1. We also introduce a Gaussian\nmixture model for the conditional distribution of the test statistics given\ncovariates, modeling the mixing proportions with a generic user-specified\nclassifier, which we implement using a two-layer neural network. Like AdaPT,\nour method provably controls the FDR in finite samples even if the classifier\nor the Gaussian mixture model is misspecified. We show in extensive simulations\nand real data examples that our new method, which we call AdaPT-GMM,\nconsistently delivers high power relative to competing state-of-the-art\nmethods. In particular, it performs well in scenarios where AdaPT is\nunderpowered, and is especially well-suited for testing composite null\nhypothesis, such as whether the effect size exceeds a practical significance\nthreshold.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 05:06:18 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Chao", "Patrick", ""], ["Fithian", "William", ""]]}, {"id": "2106.15821", "submitter": "Eduardo G. Altmann", "authors": "Charles C. Hyland, Yuanming Tao, Lamiae Azizi, Martin Gerlach, Tiago\n  P. Peixoto, and Eduardo G. Altmann", "title": "Multilayer Networks for Text Analysis with Multiple Data Types", "comments": "17 pages, 6 figures", "journal-ref": "EPJ Data Science volume 10, Article number: 33 (2021)", "doi": "10.1140/epjds/s13688-021-00288-5", "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the widespread problem of clustering documents and\nfinding topics in large collections of written documents in the presence of\nmetadata and hyperlinks. To tackle the challenge of accounting for these\ndifferent types of datasets, we propose a novel framework based on Multilayer\nNetworks and Stochastic Block Models. The main innovation of our approach over\nother techniques is that it applies the same non-parametric probabilistic\nframework to the different sources of datasets simultaneously. The key\ndifference to other multilayer complex networks is the strong unbalance between\nthe layers, with the average degree of different node types scaling differently\nwith system size. We show that the latter observation is due to generic\nproperties of text, such as Heaps' law, and strongly affects the inference of\ncommunities. We present and discuss the performance of our method in different\ndatasets (hundreds of Wikipedia documents, thousands of scientific papers, and\nthousands of E-mails) showing that taking into account multiple types of\ninformation provides a more nuanced view on topic- and document-clusters and\nincreases the ability to predict missing links.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 05:47:39 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Hyland", "Charles C.", ""], ["Tao", "Yuanming", ""], ["Azizi", "Lamiae", ""], ["Gerlach", "Martin", ""], ["Peixoto", "Tiago P.", ""], ["Altmann", "Eduardo G.", ""]]}, {"id": "2106.15921", "submitter": "Achille Thin", "authors": "Achille Thin, Nikita Kotelevskii, Arnaud Doucet, Alain Durmus, Eric\n  Moulines, Maxim Panov", "title": "Monte Carlo Variational Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Variational auto-encoders (VAE) are popular deep latent variable models which\nare trained by maximizing an Evidence Lower Bound (ELBO). To obtain tighter\nELBO and hence better variational approximations, it has been proposed to use\nimportance sampling to get a lower variance estimate of the evidence. However,\nimportance sampling is known to perform poorly in high dimensions. While it has\nbeen suggested many times in the literature to use more sophisticated\nalgorithms such as Annealed Importance Sampling (AIS) and its Sequential\nImportance Sampling (SIS) extensions, the potential benefits brought by these\nadvanced techniques have never been realized for VAE: the AIS estimate cannot\nbe easily differentiated, while SIS requires the specification of carefully\nchosen backward Markov kernels. In this paper, we address both issues and\ndemonstrate the performance of the resulting Monte Carlo VAEs on a variety of\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 09:21:47 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Thin", "Achille", ""], ["Kotelevskii", "Nikita", ""], ["Doucet", "Arnaud", ""], ["Durmus", "Alain", ""], ["Moulines", "Eric", ""], ["Panov", "Maxim", ""]]}, {"id": "2106.15927", "submitter": "Xiao-Shan Gao", "authors": "Lijia Yu and Xiao-Shan Gao", "title": "A Robust Classification-autoencoder to Defend Outliers and Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a robust classification-autoencoder (CAE) which has\nstrong ability to recognize outliers and defend adversaries. The basic idea is\nto change the autoencoder from an unsupervised learning method into a\nclassifier. The CAE is a modified autoencoder, where the encoder is used to\ncompress samples with different labels into disjoint compression spaces and the\ndecoder is used to recover a sample with a given label from the corresponding\ncompression space. The encoder is used as a classifier and the decoder is used\nto decide whether the classification given by the encoder is correct by\ncomparing the input sample with the output. Since adversary samples are seeming\ninevitable for the current DNN framework, we introduce the list classification\nbased on CAE to defend adversaries, which outputs several labels and the\ncorresponding samples recovered by the CAE. The CAE is evaluated using the\nMNIST dataset in great detail. It is shown that the CAE network can recognize\nalmost all outliers and the list classification contains the correct label for\nalmost all adversaries.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 09:30:31 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Yu", "Lijia", ""], ["Gao", "Xiao-Shan", ""]]}, {"id": "2106.15933", "submitter": "Arthur Jacot", "authors": "Arthur Jacot, Fran\\c{c}ois Ged, Franck Gabriel, Berfin \\c{S}im\\c{s}ek,\n  Cl\\'ement Hongler", "title": "Deep Linear Networks Dynamics: Low-Rank Biases Induced by Initialization\n  Scale and L2 Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For deep linear networks (DLN), various hyperparameters alter the dynamics of\ntraining dramatically. We investigate how the rank of the linear map found by\ngradient descent is affected by (1) the initialization norm and (2) the\naddition of $L_{2}$ regularization on the parameters. For (1), we study two\nregimes: (1a) the linear/lazy regime, for large norm initialization; (1b) a\n\\textquotedbl saddle-to-saddle\\textquotedbl{} regime for small initialization\nnorm. In the (1a) setting, the dynamics of a DLN of any depth is similar to\nthat of a standard linear model, without any low-rank bias. In the (1b)\nsetting, we conjecture that throughout training, gradient descent approaches a\nsequence of saddles, each corresponding to linear maps of increasing rank,\nuntil reaching a minimal rank global minimum. We support this conjecture with a\npartial proof and some numerical experiments. For (2), we show that adding a\n$L_{2}$ regularization on the parameters corresponds to the addition to the\ncost of a $L_{p}$-Schatten (quasi)norm on the linear map with $p=\\frac{2}{L}$\n(for a depth-$L$ network), leading to a stronger low-rank bias as $L$ grows.\nThe effect of $L_{2}$ regularization on the loss surface depends on the depth:\nfor shallow networks, all critical points are either strict saddles or global\nminima, whereas for deep networks, some local minima appear. We numerically\nobserve that these local minima can generalize better than global ones in some\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 09:34:05 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Jacot", "Arthur", ""], ["Ged", "Fran\u00e7ois", ""], ["Gabriel", "Franck", ""], ["\u015eim\u015fek", "Berfin", ""], ["Hongler", "Cl\u00e9ment", ""]]}, {"id": "2106.15962", "submitter": "Chang Liu", "authors": "Chang Liu, Haoyue Tang, Tao Qin, Jintao Wang, Tie-Yan Liu", "title": "On the Generative Utility of Cyclic Conditionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study whether and how can we model a joint distribution $p(x,z)$ using two\nconditional models $p(x|z)$ and $q(z|x)$ that form a cycle. This is motivated\nby the observation that deep generative models, in addition to a likelihood\nmodel $p(x|z)$, often also use an inference model $q(z|x)$ for data\nrepresentation, but they rely on a usually uninformative prior distribution\n$p(z)$ to define a joint distribution, which may render problems like posterior\ncollapse and manifold mismatch. To explore the possibility to model a joint\ndistribution using only $p(x|z)$ and $q(z|x)$, we study their compatibility and\ndeterminacy, corresponding to the existence and uniqueness of a joint\ndistribution whose conditional distributions coincide with them. We develop a\ngeneral theory for novel and operable equivalence criteria for compatibility,\nand sufficient conditions for determinacy. Based on the theory, we propose the\nCyGen framework for cyclic-conditional generative modeling, including methods\nto enforce compatibility and use the determined distribution to fit and\ngenerate data. With the prior constraint removed, CyGen better fits data and\ncaptures more representative features, supported by experiments showing better\ngeneration and downstream classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 10:23:45 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Liu", "Chang", ""], ["Tang", "Haoyue", ""], ["Qin", "Tao", ""], ["Wang", "Jintao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2106.15980", "submitter": "Ghassen Jerfel", "authors": "Ghassen Jerfel, Serena Wang, Clara Fannjiang, Katherine A. Heller,\n  Yian Ma, Michael I. Jordan", "title": "Variational Refinement for Importance Sampling Using the Forward\n  Kullback-Leibler Divergence", "comments": "Accepted for the 37th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational Inference (VI) is a popular alternative to asymptotically exact\nsampling in Bayesian inference. Its main workhorse is optimization over a\nreverse Kullback-Leibler divergence (RKL), which typically underestimates the\ntail of the posterior leading to miscalibration and potential degeneracy.\nImportance sampling (IS), on the other hand, is often used to fine-tune and\nde-bias the estimates of approximate Bayesian inference procedures. The quality\nof IS crucially depends on the choice of the proposal distribution. Ideally,\nthe proposal distribution has heavier tails than the target, which is rarely\nachievable by minimizing the RKL. We thus propose a novel combination of\noptimization and sampling techniques for approximate Bayesian inference by\nconstructing an IS proposal distribution through the minimization of a forward\nKL (FKL) divergence. This approach guarantees asymptotic consistency and a fast\nconvergence towards both the optimal IS estimator and the optimal variational\napproximation. We empirically demonstrate on real data that our method is\ncompetitive with variational boosting and MCMC.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:00:24 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Jerfel", "Ghassen", ""], ["Wang", "Serena", ""], ["Fannjiang", "Clara", ""], ["Heller", "Katherine A.", ""], ["Ma", "Yian", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2106.16004", "submitter": "Tiffany Vlaar", "authors": "Tiffany Vlaar and Jonathan Frankle", "title": "What can linear interpolation of neural network loss landscapes tell us?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying neural network loss landscapes provides insights into the nature of\nthe underlying optimization problems. Unfortunately, loss landscapes are\nnotoriously difficult to visualize in a human-comprehensible fashion. One\ncommon way to address this problem is to plot linear slices of the landscape,\nfor example from the initial state of the network to the final state after\noptimization. On the basis of this analysis, prior work has drawn broader\nconclusions about the difficulty of the optimization problem. In this paper, we\nput inferences of this kind to the test, systematically evaluating how linear\ninterpolation and final performance vary when altering the data, choice of\ninitialization, and other optimizer and architecture design choices. Further,\nwe use linear interpolation to study the role played by individual layers and\nsubstructures of the network. We find that certain layers are more sensitive to\nthe choice of initialization and optimizer hyperparameter settings, and we\nexploit these observations to design custom optimization schemes. However, our\nresults cast doubt on the broader intuition that the presence or absence of\nbarriers when interpolating necessarily relates to the success of optimization.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:54:04 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Vlaar", "Tiffany", ""], ["Frankle", "Jonathan", ""]]}, {"id": "2106.16049", "submitter": "Charilaos Mylonas Mr.", "authors": "Charilaos Mylonas, Imad Abdallah and Eleni Chatzi", "title": "Relational VAE: A Continuous Latent Variable Model for Graph Structured\n  Data", "comments": "Code and simulated datasets will be released after finalization of\n  peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Networks (GNs) enable the fusion of prior knowledge and relational\nreasoning with flexible function approximations. In this work, a general\nGN-based model is proposed which takes full advantage of the relational\nmodeling capabilities of GNs and extends these to probabilistic modeling with\nVariational Bayes (VB). To that end, we combine complementary pre-existing\napproaches on VB for graph data and propose an approach that relies on\ngraph-structured latent and conditioning variables. It is demonstrated that\nNeural Processes can also be viewed through the lens of the proposed model. We\nshow applications on the problem of structured probability density modeling for\nsimulated and real wind farm monitoring data, as well as on the meta-learning\nof simulated Gaussian Process data. We release the source code, along with the\nsimulated datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:24:27 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Mylonas", "Charilaos", ""], ["Abdallah", "Imad", ""], ["Chatzi", "Eleni", ""]]}, {"id": "2106.16116", "submitter": "Carlo Ciliberto", "authors": "Alessandro Rudi and Carlo Ciliberto", "title": "PSD Representations for Effective Probability Models", "comments": "52 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a good way to model probability densities is key to probabilistic\ninference. An ideal model should be able to concisely approximate any\nprobability, while being also compatible with two main operations:\nmultiplications of two models (product rule) and marginalization with respect\nto a subset of the random variables (sum rule). In this work, we show that a\nrecently proposed class of positive semi-definite (PSD) models for non-negative\nfunctions is particularly suited to this end. In particular, we characterize\nboth approximation and generalization capabilities of PSD models, showing that\nthey enjoy strong theoretical guarantees. Moreover, we show that we can perform\nefficiently both sum and product rule in closed form via matrix operations,\nenjoying the same versatility of mixture models. Our results open the way to\napplications of PSD models to density estimation, decision theory and\ninference. Preliminary empirical evaluation supports our findings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 15:13:39 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 13:41:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Rudi", "Alessandro", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "2106.16225", "submitter": "Sidak Pal Singh", "authors": "Sidak Pal Singh, Gregor Bachmann, Thomas Hofmann", "title": "Analytic Insights into Structure and Rank of Neural Network Hessian Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Hessian of a neural network captures parameter interactions through\nsecond-order derivatives of the loss. It is a fundamental object of study,\nclosely tied to various problems in deep learning, including model design,\noptimization, and generalization. Most prior work has been empirical, typically\nfocusing on low-rank approximations and heuristics that are blind to the\nnetwork structure. In contrast, we develop theoretical tools to analyze the\nrange of the Hessian map, providing us with a precise understanding of its rank\ndeficiency as well as the structural reasons behind it. This yields exact\nformulas and tight upper bounds for the Hessian rank of deep linear networks,\nallowing for an elegant interpretation in terms of rank deficiency. Moreover,\nwe demonstrate that our bounds remain faithful as an estimate of the numerical\nHessian rank, for a larger class of models such as rectified and hyperbolic\ntangent networks. Further, we also investigate the implications of model\narchitecture (e.g.~width, depth, bias) on the rank deficiency. Overall, our\nwork provides novel insights into the source and extent of redundancy in\noverparameterized networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:29:58 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 17:57:50 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Singh", "Sidak Pal", ""], ["Bachmann", "Gregor", ""], ["Hofmann", "Thomas", ""]]}, {"id": "2106.16239", "submitter": "Tomasz Piotrowski", "authors": "Tomasz Piotrowski and Renato L. G. Cavalcante", "title": "Fixed points of monotonic and (weakly) scalable neural networks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We derive conditions for the existence of fixed points of neural networks, an\nimportant research objective to understand their behavior in modern\napplications involving autoencoders and loop unrolling techniques, among\nothers. In particular, we focus on networks with nonnegative inputs and\nnonnegative network parameters, as often considered in the literature. We show\nthat such networks can be recognized as monotonic and (weakly) scalable\nfunctions within the framework of nonlinear Perron-Frobenius theory. This fact\nenables us to derive conditions for the existence of a nonempty fixed point set\nof the neural networks, and these conditions are weaker than those obtained\nrecently using arguments in convex analysis, which are typically based on the\nassumption of nonexpansivity of the activation functions. Furthermore, we prove\nthat the shape of the fixed point set of monotonic and weakly scalable neural\nnetworks is often an interval, which degenerates to a point for the case of\nscalable networks. The chief results of this paper are verified in numerical\nsimulations, where we consider an autoencoder-type network that first\ncompresses angular power spectra in massive MIMO systems, and, second,\nreconstruct the input spectra from the compressed signal.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:49:55 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 15:29:10 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Piotrowski", "Tomasz", ""], ["Cavalcante", "Renato L. G.", ""]]}]